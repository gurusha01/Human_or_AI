This study addresses an issue with generative adversarial networks. Their struggle to accurately assess new data samples.The authors suggest an approach that involves adjusting the GAN objective function to make the discriminator act as an energy function rather than losing its effectiveness at equilibrium like in previous methods such as BiGANs and ALIs.The training process, for this updated objective involves estimating the gradients of the generated datas entropy which poses its set of difficulties. In order to tackle this issue effectively the writers introduce two methods of approximation ; one that relies on neighbors and another that utilizes a variational lower limit. The results, from the experiments show that for datasets the trained discriminator or energy model closely matches the log likelihood of the data. However for intricate datasets the discriminator offers a trustworthy evaluation of the quality of unseen data.
In my opinion one major drawback of the paper is the issues surrounding the scalability of nearest neighbors approximation and the accuracy of variational approximation as noted by the authors. Moreover considering the link, between entropy estimation and density estimation I ponder whether any real world application of EGAN might end up resembling approximate density estimation. A problem that GAN were initially meant to avoid. However the crafted mathematical presentation and theoretical insights of the paper enhance its significance, within the field. 
There are a couple of problems with the text that should be mentioned as well. For instance. The sentence found at the beginning of page 5 which reads "Finally 'let's whose discriminative power' seems incomplete or unclear. Its hard to understand what it means." Also. The title doesn't fully express the importance of the work as it suggests a slight enhancement, to an existing training technique instead of presenting a new and innovative training structure. 