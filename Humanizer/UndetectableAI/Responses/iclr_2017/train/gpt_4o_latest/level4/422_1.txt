This paper is mainly, about delving into a toy application in a crafted manner to show how SGVB can be used in state space models context by framing the model as a deterministic temporal transformation where innovation variables act as latent variables consistently distributed over time and focusing on estimating the innovation variables approximately instead of directly tackling the states. Though this method tackles an issue (such as not considering cases where priors, for beta values change over time) it still presents an interesting and useful use case scenario. However the way the concepts are explained could be improved by being clearer and more concise ; the paper quickly delves into details possibly missing an opportunity to make it easier for a wider audience to understand.
Kudos to the writers for including thorough information, in both the main body of the text and the appendix. 
The tests conducted on small scale models demonstrate possibilities. 
Section 2.According to our convention t typically equals w,t although there may be options available for this adjustment.It might be beneficial to explain that when beta is without Ft and B the treatment is not in a style (, for example it is solely fine tuned).
In the paragraph of Section 5 of the document mentions that a significant aspect is to ensure that the latent space aligns, with the transition process.This particular aspect seems straightforward to accomplish. 
In Equation 9 it suggests breaking down the recognition model into factors.  
Nowhere does it explicitly state the factorization method used. Speaking you could opt for q(beta|x)= q(w|x,v)* q(v).