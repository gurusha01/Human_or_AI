This article presents a method that uses a competitive framework to teach a model how to carry out tasks from a first person standpoint based on demonstrations from a third person viewpoint. By using training the model learns to extract features that are not dependent on the viewpoint (like novice expert or third person, vs first person) enabling the agent to apply the same strategy across various perspectives. 
The idea presented is quite clever and new (it was a read) but further testing is needed to support the approach fully. The key issue raised is the lack of a comparison point for reference. For example how would the model perform when trained using images captured from a perspective ? Its expected to outshine the suggested method. By how much exactly ? Also what changes in performance can be observed as we shift gradually from a person, to first person viewpoint ?There's a concern that the network could just be remembering the policy instead of truly learning it.This could mean that the features extracted from the input images might actually represent time intervals in a way that works across situations but still lets the policy be executed properly.It's something to think about since these experiments are happening in a setting.A simple way to check this would be to try out the algorithm from perspectives using blurry or differently presented images and/or starting from random conditions. 
More tests need to be done to understand the picture better in this study too! Like for example I have my doubts about the flipping technique mentioned in Equation 5.The experiments should include a comparison between GAN and EM style training with the gradient flipping method.The results shown in Figures 4 5 and 6 should have error bars, for accuracy and credibility. 