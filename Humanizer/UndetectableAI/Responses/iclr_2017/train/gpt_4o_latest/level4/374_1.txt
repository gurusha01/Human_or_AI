This study presents a gating method that combines word and character representations seamlessly.The new model sets a record breaking performance on the CBT dataset while showcasing enhancements over scalar gates in tasks, like SQuAD and Twitter classification without depending on linguistic attributes. 
Its quite expected that the vector based gate performs better than the gate because its design closely matches the gating mechanisms found in LSTMs and GRUs. In my opinion what makes this work significant is showcasing how integrating features such as POS tags. Ner can enhance gate learning effectively. The visual representation in Figure 3 and the instances, in Table 4 offer evidence of the benefits of incorporating these features—great job! 
In general¸ although the suggested gating method isn't groundbreaking technically¸ the document presents an significant contribution that I think will help the NLP community positively¸ so I'm hopeful, for its acceptance. 