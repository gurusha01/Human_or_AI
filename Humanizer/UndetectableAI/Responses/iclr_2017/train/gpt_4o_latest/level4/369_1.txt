The article delves into a method, for ternary weight quantization. 
Advantages; 
The study shows enhancements in performance when compared to approaches. 
Learning the quantization process of depending on pre determined algorithms designed by humans is a fresh approach that resonates with current developments, in machine learning trends. 
Areas of improvement; 
The papers contribution adds a little bit more, to the existing body of knowledge. 
The papers intended readership is limited to those versed in ternary quantization research history as it provides an update rather than a standalone piece in the fields latest advancements.The primary algorithm explanation is concise which may be easily understood by those already familiar, with this specialized field but less so by the general deep learning community. 
The work doesn't seem to have a reason behind it.The approach presented seems like an engineering tweak that could be useful if it was proven to be practical, in real life situations.However the paper doesn't effectively show why this tweak is necessary.Are there specific real life scenarios where this level of enhancement is needed?'Because its related to technology and thats cool' doesn't seem like a good enough reason. 
In my opinion and based on my understanding of the papers content and significance level within its field of study are not sufficient to justify its inclusion, at ICLR. A conference known for attracting a varied and extensive audience without clearer practical relevance or broader implications presented in the research work. 
Furthermore it seems that the code has not been shared with the public. 