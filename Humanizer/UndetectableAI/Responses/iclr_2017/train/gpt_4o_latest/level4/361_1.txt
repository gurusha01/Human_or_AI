The paper addresses the issue of forecasting learning patterns with two differences from earlier studies. The authors develop a neural network that can adapt across various hyperparameter setups and utilize a Bayesian neural network, with SGHMC.  
The writers present proof that their suggested technique excels at extending curves and forecasting learning curves for different architectures like FC CNN, LR and VAE. This strategy seems encouraging for Bayesian optimization. It would be intriguing to conduct an experiment to evaluate the advantages of this approach in comparison, to methods ;)
Have you thought about ways to handle changes, in the learning rate over time effectively in your algorithms training process? Maybe you could try out the algorithm on a random sample of the data first and then see if you can apply it more broadly. 
Reflecting further on ways to evaluate performance beyond just Mean Squared Error (MSE) and Log Likelihood (LL) I consider that in real world situations the main focus is typically on recognizing the most successful trial or experiment run among several options available, for assessment purposes. Is it valuable to analyze the precision with which each approach identifies the performing trial effectively? 
Here are a few minor recommendations; 
The text, in the images has small font sizes making it difficult to read when printed out. Please consider increasing the size for the labels and axes to improve readability. 
It appears that some graphs in Figure 6 do not show all six lines as expected.Wonder if overlapping lines could be the reason, behind this issue? 