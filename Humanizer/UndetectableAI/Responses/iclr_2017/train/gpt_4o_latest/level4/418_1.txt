The paper introduces a method for enhancing GAN training through the use of a computational graph to represent simultaneous SGD and unrolling inner optimization in the minmax game technique. The document is nicely. Offers detailed explanations, for the new approach. The issue discussed is of importance. Although the method is original it's worth mentioning that comparable concepts have been examined in areas of GAN research as well. 
In the quantitative study detailed in Section 3 of the report the objective was to pinpoint the ideal z value that can produce accurate training samples through a process of minimizing |generated(z). Actual(x)| using L BFGS optimization technique. As per the researchers assertion – pinpointing such a z value suggests that the generator can replicate the respective training sample. The findings illustrate that 0 step GAN models fall short in generating training samples compared to unrolled GAN models. Nonetheless I have reservations, about this experiment. The ability to determine a z value that creates a particular sample does not necessarily imply that this mode is highly probable. For example an identity function could perform better than all GAN models based on this measurement. Moreover Cantors demonstration of the equality among all powers of spaces indicates that this problem exists even for lower dimensional z values. In reality any generator should be able to generate any image by finding a precise z value. The presence of such a z value does not guarantee that the generator is free, from mode collapse; it simply implies that the generator operates in a manner to an identity function capable of replicating any image. As a result of this metrics findings seem to assess something related to diversity or missing modes indirectly.A further problem with this metric is that the inability to discover a z value for a training instance does not confirm the non existence of such a z—it simply suggests that it is more challenging to uncover one.This contrast might merely indicate that unrolled GAN models exhibit functions compared to 0 step GAN models which in turn facilitates the optimization process, for z values. 
In the quantitative study they did some math to compare how far apart the generated samples are from each other and from the real data samples.The writers suggested that when these two values are similar it means the generated samples have a range of diversity like the data itself.But there are doubts about this method, for two main reasons;(sighs).Firstly the distances were calculated based pixels which may miss out important distinctions.. Secondly a GAN could still get a good score even if its spitting out gibberish. 
The research paper doesn't provide specific numerical outcomes. Although the suggested approach aims to enhance variety it'd be wise to incorporate validation measures such as assessing Inception scores or SSL performance to gauge the quality of the created examples. Another potential assessment could entail training the GAN on the MNIST dataset (a compilation of three MNIST digits) that features 1k distinct and easily recognizable modes. Subsequently showcasing that the GAN produces all 1k modes with likelihoods would be beneficial, for the authors argument. Though not flawless in its accuracy measurement capabilities; this method may offer a dependable assessment compared to the metrics cited in the paper so far.This particular evaluation technique was utilized in a submission, to ICLR; 