Summary.
The research paper suggests a method for creating acoustic word embeddings by combining both sound sequences and their written counterparts in a shared space using deep bidirectional LSTM models and various loss functions like fixed margin and cost sensitive losses across multiple perspectives. They tested this method in scenarios such as distinguishing between different spoken words based on sound patterns and comparing words, from different viewpoints to show that it outperforms existing techniques. 
Resolution
After consideration of the papers content and approach to addressing a well defined issue in speech processing research as well as the comprehensive evaluation conducted in comparison, to prior studies and varied objectives and hyperparameters analyzed thoroughly within the papers contextâ€”I have chosen to accept it for publication. 
Justifying Points
The paper offers an nicely written introduction to the challenge of acquiring acoustic word embeddings while highlighting the importance of adopting a multi view perspective. It also includes an examination of prior research efforts, on acquiring acoustic word embeddings and multi view representation learning. The comprehensive experimental assessment involves comparing with studies and investigating the impacts of various objectives and hyperparameters. The findings indicate that the new method enhances upon research in distinguishing acoustic words and also excels in tasks related to recognizing words, across different perspectives and assessing word similarities effectively. 
More Input Welcome 
To enhance the paper further I recommend expanding on how the cost sensitive loss was implemented by delving into specifics such as the selection of hyperparameters and exploring the impact of margin values. It would also be intriguing to delve into an examination of the acquired embeddings complete with a representation of the embedding space and an assessment of word relationships. Lastly authors might contemplate including insights on potential uses for the suggested method encompassing speech recognition and query, by example search.
Queries, for the Writers
Could the authors please provide clarification on the following points?
How did the writers select the hyperparameters, for the cost loss and what impact did varying margin values have on the models performance? 
Could the writers elaborate further on how they applied the view contrastive losses, in their study. Specifically discussing their selection of negative examples and the impact of using various loss functions? 
How do the writers intend to expand the suggested method to handle vocabularies and more intricate speech assignments like speech identification and search, by example queries? 