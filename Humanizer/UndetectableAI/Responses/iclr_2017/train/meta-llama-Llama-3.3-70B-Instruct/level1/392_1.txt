Key Points, from the Document
The research paper suggests a method for enhancing autoencoders to compress images with loss efficiently. The authors present a impactful solution to handle the non differentiable compression loss issue during training deep autoencoders. This enables them to create results comparable, to JPEG 2000 and surpass newer methods using RNN models. Additionally the paper introduces an efficient architecture designed for processing high resolution images effectively. 
Choice
My decision is to approve this article mainly because the method is well justified and backed by real world data evidence. The article addresses an issue within the realm of image compression and the suggested remedy is innovative and impactful. 
Reasons, in Favor 
The research paper offers an brief overview of the issue of lossy image compression and the difficulties, in optimizing autoencoders for this purpose. The authors suggest a solution to tackle the non differentiable nature of the compression loss in a significant manner. The experimental findings showcase the efficiency of the proposed method as the autoencoder surpasses JPEG 2000 in SSIM and MOS scores. 
More feedback is needed. 
To enhance the paper further and make it more comprehensive and insightful, for readers I recommend that the authors delve into an explanation of how the entropy coding scheme and range coder were applied in the experiments. It would also greatly benefit the readers if they included visual representations of the compressed images like displaying full images as demonstrated in Appendix A. 6 To provide a depiction of the compressed images quality.
Queries, for the Writers.
To better comprehend the content of the paper in question I'd appreciate the opportunity to pose a queries, to the authors; 
Could you elaborate further on why you chose those hyperparameters for the experiments. Like the number of output channels and the Î± value? 
How do you intend to expand the suggested method to incorporate media formats, like videos or audio files and what difficulties do you foresee in the process? 
Could you give details about the balance, between the trade offs related to rate distortion and computational efficiency in the suggested method and how these balances can be improved in real world applications? 