Summary of what the paper brings to the table.
The article introduces a method for controlling movements in virtual reality settings by combining detailed sensory input, with simplified measurements. The writers suggest using a learning method that takes advantage of the simultaneous nature of these inputs to teach a control system for movements. This method allows for learning without having an objective during training and adapting to different goals during testing. The authors showcase how well their method works by conducting experiments, in three dimensional simulations using the traditional first person game Doom and surpass current cutting edge deep reinforcement learning models. 
Main Factors
"I have chosen to approve this paper for two reasons;"
The research delves into an issue in sensorimotor control by introducing a fresh and thoughtful strategy that moves away, from conventional reinforcement learning frameworks. 
The writers present experimental proof showcasing the efficiency of their method by outperforming cutting edge deep reinforcement learning techniques and achieving success, in various environments and objectives. 
Here are some points to consider.
The paper is nicely organized with an concise introduction to the issue at hand along with its background and relevant research findings laid out by the authors.Their proposed method is well elaborated upon. The experimental assessment is both thorough and well crafted.The outcomes are quite remarkable as their approach surpasses existing cutting edge techniques in situations.The paper also delves into an examination of the significance of vector feedback and forecasting measurements, across different time frames. 
Feel free to share thoughts or ask any questions you may have.
To enhance the paper further I would suggest that the authors; 
Could you share details, about the computational challenges of their method and how it could be scaled up to handle more intricate environments?
Lets talk about the drawbacks and obstacles of their method, like managing complex action spaces or addressing limited observability issues. 
I suggest incorporating images or diagrams to assist readers in comprehending the experimental configuration and outcomes. 
Please respond to the questions ; 
	How do the writers aim to expand their method to tackle action spaces or more intricate goal requirements? 
	Could the writers offer information about the structure and training process of the predictive network. Such, as the hyperparameter selection and optimization algorithms utilized? 
	How do the writers imagine implementing their method in situations, like robotics or self driving vehicles? 