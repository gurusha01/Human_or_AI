This document introduces a method for developing representations across various viewpoints of objects by using a triplet loss approach to reduce the gap between different perspectives of the same object and increase the gap with an image of a different object. The effectiveness of this approach is tested through experiments on retrieving object instances and categories comparing results with convolutional neural networks (CNN) such as an untrained AlexNet and a category classified AlexNet that has been fine tuned utilizing fc7 features, with cosine distance measurements. Moreover the research incorporates a contrast, with understanding of the dataset known as the "Tenembaum objects."
The paper has its points in possibly introducing a new approach by using triplet loss for this issue; however its uniqueness might be lessened due to ongoing research, in the same area as well as being well organized and easy to understand. 
Yet there are some drawbacks to consider well; it's important to highlight the absence of proper references and connections to previous research in this area to enhance the papers credibility, in the field. 
A study closely connected to this is the "image purification" research conducted by Hao Su and others at SIGGRAPH Asia 2015 conference presentation. The main goal of this work is to understand how shapes and images are related through CNN image purification, for object retrieval regardless of the viewpoint. Specifically it links CNN characteristics to custom made light field explanations of 3D shapes. It would be helpful to compare this method with the one mentioned earlier especially the cross view retrieval test described in Table 1 of the cited paper. Since the code and data for this research are accessible online conducting such a comparison seems achievable and could offer insights, into how well the suggested model works. 