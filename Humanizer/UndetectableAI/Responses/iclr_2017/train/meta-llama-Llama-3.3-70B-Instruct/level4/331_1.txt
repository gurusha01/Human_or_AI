This research paper suggests a technique for sharing skills across tasks in a controlled setting through reinforcement learning by applying an L₂ penalty to encourage consistency in the learned embeddings for two separate tasks.The trials conducted in MuJoCo included two experiments. One focusing on joint/link states (as detailed in sections 5. 5 And 5. 3 ). Another on pixel information (as described in section 5. 6) Showcasing successful skill transfer between arms, with varied link numbers and from a torque based arm to a tendon driven one. 
One significant drawback of this study is the belief that aligning time's an easy task because of the episodic structure and common domain of the tasks involved.However time alignment plays a role in domain adaptation and transfer and can be managed by methods such, as subsampling,dynamic time warping and developing a matching function like a neural network. 
The use of Canonical Correlation Analysis (CCA) as a point of comparison is appropriate overall; in light of the experimental nature of the study including an extra baseline that incorporates random projections for the embedding functions "f" and "g" could enhance the credibility of the results by demonstrating that the underperformance in the version without transfer is truly attributable, to excessive specialization of these embeddings. It is important to mention that the issue of acquiring feature spaces is connected to metric learning as explored in studies such as [X et al., 2002]. Additionally in the paper it would be useful to compare this with task learning in machine learning and when considering knowledge transfer (section 4..11),adjustments, to α could be a valuable aspect to consider. 
The experimental section seems a bit done to me. It's interesting to note that the baseline performance consistently showing zero (signifying no transfer) doesn't provide insight; this hints at the requirement for a larger sample budget. Also its puzzling that there are no results for "CCA " and "direct mapping " in Figure 7.b. Another aspect of the experiment that raises questions is how the authors managed any variation, in training iterations for the embeddings when transfer was utilized. 
The study of transfer, in reinforcement learning is an addition overall! The experiments are captivating and deserving of publication; however the paper could use a thorough approach. 