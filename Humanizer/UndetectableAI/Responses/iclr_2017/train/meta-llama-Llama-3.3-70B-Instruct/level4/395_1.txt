The writers present a software program for probabilistic programming that makes use of the latest developments, in deep learning technology. This software has the potential to transform the field of modeling by allowing for quick testing and refinement of concepts. By incorporating composability principles and expanding inference to include Hamiltonian Monte Carlo ( HMC ) of just traditional variational inference ( VI ) they have made the software even more attractive. 
Nevertheless the effectiveness of any programming language (PPL ) relies heavily on its capability to address practical scenarios, in the real world; a facet that was not sufficiently showcased in the submission itself. While the submission offers code excerpts a majority of them are left unassessed. Of note are the Dirichlet process mixture model example (referred to as Figure 12 ) and the GAN example (as seen in Figure 7 ) both of which necessitate empirical validation to determine the effectiveness of the proposed black box inference tools. It's important to show how the GAN example aligns with data when its optimized for better results.To prove that the package is useful in real life scenarios it's crucial to have demonstrations of these examples done.Although there has been an evaluation of an autoencoder (VAE) using different inference methods which can be easily put into practice with the available TensorFlow (TF) it's still necessary to showcase the convergence of the GAN example, with real data. 
When it comes to the presentation aspect of things 
Enhancing the papers presentation could be more effective by including additional cues to help readers anticipate upcoming explanations for better clarity and understanding of the content provided in the text example, on page 5 where introducing qbeta and qZ without prior context could be enhanced by indicating that an illustrative example will follow shortly thereafter. 
The authors may want to discuss the implementation of layers. How they deal with KL divergence, in Variational Inference (VI) in the preface. 
Clarifying the optimized values and the changes that happen during inference (before section 44 would be useful as it was confusing, for most of the document. 
When it comes to conducting experiments; 
"Table 1 stands out for not including information, on how something runs." 
The authors faced challenges with reaching a consensus on entropies but it remains uncertain if the toolbox they used includes tools, for diagnosing inference problems. 
The findings, from the HMC experiment discussed towards the end of page 8 lack details; only information regarding runtime is presented. 
It's not clear how simple it is to use inference methods like HMC when you don't have control, over the structure of the computational graph and sampler. 
A comparison chart that assesses how well different inference tools perform on models (including runtime and predictive log likelihood) would provide valuable insights. 
The authors face uncertainty in selecting benchmarks for the Model Zoo due to the absence of benchmarks in probabilistic modeling field; it is essential for them to clearly define the datasets for model comparison purposes, like the Dirichlet process mixture model. 
Minor feedback comprises; 
In Table 1 it would be better to compare it to Li & Turner with alpha set to 05 since they found that this value works the best. 
The explanation of distributions (like, in Figure 5 ) is confusing. 
In Figure 7 the variable x_real has not been defined. 
It would be helpful to emphasize the letter M in the illustration shown in Figure 8. 
After reviewing the document please ensure to place a comma after "rized" of a period, on page 8. 
To sum up my thoughts; The software advancements showcased are intriguing and pave the way for making "inference, for all" more feasible and user friendly; however the current version of the submission merits a rating of 5/10. The authors need to tackle the mentioned issues to showcase how practical the package is and to highlight its ability to revolutionise modeling. 