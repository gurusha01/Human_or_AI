This study delves into comparing word representations, between languages when the embeddings are trained independently in single language settings. The approach discussed in this study presents real world uses that present an interesting challenge. Overall the paper is well written. Lacks a comprehensive evaluation; engaging in a broader downstream task could have been advantageous. 
The idea of Softmax is quite intriguing. 
To improve the paper for publications quality and readiness for submission, to the journal editor.
The writers ought to recognize and talk about the research conducted by Haghighit and others in 2008 titled "Learning Bilingual Lexicons from Monolingual Corporations " as it serves as a crucial citation, for employing CCA in alignining bilingual content. 
The study conducted by Hermann and Blunsom in 2013 on "Creating Multilingual Representations without Word Alignment" should be referenced when discussing the development of multilingual word embeddings, from aligned datasets. 
Utilizing a range of linguistic pairings, in experiments would enhance the validity of the findings rather than just concentrating on European/Romance languages. 
The conversation about the need for orthogonality appears to be connected to utilizing either a distance or covariance matrix to understand these mappings better; this topic could benefit from further exploration, during the discussion. 
When discussing the alignment of words, across languages in a more straightforward manner without using the term "translation " consider using alternative language to avoid implying a more intricate procedure than intended. 
The abstract needs to be revised to fix the error, in the Mikolov citation. 