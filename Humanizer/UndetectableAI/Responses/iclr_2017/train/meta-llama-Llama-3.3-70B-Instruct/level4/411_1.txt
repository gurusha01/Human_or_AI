This study builds upon the STOKE superoptimization engine (Schkufza et al., 2013) which focuses on enhancing program binaries through adjustments to existing programs using a proposed distribution method and evaluating these adjustments following the principles of Metropolis Hastings criteria.The criteria takes into account the correctness and efficiency of the program modifications. Increases the probability of Markov Chain Monte Carlo (MCMC)s success, in producing accurate and high performing programs. Usually in this kind of scenario the proposal distribution remains constant; however this study takes an approach by adapting the proposal distribution based on program characteristics. Specifically focusing on the collection of words from all operation codes in the program itself. Comparisons were made experimentally with methods such as a uniform proposal distribution and a trained proposal distribution without feature conditioning; results indicated a slight enhancement, in performance when using the method proposed in this study. 
However​ the importance of this study within the scope of ICLR seems to be restricted​ as it simply applies neural networks and REINFORCE to a task involving non differentiable elements rather than introducing a groundbreaking approach to representation learning​ The superoptimization task itself may not capture attention from the ICLR community indicating that conferences such, as AAAI or UAI could be better suited for this topic​
The idea presented is unique in how it incorporates learning into MCMC based synthesis methods that usually do not involve learning aspects all. Showing how this approach can be applied to synthesis tasks or even broader tasks using Metropolis Hasting MCMC methods where a trained proposal distribution could be advantageous would add value to this research. The heavy emphasis on superoptimization with slight enhancements compared to standard methods is not very convincing, in its current state. 
Moreover it is not certain if significant representation learning takes place in this method. By using a bag of word feature to portray programs the neural network is limited to identifying relationships between opcode occurrences and successful actions without delving into the meanings of program semantics. A intriguing addition could have been to utilize a model such, as Tree LSTM, which aims to grasp program semantics. The basic nature of the learning technique used diminishes the papers chances of being accepted. The authors could offer perspectives in response, to questions raised by reviewers to enhance the thoroughness of the evaluation. 