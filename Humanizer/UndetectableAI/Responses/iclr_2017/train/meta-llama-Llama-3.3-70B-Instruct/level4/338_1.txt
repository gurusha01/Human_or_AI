The way you explained the concepts of highway and residual networks was really insightful! It shed light on how each layer learns representations, in these models by incorporating residual information at specific points to preserve feature identity and prevent the problem of lesioned layers often seen in convolution neural networks. 
The paper excels, in the following aspects; 
The concept of unrolling is quite clear and easy to understand due, to its strong theoretical basis and logical assumptions. 
Figure 3 provides an illustration of the iterative unrolling viewpoint in a way that enhances understanding effectively. 
Nevertheless, 
While the perspective is interesting, in the paper mentioned. It could be improved with additional empirical evidence to support its arguments further.The experiments mainly center around image classification and character based neural language models that do not fully delve into the possibilities of the suggested concept. 
Figures 4 and 5 could be. Made larger to better illustrate the effects of batch normalization and enhance the argument being made. 