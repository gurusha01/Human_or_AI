This document introduces a method to reduce the effects of adversarial examples by using an additional classifier to recognize them. From the tests conducted in the study it was shown that adversarial examples are easily identifiable and the suggested detector is effective in identifying less powerful adversarial examples. Even though the idea itself is simple to understand its implementation poses challenges. Although not offering a system for incorporating this concept into defense mechanisms as of yet the paper suggests a hopeful path, for future studies. In my opinion and considering its groundbreaking impact I suggest approving it. 
I am mostly worried about this paper not being thorough enough, in addressing how to defend against changing opponents effectively.Itâ€™s clear that tackling this issue might not be easy but the paper seems to have not put in work in this area.Examining the possibility of defending against adversaries is an important and interesting question that emerges from the conclusions of the paper and such an exploration could greatly boost our knowledge of adversarial examples.Although theres this drawback the paper still brings ideas to the table. 
Just a quick note; 
The document could use explanations by including key information thats currently missing; for example; a more thorough description of dynamic adversaries and the approach used for training, against them in a dynamic setting. 