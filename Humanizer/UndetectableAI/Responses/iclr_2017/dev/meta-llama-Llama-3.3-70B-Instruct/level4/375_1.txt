This paper introduces a probabilistic framework for weighted bag of word models which adds an interesting perspective to the field of study. The upcoming comparison, with the work of Wang and Manning is expected to strengthen its argument more. Nevertheless it is important to note that for datasets NB SVM still proves to be the more efficient method. 
In the to last paragraph of the introduction section mentions the challenge of high co occurrence frequencies being tackled by Glove embeddings using their weighting function f. 
Here are a few tweaks that could help enhance the quality of your work;. Rectify the error in the line of the introduction where it says "The capturing the similarities.‚Äù. Adjust the citation style in the sentence " learned (by Wietling et al., 2016)" to use the citing format rather than using parentheses, for citations. 