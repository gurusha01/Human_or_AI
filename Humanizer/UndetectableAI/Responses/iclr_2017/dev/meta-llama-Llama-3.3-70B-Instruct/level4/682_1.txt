The authors recommend using leak proof rectified units instead of binary units in Gaussian Restricted Boltzman Machines (RBMs). They introduce an approach, to sampling for training the leak proof ReLU RBM and present results that include estimating the likelihood using Annealed Importance Sampling (AIS) on Cifar10 and SVHN datasets. 
The investigation into nonlinear hidden units for RBMs stands out as significant. Nevertheless there are an issues, with the present study that require attention; 
The explanation for the sampling method proposed in Algorithm 2 is not clear enough. Needs a closer look, at the extra computational work involved in the inner loop and projection stages. 
The Gaussian Restricted Boltzmann Machines performance does not meet expectations when considering both likelihood and generated samples; this indicates problems, with the training process. 
Effective generative models often improve classification accuracy when there are limited labeled samples for training purposes This is especially true when Gaussian RBMs are used for tasks like texture synthesis that require adept blending of features The authors suggest further experiments, in these domains to fully showcase the potential of their model