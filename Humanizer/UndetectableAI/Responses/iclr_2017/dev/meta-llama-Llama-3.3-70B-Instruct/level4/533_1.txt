The authors present an approach to using surprise based intrinsic motivation within deep reinforcement learning that sets it apart from other recent methods of intrinsic motivation in a clear manner. Backing up their method with real world results across areas involving both distinct and ongoing action possibilities. They introduce two versions of their framework; one that overlooks the unpredictable aspects of environmental changes and another that gauges the pace of acquiring informationâ€”reflective of Schmidhubers theory on creativity and intrinsic motivation, with a dash of amusement. Adding an exploration bonus to TRPO results in performance than the regular TRPO method does provide some benefits. However it would be helpful to conduct a thorough assessment by comparing it with other recent studies on intrinsic motivation. For instance the research conducted by Bellemare and colleagues in 2016 showed performance enhancements in challenging Atari games like Montezumas Revenge when DQN was combined with an exploration bonus ; although these findings did not include results, for this specific game. Including comparisons would greatly strengthen the credibility and significance of the paper. 