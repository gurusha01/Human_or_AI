This paper discusses the issue of maintaining privacy in a range of scenarios by training various teachers with separate sensitive data sets and having a student model make predictions using publicly available data annotated by teachers through a noisy voting method The authors present their method in a logical and understandable manner that is easy to grasp However delving deeper into the limit set out in Theorem 1 and its accuracy would enrich the conversation The authors skillfully apply the idea of introducing error perturbation into counts. A practice in differential privacy research. To a more intricate non linear setting with real world significance that goes beyond what other studies in the field have achieved so far.The versatility of the methodology and its substantial advancements over research efforts along with the clear presentation collectively provide strong support, for its publication. 