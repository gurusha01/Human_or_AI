This article introduces a system for classifying products using various modes including images and text with three key components; an Image CNN based on the VGG 16 framework) a text CNN inspired by Kim 2014s work) and strategies for combining decisions at the fusion level. The researchers investigate fusion methods such as merging probabilities from the text and image CNN models choosing predictions from one of the CNN models averaging the results and conducting end, to end training. The research findings suggest that the textual CNN performs better on its own compared to the image CNN; however combining both through modal fusion only leads to a slight increase in accuracy. Surprisingly the end to end feature level fusion yields results than the standalone textual CNN, which is somewhat surprising. The paper is articulate. Offers valuable perspectives on the real world hurdles of training extensive models. Nevertheless I lean towards suggesting rejection, for the following reasons; 
The research is constrained to one dataset without any results presented on additional datasets; reproducing the conclusions will be significantly challenging without the release of the Walmart dataset.   
The technical advancement is small. The merging methods, at the decision level have already been studied in previous research.   
The progress made in enhancing performance is minimal. 