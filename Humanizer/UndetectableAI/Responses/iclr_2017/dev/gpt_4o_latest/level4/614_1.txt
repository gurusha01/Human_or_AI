The research paper introduces a recommender system that considers the passage of time and utilizes point processes with evolving representations of users and items as parameters. These hidden representations follow processes that interact with each other as users engage with items over time and are influenced by their previous representations. This dynamic process of evolution is termed as coevolution, in the paper. Is achieved through a recurrent neural network model that can handle diverse inputs effectively. The authors test their method through experiments using datasets and evaluate how well it performs compared to other standard techniques. 
The paper offers contributions; 1. It presents recommendations as a challenge involving point processes controlled by evolving hidden user/item characteristics. 2. It suggests an optimization method to enhance the likelihood of this process by employing tactics to address its complexity. 3. It carries out experiments to assess time recommendations. 
In a study by the authors (NIPS 2016) they presented a similar model of continuous time coevolution and used a comparable evaluation method.The main distinctions are in the details of the models; although there are variations, in the point process formulation and latent factor dynamics the general modeling approach and arguments stay mostly unchanged. It remains uncertain what exactly leads to the enhanced efficiency of the model in comparison to the NIPS paper. Be it the selection of the point process or the revised parameterization and other elements involved in its performance boost.The paper also lacks an explanation, for why a particular form of point process was chosen in both works.Did the authors consider exploring formulations instead? The dynamic process faces the issue regarding non linearity in modeling latent user/item vectors being confined to a sigmoid function that might not show much difference from a linear model as, per the papers findings lack evidence to explain the significance of this non linearitys role or impact clearly; besides that discrepancy exists in the results presented across the two papers. 
In the evaluation section of the study by the authors suggests two criteria for assessment; however; the explanation concerning the evaluation of recommended items lacks clarity.The models prediction of the users interaction with an item at each time t is mentionedâ€”is this about predicting the item a user will interact with post time t? The significance of this metric, in recommendation tasks regarding time prediction is not sufficiently explained.  
It would be helpful to include a comparison of how it takes for the proposed method to run compared to other methods, in the paper. 
Overall the paper seems solid and well done; however it overlooks some points that need to be addressed in more detail. Additionally the similarities with the NIPS 2016 paper bring up questions about whether this study presents a significant advancement or just a small update, to previous research. The assessment methods could be more compelling. There isn't enough proof that the model suggested can handle large datasets efficiently. 