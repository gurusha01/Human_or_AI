This study shows that combining a reinforcement learning (RL) method with additional tasks improves navigation performance in challenging environments effectively. In this research paper conducted on the RL problem using the A3C algorithm as the base model approach and incorporating training, on two tasks. An unsupervised depth prediction task and a self supervised loop closure classification task. While its not new to use tasks to enhance model training for RL agents in this field of study is the emphasis on utilizing tasks that enhance the grasp of fundamental spatial and motion representations to enhance performance, in maze navigation challenges significantly. 
The article is nicely. The results from the experiments are quite convincing. Its clear how the additional tasks contribute to solving the problem at hand. That being said it seems like the new findings are somewhat small compared to what was known about reinforcement learning for navigation and auxiliary tasks in the field.The study would attract interest if it included a deeper analysis or fresh insights.Like exploring visual or geometry based tasks to find out which combination works best for visual navigation.. Delving into how auxiliary tasks play a broader role, in reinforcement learning. The paper currently showcases an exemplification of how geometry based additional tasks can aid in navigation but might have restricted interest because of its somewhat narrow scope. 