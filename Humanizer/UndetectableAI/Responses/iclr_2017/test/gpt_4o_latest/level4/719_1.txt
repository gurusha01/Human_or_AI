The article suggests a method for overseeing the training of neural networks that doesn't depend on labels directly but instead uses information, on whether pairs of examples are linked or not linked to train a pair of networks in which each network supervises the other. 
The paper could use some work in terms of clarity and writing quality.   
I find some design decisions lack reasoning. Such as the use of the power function in the E step to estimate the distribution (Section 2). Why limit oneself to a distribution? Although I grasp the idea of maintaining no knowledge assumption about classes, with a different prior could challenge this notion it's hard for me to imagine real world situations where this framework would actually work. 
Moreover there is an amount of research, in the field of semi supervised learning that utilizes co training principles based on a comparable idea. 
I think this work needs explanation and improvement to better match the standards of this place. 