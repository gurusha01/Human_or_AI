The article outlines a series of recommendations for creating neural network (CNN) structures specifically tailored for tasks related to image processing and computer vision. Essentially serving as a review piece that captures the CNN designs while also presenting some innovative architectural ideas influenced by these guidelines. These new concepts have been put to the test using CIFAR 10 and CIFAR 100 datasets; however their effectiveness, with these datasets seems limited (as shown in Table 1) casting doubt on their significance. 
Publishing a research paper based on compiling rules from existing studies raises some doubts in my mind about its significance and originality in the field of computer vision dominated by Convolutional Neural Networks (CNN) for quite some time now. While there could be advantages in summarizing these observations for newcomers entering the field of computer vision technology; it seems like a good portion of the content is knowledge or common sense (such as rules 1 3 7 11). The remaining information could be more suited for a course, on training CNN or even a blog post. The paper appears to put a lot of emphasis on small advancements and spends a considerable amount of time discussing the different variations of ResNet. 
The paper argues that it's a practice in all convolutional neural networks to decrease activations while increasing the number of channels from the initial to the final layer; however this assertion is inaccurate.In relation to design pattern 5 as previously mentioned the explanation given—that design patterns only apply occasionally—doesn't support making generalizations, like this one.It may be best to reconsider including this statement. 
The statement in section 3. 1S second paragraph about normalizing data to create a level playing field for input samples and enhance the effectiveness of backpropagation lacks clarity. Requires further explanation. Furthermore starting the sentence with "we feel " may seem out of place since this matter should be substantiated by evidence rather, than personal opinion. The paper contains recurring instances of language that need to be addressed for better precision.
The link, between Taylor series and the suggested Taylor Series Networks appears tenuous. The choice of name seems questionable as well.The outcome function isn't a polynomial all since each term represents a separate function  f(x) g(x)^2, h(x)^3, etc. forming a nonlinear function of x without any standout characteristics. 
The paper seems like a jumble of thoughts and findings, without an organization and the experimental outcomes don't strongly back up its main points. 