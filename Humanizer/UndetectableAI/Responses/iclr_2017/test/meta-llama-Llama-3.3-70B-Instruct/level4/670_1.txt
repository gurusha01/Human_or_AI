This paper delves into the evolution of state representations using multi task reinforcement learning methods The writers present a fresh approach that combines gated neural networks, with multi task learning while incorporating robotics priors Their technique is tested on two simulated datasets and shows promising results The paper is well organized and showcases strong theoretical foundations 
Advantages; 
The use of gating mechanisms helps in achieving a representation, in the learning process. 
Expanding multi learning beyond single task situations, in prior studies stands out as a significant advancement. 
The use of loss functions (such as Coherence and Proportionality, alongside Causality and Repeatability; and also Consistency and Separation included in the mix) helps create a strong and reliable representation. 
Areas, for improvement; 
The choice of parameters the w parameters seems to be somewhat random. 
The multi task learning framework is limited to separate tasks instead of utilizing common knowledge and transfer learning across tasks. 
Using a simulation platform, like OpenAI Gym could have made the experimental results more comparable. 
To enhance the manuscript further I recommend that the authors should think about taking a structured approach to selecting model parameters and testing their method on a wider range of standardized datasets, with high dimensions. 