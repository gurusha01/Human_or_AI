This document showcases how a deep reinforcement learning (RL) system benefits from tasks to effectively navigate intricate environments.The strategy uses A3C to address the RL challenge while also teaching the agent unsupervised depth prediction and self supervised loop closure classification simultaneously.Although its practice to use auxiliary tasks to improve model training for RL agents,the key innovation here is integrating tasks that promote the growth of an inherent spatial and motion representation result in significant advancements, in maze navigation exercises. 
The article is nicely. The research conducted is convincing in showcasing how auxiliary tasks can help tackle the issue at hand effectively. Despite that the value added by this study is notable to some extent it doesn't bring about a leap forward considering the plethora of existing studies focusing on reinforcement learning, for navigation and auxiliary tasks. To enhance the importance of this study further and delve deeper into identifying the effective mix of tasks for visual navigation (including exploring the advantages of different visual or geometry based tasks) as well as considering the broader integration of supplementary tasks, in Reinforcement Learning (RL) additional research would be essential. The current draft offers a demonstration of how geometry focused auxiliary tasks can benefit navigation; however it does so within a limited range of focus. 