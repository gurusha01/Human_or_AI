This study investigates the terrain of enhancing deep learning effectiveness by examining how it behaves with optimization techniques¬—offering insights into how these methods operate in practice. It largely follows the framework outlined by Goodfellow and colleagues back in 2015; however; its unique insights remain somewhat ambiguous—especially regarding the idea that identical starting points, for various algorithms can lead to diverse outcomes upon convergence. The authors could improve the paper by explaining the principles more clearly from the beginning and addressing an important question, about how their findings can shape future research in optimizing deep learning methods more effectively. Although the paper is interesting its connection, to the conferences theme appears to be less clear compared to how it fits within the context of a journal.  
It would be helpful to enhance the findings by adding graphs showing the eigenspectra of the results, from each algorithm to better understand the critical points hierarchy and as a way to double check the accuracy of the outcomes. 