The authors have genuinely tried to delve into the " essence of learning representations in neural networks " a topic that holds great interest and importance, in our fields realm of study. They have chosen to use pruning algorithms to see how performance is affected when units are removed. While this idea is interesting and could offer insights I feel it doesn't quite reach its desired objective. 
At glance I felt that the introduction to pruning went into too much detail and didn't bring anything new or unexpected, to the table.. For example Figure 1. A large part of Section 3 are not really needed.. The suggested pruning methods seem logical. May be too basic and would only make sense if they directly tackled the research query.. Nevertheless in my view this paper doesn't present a brief or inventive takeon pruning..
Moreover. Most importantly in my overall evaluation Section 4 lacks a detailed analysis and only touches upon the surface of the subject matter.The data mainly demonstrates the expected decrease, in effectiveness as neurons are eliminated or values are modified.The experiments focus â€¯on a simple scenario and MNIST dataset which does not provide enough evidence to persuade me that the conclusions can be applied broadly to neural networks. 
In the end the paper fails to provide perspectives on algorithms, architecture and mathematics which I view as crucial elements, in all papers except those focused mainly on experiments.