This study introduces SYMSG ( Stochastic Gradient Descent) a parallelized algorithm that maintains the sequential essence of SGD on average results level wise. SYMSG employs a model combiner based on probability to merge models acquired by each processing thread enabling parallelization of SGD while keeping its convergence characteristics intact. It is designed for classifiers with linear updating guidelines and underwent testing on 9 sets of data demonstrating an acceleration of up to 13 times compared to a finely tuned sequential reference point, on 16 processor cores.
Outcome to approve.
The paper addresses an issue in parallelizing Stochastic Gradient Descent (SGD) a commonly used technique, for regression and classification tasks. The method is well founded. The authors explain the shortcomings of existing parallelization methods clearly. Additionally the paper conducts an assessment of the new algorithm showcasing its accuracy and performance effectively. 
The study offers an examination of how SYMSGD maintains convergence rates similar to those of sequential SGD through detailed analysis and empirical testing across various datasets to showcase its scalability and precision in real world applications while also highlighting its ability to overcome the constraints posed by existing parallelization methods, like HOGWILD!. Allreduce. 
To enhance the paper more effectively the authors might consider adding further insights into how SYMSGD is implemented especially regarding the optimizations employed to minimize the computational burden of the combiner matrix. Furthermore a deeper analysis of the balance between the projected spaces dimensionality and the algorithms accuracy could be beneficial. Lastly it would be valuable for the authors to test SYMSGD on a range of datasets including those, with non linear update rules to showcase its versatility across various machine learning applications. 
Authors Questions; Could you please elaborate more about the costs involved in calculating the combiner matrix and how these costs are minimized in real world scenarios? Also interested in knowing the authors strategies for expanding SYMSGD to accommodate linear update rules similar to those in logistic regression. Furthermore could you delve deeper into the trade offs linked to the dimensionality of the projected space, versus algorithm accuracy. Explain how these trade offs are influenced by different datasets and learning tasks? 