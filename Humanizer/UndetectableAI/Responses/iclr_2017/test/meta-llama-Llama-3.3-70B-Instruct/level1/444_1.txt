In a nutshell.
This research introduces a method to show how certain inputs impact the results of a Long Short Term Memory (LSTM) network visually. The writers suggest breaking down the LSTMs output into factors that each represent the significance of individual words. They apply these importance ratings to identify phrases in a trained LSTM and test their accuracy by inputting them into a classification system based on rules. They showcased the method using sentiment analysis and question answering assignments. Achieved encouraging outcomes. 
Choice
After consideration of the content provided in the paper presented to me for review and evaluation purposes; I have chosen to approve it based on two significant factors that influenced my decision making process. First and foremost is the papers focus on addressing an issue within the realm of natural language processing â€“ specifically concerning the interpretability of LSTM models. Additionally the methodology highlighted in the paper demonstrates a rationale and is complemented by an in depth examination of existing research, in the field. 
Points, in Favor 
The paper offers an brief summary of the previous research work while pointing out the constraints of current methods for visualizing LSTM models. The authors introduce a technique for breaking down an LSTMs output after conducting a comprehensive mathematical examination. The results from experiments show the efficiency of this method as the extracted phrases closely reflect the LSTMs output. Additionally the paper carries out a comparison, with different methods emphasizing the benefits of the new approach. 
Input; More comments.
To enhance the paper further I recommend including instances of the identified phrases and conducting a thorough examination of the mistakes made by the rule based classifier. It could also be intriguing to compare this method with interpretability techniques, like attention mechanisms or saliency maps. Lastly the authors should contemplate offering information on the computational expenses involved in this approach and how it could be applied in practical situations. 
Queries, for the Writers 
To better grasp the contents of the paper. Deepen my comprehension of it. I have a questions, for the authors; 
Could you please share information, about the computational expenses related to this method and how they stack up against other ways to interpret the data? 
How will you expand the methodology to include intricate models, like transformers or graph neural networks? 
Could you share instances of the phrases you've identified and explain how they connect to the particular assignment or dataset, at hand? 
How do you reckon this method could be applied in situations like sorting texts or answering questions, in real life? 