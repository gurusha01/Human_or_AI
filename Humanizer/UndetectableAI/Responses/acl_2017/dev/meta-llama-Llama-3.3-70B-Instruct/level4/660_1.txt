The paper suggests two ways to create English poems; one method involves using a neural phonetic encoder to predict the following phoneme and a phonetic orthographic Hidden Markov Model (HMM) while the other method uses a character language model along, with a weighted Finite State Transducer (FST). This second method is used to add rhythm constraints to the language models results. Furthermore the writers present a strategy for the second method that enables the creation of poems linked to a specific theme (such as love) or poetic techniques (like alliteration). The created poems are assessed internally by examining the rhythm of produced lines, against a benchmark and externally through a study involving 70 assessors who determine if a poem was authored by a person or a machine and rate the poems based on their readability, structure and emotional impact. The findings show that the second model performs better, than the one making it challenging for human evaluators to differentiate between poems written by humans and those generated by machines. 
This article is really captivating and nicely crafted as it introduces concepts such as two unique approaches, to creating poetry; one utilizing a phonetic language model and the other relying on a character language model; both backed by compelling outcomes. 
However It would be useful to have specific details about the evaluators and the evaluation process for a better understanding of the results. In particular it would be beneficial to know if all evaluators reviewed every poem and if not how many evaluations were gathered for each poem in each category. The reference to 9 evaluators who're not native English speakers raises concerns, about their language proficiency since poems are often challenging to interpret. 
The second model (character based) doesn't seem to have a way to stop creating words that don't exist. It would be interesting to find out how often these made up words appear in the poems generated by this model. 
In the model design decision was made to utilize an HMM for converting phonetic information into written representation instead of a Conditional Random Field (CRFs) requiring clarification. 
The initial model might not be the choice for generating poetry in general; focusing more on evaluating the second model could have been more captivating instead. A deeper exploration, into how the heuristic influences the restriction of themes or poetic devices would be truly fascinating. Exploring how these constraints influence evaluation outcomes and if they can work together to restrict both theme and poetic devices simultaneously would offer perspectives. 
The idea of using a model in conjunction with a WFST reminds me of earlier research like the study "Generating Natural Language using Character Based RNNs with Finite State Preceding Knowledge " authored by Goyal et al (COLING 2016). This study merges character based models for creating dialogue acts, with a WFST to prevent the generation of nonsensical words. 