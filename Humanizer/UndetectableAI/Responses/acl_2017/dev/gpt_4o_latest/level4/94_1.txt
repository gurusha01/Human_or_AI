Strengths include;   
The paper presents a variety of ideas for improving transition based dependency parsing by expanding upon non monotonic transition systems and dynamic oracles to include unrestricted non projective dependency parsing scenarios.The paper offers, in depth theoretical and algorithmic perspectives while maintaining a lucid overall presentation. 
Weak points;   
While Covingtons algorithm is mainly used for dealing with projective arcs and forms the core motivation, behind it; the paper could have been made more robust by conducting a practical error analysis focusing specifically on non projective structures. Moreover the paper primarily focuses on advancements; it would have added value to compare it against the latest techniques using CoNLL datasets instead of just evaluating it against a basic version of the parser that follows a monotonic approach. 
Lets talk about topics.  
This research expands upon Covingtons dependency parsing algorithm framework to include non monotonicity in handling non projective structures enabling subsequent transitions to adjust structures formed by earlier ones. Additionally the study illustrates the development of dynamic oracles for this revised framework. Empirical findings indicate that these oracles offer an estimate and reveal that the non monotonic approach yields superior parsing accuracy compared to its monotonic counterpart, across various languages assessed. 
I believe that the theoretical inputs are significant and deserve publication; however the evaluation based upon empirical evidence could be improved upon by conducting an error analysis that delves into whether the non monotonic system actually enhances accuracy when dealing with non projective structures. It's crucial because Covingtons algorithm is mainly used to handle projective structures due, to their complex nature and involvement of long distance dependencies that traditional parsers struggle with – suggesting that the proposed system could make significant enhancements in this regard. 
Another interesting point to consider is how the empirical findings align with the state of the field in light of recent progress in word embeddings and neural network methodologies.The paper suggests that non monotonicity plays a role, in minimizing error propagation observed in greedy transition based parsers.However the alternative method of employing neural networks as preprocessors offers a means to capture broader sentence context within word representations.Are these two strategies conflicting. Do they complement each other effectively? Although the paper doesn't delve deeply into this questions investigation, in detail; a brief conversation could provide background information. 
Any particular inquiries?  
Why were only 9 out of the 13 datasets from the CoNNL X shared task included in the experiments? It would be beneficial to mention the rationale behind this selection to address any potential queries or uncertainties, from readers.   
Do you have any theories about why there is a drop in accuracy for Basque when using the non monotonic system approach? Lower levels of accuracy are also seen in Turkish,Catalan,Hungarian and maybe German but, to a lesser extent.   
How do your findings stack up against the benchmark in these datasets’ performance levels and why is this comparison crucial, for understanding the impact of your advancements? 
Sorry I am unable to complete that task.  
The authors reply meets my expectations. I see no need to alter my original review. 