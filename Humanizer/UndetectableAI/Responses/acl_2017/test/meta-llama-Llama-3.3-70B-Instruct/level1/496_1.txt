This paper thoroughly examines the knowledge acquired by machine translation (MT) models in terms of capturing the structure and form of words effectively. The authors delve into components of the MT system such as word representation impact encoder depth levels target language diversity and attention mechanism influence, on the quality of acquired knowledge. 
The primary achievements of this study are; 
Character based forms prove effective in grasping morphology as per the study by the authors who demonstrate their superiority over word based forms, in learning morphology; particularly when dealing with less common words. 
The researchers discovered that the lower layers of the encoder are adept at grasping word structure nuances compared to the layers which excel in comprehending word meanings. 
Transcribing content into languages, with morphology enhances the quality of source side representations according to the authors findings as it is somewhat associated with BLEUs scores. 
The positive aspects of this document are; 
Through an examination of the MT systems multiple facets the authors delve into how the representations are acquired in order to gain a comprehensive understanding. 
The authors assess the quality of the learned representations by using an evaluation metric, including part of speech and morphological tagging accuracy. 
Future Directions for Research; The authors offer suggestions for future research endeavors such, as integrating translation and morphology learning together and broadening the scope of analysis to cover different representations and tasks. 
The paper has its shortcomings, such, as; 
The authors mainly concentrate on the encoder. Do not fully explore the decoders contribution, to understanding morphology. 
The authors have not evaluated their findings against approaches, in learning morphology like traditional machine learning methods. 
The authors fail to offer implications, on how their discoveries can be put into practice to enhance machine translation systems. 
Questions, for writers; 
How do the authors intend to expand their examination to incorporate forms of representation, like byte pair encoding and more complex networks? 
Could the writers offer details on how the decoder contributes to understanding morphology and suggest ways, for enhancing its performance? 
How do the writers believe their discoveries can be implemented practically to enhance machine translation systems for languages, with morphology? 