Advantages; 
This paper effectively combines two areas of study. Human text readability and machine text comprehension. 
Areas needing improvement; 
The main goal of the paper is not clearly. May take several readings to fully understand the message being conveyed which is still not very clear. 
The article lacks clarity as it doesn't clearly differentiate between machine understanding and the readability of text. 
Important contributions, in the field of readability often go unnoticed. 
Section 3 delves, into concepts that stray from the main focus of the paper. 
The paper tries to tackle questions at once which could lessen its overall effectiveness; for example examining how text readability affects Reading Comprehension (RC) datasets should be done independently from assessing prerequisite skills. 
Lets talk about this in general. 
The titles lack of clarity could be cleared up by stating that it pertains to understanding machine generated text of human reading comprehension since the phrases "reading comprehension" and "readability" usually suggest the latter. 
The assertion that analyzing datasets indicates that the readability of RC datasets does not directly influence the level of question complexity depends on the method used; for example using POS or dependency parse features to detect answers. 
The document needs a review to correct any English errors, like the sentence "the question is easy to solve; just look..." found on the first page. 
It's not clear how datasets are annotated with "metrics".
The paper mixes up machine reading comprehension with reading comprehension even though they are different areas of study, with some similarities. 
The difference, between the "readability of text" and the "difficulty of reading contents" is explained by DuBay (2004).
The paper could be clearer by giving context to differentiate its focus on machine comprehension from human question readability; for example by including "for machine comprehension." This would help clarify statements, like "These two examples demonstrate that text readability may not always align with question difficulty " as seen on page 1. 
Section 3A could use some clarification regarding whether the skills mentioned're meant for humans or machines specifically. 
Having information about how the annotators approached the annotation process is crucial for an understanding of the task, at hand. Including the quantity of questions they annotated and their grasp of whether the task revolved around machine or human comprehension. 