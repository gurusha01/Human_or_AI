The research analyzes the concluding remarks of narratives in the dataset created for the story cloze challenge by Mostafazade et al., 2016. Suggests a model based on character and word ngrams to categorize story endings showcasing enhanced results on the story cloze challenge in contrast, to earlier studies. 
While examining writing style is fascinating and the research paper shows improved outcomes compared to investigations on the story cloze task; there are a few areas that could be enhanced in the papers presentation. To begin with; the definition of "style" needs to be clarified for understanding by readers. Furthermore; the paper would benefit from a restructuring exercise. In the "Results" section where it would help to separate results from new experiments for easier comprehension, by readers. The current layout makes it challenging to differentiate which data pertains to each experiment and what information is being discussed within the texts. 
There are a few aspects that need more explanation.
Additional details about the data utilized are required to back up the assertion that the writing assignment enforces styles on writers (lines 729–732). It is crucial to specify the quantity of stories used and authors involved well as the distribution of stories per author in order to provide sufficient support for this argument. The evaluation of coherence, after the fact only focuses on sets of stories authored by the individual; one story is deemed "coherent " while the other is labeled as "neutral."We need to confirm this selection process to support the argument for "Experiment 1 ". It may not apply to "Experiment 2." In the case of comparing "original vs right/wrong " different authors are involved. 
The paper doesn't explain statements well enough –, like why they chose the "five frequent" parts of speech and words is unclear; are these really the most common ones used? The tables are confusing with two bars shown in the legend for each category. Also not clear is why they decided to focus on character 4 grams; was this decision based on the development set? If these characteristics weren't the common ones but were selected from commonly used parts of speech and words list. It's crucial to provide a rationale, for choosing them concerning "style." It's important to clarify how these characteristics represent "style."
The link between the "Design of NLP tasks' section and the remainder of the paper is not well defined—it seems unclear how they relate to each other; this lack of clarity might be due, to mentions of "training'' and "test'' sets in this specific context. 
The distinction between the model and prior research is unclear here as there appears to be a discrepancy, between the idea that a genuine comprehension of text is needed to tackle the problem (lines 217–219) and the method put forth. 
The use of "and "incorrect" conclusions as discussed by Mostafazadeh et al. may cause confusion due to its vague interpretation regarding coherence or ethical righteousness within a narrative context involving human Turkers in the study’s tasks on the Story cloze task (lines 159–177). Explicit details, about the prompts offered to participants would help alleviate this ambiguity. 
More queries and remarks to consider are; 
Table 1 doesn't make it clear how the "original" story differs from the incoherent ones.It's important to provide details about how Turkers were instructed to create endings and what criteria were used to assess coherence or incoherence.It would be helpful to explain the differences, in judgements and whether a single Turker assessed both "and "incorrect" endings – a key aspect that influences relative judgment. 
The intent, behind "We randomly select 5 collections" is not clear. 
The statement that "Almost all sentences' should be clarified with numbers. 
Table 5 should include the weights of the features, for clarity. 
The statement "in contrast, to completing an assignment " may be misleading because Turkers are not actually concluding a task.
The claim that every set of endings must be authored by the person holds true for "correct"/ "incorrect' pairs but does not apply to "original" "new' pairs as described. 
Line 694 seems unclear when mentioning " text spans"; it would be helpful to specify the particular text being referred to in this context. 
The information mentioned should include the source of the publication. 