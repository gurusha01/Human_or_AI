This research introduces a method for labeling sequences called named entity recognition that makes use of dilated convolutions in a unique way. By incorporating ideas like shared dilated convolution blocks and predicting tags at every convolution level could make a significant impact, in the field. The authors carried out experiments to show how effective their approach is. The writing is very easy to understand. The experimental plan is well thought out. 
Pros;   
The research paper extensively compares the suggested method with structures such, as LSTM and LSTM + CRB to thoroughly assess its effectiveness. 
The innovative ideas and methods in architecture and training— the practice of sharing blocks—make a significant and meaningful addition, to the field. 
Areas, for improvement;   
One major drawback of the research is that it only focuses on identifying named entities, in English text which may be concerning considering the implications of sequence tagging implied by the title. 
Section 4 of the document could use some explanation to make it clearer for everyone by discussing how padding helps keep the output resolution consistent, throughout each block This will help improve how easy it is to understand the methodology. 
Lets delve deeper into how the model behaves and optimizes by conducting an analysis to see how the number of layers affects its performance. 
In reply, to the authors rebuttal; 
The authors response is welcomed for its perspective and consideration of feedback provided by the authors to narrow the scope, towards named entity recognition instead of broader sequence tagging; hence the rating has been adjusted upward to acknowledge this positive amendment. 