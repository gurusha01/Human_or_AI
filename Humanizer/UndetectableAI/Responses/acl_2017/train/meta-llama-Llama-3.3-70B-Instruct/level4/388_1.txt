This article introduces an ambitious project that aims to convert Universal Dependency grammar structures into semantic logical form representations automatically. A concept termed by the authors themselves. In terms. Each Universal Dependency element is linked to a specific logical form representation and a method is described to assist in this translation process using an 'inside out' approach through an intermediary stage to maintain the correct nesting of smaller structures, within larger ones. The researchers perform two assessments. One to compare the outcomes with lambda structures and another to gauge how well the derived lambda expressions address queries from two QA datasets. 
It's quite hard to summarize everything in such a space here! The authors did try to touch upon the points but there are still many details left out which could be important too. Having a version of the paper would definitely help to dive deeper into the QA results. Like pinpointing the kinds of questions that weren't handled well or answered correctly and understanding why these limitations exist. This kind of information would really help in grasping the boundaries of logical form representations. 
I'm mainly worried that the logical form representation being suggested doesn't accurately reflect a semantic representation. It essentially rephrases the input dependency structure with some improvements aimed at enhancing semantics â€“ like the use of operators and explicitly including omitted arguments while assigning appropriate types, to event related adjectives and nouns. However there are key semantic elements missing or inaccurately portrayed in this approach. Important elements, like quantification and numbers are not fully covered in the analysis. Should be addressed separately from typical words and formulas to ensure accurate handling of the data. 
Critiquing the paper for what it lacks may seem simple nevertheless it's unrealistic to demand a thorough analysis in every aspect. Nonetheless errors that stand out must not go unnoticed. The way event relationships are paired with roles is especially concerning as it overlooks the differences in semantic roles between sentences like "He broke the window.". The window broke." This matter demands attention and shouldn't be brushed aside as a task, for later semantic processing. This paper could have been enhanced by recognizing this constraint and outlining a strategy, for endeavors that might include utilizing FrameNet and meeting semantic filler needs. 
The process of converting notes is quite straightforward. Shows enhancements compared to the previous method utilizing Stanford dependencies technology The choice of the authors to present neural research to the ACL is praiseworthy given the current prevalent interest, in neural techniques. 