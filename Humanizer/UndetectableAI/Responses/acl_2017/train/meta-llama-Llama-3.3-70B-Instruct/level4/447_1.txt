This study explores how the organization of discourse using Rhetorical Structure Theory (or RST for short) can improve text classification tasks. The researchers employ a Recurrent Neural Network (abbreviated as RNN) integrated with an attention mechanism to create a representation. Results, from experiments conducted on datasets showcase the effectiveness of this method. Here are some key aspects that need to be taken into account; 
Table 2 shows that the "UNLABELED" model performs better than the "model in four of the five datasets. A surprising result considering that adding more relation labels would typically be expected to improve performance. The authors should delve deeper into this outcome and explore whether the effectiveness of relation labeling is subpar and has a negative impact, on overall performance. 
The research paper discusses converting the RST tree into a dependency structure as a step, before processing it further could involve keeping the original tree structure intact and training a hierarchical model directly on it to possibly achieve better outcomes. 
To enhance the ability to compare with research more thoroughly researchers could explore a wider variety of frequently utilized datasets in their experiments instead of restricting comparisons to just one dataset, per study as done previously. 