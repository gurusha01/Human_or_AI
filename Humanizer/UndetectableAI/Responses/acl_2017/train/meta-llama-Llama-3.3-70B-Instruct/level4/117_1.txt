The article delves into a research area; understanding the connection between natural language and Knowledge Base (KB ) relations in the context of Question Answerin g (QA). This is especially relevant when there is information, for one of the arguments and a large number of possible target relations need to be considered. 
The suggested approach includes merging two representations of the input text. One, at the word level that involves breaking down both the target relation names and input text into segments and another where relations are viewed as a single unit without segmenting either relation names or input text. 
This work seems to make an impact, on question answering by its ability to rearrange entities after the Entity Linking process. 
The findings show an advancement, beyond the existing best practices. 
However one drawback of this method is that it has only been tested on a set of data. 
When organizing the content effectively in your work piece consider merging section 3s content with the related work section to make room for a structured division, in the new section 3 and its subsequent subdivisions. 