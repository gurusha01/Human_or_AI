This entry highlights a number of strengths by offering thorough instructions paired with clear visuals to improve clarity and comprehension. 
Nevertheless the crowdsourcing annotation method that is used shows a flaw when it comes to its dependability, on document independent data.  
The work makes a contribution by creating a new standard dataset for Multi document Summarization based on concept maps featuring clear and well presented content structure.The additional resources included are also considered adequate sparking two inquiries, from this study; 
Is it really essential to separate the extraction of concept maps, as a task? Many summarization systems create knowledge graphs to produce summaries; however the clarity and uniqueness of concept maps improve as nodes increase potentially enhancing the readability and desirability of summaries. 
How can we figure out how important a concept is without looking at documents? When summarizing content to capture the ideas present in documents without bias or preference for any particular concept varies depending on the document being reviewed. Like in the case of coal mining accidents where the significance of specific incidents, versus accident causes could change based on the documents primary focus. It becomes complex to determine their importance without considering the context provided by individual documents. 
The authors should be commended for their work, in creating this dataset; however it seems to resemble a knowledge graph based on sense rather than a summary, which may pose challenges when applying it. 