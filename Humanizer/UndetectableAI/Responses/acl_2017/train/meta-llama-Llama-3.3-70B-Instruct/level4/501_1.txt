The research paper introduces a challenge; choosing the best written description for a scene or image from several similar choices while also including suggested basic models for comparison and evaluation metrics alongside ratings, from human evaluators. 
Strengths; 
The paper is structured in an organized manner that is easy to grasp and comprehend.The evidence provided strongly supports the contributions made in the paper making it highly accessible and readable.The underlying drive for the paper is clearly defined as well;the suggested approach, for choosing the suitable caption from a set of deceptive options has the potential to enhance other models related to image captioning and image comprehension by acting as a post generation re ranking technique. 
Shortcomings; 
The proposed algorithms ability to create decoys is being called into question in terms of its effectiveness and the validity of the research paper it belongs to is being doubted as a result of this discrepancy. The algorithm picks out decoys that share representations and surface forms but may not necessarily relate to the same image. However a significant issue arises; just because something doesn't match image A doesn't automatically make it an incorrect description for image A particularly when there are similarities, in representation and surface form. This problem raises uncertainties regarding the accuracy of the ground truth labels provided. According to Figure 1s illustration the created distractions are. Significantly different to be labeled as satisfactory distractions or they serve as reasonable alternatives, for the intended target thus reducing the algorithms efficiency. 
Henceforth I worry that the data produced by this algorithm might not sufficiently prepare a model to surpass keyword identification as asserted in the documents findings. Many false leads can be sieved out through discrepancies in keywords;. When unable to be distinguished by keyword comparison alone these false leads appear as alluring correct choices. Moreover the revelation that humans managed an 82..88 percent accuracy rate on a subset test raises doubts, about the complexity of the examples or the caliber of the misleading options. 
Lets chat about topics.
Overall this paper is well crafted with a rationale and significant experimental work.However I have reservations regarding the data generation process. Dataset alignment, with the papers main goals.This discrepancy undermines the strength of the findings.If these concerns are not adequately addressed in the rebuttal I am leaning towards rejecting this paper. 