This study introduces a method for creating user friendly interfaces for databases that can adapt and enhance themselves with minimal human input over time.The researchers suggest using a sequence to sequence model that connects user statements directly to SQL queries without the need for intermediate interpretation layers.This model is put into action online to gather input, from users and utilize it to enhance the models functionality. 
The primary achievements of this study are; 
The authors show how a neural sequence to sequence model can create SQL queries from language without the need, for manual feature design or intermediate meaning representations. 
The authors suggest a method of learning based on feedback that involves incorporating user feedback to determine which statements should be annotated by crowd workers in order to lessen the effort needed for model training. 
The authors introduce two methods for data augmentation. Using schema templates and paraphrasing. To enhance the models effectiveness and lessen the requirement, for labeled data. 
The paper excels, in the following areas; 
A new method is suggested by the authors for constructing Natural Language Interface Database systems merging sequence to sequence models, with feedback driven learning and data augmentation techniques. 
The authors show that their method is just as effective as systems, on two standard datasets. GEO880 and ATIS. 
The authors showcase how their method proves to be effective in a scenario by developing a semantic parser for an academic field, from the ground up. 
The shortcomings of this paper include; 
The authors only tested their method on a couple of datasets and a small online studyâ€”a limited scope that might not capture all potential scenarios. 
The authors depend on crowd workers to label utterances; however this could lead to inaccuracies and inconsistencies, in the annotation process. 
The authors have not thoroughly analyzed the mistakes made by their model. Identified the types of statements that pose the greatest parsing challenges. 
Questions, for the writers; 
How do the writers intend to tackle the challenge of dealing with noise and fluctuations in the process of annotating, by crowd workers? 
Could the writers elaborate further about the kinds of statements that're particularly difficult to understand and their strategies for enhancing the models accuracy, with these statements? 
How do the writers intend to expand their method to accommodate query languages, like SPARQL or ElasticSearch? 