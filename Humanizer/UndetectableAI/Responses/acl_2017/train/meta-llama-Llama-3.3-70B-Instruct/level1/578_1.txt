This study suggests an encoder decoder parser, for analyzing Minimal Recursion Semantics ( MRS ) and Abstract Meaning Representation ( AMRs ). The key points of this research are; 
A new parser design focused on creating reliable semantic graphs has been suggested in the paper utilizing stack based embedding characteristics to predict graphs, alongside unlexicalized predicates and their token alignments simultaneously. 
The authors use their model in parsing Abstract Meaning Representation (AMRs) incorporating structure such, as alignments and differentiating between non llexical concepts. A feature found explicitly in Minimal Recursion Semantics (MRS) but not in AMRs. 
The authors have successfully attained top notch outcomes in MRS and AMRA parsing evaluations showcasing enhancements, over current neural baseline models and achieving results that rival those of cutting edge models leveraging external resources extensively. 
The positive aspects of this document are; 
The new design of the parser is unique and efficient as it enables the analysis of semantic graphs. 
The researchers have made advancements compared to current neural baseline models and have shared results that are on par, with the best performing models available currently. 
The authors efficiently put their model into practice by utilizing GPU batch processing which makes it much faster than other parsers currently available. 
The researchers suggest a technique, for forecasting lemma forms to address data scarcity issues and enhance the parsers effectiveness. 
The paper has some drawbacks such, as; 
The authors have not extensively compared their work, on MRS and AM R parsing with existing studies which makes it challenging to assess the importance of their contributions. 
The authors did not thoroughly examine the types of errors produced by their parser to pinpoint areas, for enhancement better. 
The authors rely on existing embeddings that may not be the best fit, for MRS and AMAR parsing tasks. 
The authors did not test their parser on data, from domains to check how well it works in various situations and settings. 
Authors are often asked questions; 
How do the writers intend to tackle the challenge of dealing with data in MRS and AMF parsing and what techniques do they suggest to enhance the parsers effectiveness, on unfamiliar data sets? 
Could the writers offer a thorough examination of the mistakes made by their parsing tool and outline their strategies, for resolving these issues in upcoming research endeavors? 
How do the writers intend to expand their parser to manage semantic graphs that include multiple scopes or quantification? 
Can the writers give us details, on the computing resources needed for training and operating their parser software and discuss their strategies for enhancing the efficiency and scalability of their parser program in the future? 