This research paper presents a multi modal challenge known as Dual Machine Comprehension (DMC). In this task a computer system is tasked with selecting the appropriate textual description of a scene from various choices. The goal of this task is to assess how well the system aligns linguistic semantic interpretations. The authors introduce an scalable algorithm for producing distractors, from image captions created by humans and they develop a comprehensive machine comprehension dataset called MCIC using COCO images and captions. 
The key achievements of this study are; 
The beginning of the DMC task introduces an demanding standard, for assessing machine comprehension abilities. 
The creation of a method for producing imitation samples that can be utilized to generate data sets, for the DMC assignment. 
The MCIC dataset has been. Is now accessible to the public, for use. 
The positive aspects of this paper include; 
A novel and engaging project suggestion that could push forward the development of multi modal machine understanding. 
Creating a crafted algorithm to generate decoys is essential for producing datasets, for the DMC task efficiently. 
The development of a dataset called MCIC to assess how well machine comprehension models perform. 
The practical findings showcase how well the suggested assignment and dataset assess machine comprehension models performance. 
The examination of the findings sheds light on how the DMC task interacts with vision and language tasks, like generating image captions. 
The paper has its flaws, including; 
The difficulty of the task at hand could present a challenge, in creating models that excel in its execution. 
The evaluation of the proposed task is limited as it only focuses on one dataset. MCIC. 
The absence of comparing it to similar tasks like visual question answering could offer more valuable insights, into how well the proposed task works. 
The analysis of the results is limited. May not offer a comprehensive view of the strengths and weaknesses of the task and dataset, under consideration. 
There could be a bias, in the dataset that might impact the effectiveness of models trained using that dataset. 
Authors are often asked questions.
How do the writers intend to tackle the intricacy of the task at hand. What approaches can be employed to create models that excel in executing the task effectively? 
Could the writers offer information regarding how they assessed the proposed task in terms of the criteria utilized and the outcomes achieved? 
How does the suggested assignment connect, with tasks that involve combining vision and language like answering visual questions and what can be learned from comparing these two tasks? 
Could the writers delve deeper into the findings by discussing both the advantages and limitations of the suggested assignment and dataset? 
How can we tackle any biases, in the dataset and ensure that it accurately reflects the real world? 