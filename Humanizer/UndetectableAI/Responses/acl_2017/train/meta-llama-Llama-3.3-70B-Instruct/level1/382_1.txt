This article introduces an approach, for developing linguistically complex Natural Language Generation datasets from pre existing Knowledge Bases with some manual assistance. 
A method for developing data to text collections is presented by the authors in their paper on an approach for forming training resources, for natural language generation from current Knowledge Bases that can be applied to instruct KB verbalisers. 
A method involving the collaboration of individuals to link information with written content is utilized by the writers in connecting data units with texts created by humans to establish a correlation, between the text and the data itself. 
The authors in the study contrast their dataset (DBPNLG​ ) with an established dataset ( RNNLG​ ) demonstrating that DBPNLG contains a range of attributes and input patterns along, with different input shapes. 
The paper has strong points, including; 
A fresh approach is being introduced by the framework which greatly enhances the field of Natural Language Generation (NL) by offering a method to generate complex datasets from already existing knowledge bases. 
The DBPNLG dataset indicates variety in attributes and input structures compared to the previous version. Creating a more complex and engaging dataset, for natural language generation tasks. 
When comparing to established standards the evaluation of the suggested framework, against RNNLG gives an overview showcasing both its advantages and limitations. 
Experiments conducted using sequence to sequence models reveal the difficulties in creating intricate texts from extensive data underscoring the necessity for further advancements, in models. 
The papers shortcomings include; 
The DBPNLG datasets smaller size compared to the RNNLG dataset could restrict its effectiveness, in training and testing NLQ models. 
The DBPNLG dataset presents a level of complexity and diversity compared to the RNNLG dataset which could pose additional challenges, in handling it. 
We have seen from the tests with sequence to sequence models that there is a requirement, for sophisticated models to produce linguistically intricate texts from diverse data sources. 
Questions, for writers; 
How do you intend to expand the DBPNLG dataset to enhance its size and scope further? 
Could you share information, about how the crowdsourcing was carried out and the methods used to maintain the quality of the gathered texts? 
How do you reckon the suggested framework could be utilized to generate datasets, for natural language generation tasks like crafting dialogues or summarizing texts? 