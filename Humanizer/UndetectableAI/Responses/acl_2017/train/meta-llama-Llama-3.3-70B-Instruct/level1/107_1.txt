This document discusses two methods for conducting cross language named entity recognition (NER) utilizing supervision without requiring any human labeling, in the target language area. 
The authors have created a method for picking high quality NER data using an approach, in noisy comparable corpora called the Annotation Projection Approach.The system enhances the accuracy of the target language NER system in cases where alignment accuracy is low and the projected data are of poor quality. 
The authors suggest a method for transferring NER models directly through a representation projection technique that maps word representations (word embeddings) from a target language to a source language, in vector space.This method allows for the application of a NER system trained in the source language to the target language without requiring re training. 
The authors have come up with two decoding strategies that cleverly blend the results of both projection based methods to enhance accuracy compared to each system working independently. 
The paper excels, in the following aspects; 
The authors showcase how utilizing supervision can be impactful, in cross language named entity recognition (NER) a tough task given the scarcity of annotated data in the desired language. 
The new methods show precision compared to the latest cross language NER techniques, particularly, on the CoNNL test dataset. 
Flexibility is key here. Using the representation projection method makes it simple to include languages without needing individual embeddings, for every language pair. 
The papers drawbacks include; 
The authors only test their methods on a selection of languages (Japanese, Korean, German, Portuguese, Spanish and Dutch) and datasets (, in house and CoNNL). 
Depending on the precision of alignment is crucial for the annotation projection method to work effectively since there might be instances where the alignment, between the translated languages is not always precise or readily accessible. 
The inclusion of decoding methods might introduce intricacy to the entire system that could affect its scalability and efficiency. 
Asking authors some questions; 
How do the writers intend to expand their methods to languages, with resources and little to no parallel information available? 
Could the writers offer details about how well the heuristic data selection method and the representation projection technique work, across various language combinations and datasets? 
How do the authors intend to tackle the challenges related to scalability and efficiency in the decoding schemes they are working on? 