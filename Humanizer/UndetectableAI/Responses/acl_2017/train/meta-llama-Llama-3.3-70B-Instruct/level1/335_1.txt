This study introduces a method for answering reading comprehension questions by using gated self matching networks that have shown impressive performance, in the SQuAD dataset rankings. 
The authors suggest a modified version of networks with gated attention to assess the significance of passage sections in relation to the question, at hand. 
The authors have presented a self matching attention mechanism aimed at enhancing how the passage is represented by comparing it to itself and capturing information from the passage effectively. 
The new model performs well on the SQuAD dataset compared with other competitive systems available, in the market. 
The paper has strong points; 
The authors illustrate how attention mechanisms are efficient in enhancing reading comprehension by highlighting the significance of parts of a passage, to answering questions. 
An inventive self matching attention mechanism has been introduced, enabling the model to enhance the passage representation and gather evidence from the entire passage effectively. 
The paper showcases real world outcomes by achieving top notch performance on the SQuAD dataset and surpassing various rival systems. 
The paper has shortcomings; 
The complexity of this model is quite high as it includes components and mechanisms that might pose challenges in terms of interpretation and analysis. 
The authors show that the self matching attention mechanism works well but offer explanation on how it operates and why it is successful. 
The authors missed out on comparing their self matching attention mechanism to attention mechanisms which could have given a better insight into its effectiveness. 
Here are some queries, for the writers; 
Could you give me insights, into how the self matching attention mechanism works and show some visual aids to demonstrate the attention weights and how it enhances the passages representation? 
How does the gated attention based recurrent network stack up against attention methods, like hierarchical attention or multi perspective attention? 
Could you share information about how the training is done. Such, as the specific hyperparameter configurations and the optimization method being utilized? 