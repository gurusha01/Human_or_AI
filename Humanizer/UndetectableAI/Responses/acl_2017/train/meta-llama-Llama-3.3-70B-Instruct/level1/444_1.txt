Overview of the Document 
This study suggests a thorough assessment approach, for the job of rap songs. Creating text that mimics the style of a specific artist while offering original content. The researchers introduce an assessment method to gauge fluency and coherence in writing style and an automated evaluation method to measure uniqueness and stylistic resemblance. They compile a collection of lyrics from 13 rap artists which are marked for style compatibility and examine how well an LSTM based ghostwriter model performs using their evaluation criteria. 
Key Contributions
The authors suggest a thorough assessment approach that considers elements of ghostwriting such, as fluency, coherence, style consistency originality and stylistic resemblance. 
The researchers create an assessment method that examines fluency, consistency, in writing style and coherence to offer a detailed analysis of the produced lines. 
The researchers suggest a method, for automated assessment that considers originality and stylistic resemblance to facilitate the examination of the produced poetry. 
Advantages
Proposed evaluation approach offers an analysis of the ghostwriting task by encompassing various aspects of the created verses. 
The manual assessment approach offers an examination of the created verses that is crucial, for assessing the quality of the produced text. 
Automated assessment approach; The automated evaluation method allows for an analysis of the produced poetry on a large scale and is crucial, for assessing the effectiveness of the ghostwriter model. 

Insights on where thingsre headed next emerge, from the evaluation trials and shed light on what lies ahead for generative models including the importance of incorporating fresh vocabulary and drawing inspiration from the lyrics of other artists. 
Areas, for improvement
The evaluation method mentioned focuses on ghostwriting rap lyrics and its uncertain if it can be used for other language generation tasks as well. 
The assessment process can be subjective when done manually as it depends on annotators input which may lead to variations, in the evaluation outcomes. 
The computational complexity of the automated assessment method could pose a challenge due to high computational costs that might restrict its usefulness, with extensive sets of data. 
The authors have only assessed the effectiveness of an LSTM based ghostwriter model without comparing its performance to models using the evaluation method suggested. 
Queries, for Writers
How might the suggested assessment approach be utilized in language creation endeavors like crafting poetry or generating dialogues? 
How can we reduce the nature of manual evaluation methods and what are the consequences of utilizing various annotation systems? 
What kind of resources does the automated assessment method need and how can it be fine tuned for analyzing extensive datasets efficiently? 
How well does the ghostwriter model based on LSTM perform in comparison to models, like recurrent neural networks or transformers? 