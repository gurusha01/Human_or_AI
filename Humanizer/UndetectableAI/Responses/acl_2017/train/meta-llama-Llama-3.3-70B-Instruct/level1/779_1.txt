This study introduces a method, for zero resource neural machine translation (MT) utilizing a mentor pupil model to enhance the process.The key advancements of this research include; 
The authors suggest a model where a pre trained pivot to target model (teacher) leads the learning process of a source, to target model (student) even when parallel corporaData is not available. 
The authors present two methods for instructing the student model in their study. Sentence level teaching reduces the differences between the teacher and student models at the sentence level; while word level teaching focuses on minimizing differences, at the word level. 
The authors test their method on the Europarl and WMT datasets. Show notable enhancements compared to advanced pivot based and multilingual techniques, in translation accuracy and decoding speed. 
The paper excels, in the following areas; 
A new method has been introduced. The teacher student framework for zero resource NMT.. Its effectiveness has been shown in experiments, by the authors. 
Enhanced translation accuracy is demonstrated by the writers in their methods ability to notably enhance translation quality compared to leading methodsâ€”especially in situations, with limited resources. 
The method proposed by the authors enables a representation of the desired NMT model, without the necessity to split training or decoding into separate phases; this enhances decoding efficiency. 
The paper has some shortcomings ; 
The writers believe that similar sentences, in languages might have similar chances of producing a sentence in a third language; however they haven't thoroughly confirmed this belief. 
The authors assessment is restricted to two datasets (Europarl and WMT) focusing on Spanish French and German French language pairs, which might not fully capture all aspects of zero resource NMT situations. 
The authors in this study discuss how their method stacks up against pivot based and multilingual methods but do not provide comparisons, with zero resource NMT approaches that leverage multimodal data. 
Questions, for the writers; 
How do the writers intend to confirm the hypothesis that parallel sentences in languages are likely to produce a sentence in a third language, with similar probabilities? 
Could the authors share evaluation findings on different datasets and language combinations to showcase the versatility of their method? 
How does the method used by the authors differ from zero resource NMT techniques that incorporate multimodal data? 