This article introduces a neural network model that utilizes cross attention for answering questions based oÂ­n knowledge bases. The key accomplishments of this study include;  
A cross focus mechanism that adapts the representation of queries based on aspects of answers is shown to be more expressive and adaptable compared to earlier approaches. 
Incorporating worldwide knowledge base data during training can address the out of vocabulary (OOOV ) issue. Enhance the models overall performance. 
The results from experiments conducted on the WebQuestions dataset illustrate that the suggested method is highly effective and outperforms end to end approaches, in terms of performance. 
The positive aspects of this article are; 
The new cross focus method is an advancement compared to earlier approaches as it enables better and adaptable question representation. 
Utilizing worldwide knowledge base data is a strategy that tackles the out of vocabulary issue and boosts the models effectiveness. 
The results of the experiments are. Clearly presented to show how well the suggested method works. 
The shortcomings of this document are; 
The effectiveness of the model could be influenced by the quality of the training data; the authors might have considered investigating training methods. 
The authors might have delved deeper into analyzing the attention weights. How they influence the models effectiveness. 
Improving the models capacity to tackle inquiries and identify inaccuracies could enhance its performance since these issues frequently arise in knowledge base question answering tasks. 
Asking authors questions; 
What are the authors strategies for dealing with inquiries and inaccuracies, in labels in their upcoming research endeavors? 
Could the authors offer a thorough examination of how the attention weights influence the performance of the model? 
How do the writers intend to expand their suggested method to knowledge base question answering datasets and tasks? 