
Advantages; 
The article presents a concise. Effectively explained reason, for its content.   
ii; It offers, in depth comparisons involving models and languages to demonstrate a wide range of perspectives and diversity. 
Areas, for improvement;   
The findings are impacted by the choice of languages.   
The experiments do not completely support the arguments presented in the paper. 
Lets talk about some topics.   
This study explores a question in word representation. What are the best components of a word to capture its morphological traits and how should these components be combined effectively? The researchers conducted experiments using subunits (characters or character trigrams and morphemes) along with different methods of composition (such, as LSTM and CNN models or simple addition) in the context of a language modeling experiment. The research covers a range of ten languages selected to showcase a variety of language structures since the impact of word representations and composition techniques can differ depending on the language used. After examining the results from the experiments conducted in the study concludes that character level representations tend to be more efficient however when compared to models that integrate explicit morphological understanding they still fall short of being optimal. Furthermore the authors observed that character trigrams consistently demonstrate good perplexity performance, across the majority of languages tested. 
Nevertheless the article fails to address a number of lingering questions;   
Firstly there might be a bias in how the experimental languages were chosen by the authors. They picked ten languages from four groups with a maximum of three languages per group. But here's the thing to think about; How can we be sure that these languages truly represent their categories? Do all languages in the typological group show similar patterns in how they form words and sentences? The findings in the paper suggest otherwise especially since two agglutinative languages, from the group had different results. Thereforeâ€‹ it may be wiser to concentrate on the languages examined in this research rather than drawing sweeping conclusions, about all languages.   
Further detailing is needed to address the misalignment between the assertions presented in the paper and the extent of its experiments regarding whether language modeling's indeed the best method to confirm these claims made in this research study or if these findings might not carry over to different tasks, in other contexts.   
Why was Arabic specifically selected as the language for this experiment in Section 5 point 1 when there are languages like Japanese and Turkish, with automated morphological analyzers that could have been considered for a more thorough assessment?   
The paper focuses on character trigrams when discussing different ngram representations for a reason. What makes character trigrams stand out compared to character bigrams or character fourgrams consistently remains a question worth exploring further in this context of language modeling based on ngrams considering factors like corpus size and other contextual aspects which play a significant role, in the models performance. 
I found a small errors, in the text.  
The introduction lacks a citation (line 88, on Page 1).  
"The term 'root and patter' needs to be fixed to 'root and pattern' (line 524, on Page 6)."