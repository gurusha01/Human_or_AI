Pros; 
This study represents an advancement in the development of more complex datasets for teaching sentence planners in converting data to text in natural language generation (NL). This research direction is crucial and relevant, at this time. 
Areas, for improvement; 
The extent of improvement in the work presented in this paper compared to Perez Beltrachini et al.s (2016) method for content selection remains uncertain as the authors do not directly contrast their approach, with the work mentioned above. The main novelty of this paper appears to be focused on analysis; however it is noted that this analysis lacks substantial depth. 
The authors compare the performance of an NNLGBaseline in this dataset with that in the Wen et al.(2016)data set.However the BLEUscores cited in Wen et al.'spaper are notably higher.This brings up questions, about the suitability of the NNLGBaseline used here for making comparisons. 
Lets talk about a things; 
The authors should explain clearly why this research represents a significant improvement compared to Perez Beltrachini et al.s earlier work and why the NNLG baseline outcomes deserve attention as credible results. In contrast, to LREC ACL seldom features session papers on corpus development methods unless they present innovative system outcomes using the corpus. 
The paper would have an impact if it discussed the sentence structures in both datasets to support the claim that the new dataset is more intricate, in nature. Moreover the explanation of how the variety of path shapes was calculated should be elaborated on. Connected to specific sentence structures. 
The authors should also recognize the limitation that their approach does not encompass complex discourse connections like Contrast and Consequence that play a key role, in natural language generation (NLG). In this aspect of the research discussion presented by Walker et al.(JAIR 2007) and Isard (LREC 2016) it would be beneficial to explore how their corpora relate to the method being proposed. 
Sources; 
The study conducted by Marilyn Walker and her colleagues in 2007 focused on adapting sentence planning for dialogue, in contexts and domains as published in the Journal of Artificial Intelligence Research (JAIR) volume 30 from pages 413 to 456. 
Amy Isard presented a paper titled "The Methodius Corpus of Rhetorical Discourse Structures and Generated Text" at the Tenth Conference, on Language Resources and Evaluation (known as LREC 2016) in Portorož Slovenia in May 2016. 
I am unable to provide a response, without the text to paraphrase. Kindly provide me with the text that needs to be rewritten.
Additional Information After Authors Feedback; 
Thank you for the helpful response you provided me with Earlier on After considering your explanations This led me to adjust my overall evaluation and rating of the situation as a whole When it comes to comparing it to Perez Beltrachinis work Compared to what was presented by Perez Beltrachini and others While this distinction may matter more to the committee members rather than the final audience It is still not very clear why this improvement over their research was not clearly stated It was not explicitly mentioned why there was a leap from their findings Although Perez Beltrachinis study mainly focuses on content selection only Which is a crucial factor, in differentiating this dataset from Wen et al.s research. The process of developing the data to text dataset appears to include crowd sourcing tasks that may need highlighting if they are unique or crucial in some way.. It is worth noting the rejection of 8. 7 % Of texts sourced from the crowd during verification and could be beneficial to showcase samples of these rejected texts and analyze whether this suggests quality outputs, than Wen et al.' s dataset. Gathering these user contributed texts allows for comparisons with the corpus by Wen et al, on both the data and textual fronts—an aspect acknowledged by the reviewer regarding the papers significance. 
In terms of the NNLG baseline issue mentioned here concerns arise that the difference in performance between the two datasets could potentially diminish if Wen et al.s effective method were employed instead However it is important to acknowledge that this assumption of relative difference even, with advanced techniques should be clearly articulated perhaps through a footnote Nevertheless despite this drawback the comparison still holds significance as a crucial aspect of assessing the datasets overall
When deciding whether to approve a research paper solely focused on creating a dataset without actual system results it is essential to evaluate the uniqueness and impact of the dataset itself. In this instance this reviewer recognizes the value of the dataset in comparison, to others available even if the main progress originates from content selection efforts. 
The reviewer concurs with Reviewer 1 regarding the need for the accepted final version of the paper to expound on the significance of domain specificity and provide a definition of "wide coverage."