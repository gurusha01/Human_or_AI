  
The article introduces an intuitive expansion to the latest developments in interactive topic modeling by allowing human annotators to offer various "anchor words”, for topics generated by machines. It is well organized. The inclusion of both simulated experiments and user surveys adds strength to its credibility and impact as a submission. 
Areas that need improvement;   
The papers focus is limited when comparing interactive topic modeling approaches mentioned in it to methods available in the field of study. The authors argue this choice by discussing alternative approaches and pointing out their limitations in terms of speed or compatibility, with the proposed "anchoring" interface. Including some real world data to back up these assertions would enhance the papers argument.   
Furthermore​ the studies were confined to one set of information (20 Newsgroups) a topic that has been thoroughly researched previously​. If results, from sets of information were incorporated​ it would have improved the extent to which the discoveries could be applied broadly​.
Lets talk about topics.  
This paper is well written. Adds a valuable yet subtle and practical touch to the realm of interactive topic modeling research field. The writers have carefully examined versions of their method, in simulated tests and carried out thorough numerical assessments of both simulated scenarios and surveys involving users using various metrics to evaluate various facets of topic excellence. 