Here are some advantages;   
This study introduces a method to improve the accuracy of resolving zero pronouns in sentences without explicit references to their antecedents. The key contributions of this study include the following; 1. It presents an approach to automatically create a substantial training set for zero pronoun resolution. 2. It utilizes a two step learning process to transfer knowledge from a dataset to data specific, to a particular domain. 3. It identifies words by assigning them distinct labels. Overall the study is well crafted with planned experiments. 
"Areas, for improvement;"  
I do have some worries, about identifying the antecedent of a zero pronoun.  
How do you determine the antecedent when a pronoun is used for the predicted word? The authors suggest aligning the main noun phrases, with the pronouns as a method but its not clear how the system deals with situations where the main word's not a pronoun.   
What occurs if the suggested term is a noun that hasn't been mentioned before in the text preceding it?   
Is it feasible to test the system in two phases despite its performance on regular datasets? The initial phase could focus on how the model reinserts the omitted zero pronoun back, into a sentence while the second phase could evaluate the systems accuracy in recognizing the antecedent.   
I'm also interested in why the authors opted for an attention based network in their work? It would be helpful for fellow researchers to have an explanation of the reasoning, behind this decision.   
Could you share a thought, about the topic? Thank you!   
In Figure 3.0. would it make sense to use "a,b c..." for the labels instead of "x,y,z..."?   
Lets talk about this in general.   
This paper is really impressive, with ideas and a strong experimental design. 