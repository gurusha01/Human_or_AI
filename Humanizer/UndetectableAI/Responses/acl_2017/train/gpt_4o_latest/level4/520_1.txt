This paper presents a technique for creating image datasets using elements and connecting them with logical structures and written descriptions, in language.  
It seems like the main goal is to create a structure that allows for the structured management of image complexity and their corresponding descriptions. 
The proposed approach has a drawback in that it can only handle a limited level of complexity compared to what is usually required for tasks such, as image caption generation and other challenges involving multiple modes of data interpretation.   
The proposed approach is straightforward compared to the varied difficulty levels seen in bAbI tasks that range from simple to reasoning scenarios across a spectrum of qualitative challenges. Of introducing qualitatively challenging reasoning tasks like those found in bAbi tasks with varying difficulties, from easy to hard the proposed method focuses solely on enhancing the complexity of image recognition tasks quantitatively (i.e. by altering the number of objects or incorporating artificial noise).  
The constraints are noticeable in the part as well. If the performance outcomes fall short of expectation the problems typically revolve around either overfitting or underfitting at a level, which could be remedied by tweaking the networks capacity or incorporating more data. Extract profound qualitative insights, from the experiments proves to be a challenging task.   
The opening states that the aim is not to reach peak performance but to assess if architectures can effectively show the intended comprehension. Yet there's a contradiction present here. The task is designed to test if architectures display "understanding " although the scores obtained are not supposed to be viewed as substantial or meaningful. 
Just some overall thoughts;   
The general strategy needs to be clarified and specified earlier in the document. It would be best to do in the introduction rather than delaying it until Section 3. 