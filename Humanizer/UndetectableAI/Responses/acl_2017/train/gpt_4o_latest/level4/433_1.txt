The research paper introduces a method based on learning to analyze and break down the unique creole language spoken in Singapore (Singlish) converting it into Universal Dependencies (UD). The authors modify a parser developed by Dozat and Manning in 2016. Improve it using neural stacking techniques inspired by Chen et al.s work in 2016 as well. Their approach involves training a parser for English and using some of its underlying structures to help build a parser for Singlish language processing efficiently. By doing this they can make the most of a dataset for English while working with a smaller set of annotated data, for Singlish analysis. Their findings show that this technique (LAS 76​.57 ) performs better than using an English parser (LAS 65​.60 ) and solely training a parser on the Singlish dataset (LAS 64​.01 ). Moreover​ they examine how their method enhances the parsing accuracy, for Singlish expressions. 
The writers also. Assess a layered POS tagging system inspired by Chen et al.s work in 2016.They touch on how the UD framework handles typical Singlish structures and offer a treebank with annotations for 1,200 sentences.Out of these 100 sentences went through annotation resulting in an inter. Annotator agreement ( IAA ) of 85.3 UAS and 75.7 LAS. 
Advantages; 
The writers obtain outcomes using a carefully crafted experimental configuration. 
They carefully study aspects and effects of various model settings in great detail. 
The article presents a Singlish treebank that has been annotated following the UD, v guidelines. 
They suggest principles, for examining typical Singlish structures in UD. 
The approach is based on language insights. Effectively utilizes the commonalities, between standard English and Singlish. 
The project focuses on overcoming obstacles, in processing languages with resources. 
The suggested approach is more, than adjusting an English parser; it provides a structure that can be used for other similar language pairs as well. 
The treebanks method of selecting sentences is well thought out. Makes sense. 
The document is nicely. Easy to understand. 
Areas of improvement; 
The annotations seem to be of quality compared to ideal standards as shown by the 75 based IAA score for the 100 doubly annotated sentences in terms of LAS accuracy level is at 75%. This raises doubts, about how dependable the LAS scores provided for the model're considered to be reliable. 
The authors provided explanation in their response that the second annotator did not follow the annotation guidelines for specific constructions when annotating the 100 sentences for calculating Inter Annotator Agreement (IAA). Once these issues were rectified and addressed accordingly the IAA reached a level of agreement. Thus. This matter no longer appears to be a worry, in my opinion. 
Lets talk about topics; 
I have some reservations, about how the quality of annotations could affect the outcomes; however I believe that the paper makes an well executed contribution that would enhance the conference proceedings. 
I have some inquiries, for the writers; 
Who marked the sentences in the study mentioned in the papers details about calculating Inter Annotator Agreement (IAA)? It states that one of the authors annotated 100 sentences, for IAA calculation without mentioning who annotated the dataset. 
Why was the initial low Inter Annotator Agreement (IAA)? What were the primary reasons, for disagreement. Were the conflicting annotations eventually resolved? 
Table A2 shows that the treebank includes an amount of discourse relations compared to dobj relations, in colloquial Singlish language usage or whether the "discourse" labels were assigned to structures that may not necessarily be classified as discourse in other UD languages. 
Table A 03 raises a question about whether the items listed're solely discourse particles use in conversation patterns and tone setting expressions—or if they may represent a mix of discourse particles and foreign terms brought into the discussion atmosphere as well. If its the case of a mixture present in the listed items being both discourse particles and imported vocabulary words used for clarity purposes—it might be advantageous to separate them into separate tables for better organization and understanding by providing glosses, for each term as well. 
Low level. Remarks; 
It could be beneficial to contrast your method with the one proposed by Martinez et al in 2017 (source; https;//arxiv.org/pdf1701..03163.pdf). You might want to include a reference, to this paper in your list of sources cited. 
"The use of 'grammar' in a traditional manner could be clarified by substituting it with 'syntactic constructions (, for example on line 90)."
The way the building is portrayed doesn't quite match up with it being placed of its usual position, in the sentence structure called "it extraposition." Even though I see the point being made in Figure 2 analysis this particular sentence may not be necessary to include. 
The Doxat and Manning (2016)s parser is not cutting edge anymore so you might want to change that to "a model " or something similar. 
Adding explanations in the form of annotations, on Figure 2 could improve how easy it is to read and comprehend the content presented. 