This document introduces a tool created to aid in grading written examinations. 
  
The research article tackles an issue, in natural language processing (also known as NLP)—identifying textual entailment—in the context of a crucial real life application, which is scoring written tests. 
Areas of improvement;   
The document doesn't offer any groundbreaking insights; it mainly focuses on using a technology to address a familiar issue.   
The suggested method doesn't operate entirely on its own since it still depends on input for the scoring procedure itself. Moreover; 1.There is a lack of both qualitative assessments, in the study to showcase the usefulness of the system. 2.For example;. It does not discuss if the system eases the scorers job or improves their efficiency when compared to scoring without any automation involved.   
The system has parts; however the paper does not explain how the effectiveness of each part influences the overall user experience.   
The paper needs some work as there are parts where the language and style could be smoother.   
The paper contains detailed examples; however these instances do not make a substantial contribution, to the conversation or the overall merit of the research.   
The paper fails to mention the baseline for predicting the common class, in the classification assessment. A crucial oversight.   
Lets talk about topics.  
I feel like the paper doesn't really spark any inspiration for me overall. Apart, from introducing this systems progress it fails to deliver a strong or captivating message. 