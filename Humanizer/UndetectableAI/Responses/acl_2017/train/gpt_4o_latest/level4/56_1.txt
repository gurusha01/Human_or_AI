Strengths;   
This paper presents an enhancement to commonly used techniques for creating text vector representations.These traditional methods like skip ngram, with sampling,GloVe and other PMII based strategies primarily use word coexistence data.However it is possible to adapt these approaches to include n ngram coexistence data well. This paper suggests a way to efficiently learn embeddings for ngrams by using ngram contexts even though it would make the algorithms more complex with the growing embedding vocabulary and context space leading to results, in similarity and analogy tasks. 
One area of improvement is weaknesses.  
The research would have been much better if it had tested these embeddings in tasks after the similarity and analogy evaluations already shown. 
Lets talk about;   
I think this is an addition to have at ACL despite the limitations mentioned above.   
After examining the authors reply I can confirm that I have gone through it thoroughly. 