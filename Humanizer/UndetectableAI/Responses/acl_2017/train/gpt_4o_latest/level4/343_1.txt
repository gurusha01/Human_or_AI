Here are some positive aspects;   
The paper is organized in an easy to understand manner.   
It offers in depth comparisons, across experimental scenarios and showcases top notch performance levels.   
Challenges;   
The experiments contrast the semi supervised technique with previous supervised methods despite having enough training data, for supervised learning.   
Lets talk about some topics.  
This research utilizes a training approach to improve the segmentation of Chinese words using transition based neural word segmentation as its foundation.The goal is to enhance the understanding of characters by incorporating external resources such, as punctuation marks and diverse training data through multi task learning.Every external resource is viewed as a classification task.Experimental findings show that this method leads to top notch results on six of the seven datasets analyzed.   
The paper is nicely written and simple to understand with the proposed approachs effectiveness confirmed through experiments; however there is a noticeable issue regarding the methods reliance on semi supervised learning and utilizing external resources for character pre training. The paper also involves training datasets, for pre training purposes only. Despite these points the experiments baselines are built upon learning methods. In terms and situations where semi supervised learning tends to surpass supervised learning is because it can make good use of a lot of extra information available to it to perform better tasks effectively and efficiently as compared to usual supervised methods alone do so. Therefore the tests should have definitely involved making comparisons, with other semi supervised strategies in order to ensure a thorough and unbiased assessment was carried out.   
Post authors reply;   
The reviewer is worried about using a gold labeled'' dataset to pre train character embeddings, in the experiments baselines utilize label information predicted automatically by their base models as mentioned by the authors for a fair comparison to be maintained under similar conditions is imperative even though the "gold'' dataset may not be used directly in training the segmentation model utilizing this dataset for character embeddings pre training introduces an unfair advantage. Therefore it seems unjust to compare them since the suggested approach gains a dataset considered as "gold."