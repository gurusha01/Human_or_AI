This study introduces a method for labeling word meanings with time related details by classifying them as events or actions taking place now or in the future and those not bound by time constraints (atemporal). The technique involves using a graph based algorithm that combines details of items like temporal clues in definitions and the connections between sets of words, in Wordnet to classify them effectively.Look at the text and understand what it means. The process also makes use of data that is not labeled to provide an explanation of Wordnet by using a set that has been previously labeled for training purposes and applying this knowledge to the unlabeled part of Wordnet. The task is broken down into two categories; atemporal classification and then further categorized into past tense or present tense for temporal examples.To assess the method internally a selection of Wordnet synsets is labeled through crowd sourcing.The systems effectiveness is compared against a leading time tagger like Stanfords SUTime and other previous studies resulting in a 11 percent increase, in accuracy. The method stands out as it outperforms systems with just 400 labeled data points and shows a remarkable 10 percent enhancement in F score across four labels during the evaluation, on the TempEvald 4 task. 
The document is nicely. Easy to understand with a solid and reasoned strategy outlined within it. Creating a tool that provides time related data at the level of word meanings is a notable addition that could improve different natural language processing activities. Nevertheless certain parts of the research methods used during experiments require explanation, for better understanding.  
In the section on evaluation it would be helpful to provide more information with a practical example to clarify the prediction target (for instance pairs of entities and their characteristics such as entity qualities, parts of speech dimensions and methods for acquiring word forms). The explanation of labels like "time of creating an event to a document " and "event in the sentence, to another event " is ambiguous and its not clear if they refer to pairs or relationships being considered. The explanation provided for the 14 relationships fails to account for why other relationships were excluded and how a "complex" mapping was identified.Deciding if the scores are macro or micro averaged is crucial.Moreover the ablation study hints at an overlap, between Lexica and Entity basedon their comparable scores.This warrants exploration. 
When using SVM in the framework for extrinsic evaluation optimization of parameters is crucially important and it should be clearly stated if the SVM, within this framework is optimized as well as how it is done It is also necessary mention a reference if the Libsvm library is being used. 
Here are some more ideas to consider; Be sure to include how many instances are there for each category in your trusted data for more detailed categories and try to estimate how many words might be ambiguous, in a temporal context. Additionally if you claim that Table 3 shows improved outcomes it's important to back that up with a statistical test and provide a measurable significance level (p value).
Some small suggestions are to make it clearer what was done in the study by Filannino and Nenadic in 2014; to provide a citation for the calibration process; and to elaborate on how this model is distinct from others. Enhancing Table 3 could involve eliminating parentheses and including "(precision recall F1)" in the caption with two scores displayed for clarity; the caption should also be more concise. Additionallyâ€‹graphical representation would be more effective for the information, in Table 4. A few typographical adjustments are recommended well as updating the citation, for TempEval 6 and reordering the scores in Table 6. 