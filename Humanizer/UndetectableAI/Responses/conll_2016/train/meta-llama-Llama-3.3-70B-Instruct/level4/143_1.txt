This document provides a look at four different approaches to obtaining multilingual word embeddings and introduces an adapted QVEC measure, for evaluating their performance efficiency.The described embedding methods include the following; 
Using the multiCluster method involves using a dictionary to group words into multilingual clusters and then creating cluster embeddings to represent the words, in each cluster effectively. 
Expanding from the study by Faruqui and Dyer (2014) this technique broadens the scope of bilingual word embeddings into the realm of languages using English embeddings as a reference point with the help of bilingual dictionaries to align monolingual embeddings, from various languages onto this reference space. 
Expanding on the approach introduced by Luong and colleagues in 2015 for word embedding through alignment with source and target contexts; the multiSkip method adapts this technique to the scenario by integrating elements from all parallel corporora available, in the overall objective function. 
Translation invariance is when the word PMImatrix is decomposed into low rank components while considering bilingual alignment frequency aspects in the process; although effective, for embeddings it may have its limitations. 
The assessment method uses Canonical Correlation Analysis (CCA) to enhance the connection between word embeddings and potentially manually created information efficiently.Results are derived for the corresponding dimensions with a score that stays unchanged with rotation and linear changes.This approach is also broadened to support evaluations, in languages. 
The paper is organized effectively and presents the research clearly; however several important issues need to be addressed; 
The uniqueness of the translation invariance embedding method needs to be explained in connection with Gardner et al.s research findings, for better comprehension.If its value lies in expanding to embeddings a succinct outline of its innovative nature would be helpful. 
The application of sense annotations in various languages presents a difficulty because of the limited overlap in characteristics it may have across languages other than English mentioned in footnote 9; it would be beneficial for the authors to further explain their plans, for tackling this matter. 
Further exploration is needed to understand how the coverage affects the scores shown in table 2. For example the noticeable difference in coverage for dependency parsing, between multi cluster and multiCCA despite having scores prompts further inquiry.
The findings presented in table 3 show some inconsistency as multilingual embedding methods do not consistently perform based on internal measures of success. It is worth noting the performance of the invariance method, in achieving the main objective of producing embeddings that excel in word translation metrics. Furthermore it is surprising how the multi cluster approach achieved success in measures despite ignoring inter cluster semantic information.
Additional questions that the writers might want to consider are; 
When word embeddings are kept fixed in the dependency parsing task than being adjusted for better performance loss could be experienced. On the side. Using these embeddings as substitutes for embeddings, in the LSTM stack parser can lead to significant gains.
Is table 3 an average of all the 17 embeddings mentioned in section 5 part one? 
What benefits does using the multi Skip method provide compared to learning bilingual embeddings and then using multi Correspondence Canonical Analysis (CCA)?
Were multilingual dictionaries considered as an alternative, to extracting data from parallel corporas or using Google Translate in light of their potential limitations? 