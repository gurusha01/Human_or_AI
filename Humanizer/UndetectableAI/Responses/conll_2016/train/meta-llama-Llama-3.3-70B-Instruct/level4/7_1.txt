Some aspects of the suggested approach really catch my attention. The much quicker training pace in contrast to neural networks and its knack, for maintaining specific distribution characteristics during dimensionality reduction. 
I still have doubts, about how significant it is for vectors to be able to be transformed using PPMIs because the explanation given doesn't completely persuade me. 
One significant issue is the absence of a comparison, with previous research findings; this omission is quite crucial. 
I included comments, in my feedback.
The description of Kendalls tau presented in page 3 seems unusual and does not match the formula accurately; its background and foundation are ambiguous. 
It's strange that they didn't use the Spearman correlation on page 3 since its a metric, in semantic tasks and the authors used it for evaluation. 
The selection of datasets for assessment differs from the sets typically utilized in the NLP field to evaluate semantic similarity levels Even though examining different datasets is praiseworthy. incorporating outcomes, from the conventional datasets would prove advantageous. 
Figure 1 appears incomplete since two lines are visible, without any sign of the third line. 
The lack of a reference, to previous research is significant as it is only briefly mentioned. 
Also worth noting are mistakes, like the typo "large extend," which should be corrected to "large extent."