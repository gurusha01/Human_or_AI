This study delves into how word embeddings and part of speech (PoP boundaries interact by using the British National Corpus to develop classifiers that predict PoP tags from word embeddings. The key findings of this research are; 
The authors illustrate how word embeddings hold details about parts of speech by revealing that distributional vectors can accurately forecast PoP tags; this suggests that word embeddings encompass valuable insights, into parts of speech categories. 
The authors identify word groups that show patterns distinct from other words in the same part of speech by uncover these "outliers," which demonstrate behaviors akin to a different part of speech It exposes underlying irregularities, in the process of annotation or guidelines. 
The researchers demonstrate that the details regarding part of speech are spread across vector elements rather than being concentrated in just a couple of distinct characteristics within the word embeddings. 
The advantages of this document are; 
The authors have employed an experimental setup by utilizing a vast and extensively researched dataset while incorporating various evaluation measures to showcase the efficacy of their method. 
The authors offer an examination of the "outliers" and mistakes found in the classification outcomes that highlight the intricacies of part of speech boundaries and the constraints of existing annotation systems. 
The writers propose that their method could be utilized to enhance the accuracy of part of speech taggers in languages with resources and to identify mistakes in annotations, within datasets. 
The paper has its shortcomings ; 
The authors research is restricted in its application since they only conducted experiments, in English; it remains uncertain whether their conclusions can be applied to languages as well. 
The authors rely heavily on hyperparameters when training the distributional model but its not clear how much their findings are influenced by these choices. 
The authors have not compared their method with the Po'S taggers available, on the market which makes assessing the efficiency of their approach challenging. 
Queries, for writers; 
How do the writers intend to expand their method to languages and what difficulties do they foresee in the process? 
Could the writers offer information, about the particular hyperparameters utilized in training the distributional model and how they were selected? 
How do the writers intend to tackle the problem of errors in annotations, in data sets and what methods do they suggest to enhance the precision of Part of Speech tagging? 