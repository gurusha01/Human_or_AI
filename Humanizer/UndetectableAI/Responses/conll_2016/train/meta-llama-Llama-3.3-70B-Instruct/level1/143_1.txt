This paper presents two approaches called multiCluster and multiCCA to calculate multilingual word embeddings in a common vector space. The authors also suggest a fresh assessment measure named multiQUVECâ€“CCA to overcome the drawbacks of the QVEC metric. The paper outlines the following contributions; 
The authors introduce two techniques for estimating multilingual word embeddings called multiCluster and multiCCA in their research paper.They utilize data and bilingual dictionaries to develop embeddings that represent semantic connections within and, between languages. 
The researchers suggest QVEC CCA as a better evaluation metric compared to QVEC by utilizing canonical correlation analysis to assess the relationship between the embedding matrix and a linguistic matrix, for a more comprehensive evaluation approach. 
The authors develop a website where researchers can upload their embeddings and assess them using various metrics, for comparisons and result replication purposes. 
The papers notable attributes are; 
 2a) Innovative and efficient estimation techniques;The new approaches known as multiCluster and multiCCA show encouraging outcomes when it comes to estimating multilingual word embeddings,namely when they are trained on a range of languages. 
An enhanced measurement standard known as QVEC CCA demonstrates stronger correlation with practical applications than current intrinsic methods do, in assessing multilingual word embeddings. 
The authors web portal will make it easier for research on multilingual word embeddings, by offering a common platform to assess and compare various methods. 
This paper has its flaws, such, as; 
The paper could improve by providing a thorough comparison to already established approaches in estimating multilingual word embeddings. Not forgetting methods that utilize parallel data. 
The techniques suggested depend on having access to notch bilingual dictionaries that might not be accessible, for every language combination. 
The document may benefit from elaboration on the computational intricacies of the suggested approaches with a specific focus, on handling extensive datasets. 
Queries, for writers; 
How well do the suggested approaches fare against methods that rely on parallel data, like multiSkip? 
Could the authors offer information regarding how they constructed the bilingual dictionaries that were utilized in the experiments? 
How are the suggested approaches dealing with words not found in the list and what impact do they have for future tasks? 