Some of the reasons seem compelling to me. The suggested approach allows for quicker training, than training a neural network does and also maintains specific distribution properties while reducing dimensionality. 
On the hand I'm not fully convinced of the significance of making sure vectors can be transformed with PPMIs. 
The important aspect that is missing in the study is a clear comparison, to similar methods used in the field. 
Elaborate feedback; 
The authors explanation of Kendalls tau, on page 1 differs from its formula and lacks clear justification or origins. 
Why not consider utilizing Spearman correlation ? It's an accepted metric, for semantic tasks and was also used by them for evaluation purposes. 
The datasets chosen for assessment are different from the benchmarks that the NLP community uses to gauge semantic relationships between words and phrases.That said,it's great to venture into datasets.However I'd advise also presenting outcomes basedon the benchmarks, for a more comprehensive evaluation. 
Figure 1 seems to display two lines; where might one find the absence of the third line in this context? 
The author did not directly mention any studies in comparison to their work; they only made a general comment, on the topic. 
I noticed an errors, in the text.
To an extent "large extend" should be corrected to "large extent.‚Äù