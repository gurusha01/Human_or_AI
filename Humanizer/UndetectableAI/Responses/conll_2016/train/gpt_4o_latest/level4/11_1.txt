The writers present an approach to tackle the coreference resolution challenge tailored for Wikipedia content. The objective is to pinpoint the coreference chain linked to the entity highlighted in a Wikipedia article. To achieve this goal the writers mark up 30 documents, with all coreference chains highlighting that around a quarter of the references are related to the idea of the article. They then outline reference points and a fundamental classifier that shows better results when compared to these initial reference points. Additionallyâ€‹ they incorporate their classifier into the Stanford rule based coreference system resulting in enhancements compared to all other cutting edge systems, on Wikipedia. 
This article introduces a change to the coreference challenge that makes sense in terms of information extraction (IE) and could breathe new life into coreference studies.It also serves as a connection between coreference and entity linking research papers.While I usually have reservations about papers that introduce a task due to the limitations of existing systems and suggest minor tweaks, for enhancement this piece stands out as unique. The task is quite engaging, in itself and of fabricating a new field out of thin air; the writers effectively show that traditional systems face challenges in a truly significant environment. 
Analyzing and resolving the idea is an intriguing aspect from an Information Extraction standpoint.There are situations where documents revolve around a particular entity (, like biographical pieces or medical records) and the essential details to extract relate specifically to that entity.This task prioritizes mentions that hold significance rather than including a plethora of irrelevant mentions commonly found in traditional coreference tasks.  
From a standpoint Using the idea of a "main point" great reference point during discussions Plenty of room for enhancements especially for non pronoun references. Furthermore Analyzing coreference, on Wikipedia directly opens up possibilities in utilizing knowledge creatively as demonstrated by the writers. Therefore this field offers an opportunity to explore concepts that could improve coreference resolution on a larger scale; however making significant advancements in the overall context is difficult due, to the complex nature of the issue. 
This paper stands out from research that focuses on individual elements of coreference (such as the Winograd schema). It significantly addresses the coreference challenge within contexts, like Wikipedia that hold great importance for the ACL community. 
The methods used in this paper are effective but not particularly noteworthy.The features utilized are sensible; however investigating combinations of features could lead to better results (it is uncertain if the authors tested this approach). It would be helpful if the authors mentioned in the paper that their primary system, for resolving main concepts is a binary classifier since this detail is not clearly stated at the beginning of the description of feature engineering. 
Just some small stuff to look into.
I recommend placing the dataset after the "Related Works" section as Section 3 to help showcase the results, in the "Baselines" section earlier on and give more context for the "Approach" section to follow. 
In Section 4 when mentioning Dcore and Score in the text it is recommended that the authors include references to the papers on the Stanford coreference system or directly mention that these terms are associated with the Stanford system for better clarity as some readers may not be familiar, with these terms. 
"The phrase 'candidate list' seems a bit ambiguous in the passage mentioned."   
  "We use the links in the article to add details to the list of mentions by including basic semantic characteristics for every link present in the article being reviewed and searching the candidate list, for matching mentions based on the links visible text."  
  Kindly explain that the term "candidate list" pertains to the mentions in the article that may relate to the idea. Most readers can grasp that this component draws on details from Wikipedias hyperlink system (for instance a mention linked to an article labeled as female, in Freebase will be considered female) so using precise language is crucial. 
In Section 6.According to the text provided by Raghunathan et al. there is ambiguity concerning the connection, between WCR mentions and those predicted by their method as Section 4 suggests they are identical.As a result of this confusion the origin of any WCR mentions remains uncertain.This inconsistency requires clarification. 