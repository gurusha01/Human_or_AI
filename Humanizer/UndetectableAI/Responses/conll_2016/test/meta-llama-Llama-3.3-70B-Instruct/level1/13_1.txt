This study introduces a method for resolving event coreferences by identifying event mentions that refer to the same thing in a document using a unique process The researchers develop a dual phase model that creates hidden feature representations, for each event mention with convolutional neural networks before deciding on coreferences using these representations and pairwise features. 
The key achievements of this study are; 
A new idea is being put forward in the realm of event coreference resolution. A model that doesn't depend on external semantic attributes but leverages sentential features produced by convolutional neural networks instead. 
Achieving top notch results on two sets of data—one of them being accessible, to the public—was an accomplishment. 
An examination of errors that sheds light on the difficulties of the assignment and offers insights, for upcoming studies. 
The positive aspects of this article include; 
The writers offer an understandable overview of their model and its parts, for easy comprehension and replication. 
The comprehensive assessment is well executed and meticulously planned out; showcasing a comparison, with cutting edge systems while delving into the effects of feature categories and clustering tactics. 
The error analysis gives us insights, into the difficulties of the task and the constraints of the current model. 
The flaws, in this paper are; 
The writers have not thoroughly compared their models for event coreference resolution, with others work; such a comparison would help us grasp the advantages and drawbacks of their method better. 
The system depends on pre existing word representations that might not be accessible, for every language type and field of study. 
The writers do not explore the uses of their model beyond event coreference resolution; this could be an intriguing avenue, for future study. 
Queries, for writers; 
How do the writers intend to tackle the issue of pronoun resolution that was pinpointed as a cause of mistakes, in the error analysis? 
Could the writers offer information, about how they adjusted the hyperparameters and how the model reacts to various hyperparameter configurations? 
How do the writers aim to expand their model to languages or fields that may lack pre trained word embeddings? 