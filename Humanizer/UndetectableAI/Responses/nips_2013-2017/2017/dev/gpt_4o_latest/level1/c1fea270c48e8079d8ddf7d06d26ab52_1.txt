This research delves into the relationships between continuous strategies for minimizing decomposable submodular functions (DSFM) offering theoretical progress and thorough experimental evaluations in a structured manner.The authors enhance the complexity bounds for optimization techniques in the worst case scenario by utilizing insights from combinatorial aspects while simplifying previous proofs and achieving a \( r \) fold enhancement in the bounds.They also introduce a differentiation between level 0 and level 1 algorithms to facilitate an unbiased comparison of discrete and continuous methods, under uniform circumstances. The results of the experiment show that there are compromises between these methods. Discrete algorithms work well for supports while continuous methods are more effective, for larger supports or when approximate solutions are acceptable. 
Advantages; 
The paper presents advancements in theory by enhancing the limits on condition numbers (κ and ℓ) leading to better assurance of convergence for continuous methods.There is also an accomplishment, in simplifying earlier algebraic proofs through combinatorial reasoning. 
Through an approach to experimentation design employed by the authors in separating level 3 and level 4 algorithms ensures an equitable evaluation of discrete versus continuous techniques are made possible This strategy emphasizes the real world compromises existing between these techniques including the resilience of continuous algorithms, in approximating level 3 solutions. 
The emphasis on DSFM in this paper addresses a real world issue with implications for tasks like image segmentation and various other fields, within the realm of machine learning – appealing to both practical audiences alike. 
Innovative Discoveries; The findings from the experiment offer knowledge like the effectiveness of using gradient techniques in conjunction with pre initialized Fujishige Wolfe algorithms for dealing with large scale issues that pose challenges, for traditional methods. 
Areas, for improvement; 
The paper is structured well overall. Certain parts, like the theoretical proofs and algorithm explanations might be tough for readers not well acquainted with submodular optimization concepts to follow easily. Breaking down or summarizing points could make it easier for people to understand. 
The experiments mainly target types of potentials and datasets that are commonly used in research papers; however it would be beneficial to expand the assessments to include a wider range of real world datasets or explore other submodular applications to reinforce the empirical statements. 
The paper highlights the usefulness of using continuous methods with rough level zero solutions but it fails to thoroughly measure how these approximations affect the quality of the solutions provided which could benefit from a more, in depth analysis of this trade off. 
Reasons, in favor of approval; 
The study significantly enhances the complexity bounds. Streamlines the proofs in order to advance the current state of DSFM research. 
The experimental setup and outcomes offer advice on deciding between discrete and continuous approaches to fill a significant void, in existing research literature. 
The project closely aligns with NIPSs emphasis, on optimization and the practical applications of machine learning. 
Reasons to not agree; 
The complex way the paper is written might make it hard for more people to understand it easily. 
The thorough examination conducted could benefit from incorporating a range of datasets and real world scenarios to enhance its comprehensiveness and relevance. 
Suggestion; 
The paper should be accepted as it makes contributions to the theory and practice of DSFM, with insights that could shape future research in submodular optimization and its practical applications.The impact of the paper could be further increased by making revisions to enhance clarity and broaden the scope of experiments. 