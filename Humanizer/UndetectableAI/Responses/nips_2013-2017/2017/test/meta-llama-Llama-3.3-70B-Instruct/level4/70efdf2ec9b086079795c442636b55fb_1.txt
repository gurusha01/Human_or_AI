This study introduces a method for sharing parameters in RNN models using convolution in an LSTM cell, for disorganized input sequences where tensors act as convolutional filters and feature maps are employed. Furthermore the technique enhances model complexity through postponement of the target output for a number of time steps. 
The idea is quite fascinating. Seems to be unique in nature.The writers present a defined method that is somewhat intricate along with actual test results.When tested on a dataset like the Wikipedia language model the technique delivers results on par with the latest advancements while using only, about half the parameters. 
There are a few issues that come up with this approach. 
The practicality of creating feature maps with high dimensions for various issues is uncertain and calls into question the scalability of this method to high dimensional tensors. Especially considering that the authors only test dimensions, up to 3 in their experiments. 
Introducing "time delay for depth perception" in time or streaming tasks, like speech processing might not be ideal because of the built in delay. 
When dealing with dimensional tensors in neural networks or machine learning models the sheer volume of hyperparameters involved can increase significantly leading to potential complications, in adjusting and utilizing the model effectively.
There is also an error that has been observed.
In line 242 of the document is a mention of "Fig 4 ". It should actually be updated to "Table 4." This adjustment will help maintain accuracy, in referencing the citation. 