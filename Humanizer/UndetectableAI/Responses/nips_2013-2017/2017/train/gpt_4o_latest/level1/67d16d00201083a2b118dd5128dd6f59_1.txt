This article introduces a method for determining the gaps between distributions while accounting for consistent noise that can be added symmetrically—an important challenge in nonparametric testing and understanding distributions more effectively.The writers suggest two techniques to tackle this issue; (1)support of the imbalance in paired variations for testing hypotheses and (2)application of phase functions to create characteristics for durable learning models.These techniques strive to separate the underlying procedures from inconsequential interference—an impactful addition to kernel embeddings and distribution studies, in general. 
The new phase difference measure (PhDM) along with phase characteristics are quite groundbreaking as they enhance the versatility of kernel embeddings by incorporating resistance to disturbances.The researchers illustrate that the phase characteristics can serve well for both testing hypotheses and acquiring knowledge tasks while offering resilience against noise disruptions.The outcomes of the experiments are convincing. Demonstrate that the suggested techniques surpass conventional methods such as Maximum Mean Discrepancy (MMD) particularly, in situations involving noise. In instances such as this one where the Symmetric Mean Embedding (SEM)test's utilized effectively to manage Type I error across different noise scenarios and phase characteristics exhibit resilience in regression assignments with noisy data sets such, as Aerosol and Dark Matter. 
Areas of expertise; 
The paper demonstrates technical rigor with well founded theoretical principles and thorough proofs provided in the appendices.The link between phase functions and resistance, to noise is clearly explained. 
The research presents measures and characteristics (Ph.D. And phase features) broadening current techniques such as MMD and kernel embeddings.The emphasis on resilience to disturbances offers a viewpoint, within the field. 
The techniques tackle an practical issue in analyzing real world data where noise can often hide important distinctions.The results from experiments show how effective these techniques are, for both testing hypotheses and learning activities. 
The paper is nicely structured with a progression, from defining the issue to presenting theoretical advancements and verifying them through experiments using both artificial and real data sets to enhance the practicality of the approaches. 
Areas that need improvement; 
The theoretical aspects are impressive in their complexity; however practical application may prove daunting for those, in the field without expertise in the area of study. 
The PhD test may show higher Type I error rates, in conditions as noted by the authors; this limitation requires more study or ways to address it. 
The research could benefit from exploring options beyond just comparing its techniques to MMD and similar tests; a more comprehensive comparison, with other cutting edge noise resistant methods would enhance the assessment. 
Reasons to consider accepting; 
The article focuses on a deficiency, in nonparametric testing and learning through the introduction of noise resistant techniques. 
The new ideas presented are fresh and important. Could shape upcoming studies in kernel methods and distribution learning. 
The results, from the experiment are strong. Clearly show benefits compared to current techniques. 
Reasons to Not Agree; 
The effectiveness of the PhD test may be compromised in scenarios due to its limitations, in handling high levels of background noise. 
The complexity of these methods might make it difficult for practitioners to adopt them quickly and could restrict their effectiveness. 
Suggestion; 
In terms this document offers valuable insights in the realm of machine learning and kernel methods. Despite a shortcomings its positive aspects clearly surpass the negative ones. I suggest approving it with modifications to tackle the challenges identified in the PhD test and enhance its usability, for professionals. 