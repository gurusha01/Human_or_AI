The research paper presents a method for training predictive models that focuses not only the typical likelihood objectives but also assesses performance based an unrelated external task compared to the model itselfs performance level.This involves optimizing the model parameters to reduce loss in the task which could involve solving a sub optimal problem associated with the model parameters.The study includes experiments, with both real data sets to effectively showcase the practicality of this new approach. 
The opening is very engaging. The explanation throughout is straightforward and understandable to anyone reading it.. The research presented in the paper is solid, in terms of aspects and is based on strong theoretical principles; I couldn't spot any obvious errors or shortcomings. 
The paper presents an argument for why the proposed approach is needed in the field of study.I consider this work to be an well supported application of current technical advancements.The key technical aspect that makes this approach possible. Distinguishing through an argmax operation. Was previously discussed in a publication by Amos in 2016.Building upon these findings this research applies them to a practical and contextually relevant approach, to task oriented learning that I think will garner considerable attention within the machine learning community. 
A significant benefit well as a possible drawback of this method is that the models performance is closely linked to the task at hand. I wonder if the authors could shed some light on whether the model might become too specialized, for the assigned task and how well it can adapt to a task (even one that is slightly altered)?
It would also be useful to look into research on meta learning like the paper "Model Agnostic Meta Learning, for Quick Adaptation of Deep Networks " authored by Finn et al. as it showcases how optimization processes can lead to distinguishing characteristics. 