This paper introduces the dynamic Poisson factorization model that enhances the conventional PF by integrating temporal relationships into the mix. Unlike studies on dynamic PF models that have been conducted before this work involves a simpler version of recurrent neural network to account for long term dependencies. Parameter estimation is conducted through inference with an extra optimization process, for the neural network parameters. The models performance is assessed using five real world datasets. 
In terms and from my perspective as a reader of your work so far is that the concept you've put forward holds promise but needs substantial enhancements in its implementation to align with the caliber expected at a prestigious conference such as NIPS (Neural Information Processing Systems). Here are some specific points, for your consideration; 
Eq 4s structure doesn't match the setup of an RNN because h_t^{（N）} only relies on the memory vectors from the top layer and not on past time steps, in the same layer – can the authors explain why they chose this simpler design? 
Section 2 seems to have some model equations that are not fully explained. Like how the Gamma distribution in Equation 4 is set up and where theta_t, in Equation 3 comes from. 
I don't agree with the points made in lines 110 to 118 about " distributions." Equations 9 and 10 are clear because they show Gamma distributions with defined shapes and rates than being implicit, in nature like mentioned in the discussion. 
Lines 30 to 31 raise a question about the clarity of the method in handling types of data that have distinct patterns of long term dependence, like fanatical and disaster data. 
The section from lines 133 to 155 is a bit confusing to understand can you please explain what the "loss function" mentioned in Equation 15 is all, about? 
MSE (Mean Squared Error) or PMSE ( Mean Squared Error) may not be the best measure for models resembling Potential Field based ones like PF like models in this context. It would be beneficial if the authors incorporated metrics like predictive log likelihood, to more thoroughly assess how well the model performs. 
I think the K value used in the experiments at line 207 seems a bit low, to me; I suggest trying out values like K equals to 100 or even higher for testing purposes. 
The information provided in lines 224 to 232 lacks a link to Figure 3 requiring additional clarification. 
The equations used to update the inference procedure (Equations 11 to 14) might be better suited for inclusion, in the supplementary material to keep the main text concise and focused. 
The description of Figure 4 is hard to understand and needs to be rewritten to make it clearer. 
I highly suggest following the writing guidelines and paying attention to the excessive use of passive voice (especially in the abstract section).
The writing in the paper is not up, to standard. Has plenty of errors as shown below; 
  The dimensions are exceedingly large.
  I need to factorize this equation.
  "This belongs to the" 
  Lines 29. 34 Mention "Dirichlet".
  The text is hidden within another text.
  Figure 1 displays a representation. 
  Figure 1 displays the term "transmission " which might not be suitable, in this situation. 
  There are some sentences noted in line 49 of the document. 
  "Though the Dirichlet distribution is commonly employed as a distribution."