The paper presents a hands on method for integrating classification features into neural networks that are already, in place outlining the following steps;   
Choosing a measure to gauge the networks trust in its forecasts is crucial in assessing its accuracy and reliability.The research explores the utilization of MC dropout scores for networks trained with dropout and the highest softmax score for networks, with softmax outputs which has been proven to show results based on practical evidence.   
1) Determine the confidence level and error rate you want to achieve.   
Utilizing a search technique to find a specific score threshold that ensures the classifiers error rate on the selected samples stays below the desired level, with a certain confidence level.   
The strategy uses a limit on the actual error rate of a classifier calculated from a small sample estimation (Lemma 3. １ ) And utilizes binomial search along with a Bonferroni correction, on the confidence level (Algorithm １ ) to determine the suitable score threshold.   
The methods effectiveness is confirmed by the findings which show a clear correlation, between the targeted error rate outlined in the algorithm and the actual error rates observed in a test set.   
The paper excels, in its practicality. With the softmax response score function that can easily be used with any pretrained neural network. And the clear definition of the target confidence level and error rate as referenced in ref [5]. Though it expands on existing ideas its thorough validation of these ideas greatly boosts its significance.   
The paper doesn't include comparisons that could show why using binomial search and classifier error rate is important.The author should explore what happens when the score threshold is set as the value where the error rate on a particular tuning set meets the target.Would the outcomes be significantly different, from using the limit from Lemma 3\.1? Adding a starting point, like that would help support the methods used in the study and would definitely impact how I assess the research positively.   
There's a problem, with Algorithm 1 as it mentions an uninitialized variable called "r*."