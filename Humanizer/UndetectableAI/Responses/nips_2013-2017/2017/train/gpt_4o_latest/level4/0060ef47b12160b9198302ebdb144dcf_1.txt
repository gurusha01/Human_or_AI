The article presents a technique for creating attention grabbing masks using a network that can handle multiple images in just a few seconds. Showcasing its speed and efficiency, in computation. 
Personally speaking I find the paper to be in a bit of an area, for me – I don't strongly object to either rejecting it or accepting it outright.I do see the value in the idea of teaching a model to explain itself. I think the paper does introduce some interesting concepts worth exploring further. 
Though there aren't any mistakes present, in the text; it does highlight some significant constraints.  
Assessments of saliency are conducted in a manner either through loosely supervised localization or the suggested saliency measurement technique. Both methods display drawbacks that should be openly acknowledged in the research paper. 
The measurement of supervised localization is not the best indicator to use. If knowing the context around an object is important for identifying its category the accuracy of object localization may not always match the quality of saliency. While the findings regarding supervised localization are interesting there is a notable drawback in using it as a metric, for saliency quality. 
The saliency measurement has its constraints based on how it's used in practice.The prominent area is. Adjusted to fit back into the original image dimensions while preserving its proportions.This procedure could lead to two issues.Firstly a change, in proportions might impact the classifiers accuracy in recognizing the object.Secondly the suggested measurement tends to favor significant areas.When a small area is greatly enlarged for re evaluation,the scale at which the object is shown to the classifier might not be ideal. Although convolutional networks are typically insensitive to translation variations in data processing tasks to an extent naturally their ability to handle scale differences needs to be acquired through training; however there are practical boundaries, to this invariance. 
Is there any exploration done on how the masking model relies on the type of architecture employed to train the masks ? Were architectures experimented by the authors and if yes how did it affect the outcomes ? 
Here are a few small notes; 
Were the outcomes, in Table 1 documented for all categories or just for the category?   
Can you provide details on the LRP variant and parameter configurations that were utilized for comparison? LRP offers variants like epsilon and alpha beta along, with their respective parameters. 
I am unable to provide a response, without the input.
Comments made after presenting a rebuttal; 
The success of the suggested saliency measure relies greatly on the accuracy of the classifier and its ability to maintain consistency, across scales—thus limiting the practical use of this approach significantly.   
Applying the technique is not possible for models, in the training phase or models that do not have scale invariance capability.   
Its usefulness may be restricted when applied to areas beyond spectrogram analysis, with CNN technology.   
The approach doesn't work for all black box classifiers as mentioned in the title. 
The authors’ reply indicates a dependence, on the masking network.   
It's not clear if the highlighted saliency refers to the U network or the masking network. 
If the paper adequately addresses these constraints and interdependencies it would be suitable for publication, in my opinion; however if these concerns are not tackled I do not feel the paper should be approved. 