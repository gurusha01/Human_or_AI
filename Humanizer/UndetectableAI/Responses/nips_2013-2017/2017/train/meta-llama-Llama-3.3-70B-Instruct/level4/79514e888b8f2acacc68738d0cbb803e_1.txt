This research. Improves the use of GAN based techniques for semi supervised learning. It builds on work explored in "Improved techniques for training gans " by Salimans in 2016 and "Unsupervised and semi supervised learning with categorical generative adversarial networks " by Springenberg, in 2015. 
The writers suggest the idea of a generator that targets sampling from less crowded areas of the data distribution in feature space and delves into different objective terms based on this examination.However due to the difficulties, in estimating metrics like density and entropy the document resorts to approximations to reach the intended goal. 
The article discusses a detailed case study about data and conducts a wide range of experiments on established semi supervised benchmarks with additional analysis on the suggested concepts.The practical findings show enhancements compared to the Feature Matching standards outlined in "Enhanced methods, for gans training".
The addition of ablation studies is an enhancement to the research and its impressive that the authors shared insights into the impact of each term used in the studys methodology.However it would be beneficial if the studies were more thorough.It raises questions as to why SVHN underwent five experiments while MNIST and CIFAR were only subjected to two and three experiments respectively.Moreover the testing of Approximate Entropy Maximization terms with SVHN leaves doubts about their efficacy, with CIFAR10. The writers might want to offer details on the reasons, behind not conducting a more thorough comparison. 
The advantages of the suggested terms are not always evident in all datasets; although the text mentions this issue briefly and suggests a thorough investigation through completed ablation studies would be helpful, for researchers looking to expand or enhance the concepts outlined in this paper. 