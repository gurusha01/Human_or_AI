The research paper introduces a hashing technique that works within a controlled environment using training data labeled by classes. The models settings are fine tuned by a loss measurement that considers both pairwise similarities and the distinction between classes while assuming a structure. A notable aspect is the focus on optimizing embeddings directly in the training process without relying on relaxation methods; this is accomplished through an alternating minimization strategy. The outcomes show results than several standard methods, across two sets of data and include a detailed exploration of different possibilities. The writing is clear and well done!. As someone not well versed in this field of study I am mainly concerned with how original the approach is.I noticed that other studies ([9 17 21]) have looked into optimization methods and what sets this one apart seems to be the use of a linear classification element in the loss function.Furthermore the whole process seems complex. Might require a lot of computational power.This raises concerns, about how efficient it's to train and the costs involved. 