This study introduces a stage decoding system for Neural Machine Translation (MT) outlining a clear idea supported by practical findings that show significant enhancements compared to a standard reference point, in real world scenarios. 
The writers use Monte Carlo approximation to account for hypotheses efficientlyâ€”a valid method to employ in this context. However important specifics, like the sample size and how this hyperparameter affects performance remain undisclosed. Furthermore it is uncertain if beam search replaces sampling; a clear explanation of these technical aspects is needed. 
The paper presents a contribution with a solid experimental section; however the introduction seems somewhat pretentious by spending two paragraphs on a "Cognitive" rationale that essentially rehashes existing ideas. Multi step decoding has been a subject of exploration for quite some time now and though suggesting a solution for end, to end models is praiseworthy it's unnecessary to disregard previous work or validate it with populist cognitive arguments, particularly when "Cognitive Science" implies a scientific basis. 
I noticed that the sentence on Page 2, at line 73 seems repetitive and could possibly be omitted. 
At Line 78 of the text mentions end to end neural models is correct. Fails to acknowledge the long standing practice of multi pass decoding in speech recognition field which involves creating a word lattice with basic models and then refining it iteratively with more advanced models.This implies that dismissing, past research in order to introduce terminology is unnecessary as sequence prediction has indeed been studied in this area extensively. 
On Page 8, at Line 277th the phrase "In this work " inspired by how humans think could be left out to sound less fancy. 