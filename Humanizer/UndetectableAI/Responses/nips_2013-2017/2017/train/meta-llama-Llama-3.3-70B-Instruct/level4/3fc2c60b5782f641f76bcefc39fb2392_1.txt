This paper introduces a method, for training predictive models that focuses on assessing performance through an external task instead of the usual likelihood goals. To accomplish this goal the model parameters are fine tuned to reduce loss in the task, which could require solving a sub optimal problem that relies on these parameters. The authors back up their idea with experiments using both real data showcasing how practical their approach can be. 
The opening is quite engaging and the explanation as a whole is easy to follow.The research presented is solid. Draws upon existing knowledge, without any glaring issues being obvious. 
The article offers a reason for the suggested method and I believe this study is a valuable and well thought out utilization of current technical advancements. Even though the main technical aspect enabling this method. Differentiation via an argmax. Has been discussed before in Amos 2016 paper; this study implements it in an well reasoned way, within the context of task oriented learning that would probably attract attention from the machine learning field. 
One important point about the suggested method is that the model is closely tied to the task at hand. This could have its advantages and drawbacks alike.Doing an examination on how much the model might become too specialized, for a particular task and its capacity to adapt to slightly varied tasks would be worthwhile. 
The writers might want to look into citing research on meta learning like the study "Model Agnostic Meta Learning for Rapid Adjustment of Deep Networks " authored by Finn et al. as it also includes differentiation using an optimization process. Offering another pertinent illustration, in this scenario. 