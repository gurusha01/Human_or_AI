In this paper is the introduction of a method for depicting how humans ask questions in technical language formulating models for a machine to comprehend human queries effectively and solve them efficiently by considering various factors and conditions within the environment or scenario, at hand. The researchers test their method by simulating the kinds of ended queries that people create in a search game and discover that their model can anticipate the questions individuals will pose and generate original questions that were not included in the initial dataset. 
The article is nicely written with a structure and offers a comprehensive overview of the issue of question formulation in both humans and machines The researchers present an in depth explanation of their approach that covers the grammar and probabilistic generative model aspects and test its effectiveness using a dataset of human generated questions The findings indicate that the approach can anticipate the types of questions humans ask and produce questions that resemble human queries and are relevant, in specific situations. 
The paper stands out for being unique and clear with an impact as its strong points.The authors address an issue in a fresh manner that could push forward the current standards, in interactive machine learning.The paper is nicely. Easy to understand for a wide range of readers.The findings are important as they show the models capability to anticipate and produce questions that resemble those asked by humans. 
The papers limitations involve depending on a field (the game Battleship) requiring more assessment and expansion to different areas of study in depth. Moreover the model uses representations instead of natural language text directly which could restrict its usefulness, in practical situations. 
Reasons supporting acceptance; 
The research paper introduces an unique method, for simulating the way humans ask questions. 
The system has been thoroughly assessed with a set of questions posed by humans. Has produced notable outcomes. 
The article is nicely written with a structure and offers a comprehensive overview of the issue at hand. 
The method shows promise, in pushing the boundaries of active machine learning techniques. 
Reasons supporting acceptance; 
The scope of the model is confined to an area (the game of Battleship) and might not be applicable, to different domains. 
The system works with concepts instead of directly analyzing natural language text; this could potentially restrict its practical use cases. 
More assessment and expansion, into areas are necessary to completely showcase the abilities of the model. 
I think the paper makes a contribution, to the areas of active machine learning and cognitive science and should be accepted for publication; however the authors should also look into addressing any limitations in their approach and expanding their model to cover other domains in their future research work. 