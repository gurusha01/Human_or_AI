In this research paper introduces a method, for conducting multiple hypotheses testing known as Neural FDR utilising neural networks to determine a discovery threshold based on the features of the hypothesis being tested. The key concept involves utilizing a perceptron (MLP) to model the decision threshold effectively accommodating various types of discrete and continuous features. The researchers showcase that Neural FDR effectively manages the discovery rate (FRD) leading to an increased number of discoveries compared to existing methods when applied to both artificial and real world datasets. 
The paper is nicely written with an concise introduction to the issue of testing multiple hypotheses and the shortcomings of current methods highlighted by the authors The suggested method is well justified and explained in detail The practical results are impressive demonstrating that Neural FDR surpasses other approaches, in different scenarios
"The papers strong points are;"
A new and adaptable method for conducting multiple hypotheses testing has been suggested that is capable of managing features, in dimensions. 
The showcase of how Neural FDR manages to control the false discovery rate and uncover more findings compared to other approaches. 
A clear and succinct introduction to the issue at hand along, with the proposed method is provided. 
The method was extensively tested on sets of data. Both artificial and real world datasets. 
The papers drawbacks are as follows; 
Neural FDR performs well when there are hypotheses and a significant proportion of alternatives needed for it to work effectively. 
We don't have a grasp on which network structures best capture the information, in the data. 
Overfitting can be a problem that cross validation helps reduce. May still be a concern, in certain situations. 
In terms the study makes a valuable addition to the multiple hypotheses testing domain and offers an approach that could be useful across different areas. The authors have shown the efficiency of Neural FDR in scenarios making it appealing to both researchers and professionals, in this field. 
Reasons supporting approval; 
The article suggests an adaptable method for conducting multiple tests on hypotheses that is capable of dealing with features, across multiple dimensions. 
The technique is extensively tested on a range of datasets that encompass real world information sources. 
The findings show that Neural False Discovery Rate (Neuralfdr) effectively manages the False Discovery Rate (fdr) and uncovers discoveries compared to alternative approaches. 
The article is nicely written with an concise introduction, by the authors regarding the issue at hand and their suggested method. 
Reasons to oppose acceptance; 
The approach relies on an amount of assumptions and a substantial range of alternatives to function effectively. 
The methods effectiveness may be hindered by the uncertainty surrounding the network architectures for capturing data signals effectively. 
Sometimes there might be a worry, about overfitting in situations; however using cross validation can help reduce this risk. 