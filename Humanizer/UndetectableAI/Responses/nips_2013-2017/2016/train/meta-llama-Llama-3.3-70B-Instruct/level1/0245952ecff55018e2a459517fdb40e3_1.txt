In this paper describes an approach called Conditional Generative Moment Matching Networks (CGMMNs) which focuses on learning conditional distributions by utilizing a condition based maximum mean discrepancy (CMMD). The authors have expanded the functionality of Generative Moment Matching Networks (GMNNs) enabling them to tackle practical challenges such as predictive modeling and contextual generation in addition, to leveraging Bayesian dark knowledge. 
The article is nicely written with a explained introduction by the authors, about the background and purpose of their work The technical parts are also neatly structured with a detailed explanation of the CMMD criterion and the CGMM architecture. 
The papers advantages are as follows; 
The writers introduce an adaptable structure, for understanding conditional distributions that can be utilized across different assignments. 
The CMMD criterion is well founded. Offers a straightforward and effective method, for understanding the conditional distribution. 
The writers extensively assess the suggested approach across a range of tasks such as modeling and contextual generation with expertise, in Bayesian dark knowledge. 
The findings show that CGMMNs perform well in comparison, to the methods available. 
The paper has some limitations such, as; 
The paper presumes that readers have an understanding of deep learning and kernel methods; this might pose a challenge for those who are not experts, in the field to grasp the content easily. 
The writers may offer insight and clarification regarding why they selected the CMMD criterion and the CGMM architecture. 
In cases the outcomes from experiments, like creating images could benefit from a more thorough assessment and review process. 
The paper is nicely. The authors have made a valuable contribution to the realm of deep learning and conditional modeling with their CGMM framework.It has the potential, for applications and offers a versatile and effective means of understanding conditional distributions. 
Reasons supporting approval; 
The article introduces an adaptable approach, for understanding conditional distributions. 
The CMMD principle is well founded. Offers a straightforward and effective method, for understanding the conditional distribution. 
The authors thoroughly assess the proposed approach, across tasks. 
The findings show that CGMMNs perform well in comparison, to the techniques available. 
Reasons to not agree with it; 
The paper expects readers to have an understanding of deep learning and kernel methods. 
The writers may consider offering insight and clarification on why they opted for the CMMD criterion and the CGMM architecture. 
Some of the trial outcomes could benefit from an examination and assessment. 
Rating received is 8, out of 10.
Suggestion for approval with adjustments needed from the authors include offering greater insight and clarification regarding the selection of the CMMD criteria and CGMM architecture as well as enhancing certain experimental findings through, in depth analysis and assessment. 