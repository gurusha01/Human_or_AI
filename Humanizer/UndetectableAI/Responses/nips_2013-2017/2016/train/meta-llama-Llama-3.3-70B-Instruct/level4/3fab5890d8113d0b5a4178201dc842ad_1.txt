The writers suggest using approximations for finding nearest neighbors and selecting top K operations to calculate attention weights in a Neural Turing Machine without affecting training performance negatively and facilitating training on more extensive tasks as demonstrated in their experiments. While this study may not introduce new ideas considering related concepts found in memory network research like http;//arxiv.org/pdf//1410..3916.pdf that involve memories with millions of items and hashing techniques for efficient searches the adaptation of these methodologies, to writable memories represents a significant contribution. Although there wasn't a groundbreaking idea involved in this approachs implementation process the practical aspects are worth noting and reporting about it to others.I suggest that we go ahead and accept the paper with a revisions needed.  
I recommend that the writers give explanations of the tasks and how they were developed since the current explanations are not detailed enough, for replication. Especially considering the absence of the original NTM papers code and the absence of a standardized version of the tasks. Furthermore I ask that the writers agree to share their experiment code to make it easier to replicate their results. 
It's also important to talk about the drawbacks and situations where the suggested model might not work as expected.The authors highlight how their model works smoothly; however it's important to recognize that the argmax (or K maximum argmax ) operation isn't always smooth.When K equals 1 in the read scenario the model shares similarities with MemNN WSH from a study, at http;//arxiv.org/pdf /1503.08895.pdf.This study found that it didn't perform well as a fully smooth model. Enhancing the papers value could be achieved by examining failure cases and discussing the types of tasks and setups that lead to training processes further in detail than currently done in the paper. The models discrete action and lack of attention to this aspect during training should be investigated as noted in http;//arxiv.org/pdf1511_07275. While the results presented by the authors are indeed contributions to the field of study at hand it is crucial to also comprehend the limitations inherent, in their approach. 
I suggest deleting section 3 point 3. Advise the authors to refrain from labeling the Omniglot data as "non simulated" or "real world.‚Äù