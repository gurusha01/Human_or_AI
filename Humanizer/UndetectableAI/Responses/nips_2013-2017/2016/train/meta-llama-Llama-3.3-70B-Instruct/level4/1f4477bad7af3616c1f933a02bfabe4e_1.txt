This research paper delves into a kind of neural network and reveals that it has one stable point that does not change position.The authors suggest an approach that leads to reaching this distinct fixed point representing the lowest overall cost of the function.The study addresses an issue by demonstrating how a sophisticated model, with specific limitations can display just one stable point. In addition to convexity and its variations, like convexity the usual method to demonstrate the singularity of a stationary point relies on fixed point theory, which is the technique utilized in this research. The authors show that by forming a map its fixed point serves as the sole minimizer of the expense function. One drawback of the suggested approach is that it depends on the radius of a non trivial matrix being bounded for convergence proof purposes. A point noted by the authors themselves. Which limited their experiments to networks with fewer hidden units. Furthermore implementing this method involves adjusting parameters which may seem counterintuitive and requires confirming the spectral condition, for each parameter selection. In their experimental analysis section the authors examined around 150000 parameter configurations and chose the most effective one based on cross validation accuracy. However their method surpassed the SVM model in just 2 out of 7 datasets, which brings into question the actual capabilities of the neural network, under investigation. 