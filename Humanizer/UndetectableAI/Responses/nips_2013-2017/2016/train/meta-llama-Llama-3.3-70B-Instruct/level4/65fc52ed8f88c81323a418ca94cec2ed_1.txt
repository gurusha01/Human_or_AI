This document delves into creating similarity characteristics from examples without supervision and introduces a training method and loss function that combines a CNN structure with clustering techniques effectively handling the challenge of uneven training data when working with examples in conjunction with massive neural networks through the use of a differentiated form of discrete clustering loss function.The authors showcase the effectiveness of their approach, on three datasets. Olympic images person pose estimation and the Pascal object recognition dataset. The study introduces an approach that uses CNNs to extract unsupervised similarity features from examples and creates a distinct differentiable loss function while applying clustering to categorize the data into separate groups to address the issue of scarce exemplars compared to abundant negative examples effectively. The paper is thoughtfully. Shows enthusiasm for merging discrete optimization techniques with deep networks for significant impact in the field. While the outcomes, on real world datasets show promise additional validation would be advantageous. There is a point of concern regarding the transition to a feature initialization method for the Pascal dataset. Moving from HOG LDA to Wang et al.s approach; it remains unclear why the HOG LDA features are deemed ineffective for initialization in this scenario and whether the proposed method can effectively address poor initialization issues. Other minor concerns involve the lack of clarity in the wording found in line 41 and the absence of a citation for complete linkage clustering mentioned in line 130 well as the limited presentation of results, for the Pascal dataset showing only k equals 5. It would be helpful to share the outcomes for values ranging from 1 to 10 and specify if the increase of 3 percent is dependent upon the value of k being equal to ùü±. Moreover " lines number two (2) seventy six (76) one hundred twenty six (126) and two hundred twenty five (225) exhibit grammar and spelling errors that need correction, for clarity and accuracy. 