This research paper introduces complex network structures created to forecast pixel level outcomes of video frames and unveils an original extensive dataset showcasing videos depicting real world object handling by robotic arms. Of directly estimating pixel values the suggested structures anticipate pixel movements, in each frame enabling more precise forecasts when used on unfamiliar objects. Two of the designs stand out for their use of a "compositing" feature that allows different changes to be made to separate objects in a way that leads to object segmentation effectively being achieved. The extensive dataset supports comprehensive system training. Offers a solid foundation for comparing different approaches. Moreover the dataset contains not video input but also information on the robot arms position and an illustration of the desired pose making it ideal, for examining how actions impact the environment. With these combined efforts could help propel the progress of creating robots that can learn from their environment through casual interactions. 
The dataset discussed in this paper is a resource that showcases real life interactions between a robot and different objects and is expected to spark further research endeavors in the future significantly. The new models suggested demonstrate performance compared to current techniques; however it is worth mentioning that the accuracy of the predictions is still somewhat modest. Although the paper rightly highlights the importance of using real world data in its research findings about the potential of the proposed structures to grasp dynamics could use more verification, for credibility. For example​; Evaluating the structures on a defined dataset like the block world dataset introduced by Battaglia et al. could offer a more precise evaluation of how well the models can grasp authentic physical laws and limitations​. Simply put​; There is a disparity between comprehending the fundamental cause and effect relationships, in physics and just forecasting movement​. 
Moreover in a study by Lotter et al. they showcased the ability to predict future frames at the pixel level over multiple time steps with outcomes that seem to match up well with the findings of this paper to some extent at least.In a scenario this technique could have been part of the quantitative analysis outlined in the paper.However due, to the novelty of this research undertaking such comparisons might not be realistic. It is important to address this related work, in the paper at a minimum. 