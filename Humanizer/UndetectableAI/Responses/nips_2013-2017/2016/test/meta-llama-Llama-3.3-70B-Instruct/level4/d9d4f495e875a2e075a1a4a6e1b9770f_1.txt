This document introduces advanced network structures created to forecast video frames at the pixel level and presents a vast collection of real world scenarios involving robotic arms manipulating objects.The novel architectures predict pixel movement within each frame of predicting exact pixel values directly resulting in more precise predictions for unfamiliar objects.Furthermore some of these structures employ a 'compositing' method that applies changes, to individual objects enabling a limited degree of unsupervised object segmentation. The extensive dataset enables training of entire systems and thorough assessment of different methods in competition scenarios.The dataset notably contains the position of the robot arm and a depiction of the desired position target which's beneficial for understanding the impacts of actions in an environment.These progressions have the capability to aid in the advancement of robots that're capable of acquiring knowledge from natural interactions, with their surroundings.The incorporation of a physical interaction dataset involving a robot and diverse objects is a noteworthy addition that is expected to spark significant research endeavors in the future. While the new models show performance compared to other methods available in the market out there; the accuracy of their predictions still falls short somehow in absolute terms. The research paper mainly talks about using a real world dataset that has been introduced recently; however it might be useful to test these new neural network designs on datasets like the block world dataset developed by Battaglia and team to confirm their capability in understanding environmental physics. By doing this kind of testing it would be possible to assess how well these models can grasp real physical principles and limitations since learning physics—meaning understanding the root causal relationships—could be quite different, from just predicting motion patterns. Recent research by Lotter et al.s study on Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning (published in ArXiv in 2016) has demonstrated outcomes in predicting pixel level details several time steps ahead in the future effectively.A discussion about this approach could serve as an alternative, for the papers quantitative evaluations considering its recent emergence. 