This research paper presents a technique to develop policy models based on demonstrations and applies it to analyzing player behavior in basketball games. The authors use neural networks along with an attention mechanism to merge overall objectives with detailed actions. While the research goal is interesting and engaging for readers like me who understand reinforcement learning but not deep learning, in depth the technical aspect of the contribution may be challenging to grasp and assess in its state. I had a time understanding Section 4 of the document that explains the new method because I'm not familiar with deep learning concepts as an expert would be. Some parts were unclear to me like in Equation 5. I wasn't sure about the meaning of "L." Is it referring to a loss function. If yes how exactly is the loss defined? Additionally it seems like the work doesn't show connections to previous research or mention any alternative methods, for comparison purposes. In this case study by George Koniaris and Sanjoy Krishnan regarding acquiring skills and strategies from demonstrations has relevance but lacks proper acknowledgment or exploration in the writing itself. I urge the authors to review and resubmit their paper with these points in mind. Here are a few references to studies that could be beneficial, for integration and contrast;   
In a research paper titled "Robot Learning from Demonstration by Constructing Skill Trees " authored by G.D Konidaris and colleagues and published in the International Journal of Robotics Research in March 2012 (Volume 31 Issue 03) the authors delve into the topic of robot learning techniques, through the creation of skill trees.   
The work titled "Learning and generalization of tasks from unstructured demonstrations" was presented at the 2012 IEEE/RJS International Conference on Intelligent Robots and Systems (IROS). This study explores the process of acquiring and applying knowledge from demonstrations, in complex tasks.   
"The study by Han et al. presented at the 2015 IEEE/RSI International Conference on Intelligent Robots and Systems (IROS) explores the development of multi step controllers in scenarios, with uncertain dynamics."  
In a study presented at the 2016 IEEE International Conference on Robotics and Automation (ICRA) researchers Murali et al., introduced a method called "TSC DL" for segmenting modal surgical demonstrations using Deep Learning techniques (pp 4150â€“4157). The research was conducted in collaboration with experts from fields such as Abbeel and Darrell from UC Berkeley and Goldberg, from UC Berkeley and Google Brain team.   
I would also like to understand more about how the approach works in real world scenarios and where the weak labels come from, in applications. 