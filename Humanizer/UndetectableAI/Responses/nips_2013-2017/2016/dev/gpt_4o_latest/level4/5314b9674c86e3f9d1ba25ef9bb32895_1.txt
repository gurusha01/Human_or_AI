The paper discusses how matrix product states (MPS) decomposition is used as a tensor network method to solve a multiclass supervised classification issue in a broad sense of context understanding, with MPS and tensor networks concepts often seen in quantum physics but not as commonly known in the broader machine learning field. The suggested method expands on research (citations [3] and [4]) offering gradual and somewhat comparable advancements as those seen in earlier investigations. The key contributions of the paper can be outlined as follows; a). It presents a kernel inspired by tensors, for encoding which can be utilized in any classification task where the input data is depicted as vectors of fixed lengths. B).It uses descent to enhance the MPS representation for the classification assignment instead of choosing the MPS representation initially through unsupervised means as done in reference [3]. Then employing it in a separate phase, for classification using a regular classification algorithm on the altered data. 
The paper starts by assuming that readers are already familiar with tensor networks and MPS. Concepts often found in quantum physics but not necessarily known to everyone in the NIPS audience. I believe the paper would greatly improve with a detailed explanation of these concepts starting from the fundamentals. Although it may be tough to fit all this information into a NIPS paper due to space limitations it's crucial, for ensuring that the paper is easier to understand for an audience.   
Adding the sizes of vectors and matrices in the paper would really help with understanding. Making things clearer, for the readers.   
In line 153 of the document it talks about employing a zig arrangement; however Figure 8 doesn't seem to show this pattern accurately depicted in the visual representation provided there.Can you confirm if this is a typing mistake or if the incorrect image was included in this context?   
The paper should discuss the variances between this study and references [1][2] on in the document, for better clarity and reader comprehension of tensor networks unfamiliar readers to grasp the significance of the present research findings.   
The mention of networks towards the conclusion adds valuable insights for readers, in this context; further elaborating on this topic would enhance the papers quality.   
Can you give me information, about how the starting process works in this case and how much the suggested approach is affected by small minimum values and what steps were taken to deal with this problem?   
It would help to mention the tools or libraries utilized for carrying out singular value decomposition ( SVD).