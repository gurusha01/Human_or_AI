The manuscript describes a method for visual question answering (VQA) where multiple layers of reasoning are used to improve question understanding based on image details, over several iterations. Each layer of reasoning consists of two parts. Question Image interaction. Weighted pooling. Which work together to refine the representations by integrating question and image features using neural networks and attention weights learned during training. The model utilizes object proposals to pinpoint image regions and processes them through a convolutional neural network (CNN).The visual attributes in the image interact, with how questionsre presented and a gentle focus mechanism creates an attention spread across different parts of the image. 
The manuscripts primary strength lies in its advancements that skillfully expand upon and merge established ideas like the "Neural Reasoner " spatial coordinates concept by R.Hu et al., 2015 and soft attention mechanisms, by K.Xu et al., 2015. The document is nicely. Simple to grasp with its clear breakdown of the models structure. Covering the components like image analysis layer and question processing layer through, to reasoning and response layers.The innovation of refining question representations using image characteristics stands out as an addition not found in earlier VQA setups. 
However there are some shortcomings that have been identified in the study mentioned in Section 3 Point 1 where they suggest incorporating 8 spatial coordinates to account for the absence of spatial information regarding object positions But it remains unclear if any tests were carried out to compare how well models perform with and without these spatial coordinates Without empirical evidence it becomes difficult to assess whether these additional coordinates actually improve the models grasp of the spatial connections, among object suggestionsIn case these coordinates don't work as expected the model might face the problem, which could pose a major drawback.
Additionally in Section 4 point 3 of the report indicates that the new model performs better than SAN (Stacked Attention Networks) when answering questions related to objects by focusing on specific object proposal regions with high object probability selected beforehand; however according to the data presented in Table 3 this assertion is not completely supported as the new model excels only in responding to Yes or No inquiries but fares worse in other question types when compared to SAN model performance wise; this discrepancy, between analysis and findings complicates the assessment of the new models competency in handling other question types effectively. 
After taking another look at it the suggested model seems to be built upon the "Neural Reasoner" [referencing B.Peng et al., 2015] involving images and attention mechanisms which could lessen the originality of the method suggested As stated in the response remarks on enhanced performance while positive does not showcase any advantages of the model since other models could also see enhancements through refining visual representations. The manuscript mainly focuses its attention two contributions but they are somewhat constrained in their originalityâ€”updating question representations iteratively aligns with previous endeavors [21] and the employment of object proposals does not introduce a new concept [23]. Due to the absence of ablation experiments and the modest advancements, over studies it is advised to decline the paper for publication. 