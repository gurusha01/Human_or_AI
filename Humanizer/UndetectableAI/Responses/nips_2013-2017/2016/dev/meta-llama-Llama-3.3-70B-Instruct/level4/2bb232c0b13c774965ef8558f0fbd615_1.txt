The writers have put forward a system to analyze handwritten text in images that have several horizontal lines by enhancing the single line parser developed by Graves et al [18] incorporating an attention mechanism into the process of decoding the text using Bidirectional LSTMs of the original softmax method used by Graves et al. The systems effectiveness is assessed using the Rimes and IAM datasets. Shows similar outcomes to cutting edge techniques on the Rimes dataset but isn't as successful on the IAM dataset. This study demonstrates an use of guided attention, for recognizing sequences of handwritten text lines in an image by building upon the region attention method introduced by Xu et al [38]. Other researchers.  
To improve the papers clarity and completeness it would be helpful to offer a thorough description of the MD LSTM model in section 3 that is similar, to what can be found in reference [18]. The authors should delve deeper into aspects of the findings and research methods for better understanding.  
The better results achieved by the method compared to techniques that rely on known line labeling can be seen in table 2 and section 5. This difference may be due, to how the decoder RNN's reinitialized in each approach. Provided a detailed explanation of how the authors implemented Graves et al.s method would help clarify why this gap exists. 
The statement made on line 142 about achieving a speed improvement of 20 to 30 times compared to the character decoder method, by Bluche et al. lacks timing comparisons to support this claim. 
There seems to be a difference in the performance of the Rimes and IAM datasets; while the system performs well on Rimes data but struggles with IAM data which might be because of not enough training data available to it could be resolved by conducting another experiment where the model is trained on both test and training data, from the other dataset first and then fine tuned on IAM training data This approach would offer valuable insights into how well the system can adjust and what kind of data it needs. 
Line 213 discusses how the attention mechanism struggles with identifying punctuation marks and highlights the need for an explanation to grasp the reasons, behind this issue and explore ways to enhance it further. 