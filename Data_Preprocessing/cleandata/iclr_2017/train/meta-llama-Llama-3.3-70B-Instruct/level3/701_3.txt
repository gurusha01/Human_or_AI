Summary
The paper proposes a novel technique, NoiseOut, for pruning neural networks by removing neurons with correlated activations during training. The authors introduce a method to encourage higher correlation between neurons by adding noise outputs to the network, which helps to prune more redundant neurons without accuracy loss. The experimental results demonstrate the effectiveness of NoiseOut in reducing the number of parameters in dense layers of neural networks while maintaining accuracy.
Decision
I decide to reject this paper, primarily due to two key reasons. Firstly, the paper lacks a thorough comparison with strong baselines, such as an ensemble of pre-trained nets, which makes it difficult to evaluate the effectiveness of the proposed technique. Secondly, the results in Section 3 are weak due to the use of a large network, and experimenting with smaller nets could provide more insightful results.
Supporting Arguments
The paper presents an interesting approach to pruning neural networks, but it falls short in providing a comprehensive evaluation of its effectiveness. The absence of previously published results in figures 4, 5, and 8 makes it challenging to situate the paper and evaluate its contribution to the field. Additionally, the use of a batch five times in a row during training is unconventional, and its effectiveness compared to regular SGD is unclear. The paper's figures, particularly Figure 5, require improvement in terms of labeling and presentation for better readability.
Additional Feedback
To improve the paper, I suggest that the authors provide a more detailed comparison with existing pruning methods, such as Progressive Nets and ResNet. The authors should also experiment with smaller networks to demonstrate the effectiveness of NoiseOut in more realistic scenarios. Furthermore, the authors should consider adding an explicit constraint to the loss function to strengthen their claim of learning complementary features. Finally, the authors should provide more insight into the effect of NoiseOut on the test accuracy and its relation to dropout and regularization.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
1. How does NoiseOut compare to other pruning methods, such as Progressive Nets and ResNet, in terms of pruning efficiency and accuracy?
2. Can the authors provide more insight into the effect of NoiseOut on the test accuracy and its relation to dropout and regularization?
3. How does the choice of noise distribution affect the pruning process, and are there any specific distributions that work better than others?