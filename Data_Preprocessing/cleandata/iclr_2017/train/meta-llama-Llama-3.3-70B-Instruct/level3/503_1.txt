Summary
The paper proposes a novel approach to few-shot learning called prototypical networks, which learns a metric space where few-shot classification can be performed by computing Euclidean distances to prototype representations of each class. The authors demonstrate the effectiveness of their approach on the Omniglot and miniImageNet datasets, achieving state-of-the-art results on the former and competitive results on the latter. They also show that their approach can be adapted to zero-shot learning, achieving state-of-the-art results on the Caltech UCSD birds dataset.
Decision
I decide to accept this paper, with the main reason being that the approach is well-motivated, simple, and effective. The authors provide a clear and concise explanation of their method, and the experimental results demonstrate its competitiveness with state-of-the-art approaches.
Supporting Arguments
The paper tackles a specific question in few-shot learning, which is an important problem in machine learning. The approach is well-placed in the literature, building on existing work in metric learning and episodic training. The authors provide a thorough analysis of their method, including a discussion of the design choices and the equivalence to a linear classifier. The experimental results are convincing, demonstrating the effectiveness of the approach on multiple datasets.
Additional Feedback
To further improve the paper, I suggest that the authors provide more discussion on the related work, including mixture of experts models and multiplicative RNN models, to provide a broader context for their approach. Additionally, it would be helpful to include more synthetic examples to demonstrate the capability of handling missing data when one or more modalities are unavailable at test time. A comparison with a fully-connected MLP model of similar complexity in the synthetic experiment would also be useful to evaluate the decision boundary capabilities of the proposed model.
Questions for the Authors
I would like the authors to clarify how they handle the multi-modal case, specifically regarding the equation for weighted activation and the choice of nonlinearity. I would also like to know more about the possibility of handling missing data and how the authors plan to address this in future work. Finally, I would like to see more visualizations of the learned prototypes and embeddings to gain a better understanding of the model's behavior.