The paper proposes a novel approach to learning algorithmic tasks by combining a Convolutional Neural Network (CNN) with a Scattering network. This hybrid architecture aims to improve stability and performance, particularly in limited data scenarios. The authors demonstrate the effectiveness of their approach on two paradigmatic problems: sorting and finding planar convex hulls.
I decide to accept this paper with minor revisions. The key reasons for this decision are:
1. The paper tackles a specific and well-defined problem, namely, learning algorithmic tasks with limited data.
2. The approach is well-motivated, building upon the principles of divide and conquer, and leveraging the strengths of both CNNs and Scattering networks.
To support this decision, I provide the following arguments:
* The authors provide a clear and concise explanation of their approach, including the architecture and training procedure.
* The experimental results demonstrate the effectiveness of the proposed approach, particularly in limited data scenarios.
* The paper is well-organized, and the writing is clear and concise.
However, I also provide some additional feedback to improve the paper:
* I recommend adding a state-of-the-art ResNet to Table 3 to provide a more comprehensive comparison.
* There are some minor typos in the paper that should be corrected.
* The authors could benefit from investigating the effect of stable bottom layers on adversarial examples to determine if the hybrid architecture increases robustness.
* The proposed architecture lacks evaluation on real-world limited data problems, which could further support the improved generalization claim.
To clarify my understanding of the paper, I would like the authors to answer the following questions:
* Can you provide more details on how the Scattering network is integrated with the CNN, and how the parameters are shared across the two networks?
* How do you plan to extend the approach to more complex algorithmic tasks, such as those involving graphs or sequences?
* Can you provide more insights into the trade-offs between accuracy and complexity in the proposed approach, and how these trade-offs can be optimized in practice?