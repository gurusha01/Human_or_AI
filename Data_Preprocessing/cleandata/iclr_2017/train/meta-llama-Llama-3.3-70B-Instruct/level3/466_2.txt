This paper presents a novel approach to policy search in stochastic dynamical systems using model-based reinforcement learning with Bayesian neural networks (BNNs) that include stochastic input variables. The authors demonstrate the effectiveness of their approach in solving a challenging benchmark problem and achieving promising results on real-world industrial applications.
The paper tackles the specific question of how to learn a policy in a stochastic environment using a model-based approach, which is a well-motivated problem in the field of reinforcement learning. The approach is well-placed in the literature, building on recent advances in Bayesian neural networks and model-based reinforcement learning.
The paper supports its claims with thorough experiments on several benchmark problems, including the Wet-Chicken problem and two industrial applications. The results demonstrate the effectiveness of the proposed approach in learning policies that achieve high rewards, often outperforming other methods such as Gaussian processes and variational Bayes.
However, I have some concerns regarding the clarity of the presentation and the lack of intuition on how the identity re-parametrization helps optimization. Specifically, I would like the authors to provide more insight into the construction of the non-linear residual networks and the role of the resnet in it. Additionally, I question the uniqueness of the construction and the implications of the existence of a network in the residual class that overfits.
To improve the paper, I suggest that the authors provide more details on the dimension matching in Eq 3.4 and clarify the dimensions of qj and ej. Furthermore, I would like to see more discussion on the relation to Nystrom approximation and clustering activations independently from labels.
Overall, I decide to accept this paper, but I would like the authors to address the above concerns and provide more clarity and intuition on their approach.
Some specific questions I would like the authors to answer are:
* Can you provide more insight into the construction of the non-linear residual networks and the role of the resnet in it?
* How does the identity re-parametrization help optimization, and what are the implications of the existence of a network in the residual class that overfits?
* Can you provide more details on the dimension matching in Eq 3.4 and clarify the dimensions of qj and ej?
* How does your approach relate to Nystrom approximation and clustering activations independently from labels?