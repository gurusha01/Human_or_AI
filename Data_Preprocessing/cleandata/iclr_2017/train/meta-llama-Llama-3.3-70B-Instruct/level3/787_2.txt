The paper proposes a novel approach to learning binary autoencoders, formulating the problem as a biconvex optimization problem that learns from pairwise correlations between encoded and decoded bits. The authors derive an optimal decoding function, which emerges as a single layer of logistic sigmoid artificial neurons, and propose an efficient optimization algorithm to learn the autoencoder.
The paper tackles the specific question of learning binary autoencoders with worst-case optimal loss, and the approach is well-motivated by the desire to avoid explicit model assumptions and non-convex optimization. The authors provide a clear and detailed derivation of the optimal decoding function and the optimization algorithm, and the paper is well-placed in the literature, drawing on ideas from minimax theory, convex optimization, and autoencoding.
However, I have some concerns regarding the paper's claims and results. The authors claim that their approach is competitive with standard autoencoders trained with backpropagation, but the experimental results are limited to a few datasets, and it is unclear how the approach would perform on more complex tasks. Additionally, the authors do not provide a clear comparison to other autoencoding methods, such as variational autoencoders, which are not included in the experimental results.
Therefore, I would like to reject the paper, with the main reason being that the experimental results are limited and do not provide a comprehensive evaluation of the approach. Additionally, I would like to see a more detailed comparison to other autoencoding methods and a clearer discussion of the advantages and limitations of the proposed approach.
To improve the paper, I would suggest the following:
* Provide more comprehensive experimental results, including a comparison to other autoencoding methods and an evaluation on more complex tasks.
* Clarify the advantages and limitations of the proposed approach, including a discussion of the trade-offs between the proposed approach and other autoencoding methods.
* Consider providing more details on the optimization algorithm, including convergence guarantees and computational complexity.
* Address the question of how the approach would perform on datasets with more complex structures, such as images or text data.
Some questions I would like the authors to answer include:
* How does the proposed approach compare to other autoencoding methods, such as variational autoencoders, in terms of reconstruction loss and computational complexity?
* Can the authors provide more details on the optimization algorithm, including convergence guarantees and computational complexity?
* How would the approach perform on datasets with more complex structures, such as images or text data?
* What are the advantages and limitations of the proposed approach, and how does it compare to other autoencoding methods in terms of flexibility and interpretability?