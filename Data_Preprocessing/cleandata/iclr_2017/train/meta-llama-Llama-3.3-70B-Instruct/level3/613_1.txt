Summary
The paper proposes a differentiable implementation of Canonical Correlation Analysis (CCA), which enables the incorporation of CCA as a building block within multi-modality neural networks. The authors demonstrate the effectiveness of this approach in cross-modality retrieval experiments on two public image-to-text datasets, outperforming both Deep CCA and a multi-view network with freely-learned projections.
Decision
I decide to Accept this paper, with the primary reason being that the approach is well-motivated and effectively addresses a specific problem in the field of multi-modality learning. The paper provides a clear and concise explanation of the methodology, and the experimental results demonstrate the superiority of the proposed approach over existing methods.
Supporting Arguments
The paper tackles a specific question of how to effectively incorporate CCA into a neural network architecture, and the authors provide a well-motivated solution. The approach is built on existing methods, but the authors provide a novel and effective way to make CCA differentiable, allowing for end-to-end training. The experimental results are convincing, and the authors provide a thorough analysis of the learned representations.
Additional Feedback
To further improve the paper, I suggest that the authors provide more theoretical motivation and technical insight into the differentiable CCA formulation. Additionally, the authors could benefit from providing more controlled experiments, such as synthetic experiments, to enhance reproducibility and technical perspective. It would also be helpful to include a theorem on the identifiability of causal and discriminative variables to provide a more rigorous foundation for the approach.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more intuition on why the differentiable CCA formulation is effective in practice, and how it relates to the underlying mathematical principles of CCA?
2. How do you plan to address the potential limitations of the approach, such as the requirement for large batch sizes and the sensitivity to hyperparameters?
3. Can you provide more details on the experimental setup, such as the specific architectures used and the hyperparameter tuning process, to facilitate reproducibility of the results?