Summary of the Paper's Contributions
The paper proposes a novel approach to learning bilingual word vectors using a linear transformation between vector spaces, which is proven to be orthogonal and can be obtained through a single application of the Singular Value Decomposition (SVD) on a dictionary of translation pairs. The authors introduce a new "inverted softmax" method for identifying translation pairs, which significantly improves the accuracy of predicted translations. The paper also demonstrates the robustness of orthogonal transformations by achieving high precision using a pseudo-dictionary acquired from identical word strings in both languages.
Decision and Key Reasons
I decide to accept this paper, with two key reasons for this choice. Firstly, the paper tackles a specific and well-motivated problem in the field of natural language processing, namely the learning of bilingual word vectors. The approach is well-placed in the literature, building on existing work by Mikolov et al. and Faruqui & Dyer. Secondly, the paper provides a clear and rigorous theoretical framework for the proposed method, including a proof that the optimal linear transformation between word vector spaces should be orthogonal.
Supporting Arguments
The paper provides a thorough evaluation of the proposed method, including experiments using an expert training dictionary, a pseudo-dictionary, and the Europarl corpus of aligned sentences. The results demonstrate the effectiveness of the proposed method, achieving high precision in translating words and sentences between languages. The paper also provides a detailed analysis of the robustness of orthogonal transformations, showing that they can achieve high precision even when using a pseudo-dictionary.
Additional Feedback
To further improve the paper, I suggest that the authors provide more detailed comparisons with other state-of-the-art methods for learning bilingual word vectors, including online approaches that use aligned text as the bilingual signal. Additionally, the authors could explore the application of the proposed method to other languages and domains, to demonstrate its generalizability and effectiveness.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. How do the authors plan to extend the proposed method to handle more diverse language pairs, where the number of identical character strings may be limited?
2. Can the authors provide more insight into the relationship between the proposed method and other approaches to learning bilingual word vectors, such as CCA and online methods?
3. How do the authors plan to evaluate the effectiveness of the proposed method in real-world applications, such as machine translation and language-agnostic text classification?