Summary
The paper proposes a novel approach to constructing a tree of life using the deep representation of convolutional neural networks (CNNs) trained for image classification. The authors leverage the hierarchical feature representation learned by deep networks to quantify the visual similarity of species and construct a tree of life. The method is evaluated on various species, including fish, canine, and vehicle categories, and shows promising results.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the approach presented in the paper, although interesting, is not particularly novel, which may limit its impact at a conference like ICLR. Secondly, the results are difficult to interpret, and the real impact of the model is unclear, making it challenging to assess the significance of the contributions.
Supporting Arguments
The paper proposes a competitive learning architecture that learns different RNN predictors independently to predict driving behaviors from human drivers. However, the frequent switching of behaviors within seconds raises questions about the effectiveness of the model in choosing the best driving mode for a given situation. Furthermore, the paper's focus on visual similarity may not be sufficient to capture the complex relationships between species, and the use of deep learning techniques may not provide a significant advantage over traditional methods.
Additional Feedback
To improve the paper, the authors could provide more context on the limitations of traditional methods for constructing trees of life and how their approach addresses these limitations. Additionally, the authors could include more detailed analysis of the results, including comparisons with other methods and discussions of the potential biases and limitations of their approach. It would also be helpful to include more visualizations and examples to illustrate the constructed trees of life and facilitate understanding of the results.
Questions for the Authors
I would like the authors to clarify the following points:
* How do the authors plan to address the limitations of their approach, particularly with regards to the frequent switching of behaviors and the focus on visual similarity?
* Can the authors provide more detailed comparisons with other methods for constructing trees of life, including traditional methods and other deep learning-based approaches?
* How do the authors plan to extend their approach to incorporate additional information, such as gene similarity, to construct more delicate trees of life?