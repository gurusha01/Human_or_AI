Summary of the Paper's Claims and Contributions
The paper proposes a novel approach to machine translation by formulating it as a noisy channel decoding problem. The authors introduce a recurrent neural network-based model that parameterizes the source and channel models, allowing for the use of unpaired output data to improve translation quality. The model is trained using a dynamic programming algorithm to marginalize the latent alignment variable, and decoding is performed using a beam search algorithm. The authors claim that their approach outperforms direct models and achieves state-of-the-art results on several machine translation tasks.
Decision and Key Reasons
I decide to reject this paper, with two key reasons:
1. Lack of Convincing Results: The paper's results are not convincing, with a low probability of correctly labeling a word as a mistake, and the oracle experiments are deemed meaningless. The authors' claims of outperforming direct models are not sufficiently supported by the experimental results.
2. Methodological Concerns: The paper's approach raises methodological concerns, such as the need for a new method to correct another method's predictions, and the convergence of the iterative approach to a better solution. The authors do not provide sufficient justification for their approach or address these concerns adequately.
Supporting Arguments
The paper's notation is excessively fiddly and confusing, making it difficult to follow the authors' arguments. The discussion in Section 4 creates a mismatch between training and test conditions, which raises questions about the validity of the results. The authors' comparison to other models is limited, and stronger baselines are needed to demonstrate the benefits of their approach.
Additional Feedback and Questions
To improve the paper, the authors should:
* Simplify the notation and provide a clearer explanation of their approach
* Address the methodological concerns and provide more convincing results
* Compare their approach to more powerful convolutional models and system combinations
* Clarify the mismatch between training and test conditions and provide a solution to address this issue
I would like the authors to answer the following questions:
* Can you provide more detailed results on the performance of your model on different datasets and tasks?
* How do you plan to address the methodological concerns and improve the convergence of your approach?
* Can you provide a more detailed comparison to other models and baselines, including convolutional models and system combinations?