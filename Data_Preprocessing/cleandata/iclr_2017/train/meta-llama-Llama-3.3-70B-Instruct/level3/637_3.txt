Summary
The paper proposes a novel approach to learning state representations in robotics using deep neural networks and robotic priors. The authors demonstrate the effectiveness of their approach in learning a one-dimensional representation of a Baxter robot's head position from raw images. The use of robotic priors, such as temporal coherence, proportionality, repeatability, and causality, allows the network to learn a representation that is consistent with the physical rules of the environment.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the approach seems to be tailored to a specific task and environment, and it is unclear how well it would generalize to more complex scenarios. Secondly, the experimental evaluation is limited to a single task and environment, and there is no comparison to other state-of-the-art methods.
Supporting Arguments
The paper presents an interesting idea, but the evaluation is limited to a simple task and environment. The authors claim that their approach can learn a representation that is robust to noise and luminosity perturbations, but this is only demonstrated in a controlled simulation environment. It is unclear how well the approach would perform in more realistic settings. Additionally, the paper lacks a thorough comparison to other state-of-the-art methods for learning state representations in robotics.
Additional Feedback
To improve the paper, the authors could provide more detailed comparisons to other methods, such as those using supervised learning or reinforcement learning. They could also demonstrate the effectiveness of their approach in more complex environments, such as those with multiple objects or dynamic scenes. Furthermore, the authors could provide more insight into how the robotic priors are selected and tuned, and how they affect the learned representation.
Questions for the Authors
I would like to ask the authors to clarify the following points:
* How do the authors plan to extend their approach to more complex environments and tasks?
* How do the robotic priors affect the learned representation, and are there any limitations to their use?
* Can the authors provide more details on the training process, such as the number of iterations and the learning rate schedule?
* How do the authors plan to evaluate the effectiveness of their approach in more realistic settings, such as with real-world images or in scenarios with limited supervision?