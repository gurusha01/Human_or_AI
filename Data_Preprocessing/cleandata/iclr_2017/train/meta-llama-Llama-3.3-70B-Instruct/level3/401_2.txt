Summary of the Paper's Contributions
The paper proposes a novel formulation of Canonical Correlation Analysis (CCA) as a fully differentiable neural network layer, enabling gradient flow through the computation of CCA projection matrices. This allows CCA to be used as a building block within multi-modality neural networks, producing maximally-correlated projections of its inputs. The authors demonstrate the effectiveness of this approach in cross-modality retrieval experiments on two public image-to-text datasets, surpassing both Deep CCA and a multi-view network with freely-learned projections.
Decision and Key Reasons
I recommend accepting this paper, with the key reason being its novelty and potential to contribute to the field of multi-modality learning. The paper presents a well-written and compelling idea, and the experimental results demonstrate the effectiveness of the proposed approach.
Supporting Arguments
The paper tackles a specific question of how to extend CCA to be used as a building block within neural networks, and the approach is well-motivated and well-placed in the literature. The authors provide a clear and detailed description of the proposed differentiable CCA layer and its application to cross-modality retrieval. The experimental results are convincing, and the comparison to state-of-the-art methods is thorough.
Additional Feedback and Questions
To improve the paper, I suggest providing more details on the training process of the introspection network and the use of a more current state-of-the-art model in ImageNet experiments. Additionally, it would be helpful to clarify the influence of the weighting coefficient α when using exponential moving average estimates of the covariance matrices for CCA computation. I would like the authors to answer the following questions:
* Can you provide more details on the layer sizes and learning rates used in the experiments?
* How does the choice of α affect the performance of the model, and what is the optimal value for α?
* Have you considered applying the proposed differentiable CCA layer to other multi-modality tasks, such as speech-based emotion recognition or multi-modal sentiment analysis?