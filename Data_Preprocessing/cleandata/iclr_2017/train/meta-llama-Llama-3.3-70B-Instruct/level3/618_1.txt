Summary
The paper proposes a novel approach to convolutional neural networks (CNNs) by introducing the concept of frames, which are a generalization of orthogonal bases. The authors argue that using frames as a basis for representing signals can lead to increased expressiveness and improved performance in CNNs. They also propose a new architecture, called Dynamic Steerable Frame Networks (DSFNs), which combines the advantages of steerable function spaces with the power of neural network function estimators. The DSFNs are shown to outperform traditional CNNs and other state-of-the-art methods in several experiments, including edge detection and video classification tasks.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper's practical value is questionable due to its reliance on assumptions about input image transformations, which may not constitute real challenges in practice. Secondly, the paper's experiments are limited to Cifar-10 and do not provide a strong argument for its contribution to the state of the art.
Supporting Arguments
The paper's contribution to the field of CNNs is significant, as it introduces a new perspective on signal representation and proposes a novel architecture that can learn to separate pose and feature learning. However, the paper's limitations, such as the lack of experiments on more challenging datasets and the absence of a discussion on the computational cost of the proposed method, undermine its practical value. Additionally, the paper's reliance on assumptions about input image transformations may not be realistic in many real-world applications.
Additional Feedback
To improve the paper, I suggest that the authors conduct more experiments on more challenging datasets, such as ImageNet or COCO, to demonstrate the effectiveness of their approach in more realistic settings. Additionally, the authors should provide a detailed discussion on the computational cost of their proposed method and compare it to other state-of-the-art methods. Finally, the authors should consider addressing the potential limitations of their approach, such as the assumption of input image transformations, and provide more insights into the applicability of their method in real-world applications.
Questions for the Authors
To clarify my understanding of the paper, I would like to ask the authors the following questions:
1. Can you provide more insights into the choice of frames used in your experiments, and how they were selected?
2. How do you plan to address the potential limitations of your approach, such as the assumption of input image transformations, in future work?
3. Can you provide more details on the computational cost of your proposed method, and how it compares to other state-of-the-art methods?