Summary
The paper introduces a novel approach to neural machine translation by experimenting with various vocabulary selection techniques to improve decoding and training efficiency. The authors investigate multiple selection methods, including word co-occurrences, bilingual embeddings, word alignments, phrase pairs, and Support Vector Machines, and analyze their impact on speed and accuracy. The results show that decoding time can be reduced by up to 90% without compromising accuracy, and training time can be improved by up to 25% with a bi-directional LSTM encoder.
Decision
I decide to Accept this paper, with the primary reason being the innovative approach to improving neural machine translation efficiency. The paper presents a comprehensive analysis of various vocabulary selection techniques, providing valuable insights into their strengths and weaknesses.
Supporting Arguments
The paper is well-motivated, and the authors provide a clear overview of the problem and the proposed solution. The experimental setup is thorough, and the results are convincing, demonstrating significant improvements in decoding and training efficiency. The use of multiple selection methods and the analysis of their impact on speed and accuracy add to the paper's strengths.
Additional Feedback
To further improve the paper, I suggest the authors provide more detailed analysis of the computational costs associated with each selection method and their impact on the overall efficiency of the system. Additionally, it would be interesting to see more extensive experiments on other language pairs and datasets to confirm the generalizability of the results.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. How do the authors plan to address the potential issue of overfitting when using smaller vocabulary sizes during training?
2. Can the authors provide more details on the computational resources used for the experiments and how they affected the results?
3. How do the authors envision the proposed approach being integrated into existing neural machine translation systems, and what potential challenges do they foresee?