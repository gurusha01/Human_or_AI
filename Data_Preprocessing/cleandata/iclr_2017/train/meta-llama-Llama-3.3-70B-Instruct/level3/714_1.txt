Summary
This paper proposes a method for learning a low-dimensional state representation of a robot's head position from synthetic images using a neural network trained with "robotic priors". The authors implement a siamese network architecture and demonstrate the effectiveness of their approach through a preliminary experiment, achieving a 97.7% correlation between the learned representation and the ground truth.
Decision
I decide to reject this paper, primarily due to the lack of novelty in the approach and the limited experimental evaluation. The paper implements Jonschkowski & Brock's method without significant modifications or improvements, and the experiments are preliminary and do not provide a comprehensive comparison to prior methods.
Supporting Arguments
The paper's primary contribution is the experimental evaluation of the correlation between the learned state representation and the ideal state representation for a simple task. However, this evaluation is limited to a single task and does not provide a thorough comparison to other state representation learning methods, such as those proposed by Lange et al., Watter et al., and Finn et al. Furthermore, the related work section is incomplete, missing discussions of other relevant state representation learning methods.
Additional Feedback
To improve the paper, I suggest that the authors provide a more comprehensive comparison to prior methods, including a discussion of the advantages and limitations of their approach. Additionally, the authors should consider evaluating their method on more complex tasks and environments to demonstrate its scalability and robustness. The use of real images and more complex state representations, such as object positions in three dimensions, would also be a valuable extension of this work.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence for my assessment, I would like the authors to answer the following questions:
1. How do the authors plan to address the limitation of their approach in terms of assessing the training quality, particularly in situations where ground truth is unavailable?
2. Can the authors provide more details on the experimental setup and the hyperparameters used for training the neural network?
3. How do the authors envision their approach being used in more complex scenarios, such as learning state representations for multiple objects or tasks?