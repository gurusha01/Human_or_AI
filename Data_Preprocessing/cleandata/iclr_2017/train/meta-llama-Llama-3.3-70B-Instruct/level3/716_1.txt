Summary
The paper proposes a novel deep neural network architecture called ENet, designed for real-time pixel-wise semantic segmentation on mobile devices. ENet achieves comparable performance to state-of-the-art models like SegNet while being 10x faster and using 10x less memory. The authors attribute this efficiency to their carefully designed encoder-decoder architecture, which uses techniques like dilated convolutions, factorizing filters, and spatial dropout.
Decision
I decide to reject this paper, primarily due to the lack of detailed experimental results and limited evidence to support the design rationale. While the paper presents an impressive architecture, the experimental evaluation is limited, and the comparison to the baseline model, SegNet, is not comprehensive.
Supporting Arguments
The paper's quality is limited by its focus on speed over quality, using a weak baseline, and lacking experimental evidence to support its claims. The model description section is unclear and concise, making it difficult to understand the architecture's details. Additionally, the paper's originality is limited, as it is a compendium of existing techniques applied to a specific task, rather than a novel contribution. The significance of the work is also limited by its focus on speed over quality, and the lack of a trade-off curve showing the relationship between speed and quality.
Additional Feedback
To improve the paper, I suggest the authors provide more detailed experimental results, including a comprehensive comparison to state-of-the-art models, and a thorough analysis of the trade-offs between speed and quality. The authors should also consider adding more visualizations and illustrations to help understand the architecture and its components. Furthermore, the authors should address the minor errors and areas for improvement, such as unclear sentence constructions, missing details, and inconsistent terminology.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
1. Can you provide more detailed experimental results, including a comprehensive comparison to state-of-the-art models, and a thorough analysis of the trade-offs between speed and quality?
2. How did you select the hyperparameters for the ENet architecture, and what is the sensitivity of the model to these hyperparameters?
3. Can you provide more visualizations and illustrations to help understand the architecture and its components, such as the bottleneck modules and the decoder?
4. How do you plan to address the limitations of the current implementation, such as the increased number of kernel calls and the overhead of data movement?