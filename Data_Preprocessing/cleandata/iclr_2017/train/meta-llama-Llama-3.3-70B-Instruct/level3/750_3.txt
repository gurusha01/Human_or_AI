Summary
The paper proposes a novel method for finding dependent subspaces across multiple views, preserving neighborhood relationships of data. The method directly maximizes the between-view similarity of neighborhoods of data samples, a natural measure for similarity of data relationships among the views. The authors demonstrate the effectiveness of their method on various datasets, including artificial and real-world data, and show that it outperforms existing methods such as CCA and LPCCA.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper seems to have two unrelated stories: the feature penalty as a soft batch norm version and low-shot learning, with unclear reasoning for its specific adaptation to low-shot learning. Secondly, the results on Omniglot are 2% worse than the Matching Networks, and the feature penalty performance is also worse than Batch Norm, with better results when both are combined.
Supporting Arguments
The paper lacks convincing results, particularly on Omniglot where it is significantly far from the current state of the art. The new experiments do not confirm or infirm the relationship with Batch Norm, and the added explanation for why feature penalty works for low-shot setting is basic and lacks depth. Furthermore, the paper does not provide a clear motivation for the approach, and the connection to Batch Norm and weight decay is not well-established.
Additional Feedback
To improve the paper, the authors should provide more convincing results, particularly on benchmark datasets such as Omniglot. They should also clarify the relationship between the feature penalty and Batch Norm, and provide a more detailed explanation for why the feature penalty works for low-shot learning. Additionally, the authors should consider providing more background information on the motivation for the approach and its connection to existing methods.
Questions for the Authors
I would like the authors to answer the following questions to clarify my understanding of the paper:
1. Can you provide more details on the motivation for the feature penalty approach and its connection to Batch Norm and weight decay?
2. How do you explain the poor performance of the feature penalty on Omniglot compared to Matching Networks?
3. Can you provide more experiments to confirm or infirm the relationship between the feature penalty and Batch Norm?
4. How do you plan to address the lack of convincing results and provide more robust evidence for the effectiveness of the feature penalty approach?