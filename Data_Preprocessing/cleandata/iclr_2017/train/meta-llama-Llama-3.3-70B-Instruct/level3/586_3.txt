Summary of the Paper's Contributions
The paper explores the limitations of Neural GPU models by examining their training strategies and investigating the error surface of deep models. The authors provide a well-written and investigative analysis, highlighting the importance of initialization, data structure, and model architecture in determining the learning dynamics of neural networks. The paper presents several theoretical examples and empirical results that demonstrate the existence of bad local minima in the error surface of rectified neural networks, even when the dataset is linearly separable.
Decision to Reject
Based on the evaluation of the paper, I decide to reject it with two key reasons: (1) the title of the paper is misleading, as it does not accurately reflect the content of the paper, and (2) the paper lacks comparisons to similar architectures and limited experiments, which makes it difficult to fully understand the implications of the results.
Supporting Arguments
The paper's analysis of the error surface of deep models is well-motivated and provides valuable insights into the limitations of Neural GPU models. However, the paper's title is misleading, as it suggests that the paper provides a general theory for the error surface of deep models, when in fact it only presents specific examples and counterexamples. Additionally, the paper's experiments are limited to a specific dataset and model architecture, which makes it difficult to generalize the results to other settings.
Additional Feedback
To improve the paper, I suggest that the authors provide more experiments on various tasks and datasets to demonstrate the robustness of their results. Additionally, a deeper analysis of the model's failures and a more detailed comparison to similar architectures would be beneficial. The authors should also consider providing more context and background information on the related work in the field, as well as a clearer explanation of the implications of their results.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on how the initialization scheme was chosen, and how it affects the learning dynamics of the model?
2. How do the results of the paper relate to other work on the error surface of deep models, and what are the implications of the paper's findings for the design of neural network architectures?
3. Can you provide more experiments or simulations to demonstrate the robustness of the results to different datasets, model architectures, and initialization schemes?