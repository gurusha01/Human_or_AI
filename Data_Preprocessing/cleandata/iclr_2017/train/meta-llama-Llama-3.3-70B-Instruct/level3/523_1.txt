This paper proposes a novel approach to generating transferable adversarial examples, which can successfully attack black-box image classification systems. The authors conduct an extensive study of the transferability of both non-targeted and targeted adversarial examples over large models and a large-scale dataset, and their results confirm that non-targeted adversarial examples can transfer well, while targeted adversarial examples are harder to generate.
The authors propose an ensemble-based approach to generate transferable targeted adversarial examples, which exhibits better performance than previous work. They also demonstrate that their approach can generate non-targeted transferable adversarial examples with high success rates. Furthermore, they show that both non-targeted and targeted adversarial examples generated using their approach can successfully attack Clarifai.com, a black-box image classification system.
I decide to accept this paper because it tackles a specific and important problem in the field of deep learning, and the approach is well-motivated and well-placed in the literature. The paper supports its claims with thorough experiments and analysis, and the results are scientifically rigorous.
The paper's presentation is clear, and the underlying concepts are well-explained. However, there are some minor typos and notation inconsistencies that need to be addressed. Additionally, the complexity analysis in Section 4.2 could be improved with additional figures and explanatory sentences to make the logic easier to follow.
To improve the paper, I suggest that the authors provide more details on the geometric properties of the models and how they relate to the transferability of adversarial examples. Additionally, it would be interesting to see more examples of targeted adversarial examples that can successfully attack Clarifai.com.
I would like the authors to answer the following questions to clarify my understanding of the paper: (1) Can you provide more intuition on why the ensemble-based approach is effective in generating transferable targeted adversarial examples? (2) How do you plan to extend this work to other types of deep learning models and applications? (3) Can you provide more details on the computational resources required to generate the adversarial examples using the ensemble-based approach?