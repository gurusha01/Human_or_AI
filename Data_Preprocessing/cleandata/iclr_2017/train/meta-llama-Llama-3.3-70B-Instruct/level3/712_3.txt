Summary
The paper proposes a novel extension of Stochastic Gradient Variational Bayes (SGVB) to perform posterior inference for the weights of Stick-Breaking processes, allowing for the definition of a Stick-Breaking Variational Autoencoder (SB-VAE). The SB-VAE is a Bayesian nonparametric version of the variational autoencoder with a latent representation of stochastic dimensionality. The authors experimentally demonstrate that the SB-VAE and its semi-supervised variant learn highly discriminative latent representations that often outperform the Gaussian VAE's.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper's novelty is questionable due to the RNN-VAE combination being around for over a year with no significant proposed changes. Secondly, the paper may be more suitable for an application-targeting conference rather than ICLR due to its focus on great performances and interesting applications.
Supporting Arguments
The paper's contribution is mainly an extension of existing work, and the authors do not provide sufficient evidence to demonstrate the significance of their proposed changes. Additionally, the paper's focus on applications and performance may not align with the theoretical and methodological focus of ICLR. The authors do provide some experimental results demonstrating the effectiveness of their approach, but these results are not sufficient to overcome the concerns about novelty and relevance to the conference.
Additional Feedback
To improve the paper, the authors could provide more detailed comparisons with existing work, highlighting the specific contributions and advantages of their approach. They could also consider providing more theoretical analysis or justification for their proposed method, to demonstrate its validity and relevance to the broader research community. Furthermore, the authors could consider revising their paper to better align with the focus and scope of ICLR, by emphasizing the theoretical and methodological aspects of their work.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
1. Can you provide more detailed comparisons with existing work on variational autoencoders and Bayesian nonparametric models, highlighting the specific contributions and advantages of your approach?
2. How do you respond to concerns that your paper may be more suitable for an application-targeting conference, given its focus on performance and applications?
3. Can you provide more theoretical analysis or justification for your proposed method, to demonstrate its validity and relevance to the broader research community?