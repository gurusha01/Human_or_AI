Summary
The paper proposes a novel approach for transfer reinforcement learning, introducing the "A2T" learning algorithm, which combines existing solutions with a new solution to tackle a novel task. The algorithm allocates more weights to relevant solutions, demonstrating its ability to accelerate learning speed. The experiments, conducted on synthetic Chain World and Puddle World simulation and Atari 2600 game Pong, showcase the method's effectiveness.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the algorithm's overall performance is not better than the solo base network, and it would be more convincing to show examples where existing solutions are complementary to the base network. Secondly, the paper does not study the algorithm's ability to automatically determine if existing solutions are sufficient to solve the novel task, as most experiments use a learning-from-scratch solution as the base network.
Supporting Arguments
The paper's approach is well-motivated, and the experiments are cleverly designed to demonstrate the method's ability. However, the lack of comparison with other state-of-the-art methods and the limited analysis of the algorithm's performance in different scenarios are notable weaknesses. Additionally, the paper could benefit from a more detailed analysis of the algorithm's ability to handle complex tasks and its potential applications in real-world scenarios.
Additional Feedback
To improve the paper, I suggest the authors provide more comprehensive experiments, including comparisons with other state-of-the-art methods and analysis of the algorithm's performance in different scenarios. Additionally, the authors could explore the application of the A2T algorithm in more complex tasks and real-world scenarios, demonstrating its potential impact and usefulness. It would also be beneficial to investigate the algorithm's ability to automatically determine if existing solutions are sufficient to solve the novel task, and to provide more insights into the algorithm's behavior and limitations.
Questions for the Authors
I would like the authors to clarify the following points:
1. How does the A2T algorithm handle cases where the existing solutions are not relevant to the novel task?
2. Can the authors provide more details on the implementation of the A2T algorithm, including the specific architectures and hyperparameters used?
3. How does the algorithm's performance change when using different base networks or existing solutions?
4. Are there any plans to explore the application of the A2T algorithm in more complex tasks or real-world scenarios?