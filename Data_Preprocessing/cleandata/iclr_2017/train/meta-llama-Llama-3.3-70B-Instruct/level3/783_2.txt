Summary of the Paper's Contributions
The paper proposes a novel approach to learning bilingual word vectors offline, leveraging the concept of orthogonal transformations to align vector spaces. The authors demonstrate that their method, which utilizes the singular value decomposition (SVD) to obtain an orthogonal transformation, outperforms existing approaches in translating words between languages. They also introduce an "inverted softmax" technique to improve the accuracy of translation predictions. The paper's key contributions include: (1) proving that the optimal linear transformation between word vector spaces should be orthogonal, (2) demonstrating the effectiveness of the SVD in obtaining bilingual word vectors, and (3) showcasing the robustness of orthogonal transformations in learning bilingual vector spaces without expert bilingual signals.
Decision and Key Reasons
Based on the paper's contributions and the evaluation criteria, I decide to Accept this paper. The two key reasons for this decision are: (1) the paper's well-motivated approach to learning bilingual word vectors offline, which addresses a significant problem in natural language processing, and (2) the thorough experimental evaluation, which demonstrates the effectiveness of the proposed method in various settings, including the use of expert training dictionaries and pseudo-dictionaries.
Supporting Arguments
The paper provides a clear and well-structured presentation of the proposed approach, including a thorough review of related work and a detailed explanation of the orthogonal transformation technique. The experimental evaluation is comprehensive, covering various scenarios, including the use of different dictionaries and languages. The results demonstrate the superiority of the proposed method over existing approaches, including Mikolov's linear mapping and CCA. The paper also provides additional insights into the robustness of orthogonal transformations and their potential applications in learning bilingual vector spaces without expert bilingual signals.
Additional Feedback and Questions
To further improve the paper, I suggest that the authors consider the following: (1) provide more detailed analysis of the computational complexity of the proposed method, particularly in comparison to existing approaches, and (2) explore the potential applications of the proposed method in other NLP tasks, such as machine translation and language modeling. Some questions that I would like the authors to address include: (1) How does the proposed method handle out-of-vocabulary words, and (2) Can the authors provide more insights into the choice of hyperparameters, such as the dimensionality of the word vectors and the number of iterations for the SVD?