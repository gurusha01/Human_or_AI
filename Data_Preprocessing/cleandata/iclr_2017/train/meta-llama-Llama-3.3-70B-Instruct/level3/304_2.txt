Summary
The paper proposes a novel hardware accelerator, Tartan (TRT), for inference with Deep Neural Networks (DNNs). TRT exploits the variable precision requirements of DNNs to deliver execution time proportional to the precision used per layer for convolutional and fully-connected layers. The authors demonstrate TRT's performance, energy efficiency, and area overhead compared to the state-of-the-art DaDianNao (DaDN) accelerator. TRT enables trading off accuracy for additional improvements in execution performance and energy efficiency.
Decision
I decide to Accept this paper with two key reasons: (1) the paper proposes a well-motivated approach to enhance Neural Programming Interpreters by incorporating recursion, allowing for better generalization from fewer execution traces, and (2) the paper provides a thorough evaluation of TRT's performance, energy efficiency, and area overhead compared to DaDN.
Supporting Arguments
The paper is well-structured and easy to read, with consistent notation used throughout. The authors provide a clear explanation of the TRT design, including the bit-serial processing of activations and weights, and the cascading of adder trees to enable slicing the output computation. The evaluation results show that TRT outperforms DaDN in terms of execution time and energy efficiency, while requiring no network retraining. The authors also discuss the limitations of their work, including the assumption that each layer fits on-chip and the need for further research on applying TRT to other network architectures and machine learning algorithms.
Additional Feedback
To improve the paper, I suggest that the authors provide more details on the potential release of the source code for the proposed TRT approach. This would enable other researchers to reproduce the results and build upon the work. Additionally, the authors may want to consider exploring the application of TRT to other machine learning algorithms and network architectures, as well as investigating the interaction between TRT and other techniques such as quantization, pruning, and compression.
Questions for the Authors
I would like to ask the authors to clarify the following points:
* How do the authors plan to make the TRT source code available to the research community?
* What are the potential applications of TRT beyond image classification networks, and how do the authors plan to explore these applications in future work?
* How does TRT interact with other techniques such as quantization, pruning, and compression, and are there any potential synergies between these techniques?