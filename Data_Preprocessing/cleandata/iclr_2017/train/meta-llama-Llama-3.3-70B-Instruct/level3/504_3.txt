The paper proposes a novel approach to network morphism, which enables the transformation of a convolutional layer into an arbitrary module of a neural network. The authors introduce a graph-based representation for modules, allowing the network morphism process to be formulated as a graph transformation problem. Two atomic morphing operations are defined, and a large family of modules, called simple morphable modules, can be transformed using these operations. The authors also propose an algorithm for complex modules, which reduces them to irreducible modules and solves the modular network morphism equation.
The paper is well-written and clearly explains the concepts, making it easy to follow. The experimental results demonstrate the effectiveness of the proposed approach, showing significant performance improvements over the original ResNet on benchmark datasets such as CIFAR10, CIFAR100, and ImageNet.
However, there are some issues that need to be addressed to strengthen the paper. The use of a simple controller in the experiments may introduce bias, and it would be beneficial to add an experiment to test the approach with other RL methods. Additionally, the paper lacks theoretical advances, making the empirical evaluation crucial to its validity. The approach can be seen as computing quadratic distances to features of pre-extracted "key-frames", and the connection to standard IRL approaches is nice but not strictly necessary.
To improve the paper, I suggest adding two baselines to the experiments: one without feature selection and another using all frames of the recorded trajectories. This would help to better understand the contribution of the proposed approach. Furthermore, the paper could benefit from a more detailed analysis of the results, including a discussion of the limitations and potential applications of the proposed method.
In terms of the conference guidelines, I would answer the three key questions as follows:
1. The specific question/problem tackled by the paper is: Can a convolutional layer be morphed into an arbitrary module of a neural network?
2. The approach is well-motivated, including being well-placed in the literature, as it builds upon existing work on network morphism and modularized network architectures.
3. The paper supports its claims through extensive experiments on benchmark datasets, demonstrating the effectiveness of the proposed approach.
Based on these answers, I would decide to accept the paper, with the condition that the authors address the issues mentioned above and provide additional experiments and analysis to strengthen the paper.
Some questions I would like the authors to answer to clarify my understanding of the paper include:
* How do the authors plan to extend the proposed approach to more complex modules and larger neural networks?
* Can the authors provide more insights into the computational cost and memory requirements of the proposed approach?
* How do the authors think the proposed approach could be applied to other domains, such as natural language processing or robotics?