This paper explores the optimization of neural networks for variational approximations of the information bottleneck, which has potential applications in regularization, adversarial robustness, and privacy. The authors propose a method called Deep Variational Information Bottleneck (Deep VIB) that uses a neural network to parameterize the information bottleneck model and leverages the reparameterization trick for efficient training.
The paper claims to contribute to the field by providing a novel approach to learning representations that are maximally informative about the target variable while being maximally compressive about the input data. The authors demonstrate the effectiveness of their approach through experiments on the MNIST and ImageNet datasets, showing that models trained with the VIB objective outperform those trained with other forms of regularization in terms of generalization performance and robustness to adversarial attacks.
However, I have some concerns about the paper. Firstly, the theoretical contribution is a straightforward application of well-known ideas, and I would have liked to see a stronger experimental section to demonstrate the approach's effectiveness. The experimental section is limited by using only the MNIST dataset, and I suggest testing on larger problems to demonstrate scalability. Additionally, I question the absence of dropout in the quantitative comparison of robustness to adversarial examples and seek clarification on certain experimental design choices.
Furthermore, the paper lacks comparison to other relevant methods, such as variational fair autoencoders, which also aim to learn representations that minimize information sharing. I also note some technical issues, including inconsistent figure scaling and potential errors in the text, such as the claim about the posterior covariance.
To improve the paper, I suggest the authors provide more detailed comparisons to other relevant methods, clarify their experimental design choices, and address the technical issues mentioned above. Additionally, I would like to see more extensive experiments on larger datasets to demonstrate the scalability and effectiveness of the Deep VIB approach.
To answer the three key questions for myself:
1. What is the specific question/problem tackled by the paper? The paper tackles the problem of learning representations that are maximally informative about the target variable while being maximally compressive about the input data.
2. Is the approach well motivated, including being well-placed in the literature? The approach is well-motivated, but I would have liked to see more detailed comparisons to other relevant methods.
3. Does the paper support the claims? The paper provides some evidence to support the claims, but I have some concerns about the experimental section and suggest more extensive experiments to demonstrate the effectiveness of the approach.
Based on these questions, I would reject the paper in its current form, but I believe that with revisions to address the concerns mentioned above, the paper has the potential to make a significant contribution to the field.
I would like the authors to answer the following questions to clarify my understanding of the paper:
* Can you provide more detailed comparisons to other relevant methods, such as variational fair autoencoders?
* Can you clarify your experimental design choices, including the absence of dropout in the quantitative comparison of robustness to adversarial examples?
* Can you address the technical issues mentioned above, including inconsistent figure scaling and potential errors in the text?