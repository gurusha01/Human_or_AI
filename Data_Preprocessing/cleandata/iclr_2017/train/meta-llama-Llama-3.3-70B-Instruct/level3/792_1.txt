This paper introduces a novel approach to simulating action-conditional dynamics in various environments, including Atari games, 3D car racing, and mazes. The authors propose a recurrent neural network architecture that can make temporally and spatially coherent predictions for hundreds of time-steps into the future. The paper provides an in-depth analysis of the factors affecting performance and presents state-of-the-art results on Atari.
The specific question tackled by the paper is how to simulate action-conditional dynamics in complex environments. The approach is well-motivated, building on existing work in the field, and the authors provide a clear explanation of their methodology. The paper supports its claims with extensive experimental results, demonstrating the effectiveness of the proposed approach in various environments.
However, I have some concerns regarding the novelty of the approach. The paper bears a strong resemblance to existing work, particularly the method proposed by Hinton et al. in 2016. While the authors provide some new insights and improvements, it is unclear whether the approach is sufficiently novel for publication in a top conference like ICLR.
Furthermore, the paper has some weak baselines, and the authors may not have found the optimal hyper-parameters for their experiments. For example, a simple 5-layer MNIST model achieves higher accuracy without regularizers, which raises questions about the effectiveness of the proposed approach.
To improve the paper, I would suggest that the authors provide more detailed comparisons with existing work, highlighting the key differences and advantages of their approach. Additionally, they should consider using more robust baselines and performing a more thorough hyper-parameter search to ensure that their results are optimal.
Some questions I would like the authors to answer to clarify my understanding of the paper include:
* Can you provide more details on how your approach differs from existing work, particularly the method proposed by Hinton et al. in 2016?
* How did you select the hyper-parameters for your experiments, and did you perform a thorough search to ensure that your results are optimal?
* Can you provide more information on the computational resources required to train and evaluate your models, and how this might impact the scalability of your approach?
Overall, while the paper presents some interesting results and insights, I have some concerns regarding its novelty and the effectiveness of the proposed approach. With some revisions to address these concerns, the paper could be stronger and more suitable for publication in a top conference. Based on the current version, I would recommend rejecting the paper.