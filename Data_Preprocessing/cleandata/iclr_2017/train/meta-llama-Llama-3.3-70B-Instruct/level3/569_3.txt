Summary of the Paper's Contributions
The paper presents a novel approach to detecting misclassified or out-of-distribution examples by utilizing probabilities from softmax distributions. The authors demonstrate that correctly classified examples tend to have higher maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. They assess the performance of this baseline across various tasks in computer vision, natural language processing, and automatic speech recognition, showing its effectiveness.
Decision and Key Reasons
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper lacks experimental results on the LFW dataset, which is mentioned but not utilized to demonstrate the method's effectiveness. Secondly, the experiments on the Omniglot dataset are insufficient and require additional illustrations, such as attendance trajectories, to provide a clearer understanding of the model's functionality.
Supporting Arguments
The paper's idea of using softmax probabilities to detect misclassified or out-of-distribution examples is interesting, but its presentation is marred by poor writing and incomplete references. The authors fail to provide a comprehensive evaluation of their method, particularly on the LFW dataset, which is a significant omission. Furthermore, the experiments on the Omniglot dataset are limited, and the authors do not provide sufficient visualizations to support their claims.
Additional Feedback
To improve the paper, I suggest that the authors provide more comprehensive experimental results, including evaluations on the LFW dataset and additional visualizations for the Omniglot dataset. They should also improve the writing and referencing to make the paper more readable and credible. Additionally, the authors could consider providing more detailed analysis of the results, including discussions of the limitations and potential applications of their method.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
1. Can you provide more details on why the LFW dataset was not used to evaluate the method's effectiveness?
2. How do you plan to address the limitations of the experiments on the Omniglot dataset, and what additional visualizations or analyses can you provide to support your claims?
3. Can you provide more comprehensive evaluations of the method's performance, including comparisons to other state-of-the-art approaches?