This paper presents a novel approach to enriching medical concepts with their parent nodes in an ontology using an attention mechanism. The proposed model, called Layer-RNN (L-RNN), combines traditional convolutional layers with recurrent neural network (RNN) modules to learn long-range dependencies at multiple levels. The authors demonstrate the effectiveness of their approach on two tasks: predicting diagnosis categories and predicting heart failure likelihood.
The paper is well-motivated, and the authors provide a clear explanation of the background and related work. The proposed L-RNN module is a significant contribution, as it allows for the incorporation of multi-level contextual information into the model. The experimental evaluation is thorough, and the results show that the L-RNN module can improve the performance of pre-trained networks on both tasks.
However, I have some concerns regarding the learning of concept representations in the ontology. The authors use a naive approach to learn these representations, which may not be sufficient to capture the complex relationships between medical concepts. I suggest exploring alternative approaches, such as knowledge base factorization or graph convolutional methods, to improve the learning of concept representations.
Additionally, I question the decision to fine-tune leaf node representations while not adjusting inner node representations. This may lead to inconsistent representations across the ontology, which could negatively impact the performance of the model. I recommend exploring alternative strategies for fine-tuning the representations, such as jointly optimizing the leaf and inner node representations.
The presentation of the paper is clear, but there are some minor issues with formatting, particularly in Figure 2. I suggest using the same image format and resolution throughout the paper to improve readability.
To answer the three key questions:
1. The specific question/problem tackled by the paper is how to effectively incorporate multi-level contextual information into a neural network model for medical concept representation and prediction tasks.
2. The approach is well-motivated, and the authors provide a clear explanation of the background and related work. However, I have some concerns regarding the learning of concept representations in the ontology.
3. The paper supports its claims with thorough experimental evaluations, but I suggest exploring alternative approaches to improve the learning of concept representations and fine-tuning the representations.
Additional feedback:
* The authors may want to consider exploring the application of their approach to other domains, such as natural language processing or computer vision, to demonstrate its generalizability.
* The use of attention mechanisms and RNNs is well-established in the literature, but the authors may want to consider exploring other architectures, such as transformers or graph neural networks, to improve the performance of their model.
* The paper could benefit from a more detailed analysis of the results, including an exploration of the strengths and weaknesses of the L-RNN module and its potential applications in real-world scenarios.
Questions for the authors:
* Can you provide more details on the ontology used in the experiments and how the concept representations were learned?
* How did you determine the optimal number of RNN modules and their placement in the network?
* Have you explored the use of other architectures, such as transformers or graph neural networks, for medical concept representation and prediction tasks?