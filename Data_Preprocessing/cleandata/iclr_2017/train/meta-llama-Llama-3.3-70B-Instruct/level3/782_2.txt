Summary of the Paper's Contributions
The paper proposes a novel approach to pruning convolutional neural networks (CNNs) by iteratively removing the least important feature maps based on a Taylor expansion-based criterion. The authors demonstrate that their approach outperforms other pruning criteria, including the popular Optimal Brain Damage (OBD) method, and achieves significant reductions in computational cost while maintaining good generalization performance.
Decision to Accept or Reject
Based on the provided guidelines, I decide to Accept this paper. The main reasons for this decision are:
1. The paper tackles a specific and relevant problem in the field of deep learning, namely, reducing the computational cost of CNNs while maintaining their accuracy.
2. The approach proposed by the authors is well-motivated and grounded in theoretical foundations, making it a valuable contribution to the field.
Supporting Arguments
The paper provides a thorough analysis of the proposed Taylor expansion-based criterion, including its relation to other pruning methods, such as OBD. The authors also provide extensive experimental results on various datasets, including ImageNet, Birds-200, and Flowers-102, demonstrating the effectiveness of their approach. Additionally, the paper discusses the importance of per-layer normalization and the use of FLOPs regularization to guide the pruning process.
Additional Feedback
To further improve the paper, I suggest that the authors:
1. Provide more detailed analysis of the computational cost and memory requirements of their approach, particularly in comparison to other pruning methods.
2. Investigate the applicability of their approach to other types of neural networks, such as recurrent neural networks (RNNs) and transformers.
3. Consider providing more visualizations and illustrations to help readers understand the pruning process and the effects of different criteria on the network's architecture.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. How do the authors plan to extend their approach to handle more complex pruning scenarios, such as pruning entire layers or groups of layers?
2. Can the authors provide more insights into the relationship between the Taylor expansion-based criterion and other pruning methods, such as OBD and gradient-based methods?
3. How do the authors envision their approach being used in practice, particularly in resource-constrained environments, such as embedded devices or mobile applications?