Summary of the Paper's Claims and Contributions
The authors propose a novel method for pruning convolutional neural networks (CNNs) to enable efficient inference. They interleave greedy criteria-based pruning with fine-tuning by backpropagation, which maintains good generalization in the pruned network. The authors introduce a new criterion based on Taylor expansion that approximates the change in the cost function induced by pruning network parameters. They demonstrate superior performance compared to other criteria, such as the norm of kernel weights or feature map activation, for pruning large CNNs after adaptation to fine-grained classification tasks.
Decision and Key Reasons
I decide to reject this paper, with two key reasons:
1. Lack of clarity and standard notation: The paper's notation is nonstandard and unclear, particularly with regards to the definitions of various criteria and the Taylor expansion-based criterion. This lack of clarity makes it difficult to understand and evaluate the proposed method.
2. Insufficient comparison to existing methods: The paper does not provide a thorough comparison to existing pruning methods, such as Optimal Brain Damage (OBD) and other regularization-based techniques. While the authors mention OBD, they do not provide a detailed analysis of the differences between their approach and OBD.
Supporting Arguments
The paper's proposed method is based on a Taylor expansion-based criterion, which is not clearly explained and may not be novel. The authors claim that their method is faster and more efficient than OBD, but they do not provide a detailed comparison of the computational costs and accuracy of the two methods. Additionally, the paper's experimental results are not convincing, as the authors only demonstrate the effectiveness of their method on a few datasets and do not provide a thorough analysis of the results.
Additional Feedback and Questions
To improve the paper, I suggest that the authors:
* Clarify the notation and provide a detailed explanation of the Taylor expansion-based criterion.
* Provide a thorough comparison to existing pruning methods, including OBD and other regularization-based techniques.
* Conduct more extensive experiments to demonstrate the effectiveness of their method on a variety of datasets and tasks.
* Address the following questions:
	+ How does the proposed method handle the dependencies between parameters in the network?
	+ How does the method scale to larger networks and more complex tasks?
	+ What are the limitations of the proposed method, and how can they be addressed in future work?