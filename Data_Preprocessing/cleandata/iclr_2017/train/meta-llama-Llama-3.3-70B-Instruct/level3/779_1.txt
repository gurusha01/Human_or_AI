Summary of the Paper's Contributions
The paper explores various vocabulary selection strategies to reduce computational costs in neural machine translation, investigating techniques from simple word co-occurrences to complex SVMs. The authors experiment with context and embedding-based selection methods, extending previous work by examining speed and accuracy trade-offs in more detail. They demonstrate that decoding time on CPUs can be reduced by up to 90% and training time by 25% on the WMT15 English-German and WMT16 English-Romanian tasks at the same or only negligible change in accuracy.
Decision and Key Reasons
I decide to reject this paper, with the primary reason being the lack of novelty in the proposed approaches. The paper relies on standard and simple techniques, with little originality beyond existing work, such as Mi et al. (2016). Additionally, the experiments conducted, although comprehensive, are limited in scope, particularly in section 4.3 on vocabulary selection during training.
Supporting Arguments
The paper's contributions, while useful, do not significantly advance the state-of-the-art in neural machine translation. The authors' experiments demonstrate the effectiveness of vocabulary selection techniques, but the results are not surprising, and the methods used are not particularly innovative. Furthermore, the paper raises minor questions, such as whether smoothing was used to make the word co-occurrence measure more robust to low counts in section 2.1, which suggests that the authors may not have fully considered the limitations of their approaches.
Additional Feedback and Questions
To improve the paper, I suggest that the authors consider more innovative and original approaches to vocabulary selection, such as exploring new techniques for selecting target words or incorporating additional context information. I would also like the authors to clarify the following points:
* How did the authors determine the optimal vocabulary size for each selection method?
* What is the impact of using different encoder architectures on the efficiency gains of vocabulary selection?
* Can the authors provide more detailed analysis of the results in section 4.3, particularly with regards to the effect of vocabulary selection on training speed and accuracy?