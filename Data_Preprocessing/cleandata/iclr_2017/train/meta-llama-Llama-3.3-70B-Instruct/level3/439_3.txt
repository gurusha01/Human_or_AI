Summary
The paper proposes a novel approach to generating programs by training a neural network to estimate a fixed set of attributes that condition a search procedure. This approach is motivated by the complexity of building a generative model of programs. The authors introduce a multiplicative LSTM (mLSTM) architecture, which combines the strengths of LSTM and multiplicative RNNs to achieve faster computation times and improved performance on character-level language modeling tasks.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the approach, although well-motivated, lacks a thorough analysis of the results, including the types of programs that are difficult, the frequency of neural network errors, and the failure modes of the proposed method. Secondly, the paper's metric of time to find a single program may not be sufficient, and experiments showing the approach's effectiveness in finding the best program or a rank list of programs would be more useful.
Supporting Arguments
The paper's approach is well-motivated, and the introduction of mLSTM is a significant contribution. However, the lack of analysis of the results and the limited evaluation metric are significant concerns. The paper's experiments show promising results, but they are limited to small programs, and the scalability of the approach to larger programs is uncertain. Additionally, the use of average pooling to combine input-output pair representations is questionable, and alternative methods such as combining predictions at the decoder may be more effective.
Additional Feedback
To improve the paper, I suggest that the authors provide a more thorough analysis of the results, including the types of programs that are difficult, the frequency of neural network errors, and the failure modes of the proposed method. Additionally, the authors should consider using more comprehensive evaluation metrics, such as finding the best program or a rank list of programs. The authors should also explore alternative methods for combining input-output pair representations and investigate the scalability of the approach to larger programs.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
1. Can you provide more details on the types of programs that are difficult for the proposed approach?
2. How do you plan to address the scalability of the approach to larger programs?
3. Can you provide more comprehensive evaluation metrics, such as finding the best program or a rank list of programs?
4. Have you considered alternative methods for combining input-output pair representations, and if so, what are the results?