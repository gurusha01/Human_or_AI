This paper proposes a novel approach to incorporating prior procedural knowledge into neural networks by introducing a differentiable abstract machine for the Forth programming language, called ∂4. The authors demonstrate how ∂4 can be used to learn complex transduction tasks, such as sorting and addition, using only program sketches and input-output pairs as input.
The specific question tackled by the paper is how to effectively incorporate prior procedural knowledge into neural networks, which is a crucial problem in artificial intelligence. The approach is well-motivated, as it builds upon the idea of program synthesis and probabilistic programming languages. The authors provide a clear and detailed explanation of the ∂4 architecture and its components, including the differentiable Forth words, sketches, and execution RNN.
However, I decide to reject this paper due to two key reasons. Firstly, the paper lacks a thorough evaluation of the proposed approach, with only two tasks (sorting and addition) being considered. Additionally, the experimental design is flawed, as the authors do not provide a clear comparison with other state-of-the-art methods. Secondly, the connection between the decoder parameter matrix and latent variables is unclear, which raises concerns about the validity of the proposed approach.
To improve the paper, I suggest that the authors provide a more comprehensive evaluation of the proposed approach, including a comparison with other state-of-the-art methods. Additionally, the authors should clarify the connection between the decoder parameter matrix and latent variables, and provide more details on the experimental design and hyperparameter tuning.
Some questions I would like the authors to answer to clarify my understanding of the paper include: (1) How do the authors plan to extend the proposed approach to more complex tasks and domains? (2) Can the authors provide more details on the implementation of the differentiable Forth words and sketches? (3) How do the authors plan to address the issue of incongruencies between traditional language properties and the desire for neural networks to learn behaviors that generalize to unseen data? 
Overall, while the paper proposes an interesting and novel approach, it requires significant improvements in terms of evaluation, clarity, and experimental design to be considered for acceptance.