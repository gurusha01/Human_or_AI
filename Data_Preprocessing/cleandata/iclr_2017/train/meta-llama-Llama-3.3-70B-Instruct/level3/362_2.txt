Summary of the Paper's Contributions
The paper proposes a novel "density-diversity penalty" regularizer that can be applied to fully-connected layers of neural networks during training. This regularizer encourages low diversity and high sparsity in the weight matrices, resulting in highly compressible models without significant loss in performance. The authors demonstrate the effectiveness of their approach on two tasks, computer vision and speech recognition, achieving compression rates of up to 226X on fully-connected layers.
Decision and Key Reasons
Based on the review, I decide to Accept this paper. The key reasons for this decision are:
1. The paper tackles a specific and important problem in deep learning, namely reducing the memory and computational costs of neural networks.
2. The approach is well-motivated and placed in the literature, with a clear explanation of the density-diversity penalty and its relationship to existing methods.
Supporting Arguments
The paper provides a thorough explanation of the density-diversity penalty and its optimization using a "sorting trick". The authors also demonstrate the effectiveness of their approach on two tasks, with impressive compression rates and minimal loss in performance. The paper is well-organized and easy to follow, with clear explanations of the methodology and results.
Additional Feedback
To further improve the paper, I suggest avoiding certain words like "mantra" to enhance the text's clarity and professionalism. Additionally, the authors may want to consider addressing the criticism regarding "randomly generated tasks" and providing more evidence to support their claims. It would also be helpful to provide more details on the implementation and hyperparameter tuning for the density-diversity penalty.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
1. Can you provide more details on the implementation of the density-diversity penalty and the hyperparameter tuning process?
2. How do you plan to extend the density-diversity penalty to convolutional layers and recurrent models?
3. Can you provide more evidence to support the claim that the density-diversity penalty can discover underlying hidden patterns in data without prior knowledge of the structure?