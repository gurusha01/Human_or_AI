Summary
The paper proposes a novel approach to compensate for input/activation variance introduced by dropout in a network and presents a practical inference trick for re-estimating batch normalization parameters. The authors introduce a density-diversity penalty regularization that encourages low diversity and high sparsity in fully-connected layers of neural networks. This approach results in highly compressible weight matrices, allowing for significant reductions in memory and computational costs.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper lacks validation for considering backpropagation variance, which is a crucial aspect of neural network training. Secondly, the comparison to batch normalization is limited, and the paper does not fully explore the broader implications of the proposed approach.
Supporting Arguments
The paper presents an interesting approach to reducing the complexity of fully-connected layers in neural networks. However, the experimental validation is limited, and it is unclear how the proposed approach would perform on more complex tasks or larger datasets. Additionally, the paper does not provide a thorough analysis of the trade-offs between sparsity, diversity, and performance.
Additional Feedback
To improve the paper, I suggest that the authors provide more extensive experimental results, including comparisons to other state-of-the-art compression techniques. Additionally, the authors should consider exploring the application of the density-diversity penalty to other types of neural network layers, such as convolutional layers. It would also be helpful to provide more insight into the hyperparameter tuning process and the sensitivity of the approach to different hyperparameter settings.
Questions for the Authors
I would like the authors to clarify the following points:
1. How do the authors plan to address the issue of backpropagation variance in future work?
2. Can the authors provide more details on the computational cost of the sorting trick and how it scales with the size of the weight matrices?
3. How do the authors envision the density-diversity penalty being used in practice, and what are the potential applications of this approach beyond neural network compression?