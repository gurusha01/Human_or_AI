This paper proposes a novel optimization algorithm called Entropy-SGD for training deep neural networks. The authors claim that their approach can achieve better generalization error than traditional SGD by exploiting the local geometry of the energy landscape. The key idea is to use a local entropy-based objective function that favors wide valleys in the energy landscape, which are believed to generalize better.
The paper is well-executed and explained, with a clear motivation and a thorough analysis of the proposed algorithm. The authors provide a detailed derivation of the local entropy objective and its connection to the geometry of the energy landscape. They also present experimental results on several benchmark datasets, including MNIST, CIFAR-10, and PTB, which demonstrate the effectiveness of Entropy-SGD.
However, I have some concerns regarding the novelty and significance of the proposed approach. The idea of using entropy-based objectives to improve generalization is not new, and similar approaches have been proposed in the past. Additionally, the authors' claim that Entropy-SGD can achieve better generalization error than SGD is not entirely convincing, as the experimental results show only marginal improvements.
To answer the three key questions, I would say that:
1. The specific question/problem tackled by the paper is how to improve the generalization error of deep neural networks by exploiting the local geometry of the energy landscape.
2. The approach is well-motivated, but its novelty and significance are questionable.
3. The paper supports its claims with experimental results, but the improvements over traditional SGD are not substantial.
Based on these considerations, I would recommend rejecting the paper. However, I would like to see the authors address the following questions and concerns:
* How does Entropy-SGD differ from existing entropy-based approaches, and what are its unique advantages?
* Can the authors provide more convincing experimental results that demonstrate the superiority of Entropy-SGD over traditional SGD?
* How does the choice of hyperparameters, such as the scope Î³, affect the performance of Entropy-SGD, and are there any guidelines for tuning these parameters in practice?
Overall, while the paper is well-written and presents an interesting idea, it falls short of providing a compelling case for the novelty and significance of the proposed approach.