Summary
This paper proposes a novel approach to learning chess game concepts under weak supervision using convolutional neural networks (CNNs). The authors use a simple chess game, tic-tac-toe, as a case study and demonstrate that a CNN can automatically figure out complicated game rule concepts, such as the concept of a chessboard grid, the winning rule, and the concept of two sides. The paper also shows that cross-modal supervision for representation learning is still applicable in this case of higher-level semantics and that the technique of class activation mapping (CAM) can activate at non-salient regions.
Decision
I decide to accept this paper with some reservations. The paper tackles a specific and interesting question of whether a CNN can learn game concepts under weak supervision, and the approach is well-motivated and placed in the literature. However, the paper's clarity is a major issue, and some of the results and conclusions could be more rigorously supported.
Supporting Arguments
The paper's main contribution is the demonstration that a CNN can learn game concepts under weak supervision, which is a novel and interesting result. The authors provide a clear and well-structured introduction to the problem and the methodology, and the experiments are well-designed and executed. The use of CAM to visualize the learned representations is also a nice touch. However, the paper could benefit from more rigorous evaluation and analysis of the results, particularly in terms of the quantitative evaluation protocols.
Additional Feedback
To improve the paper, I would suggest the following: (1) provide more detailed analysis of the learned representations and how they relate to the game concepts; (2) consider using more advanced techniques for evaluating the learned representations, such as those used in natural language processing or computer vision; (3) provide more discussion on the implications of the results and how they can be applied to more complex games or real-world scenarios.
Questions for the Authors
I would like the authors to clarify the following points: (1) How do the learned representations change when the game rules or the supervision signal are modified? (2) Can the authors provide more insight into how the CAM technique is able to activate at non-salient regions, and what this means for our understanding of CNNs? (3) How do the results of this paper relate to other work on learning game concepts or representations, and what are the implications for future research in this area?