Summary of the Paper's Contributions
The paper proposes a novel approach to visual servoing, which combines learned visual features, learned predictive dynamics models, and reinforcement learning to learn visual servoing mechanisms. The authors demonstrate that standard deep features, such as those learned from object classification tasks, can be used together with a bilinear predictive model to learn an effective visual servo that is robust to visual variation, changes in viewing angle and appearance, and occlusions. The paper also introduces a sample-efficient fitted Q-iteration algorithm to learn the weights of the features, which allows the visual servo to pick out the target of interest from irrelevant distractor objects.
Decision: Reject
The paper has some issues, including being hurriedly written and making strong claims not backed up by the approach. While the idea of third-person imitation learning is novel, the authors' approach is limited to extending a specific IRL algorithm using GANs, rather than exploring how to adapt current IRL algorithms to this setting. Additionally, the paper lacks empirical validation of its claims that existing IRL algorithms will fail in the proposed setting, and no comparison is made with other approaches such as supervised learning or behavioral cloning.
Supporting Arguments
The experimental evaluation is limited and lacks details, including the cost of TRPO training, the number of roll-outs necessary, and the variance of the results. The experiments also lack transparency, including how expert trajectories were obtained, the specifics of the domains used in the pendulum experiment, and the frequency of training failures. Furthermore, the paper does not provide a clear comparison with other state-of-the-art methods, making it difficult to assess the significance of the results.
Additional Feedback
To improve the paper, the authors should provide more detailed experiments, including comparisons with other state-of-the-art methods, and more transparent descriptions of their experimental setup. Additionally, the authors should consider exploring other approaches to adapting IRL algorithms to the third-person imitation learning setting, rather than relying solely on GANs. The authors should also provide more empirical validation of their claims and consider using more robust evaluation metrics.
Questions for the Authors
1. Can you provide more details on how the expert trajectories were obtained and what specific domains were used in the pendulum experiment?
2. How did you determine the number of roll-outs necessary for the TRPO training, and what was the variance of the results?
3. Can you provide a more detailed comparison with other state-of-the-art methods, including supervised learning and behavioral cloning?
4. How do you plan to address the limitations of the current approach, including the reliance on GANs and the lack of exploration of other IRL algorithms?