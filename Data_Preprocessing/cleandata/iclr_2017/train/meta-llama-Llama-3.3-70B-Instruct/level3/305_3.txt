Summary of the Paper's Claims and Contributions
The paper presents a novel approach to learning perceptual similarity judgment using a deep convolutional neural network (DCNN) fine-tuned with object persistence constraints. The authors propose a Siamese triplet architecture that associates different views of the same 3D object to capture the notion of object persistence and continuity in our visual experience. The resulting network, called Object Persistence Net (OPnet), demonstrates improved performance in similarity judgment tasks, including instance and categorical retrieval, on both trained and untrained categories of objects. The paper also shows that OPnet's feature representations match human perceptual similarity judgment better than AlexNet, suggesting that object persistence might play a role in shaping human similarity judgment.
Decision and Key Reasons
Based on the review, I decide to Accept this paper. The two key reasons for this choice are:
1. Well-motivated approach: The paper presents a well-motivated approach to learning perceptual similarity judgment, building on the idea of object persistence and continuity in our visual experience. The authors provide a clear explanation of the problem, the proposed solution, and the experimental design.
2. Strong empirical results: The paper presents strong empirical results, demonstrating the effectiveness of OPnet in similarity judgment tasks, including instance and categorical retrieval, on both trained and untrained categories of objects. The results also show that OPnet's feature representations match human perceptual similarity judgment better than AlexNet.
Supporting Arguments
The paper provides a thorough introduction to the problem of perceptual similarity judgment and the limitations of existing approaches. The authors also provide a clear explanation of the proposed approach, including the Siamese triplet architecture and the object persistence constraints. The experimental design is well-justified, and the results are thoroughly analyzed and discussed. The paper also provides a detailed comparison with existing approaches, including AlexNet and the joint embedding model.
Additional Feedback and Questions
To further improve the paper, I suggest that the authors:
* Provide more details on the rendering process of the multi-view datasets and the selection of the 3D object models.
* Discuss the potential limitations of the approach, including the reliance on 3D object models and the potential bias in the ShapeNet dataset.
* Explore the transferability of the approach to other domains, such as real-world images and videos.
* Provide more insights into the neural mechanisms underlying human similarity judgment and how they relate to the proposed approach.
Some questions I would like the authors to answer:
* How do the authors plan to address the potential overfitting of OPnet to the ShapeNet dataset?
* Can the authors provide more details on the computational resources required to train and test OPnet?
* How do the authors plan to extend the approach to handle more complex variations, such as lighting and scale, in real-world environments?