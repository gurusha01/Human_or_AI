Summary
The paper introduces the concept of Frame-based convolutional networks, which extends the traditional pixel basis to a more general notion of frames. The authors propose Dynamic Steerable Frame Networks (DSFNs) that can continuously transform features locally and fill the gap between Spatial Transformer Networks and Dynamic Filter Networks. The paper demonstrates the effectiveness of DSFNs on edge detection and limited-data hand-gesture recognition tasks.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper lacks high-level arguments on the method's goals and limitations, and the main novel contribution needs clarification. Secondly, the experimental results are not convincing, particularly on the Cifar10+ dataset, where the Gauss-Frame gives better results only after an expensive search.
Supporting Arguments
The paper's readability can be improved, particularly in the introduction of frames, which lacks motivation and clarity for those new to the concept. The work falls under the category of methods that impose knowledge about filter transformations into the network architecture, but it is unclear about the practicality and usefulness of this approach. The paper lacks insights into transformational parameters relevant to the problem, unlike the spatial transformer network paper, which provided valuable insights into feature transformation learned by the algorithm. The algorithm is similar to the Dynamic Filter Networks paper, and it is not clear what advantages the proposed formulation brings.
Additional Feedback
To improve the paper, the authors should provide more context and motivation for the concept of frames and their application to convolutional networks. The experimental results should be more comprehensive and convincing, with a clearer comparison to existing methods. The authors should also provide more insights into the transformational parameters learned by the network and their relevance to the problem at hand. Additionally, the authors should consider providing more visualizations and examples to illustrate the effectiveness of the proposed method.
Questions for the Authors
1. Can you provide more context and motivation for the concept of frames and their application to convolutional networks?
2. How do the proposed Dynamic Steerable Frame Networks differ from existing methods, such as Dynamic Filter Networks and Spatial Transformer Networks?
3. Can you provide more insights into the transformational parameters learned by the network and their relevance to the problem at hand?
4. How do you plan to address the issue of expensive search for optimal frames in the Cifar10+ dataset?
5. Can you provide more visualizations and examples to illustrate the effectiveness of the proposed method?