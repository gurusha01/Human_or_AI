Summary
The paper proposes a novel approach to sequence learning, called Incremental Sequence Learning, which involves training a network on the first few steps of each sequence and gradually increasing the length of the sequences used for training. The authors evaluate this approach on a new dataset, MNIST pen stroke sequences, and demonstrate that it significantly improves sequence learning performance, reducing the test error by 74% and achieving a 20-fold speedup in training time. The paper also explores the origins of this performance improvement and demonstrates the effectiveness of Incremental Sequence Learning in transfer learning to sequence classification.
Decision
I decide to Accept this paper, with two key reasons for this choice: (1) the paper proposes a novel and well-motivated approach to sequence learning, which is supported by a thorough analysis of the results, and (2) the experimental evaluation is rigorous and demonstrates significant improvements in sequence learning performance.
Supporting Arguments
The paper is well-written and clearly motivated, with a thorough review of related work in incremental and curriculum learning. The proposed approach, Incremental Sequence Learning, is simple yet effective, and the authors provide a detailed analysis of the results, including an investigation of the origins of the performance improvement. The experimental evaluation is rigorous, with multiple comparisons to baseline methods and a thorough analysis of the results. The paper also demonstrates the effectiveness of Incremental Sequence Learning in transfer learning to sequence classification, which is an important application of sequence learning.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the hyperparameter tuning process, particularly for the threshold value used to determine when to increase the sequence length. Additionally, it would be interesting to see more examples of the generated sequences and a more detailed analysis of the sequence classification results. Finally, the authors may want to consider comparing their approach to other state-of-the-art sequence learning methods, such as those using attention mechanisms or graph neural networks.
Questions for the Authors
I would like to ask the authors to clarify the following points: (1) How did they choose the threshold value used to determine when to increase the sequence length, and what is the sensitivity of the results to this hyperparameter? (2) Can they provide more examples of the generated sequences and a more detailed analysis of the sequence classification results? (3) Have they considered comparing their approach to other state-of-the-art sequence learning methods, and if so, what were the results?