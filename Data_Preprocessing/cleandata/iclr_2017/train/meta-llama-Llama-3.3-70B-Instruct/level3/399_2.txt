This paper presents a novel approach to policy search in stochastic dynamical systems using model-based reinforcement learning. The authors utilize Bayesian neural networks (BNNs) with stochastic inputs to capture complex statistical patterns in the transition dynamics, which is a significant improvement over traditional methods. The paper effectively utilizes Mixture of Experts (MoE) to expand model capacity, enabling the training of large models on vast datasets in a computationally feasible manner.
The approach is well-motivated, and the authors provide a clear explanation of the background and related work in model-based reinforcement learning. The use of BNNs with stochastic inputs is a key contribution, allowing the model to capture complex stochastic patterns in the dynamics. The experimental results provide interesting insights into the effects of increasing the number of MoEs, aligning with expectations.
However, a notable weakness of the paper is the lack of comparison between MoE and alternative methods for increasing model capacity in terms of computational efficiency and other factors. This comparison would have provided a more comprehensive understanding of the benefits and limitations of the proposed approach.
Based on the provided guidelines, I will answer the three key questions:
1. What is the specific question/problem tackled by the paper?
The paper tackles the problem of policy search in stochastic dynamical systems using model-based reinforcement learning, with a focus on capturing complex statistical patterns in the transition dynamics.
2. Is the approach well-motivated, including being well-placed in the literature?
Yes, the approach is well-motivated, and the authors provide a clear explanation of the background and related work in model-based reinforcement learning.
3. Does the paper support the claims?
Yes, the paper provides experimental results that support the claims made by the authors, demonstrating the effectiveness of the proposed approach in capturing complex stochastic patterns in the dynamics.
My decision is to accept the paper, with the reason being that the approach is well-motivated, and the experimental results provide interesting insights into the effects of increasing the number of MoEs.
To improve the paper, I suggest that the authors provide a more comprehensive comparison between MoE and alternative methods for increasing model capacity, including computational efficiency and other factors. Additionally, the authors could provide more details on the hyperparameter tuning process and the sensitivity of the results to different hyperparameter settings.
I would like the authors to answer the following questions to clarify my understanding of the paper:
* Can you provide more details on the hyperparameter tuning process and the sensitivity of the results to different hyperparameter settings?
* How do you plan to address the lack of comparison between MoE and alternative methods for increasing model capacity in future work?
* Can you provide more insights into the computational complexity of the proposed approach and how it compares to other methods in the literature?