Summary of the Paper
The paper proposes a technique to reduce the number of weights in recurrent neural networks (RNNs) by pruning weights during the initial training of the network. The authors introduce a "Data Filter" that selects examples for the target network to learn optimally, learned simultaneously via Reinforcement Learning algorithms. The proposed method achieves sparsity of 90% with a small loss in accuracy and can also improve the accuracy over a dense baseline by starting with a larger dense matrix and then pruning it down.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the experimental setting lacks proper evaluation, such as using single experiments and not experimenting with state-of-the-art optimization methods like Adam and RMSProp. Secondly, the paper does not address the non-stationary environment and the impact of the changing feature distribution on optimization.
Supporting Arguments
The paper's methodology has flaws, and clearer explanations and more experiments are needed to make the paper complete and convincing. The choice of updating the REINFORCE policy only at the end of the episode, while training the actor-critic at each step, is questionable. Additionally, the use of "pseudo-validation" data for the policy is unclear and needs further explanation.
Additional Feedback
To improve the paper, I suggest using the more common style of citing authors, such as "(Author, year)" instead of "Author (year)". The paragraph explaining the dynamic determination of instances for training needs clarification on the forward-pass and computation of features. The authors should also provide more details on the hyperparameters used in the experiments and the criteria used to select the threshold for pruning.
Questions for the Authors
I would like the authors to clarify the following points:
1. How do the authors plan to address the non-stationary environment and the impact of the changing feature distribution on optimization?
2. Can the authors provide more details on the experimental setting, including the number of experiments run and the optimization methods used?
3. How do the authors select the threshold for pruning, and what are the criteria used to determine the hyperparameters for the pruning algorithm?