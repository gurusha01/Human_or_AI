Summary
The paper proposes a novel approach to question classification by incorporating answer information into question representation using Group Sparse Autoencoders (GSA) and Group Sparse Convolutional Neural Networks (GSCNNs). The authors argue that traditional question classification techniques do not fully utilize the well-prepared answer data, which has great potential for improving question representation. The proposed model shows significant improvements over strong baselines on four datasets.
Decision
I decide to accept this paper with minor revisions. The key reasons for this choice are: (1) the paper tackles a specific and important problem in question classification, and (2) the proposed approach is well-motivated and shows promising results.
Supporting Arguments
The paper clearly identifies the limitations of traditional question classification techniques and proposes a novel approach to address these limitations. The authors provide a thorough analysis of the problem and propose a well-motivated solution. The experimental results show significant improvements over strong baselines on four datasets, which demonstrates the effectiveness of the proposed approach.
Additional Feedback
To improve the paper, I suggest the authors provide more details on the implementation of GSA and GSCNNs, such as the choice of hyperparameters and the optimization process. Additionally, the authors could provide more analysis on the results, such as the effect of different initialization methods for the projection matrix and the impact of the group sparse constraint on the performance.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on the choice of hyperparameters for GSA and GSCNNs, such as the number of groups, the sparsity parameter, and the learning rate?
2. How do you initialize the projection matrix in GSA, and what is the effect of different initialization methods on the performance?
3. Can you provide more analysis on the results, such as the effect of the group sparse constraint on the performance and the comparison with other state-of-the-art methods?