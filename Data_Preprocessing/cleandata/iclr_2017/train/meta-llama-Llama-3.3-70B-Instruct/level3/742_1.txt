This paper presents a novel approach to sequence learning, combining supervised learning and reinforcement learning (RL) to refine a pre-trained Recurrent Neural Network (RNN) for music generation. The authors propose RL Tuner, a framework that uses RL to impose music theory constraints on the generated melodies while maintaining the information learned from the training data.
The paper claims to contribute to the sequence training and RL literature by proposing a new method for combining maximum likelihood (ML) and RL training, showing the connection between this approach and Stochastic Optimal Control (SOC)/KL-control, and exploring the usefulness of this approach in music generation.
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper lacks solid justification for the newly introduced measures of expressivity, such as trajectory length, which seem questionable as measures of expressivity. Secondly, the paper is overly long and obscure, making it difficult to understand the context and significance of the work.
To support my decision, I argue that the paper's approach, although novel, is not well-motivated, and the use of random networks as a basis for study is not relevant to practical applications. The results may not generalize to trained or non-random networks, and the choice of network width, such as 100 for MNIST, is deemed too small and may not be representative of real-world scenarios.
To improve the paper, I suggest that the authors provide more solid justification for their measures of expressivity, clarify the context and significance of their work, and consider using more relevant and practical network architectures. Additionally, the authors could provide more detailed analysis of the results, including comparisons with other state-of-the-art methods, and discuss the potential limitations and future directions of their approach.
I would like to ask the authors to clarify the following points: (1) How do they justify the use of trajectory length as a measure of expressivity? (2) Can they provide more detailed analysis of the results, including comparisons with other state-of-the-art methods? (3) How do they plan to address the potential limitations of their approach, such as the use of random networks and small network width?