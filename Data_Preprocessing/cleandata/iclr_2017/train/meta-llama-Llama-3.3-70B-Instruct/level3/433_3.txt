Summary
The paper proposes an end-to-end differentiable programming language, inspired by functional programming, to learn programs from input/output examples. The authors develop a range of models, starting from a simple assembly-like language and progressing to a differentiable version of a simple functional programming language. They evaluate the effect of four modeling recommendations: fixed heap memory allocation, structured control flow using loops and if-then-else instructions, immutable registers, and typed registers. The experiments demonstrate that these recommendations significantly improve the success ratio of learning programs from input/output examples.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper lacks a clear motivation for the specific problem tackled, and the authors do not provide enough evidence to support the claim that their approach is well-placed in the literature. Secondly, the paper does not provide sufficient analysis of the learned representations' usefulness for downstream tasks, which is a crucial aspect of evaluating the effectiveness of a programming language.
Supporting Arguments
The paper presents a range of modeling choices for end-to-end differentiable programming languages, but it does not clearly motivate why these choices are necessary or how they relate to existing work in the field. The authors also do not provide enough evidence to support the claim that their approach is better than existing methods, such as λ2, which performs better than all of their considered models. Additionally, the paper lacks a thorough analysis of the learned representations' usefulness for downstream tasks, which is a crucial aspect of evaluating the effectiveness of a programming language.
Additional Feedback
To improve the paper, the authors should provide a clearer motivation for the specific problem tackled and a more thorough analysis of the learned representations' usefulness for downstream tasks. They should also provide more evidence to support the claim that their approach is well-placed in the literature and better than existing methods. Additionally, the authors should consider providing more details about the implementation of their models and the experiments, such as the hyperparameter settings and the training procedures.
Questions for the Authors
1. Can you provide more motivation for the specific problem tackled in the paper and explain how it relates to existing work in the field?
2. How do you plan to analyze the learned representations' usefulness for downstream tasks, and what metrics will you use to evaluate their effectiveness?
3. Can you provide more evidence to support the claim that your approach is better than existing methods, such as λ2, and explain why your approach is more suitable for certain tasks?