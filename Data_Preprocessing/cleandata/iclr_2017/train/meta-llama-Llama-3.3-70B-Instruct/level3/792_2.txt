This paper proposes a novel approach to simulating action-conditional dynamics in various environments, including Atari games, 3D car racing, and mazes. The authors introduce an action-dependent state transition model that enables the simulator to learn the global dynamics of the environment, leading to improved long-term predictions. The paper also presents an extensive analysis of the effects of different training approaches on short-term and long-term prediction capabilities.
I decide to reject this paper, primarily due to two key reasons. Firstly, the comparison to existing methods, such as the model proposed by Oh et al. (2015), is not thorough, and the results may change with proper tuning and cross-validation. Secondly, the baseline architectures used are outdated and do not represent the current state-of-the-art methods, resulting in lower accuracy and questionable significance of the method.
To support my decision, I provide the following arguments. The paper lacks a comprehensive comparison to existing methods, which makes it challenging to assess the novelty and significance of the proposed approach. Additionally, the experiment setup lacks data augmentation and convergence tests, which may impact the results and significance of the method. The calculation of co-label similarities can be improved by using softmax results at the final layer instead of predicted labels. The results do not support the intuitive claims regarding the proposed procedure, and the iterative version can be unstable in practice.
To improve the paper, I suggest the following. The authors should provide a more comprehensive comparison to existing methods, including a thorough hyperparameter tuning and cross-validation. The baseline architectures should be updated to reflect the current state-of-the-art methods. The experiment setup should include data augmentation and convergence tests to ensure the robustness of the results. The authors should also consider alternative methods, such as totally corrective updates, and provide a more detailed explanation of the updates used in the paper.
I would like the authors to answer the following questions to clarify my understanding of the paper and provide additional evidence to support their claims. How do the authors plan to address the issue of outdated baseline architectures and ensure that their method is compared to the current state-of-the-art methods? Can the authors provide more details on the hyperparameter tuning process and the cross-validation procedure used in the paper? How do the authors plan to improve the stability of the iterative version of their method? Can the authors provide more insights into the calculation of co-label similarities and how it can be improved using softmax results at the final layer?