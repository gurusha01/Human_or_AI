Summary of the Paper's Contributions
The paper proposes a multi-view Bayesian non-parametric algorithm for learning multi-sense word embeddings. The approach leverages multilingual distributional information to improve sense embeddings beyond what can be achieved with bilingual information. The algorithm uses a principled approach to learn a variable number of senses per word in a data-driven manner, making it the first approach to efficiently utilize multilingual corpora for multi-sense representation learning.
Decision and Reasons
I decide to reject this paper, with two key reasons for this choice. Firstly, the proposed regularizer is a combination of existing methods, lacking novelty in its approach. Secondly, while the connection between nonlinearities and stochastic regularizers is intriguing, the empirical performance is not significantly better than similar methods.
Supporting Arguments
The paper's approach, although well-motivated and well-placed in the literature, does not introduce significant new ideas. The use of multilingual distributional information is a natural extension of previous work, and the algorithm's performance, while competitive, does not demonstrate a substantial improvement over existing methods. Furthermore, the paper's evaluation is limited to a specific task, word sense induction, and it is unclear how the approach would perform on other tasks.
Additional Feedback and Questions
To improve the paper, I suggest the authors provide more detailed analysis of the algorithm's performance on different tasks and datasets. Additionally, it would be helpful to include more ablation studies to understand the contribution of each component of the algorithm. I would like the authors to answer the following questions: (1) How does the algorithm's performance change when using different language families or datasets? (2) Can the authors provide more insight into the learned sense embeddings, such as visualizations or examples of the induced senses? (3) How does the algorithm's performance compare to other state-of-the-art methods on tasks beyond word sense induction?