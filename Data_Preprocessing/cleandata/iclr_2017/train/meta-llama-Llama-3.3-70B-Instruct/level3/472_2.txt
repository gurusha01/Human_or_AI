This paper proposes a novel approach to dialogue agents, where the agent learns to interact with users by asking questions. The authors design a simulator and a set of synthetic tasks in the movie question answering domain, allowing a bot to interact with a teacher to address issues such as question clarification, knowledge operation, and knowledge acquisition. The paper explores both offline supervised and online reinforcement learning settings, demonstrating that the learner improves when asking questions.
The paper is well-written, with detailed derivations and explanations of the algorithm's design and motivation. The authors provide a thorough analysis of the results, highlighting the benefits of asking questions in different scenarios. However, the experimental results are not entirely convincing, with small datasets and modest improvements over standard question answering approaches.
One of the main concerns is the lack of baseline comparisons to other state-of-the-art image clustering methods. The evaluation methodology is also questionable, with potential overfitting due to hyperparameter selection using the test set. To improve the paper, the authors could consider alternative evaluation methods, such as reconstruction error, sparsity, and denoising performance, to directly assess the sparse coding approach.
To answer the conference guidelines, I would say that:
1. The specific question/problem tackled by the paper is how to design a dialogue agent that can learn to interact with users by asking questions.
2. The approach is well-motivated, building on existing work in dialogue systems and question answering.
3. However, the paper does not entirely support its claims, due to the limited experimental results and lack of baseline comparisons.
Based on these considerations, I would reject the paper, primarily due to the limited experimental results and lack of baseline comparisons. However, I believe that the proposed approach is an interesting direction, and with additional experiments and evaluations, it could be a strong contribution to the field.
Some questions I would like the authors to answer to clarify my understanding of the paper include:
* How do the authors plan to address the issue of overfitting due to hyperparameter selection using the test set?
* Can the authors provide more details on the experimental setup, including the size of the datasets and the number of parameters in the models?
* How do the authors plan to extend the approach to more complex dialogue scenarios, such as multi-turn conversations or conversations with multiple participants?