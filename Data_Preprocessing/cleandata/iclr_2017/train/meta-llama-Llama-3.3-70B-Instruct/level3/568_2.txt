Summary of the Paper's Contributions
The paper proposes a novel deep learning model, GRU-D, for handling missing values in multivariate time series data. The model is based on Gated Recurrent Units (GRU) and incorporates two representations of informative missingness patterns: masking and time interval. The authors demonstrate the effectiveness of their model on both synthetic and real-world healthcare datasets, showing that it outperforms strong baselines and provides useful insights into the impact of missing values on prediction tasks.
Decision: Accept
I decide to accept this paper because it tackles a specific and important problem in time series analysis, namely handling missing values, and proposes a well-motivated and novel solution. The paper is well-structured, and the authors provide a clear explanation of their model and its components. The experimental results are thorough and demonstrate the effectiveness of the proposed model.
Supporting Arguments
1. Specific question/problem tackled: The paper addresses a specific and important problem in time series analysis, which is handling missing values. The authors provide a clear motivation for their work and demonstrate the importance of exploiting informative missingness patterns in time series data.
2. Well-motivated approach: The proposed model, GRU-D, is well-motivated and based on a solid understanding of the problem. The authors provide a clear explanation of their model and its components, including the use of masking and time interval to capture informative missingness patterns.
3. Strong empirical results: The experimental results are thorough and demonstrate the effectiveness of the proposed model. The authors evaluate their model on both synthetic and real-world healthcare datasets and show that it outperforms strong baselines.
Additional Feedback
To further improve the paper, I suggest that the authors provide more insights into the interpretability of their model and its components. For example, they could provide more analysis on the learned decay rates and their relationship to the underlying missingness patterns. Additionally, the authors could explore the application of their model to other domains and tasks, such as time series forecasting or anomaly detection.
Questions for the Authors
1. Can you provide more insights into the interpretability of the learned decay rates and their relationship to the underlying missingness patterns?
2. How do you plan to extend your model to handle more complex missingness patterns, such as non-random missingness or missingness that depends on the input variables?
3. Can you provide more details on the computational complexity of your model and its scalability to large datasets?