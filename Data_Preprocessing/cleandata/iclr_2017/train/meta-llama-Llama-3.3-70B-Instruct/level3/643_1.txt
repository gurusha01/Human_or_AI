This paper proposes a novel online dictionary learning approach, Neurogenetic Online Dictionary Learning (NODL), which incorporates the addition and deletion of dictionary elements to adapt to changing data properties. The authors draw inspiration from the adult neurogenesis phenomenon in the hippocampus, where new neurons are born and old ones die, allowing the brain to adapt to new environments. The NODL algorithm extends the state-of-the-art online dictionary learning method of Mairal et al. (2009) by introducing a conditional neurogenesis step, where new dictionary elements are added based on the current representation error, and a group-sparsity regularization step, which removes "useless" elements.
The paper claims to contribute a new online model selection approach to dictionary learning, which outperforms the state-of-the-art baseline, especially in non-stationary settings. The authors provide an extensive empirical evaluation on both synthetic and real datasets, including images and language data, and identify certain data properties and parameter settings associated with the improvements.
I decide to accept this paper with two key reasons: (1) the approach is well-motivated and well-placed in the literature, and (2) the paper supports its claims with extensive empirical evaluations and some theoretical analysis. The authors provide a clear and concise explanation of the proposed algorithm and its components, and the experimental results demonstrate the effectiveness of the NODL approach in adapting to changing data properties.
However, I would like to see more detailed analysis of the algorithm's behavior, such as the effect of the threshold parameter γ on the number of new elements added, and the impact of the group-sparsity regularization parameter λg on the dictionary size and reconstruction accuracy. Additionally, it would be interesting to explore the application of the NODL approach to other domains, such as audio or video processing.
To improve the paper, I suggest the authors provide more insights into the theoretical properties of the NODL algorithm, such as convergence guarantees and bounds on the representation error. Furthermore, the authors could explore the use of other metrics for evaluating the dictionary's performance, such as the reconstruction error or the classification accuracy.
Some questions I would like the authors to answer include: (1) How does the choice of the threshold parameter γ affect the number of new elements added and the overall performance of the algorithm? (2) Can the authors provide more insights into the effect of the group-sparsity regularization parameter λg on the dictionary size and reconstruction accuracy? (3) How does the NODL approach compare to other online dictionary learning methods, such as those using incremental PCA or incremental NMF? (4) Can the authors explore the application of the NODL approach to other domains, such as audio or video processing, and report on the results?