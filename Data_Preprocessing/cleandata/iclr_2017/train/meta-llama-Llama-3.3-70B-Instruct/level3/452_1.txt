This paper proposes a novel approach to learning activation functions in deep neural networks through nonparametric estimation, specifically using a Fourier basis expansion. The authors demonstrate the effectiveness of their approach on several benchmark datasets, including MNIST and CIFAR-10, and provide a theoretical justification for their method. The paper is well-written, and the authors provide a clear and concise explanation of their approach and its benefits.
The specific question or problem tackled by the paper is how to learn activation functions in deep neural networks, which is a crucial aspect of deep learning. The authors' approach is well-motivated, as they argue that current methods for selecting activation functions are limited and often rely on empirical choices. The paper provides a thorough evaluation of the proposed method, including experiments on several datasets and a comparison to existing methods.
The approach is well-placed in the literature, as it builds upon existing work on learning activation functions and nonparametric estimation. The authors provide a clear and concise overview of the related work and demonstrate how their approach improves upon existing methods.
The paper supports its claims through a combination of theoretical analysis and empirical evaluation. The authors provide a theoretical justification for their approach, including a proof of the generalization bound for their method. They also provide an extensive empirical evaluation, including experiments on several datasets and a comparison to existing methods.
Based on the evaluation, I decide to accept this paper. The paper makes a significant contribution to the field of deep learning, and the authors provide a clear and concise explanation of their approach and its benefits. The paper is well-written, and the authors provide a thorough evaluation of their method.
One key reason for this choice is that the paper provides a novel and effective approach to learning activation functions in deep neural networks. The authors demonstrate the effectiveness of their approach on several benchmark datasets, and their method has the potential to improve the performance of deep neural networks in a variety of applications.
Another key reason is that the paper provides a thorough evaluation of the proposed method, including experiments on several datasets and a comparison to existing methods. The authors provide a clear and concise explanation of their approach and its benefits, and they demonstrate how their method improves upon existing methods.
To improve the paper, I suggest that the authors provide more details on the implementation of their method, including the specific hyperparameters used in their experiments. Additionally, the authors could provide more analysis on the computational complexity of their method and its potential applications in real-world scenarios.
I would like the authors to answer the following questions to clarify my understanding of the paper:
1. Can you provide more details on the implementation of your method, including the specific hyperparameters used in your experiments?
2. How does your method compare to existing methods for learning activation functions, such as the method proposed by Agostinelli et al. (2015)?
3. What are the potential applications of your method in real-world scenarios, and how does it compare to existing methods in terms of computational complexity and performance?