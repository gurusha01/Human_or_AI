The paper proposes a novel approach to training recurrent neural networks (RNNs) using surprisal-driven feedback, where the next-step prediction error is fed back as input to the network. This approach is applied to language modeling tasks, and the results show promise. The introduction of surprisal-driven feedback is a key contribution, as it utilizes feedback from previous time-step errors as additional input to the model.
I decide to reject this paper, with the primary reason being the lack of clarity on whether ground-truth labels are used for surprisal feedback on the test set. The assumption is that they are used due to the claim of utilizing misprediction error as input, which raises concerns about the model's ability to generalize to unseen data. Additionally, the paper's poor writing and lack of convincing justification and experimental results make it difficult to fully evaluate the effectiveness of the proposed approach.
The experimental results are limited to a single dataset, and the claim of achieving state-of-the-art results on enwiki8 is disputed, with other papers such as HyperNetworks achieving better results. The model's requirement for ground-truth labels on the test set limits its application to a narrow set of tasks, excluding most conditional language modeling tasks. The pros of the paper include a simple yet interesting modification that improves results, while the cons include the need for test-set labels, poor writing, and limited experimental results.
To improve the paper, I suggest reorganizing the content to make it clearer and more concise, moving unnecessary equations to the appendix, and providing more convincing justification and experimental results. Additionally, the authors should address the concerns about the model's ability to generalize to unseen data and provide more detailed analysis of the results.
I would like the authors to answer the following questions to clarify my understanding of the paper and provide additional evidence to support their claims: 
1. Can you provide more details on how the surprisal-driven feedback is implemented, and how it is used to improve the model's performance?
2. How do you address the concern that the model's requirement for ground-truth labels on the test set limits its application to a narrow set of tasks?
3. Can you provide more experimental results on different datasets and tasks to demonstrate the effectiveness of the proposed approach?
4. How do you plan to extend the proposed approach to tackle summarization problems with large input text, and what are the potential challenges and limitations of this approach?