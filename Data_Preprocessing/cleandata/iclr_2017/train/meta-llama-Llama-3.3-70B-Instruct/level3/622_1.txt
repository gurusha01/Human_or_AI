Summary of the Paper's Claims and Contributions
The paper proposes a novel approach to network morphism, which enables the transformation of a convolutional layer into an arbitrary module of a neural network. The authors introduce a graph-based representation for modular networks and formulate the network morphism process as a graph transformation problem. They define two atomic morphing operations and propose algorithms for simple morphable modules and complex modules. The paper claims that a convolutional layer can be morphed into any module, providing a theoretical upper bound for the capability of this learning scheme. The authors also present extensive experiments on benchmark datasets, demonstrating the effectiveness of the proposed morphing approach in achieving better performance with minimal extra computational cost.
Decision and Key Reasons
I decide to reject this paper. The two key reasons for this decision are:
1. Limited novelty: Although the paper applies spin glass techniques to deep residual networks, making an interesting contribution, the main theoretical techniques and results were already introduced and proven in previous work, specifically Choromanska et al. The paper's contribution is limited to extending these techniques to a new domain, rather than providing significant new insights or breakthroughs.
2. Failure to eliminate assumptions: The authors fail to eliminate several assumptions from previous work, including path-independence and assumptions about weight distributions. These assumptions may not hold in practice, which could limit the applicability and effectiveness of the proposed approach.
Supporting Arguments
The paper's approach is based on a graph-based representation of modular networks, which is a useful abstraction. However, the authors do not provide sufficient evidence to support the claim that this representation is general enough to capture the complexity of real-world neural networks. Furthermore, the paper's experiments are limited to a specific dataset and network architecture, which may not be representative of the broader range of applications and scenarios.
Additional Feedback and Questions
To improve the paper, I would suggest that the authors:
* Provide more detailed comparisons with existing work, highlighting the specific contributions and advancements made in this paper.
* Address the limitations and assumptions of the proposed approach, and discuss potential ways to mitigate these limitations.
* Conduct more extensive experiments on a wider range of datasets and network architectures to demonstrate the generality and effectiveness of the proposed approach.
Some specific questions I would like the authors to address are:
* How do the authors plan to extend the proposed approach to more complex network architectures, such as those with multiple branches or recursive connections?
* What are the computational costs and memory requirements of the proposed approach, and how do these scale with the size of the input network?
* How do the authors plan to handle cases where the input network is not a simple morphable module, and more complex morphing operations are required?