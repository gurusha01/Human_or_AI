This paper proposes a novel loss framework for language modeling, which addresses two major drawbacks of the conventional classification framework: the lack of a natural metric on the output space and the isolation of inputs and outputs. The authors introduce an additional loss term that minimizes the KL-divergence between the model's prediction and an estimated target distribution based on word embeddings. This leads to a theoretical justification for reusing the input word embedding matrix as the output projection matrix, reducing the number of trainable variables.
The paper claims to contribute to the field of language modeling by providing a new loss framework that improves learning and reduces model complexity. The authors support their claims with extensive experiments on the Penn Treebank and Wikitext-2 datasets, demonstrating that their framework outperforms the conventional one.
I decide to accept this paper with two key reasons: (1) the paper proposes a well-motivated and theoretically grounded approach to language modeling, and (2) the experimental results are supportive of the proposed framework, demonstrating significant improvements over the baseline.
The approach is well-motivated because it addresses the limitations of the conventional classification framework and provides a natural way to incorporate word embeddings into the loss function. The theoretical analysis is thorough and provides a clear understanding of the proposed framework. The experimental results are also convincing, demonstrating that the proposed framework can achieve state-of-the-art performance on benchmark datasets.
To improve the paper, I suggest that the authors provide more details on the hyperparameter tuning process, particularly for the temperature parameter τ and the weight of the augmented loss α. Additionally, it would be helpful to include more qualitative analysis of the results, such as examples of generated text or visualizations of the learned word embeddings.
I would like to ask the authors to clarify the following points: (1) How do the authors plan to extend their framework to other NLP tasks, such as machine translation or text summarization? (2) Can the authors provide more insights into the trade-offs between the augmented loss and the reuse of word embeddings, and how these two components contribute to the overall performance of the model? (3) How do the authors plan to address the potential issue of overfitting, particularly when using the reused word embeddings in the output projection layer?