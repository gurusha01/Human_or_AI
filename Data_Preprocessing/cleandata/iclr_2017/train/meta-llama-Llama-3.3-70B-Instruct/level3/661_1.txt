The paper proposes a semi-supervised method for neural networks inspired by label propagation, but it appears to be similar to an existing method proposed by Weston et al in 2008. The authors suggest using the adjacency matrix as input to the neural network when no other features are available and demonstrate success on the BlogCatalog dataset. However, the experimental results on text classification and semantic intent classification are not convincing due to a lack of comparison with existing baselines and unimpressive top reported accuracies.
I decide to reject this paper for the following reasons: 
1. The paper lacks scientific novelty, essentially rebranding an existing algorithm under a new name and proposing few new applications. 
2. The optimized objective function in the paper is identical to the one in Weston et al's 2008 paper, raising concerns about novelty.
To improve the paper, I suggest the authors provide more convincing experimental results, compare their method with existing baselines, and demonstrate the effectiveness of their approach on a wider range of tasks. Additionally, the authors should clearly highlight the differences between their method and existing methods, such as Weston et al's 2008 paper, and provide a more detailed analysis of the theoretical contributions of their work.
Some questions I would like the authors to answer to clarify my understanding of the paper include: 
- How does the proposed method differ from Weston et al's 2008 paper, and what are the key contributions of this work? 
- Can the authors provide more detailed experimental results, including comparisons with existing baselines and more impressive top reported accuracies? 
- How does the authors' method handle cases where the adjacency matrix is not available or is incomplete? 
- Can the authors provide more insight into the theoretical analysis of their method, including the optimized objective function and its relationship to existing methods?