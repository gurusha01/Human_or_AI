Summary of the Paper's Contributions
The paper proposes a Neural Knowledge Language Model (NKLM) that incorporates symbolic knowledge from a knowledge graph into a recurrent neural network (RNN) language model. The model predicts whether a word is based on a fact or not and generates words either from the vocabulary or by copying from the fact description. The authors introduce a new dataset, WikiFacts, and a modified perplexity metric, Unknown-Penalized Perplexity (UPP), to evaluate the model's performance. The results show that the NKLM outperforms the traditional RNN language model in terms of perplexity and generates named entities that are not observed during training.
Decision and Reasons
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper's writing needs significant improvement, with unclear definitions and notations, such as the fact embeddings and the use of entity embeddings from TransE. Secondly, the approach to generating words from KB entities is questionable, as it generates a symbol position first and may not preserve the order of multiple-word entities.
Supporting Arguments
The paper's motivation to improve learning of named entity words is well-placed in the literature, and the introduction of the WikiFacts dataset and the UPP metric is a valuable contribution. However, the paper's technical presentation is marred by unclear definitions and notations, which makes it difficult to understand the model's architecture and training procedure. Additionally, the approach to generating words from KB entities raises concerns about the model's ability to preserve the order of multiple-word entities and its reliance on a simple position prediction mechanism.
Additional Feedback and Questions
To improve the paper, I suggest that the authors clarify the definitions and notations, provide more details on the model's architecture and training procedure, and address the concerns about the approach to generating words from KB entities. Some questions that I would like the authors to answer include: How do the fact embeddings capture the semantic meaning of the facts? How does the model handle cases where the fact description is long or contains multiple entities? Can the authors provide more examples of the model's output and evaluate its performance on other datasets? How does the NKLM compare to other language models that incorporate external knowledge, such as memory-augmented neural networks?