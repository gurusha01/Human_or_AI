This paper proposes a dynamic neural Turing machine (D-NTM) that extends the traditional neural Turing machine (NTM) by introducing a learnable addressing scheme. The D-NTM allows for more flexible and nonlinear location-based addressing, which is shown to be effective in various tasks, including episodic question-answering and sequential MNIST.
The paper claims to contribute to the development of general-purpose learning algorithms, which is a long-standing goal of artificial intelligence. The authors demonstrate the effectiveness of the D-NTM on several tasks, including Facebook's bAbI tasks, sequential MNIST, and algorithmic tasks such as copy and associative recall.
However, I have some concerns regarding the feature engineering approach used in this paper. The authors rely heavily on hand-designed features, such as the learnable address vectors and the content-based addressing mechanism. While these features may be effective for the specific tasks considered in the paper, they may not generalize well to other tasks or domains.
I would like to see a more data-driven approach to feature learning, where the model learns to represent the data in a way that is optimal for the task at hand. This could involve using techniques such as generative models or self-supervised learning to learn feature representations from the data.
Furthermore, I think it would be beneficial to collect a larger corpus of audio data from zoos or nature and train a generative model to learn the underlying feature representations. This would allow the model to learn a more general and robust representation of the data, rather than relying on hand-designed features.
The learned feature representation could then be used to feed a classifier for improved results, rather than relying on methods like chirplets. This approach would be more in line with current trends in deep learning, where data-driven feature learning has been shown to be highly effective in a wide range of tasks.
Overall, while the paper presents some interesting results and contributions, I think it would benefit from a more data-driven approach to feature learning and a larger and more diverse dataset.
My decision is to reject this paper, with the main reason being the lack of a data-driven approach to feature learning. I would like to see the authors revisit their approach and consider using more modern techniques for feature learning.
Some questions I would like the authors to answer include:
* How do the learned feature representations compare to hand-designed features, such as those used in the paper?
* Can the authors demonstrate the effectiveness of their approach on a larger and more diverse dataset?
* How do the results of the D-NTM compare to other state-of-the-art models on the tasks considered in the paper?
Additional feedback I would like to provide includes:
* The paper could benefit from a more detailed analysis of the learned feature representations and how they relate to the task at hand.
* The authors may want to consider using more modern techniques for feature learning, such as generative models or self-supervised learning.
* The paper could benefit from a more detailed comparison to other state-of-the-art models on the tasks considered in the paper.