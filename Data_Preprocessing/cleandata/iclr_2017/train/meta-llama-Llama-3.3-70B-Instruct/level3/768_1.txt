This paper proposes a novel technique for exploration in deep reinforcement learning (RL) by extending classic count-based methods to high-dimensional state spaces through hashing. The approach is simple, fast, and flexible, and achieves near state-of-the-art performance on various challenging tasks, including continuous control and Atari 2600 games.
The specific question tackled by the paper is how to balance exploration and exploitation in high-dimensional state spaces, where most states will only occur once. The approach is well-motivated, drawing on classic count-based methods and extending them to high-dimensional spaces through hashing.
The paper supports its claims with extensive experiments on various benchmarks, including rllab and Atari 2600 games. The results demonstrate that the proposed method outperforms baseline methods and achieves near state-of-the-art performance on several tasks.
Based on the evaluation, I decide to accept this paper. The two key reasons for this choice are: (1) the paper proposes a novel and simple approach for exploration in deep RL, which achieves near state-of-the-art performance on various challenging tasks; and (2) the paper provides extensive experiments and analysis to support its claims, demonstrating the effectiveness and robustness of the proposed method.
To improve the paper, I suggest the following additional feedback: (1) provide more discussion on the choice of hash function and its impact on performance; (2) investigate the use of other exploration strategies, such as entropy regularization, in combination with the proposed method; and (3) provide more analysis on the computational efficiency of the proposed method, particularly in comparison to other state-of-the-art methods.
Some questions I would like the authors to answer to clarify my understanding of the paper are: (1) how do the authors choose the hyperparameters, such as the bonus coefficient and the hash function parameters, and what is the sensitivity of the method to these hyperparameters; (2) how does the proposed method handle cases where the state space is extremely large or infinite, and what are the limitations of the method in such cases; and (3) what are the potential applications of the proposed method beyond the benchmarks evaluated in the paper, and how can it be extended to more complex and real-world tasks.