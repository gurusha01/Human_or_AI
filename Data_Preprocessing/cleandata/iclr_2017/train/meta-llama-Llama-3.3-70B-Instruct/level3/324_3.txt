Summary
The paper proposes a neural network architecture and statistical framework for modeling frames in videos using principles inspired by computer graphics pipelines. The approach, called Perception Updating Networks (PUN), explicitly represents "sprites" or percepts inferred from the maximum likelihood of the scene and infers their movement independently of their content. The authors demonstrate the effectiveness of PUN on synthetic datasets, including bouncing shapes and moving MNIST, and show that it can generate videos that are interpretable and better suited for long video generation.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the selection criteria for pruning filters lacks justification and misses critical baselines such as random pruning and pruning based on activation pattern norms. Secondly, the method's empirical speedup is unclear as it only reports FLOPs without providing wall-clock speedup.
Supporting Arguments
The paper proposes an impressive approach to video modeling, but it falls short in providing a thorough evaluation of its method. The lack of justification for the selection criteria of pruning filters raises concerns about the robustness of the approach. Additionally, the absence of wall-clock speedup measurements makes it difficult to assess the practical impact of the method. While the paper presents promising results on synthetic datasets, it is essential to address these limitations to ensure the validity and usefulness of the proposed approach.
Additional Feedback
To improve the paper, I suggest that the authors provide a more comprehensive evaluation of their method, including a thorough justification of the selection criteria for pruning filters and measurements of wall-clock speedup. Additionally, it would be beneficial to compare the proposed approach to other state-of-the-art methods for video modeling and generation. The authors may also consider providing more visualizations and examples to illustrate the effectiveness of their approach.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
1. Can you provide more details on the selection criteria for pruning filters and justify why these criteria were chosen?
2. How do you plan to address the lack of wall-clock speedup measurements, and what additional experiments can be conducted to demonstrate the practical impact of the proposed approach?
3. Can you provide more comparisons to other state-of-the-art methods for video modeling and generation, and how does the proposed approach differ from these methods?