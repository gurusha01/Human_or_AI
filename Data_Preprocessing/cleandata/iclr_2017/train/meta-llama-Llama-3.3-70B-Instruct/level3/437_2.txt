Summary of the Paper's Contributions
The paper proposes a variant of the Generative Adversarial Network (GAN) framework, called Generative Multi-Adversarial Network (GMAN), which extends GANs to multiple discriminators. The authors introduce a new metric, GMAM, to evaluate the performance of GMAN and demonstrate its effectiveness on various image generation tasks. The paper also explores different design perspectives, including a formidable adversary and a forgiving teacher, and shows that GMAN can be reliably trained with the original, untampered minimax objective.
Decision and Reasons
I decide to Reject this paper, with two key reasons:
1. Lack of extensive experiments: The paper lacks extensive experiments in multiple Atari and non-Atari domains, which is a crucial aspect of reinforcement learning. The experiments are limited to image generation tasks, and the results may not generalize to other domains.
2. Limited plots for observing instabilities: The paper provides limited plots for observing instabilities across multiple runs, which makes it difficult to assess the stability of the proposed method.
Supporting Arguments
The paper's stability and ability to achieve good results in various domains are compromised due to the limited scope of experiments. The authors claim that GMAN can be reliably trained with the original, untampered minimax objective, but this claim is not supported by sufficient experimental evidence. Additionally, the paper's evaluation metric, GMAM, may not be suitable for all types of generative models, and its effectiveness in other domains is unclear.
Additional Feedback
To improve the paper, I suggest the following:
* Conduct more extensive experiments in multiple domains, including Atari and non-Atari games, to demonstrate the generalizability of the proposed method.
* Provide more plots and visualizations to observe instabilities across multiple runs and assess the stability of the proposed method.
* Investigate the effectiveness of GMAM in other domains and consider alternative evaluation metrics.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
* Can you provide more details on the experimental setup and hyperparameter tuning for the image generation tasks?
* How do you plan to address the issue of mode collapse in GMAN, and what strategies can be employed to promote diversity in the generated samples?
* Can you provide more insights into the design of the GMAM metric and its limitations in evaluating the performance of generative models?