Summary
The paper proposes an enhanced attention mechanism for sentiment classification using a global context computed by a Bi-LSTM, achieving better results than existing models on three sentiment analysis datasets. The model incorporates local contexts with the guide of global context attention, mimicking human reading behavior. The authors demonstrate the effectiveness of their proposed models, TS-ATT and SS-ATT, through experiments on benchmark datasets.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the idea of using Bi-LSTM to compute global context for attention is not novel, having been proposed previously in the literature. Secondly, the experiments could be improved by showing results with additional techniques like dropout or pre-trained word embeddings to demonstrate the model's robustness and comparability to existing literature.
Supporting Arguments
The paper's approach, while well-motivated, lacks novelty in its use of Bi-LSTM for global context computation. The authors cite previous work, such as Luong et al. (2015) and Shen & Lee (2016), which have already explored similar ideas. Furthermore, the experiments, although demonstrating the effectiveness of the proposed models, do not provide a comprehensive comparison with existing state-of-the-art models. The lack of results with additional techniques like dropout or pre-trained word embeddings makes it difficult to assess the model's robustness and comparability.
Additional Feedback
To improve the paper, I suggest the authors consider the following: (1) provide a more thorough review of existing literature on attention mechanisms and sentiment analysis, highlighting the novelty of their approach; (2) conduct additional experiments with dropout, pre-trained word embeddings, and other techniques to demonstrate the model's robustness and comparability; and (3) provide more detailed analysis of the attention visualization results, including case studies and qualitative evaluations.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions: (1) How do the authors plan to address the lack of novelty in their approach, and what specific contributions do they believe their paper makes to the field? (2) Can the authors provide more detailed results on the attention visualization, including quantitative evaluations and comparisons with other attention-based models? (3) How do the authors plan to extend their work to other NLP tasks, such as machine translation or question answering, and what potential challenges do they foresee?