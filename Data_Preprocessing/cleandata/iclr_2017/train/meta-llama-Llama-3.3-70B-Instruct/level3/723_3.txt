Summary
The paper proposes an LSTM-based meta-learner model to learn the optimization algorithm for training a neural network classifier in the few-shot learning setting. The model is trained to discover a good initialization for the learner's parameters and a successful mechanism for updating the learner's parameters to a given small training set for a new classification task. The authors demonstrate that their approach outperforms natural baselines and is competitive with the state-of-the-art in metric learning for few-shot learning.
Decision
I decide to reject this paper, with the main reason being that the comparison between the proposed approach and the standard approach is not thorough enough. Specifically, the paper lacks a detailed analysis of the model complexity, such as the number of parameters used, and the use of language models in the evaluation.
Supporting Arguments
The paper presents a well-written and well-motivated approach to few-shot learning, but the evaluation section lacks a thorough comparison with the standard approach. The authors only compare their approach with two baselines and a recent metric-learning technique, but do not provide a detailed analysis of the model complexity and the use of language models. Additionally, the paper could benefit from more quantitative results to evaluate the effect of using only 70% of the data by selecting longer words.
Additional Feedback
To improve the paper, I suggest that the authors provide more details on the model complexity, such as the number of parameters used, and the use of language models in the evaluation. Additionally, the authors could provide more quantitative results to evaluate the effect of using only 70% of the data by selecting longer words. The paper could also benefit from more experiments to vary the use of order in the sequential classification problem. Furthermore, the authors should clarify the notation and terminology used in the paper, such as "whole language method" and the notation for rnn_d(x,t).
Questions
I would like the authors to answer the following questions to clarify my understanding of the paper:
1. Can you provide more details on the model complexity, such as the number of parameters used, and the use of language models in the evaluation?
2. How does the use of only 70% of the data by selecting longer words affect the performance of the model?
3. Can you provide more experiments to vary the use of order in the sequential classification problem?
4. Can you clarify the notation and terminology used in the paper, such as "whole language method" and the notation for rnn_d(x,t)?