Summary of the Paper
The paper proposes a novel approach to improve feature learning in deep reinforcement learning by adding auxiliary tasks to the main policy's optimization problem. This approach aims to achieve better data efficiency by leveraging the additional tasks to learn more informative features. The authors also introduce a "Read-Again" model, which reads the input sequence twice to capture more context and improve the representation of each word.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper lacks a clear discussion on the extra computational cost of optimizing the auxiliary tasks and its impact on training speed. Secondly, the "feature control" idea is not empirically validated, and the paper does not provide sufficient evidence to support its effectiveness.
Supporting Arguments
The paper proposes an interesting approach to improve feature learning in deep reinforcement learning. However, the authors do not provide a thorough analysis of the computational cost of optimizing the auxiliary tasks. This is a crucial aspect, as the added complexity may outweigh the benefits of improved feature learning. Furthermore, the "feature control" idea is not well-supported by empirical evidence, and the paper does not provide sufficient experiments to demonstrate its effectiveness.
Additional Feedback
To improve the paper, the authors should provide a more detailed analysis of the computational cost of optimizing the auxiliary tasks and its impact on training speed. Additionally, the authors should conduct more experiments to empirically validate the "feature control" idea and demonstrate its effectiveness in different scenarios. The paper could also benefit from a clearer discussion on the relationship between the auxiliary tasks and the main policy's optimization problem.
Questions for the Authors
1. Can you provide more details on the computational cost of optimizing the auxiliary tasks and its impact on training speed?
2. How do you plan to empirically validate the "feature control" idea, and what experiments do you propose to conduct to demonstrate its effectiveness?
3. Can you provide more insight into the relationship between the auxiliary tasks and the main policy's optimization problem, and how they interact with each other?