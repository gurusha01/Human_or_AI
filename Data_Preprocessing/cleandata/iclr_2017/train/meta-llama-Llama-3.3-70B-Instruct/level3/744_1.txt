Summary
The paper proposes a novel approach to sentiment analysis, introducing a global-local context attention framework that mimics human reading behavior. The model uses a bidirectional LSTM (Bi-LSTM) network to extract a global context representation, which is then used as attention to incorporate important local contexts. The authors evaluate their model on several benchmark datasets, demonstrating its effectiveness in sentiment classification tasks.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper's approach, although novel, is not sufficiently justified, and the empirical results do not demonstrate its effectiveness over existing state-of-the-art models. Secondly, the paper lacks clarity and completeness in its presentation, with missing comparisons and inconsistent reporting of results.
Supporting Arguments
The paper's approach is an incremental combination of existing techniques, such as Highway Neural Networks and Residual Networks. While the authors claim that their model achieves state-of-the-art results on some benchmark datasets, the results are not consistently reported, and the comparisons with other models are incomplete. Furthermore, the paper lacks a thorough analysis of the model's performance on ImageNet, which is a standard benchmark for evaluating the effectiveness of deep learning models.
Additional Feedback
To improve the paper, I suggest that the authors provide a more detailed analysis of their model's performance, including a thorough comparison with existing state-of-the-art models. Additionally, the authors should clarify their assumptions and derivations, such as the use of squared parameter-wise distance and the substitution of mean and variance with initialization mean variance. The authors should also provide more comprehensive empirical results, including ImageNet comparisons, to demonstrate the effectiveness of their model.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide a more detailed explanation of the motivation behind using a global-local context attention framework for sentiment analysis?
2. How do you justify the use of a Bi-LSTM network to extract a global context representation, and what are the advantages of this approach over other existing techniques?
3. Can you provide a more comprehensive comparison of your model's performance with existing state-of-the-art models, including a thorough analysis of the results on ImageNet?