Summary of the Paper's Contributions
The paper explores the concept of sample importance in deep neural networks, which refers to the change in parameters induced by a sample during training. The authors define a quantitative measurement of sample importance and conduct empirical analysis on two standard datasets, MNIST and CIFAR-10. They find that easy samples shape parameters closer to the output layer, while hard samples impact parameters closer to the input layer. Additionally, they show that mixing hard and easy samples in each batch is beneficial for training, contradicting some results on curriculum learning.
Decision and Key Reasons
I decide to Accept this paper, with the key reasons being:
1. The paper tackles a specific and interesting question about sample importance in deep neural networks.
2. The approach is well-motivated, and the authors provide a clear definition of sample importance and its measurement.
3. The empirical analysis is thorough, and the results are reasonable and validated on three different tasks.
Supporting Arguments
The paper provides a clear and concise introduction to the concept of sample importance, and the authors motivate their approach by highlighting the limitations of existing methods. The empirical analysis is well-designed, and the results are presented in a clear and easy-to-understand manner. The authors also provide a thorough discussion of their findings and their implications for deep learning.
Additional Feedback
To improve the paper, I suggest that the authors provide more specific and original sources in their references, such as Rumelhart's paper on back-propagation instead of the Deep Learning book. Additionally, the authors could consider expanding their analysis to other deep learning structures, such as Convolutional Neural Networks and Recurrent Neural Networks.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on how you calculated the sample importance, and how you chose the specific measurement used in the paper?
2. How do you think the results would change if you used a different deep learning architecture, such as a Convolutional Neural Network?
3. Can you provide more insight into the implications of your findings for curriculum learning and self-paced learning, and how they can be used to improve the training of deep neural networks?