Summary
The paper proposes a novel pruning method called NoiseOut, which reduces the number of parameters in neural networks by removing neurons with correlated activations during training. The authors introduce a technique to encourage correlation between neurons by adding noise outputs to the network, allowing for more efficient pruning. The method is tested on various networks and datasets, achieving significant compression rates without loss of accuracy.
Decision
I decide to Reject this paper, with two key reasons for this choice. Firstly, the paper is hard to follow, and the writing clarity could be improved for easier presentation. Secondly, the performance of the models reported in the paper is relatively low, raising concerns about the experimental results.
Supporting Arguments
The idea of using a probabilistic model to capture polysemy is interesting, and the extension of the skipgram model to learn word embeddings is a valuable contribution. However, the paper's complexity and lack of clarity make it challenging to understand and evaluate the proposed method. Additionally, the low performance of the models reported in the paper raises concerns about the effectiveness of the proposed method.
Additional Feedback
To improve the paper, I suggest simplifying the writing and providing more intuitive explanations of the proposed method. Additionally, the authors could provide more detailed analysis of the experimental results, including comparisons with other pruning methods and more extensive evaluations on different datasets. It would also be helpful to provide more insights into the relationship between the proposed method and other techniques designed to avoid overfitting, such as Dropout and Regularization.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
1. Can you provide more detailed explanations of the proposed method, including the intuition behind adding noise outputs to the network?
2. How do you plan to address the concerns about the low performance of the models reported in the paper?
3. Can you provide more extensive evaluations of the proposed method on different datasets and comparisons with other pruning methods?