This paper proposes a novel approach to generating transferable adversarial examples for deep neural networks. The authors conduct an extensive study of the transferability of both non-targeted and targeted adversarial examples over large models and a large-scale dataset, ImageNet. They demonstrate that while non-targeted adversarial examples can transfer well among models, targeted adversarial examples generated using existing approaches rarely transfer with their target labels. To address this, they propose ensemble-based approaches that generate adversarial examples for multiple models, which exhibit better transferability.
I decide to reject this paper for two key reasons. Firstly, the experimental evaluation lacks thoroughness, specifically in implementing a simple multi-task learning baseline to test the hypothesis of task ordering by complexity. This omission makes it difficult to fully assess the effectiveness of the proposed approach. Secondly, the results related to chunking are not informative due to the test set being included in the training data of dependency parsing, which biases the evaluation.
To support my decision, I argue that the paper's approach, although well-motivated and well-placed in the literature, does not provide sufficient evidence to support its claims. The lack of a thorough experimental evaluation and the biased results for chunking undermine the paper's conclusions. Furthermore, the model's results are not fair because it does not guarantee well-formed dependency trees, particularly as seen in table 4. Additionally, chunking is incorrectly classified as a word-level task, when in fact it is a structured prediction task that involves learning a structured annotation over a sequence.
To improve the paper, I suggest that the authors conduct a more thorough experimental evaluation, including a simple multi-task learning baseline, and ensure that the test set is not included in the training data for dependency parsing. Additionally, the authors should provide more detailed analysis of the geometric properties of the models and the decision boundaries of the targeted ensemble-based approaches. I would like the authors to answer the following questions: (1) How do the authors plan to address the lack of thoroughness in the experimental evaluation? (2) Can the authors provide more insights into the geometric properties of the models and how they relate to the transferability of adversarial examples? (3) How do the authors plan to ensure that the model's results are fair and guarantee well-formed dependency trees?