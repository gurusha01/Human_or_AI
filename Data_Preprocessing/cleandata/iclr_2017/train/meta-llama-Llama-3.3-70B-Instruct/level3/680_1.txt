Summary
The paper proposes a neural machine translation model that achieves compelling results on various bilingual corpora by using vocabulary selection techniques to constrain the output words to be scored to a small subset relevant to the current source sentence. The authors explore a wide range of simple and complex selection techniques, including bilingual word co-occurrence counts, bilingual embeddings, word alignments, phrase pairs, and discriminative SVM classifiers. The experiments show that decoding speed-up can be reduced by up to 90% without compromising accuracy, and word alignments, bilingual phrases, and SVMs can achieve high accuracy even when considering fewer than 1,000 word types per sentence.
Decision
I decide to accept this paper, with the main reason being that it presents a comprehensive analysis of vocabulary selection techniques for neural machine translation and demonstrates significant efficiency gains without compromising accuracy. The paper is well-written, and the experiments are thorough and well-designed.
Supporting Arguments
The paper's contributions are significant, as it extends previous work by considering a wide range of selection techniques and exploring the trade-off between speed and accuracy for different vocabulary sizes. The results are convincing, with decoding speed-up reduced by up to 90% without compromising accuracy. The paper also provides a thorough analysis of the impact of vocabulary selection on training speed, which is an important aspect of neural machine translation.
Additional Feedback
To improve the paper, I suggest that the authors provide more details on the model size in Table 1 and include examples of failure cases where the model failed to translate correctly. Additionally, the authors could discuss the potential limitations of the vocabulary selection approach and provide more insights into the trade-off between speed and accuracy. It would also be helpful to include more related work on neural machine translation and vocabulary selection techniques.
Questions for the Authors
I would like the authors to clarify the following points:
* Can you provide more details on the model size in Table 1 and how it was determined?
* Can you include examples of failure cases where the model failed to translate correctly and discuss the potential limitations of the vocabulary selection approach?
* How do you plan to address the issue of rare words receiving fewer updates during training, and what are the potential consequences of this on the model's performance?