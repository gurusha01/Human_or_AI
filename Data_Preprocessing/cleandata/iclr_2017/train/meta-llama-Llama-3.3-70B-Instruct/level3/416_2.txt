This paper proposes a novel approach to integrate efficient inference within the Generative Adversarial Network (GAN) framework, called Adversarially Learned Inference (ALI). The authors contribute to the field by recognizing that normalizing flows can provide unbiased estimators for entropy and implementing the resulting Lagrangian as a relaxation of an augmented Lagrangian. The paper explores maximum entropy approaches as a valid modeling scenario, which is an underexplored area in deep learning literature, and proposes using invertible neural models to solve the maximum entropy network problem.
I decide to accept this paper with two key reasons: (1) the approach is well-motivated and provides a novel basis for flexible maximum entropy models, and (2) the paper provides good sound quality, clarity, originality, and significance in model development terms. The authors demonstrate the approach on several models with clear evaluation and establish the practical issues in doing the augmented Lagrangian optimization.
To improve the paper, I suggest that the authors discuss appropriate use cases and computational scaling aspects, as the approach may be more suitable for model learning than inferential settings. Additionally, minor issues include labeling equations, algorithm notation, and clarifying stability issues and support conditions for the proposed method.
To clarify my understanding of the paper, I would like the authors to answer the following questions: (1) Can you provide more details on the relationship between ALI and other approaches to generative modeling, such as Variational Autoencoders (VAEs) and autoregressive models? (2) How do you plan to address the potential mode-dropping issue in ALI, where the generator may not cover all modes of the data distribution? (3) Can you provide more insights on the choice of hyperparameters and the sensitivity of the results to these choices? 
Overall, the paper provides a significant contribution to the field of deep learning and generative modeling, and with some minor revisions, it has the potential to be a strong publication.