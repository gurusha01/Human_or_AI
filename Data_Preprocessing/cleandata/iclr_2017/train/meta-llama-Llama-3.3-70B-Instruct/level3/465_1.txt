Summary of the Paper's Contributions
The paper presents a comprehensive study of targeted and non-targeted adversarial examples in CNNs, exploring their effectiveness and transferability. The authors propose novel ensemble-based approaches to generate transferable adversarial examples, which demonstrate a high success rate in transferring targeted attacks. The paper also provides geometric insights into the transferability of adversarial examples, shedding light on the decision boundaries of different models.
Decision to Accept or Reject
Based on the evaluation, I decide to accept the paper with minor revisions. The key reasons for this decision are:
1. The paper tackles a specific and important problem in the field of deep learning, namely the transferability of adversarial examples.
2. The approach is well-motivated, and the authors provide a clear and comprehensive evaluation of their methods.
3. The paper supports its claims with extensive experiments and provides valuable insights into the geometric properties of adversarial examples.
Supporting Arguments
The paper's contributions are significant, and the authors demonstrate a thorough understanding of the problem and its implications. The ensemble-based approaches proposed in the paper show promising results, and the geometric analysis provides a deeper understanding of the transferability of adversarial examples. The experiments are well-designed, and the results are clearly presented.
Additional Feedback
To improve the paper, I suggest the following:
1. Clarify the key contributions of the paper and provide a more focused narrative on the ensemble method and its ability to handle targeted attacks.
2. Consider using more diverse models, such as AlexNet and Network-in-Network, to make the ensemble results more compelling.
3. Provide more details on the geometric properties of the models and their implications for transferability.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more insights into the choice of ensemble weights and their impact on the transferability of adversarial examples?
2. How do the geometric properties of the models relate to the transferability of adversarial examples, and what are the implications for designing more robust models?
3. Can you provide more examples of targeted adversarial attacks on Clarifai.com and discuss the potential consequences of such attacks in real-world scenarios?