Summary of the Paper's Contributions
The paper proposes a method to control the expansivity of gradients during backpropagation in Recurrent Neural Networks (RNNs) by manipulating orthogonality constraints and regularization on matrices. The authors explore the effect of loosening hard orthogonality constraints on the hidden-to-hidden transition matrix and introduce a factorization technique that allows for bounding the matrix norms. The paper presents experimental results on various tasks, including synthetic memory tasks and real-world datasets, demonstrating that orthogonal initialization can be beneficial, but maintaining constraints on orthogonality can be detrimental to optimization convergence rate and model performance.
Decision and Reasons
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper's approach, although well-motivated, is not entirely new, and the authors could have done a better job of placing their work in the context of existing literature. Secondly, the experimental results, while interesting, are not entirely convincing, and the paper could benefit from more rigorous evaluation and comparison to existing methods.
Supporting Arguments
The paper's proposal to control the expansivity of gradients by manipulating orthogonality constraints is a valid one, and the authors provide some interesting insights into the effects of loosening hard orthogonality constraints. However, the paper's presentation is often convoluted, and the authors could have done a better job of motivating their approach and explaining the intuition behind their method. Additionally, the experimental results, while promising, are not comprehensive, and the paper could benefit from more extensive evaluation and comparison to existing methods.
Additional Feedback and Questions
To improve the paper, I would suggest that the authors provide a clearer motivation for their approach, including a more detailed discussion of the existing literature and how their work relates to it. Additionally, the authors could benefit from more rigorous evaluation and comparison to existing methods, including a more comprehensive set of experiments and a more detailed analysis of the results. Some questions I would like the authors to answer include: How does the proposed method compare to existing methods for controlling the expansivity of gradients, such as gradient clipping and weight normalization? What are the computational costs associated with the proposed method, and how do they compare to existing methods? How do the authors plan to extend their work to more complex models and tasks, such as those involving multiple layers and large datasets?