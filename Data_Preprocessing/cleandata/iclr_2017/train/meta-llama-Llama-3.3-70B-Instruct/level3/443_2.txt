Summary
The paper proposes a novel neural network architecture and statistical framework for modeling frames in videos, inspired by computer graphics pipelines. The approach explicitly represents "sprites" or percepts inferred from the maximum likelihood of the scene and infers their movement independently of their content. The authors introduce a variational lower bound that decouples sprites and their dynamics in a video and propose a family of architectures called Perception Updating Networks to optimize this bound.
Decision
I decide to Accept this paper with minor revisions. The paper's strong points include its well-written content, interesting idea of combining various sources of information in a Bayesian framework, and a strong experimental section with notable results. However, I have some minor concerns that need to be addressed.
Supporting Arguments
The paper tackles a specific question of modeling video frames using a statistical framework inspired by computer graphics pipelines. The approach is well-motivated and placed in the literature, drawing connections to existing work on vision as inverse graphics. The experimental section is thorough, and the results demonstrate the effectiveness of the proposed architecture in generating interpretable videos.
However, I have some minor concerns. Firstly, the paper could benefit from a clearer explanation of the conceptual difference between the proposed work and existing approaches, such as Tillmann et al.'s work. Secondly, the sensitivity of the model to different hyper-parameter choices could be further explored.
Additional Feedback
To improve the paper, I suggest the authors provide more details on the computational complexity of the proposed architecture and compare it to existing approaches. Additionally, the authors could explore the application of their approach to more complex video datasets and provide more visualizations of the learned sprites and their dynamics.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on the differences between the proposed approach and Tillmann et al.'s work?
2. How sensitive is the model to different hyper-parameter choices, and what are the implications for the results?
3. Can you provide more visualizations of the learned sprites and their dynamics, particularly for the Moving MNIST dataset?