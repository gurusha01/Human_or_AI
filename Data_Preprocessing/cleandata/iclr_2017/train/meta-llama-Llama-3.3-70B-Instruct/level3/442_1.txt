The paper proposes a novel approach to supervised learning by applying the information bottleneck principle, which aims to find a representation that is maximally informative about the target variable while being maximally compressive about the input data. The authors introduce a variational approximation to the information bottleneck objective, called Deep Variational Information Bottleneck (VIB), which allows for efficient training using stochastic gradient descent.
The paper claims to contribute to the development of a new regularizer that can improve the robustness of neural networks to adversarial attacks. The authors demonstrate the effectiveness of VIB on several datasets, including MNIST and ImageNet, and show that it can outperform other regularization techniques, such as dropout and confidence penalty.
I decide to reject this paper, primarily because the results, although promising, are not strong enough to support the claims made by the authors. The MNIST accuracy results are not impressive, with an error rate of 1.13%, and the comparison to external quantitative baselines is lacking. Additionally, the paper has many distinct architectural choices, such as the number of hidden layers and the choice of a simple logistic regression for the decoder, which are not clearly justified.
To improve the paper, I would suggest that the authors provide more comprehensive comparisons to other regularization techniques and evaluate the performance of VIB on a wider range of datasets. Furthermore, the authors should provide more insight into the choice of hyperparameters and architectural decisions, and consider using more advanced techniques, such as Bayesian neural networks or adversarial training, to improve the robustness of the model.
Some questions I would like the authors to answer to clarify my understanding of the paper include: How did the authors choose the value of β, and what is the effect of varying β on the performance of the model? How does the VIB objective compare to other regularization techniques, such as dropout and confidence penalty, in terms of computational cost and performance? Can the authors provide more insight into the relationship between the information bottleneck principle and the robustness of neural networks to adversarial attacks? 
Overall, while the paper presents an interesting idea, it requires more rigorous evaluation and comparison to other techniques to support its claims. With additional experimentation and analysis, the authors may be able to strengthen their results and provide more convincing evidence for the effectiveness of VIB as a regularizer.