Summary
The paper presents a novel perspective on Highway and Residual networks, proposing that they perform unrolled iterative estimation. This view challenges the traditional representation view of deep learning, where each layer computes a new level of abstraction. Instead, the authors argue that successive layers within a stage cooperate to compute a single level of representation, with the first layer providing a rough estimate that is then iteratively refined by subsequent layers.
Decision
I decide to accept this paper, with two key reasons for this choice. Firstly, the paper tackles a specific and well-defined problem in the field of deep learning, providing a clear and well-motivated alternative perspective on Highway and Residual networks. Secondly, the approach is well-supported by theoretical derivations and empirical evidence, including experiments on image classification and language modeling tasks.
Supporting Arguments
The paper provides a thorough analysis of the limitations of the traditional representation view, highlighting several findings that contradict this perspective. The authors then derive both Highway and Residual networks from the unrolled iterative estimation perspective, providing a unified theory for understanding these architectures. The experimental results demonstrate the effectiveness of this perspective, refuting some claims that Highway networks require more parameters or are impaired by gating.
Additional Feedback
To further improve the paper, I suggest that the authors provide more visualizations and intuitive explanations to help readers understand the unrolled iterative estimation perspective. Additionally, it would be beneficial to explore the implications of this perspective on other deep learning architectures and tasks. Some questions I would like the authors to address include: How does the unrolled iterative estimation perspective relate to other optimization techniques, such as batch normalization and layer normalization? Can this perspective be applied to other types of neural networks, such as recurrent neural networks or graph neural networks?
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on how the unrolled iterative estimation perspective relates to the optimization perspective, and how they complement each other?
2. How do you envision the unrolled iterative estimation perspective influencing the design of future deep learning architectures?
3. Are there any potential limitations or drawbacks to the unrolled iterative estimation perspective that you have not addressed in the paper?