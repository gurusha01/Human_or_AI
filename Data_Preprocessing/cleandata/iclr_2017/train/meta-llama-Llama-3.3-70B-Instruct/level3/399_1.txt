This paper proposes a novel approach to policy search in stochastic dynamical systems using model-based reinforcement learning with Bayesian neural networks (BNNs) and stochastic inputs. The authors introduce a method to learn complex stochastic patterns in the transition dynamics using BNNs with random inputs and α-divergence minimization. They also present an algorithm for policy search using random roll-outs and stochastic optimization.
The paper claims to contribute to the field of reinforcement learning by providing a powerful black-box tool for policy search in industry domains. The authors demonstrate the effectiveness of their approach on several benchmark problems, including the Wet-Chicken problem, gas turbine data, and an industrial benchmark. The results show that their method outperforms other approaches, such as Gaussian processes and variational Bayes, in terms of test log-likelihood and policy performance.
Based on the provided guidelines, I will evaluate the paper as follows:
1. The specific question/problem tackled by the paper is policy search in stochastic dynamical systems using model-based reinforcement learning with BNNs and stochastic inputs.
2. The approach is well-motivated, and the authors provide a clear explanation of the background and related work in the field. However, the paper could benefit from a more detailed explanation of the key concepts, such as equation 8, and a clearer organization of the experiment section.
3. The paper supports its claims with empirical results on several benchmark problems, demonstrating the effectiveness of the proposed approach.
My decision is to accept the paper, with the following reasons:
* The paper proposes a novel and well-motivated approach to policy search in stochastic dynamical systems.
* The authors provide a clear explanation of the background and related work in the field.
* The empirical results demonstrate the effectiveness of the proposed approach on several benchmark problems.
However, I suggest the following improvements to the paper:
* Provide a more detailed explanation of the key concepts, such as equation 8.
* Reorganize the experiment section to make it clearer and easier to follow.
* Include more references to related work in the field of conditional computation.
I would like the authors to answer the following questions to clarify my understanding of the paper:
* Can you provide more details on the implementation of the α-divergence minimization algorithm?
* How did you choose the hyperparameters for the BNNs and the policy network?
* Can you provide more information on the computational complexity of the proposed approach compared to other methods?