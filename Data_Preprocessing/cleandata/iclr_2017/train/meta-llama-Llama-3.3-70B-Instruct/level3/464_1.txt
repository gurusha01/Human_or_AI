Summary
The paper explores the error surface of deep neural networks, specifically examining the impact of finite-sized datasets and models on the learning dynamics. The authors construct counterexamples to demonstrate that, unlike previous claims, the error surface of deep models can have bad local minima, even for simple models and datasets. They also provide empirical evidence to support their theoretical findings, showing that bad initialization and data structure can lead to suboptimal learning dynamics.
Decision
I decide to Accept this paper, with the primary reason being that it presents a well-motivated and well-executed exploration of the error surface of deep neural networks, which is a crucial aspect of understanding the behavior of these models. The paper's contribution to the ongoing effort to explore new directions in NLP and its relevance to the conference theme are also significant factors in my decision.
Supporting Arguments
The paper tackles a specific question/problem, namely, the characterization of the error surface of deep models, and provides a clear and well-structured argument. The approach is well-motivated, and the authors provide a thorough literature review, highlighting the limitations of previous work and the need for a more nuanced understanding of the error surface. The paper's results, both theoretical and empirical, are correct and scientifically rigorous, demonstrating a deep understanding of the subject matter.
Additional Feedback
To further improve the paper, I suggest that the authors consider providing more context on the implications of their findings for practical applications, such as how their results can inform the design of more efficient and effective neural network architectures. Additionally, the authors may want to explore the relationship between the error surface and other aspects of neural network behavior, such as generalization and robustness.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to address the following questions:
1. Can you provide more insight into the construction of the counterexamples, specifically how you chose the datasets and model initializations?
2. How do you think your results relate to other aspects of neural network behavior, such as generalization and robustness?
3. What are the potential implications of your findings for the design of more efficient and effective neural network architectures?