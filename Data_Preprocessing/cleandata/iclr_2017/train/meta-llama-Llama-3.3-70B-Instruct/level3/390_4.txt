Summary
The paper proposes an automatic dialogue evaluation model (ADEM) that learns to predict human-like scores for input responses. ADEM uses a hierarchical recurrent neural network (RNN) encoder to learn distributed representations of the context, model response, and reference response. The model is trained in a semi-supervised manner using a pre-trained VHRED model and achieves significant correlations with human judgements at both the utterance and system levels.
Decision
I decide to accept this paper with the following key reasons:
1. The approach is well-motivated and addresses a significant problem in dialogue research, which is the need for an accurate automatic evaluation procedure.
2. The results demonstrate that ADEM correlates significantly with human judgements and outperforms traditional word-overlap metrics such as BLEU.
Supporting Arguments
The paper provides a thorough analysis of the limitations of word-overlap metrics and demonstrates the effectiveness of ADEM in evaluating dialogue responses. The use of a hierarchical RNN encoder and semi-supervised learning with VHRED pre-training allows ADEM to capture semantic similarity beyond word overlap statistics and exploit both the context of the conversation and the reference response. The results show that ADEM generalizes well to new models and achieves significant correlations with human judgements.
Additional Feedback
To further improve the paper, I suggest the authors consider the following:
* Provide more analysis on the failure cases of ADEM, such as the cases where ADEM misses a good response or erroneously ranks a response highly.
* Investigate the use of other evaluation metrics, such as METEOR or ROUGE, in addition to BLEU.
* Consider the potential biases in human evaluations and explore ways to mitigate them, such as using multiple human evaluators or developing more objective evaluation metrics.
Questions for the Authors
1. Can you provide more details on the VHRED pre-training process and how it contributes to the performance of ADEM?
2. How do you plan to address the issue of generic responses, which are often rated highly by humans but may not be desirable in a dialogue system?
3. Have you considered applying ADEM to other domains, such as task-oriented dialogue systems, and if so, what are the potential challenges and opportunities?