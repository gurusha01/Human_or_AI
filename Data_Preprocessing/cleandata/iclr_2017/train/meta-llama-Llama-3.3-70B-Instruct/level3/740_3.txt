Summary
The paper introduces NewsQA, a large-scale machine comprehension dataset consisting of over 100,000 question-answer pairs based on news articles from CNN. The dataset is designed to require reasoning mechanisms, such as synthesis of information across different parts of an article, and encourages exploratory, curiosity-based questions that reflect human information seeking. The authors provide a thorough analysis of the dataset, including answer types and reasoning types, and evaluate the performance of several baseline models, including human data analysts and two neural models.
Decision
I decide to accept this paper, with the main reason being that it presents a well-motivated and well-designed dataset that addresses a significant need in the field of machine comprehension. The paper provides a clear and detailed description of the dataset collection methodology, and the analysis of the dataset is thorough and informative.
Supporting Arguments
The paper is well-motivated, as it addresses the limitations of existing machine comprehension datasets, which are either too small or too easy. The authors provide a clear explanation of the need for a dataset that requires reasoning mechanisms and encourages exploratory questions. The dataset collection methodology is well-designed, using a four-stage process that involves article curation, question sourcing, answer sourcing, and validation. The analysis of the dataset is thorough, providing insights into answer types and reasoning types, and the evaluation of baseline models is informative, highlighting the challenges of the dataset.
Additional Feedback
To improve the paper, I suggest that the authors provide more concrete examples of the types of questions and answers in the dataset, and consider adding more details about the neural models used in the evaluation. Additionally, it would be helpful to include more discussion about the potential applications of the NewsQA dataset and how it can be used to advance the field of machine comprehension. I would like the authors to answer the following questions: (1) Can you provide more examples of the types of questions and answers in the dataset? (2) How do you plan to make the dataset available to the research community? (3) What are the potential applications of the NewsQA dataset, and how can it be used to advance the field of machine comprehension? 
Questions for Clarification
I have the following questions for the authors: (1) How did you ensure the quality of the crowd-sourced questions and answers? (2) Can you provide more details about the neural models used in the evaluation, including their architecture and training procedures? (3) How do you plan to handle the cases where there are multiple possible answers to a question, or where the answer is not explicitly stated in the text?