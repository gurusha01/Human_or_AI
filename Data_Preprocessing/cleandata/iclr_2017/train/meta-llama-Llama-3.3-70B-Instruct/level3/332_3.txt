Summary
The paper proposes a novel approach to learning perceptual similarity judgment using a deep convolutional neural network (DCNN) with object persistence constraints. The authors retrain a standard DCNN (AlexNet) using a Siamese triplet architecture with multi-view images of 3D objects, which enables the network to learn a view-manifold that captures the notion of object persistence and continuity. The resulting network, called Object Persistence Net (OPnet), demonstrates improved performance in similarity judgment tasks, including instance and categorical retrieval, and shows a higher correlation with human perceptual similarity judgment.
Decision
I decide to accept this paper, with two key reasons: (1) the paper tackles a specific and interesting question related to human perception and similarity judgment, and (2) the approach is well-motivated and supported by experimental results.
Supporting Arguments
The paper provides a clear and well-structured introduction to the problem of perceptual similarity judgment and its importance in understanding human perception. The authors also provide a thorough review of related work in deep learning and computer vision. The experimental results demonstrate the effectiveness of the proposed approach in improving similarity judgment performance, particularly in the case of novel objects and categories. The comparison with human perceptual similarity judgment data also provides strong evidence for the validity of the approach.
Additional Feedback
To further improve the paper, I suggest that the authors consider the following points: (1) provide more details on the rendering process of the multi-view datasets, (2) explore the use of real-world datasets, such as ALOI, to evaluate the performance of OPnet, and (3) investigate the transferability of the learned view-manifold to other tasks, such as object recognition and image classification.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions: (1) How do the object persistence constraints affect the learned feature representations in OPnet, and (2) Can the authors provide more insights into the hierarchical structure of the view-manifold learned by OPnet, and how it relates to human perceptual similarity judgment?