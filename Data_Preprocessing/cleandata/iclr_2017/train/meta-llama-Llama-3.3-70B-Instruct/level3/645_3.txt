This paper proposes a novel approach to pruning convolutional neural networks (CNNs) by iteratively removing the least important feature maps based on a Taylor expansion-based criterion. The authors demonstrate that their method outperforms other pruning criteria, including the popular Optimal Brain Damage (OBD) method, and achieves significant reductions in computational cost while maintaining good generalization performance.
The specific question tackled by the paper is how to efficiently prune CNNs to reduce their computational cost while preserving their accuracy. The approach is well-motivated, building on existing work on neural network pruning and transfer learning. The authors provide a clear and well-structured presentation of their method, including a detailed description of the Taylor expansion-based criterion and its relation to OBD.
The paper supports its claims with extensive experimental results on several benchmark datasets, including Birds-200, Flowers-102, and ImageNet. The results demonstrate the effectiveness of the proposed method in reducing the number of feature maps and floating-point operations (FLOPs) while maintaining good accuracy. The authors also provide a detailed analysis of the oracle ranking, which helps to understand the importance of different feature maps and the effectiveness of the proposed criterion.
One of the key strengths of the paper is its thorough evaluation of the proposed method, including comparisons with other pruning criteria and an analysis of the impact of different hyperparameters. The authors also provide a detailed discussion of the limitations of their method and potential avenues for future work.
To improve the paper, I would suggest adding more visualizations, such as plots of the feature maps and their importance scores, to help illustrate the effectiveness of the proposed method. Additionally, the authors could provide more details on the computational cost of their method, including the time and memory requirements for pruning and fine-tuning.
Overall, I would accept this paper, as it presents a well-motivated and thoroughly evaluated approach to pruning CNNs. The proposed method has the potential to be widely applicable and could have a significant impact on the field of computer vision.
Some questions I would like the authors to answer to clarify my understanding of the paper include:
* Can you provide more details on the computational cost of the proposed method, including the time and memory requirements for pruning and fine-tuning?
* How do you select the hyperparameters for the proposed method, such as the learning rate and regularization coefficient?
* Can you provide more visualizations, such as plots of the feature maps and their importance scores, to help illustrate the effectiveness of the proposed method?
* How does the proposed method compare to other pruning methods, such as those based on reinforcement learning or evolutionary algorithms?
* Can you provide more details on the potential applications of the proposed method, including its use in real-time computer vision systems or edge devices?