Summary of the Paper's Contributions
The paper proposes a Neural Knowledge Language Model (NKLM) that combines symbolic knowledge from a knowledge graph with the expressive power of Recurrent Neural Network (RNN) language models. The NKLM predicts whether a word to generate has an underlying fact or not and generates words either from the vocabulary or by copying from the description of the predicted fact. The model is trained on a new dataset, WikiFacts, and significantly improves perplexity while generating a much smaller number of unknown words.
Decision and Reasons
I decide to Accept this paper with two key reasons: (1) the paper provides a well-engineered solution to exploiting sparsity in convolutional layers of a deep network, leading to significant speedups, and (2) the analysis of when this solution is possible is useful for practitioners, providing valuable insights for implementation.
Supporting Arguments
The paper's approach is well-motivated, and the authors provide a clear explanation of the limitations of traditional language models in encoding and decoding factual knowledge. The NKLM model is well-designed, and the authors provide a detailed description of the model's architecture and training procedure. The experimental results demonstrate the effectiveness of the NKLM model in improving perplexity and generating named entities.
Additional Feedback
To improve the paper, I suggest that the authors provide more analysis on the computational complexity of the NKLM model and its scalability to larger datasets. Additionally, the authors could explore the application of the NKLM model to other knowledge-related language tasks, such as question answering and dialogue modeling.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. How do the authors plan to extend the NKLM model to handle more complex knowledge graphs and larger datasets?
2. Can the authors provide more details on the WikiFacts dataset, including the size of the dataset and the process of aligning Wikipedia descriptions with Freebase facts?
3. How do the authors evaluate the performance of the NKLM model in terms of reasoning and adapting to changes in knowledge?