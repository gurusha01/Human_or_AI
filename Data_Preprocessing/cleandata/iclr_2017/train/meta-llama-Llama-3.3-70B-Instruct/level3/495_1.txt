This paper explores the representational power of deep vs shallow neural networks with ReLU and threshold units, showing that deeper networks can approximate functions with much less units. The authors present an interesting combination of tools and arrive at a nice result on the exponential superiority of depth in neural networks. 
I decide to accept this paper with two key reasons for this choice. Firstly, the paper tackles a specific question of what kind of design choices should be made to fully utilize the representational power of existing models for instance-level image retrieval. Secondly, the approach is well-motivated and well-placed in the literature, with the authors conducting extensive experiments to evaluate the impact of five factors on the performances of image retrieval.
The paper supports its claims with correct and scientifically rigorous results, both theoretical and empirical. The authors evaluate the impact of different factors such as feature aggregation and normalization, output layer selection, image resizing, multi-scale feature representation, and PCA and whitening on the retrieval performances. They also propose a new multi-scale image representation method and show that it outperforms state-of-the-art methods on four datasets.
To improve the paper, I suggest clarifying certain points, such as the comment on L, and advertising the main result more prominently in the introduction. Additionally, the authors could include a reference to a related paper by Montufar et al. to provide a more comprehensive overview of the topic. There are also several minor errors in the paper, including typos in Lemma 3, Theorem 4, and Theorem 11, which need to be corrected for accuracy and clarity.
I would like the authors to answer the following questions to clarify my understanding of the paper: How do the authors plan to address the limitation of their main result, which only addresses strongly convex univariate functions? Can they provide more details on the network transformations and the overlap in each scale? How do the authors think their method can be applied to other tasks beyond instance-level image retrieval?