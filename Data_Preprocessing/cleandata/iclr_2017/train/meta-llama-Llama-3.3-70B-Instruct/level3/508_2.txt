This paper proposes a novel approach to learning symmetric and asymmetric encryption using neural networks. The authors demonstrate that neural networks can learn to protect communications without being prescribed a particular set of cryptographic algorithms. The approach involves training neural networks to communicate securely by minimizing a loss function that reflects the goals of the participants in the system.
The paper tackles the specific question of whether neural networks can learn to use secret keys to protect information from other neural networks. The approach is well-motivated, drawing on ideas from cryptography and machine learning, and is placed within the context of existing research on adversarial training and generative models.
However, despite the technical contribution of the paper, I must reject it due to the need for significant cleanup and clarification of the presentation. The writing is often unclear and poorly structured, making it difficult to understand the proposed approach and its components. I have several unanswered questions about the paper, including the specifics of the neural network architecture, the dimensionalities of the representations, and the motivation behind certain choices.
To improve the paper, I would suggest that the authors provide a clearer and more concise explanation of their approach, including a detailed description of the neural network architecture and the training procedure. Additionally, the authors should provide more empirical evidence to support their claims, including results on larger datasets and more complex tasks.
Some specific questions I would like the authors to answer include:
* Can you provide a more detailed description of the neural network architecture used in the experiments, including the number of layers, the number of units in each layer, and the activation functions used?
* How did you choose the hyperparameters for the training procedure, such as the learning rate and the minibatch size?
* Can you provide more results on the robustness of the trained models to different types of attacks, such as adversarial examples and side-channel attacks?
Overall, while the paper presents an interesting and novel approach to learning encryption using neural networks, it requires significant revision and clarification to be considered for acceptance.