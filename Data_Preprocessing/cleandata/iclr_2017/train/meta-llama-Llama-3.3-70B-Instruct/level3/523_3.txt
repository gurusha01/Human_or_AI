This paper proposes a novel approach to generating transferable adversarial examples for deep neural networks, with a focus on both non-targeted and targeted attacks. The authors conduct an extensive study on the transferability of adversarial examples over large models and a large-scale dataset, ImageNet. They evaluate the effectiveness of various approaches, including optimization-based, fast gradient sign, and fast gradient methods, and propose a new ensemble-based approach that generates adversarial examples for multiple models simultaneously.
The paper claims to contribute to the understanding of transferable adversarial examples in several ways. Firstly, it demonstrates that non-targeted adversarial examples can transfer well among different models, even when the models have different architectures. Secondly, it shows that targeted adversarial examples generated using existing approaches rarely transfer, but the proposed ensemble-based approach can generate targeted adversarial examples with high transferability. Finally, the paper provides geometric insights into the decision boundaries of different models, which helps to understand why adversarial examples can transfer.
Based on the conference guidelines, I will answer the three key questions to make a decision to Accept or Reject.
1. What is the specific question/problem tackled by the paper?
The paper tackles the problem of generating transferable adversarial examples for deep neural networks, with a focus on both non-targeted and targeted attacks.
2. Is the approach well motivated, including being well-placed in the literature?
The approach is well-motivated, and the paper provides a thorough review of the existing literature on adversarial examples and transferability. The authors clearly explain the limitations of existing approaches and propose a novel ensemble-based approach to address these limitations.
3. Does the paper support the claims?
The paper provides extensive experimental results to support its claims. The authors evaluate their approach on a large-scale dataset, ImageNet, and demonstrate the effectiveness of their approach in generating transferable adversarial examples. They also provide geometric insights into the decision boundaries of different models, which helps to understand why adversarial examples can transfer.
Based on these questions, I decide to Accept this paper. The paper provides a thorough and well-motivated approach to generating transferable adversarial examples, and the experimental results support the claims made by the authors.
However, I do have some minor comments and suggestions to improve the paper. Firstly, the notation used in the paper could be improved for better clarity. Secondly, the paper could benefit from more detailed explanations of the geometric insights and decision boundaries of different models. Finally, the authors could provide more examples of targeted adversarial examples that transfer to Clarifai.com, to demonstrate the effectiveness of their approach in a real-world setting.
Some questions I would like the authors to answer to clarify my understanding of the paper include:
* Can the authors provide more details on how they chose the hyperparameters for their ensemble-based approach?
* How do the authors plan to extend their approach to other types of deep neural networks, such as recurrent neural networks or generative adversarial networks?
* Can the authors provide more insights into the geometric properties of the decision boundaries of different models, and how these properties relate to the transferability of adversarial examples?