Summary
The paper proposes a novel approach to question classification by introducing Group Sparse Autoencoders (GSA) and Group Sparse Convolutional Neural Networks (GSCNNs). The authors argue that traditional question classification techniques do not fully utilize the potential of answer data, which can improve question representation and lead to better classification performance. The proposed model combines the strengths of latent variable models and auto-regressive models, and the experimental results show significant improvements over strong baselines on four datasets.
Decision
I decide to accept this paper, with the main reason being that the approach is well-motivated and the experimental results are promising. Although the paper may not represent a significant breakthrough in the field, it provides a new perspective on question classification and demonstrates the potential of incorporating answer data into the classification process.
Supporting Arguments
The paper is well-structured and easy to follow, with a clear introduction to the problem and the proposed approach. The authors provide a thorough discussion of the related work and the motivations behind their approach. The experimental results are convincing, and the comparison with strong baselines demonstrates the effectiveness of the proposed model. The use of visualization techniques to illustrate the learning ability of GSA is also a strength of the paper.
Additional Feedback
To further improve the paper, I suggest that the authors provide more comprehensive evaluations beyond NLL measurements and samples, such as classification tasks. Additionally, it would be helpful to include more details about the implementation and architecture choices of the model, as well as the hyperparameter tuning process. The authors may also consider providing more insights into the interpretability of the results and the potential applications of the proposed approach.
Questions for the Authors
To clarify my understanding of the paper, I would like to ask the authors the following questions:
1. Can you provide more details about the initialization methods for the projection matrix in GSA, and how they affect the performance of the model?
2. How do you plan to extend the proposed approach to other NLP tasks, such as text classification or sentiment analysis?
3. Can you provide more insights into the computational complexity of the proposed model, and how it compares to other state-of-the-art models in the field?