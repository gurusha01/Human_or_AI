The paper proposes a novel approach to learning binary autoencoders by formulating it as a biconvex optimization problem. The authors derive an optimal decoding function that emerges from the minimax loss minimization, which is a single layer of artificial neurons with learned weights. The approach is theoretically convincing and well-written, with a clear motivation and explanation of the methodology.
The experimental study demonstrates competitive results with equivalent fully-connected autoencoders trained with backpropagation. However, the computational cost of the approach is a concern, with the model taking around 5 days to converge, even with downsampling the data. The use of only one sample when computing the gradient may also be a limitation.
To improve the paper, I suggest adding a word-level baseline to the experimental study to provide a more comprehensive comparison. Additionally, exploring the computational bottleneck of the proposed approach and potential optimizations could be beneficial.
The presentation of results in Table 2 could be misleading, as the comparison with other models is not fully accurate. A more detailed analysis of the results and a clearer presentation of the comparisons would be helpful.
Overall, I decide to accept the paper, but with the suggestion to address the above concerns to improve the quality and clarity of the presentation.
To support my decision, I provide the following arguments:
1. The paper tackles a specific question/problem: The paper proposes a novel approach to learning binary autoencoders, which is a well-defined problem in the field of machine learning.
2. The approach is well-motivated: The authors provide a clear motivation for their approach, explaining how it emerges from the minimax loss minimization and how it relates to existing work in the field.
3. The paper supports its claims: The experimental study demonstrates competitive results with equivalent fully-connected autoencoders trained with backpropagation, which supports the authors' claims about the effectiveness of their approach.
To improve the paper, I provide the following feedback:
* Add a word-level baseline to the experimental study to provide a more comprehensive comparison.
* Explore the computational bottleneck of the proposed approach and potential optimizations.
* Provide a more detailed analysis of the results and a clearer presentation of the comparisons in Table 2.
I would like the authors to answer the following questions to clarify my understanding of the paper:
* Can you provide more details on the computational cost of the approach and potential optimizations?
* How do you plan to address the limitation of using only one sample when computing the gradient?
* Can you provide a more detailed analysis of the results in Table 2 and a clearer presentation of the comparisons with other models?