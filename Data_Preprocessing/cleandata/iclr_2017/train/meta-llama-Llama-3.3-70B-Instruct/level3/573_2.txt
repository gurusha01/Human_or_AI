Summary
The paper proposes a setting to learn models that actively seek information to solve tasks and introduces a set of tasks designed for this goal. The authors demonstrate the ability to train agents to solve tasks using deep learning models and reinforcement learning. However, the tasks proposed in the paper lack clear motivation and selection criteria, and the approach may be too simple and limited to toy-ish settings with perfect information.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper lacks clear motivation and selection criteria for the proposed tasks, which makes it difficult to understand the significance and relevance of the research. Secondly, the approach may be too simple and limited to toy-ish settings with perfect information, which reduces the level of noise in more realistic settings.
Supporting Arguments
The paper develops the ability of models to actively seek information, but the tasks are limited to selecting questions from a finite set of clean and informative possibilities. The absence of baselines in the experiments limits the conclusions that can be drawn, and it would be interesting to see how simple baselines, such as frequency-based models, perform on the tasks. Additionally, the paper explores an interesting direction of research, but the analysis of the tasks is limited, and it would be beneficial to focus on human performance, strong simple baselines, and more natural language-related tasks.
Additional Feedback
To improve the paper, I suggest that the authors provide a clearer motivation and selection criteria for the proposed tasks, and consider more realistic settings with noise and uncertainty. Additionally, the authors should include baselines in the experiments to provide a more comprehensive evaluation of the approach. It would also be beneficial to explore more natural language-related tasks and analyze human performance on these tasks to provide a better understanding of the research.
Questions for the Authors
I would like to ask the authors to clarify the motivation and selection criteria for the proposed tasks, and to provide more details on how the tasks distinguish themselves from existing literature, such as games like 20Q. I would also like to know how the authors plan to extend the approach to more realistic settings with noise and uncertainty, and how they plan to evaluate the performance of the approach in these settings. Finally, I would like to ask the authors to provide more details on the experimental setup and the results, including the performance of simple baselines and the analysis of human performance on the tasks.