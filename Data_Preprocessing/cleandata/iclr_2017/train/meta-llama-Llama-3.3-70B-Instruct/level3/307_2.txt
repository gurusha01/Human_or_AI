This paper provides a comprehensive study on the transferability of adversarial examples in deep neural networks, specifically focusing on the limitations of current chatbots and the need for more realistic validation of machine learning applied to dialogs. The authors propose a novel ensemble-based approach to generate transferable adversarial examples, which exhibits better performance than previous work. The paper also explores the geometric properties of different models to better understand transferable adversarial examples.
I decide to accept this paper with two key reasons: (1) the paper tackles a specific and important question in the field of adversarial examples, and (2) the approach is well-motivated and supported by thorough experiments.
The paper supports its claims through extensive experiments on large models and a large-scale dataset, demonstrating the effectiveness of the proposed ensemble-based approach in generating transferable targeted adversarial examples. The results show that the approach can successfully attack a black-box image classification system, Clarifai.com, with a high success rate.
However, I would like to provide some additional feedback to improve the paper. Firstly, the paper could benefit from a more detailed analysis of the geometric properties of different models, particularly in relation to the transferability of adversarial examples. Secondly, the authors could consider exploring the application of their approach to other domains, such as natural language processing, to further demonstrate its effectiveness.
To clarify my understanding of the paper, I would like to ask the authors the following questions: (1) Can you provide more insights into the choice of the ensemble weights in the proposed approach? (2) How do you plan to extend your work to other domains, such as natural language processing, and what challenges do you anticipate in doing so? (3) Can you provide more examples of the targeted adversarial examples generated using the ensemble-based approach and their corresponding results on Clarifai.com? 
Overall, this paper makes a significant contribution to the field of adversarial examples and has the potential to impact the development of more robust and secure machine learning models. With some revisions to address the above feedback and questions, the paper can be even stronger and more impactful.