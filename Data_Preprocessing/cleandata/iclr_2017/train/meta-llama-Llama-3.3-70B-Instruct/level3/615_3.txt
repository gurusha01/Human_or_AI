Summary
The paper proposes a novel loss framework for language modeling, which augments the conventional cross-entropy loss with an additional term that minimizes the KL-divergence between the model's prediction and an estimated target distribution based on the word embeddings space. The authors also theoretically motivate and introduce a second modification to improve learning in the language model, which is reusing the input embedding matrix in the output projection layer. The experiments on the Penn Treebank corpus and Wikitext-2 dataset show that the proposed framework outperforms the conventional one, and that even the simple modification of reusing the word embedding in the output projection layer is sufficient for large networks.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the idea of using SR1 update to optimize saddle points is interesting, but it lacks important comparisons to recent 2nd order optimizations. Secondly, the experiments do not show a clear advantage over AdaDelta/Nag, and more experimentation is needed to support claims about mini-batch insensitivity to performance.
Supporting Arguments
The paper proposes a novel loss framework for language modeling, which is a significant contribution to the field. However, the lack of comparison to recent 2nd order optimizations is a major limitation of the paper. Additionally, the experiments do not provide sufficient evidence to support the claims made by the authors. For example, the results on the Penn Treebank corpus and Wikitext-2 dataset are not consistent, and the authors do not provide a clear explanation for this inconsistency.
Additional Feedback
To improve the paper, the authors should provide more comparisons to recent 2nd order optimizations and conduct more experiments to support their claims. Additionally, the authors should provide more details about the implementation of the proposed framework, such as the hyperparameter settings and the training procedures. The authors should also consider providing more qualitative results, such as examples of generated text, to demonstrate the effectiveness of the proposed framework.
Questions
I would like to ask the authors to clarify the following points:
* How does the proposed framework compare to recent 2nd order optimizations, such as Adam and RMSProp?
* Can the authors provide more details about the implementation of the proposed framework, such as the hyperparameter settings and the training procedures?
* How do the authors plan to address the inconsistency in the results on the Penn Treebank corpus and Wikitext-2 dataset?
* Can the authors provide more qualitative results, such as examples of generated text, to demonstrate the effectiveness of the proposed framework?