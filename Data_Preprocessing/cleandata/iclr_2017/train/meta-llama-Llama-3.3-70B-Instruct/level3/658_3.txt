This paper proposes a novel approach to learning latent Markovian state space models from raw, non-Markovian sequence data, leveraging recent advances in stochastic gradient variational Bayes. The authors introduce Deep Variational Bayes Filters (DVBF), which decouple the dependencies in the predicted space and perform better than existing methods such as Deep Kalman Filters (DKF). The key contribution of this paper is the proposal of a scheme for learning DVBFs, which includes decoding the output embeddings using a Markov Product Network (MPN) and analyzing perfect encoding/decodings.
The paper's main strengths lie in its ability to learn latent spaces that capture the underlying physical quantities of the system, as demonstrated through a series of vision-based experiments. The results show that DVBFs can recover latent states that identify the underlying system dynamics, enabling stable long-term predictions beyond the sequence length used during training.
However, there are some concerns that need to be addressed. Firstly, the paper lacks discriminative structured prediction baselines, which would provide a more comprehensive comparison of the proposed method's performance. Secondly, the relative computation complexity of each method is unclear, making it difficult to assess the practicality of the proposed approach. Lastly, the explanation of why the proposed method works better than alternatives, such as MADE, is not entirely clear and requires further clarification.
To improve the paper, I suggest simplifying the presentation of experiments, such as using a table to compare average results across datasets for the proposed method and competitor methods. This would make it easier to verify the claims made in the paper. Additionally, more details on the relative computation complexity of each method and a clearer explanation of why the proposed method outperforms alternatives would be beneficial.
In terms of the conference guidelines, I would like to ask the authors to clarify the following:
1. What is the specific question or problem that the paper tackles, and how does it relate to the broader field of machine learning?
2. How does the proposed approach compare to existing methods in terms of performance, computational complexity, and interpretability?
3. What are the potential applications and implications of the proposed method, and how can it be used in practice?
Overall, I believe that this paper has the potential to make a significant contribution to the field of machine learning, but it requires some revisions to address the concerns mentioned above. 
Decision: Reject, but encourage resubmission after addressing the concerns mentioned above. 
Reasons for decision: 
1. Lack of discriminative structured prediction baselines
2. Unclear relative computation complexity of each method
3. Need for a clearer explanation of why the proposed method works better than alternatives 
Additional feedback: 
- Simplify the presentation of experiments
- Provide more details on the relative computation complexity of each method
- Clarify why the proposed method outperforms alternatives
- Discuss potential applications and implications of the proposed method 
Questions for the authors: 
1. Can you provide more details on the relative computation complexity of each method?
2. How does the proposed approach compare to existing methods in terms of performance, computational complexity, and interpretability?
3. What are the potential applications and implications of the proposed method, and how can it be used in practice?