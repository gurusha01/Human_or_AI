Summary
The paper proposes a novel approach to domain-invariant representation learning, called Central Moment Discrepancy (CMD), which matches the higher-order central moments of the domain-specific hidden activation distributions. The authors demonstrate that CMD is a metric on the set of probability distributions on a compact interval and that convergence in CMD implies convergence in distribution. The experimental results show that CMD outperforms state-of-the-art methods, including Maximum Mean Discrepancy (MMD) and Domain Adversarial Neural Networks (DANN), on several benchmark datasets.
Decision
I decide to Accept this paper, with two key reasons: (1) the paper proposes a novel and well-motivated approach to domain-invariant representation learning, and (2) the experimental results demonstrate the effectiveness of the proposed method.
Supporting Arguments
The paper is well-written, and the authors provide a clear and concise introduction to the problem of domain-invariant representation learning. The proposed approach, CMD, is well-motivated and theoretically sound, with a clear connection to the concept of moment matching. The experimental results are thorough and demonstrate the effectiveness of CMD on several benchmark datasets, including Amazon reviews and Office. The authors also provide a detailed analysis of the sensitivity of the method to parameter changes, which shows that the method is robust to different settings of the hyperparameters.
Additional Feedback
To further improve the paper, I suggest that the authors provide more insights into the computational complexity of the proposed method, particularly in comparison to other state-of-the-art methods. Additionally, it would be interesting to see more experiments on other datasets and tasks, to further demonstrate the generality and effectiveness of the proposed approach.
Questions for the Authors
I would like to ask the authors to clarify the following points:
* How does the proposed method handle cases where the domain shift is significant, and the source and target distributions are very different?
* Can the authors provide more insights into the choice of the hyperparameter K, and how it affects the performance of the method?
* Are there any plans to extend the proposed method to other tasks, such as image classification or natural language processing?