Summary
The paper proposes a novel Group Sparse Autoencoder (GSA) that enforces sparsity of the hidden representation group-wise, allowing learning of more discriminative, class-specific patterns in the dataset. The authors also introduce a Group Sparse Convolutional Neural Network (GSCNN) that combines the benefits of GSA and CNNs. The proposed model shows significant improvements over strong baselines on four datasets.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the clarity of the paper is low, with questions raised about the usage of group activation for reconstruction and the summation in Equation (7). Secondly, the algorithm's end-to-end trainability is uncertain, with concerns that it may be no more than a standard GSA with pre-trained CNN features as input.
Supporting Arguments
The paper lacks comparison to a suitable baseline model, such as sequential CNN + sparse autoencoder, and requires more control experiments to compare different equations and hyperparameters. Additionally, the results in Figure 3 (b) are not convincing enough to support the claim that GSA learns more group-relevant features, with inconsistencies in the filter visuals. The paper also misses a relevant reference, specifically Shang et al.'s work on discriminative training of structured dictionaries via block orthogonal matching pursuit.
Additional Feedback
To improve the paper, the authors should provide more detailed explanations of the GSA and GSCNN models, including the usage of group activation for reconstruction and the summation in Equation (7). They should also conduct more control experiments to compare different equations and hyperparameters, and provide more convincing results to support their claims. Furthermore, the authors should consider comparing their model to other relevant baseline models, such as autoencoders that combine classification in their objective function.
Questions for the Authors
I would like the authors to answer the following questions to clarify my understanding of the paper and provide additional evidence:
1. Can you provide more detailed explanations of the GSA and GSCNN models, including the usage of group activation for reconstruction and the summation in Equation (7)?
2. How do you ensure the end-to-end trainability of the GSCNN model, and can you provide more experiments to support this claim?
3. Can you provide more convincing results to support the claim that GSA learns more group-relevant features, and address the inconsistencies in the filter visuals in Figure 3 (b)?