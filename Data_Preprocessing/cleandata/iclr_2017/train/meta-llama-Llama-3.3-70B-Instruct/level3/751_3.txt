This paper proposes a novel approach to dialogue agents, where the agent learns to interact with users by asking questions. The authors design a simulator and a set of synthetic tasks in the movie question answering domain, allowing a bot to interact with a teacher to address issues such as question clarification, knowledge operation, and knowledge acquisition. The paper explores both offline supervised and online reinforcement learning settings, demonstrating that the learner improves when asking questions.
I decide to reject this paper, primarily due to two key reasons. Firstly, the paper lacks sufficient context of previous studies in shallow RL, particularly in the field of "robust RL", and could benefit from referencing works like Shie Mannor's. This lack of context makes it difficult to understand the significance and novelty of the proposed approach. Secondly, the problem setup is ill-defined, with concerns about post-hoc labeling of actions as "catastrophic" and evaluating the system with a different metric than it was trained on. This raises questions about the validity and reliability of the results.
The proposed solution is somewhat ad-hoc, introducing new domain-specific hyperparameters and components, which may not be trustworthy due to the simplicity of the cart-pole problem. However, the concept of D_d, a set of rare but dangerous states, is a good idea that the authors should pursue further, as it has potential applications in continual learning. Additionally, the paper's bibliography is incomplete and sloppy, with missing information and incorrect citations, which should be revised to include proper citations and references.
To improve the paper, I suggest that the authors provide more context and background on previous studies in shallow RL and robust RL, and clarify the problem setup and evaluation metrics. They should also consider simplifying the proposed solution and providing more rigorous analysis and evaluation of the results. Furthermore, the authors should ensure that the bibliography is complete and accurate.
I would like the authors to answer the following questions to clarify my understanding of the paper: (1) How do the authors plan to address the lack of context and background on previous studies in shallow RL and robust RL? (2) Can the authors provide more details on the problem setup and evaluation metrics, and how they ensure the validity and reliability of the results? (3) How do the authors plan to simplify the proposed solution and provide more rigorous analysis and evaluation of the results?