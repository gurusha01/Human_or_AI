This paper presents a novel approach to visual servoing, which combines learned visual features, learned predictive dynamics models, and reinforcement learning to learn visual servoing mechanisms. The authors propose a method that uses pre-trained features, obtained from a model trained for object classification, and a bilinear predictive model to learn an effective visual servo that is robust to visual variation, changes in viewing angle and appearance, and occlusions.
The approach is well-motivated, and the authors provide a clear explanation of the problem and the proposed solution. The paper is well-organized, and the authors provide a thorough review of related work in the field. The experimental results demonstrate the effectiveness of the proposed approach, showing substantial improvement over conventional approaches based on image pixels or hand-designed keypoints.
I decide to accept this paper because it presents a novel and well-motivated approach to visual servoing, and the experimental results demonstrate its effectiveness. The paper is well-written, and the authors provide a clear explanation of the proposed method and its advantages.
To further improve the paper, I suggest that the authors provide more comparisons to other state-of-the-art methods in the field, such as deep reinforcement learning algorithms. Additionally, the authors could provide more details on the implementation of the proposed method, such as the specific architecture of the neural networks used and the hyperparameters chosen.
Some questions I would like the authors to answer to clarify my understanding of the paper are:
* How do the authors choose the specific pre-trained features used in the proposed method, and how do they determine the optimal number of features to use?
* Can the authors provide more details on the bilinear predictive model used in the proposed method, and how it is trained?
* How do the authors handle cases where the target object is partially occluded or has varying lighting conditions?
* Can the authors provide more comparisons to other state-of-the-art methods in the field, such as deep reinforcement learning algorithms? 
Overall, this is a well-written paper that presents a novel and effective approach to visual servoing. With some additional comparisons and implementation details, it has the potential to be a strong contribution to the field.