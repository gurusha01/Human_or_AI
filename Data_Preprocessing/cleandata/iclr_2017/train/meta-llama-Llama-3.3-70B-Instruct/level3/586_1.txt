Summary
The paper presents a study on the error surface of deep neural networks, specifically focusing on the case of finite-sized models and datasets. The authors argue that the well-behaved learning dynamics observed in practice may not be a global property of the model, but rather a local one, conditioned on the data structure, initialization, and other architectural choices. They provide theoretical examples and empirical evidence to support this claim, demonstrating that bad initialization and data structure can lead to suboptimal learning dynamics.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper lacks a significant breakthrough in the study of the Neural GPU model, with scattered remarks that don't contribute to substantial progress. Secondly, the claimed improvements to the memory efficiency of Neural GPU are not remarkable and may even slow down training and inference.
Supporting Arguments
The paper's theoretical examples and empirical evidence are interesting, but they do not provide a comprehensive understanding of the error surface of deep neural networks. The authors' claim that the well-behaved learning dynamics are local and conditioned on the data structure, initialization, and other architectural choices is not fully supported by the results. Additionally, the paper's focus on finite-sized models and datasets may not be representative of real-world scenarios, where models and datasets are often much larger.
Additional Feedback
To improve the paper, the authors could provide more comprehensive theoretical analysis and empirical evidence to support their claims. They could also explore the implications of their results for real-world applications and provide more detailed comparisons with existing work. Furthermore, the authors could consider using more advanced optimization techniques and evaluating the performance of their model on a wider range of tasks and datasets.
Questions for the Authors
I would like to ask the authors to clarify the following points:
1. How do the authors plan to extend their results to larger models and datasets, and what implications do they think their findings will have for real-world applications?
2. Can the authors provide more detailed comparisons with existing work on the error surface of deep neural networks, and how do their results relate to the existing literature?
3. How do the authors plan to address the issue of bad initialization, and what strategies do they propose for improving the robustness of neural networks to initialization?