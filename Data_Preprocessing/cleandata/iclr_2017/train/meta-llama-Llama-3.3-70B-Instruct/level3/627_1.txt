Summary of the Paper's Claims and Contributions
The paper proposes a novel approach to dialogue agents, where the agent learns to interact with users by asking questions to improve its language understanding and question-answering ability. The authors design a simulator and a set of synthetic tasks in the movie question-answering domain, allowing the agent to interact with a teacher to address various issues, such as question clarification, knowledge operation, and knowledge acquisition. The paper claims that the agent improves its performance through interacting with users, and this improvement is validated on real data collected via Amazon Mechanical Turk.
Decision and Reasons
I decide to reject this paper, with two key reasons for this choice:
1. Lack of clear contribution to the field: While the paper presents an interesting approach to dialogue agents, it is unclear what specific contribution it makes to the field. The authors do not provide a clear comparison to existing work or demonstrate how their approach improves upon existing methods.
2. Methodological issues: The paper's experimental design and evaluation methodology are not rigorous enough to support the claims made. For example, the authors do not provide sufficient details about the hyperparameter tuning process, and the results are not consistently reported across different tasks and settings.
Supporting Arguments
The paper's approach to dialogue agents is novel, and the authors provide some interesting insights into the benefits of interaction for language understanding. However, the paper's methodology and evaluation are not robust enough to support the claims made. For example, the authors use a simple MemN2N model as the backbone, which may not be the best choice for this task. Additionally, the paper's results are not consistently reported, making it difficult to compare across different tasks and settings.
Additional Feedback and Questions
To improve the paper, I would suggest the following:
* Provide a clearer comparison to existing work in the field, highlighting the specific contributions of this paper.
* Improve the experimental design and evaluation methodology, including more rigorous hyperparameter tuning and consistent reporting of results.
* Consider using more advanced models, such as transformers or graph-based models, which may be better suited to this task.
* Provide more detailed analysis of the results, including error analysis and discussion of the limitations of the approach.
Some questions I would like the authors to answer to clarify my understanding of the paper include:
* How do the authors plan to address the issue of overfitting, given the relatively small size of the training dataset?
* Can the authors provide more details about the hyperparameter tuning process, including the specific hyperparameters tuned and the ranges of values considered?
* How do the authors plan to extend this work to more complex dialogue tasks, such as multi-turn conversations or tasks that require more nuanced understanding of language?