Summary
The paper proposes a novel method called Differentiable Canonical Correlation Analysis (DCCA), which enables the computation of canonical correlation analysis as a fully differentiable neural network layer. This allows for parameter optimization via back-propagation through the CCA projection matrices, making it a useful building block for multi-modality tasks. The authors demonstrate the effectiveness of this approach in cross-modality retrieval experiments on two public image-to-text datasets, surpassing both Deep CCA and a multi-view network with freely-learned projections.
Decision
I decide to Accept this paper, with the main reason being that the approach is well-motivated and well-placed in the literature. The authors provide a clear and concise explanation of the methodology and demonstrate its effectiveness in experiments.
Supporting Arguments
The paper tackles a specific question of how to extend Canonical Correlation Analysis to a fully differentiable neural network layer, which is a well-defined problem. The approach is well-motivated, as it allows for parameter optimization via back-propagation, making it a useful tool for multi-modality tasks. The authors provide a clear and concise explanation of the methodology, including the gradient computation and stochastic optimization. The experimental results demonstrate the effectiveness of the approach, showing improved retrieval performance compared to Deep CCA and a multi-view network with freely-learned projections.
Additional Feedback
To further improve the paper, I suggest that the authors provide more quantitative results, such as extracting adversarial examples at different layers and comparing network performance. Additionally, the authors could provide more details on the optimization settings and hyperparameter tuning, as well as more analysis on the learned representations. I would like the authors to answer the following questions: (1) How do the authors plan to extend this work to other multi-modality tasks? (2) Can the authors provide more insights into the learned representations and how they differ from those learned by Deep CCA? (3) How do the authors plan to address the potential limitations of the approach, such as the requirement for large batch sizes? 
Questions for Authors
1. How do the authors plan to extend this work to other multi-modality tasks, such as speech recognition or natural language processing?
2. Can the authors provide more insights into the learned representations and how they differ from those learned by Deep CCA?
3. How do the authors plan to address the potential limitations of the approach, such as the requirement for large batch sizes?