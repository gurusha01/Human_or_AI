Summary of the Paper's Contributions
The paper provides a thorough evaluation of the factors that impact the discriminative ability of features extracted from convolutional neural networks (CNNs) for instance-level image retrieval. The authors identify five key factors: feature aggregation and normalization, output layer selection, image resizing, multi-scale feature representation, and PCA and whitening. They conduct extensive experiments to analyze the impact of these factors on retrieval performance and propose a new multi-scale image representation method that outperforms state-of-the-art methods on four datasets.
Decision and Reasons
Based on the review, I decide to Accept this paper. The two key reasons for this choice are:
1. The paper tackles a specific and well-defined problem in the field of computer vision, namely, instance-level image retrieval using CNNs. The authors provide a clear and concise overview of the problem and its significance.
2. The approach is well-motivated, and the authors provide a thorough analysis of the factors that impact the performance of CNNs for image retrieval. The experimental results are convincing, and the proposed method shows significant improvements over state-of-the-art methods.
Supporting Arguments
The paper provides a comprehensive evaluation of the factors that affect the performance of CNNs for image retrieval. The authors' analysis of the impact of feature aggregation and normalization, output layer selection, image resizing, multi-scale feature representation, and PCA and whitening is thorough and well-supported by experimental results. The proposed multi-scale image representation method is well-designed, and the experimental results demonstrate its effectiveness.
Additional Feedback and Questions
To further improve the paper, I suggest that the authors provide more details on the computational cost of their proposed method and compare it with other state-of-the-art methods. Additionally, it would be interesting to see how the proposed method performs on other datasets and tasks, such as object detection and image classification.
I would like the authors to answer the following questions to clarify my understanding of the paper:
* Can you provide more details on the network transformations used in the paper, specifically the changes made to the fully-connected layers?
* How did you determine the optimal number of scales for the multi-scale feature representation, and what is the intuition behind the choice of 4 scales?
* Can you provide more insights into the impact of PCA and whitening on the performance of the proposed method, and why learning the PCA and whitening matrix from a different dataset can lead to improved performance?