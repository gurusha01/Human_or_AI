Summary
The paper proposes multiple approaches to improve the performance of gradient descent when utilizing multiple compute resources. The authors present a new approach, asynchronous layer-wise gradient descent, which maximizes the overlap of layer-wise backpropagation with gradient synchronization. They implement their approaches using Caffe and evaluate them on both an Intel Sandy Bridge cluster and an NVIDIA DGX-1 system. The results show that delaying gradient updates by one or more iterations is the most effective means of hiding communication latency, achieving a speedup of up to 1.7x compared to synchronous gradient descent.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper's novelty is somewhat limited due to the existing implementation of similar techniques in other solutions, such as TensorFlow and MXNet. Secondly, the experiments could be improved to better demonstrate the advantages of the proposed delayed SyncSGD approach, particularly in terms of convergence accuracy and full convergence curves for all compared networks.
Supporting Arguments
The paper's manual implementation of delayed synchronization and state protection is helpful, but could be improved by using a dependency scheduler. The overlap of computation and communication is not a novel contribution, as it has been implemented in existing solutions. The convergence accuracy reporting is limited, only covering initial iterations and AlexNet, and should be expanded to include full convergence curves for all compared networks. The paper's evaluation indicates the efficacy of the proposed approach, but the results are not sufficient to demonstrate the advantages of the proposed approach over existing solutions.
Additional Feedback
To improve the paper, the authors could consider using a dependency scheduler to improve the implementation of delayed synchronization and state protection. They could also provide more detailed convergence accuracy reporting, including full convergence curves for all compared networks. Additionally, the authors could compare their approach to other existing solutions, such as TensorFlow and MXNet, to demonstrate the advantages of their proposed approach.
Questions for the Authors
I would like to ask the authors to clarify the following points:
* How does the proposed approach compare to other existing solutions, such as TensorFlow and MXNet, in terms of convergence accuracy and speedup?
* Can the authors provide more detailed convergence accuracy reporting, including full convergence curves for all compared networks?
* How does the proposed approach handle the tradeoff between maintaining equivalence to sequential methods and leveraging computational resources, and what are the implications for the accuracy of the model?