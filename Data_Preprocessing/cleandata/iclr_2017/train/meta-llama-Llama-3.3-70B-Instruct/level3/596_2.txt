Summary
The paper proposes a novel pruning method, NoiseOut, which reduces the number of parameters in neural networks by removing neurons with correlated activations during training. The authors introduce an innovative approach to encourage correlation between neurons by adding noise outputs to the network, resulting in more efficient pruning. The method is tested on various networks and datasets, achieving significant compression rates without loss of accuracy.
Decision
I decide to Accept this paper, with the primary reason being the innovative approach to pruning neural networks and the impressive experimental results. The paper provides a clear and well-motivated methodology, and the authors demonstrate the effectiveness of their approach on various benchmarks.
Supporting Arguments
The paper tackles a specific and relevant problem in the field of neural networks, namely reducing the number of parameters to improve efficiency. The approach is well-motivated, and the authors provide a clear explanation of the methodology. The experimental results are impressive, with significant compression rates achieved without loss of accuracy. The paper also provides a thorough analysis of the effect of NoiseOut on test accuracy and its relation to dropout and regularization.
Additional Feedback
To further improve the paper, I suggest the authors provide more analysis on the performance of NoiseOut without the noise outputs and with varying parameters. Additionally, it would be beneficial to test the model on larger and more modern benchmarks, as the current benchmarks may be outdated. I would also like to see more discussion on the potential applications of NoiseOut in real-world scenarios.
Questions for the Authors
1. Can you provide more insight into how the noise outputs affect the correlation between neurons, and how this correlation changes with different types of noise distributions?
2. How does the choice of hyperparameters, such as the number of noise outputs and the threshold for pruning, affect the performance of NoiseOut?
3. Can you provide more details on the computational resources required for NoiseOut, and how it compares to other pruning methods in terms of efficiency?