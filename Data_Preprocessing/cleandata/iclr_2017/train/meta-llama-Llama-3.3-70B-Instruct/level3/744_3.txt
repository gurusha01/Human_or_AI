Summary
The paper proposes a novel attention-based framework for sentiment analysis, which incorporates local contexts with a global context attention. The model is inspired by human reading behavior and consists of two parts: a bidirectional LSTM (Bi-LSTM) network to extract a global context representation, and another Bi-LSTM network with attention to learn local contexts and composite them using the global context attention. The authors also propose a simplified version of the model, called Single-Scan Approach with Attention (SS-ATT), which uses only one Bi-LSTM network to improve global and local context representation mutually.
Decision
I decide to reject this paper, with two key reasons: (1) the experimental validation of the approach is weak due to limited reported performances and a small number of large-scale experiments, and (2) the introduced SDI metric is not well-supported by the experimental evidence, with mostly small and consistent values across layers.
Supporting Arguments
The paper proposes an interesting and well-motivated approach to sentiment analysis, and the authors provide a clear and detailed description of the model and its components. However, the experimental evaluation of the approach is limited to three benchmark datasets, and the results are not consistently better than the baseline models. Additionally, the authors do not provide a thorough analysis of the learned attention weights and their impact on the model's performance.
Additional Feedback
To improve the paper, the authors should provide more extensive experimental evaluations, including larger-scale experiments and more detailed analyses of the attention weights and their impact on the model's performance. Additionally, the authors should consider using more advanced evaluation metrics, such as precision, recall, and F1-score, to provide a more comprehensive assessment of the model's performance.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
* Can you provide more details on the hyperparameter tuning process and the selection of the optimal hyperparameters for the model?
* How do you plan to extend the model to handle more complex sentiment analysis tasks, such as aspect-level sentiment analysis or sentiment analysis in multi-domain settings?
* Can you provide more insights into the learned attention weights and their impact on the model's performance, including visualizations and quantitative analyses?