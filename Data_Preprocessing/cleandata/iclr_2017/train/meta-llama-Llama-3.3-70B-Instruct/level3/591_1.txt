Summary
The paper proposes a new concept called sample importance to study the impact of samples during deep neural network training. The authors define sample importance as the change in parameters induced by a sample and explore its evolution during training on MNIST and CIFAR datasets. They find that easy samples shape parameters closer to the output, while hard samples impact parameters closer to the input. The authors also investigate the effect of batch construction on training and conclude that mixing hard and easy samples in each batch is beneficial.
Decision
I decide to reject this paper, mainly due to two key reasons: (1) the definition of sample importance is unclear and strangely scaled by the learning rate, and (2) the results on CIFAR are very poor, with a 50% error rate, which discredits the applicability of the results.
Supporting Arguments
The paper's definition of sample importance is not well-motivated, and its scaling by the learning rate is unclear. This lack of clarity makes it difficult to understand the significance of the results. Furthermore, the poor performance on CIFAR, a relatively simple dataset, raises concerns about the effectiveness of the proposed approach. The paper's conclusions, such as the importance of mixing hard and easy samples in each batch, are not sufficiently supported by the results.
Additional Feedback
To improve the paper, the authors should provide a clearer definition of sample importance and motivate its use in the context of deep neural networks. They should also conduct more extensive experiments on various datasets to demonstrate the applicability of their approach. Additionally, the authors should consider using more robust evaluation metrics and provide a more detailed analysis of the results.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide a more intuitive explanation of the sample importance definition and its scaling by the learning rate?
2. How do you plan to address the poor performance on CIFAR, and what modifications to the approach do you think are necessary to improve the results?
3. Can you provide more details on the experimental setup and the hyperparameter tuning process to ensure the results are reproducible?