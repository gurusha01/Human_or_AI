Summary
The paper proposes a novel approach to sequence generation using a physiologically plausible model of handwriting as a feature representation for recurrent mixture density networks. The authors build on previous work in handwriting prediction and introduce a modular workflow that can be exploited for various applications, including learning from small datasets and mixing styles. The system consists of two main components: a virtual target prediction model (V2V) and a dynamic parameter prediction model (V2D and A2D). The authors demonstrate the effectiveness of their approach through various experiments, including predicting virtual targets, dynamic parameters, and user-defined virtual targets.
Decision
I decide to accept this paper, with the main reason being the originality and inventiveness of the proposed method. The paper presents a well-motivated approach that tackles a specific problem in sequence generation, and the authors provide a clear and detailed explanation of their methodology.
Supporting Arguments
The paper's strengths include its ability to learn from small datasets, mix styles, and generate resolution-independent outputs. The authors also provide a thorough analysis of their results, including visualizations and comparisons with baseline models. Additionally, the paper's modular workflow allows for various applications, making it a valuable contribution to the field.
However, I do have some concerns regarding the fairness of comparison with baseline models, as the hyperparameter tuning process is not clearly explained. Furthermore, the paper lacks wall time measurements to support the claim of computational efficiency, which makes me skeptical about the actual computational gains.
Additional Feedback
To improve the paper, I suggest that the authors provide more details on the hyperparameter tuning process and include wall time measurements to support their claims. Additionally, the authors could consider providing more analysis on the interpretability of their results and the potential applications of their approach in real-world scenarios.
Questions for the Authors
1. Can you provide more details on the hyperparameter tuning process and how you selected the optimal hyperparameters for your models?
2. How do you plan to address the issue of computational efficiency, and can you provide more insights into the wall time measurements for your approach?
3. Can you provide more analysis on the interpretability of your results and how they can be applied in real-world scenarios, such as text-to-handwriting synthesis or handwriting recognition?