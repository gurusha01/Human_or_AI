Summary
The paper proposes a novel method for finding dependent subspaces across multiple views, preserving neighborhood relationships of data. The method directly maximizes the between-view similarity of neighborhoods of data samples, a natural measure for similarity of data relationships among the views. The authors demonstrate the effectiveness of their method on various datasets, including artificial and real-world data, and show that it outperforms existing methods such as CCA and LPCCA.
Decision
I decide to accept this paper, with the main reason being that it presents a well-motivated and novel approach to finding dependent subspaces across multiple views. The paper provides a clear and detailed explanation of the method, and the experiments demonstrate its effectiveness in various scenarios.
Supporting Arguments
The paper's strengths include a simple and intuitive formulation of the problem, a well-designed objective function, and a thorough evaluation of the method on various datasets. The authors also provide a clear and detailed explanation of the method, making it easy to understand and implement. The experiments demonstrate the effectiveness of the method in finding dependent subspaces, and the results are promising.
Additional Feedback
To further improve the paper, I suggest that the authors provide more detailed derivations of the objective function and the optimization technique used. Additionally, it would be helpful to include more comparisons with other existing methods, such as nonlinear CCA variants, to demonstrate the superiority of the proposed method. Furthermore, the authors could consider providing more insights into the interpretation of the results, and discussing potential applications of the method in real-world scenarios.
Questions for the Authors
I would like to ask the authors to clarify the following points:
1. How did you choose the parameters for the optimization technique, such as the learning rate and the number of iterations?
2. Can you provide more details on the computational complexity of the method, and how it scales with the size of the dataset?
3. How do you plan to extend the method to handle nonlinear transformations, and what are the potential challenges and limitations of such an extension?