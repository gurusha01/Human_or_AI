This paper proposes a novel approach for learning visual servoing based on Q-iteration, which combines learned visual features, learned predictive dynamics models, and reinforcement learning. The main contributions of the paper include a bilinear dynamics model, Q-function formulation, and optimization of the Bellman error. The authors explore different ways to connect action and frame representation to predict next frame features, arguing in favor of a locally connected bilinear model.
The paper's technical novelty and problem formulations are solid, and the idea of weighting different channels to capture object importance is effective. The optimization scheme for solving the Bellman error is also considered solid. However, the lack of experimental results comparing different approaches, such as fully connected, convolutional, and locally connected dynamics, is a significant limitation. The experimental results presented are unsatisfying due to their small scale and toy simulations, although the lack of benchmarks in the domain is acknowledged.
To improve the paper, I suggest that the authors conduct stronger experiments, including comparisons between FQI and iterative approaches, and validation of the modified VGG architecture. Additionally, the authors could provide more details on the training process, such as the number of iterations, batch size, and learning rate, to facilitate reproducibility.
Based on the conference guidelines, I would answer the three key questions as follows:
1. What is the specific question/problem tackled by the paper? The paper tackles the problem of learning visual servoing mechanisms using learned visual features, learned predictive dynamics models, and reinforcement learning.
2. Is the approach well motivated, including being well-placed in the literature? The approach is well-motivated, and the authors provide a clear overview of the related work in visual servoing and reinforcement learning.
3. Does the paper support the claims? The paper provides some experimental results to support the claims, but the results are limited, and more comprehensive experiments are needed to fully validate the approach.
Overall, I would reject the paper in its current form due to the lack of comprehensive experimental results and the limited scale of the simulations. However, with additional experiments and more detailed descriptions of the training process, the paper has the potential to be a strong contribution to the field.
To help improve the paper, I would like the authors to answer the following questions:
* Can you provide more details on the training process, such as the number of iterations, batch size, and learning rate?
* How do you plan to address the lack of comprehensive experimental results and the limited scale of the simulations?
* Can you provide more comparisons between different approaches, such as fully connected, convolutional, and locally connected dynamics?
* How do you plan to validate the modified VGG architecture and the Q-function formulation?