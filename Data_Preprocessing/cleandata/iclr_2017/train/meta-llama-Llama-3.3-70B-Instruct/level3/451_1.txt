Summary of the Paper's Claims and Contributions
The paper studies the loss surface of deep neural networks, focusing on the conditions that prevent the existence of bad local minima. The authors provide theoretical results that quantify the amount of uphill climbing required to progress to lower energy configurations in single hidden-layer ReLU networks. They also introduce a dynamic programming algorithm to efficiently approximate geodesics within each level set, providing a tool to verify the connectedness of level sets and estimate their geometric regularity.
Decision and Key Reasons
I decide to reject this paper, with the key reasons being:
1. Unconvincing Theoretical Claims: The paper's theoretical claims, particularly Theorem 2.4, lack intuitive explanations, making it difficult to verify their correctness. The proof of Theorem 2.4 is lengthy and relies on several technical assumptions, which may not be immediately clear to readers.
2. Poor Writing and Formatting: The paper's writing and formatting are subpar, with some sections being overly technical and others lacking clarity. This makes it challenging to follow the authors' arguments and understand the significance of their contributions.
Supporting Arguments
1. Incremental and Unclear Results: The results presented in the paper are considered incremental and unclear, with similar results having already been published in the literature. The authors' contributions do not significantly advance the state-of-the-art in the field.
2. Weak Experimental Section: The paper's experimental section is weak, with the algorithm's performance being evaluated on a limited set of tasks and datasets. The results do not provide conclusive evidence for the effectiveness of the proposed approach.
3. Lack of Clear Motivation: The paper does not provide a clear motivation for the research, and the authors' goals are not well-defined. This makes it difficult to understand the significance of the paper's contributions and their potential impact on the field.
Additional Feedback and Suggestions
To improve the paper, I suggest the following:
1. Clarify Theoretical Claims: Provide more intuitive explanations for the theoretical claims, particularly Theorem 2.4. Break down the proof into smaller, more manageable sections, and highlight the key insights and assumptions.
2. Improve Writing and Formatting: Revise the paper to improve its clarity, coherence, and overall readability. Use clear and concise language, and ensure that the formatting is consistent throughout the paper.
3. Strengthen Experimental Section: Expand the experimental section to include a more comprehensive evaluation of the algorithm's performance on a variety of tasks and datasets. Provide more detailed analysis and discussion of the results, and highlight the strengths and limitations of the proposed approach.
4. Provide Clear Motivation: Clearly define the research goals and motivations, and provide a concise overview of the paper's contributions and their potential impact on the field.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence for my assessment, I would like the authors to answer the following questions:
1. Can you provide a more intuitive explanation for Theorem 2.4 and its significance in the context of deep neural networks?
2. How do you respond to the criticism that the paper's results are incremental and unclear, and that similar results have already been published in the literature?
3. Can you provide more details on the experimental setup and the datasets used to evaluate the algorithm's performance?
4. How do you plan to address the limitations of the proposed approach, particularly with regards to its scalability and applicability to more complex tasks and datasets?