Summary of the Paper's Contributions
The paper proposes a novel neural network architecture called Attentive Recurrent Comparators (ARCs) that learns to estimate the similarity of a set of objects by cycling through them and making observations. The model uses attention and recurrence to focus on salient aspects of the objects and condition new observations on previous context. The authors demonstrate the effectiveness of ARCs on various visual tasks, including one-shot learning on the Omniglot dataset, where they achieve state-of-the-art performance surpassing human performance.
Decision and Key Reasons
I decide to accept this paper with minor revisions. The two key reasons for this choice are: (1) the paper proposes a novel and well-motivated architecture that addresses a fundamental problem in machine learning, and (2) the authors provide extensive experimental evaluations that demonstrate the effectiveness of their approach.
Supporting Arguments
The paper is well-written, and the authors provide a clear and concise explanation of their architecture and its motivations. The use of attention and recurrence to model the comparison process is innovative and well-justified. The experimental evaluations are thorough and demonstrate the superiority of ARCs over existing approaches, including Siamese neural networks and Hierarchical Bayesian Program Learning (HBPL). The results on the Omniglot dataset are particularly impressive, with ARCs achieving a 2-3x reduction in error rate compared to previous state-of-the-art models.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the training process, including the optimization algorithm used, the learning rate schedule, and the batch size. Additionally, it would be helpful to include more visualizations of the attention mechanisms and the recurrent core to provide a better understanding of how the model works. Finally, the authors may want to consider exploring the application of ARCs to other domains, such as natural language processing or speech recognition, to demonstrate the generality of their approach.
Questions for the Authors
1. Can you provide more details on the computational cost of ARCs compared to other approaches, and how this cost scales with the size of the input data?
2. How do you plan to extend ARCs to more complex tasks, such as multi-object comparison or scene understanding?
3. Have you considered using other attention mechanisms, such as hard attention or graph-based attention, and how do they compare to the soft attention mechanism used in ARCs?