This paper proposes a novel approach to sampling from generative autoencoders by formulating a Markov chain Monte Carlo (MCMC) process. The authors argue that the traditional approach of sampling from the prior distribution can lead to suboptimal results, and instead propose to sample from the learned latent distribution, which can be achieved through MCMC sampling. The paper also extends this approach to denoising generative autoencoders and demonstrates its effectiveness in improving the quality of generated samples.
I decide to accept this paper, with two key reasons for this choice. Firstly, the paper proposes a unified framework for evaluating novelty generation models by repurposing existing generative model evaluation metrics, which is a valuable contribution to the field. Secondly, the experimental results demonstrate the effectiveness of the proposed MCMC sampling process in improving the quality of generated samples, particularly when combined with denoising generative autoencoders.
The paper's approach is well-motivated, and the authors provide a clear and concise overview of the background and related work. The theoretical sections are sound, and the experimental results are convincing. However, the paper's writing and organization could be improved to make it more accessible and digestible for readers, particularly those outside the sub-field of novelty generation.
To improve the paper, I suggest that the authors provide more concrete examples and illustrations to help readers understand the theoretical concepts and the MCMC sampling process. Additionally, the authors could consider including more detailed descriptions of the experimental setup and the evaluation metrics used to assess the quality of the generated samples.
I would like the authors to answer the following questions to clarify my understanding of the paper: (1) How do the authors choose the number of iterations for the MCMC sampling process, and what is the effect of this choice on the quality of the generated samples? (2) Can the authors provide more insights into the relationship between the learned latent distribution and the prior distribution, and how this relationship affects the quality of the generated samples? (3) How do the authors plan to extend this work to more complex datasets and models, and what are the potential challenges and limitations of this approach?