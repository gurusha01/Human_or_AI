This paper proposes a novel approach to distributed training of deep learning models, addressing the weaknesses of both synchronous and asynchronous stochastic optimization methods. The authors introduce a synchronous optimization method with backup workers, which mitigates the straggler effect while avoiding gradient staleness. The approach is empirically validated on several datasets, including ImageNet and CIFAR-10, and demonstrates faster convergence and better test accuracies compared to asynchronous training.
I decide to accept this paper, with two key reasons for this choice. Firstly, the paper tackles a specific and important problem in distributed deep learning, and the proposed approach is well-motivated and grounded in the literature. Secondly, the empirical evaluation is thorough and convincing, demonstrating the effectiveness of the proposed method on multiple datasets and models.
The paper provides a clear and detailed explanation of the proposed approach, including the use of backup workers to mitigate stragglers. The authors also provide a comprehensive analysis of the trade-offs between synchronous and asynchronous optimization, and demonstrate the benefits of their approach in terms of convergence speed and test accuracy. The empirical evaluation is well-designed and includes a range of experiments on different datasets and models, providing strong evidence for the effectiveness of the proposed method.
To further improve the paper, I suggest that the authors consider comparing their approach to other methods, such as hypercolumns, which may provide additional insights into the strengths and weaknesses of their approach. Additionally, the authors may want to provide more details on the implementation of their method, including the specific hardware and software configurations used in their experiments.
I would like to ask the authors to clarify a few points in their paper. Firstly, how do the authors select the number of backup workers, and what is the impact of this choice on the performance of the proposed method? Secondly, how do the authors handle the case where the number of workers is large, and the communication overhead becomes significant? Finally, what are the potential limitations of the proposed approach, and how do the authors plan to address these limitations in future work?