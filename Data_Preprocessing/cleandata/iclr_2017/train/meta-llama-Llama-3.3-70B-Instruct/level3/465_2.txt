This paper presents an extensive study on the transferability of adversarial examples in image classification, exploring both non-targeted and targeted attacks on large models and a large-scale dataset. The authors propose a novel ensemble-based approach to generate targeted adversarial examples, which improves the success rate of transferable attacks. The paper also provides insights into the geometric properties of different models, shedding light on why adversarial examples can transfer between models.
I decide to Reject this paper, with two key reasons for this choice. Firstly, the paper treats correlated ResNet-based networks as separate entities, which may lead to an overestimation of the transferability of adversarial examples. Secondly, the paper uses a subjective measure to evaluate the effectiveness of attacks on the black-box system Clarifai.com, which may not provide a comprehensive understanding of the attack's success.
To support these reasons, the paper's results show that non-targeted adversarial examples can transfer easily, even between different architectures, but the transferability of targeted adversarial examples is more challenging to achieve. The proposed ensemble-based approach improves the success rate of targeted attacks, but the success rate is still limited to around 20% on Clarifai.com. Furthermore, the paper's use of a subjective measure to evaluate the attack's success on Clarifai.com may not provide a reliable assessment of the attack's effectiveness.
To improve the paper, I suggest that the authors consider the following feedback: (1) provide a more rigorous evaluation of the transferability of adversarial examples between correlated models, and (2) use a more objective measure to evaluate the effectiveness of attacks on black-box systems. Additionally, the authors could provide more discussions on the optimization method used in the study and its potential impact on the results.
I would like the authors to answer the following questions to clarify my understanding of the paper: (1) How do the authors plan to address the issue of correlated models in future work? (2) Can the authors provide more details on the subjective measure used to evaluate the attack's success on Clarifai.com? (3) How do the authors think the optimization method used in the study affects the results, and are there any plans to explore alternative optimization methods?