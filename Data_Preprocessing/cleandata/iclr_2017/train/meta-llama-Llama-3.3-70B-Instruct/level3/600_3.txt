Summary
The paper proposes a multi-view approach to learning acoustic word embeddings, where both acoustic sequences and their corresponding character sequences are jointly embedded into a common space. The authors use deep bidirectional LSTM embedding models and multi-view contrastive losses to learn the embeddings. The approach is evaluated on three tasks: acoustic word discrimination, cross-view word discrimination, and word similarity. The results show that the proposed approach outperforms previous methods on acoustic word discrimination and achieves promising results on cross-view word discrimination and word similarity.
Decision
I decide to accept this paper with minor revisions. The main reasons for this decision are: (1) the paper tackles a specific and interesting problem in the field of speech processing, (2) the approach is well-motivated and grounded in the literature, and (3) the results are promising and demonstrate the effectiveness of the proposed method.
Supporting Arguments
The paper provides a clear and concise introduction to the problem of learning acoustic word embeddings and motivates the need for a multi-view approach. The authors provide a thorough review of related work and clearly explain the differences between their approach and previous methods. The experimental evaluation is comprehensive and well-designed, and the results are promising. The paper also provides additional analysis and visualization of the learned embeddings, which helps to understand the properties of the proposed method.
Additional Feedback
To further improve the paper, I suggest the following: (1) provide more details on the hyperparameter tuning process and the sensitivity of the results to different hyperparameters, (2) consider evaluating the proposed method on other datasets and tasks to demonstrate its generalizability, and (3) provide more discussion on the potential applications and implications of the proposed method in speech processing and related fields.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions: (1) Can you provide more details on the computational resources and training time required for the proposed method? (2) How do you plan to extend the proposed method to handle out-of-vocabulary words and non-word segments? (3) Can you provide more insights on the properties of the learned embeddings and how they relate to phonetic and orthographic similarities?