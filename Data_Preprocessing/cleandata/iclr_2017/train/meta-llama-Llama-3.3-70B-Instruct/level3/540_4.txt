This paper presents a novel approach to visual servoing, which combines learned visual features, predictive dynamics models, and reinforcement learning to learn effective visual servoing mechanisms. The authors propose a method that uses pre-trained features from a convolutional neural network, along with a bilinear predictive model, to learn a visual servo that is robust to visual variation, changes in viewing angle and appearance, and occlusions.
The paper claims to achieve significant improvements over conventional approaches, including a substantial reduction in sample complexity compared to standard model-free deep reinforcement learning algorithms. The authors demonstrate the effectiveness of their approach on a complex synthetic car following benchmark, using only 20 training trajectory samples for reinforcement learning.
However, I decide to reject this paper due to two key reasons. Firstly, the paper lacks experimental evidence to support some of its claims, including comparisons to networks trained from scratch and the source of extra computational cost. Secondly, the baselines used in the paper are weaker than those reported in the literature, with the quality of the baseline ResNet models lagging behind those reported in the literature and on GitHub.
To improve the paper, I suggest that the authors provide more experimental evidence to evaluate the validity of their claims and increase the convincingness of their approach. This could include additional comparisons to other state-of-the-art methods, as well as a more detailed analysis of the computational cost and sample complexity of their approach.
Some specific questions that I would like the authors to answer include: How do the learned visual features and predictive dynamics models contribute to the overall performance of the visual servoing system? Can the authors provide more details on the training process and the hyperparameters used for the reinforcement learning algorithm? How does the proposed approach compare to other state-of-the-art methods in terms of sample complexity and computational cost?
Overall, while the paper presents an interesting and novel approach to visual servoing, it requires more experimental evidence and analysis to fully support its claims and demonstrate its effectiveness. With additional experimentation and analysis, this approach has the potential to make a significant contribution to the field of visual servoing and robotics.