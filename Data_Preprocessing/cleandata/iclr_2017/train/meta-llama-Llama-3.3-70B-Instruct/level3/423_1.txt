Summary of the Paper's Contributions
The paper proposes a novel framework called Generative Multi-Adversarial Network (GMAN), which extends the traditional Generative Adversarial Network (GAN) framework to multiple discriminators. The authors argue that the introduction of multiple discriminators can help stabilize the training process and improve the quality of generated samples. They explore various design perspectives, including using multiple discriminators as a formidable adversary or a forgiving teacher, and propose a generative multi-adversarial metric (GMAM) to evaluate the performance of GMAN.
Decision and Reasons
Based on the review, I decide to Accept the paper with minor revisions. The main reasons for this decision are:
1. The paper introduces a novel and promising approach to stabilizing GAN training, which is a well-known challenge in the field.
2. The authors provide a thorough analysis of the proposed framework, including theoretical justifications and empirical evaluations on various image generation tasks.
Supporting Arguments
The paper provides a clear and well-motivated introduction to the problem of stabilizing GAN training, and the proposed GMAN framework is well-placed in the literature. The authors provide a thorough analysis of the benefits of using multiple discriminators, including improved stability and faster convergence to a higher-quality steady state. The empirical evaluations on MNIST, CIFAR-10, and CelebA datasets demonstrate the effectiveness of the proposed approach.
Additional Feedback
To further improve the paper, I suggest the authors:
1. Provide more comparisons with other approaches that enforce discriminator gradient, such as GAN with DAE.
2. Clarify the relationship between the proposed GMAN framework and other multi-discriminator approaches, such as the one proposed in Yoo et al. (2016).
3. Consider providing more detailed analysis of the computational cost and memory requirements of the proposed framework.
Questions for the Authors
1. Can you provide more insights into the choice of the softmax function and its hyperparameters in the GMAN framework?
2. How do you plan to extend the GMAN framework to other domains, such as text generation or video generation?
3. Can you provide more details on the experimental setup, including the architecture and hyperparameters used for the discriminators and generators?