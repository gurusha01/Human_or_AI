The paper proposes a novel approach to learning algorithmic tasks by leveraging the principle of divide and conquer, which is a fundamental concept in discrete mathematics and computer science. The authors introduce a recursive split and merge architecture, along with a learning framework that optimizes it for both accuracy and computational complexity using only input-output example pairs. This approach has the potential to provide a significant contribution to understanding how deep neural networks (DNNs) function and has potential applications in various fields.
I decide to accept this paper with two key reasons: (1) the paper tackles a specific and well-defined problem, and (2) the approach is well-motivated and supported by convincing examples. The authors provide a thorough analysis of their method, including a detailed description of the split and merge architectures, the learning framework, and the experimental results. The paper is well-written, clear, and easy to read, making it accessible to a broad audience.
To support my decision, I provide the following arguments: (1) the paper addresses a significant question in the field of deep learning, which is how to learn algorithmic tasks efficiently; (2) the proposed approach is novel and has the potential to provide new insights into the workings of DNNs; and (3) the experimental results demonstrate the effectiveness of the approach in learning complex tasks such as sorting and planar convex hull.
To improve the paper, I suggest that the authors provide more random and diverse examples, such as from ImageNet, to further demonstrate the generality of their approach. Additionally, a comparison with other methods, such as gradient-based or deconvolution-based ones, would be desirable to further validate the authors' approach. I would like the authors to answer the following questions: (1) How do the authors plan to extend their approach to more complex tasks, such as those involving multiple inputs or outputs? (2) Can the authors provide more details on the computational complexity of their approach and how it compares to other methods? (3) How do the authors plan to address the issue of overfitting, which is a common problem in deep learning?