Summary
The paper proposes a novel approach to few-shot learning called prototypical networks, which learns a metric space where classification can be performed by computing Euclidean distances to prototype representations of each class. The authors demonstrate the effectiveness of their approach on the Omniglot and miniImageNet datasets, achieving state-of-the-art results on the former and competitive results on the latter. They also show that their approach can be adapted to zero-shot learning, achieving state-of-the-art results on the Caltech UCSD birds dataset.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper's contribution, while significant, is not particularly novel, as the idea of using prototypes for few-shot learning has been explored before. Secondly, the experiments, although thorough, are limited to a few datasets and do not provide a comprehensive evaluation of the approach's strengths and weaknesses.
Supporting Arguments
The paper's approach, while simple and efficient, is not particularly groundbreaking, as the concept of prototypes has been used in various forms in previous work. The authors' claim that their approach is equivalent to predicting the weights of a linear classifier is interesting, but it is not entirely clear how this relates to the broader context of few-shot learning. The experiments, while well-designed, are limited to a few datasets and do not provide a thorough evaluation of the approach's performance on more challenging tasks or in more realistic scenarios.
Additional Feedback
To improve the paper, I would suggest that the authors provide a more comprehensive evaluation of their approach, including experiments on more datasets and tasks, as well as a more detailed analysis of the approach's strengths and weaknesses. Additionally, the authors could provide more context on how their approach relates to previous work in few-shot learning and how it can be used in practice. Some questions I would like the authors to answer include: How does the approach perform on more challenging tasks, such as few-shot learning with noisy or limited data? How does the approach compare to other state-of-the-art methods in few-shot learning? Can the approach be used in more realistic scenarios, such as in real-world applications where data is limited or noisy?