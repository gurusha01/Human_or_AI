Summary
The paper proposes a method for learning perceptual reward functions from a few demonstrations of real-world tasks, leveraging the abstraction power of intermediate visual representations learned by deep models. The approach is able to identify key intermediate steps of a task and automatically discover the most discriminative features for identifying these steps. The resulting reward functions are dense and smooth, enabling a reinforcement learning agent to learn to perform the task in real-world settings.
Decision
I decide to Accept this paper with two key reasons: (1) the paper tackles a significant problem in reinforcement learning, namely the design of reward functions for complex tasks, and (2) the approach is well-motivated and supported by theoretical analysis and practical validation.
Supporting Arguments
The paper provides a clear and well-structured presentation of the approach, including a simple and efficient approximation to inverse reinforcement learning. The use of pre-trained deep models to extract visual features is a key insight, allowing the approach to leverage prior knowledge about the visual world. The experimental evaluation demonstrates the effectiveness of the approach on two real-world tasks, including a robotic door opening task.
Additional Feedback
To further improve the paper, I suggest providing more details on the feature selection algorithm and its hyperparameters. Additionally, it would be interesting to see more qualitative results on the learned reward functions and their robustness to variations in the task and environment. Finally, the paper could benefit from a more detailed discussion of the limitations and potential applications of the approach.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on the choice of hyperparameters for the feature selection algorithm, such as the value of Î± and M?
2. How do the learned reward functions generalize to new, unseen tasks or environments?
3. What are the potential limitations of the approach, and how do you envision addressing them in future work?