Summary
The paper proposes a novel approach to similarity learning using Attentive Recurrent Comparators (ARCs), which leverage attention and recurrence to estimate the similarity between a set of objects. The authors demonstrate the effectiveness of ARCs in various visual tasks, including one-shot learning on the Omniglot dataset, where they achieve state-of-the-art performance surpassing human performance.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper lacks thoroughness in controlling for the number of training iterations for the embeddings, which could impact the transfer results. Secondly, the experiments are criticized for being rushed, with uninformative baseline performance and incomplete results.
Supporting Arguments
The paper's approach is well-motivated, and the use of attention and recurrence to estimate similarity is a novel and interesting idea. However, the lack of thoroughness in controlling for training iterations and the rushed experiments undermine the validity of the results. Additionally, the comparison to other baselines, such as random projections, could strengthen the comparison and validate the results.
Additional Feedback
To improve the paper, I suggest that the authors provide more detailed information about the training process, including the number of iterations and the learning rate schedule. Additionally, the authors should consider adding more baselines, such as random projections, to strengthen the comparison. Furthermore, the authors should provide more detailed analysis of the results, including error bars and statistical significance tests.
Questions for the Authors
I would like to ask the authors to clarify the following points:
1. How did the authors control for the number of training iterations for the embeddings, and what was the impact on the transfer results?
2. Can the authors provide more detailed information about the experimental setup, including the hyperparameters and the learning rate schedule?
3. How do the authors plan to address the issue of rushed experiments and uninformative baseline performance in future work?