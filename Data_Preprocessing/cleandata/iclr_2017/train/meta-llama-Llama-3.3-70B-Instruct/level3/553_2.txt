The paper presents a novel approach to learning acoustic word embeddings in a multi-view setting, where both acoustic sequences and their corresponding character sequences are jointly learned. This approach has the potential to improve performance on tasks such as speech recognition and query-by-example search. The authors propose several contrastive losses, including a cost-sensitive loss that aims to capture orthographic edit distances, and demonstrate the effectiveness of their approach on various tasks, including acoustic word discrimination, cross-view word discrimination, and word similarity.
I decide to reject this paper, primarily due to two key reasons. Firstly, while the paper is well-written, it lacks in-depth discussion of technical details, which makes it challenging to fully understand the proposed approach. Secondly, the paper's evaluation methodology, although interesting, does not provide a clear understanding of the expected practical improvements of the proposed approach.
To support my decision, I argue that the paper's lack of technical detail makes it difficult to assess the novelty and significance of the proposed approach. Additionally, the evaluation methodology, while innovative, does not provide a clear comparison to state-of-the-art methods, making it challenging to determine the practical impact of the proposed approach.
To improve the paper, I suggest that the authors provide more technical details, such as a more in-depth explanation of the contrastive losses and the recurrent neural network architecture. Additionally, the authors should consider providing a more comprehensive evaluation of their approach, including a comparison to state-of-the-art methods and an analysis of the practical implications of their results.
I would like to ask the authors to clarify the following points: (1) How do the proposed contrastive losses differ from existing methods, and what are the advantages of using a cost-sensitive loss? (2) Can the authors provide more details on the recurrent neural network architecture, including the number of layers and the number of hidden units? (3) How do the authors plan to extend their approach to directly train on both word and non-word segments? (4) Can the authors provide a more comprehensive evaluation of their approach, including a comparison to state-of-the-art methods and an analysis of the practical implications of their results?