Summary of the Paper's Claims and Contributions
The paper proposes two RNN-based architectures, "Classify" and "Select", for extractive document summarization, which read the whole document and decide on sentence inclusion. The models assume oracle extractive summaries exist and use a pseudo ground-truth generation procedure. The paper also presents a new weight initialization technique that corrects for the influence of dropout rates and an arbitrary nonlinearity's effect on variance, and demonstrates the importance of re-estimating Batch Normalization variance parameters after training.
Decision and Key Reasons
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper's performance is similar or worse than existing work, such as Cheng & Lapata (2016), which is considered a small increment over existing work. Secondly, the problem of single document extractive summarization is not particularly exciting, as existing models have already achieved good results, and the paper fails to address more interesting problems such as abstractive summarization or multi-document summarization.
Supporting Arguments
The paper's proposed architectures, "Classify" and "Select", do not demonstrate significant improvements over existing work, and the pseudo ground-truth generation procedure is similar to previous works. The paper's focus on single document extractive summarization is also limiting, as it does not address more challenging and interesting problems in the field. Additionally, the paper's scalability is limited, as evidenced by the need to cap the maximum sentence length to 50.
Additional Feedback and Questions
To improve the paper, I suggest that the authors consider addressing more challenging problems in the field, such as abstractive summarization or multi-document summarization. I also recommend that the authors provide more detailed comparisons with existing work and demonstrate significant improvements over state-of-the-art models. Some questions I would like the authors to answer include: How do the proposed architectures handle longer documents or documents with complex structures? Can the authors provide more detailed analysis of the pseudo ground-truth generation procedure and its limitations? How do the authors plan to address the scalability issues of their models?