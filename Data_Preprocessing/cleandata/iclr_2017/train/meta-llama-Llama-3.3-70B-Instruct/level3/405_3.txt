Summary
The paper proposes a novel approach to object recognition, called Compositional Kernel Machines (CKMs), which addresses the limitations of deep architectures and other kernel methods. CKMs use a sum-product function to represent a discriminant function, allowing for tractable summation over an exponential set of virtual instances. This approach mitigates the curse of dimensionality and improves sample complexity. The authors demonstrate the effectiveness of CKMs in several scenarios, including image classification, composition, and symmetry tasks.
Decision
I decide to Accept this paper, with the primary reason being the novelty and potential impact of the proposed approach. The paper presents a well-motivated and well-placed contribution in the literature, addressing the limitations of current state-of-the-art methods.
Supporting Arguments
The paper provides extensive experimental evaluation on several benchmarks, yielding promising results and demonstrating the usefulness of CKMs in various applications. The authors also provide a clear and well-written explanation of the proposed approach, making it easy to understand and follow. Additionally, the paper highlights the advantages of CKMs, including fast learning speed and improved sample complexity, which are significant benefits in many real-world applications.
Additional Feedback
To further improve the paper, I suggest that the authors provide more detailed comparisons with other state-of-the-art methods, including a more thorough analysis of the computational complexity and scalability of CKMs. Additionally, it would be beneficial to explore the application of CKMs to other domains, such as structured prediction, regression, and reinforcement learning problems.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence for my assessment, I would like the authors to answer the following questions:
1. Can you provide more details on the computational complexity of CKMs and how they scale with the size of the training set and the number of virtual instances?
2. How do CKMs handle cases where the training set is highly imbalanced or contains noisy data?
3. Can you provide more insights into the choice of the sum-product function and the leaf kernel, and how they affect the performance of CKMs?