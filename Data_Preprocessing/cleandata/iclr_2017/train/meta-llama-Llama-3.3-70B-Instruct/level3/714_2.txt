Summary
The paper proposes a novel approach to learning state representations using deep neural networks and robotic priors. The authors aim to reproduce the human brain's ability to simplify complex environments by learning a low-dimensional representation of the world from images acquired by a robot. The approach uses a siamese network to impose constraints on the learned representation, ensuring consistency with physical and task-specific rules. The paper presents preliminary experiments on a simple synthetic task, demonstrating the ability to learn a one-dimensional representation of a Baxter head position from raw images.
Decision
I decide to reject this paper, primarily due to the limited contribution and unsatisfactory experimental evaluation. The approach, although interesting, lacks comparison with existing approaches or baselines, making it impossible to judge its usefulness or performance. Additionally, the experiments are conducted on a simple synthetic task with small datasets and little variation, which raises concerns about the applicability of the approach to more realistic scenarios.
Supporting Arguments
The paper's contribution is limited, as it primarily builds upon existing work on robotic priors and deep learning. The experimental evaluation is also unsatisfactory, as it only demonstrates the approach on a simple task with a small dataset. The lack of comparison with existing approaches or baselines makes it difficult to assess the performance of the proposed method. Furthermore, the paper acknowledges the limitation of the approach in assessing the training quality, which is a crucial aspect of any learning method.
Additional Feedback
To improve the paper, I suggest the authors conduct more extensive experiments on more realistic scenarios, including comparisons with existing approaches or baselines. They should also investigate ways to assess the training quality, such as using reinforcement learning algorithms to evaluate the learned representation. Additionally, the authors could explore the application of their approach to more complex tasks, such as learning object positions in three dimensions.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
1. How do the authors plan to address the limitation of assessing the training quality, particularly in situations where ground truth is unavailable?
2. Can the authors provide more details on the experimental setup, including the size of the dataset and the specific tasks used to evaluate the approach?
3. How do the authors envision their approach being applied to more realistic scenarios, such as learning from real-world images or videos?