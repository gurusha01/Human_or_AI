This paper proposes a new approach to network quantization, which is a technique used to reduce the memory requirements of deep neural networks. The authors introduce a Hessian-weighted distortion measure to quantify the impact of quantization errors on the neural network loss function. They also propose two efficient heuristic solutions for entropy-constrained scalar quantization (ECSQ) to solve the network quantization problem under a compression ratio constraint.
The paper claims to contribute to the field of network quantization by providing a new perspective on how to quantify and minimize the loss due to quantization. The authors demonstrate the effectiveness of their approach through experiments on several benchmark datasets, including LeNet, ResNet, and AlexNet. The results show that the proposed network quantization schemes can achieve significant compression ratios with minimal performance loss.
I decide to accept this paper with some minor revisions. The main reason for my decision is that the paper presents a well-motivated and well-executed approach to network quantization. The authors provide a clear and concise explanation of their methodology and demonstrate its effectiveness through experiments. The paper is also well-organized and easy to follow.
One of the key strengths of the paper is its ability to connect the network quantization problem to the entropy-constrained data compression problem in information theory. This connection allows the authors to push the compression ratio to the limit that information theory provides. The proposed ECSQ solutions, including uniform quantization and an iterative algorithm, are efficient and effective in achieving high compression ratios.
However, I do have some minor concerns that need to be addressed. Firstly, the paper could benefit from a more detailed discussion on the computational complexity of the proposed approach. The authors mention that Hessian computation is not free, but they do not provide a detailed analysis of the computational requirements of their approach. Secondly, the paper could benefit from a more thorough comparison with existing network quantization methods. While the authors compare their approach with k-means clustering, they do not provide a detailed comparison with other state-of-the-art methods.
To improve the paper, I suggest that the authors provide more details on the computational complexity of their approach and compare their method with other state-of-the-art network quantization methods. Additionally, the authors could provide more insights into the trade-offs between compression ratio and performance loss. What are the limitations of the proposed approach, and how can they be addressed in future work?
Some questions that I would like the authors to answer include: How does the proposed approach handle non-linear relationships between network parameters? Can the authors provide more insights into the choice of the Hessian-weighted distortion measure, and how it relates to other distortion measures used in network quantization? How does the proposed approach compare with other network compression methods, such as network pruning and knowledge distillation?