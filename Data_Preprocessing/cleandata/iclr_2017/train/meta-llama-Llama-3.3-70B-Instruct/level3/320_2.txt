This paper proposes a novel approach to visual servoing, which combines learned visual features, learned predictive dynamics models, and reinforcement learning to learn effective visual servoing mechanisms. The authors demonstrate that standard deep features, such as those from a VGG network, can be used together with a bilinear predictive model to learn a robust visual servo that is tolerant to visual variation, changes in viewing angle and appearance, and occlusions.
The paper is well-written and mathematically solid, with a clear explanation of the proposed approach and its components. The experiments demonstrate the benefits of using a value-weighted objective and show significant improvement over conventional approaches based on image pixels or hand-designed keypoints. The use of pre-trained visual features from a VGG net is also shown to be beneficial for generalization.
However, I decide to reject this paper because its contribution to the representation learning problem is limited, and its focus on the control problem rather than representation learning may make it less aligned with the conference's goals. Additionally, the paper's use of a fixed policy representation may limit its applicability to more complex tasks.
To improve the paper, I suggest that the authors provide more discussion on the limitations of their approach and potential future directions. For example, they could explore the use of more advanced reinforcement learning algorithms or investigate the application of their approach to more complex tasks, such as robotic manipulation or navigation.
I would like the authors to answer the following questions to clarify my understanding of the paper:
1. How do the authors plan to extend their approach to more complex tasks, such as robotic manipulation or navigation?
2. Can the authors provide more details on the computational efficiency of their approach, including the time complexity of the algorithms and the computational resources required?
3. How do the authors evaluate the robustness of their approach to different types of visual variations, such as changes in lighting or occlusions?
Overall, while the paper presents a novel and interesting approach to visual servoing, its limitations and potential future directions need to be further explored and discussed.