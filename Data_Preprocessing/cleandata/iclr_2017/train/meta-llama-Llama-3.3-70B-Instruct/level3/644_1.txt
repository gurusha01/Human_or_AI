Summary
The paper proposes a framework for multitask deep reinforcement learning guided by policy sketches. The approach associates each subtask with its own modular subpolicy and jointly optimizes over full task-specific policies by tying parameters across shared subpolicies. The authors evaluate the effectiveness of their approach on a maze navigation game and a 2-D Minecraft-inspired crafting game, demonstrating that it outperforms standard baselines and naturally induces a library of primitive behaviors that can be recombined to rapidly acquire policies for new tasks.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the improvements shown in the paper are minor and do not substantiate the overall claim made by the authors. Secondly, the approach proposed by the authors seems ad hoc and its potential for widespread adoption is uncertain, although the idea behind it is interesting.
Supporting Arguments
The paper tackles the significant issue of enhancing diversity in responses and demonstrates its applicability across various tasks. However, the results presented in the paper are not convincing enough to support the claims made by the authors. The approach proposed by the authors is based on a simple decoupled actor-critic training objective, which may not be sufficient to handle complex tasks. Additionally, the use of a curriculum learning scheme to scale up from easy tasks to more difficult ones may not be the most effective way to learn hierarchical policies.
Additional Feedback
To improve the paper, the authors could provide more detailed analysis of the results and compare their approach with other state-of-the-art methods. They could also consider using more complex tasks to evaluate the effectiveness of their approach. Furthermore, the authors could provide more insights into the learned models' ability to generalize or adapt to held-out tasks.
Questions for the Authors
I would like to ask the authors to clarify the following points:
1. How do the authors plan to extend their approach to more complex tasks and environments?
2. Can the authors provide more details on the curriculum learning scheme and how it is used to scale up from easy tasks to more difficult ones?
3. How do the authors evaluate the effectiveness of their approach in terms of generalization and adaptation to new tasks?