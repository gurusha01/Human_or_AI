Summary
The paper presents a comprehensive investigation of different context types and representations for learning word embeddings, a crucial aspect of natural language processing. The authors conduct extensive experiments across 21 datasets and 4 tasks, aiming to provide insights into context selection and establish a guideline for the community. This contribution has the potential to advance our understanding of word embeddings and inform future research in the field.
Decision
I decide to Reject this paper, primarily due to two key reasons. Firstly, I find Finding 2 to be trivial and not worthy of emphasis, which raises concerns about the paper's ability to provide significant new insights. Secondly, Finding 1 is questionable due to the noisy Figure 4, which lacks error analysis and makes it challenging to determine the robustness of the finding.
Supporting Arguments
The paper's emphasis on Finding 2 seems misplaced, as it does not contribute substantially to the existing body of knowledge. Furthermore, the lack of error analysis in Figure 4 undermines the credibility of Finding 1, making it difficult to trust the results. While the paper provides a reasonable review of state-of-the-art vision architectures, it fails to offer novel perspectives or contributions.
Additional Feedback
To improve the paper, I suggest the authors reconsider the emphasis on Finding 2 and provide a more detailed error analysis for Figure 4. Additionally, the color scheme used in the paper may not be accessible to colorblind readers or those with black and white printers, which could be revised to ensure inclusivity. It is also interesting to note that VGG models are often unfairly targeted for benchmarking model compression algorithms, and the authors' highlighting of this issue is a valuable contribution.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions: 
1. Can you provide more context about why Finding 2 is significant and how it contributes to the existing literature?
2. How do you plan to address the lack of error analysis in Figure 4, and what steps can be taken to increase the robustness of Finding 1?
3. Can you discuss potential avenues for future research in context selection for word embeddings, and how this paper's findings can be built upon?