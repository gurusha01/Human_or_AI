This paper proposes a method for transferring weights from a deterministic deep neural network to a stochastic feedforward neural network, which can improve the performance of a deterministic model. The authors introduce a "simplified stochastic feedforward neural network" to tackle the problem of transferring weights from a DNN to a stochastic network when the DNN uses ReLU nonlinearities. The training process involves three steps: pretraining a DNN, transferring weights to a simplified SFNN, and optionally transferring weights to a full SFNN or a deterministic model.
The experimental results on MNIST classification, generative tasks, and CIFAR-10, CIFAR-100, and SVHN datasets show that the proposed method can improve the performance of a deterministic model. However, the paper could be easier to read if the notation and terminology were more precise and consistent, and if the results were compared to stronger baselines. There are also several minor issues with the paper, including grammatical errors, inconsistent notation, and unclear explanations.
To make a decision to accept or reject this paper, I need to answer three key questions: 
1. What is the specific question/problem tackled by the paper? 
The paper tackles the problem of transferring weights from a deterministic deep neural network to a stochastic feedforward neural network.
2. Is the approach well motivated, including being well-placed in the literature? 
The approach is well-motivated, and the authors provide a clear explanation of the problem and the proposed solution.
3. Does the paper support the claims? 
The paper provides experimental results that support the claims, but the results could be stronger if compared to more baselines.
Based on these questions, I decide to accept this paper because it proposes a novel method for transferring weights from a deterministic deep neural network to a stochastic feedforward neural network, and the experimental results show that the proposed method can improve the performance of a deterministic model.
To improve the paper, I suggest that the authors clarify the notation and terminology, compare the results to stronger baselines, and address the minor issues with the paper. Additionally, I would like the authors to answer the following questions: 
 How are the weights transferred from the simplified SFNN to the DNN model? 
* What does NCSFNN stand for in the supplementary material? 
* Can the authors provide more details about the experimental setup and the hyperparameters used in the experiments? 
Overall, this paper proposes a novel method for transferring weights from a deterministic deep neural network to a stochastic feedforward neural network, and the experimental results show that the proposed method can improve the performance of a deterministic model. With some revisions to address the minor issues and provide more clarity, this paper has the potential to make a significant contribution to the field.