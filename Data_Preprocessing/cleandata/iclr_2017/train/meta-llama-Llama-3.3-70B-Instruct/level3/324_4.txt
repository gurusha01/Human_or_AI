Summary
The paper proposes a novel approach to video frame prediction by modeling frames using principles inspired by computer graphics pipelines. The authors introduce a statistical framework that explicitly represents "sprites" or percepts inferred from the maximum likelihood of the scene and infers their movement independently of their content. The proposed model, called Perception Updating Networks (PUN), uses a recurrent neural network (RNN) augmented with task-specific modules to optimize a variational lower bound that decouples sprites and their dynamics in a video.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper lacks a thorough evaluation of the impact of filter pruning on transfer learning, which is a significant concern in the field. Secondly, the paper misses an opportunity to explore the direction of transfer learning and its potential harm caused by filter pruning, which is a key interest in both academia and industry.
Supporting Arguments
The paper proposes a simple method to reduce FLOPs and memory consumption by pruning low-weight filters from ConvNets, which is experimented on VGG-16 and ResNets on CIFAR10 and ImageNet. However, the method creates structured sparsity, improving performance without changing the underlying convolution implementation, and is very simple to implement. Despite these strengths, the paper's lack of evaluation on transfer learning and its potential harm is a significant weakness.
Additional Feedback
To improve the paper, I suggest that the authors conduct a thorough evaluation of the impact of filter pruning on transfer learning and explore the direction of transfer learning and its potential harm caused by filter pruning. Additionally, the authors could provide more visualizations and interpretations of the learned sprites and their dynamics, which would help to better understand the strengths and limitations of the proposed approach.
Questions for the Authors
I would like the authors to answer the following questions to clarify my understanding of the paper and provide additional evidence:
1. How do the authors plan to address the issue of transfer learning and its potential harm caused by filter pruning in future work?
2. Can the authors provide more visualizations and interpretations of the learned sprites and their dynamics, particularly in the context of the Moving MNIST dataset?
3. How do the authors think the proposed approach could be improved to maintain the internal dynamics of the RNN for longer periods, as observed in the rollout mode experiments?