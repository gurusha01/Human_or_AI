Summary of the Paper's Contributions
The paper introduces PixelVAE, a novel generative model that combines the strengths of Variational Autoencoders (VAEs) and PixelCNNs. PixelVAE uses a conditional PixelCNN in the decoder to model the output distribution, allowing it to capture fine details in images while still learning a useful latent representation. The authors also extend PixelVAE to a hierarchical model with multiple stochastic layers, enabling it to scale to challenging natural image datasets. The paper demonstrates state-of-the-art performance on binarized MNIST, competitive performance on 64 Ã— 64 ImageNet, and high-quality samples on the LSUN bedrooms dataset.
Decision and Key Reasons
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper's exposition needs significant improvement, as the current version is poorly motivated, described, and justified. The authors propose multiple alternatives and heuristics for the b-GAN, introducing complexity and requiring further work to rule out unnecessary variants. Secondly, the experimental results, particularly Figures 2, 3, and 4, are difficult to interpret and do not convincingly demonstrate the practical advantage of the proposed approach.
Supporting Arguments
The paper tackles the specific question of natural image modeling, a landmark challenge of unsupervised learning. However, the approach is not well-motivated, and the authors fail to provide a clear justification for the use of PixelCNNs in the decoder. The paper also lacks a thorough comparison with existing state-of-the-art models, making it difficult to assess the significance of the results. Furthermore, the experimental results are not rigorously evaluated, and the authors do not provide sufficient evidence to support their claims.
Additional Feedback and Questions
To improve the paper, I suggest that the authors provide a clearer motivation for the use of PixelCNNs in the decoder and a more thorough comparison with existing state-of-the-art models. The authors should also provide more detailed experimental results, including a rigorous evaluation of the model's performance on various datasets. I would like the authors to answer the following questions: (1) How do the authors plan to address the complexity introduced by the multiple alternatives and heuristics for the b-GAN? (2) Can the authors provide more detailed experimental results, including a comparison with existing state-of-the-art models on the same datasets? (3) How do the authors plan to improve the interpretability of the experimental results, particularly Figures 2, 3, and 4?