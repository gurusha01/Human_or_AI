Summary
The paper proposes a novel perspective on understanding generative autoencoders, specifically focusing on the idea that the encoder and decoder distributions, Qφ(Z|X) and Pθ(X|Z), can be used to draw samples from the conditional distributions. The authors introduce a Markov chain Monte Carlo (MCMC) sampling process, which allows for direct sampling from the learned latent distribution, P̂(Z). This approach is shown to improve the quality of generated samples, particularly when the learned latent distribution is far from the prior distribution.
Decision
I decide to reject the paper, with two key reasons for this choice. Firstly, the experiments are insufficient, particularly in supporting the "unrolled iterative estimation" concept and addressing the underestimation issue in stage 4 of Figure 3. Secondly, the paper lacks experiments to provide evidence for the "unrolled iterative estimation" concept, independent of comparing ResNet with Highway Net, which is a major concern.
Supporting Arguments
The paper provides a new perspective on understanding generative autoencoders, which is a significant contribution. However, the experimental evaluation is limited, and the results are not convincing enough to support the claims made in the paper. The authors rely heavily on visual inspections of generated samples, which is not a robust evaluation metric. Furthermore, the paper lacks a thorough comparison with existing methods, which makes it difficult to assess the effectiveness of the proposed approach.
Additional Feedback
To improve the paper, I suggest that the authors conduct more extensive experiments, including quantitative evaluations and comparisons with existing methods. Additionally, the authors should provide more details on the implementation of the MCMC sampling process and the hyperparameter settings used in the experiments. It would also be helpful to include more visualizations and examples to illustrate the effectiveness of the proposed approach.
Questions for the Authors
I would like the authors to clarify the following points:
1. How did you choose the hyperparameters for the MCMC sampling process, and what is the sensitivity of the results to these hyperparameters?
2. Can you provide more details on the experimental setup, including the dataset, model architecture, and training procedure?
3. How do you plan to address the underestimation issue in stage 4 of Figure 3, and what are the implications of this issue on the overall performance of the proposed approach?