This research paper proposes a novel approach to learning binary autoencoders, which is formulated as a biconvex optimization problem. The approach learns from pairwise correlations between encoded and decoded bits, and the optimal decoder is shown to be a single layer of artificial neurons. The paper presents a learning algorithm, called Pairwise Correlation Autoencoder (PC-AE), which alternately minimizes the loss with respect to the encoding and decoding parameters.
The paper claims to contribute to the field of autoencoding by providing a new perspective on the problem, avoiding explicit model assumptions and non-convex optimizations. The approach is shown to be competitive with standard autoencoders trained with backpropagation, and the paper provides empirical results on several datasets.
However, upon closer examination, the approach is found to be simple and not technically interesting, with a code size of 128 showing moderate loss compared to continuous paragraph vectors. The paper lacks baseline numbers and comparable results, with inconsistencies in dataset usage. Additional comparisons, such as the number of binary bits required to match continuous representation performance, would strengthen the paper.
Furthermore, the use of binary codes may not be suitable for high-quality ranking after retrieval, and a standard PV-DBOW may be preferred for continuous representation. Minor errors, such as typos and unclear terminology, are present throughout the paper, including inconsistencies in table notation and grammatical errors.
Based on the conference guidelines, I would reject this paper. The specific question/problem tackled by the paper is not clearly motivated, and the approach is not well-placed in the literature. The paper does not provide sufficient evidence to support its claims, and the results are not scientifically rigorous.
To improve the paper, the authors should provide more baseline numbers and comparable results, and address the inconsistencies in dataset usage. They should also consider additional comparisons, such as the number of binary bits required to match continuous representation performance. Furthermore, the authors should revise the paper to address the minor errors and inconsistencies, and provide a clearer motivation for the approach and its place in the literature.
I would like to ask the authors to clarify the following points:
* How does the proposed approach compare to other autoencoding methods, such as variational autoencoders and generative adversarial networks?
* How does the use of binary codes affect the quality of the retrieved documents, and what are the implications for high-quality ranking after retrieval?
* Can the authors provide more details on the experimental setup, including the datasets used and the hyperparameters tuned?
* How does the proposed approach handle cases where the input data is not binary, and what are the implications for continuous representation?