Summary
The paper proposes a novel approach to learning chess game concepts under weak supervision using convolutional neural networks (CNNs). The authors use a simple chess game, tic-tac-toe, as a case study and demonstrate that a CNN can automatically figure out complicated game rule concepts, such as the concept of a chessboard grid, the winning rule, and the concept of two sides. The paper also shows that cross-modal supervision for representation learning is still applicable in this case of higher-level semantics and that the technique of class activation mapping (CAM) can activate at non-salient regions.
Decision
I decide to accept this paper with some minor revisions. The main reason for this decision is that the paper tackles a specific and interesting question, namely, whether a CNN can learn chess game concepts under weak supervision. The approach is well-motivated, and the experiments are carefully designed and executed. The results are also interesting and provide new insights into the capabilities of CNNs.
Supporting Arguments
The paper provides a clear and concise introduction to the problem and the methodology used to tackle it. The authors also provide a thorough review of related work, which helps to situate their contribution in the context of existing research. The experiments are well-designed, and the results are carefully analyzed and interpreted. The use of CAM to visualize the learned representations is particularly effective in demonstrating the emergence of game rule concepts in the learned representations.
Additional Feedback
To improve the paper, I suggest that the authors provide more details about the implementation of the CNN and the training procedure. Additionally, it would be helpful to include more quantitative evaluations of the learned representations, such as metrics that measure the accuracy of the predicted moves. Finally, the authors could provide more discussion about the implications of their results for other applications of CNNs, such as game playing and decision-making.
Questions for the Authors
I would like to ask the authors to clarify the following points:
* How do the authors ensure that the learned representations are not simply memorizing the training data, but rather learning generalizable concepts?
* Can the authors provide more insights into why the addition of grid lines to the chessboard improves the performance of the CNN?
* How do the authors plan to extend their approach to more complex games, such as chess or Go?