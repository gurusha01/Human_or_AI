The paper proposes a technique to reduce the parameters of a Recurrent Neural Network (RNN) by pruning weights during the initial training of the network. The authors claim that their approach can achieve sparsity of 90% with a small loss in accuracy and can also improve the accuracy over a dense baseline by starting with a larger dense matrix and then pruning it down. The paper presents experiments on bidirectional RNNs and Gated Recurrent Units (GRUs) and demonstrates significant reductions in model size and improvements in computational efficiency.
I decide to reject this paper, primarily due to the lack of novelty in the proposed approach and the absence of a thorough analysis of different AllReduce techniques. The paper's use of the term "linear pipeline" is also confusing and should be replaced with the standard term "ring-based approach" to make connections easier. Furthermore, the cost analysis of ring-based AllReduce is not new and has been previously provided in existing literature.
The paper's claim of being the first implementation of the ring-based AllReduce approach is also incorrect, as this approach is already supported by NVidia's NCCL library. Additionally, the overlap of communication and computation is an existing technique used in systems like TensorFlow and MXNet, and the authors' proposed schedule only partially exploits this overlap. A more detailed analysis of different AllReduce techniques, including tree-shape reduction, ring-based approach, and all-to-all approach, would improve the paper's analysis.
To improve the paper, I suggest that the authors provide a more thorough review of existing literature on model pruning and compression, and clearly highlight the novelty of their approach. They should also provide more detailed experiments and analysis to demonstrate the effectiveness of their technique, including comparisons with other state-of-the-art methods. Additionally, the authors should address the inconsistencies in their claims and provide more accurate information about the existing implementations of the ring-based AllReduce approach.
I would like the authors to answer the following questions to clarify my understanding of the paper: (1) How does the proposed pruning technique differ from existing methods, and what are the advantages of using this approach? (2) Can the authors provide more detailed information about the experiments, including the hyperparameters used and the datasets employed? (3) How do the authors plan to address the limitations of their approach, including the potential impact on model accuracy and the need for more efficient sparse matrix-vector libraries?