Summary
This paper proposes a novel approach to learning state representations in robotics using deep neural networks and robotic priors. The authors demonstrate the effectiveness of their approach in learning a one-dimensional representation of a Baxter robot's head position from raw images. The paper also shows that the learned representation is robust to noise and luminosity perturbations.
Decision
I decide to reject this paper, primarily due to two key reasons. Firstly, the paper is overly long and contains too many results, making it unclear what the single message of the paper is. The clarity of presentation is compromised, and the paper needs to be trimmed down to improve focus. Secondly, the demonstration of the approach, although compelling, does not significantly advance the state-of-the-art in the field, as similar results have been reported in previous work.
Supporting Arguments
The paper's main contribution is the use of robotic priors in a siamese network to train a deep convolutional neural network. However, the section on geometric understanding of adversarial examples is similar to previous results and does not show significant new findings beyond existing literature. The authors demonstrate susceptibility of large-scale models to adversarial perturbations, but this expands on existing results and does not add much new to the literature. The demonstration of real-world attacks on a vision API is compelling, but its significance and novelty compared to previous work are unclear.
Additional Feedback
To improve the paper, I suggest trimming down the content to focus on the main contribution and removing unnecessary sections, such as Table 1, Section 2.2.1, and Figure 2 panels. The authors should also provide more context and comparison to previous work to clarify the significance and novelty of their approach. Additionally, the authors should consider using more robust evaluation metrics, such as reinforcement learning algorithms, to measure the quality of the learned representation.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
1. How do the authors plan to extend their approach to learn more complex representations, such as objects positions in three dimensions?
2. Can the authors provide more details on the reinforcement learning algorithm used to measure the quality of the learned representation, as mentioned in the discussion section?
3. How do the authors plan to address the limitation of their approach, specifically the assessment of training quality, in future work?