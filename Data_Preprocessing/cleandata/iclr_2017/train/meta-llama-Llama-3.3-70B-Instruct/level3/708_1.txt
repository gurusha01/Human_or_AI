Summary of the Paper
The paper proposes a new approach to controlling the expansivity of gradients during backpropagation in recurrent neural networks (RNNs) by manipulating orthogonality constraints and regularization on matrices. The authors explore the effect of loosening hard orthogonality constraints on the hidden-to-hidden transition matrix and introduce a factorization technique that allows for bounding the singular values of the matrix. The paper presents experimental results on various tasks, including synthetic memory tasks and real-world datasets, demonstrating that loosening orthogonality constraints can improve optimization convergence rate and model performance.
Decision
I decide to reject this paper, primarily due to two key reasons: (1) the paper suffers from issues such as verbosity, disorganization, and limited interest in experiments, which compromises the clarity and overall quality of the presentation; and (2) the approach and results lack technical novelty and surprising insights, with the paper's contributions being incremental and not significantly advancing the state-of-the-art in the field.
Supporting Arguments
The paper's quality is lacking due to poor method description and experimental setup, which makes it challenging to follow and understand the authors' approach. The text is verbose, and the organization of the paper could be improved to enhance clarity. Furthermore, the experiments are flawed, with issues such as unclamped pixel values and unclear modification procedures, which raises questions about the realism of the modification procedure and the comparison of results to other methods. The paper also lacks discussion on important aspects, such as average model evaluations and comparison to other techniques, which limits the potential impact of the work.
Additional Feedback
To improve the paper, I suggest shortening it by 30-40% to enhance argumentation and descriptions, and selecting only the most important experiments to present. The authors should also develop more experiments and tune down claims, particularly regarding the Top-k approach. Additionally, the paper's minor issues, such as abuse of footnotes, unclear variable meanings, and poor table formatting, should be addressed to improve the overall presentation.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
1. Can you provide more details on the experimental setup and the modification procedure used in the paper?
2. How do you plan to address the issues of verbosity and disorganization in the paper to improve clarity and presentation?
3. Can you provide more insights into the technical novelty and surprising aspects of the approach and results, and how they advance the state-of-the-art in the field?