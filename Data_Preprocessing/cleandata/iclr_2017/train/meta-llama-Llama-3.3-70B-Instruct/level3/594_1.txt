This research paper proposes a novel optimization algorithm called Entropy-SGD for training deep neural networks. The algorithm is motivated by the local geometry of the energy landscape and aims to exploit the phenomenon of wide valleys in the energy landscape, which are believed to generalize better. The authors introduce the concept of local entropy, which measures the flatness of the energy landscape, and use it to bias the optimization towards flat regions.
The paper claims to contribute to the field by providing a new optimization tool that can improve the generalization performance of deep neural networks. The authors demonstrate the effectiveness of Entropy-SGD on various datasets, including MNIST, CIFAR-10, and Penn Tree Bank, and show that it can achieve comparable or better performance than state-of-the-art techniques.
However, upon closer examination, there are several concerns with the paper. Firstly, the proposed passthrough framework seems to offer little novelty compared to existing formalisms like LSTM or highway networks. Secondly, the empirical evaluation has several methodological issues, such as the lack of baseline comparisons in some experiments and the use of different experimental settings than previous works. Additionally, the authors' claim of state-of-the-art performance in the memory task is questionable due to the use of more parameters than the uRNN, making the comparison unfair.
Based on these concerns, I would reject this paper. The main reasons for this decision are the lack of novelty in the proposed framework and the methodological issues in the empirical evaluation. While the paper provides some interesting insights into the energy landscape of deep neural networks, the contributions are not significant enough to warrant acceptance.
To improve the paper, I would suggest that the authors provide more rigorous evaluations of their proposed algorithm, including comparisons with existing state-of-the-art techniques and more detailed analyses of the energy landscape. Additionally, the authors should address the methodological issues in their experiments and provide more clarity on the advantages of their proposed framework over existing approaches.
Some questions that I would like the authors to answer to clarify my understanding of the paper include:
* Can the authors provide more details on how the passthrough framework differs from existing formalisms like LSTM or highway networks?
* How do the authors plan to address the methodological issues in their empirical evaluation, such as the lack of baseline comparisons and the use of different experimental settings?
* Can the authors provide more insights into the energy landscape of deep neural networks and how their proposed algorithm exploits this landscape to improve generalization performance?