Summary
The paper presents a systematic investigation of the impact of different context types on the quality of word embeddings, a crucial aspect of natural language processing. The authors conduct comprehensive experiments across 21 datasets and 4 tasks, aiming to provide insights into context selection and serve as a guideline for the community. This work tackles an important question in the field, and the authors' efforts to evaluate various context types are commendable.
Decision
I decide to Reject this paper, primarily due to the inconclusive results of the experiments and the limited discussion of context types. The paper's findings do not show a significant and consistent advantage of any context type, which raises questions about the sensitivity of the benchmarks used.
Supporting Arguments
The approach is well-motivated, and the authors are well-placed in the literature. However, the paper's conclusions are not supported by strong empirical evidence. The experiments, although comprehensive, do not provide clear insights into the effectiveness of different context types. Furthermore, the discussion of context types is limited, and the authors could benefit from exploring other types, such as those presented in "Open IE as an Intermediate Structure for Semantic Tasks" by Stanovsky et al.
Additional Feedback
To improve the paper, I suggest that the authors provide a more elaborate version, including a more detailed analysis of the results and a clearer discussion of the implications. The authors could also benefit from exploring other context types and evaluating their effectiveness. Additionally, the authors could provide more information about the benchmarks used and their sensitivity to different context types.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions: (1) How do the authors plan to address the inconclusive results of the experiments, and what additional analyses or experiments could be conducted to provide clearer insights? (2) Can the authors provide more information about the benchmarks used and their sensitivity to different context types? (3) How do the authors plan to explore other context types, such as those presented in "Open IE as an Intermediate Structure for Semantic Tasks" by Stanovsky et al., and evaluate their effectiveness?