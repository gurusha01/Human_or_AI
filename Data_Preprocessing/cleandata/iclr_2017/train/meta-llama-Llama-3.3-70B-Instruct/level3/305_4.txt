Summary of the Paper's Contributions
The paper presents a novel approach to learning perceptual similarity judgment using a deep convolutional neural network (DCNN) with object persistence constraints. The authors propose a Siamese triplet architecture, called Object Persistence Net (OPnet), which learns to associate different views of the same 3D object, resulting in a view-manifold that captures the notion of object persistence and continuity. The paper demonstrates that OPnet outperforms existing approaches, including AlexNet, in instance and categorical retrieval tasks on novel objects, and shows a higher correlation with human perceptual similarity judgment.
Decision and Key Reasons
I recommend accepting this paper due to its innovative approach, thorough analysis, and impressive results. The key reasons for this decision are: (1) the paper tackles a specific and interesting problem in computer vision, namely, learning perceptual similarity judgment, and (2) the approach is well-motivated and supported by extensive experiments and analysis.
Supporting Arguments
The paper provides a clear and well-structured presentation of the approach, including the architecture, training procedure, and evaluation metrics. The authors demonstrate the effectiveness of OPnet in various retrieval tasks, including instance and categorical retrieval, and show that it outperforms existing approaches. The paper also provides a thorough analysis of the view-manifold learned by OPnet and its correlation with human perceptual similarity judgment. The results are impressive, with OPnet achieving a significant improvement in instance retrieval tasks and a higher correlation with human perception.
Additional Feedback and Questions
To further improve the paper, I suggest that the authors provide more details on the rendering process of the multi-view datasets and the selection of the margin parameter in the triplet loss function. Additionally, it would be interesting to see more experiments on the transferability of OPnet to other domains, such as real-world images or videos. I would like the authors to answer the following questions: (1) How do the authors plan to extend OPnet to handle more complex variations, such as lighting and scale, in real-world environments? (2) Can the authors provide more insights into the hierarchical structure of the view-manifold learned by OPnet and its relation to human perceptual similarity judgment?