Summary of the Paper's Contributions
The paper proposes a simple yet effective baseline for detecting misclassified or out-of-distribution examples in machine learning models. The authors utilize the maximum softmax probability as a detection metric, demonstrating its efficacy across various computer vision, natural language processing, and automatic speech recognition tasks. Additionally, they introduce an abnormality module that exploits the internal representations of neural networks to improve detection performance.
Decision and Key Reasons
I decide to accept this paper with minor revisions. The two key reasons for this decision are: (1) the paper tackles an important and underexplored problem in machine learning, and (2) the proposed baseline and abnormality module demonstrate promising results across multiple tasks and datasets.
Supporting Arguments
The paper is well-motivated, and the authors provide a clear problem formulation and evaluation metrics. The experimental results are convincing, showing that the softmax prediction probability baseline is effective in detecting misclassified or out-of-distribution examples. The introduction of the abnormality module further improves detection performance, demonstrating the potential for future research in this area.
Additional Feedback and Questions
To improve the paper, I suggest that the authors provide more detailed comparisons with competing methods, such as Factorization Machines, to strengthen their claims. Additionally, it would be helpful to include more analysis on the limitations of the proposed approach and potential avenues for future research. Some questions I would like the authors to address include: (1) How do the results change when using different neural network architectures or training protocols? (2) Can the abnormality module be applied to other types of machine learning models, such as decision trees or support vector machines? (3) How does the proposed approach perform in real-world scenarios where the distribution of the data may change over time?