This paper presents a novel approach to learning activation functions in deep neural networks using a nonparametric framework. The authors propose a principled method for estimating activation functions through a Fourier basis expansion, which allows for more flexible and expressive models. The paper provides a thorough theoretical justification for the approach, including a generalization bound for fully connected networks with the proposed activation functions.
The results of the paper are promising, with experiments on MNIST and CIFAR-10 datasets showing improved performance compared to baseline models. The authors also introduce a two-stage training procedure, which helps to stabilize the training process and improve the performance of the model.
However, the paper is lengthy and difficult to follow, with some concepts and notation that could be clarified and condensed for better understanding. The authors are recommended to condense the paper and move detailed mathematical developments to a supplementary document to convey the central message more effectively.
To evaluate this paper, I considered the following key questions:
1. What is the specific question/problem tackled by the paper? The paper addresses the problem of learning activation functions in deep neural networks.
2. Is the approach well motivated, including being well-placed in the literature? The approach is well motivated, and the authors provide a clear overview of the related work in the field.
3. Does the paper support the claims? The paper provides theoretical justification and experimental results to support the claims, although some of the mathematical developments could be clarified.
Based on these questions, I decide to accept the paper, but with some revisions to improve clarity and readability. The paper makes a significant contribution to the field of deep learning, and the results are promising. However, the authors need to address the issues with clarity and notation to make the paper more accessible to a broader audience.
Some additional feedback and questions for the authors:
* Could you provide more intuition and explanation for the choice of Fourier basis expansion for the activation functions?
* How do the authors plan to extend the approach to more complex models and datasets?
* Could you provide more details on the implementation and training procedure for the two-stage training approach?
* How do the authors plan to address the potential issue of overfitting with the nonparametric activation functions?