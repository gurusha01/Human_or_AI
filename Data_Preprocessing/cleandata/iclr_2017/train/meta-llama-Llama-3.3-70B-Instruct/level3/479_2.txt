Summary of the Paper's Contributions
The paper proposes a novel approach to neural architecture search, using a recurrent neural network (RNN) as a controller to generate model descriptions of neural networks. The controller is trained with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. The authors demonstrate the effectiveness of their approach on two challenging benchmarks: CIFAR-10 and Penn Treebank. The results show that the proposed method can design novel architectures that rival the best human-invented architectures in terms of test set accuracy.
Decision and Key Reasons
Based on the review, I decide to Accept the paper. The two key reasons for this decision are:
1. The paper proposes a well-motivated and novel approach to neural architecture search, which is a significant contribution to the field.
2. The experimental results demonstrate the effectiveness of the proposed method on two challenging benchmarks, showing that it can design novel architectures that rival the best human-invented architectures.
Supporting Arguments
The paper provides a clear and well-written introduction to the problem of neural architecture search and the proposed approach. The authors provide a thorough review of related work and demonstrate a good understanding of the field. The experimental results are well-presented and demonstrate the effectiveness of the proposed method. The authors also provide a detailed description of the controller RNN and the reinforcement learning algorithm used to train it.
Additional Feedback and Questions
To improve the paper, I would like to see more analysis of the search space and the optimization process. Specifically, I would like to know more about the distribution of the architectures generated by the controller RNN and how the reinforcement learning algorithm converges. I also have some questions about the implementation details, such as:
* Can you provide more details about the MLP setting used in the composing module of the proposed model?
* How did you select the hidden state sizes, specifically the choice of 436?
* Can you provide more ablation studies to investigate the effect of using different values of T on the model's performance?
* What is the distribution of T in the testing data, particularly in relation to the adaptive computation model's stopping criterion of P_T < 0?
Overall, the paper is well-written and provides a significant contribution to the field of neural architecture search. With some additional analysis and clarification of the implementation details, the paper can be even stronger.