The paper "Semi-Supervised Learning in Variational Autoencoders" presents a novel framework for incorporating domain knowledge into variational autoencoders (VAEs) to learn disentangled representations. The authors propose a semi-supervised learning approach that allows for flexible specification of probabilistic encoders as directed graphical models, enabling the incorporation of structural constraints and domain knowledge into the recognition network.
The paper claims to contribute a new formulation of semi-supervised learning in VAEs, which permits the specification of probabilistic encoders as directed graphical models via a stochastic computation graph. The authors demonstrate the effectiveness of their approach on several datasets, including MNIST, SVHN, and Yale B, and show that their method can learn disentangled representations with minimal supervision.
I decide to accept this paper, with two key reasons for this choice: (1) the paper presents a novel and well-motivated approach to semi-supervised learning in VAEs, and (2) the experimental results demonstrate the effectiveness of the proposed method in learning disentangled representations.
The paper provides a clear and well-structured presentation of the proposed framework, including a detailed description of the variational objective and the modified training procedure. The authors also provide a thorough discussion of related work and demonstrate a good understanding of the existing literature on VAEs and semi-supervised learning.
The experimental results are impressive, showing that the proposed method can learn disentangled representations with minimal supervision. The results on MNIST and SVHN demonstrate the ability of the method to learn disentangled representations of digits and styles, while the results on Yale B show the ability to learn disentangled representations of faces.
To improve the paper, I suggest that the authors provide more details on the implementation of the stochastic computation graph and the plug-in estimator for discrete variables. Additionally, the authors could provide more discussion on the choice of hyperparameters and the supervision rate, and how these affect the performance of the method.
Some questions I would like the authors to answer include: (1) How do the authors choose the structure of the graphical model for the recognition network, and what is the effect of different structures on the performance of the method? (2) Can the authors provide more details on the implementation of the plug-in estimator for discrete variables, and how it compares to other methods such as REINFORCE-style estimators? (3) How do the authors plan to extend the proposed framework to more complex datasets and tasks, such as image segmentation or object detection?