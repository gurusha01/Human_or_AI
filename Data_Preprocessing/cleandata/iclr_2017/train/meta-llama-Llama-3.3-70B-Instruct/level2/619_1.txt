Summary
The paper proposes a simple yet effective technique for training deep neural networks by adding annealed Gaussian noise to the gradient. The authors demonstrate the broad applicability of this method to various complex neural network architectures, including deep fully-connected networks, End-To-End Memory Networks, Neural Programmer, Neural Random Access Machines, and Convolutional Gated Recurrent Networks. The results show consistent improvements in performance across these models, with the added noise helping to avoid overfitting and achieve lower training loss.
Decision
I decide to accept this paper, with the main reasons being the novelty and effectiveness of the proposed technique, as well as the thorough experimentation and analysis provided.
Supporting Arguments
The paper presents a well-motivated approach to addressing the optimization challenges in deep neural networks. The authors provide a clear explanation of the technique and its potential benefits, and support their claims with extensive experimental results. The experiments demonstrate the robustness of the method to different models, hyperparameters, and initialization schemes. The paper also provides a thorough discussion of related work and the differences between the proposed technique and existing methods.
Additional Feedback
To further improve the paper, I suggest that the authors provide more insight into the theoretical foundations of the proposed technique. While the paper mentions the connection to Stochastic Gradient Langevin Dynamics, a more detailed analysis of the underlying mathematical principles would be beneficial. Additionally, it would be interesting to see more experiments on the sensitivity of the method to the noise hyperparameters and the potential applications of the technique to other optimization problems.
Questions for the Authors
1. Can you provide more intuition on why the annealed Gaussian noise schedule is more effective than a fixed noise schedule?
2. How do you think the proposed technique would perform on other optimization problems, such as reinforcement learning or generative models?
3. Are there any potential limitations or drawbacks to using the proposed technique, and how might they be addressed?