This paper presents a novel approach to extractive question answering, specifically designed for the SQUAD dataset. The authors propose a model architecture called RASOR, which efficiently builds fixed-length representations of all spans in the evidence document using a recurrent network. The key contribution of this paper is the ability to explicitly represent and score answer span candidates, allowing for global normalization during training and exact decoding during evaluation.
I decide to accept this paper, with the main reason being that it presents a well-motivated and novel approach to extractive question answering, with significant improvements over existing baselines. The paper is well-written, and the authors provide a clear and detailed explanation of their model architecture and experimental setup.
The approach is well-motivated, and the authors provide a thorough analysis of the task and the limitations of existing approaches. The use of recurrent span representations and the incorporation of both passage-independent and passage-aligned question representations are significant contributions to the field. The experimental results demonstrate the effectiveness of the proposed approach, with a 5% improvement over the best published results and a 50% reduction in error compared to the baseline.
To further improve the paper, I suggest that the authors provide more analysis on the failure cases of their model, such as the example shown in Figure 2, where the endpoint predictor underpredicts single-word answer spans and overpredicts longer answer spans. Additionally, it would be interesting to see more examples of the attention masks for both question representations, as shown in Figure 3, to gain a better understanding of how the model is using the question information.
Some questions I would like the authors to answer to clarify my understanding of the paper include: How do the authors plan to address the issue of overpredicting longer answer spans, and what are the potential limitations of using a recurrent network to build span representations? How do the authors plan to extend their approach to other question answering datasets, and what are the potential challenges and opportunities in doing so?