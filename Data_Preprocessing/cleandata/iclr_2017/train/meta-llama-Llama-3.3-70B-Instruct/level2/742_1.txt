This paper presents a comprehensive study on the expressive power of deep neural networks, focusing on the relationship between network depth, width, and expressivity. The authors introduce three natural measures of expressivity: neuron transitions, activation patterns, and dichotomies, and demonstrate that all three measures exhibit an exponential dependence on the depth of the network. They also prove that these measures are related to a fourth quantity, trajectory length, which grows exponentially with depth.
The paper is well-motivated, and the authors provide a clear overview of the current state of research on neural network expressivity. The theoretical analysis is rigorous, and the experimental results support the theoretical findings. The authors also explore the consequences of their results for trained networks, including the effect of training on the input-output map and the trade-off between stability and expressivity.
I decide to accept this paper because it presents a significant contribution to the understanding of neural network expressivity, and the results have important implications for the design and training of deep neural networks. The paper is well-written, and the authors provide a clear and concise presentation of their results.
To further improve the paper, I suggest that the authors provide more details on the experimental setup and the implementation of the random network architecture. Additionally, it would be interesting to see more results on the effect of training on the input-output map, including the trade-off between stability and expressivity.
Some questions I would like the authors to answer to clarify my understanding of the paper include:
* Can the authors provide more intuition on why the trajectory length grows exponentially with depth?
* How do the results on random networks translate to trained networks, and what are the implications for neural network design and training?
* Can the authors provide more details on the experimental results on Convolutional Networks, and how they compare to the results on fully connected networks?