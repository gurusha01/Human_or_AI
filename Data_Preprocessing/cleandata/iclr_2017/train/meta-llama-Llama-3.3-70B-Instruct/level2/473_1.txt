The paper claims to introduce a novel theoretical framework for language modeling that improves learning by utilizing the metric space of word embeddings. The authors propose a loss framework that augments the conventional cross-entropy loss with an additional term that minimizes the KL-divergence between the model's prediction and an estimated target distribution based on word embeddings. This leads to a second improvement, which is reusing the input embedding matrix in the output projection layer, reducing the number of trainable variables.
I decide to accept this paper with two key reasons: (1) the paper presents a well-motivated approach that addresses the limitations of the conventional classification framework in language modeling, and (2) the authors provide empirical evidence that their proposed framework outperforms the conventional one on two benchmark datasets, Penn Treebank and Wikitext-2.
The paper provides a clear and detailed explanation of the proposed framework, including the theoretical analysis and empirical validation. The authors also discuss the related work and highlight the differences between their approach and existing methods. The experimental results demonstrate the effectiveness of the proposed framework, and the authors provide a thorough analysis of the results, including the impact of the augmented loss and the reuse of word embeddings on the performance of the model.
To further improve the paper, I suggest that the authors provide more insights into the choice of hyperparameters, such as the temperature parameter τ and the weight of the augmented loss α. Additionally, it would be interesting to see more qualitative results, such as examples of generated text or analysis of the word embeddings learned by the model.
I would like to ask the authors to clarify the following points: (1) How do the authors choose the value of τ and α, and what is the sensitivity of the results to these hyperparameters? (2) Can the authors provide more examples of the qualitative results, such as generated text or analysis of the word embeddings learned by the model? (3) How do the authors plan to extend their framework to other NLP tasks, such as neural machine translation or text summarization?