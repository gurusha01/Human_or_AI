This paper proposes an approximate strategy, called adaptive softmax, to efficiently train neural network-based language models over very large vocabularies. The approach exploits the unbalanced word distribution to form clusters that minimize computational complexity, making it particularly suited for graphical processing units (GPUs). The authors claim that their method achieves a significant acceleration factor compared to the regular softmax, with 2× to 10× speed-ups, while maintaining an accuracy close to that of the full softmax.
I decide to accept this paper, with the main reasons being that the approach is well-motivated, and the results are correct and scientifically rigorous. The authors provide a clear and detailed explanation of their method, and the experiments demonstrate the effectiveness of the approach on standard benchmarks.
The supporting arguments for this decision include the fact that the authors provide a thorough analysis of the computational complexity of their approach and demonstrate its efficiency on GPUs. The experimental results show that the adaptive softmax achieves state-of-the-art performance on several benchmarks, including the One Billion Word benchmark, while being significantly faster than other approximate methods.
Additional feedback to improve the paper includes providing more details on the optimization process, such as the choice of hyperparameters and the convergence criteria. It would also be helpful to include more comparisons with other approximate methods, such as the differentiated softmax, to further demonstrate the advantages of the adaptive softmax.
Questions I would like the authors to answer include: (1) How do the authors choose the number of clusters (J) in the adaptive softmax, and what is the effect of this parameter on the performance of the model? (2) Can the authors provide more details on the computational complexity model used in the paper, and how it is derived? (3) How does the adaptive softmax perform on other tasks, such as machine translation or automatic speech recognition, where the vocabulary size is large? 
These questions will help clarify the paper and provide more evidence for the effectiveness of the adaptive softmax approach. Overall, the paper is well-written, and the approach is well-motivated and effective, making it a strong contribution to the field of natural language processing.