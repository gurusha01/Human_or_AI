This paper explores the concept of neural networks learning to protect information from other neural networks, specifically in the context of multiagent systems and confidentiality properties. The authors propose a framework where neural networks, referred to as Alice and Bob, learn to communicate securely without being prescribed specific cryptographic algorithms. Instead, they are trained end-to-end, adversarially, to defeat a third neural network, Eve, which attempts to eavesdrop on their communication.
The paper claims to demonstrate that neural networks can learn to perform forms of encryption and decryption, as well as apply these operations selectively to meet confidentiality goals. The authors also explore the concept of asymmetric encryption and provide experimental results.
I decide to accept this paper, with the main reason being that it presents a novel and intriguing approach to learning cryptographic concepts using neural networks. The paper is well-motivated, and the authors provide a clear explanation of their framework and experimental results.
The approach is well-placed in the literature, drawing on concepts from cryptography, machine learning, and multiagent systems. The authors provide a comprehensive review of background concepts and related work, making the paper accessible to a broad audience.
The results presented in the paper are promising, demonstrating that neural networks can learn to protect information from other neural networks. The experiments are well-designed, and the authors provide a detailed analysis of their results.
To improve the paper, I suggest that the authors provide more discussion on the limitations of their approach and potential avenues for future work. Additionally, it would be helpful to include more details on the neural network architectures used and the training procedures employed.
Some questions I would like the authors to answer include: How do the authors plan to address the issue of "security by obscurity" in their approach, and what steps can be taken to ensure that the learned cryptographic concepts are robust and generalizable? How do the authors envision their approach being applied in real-world scenarios, and what potential challenges or limitations may arise in such contexts? 
Overall, the paper presents a fascinating exploration of the intersection of machine learning and cryptography, and I believe it has the potential to contribute meaningfully to the field.