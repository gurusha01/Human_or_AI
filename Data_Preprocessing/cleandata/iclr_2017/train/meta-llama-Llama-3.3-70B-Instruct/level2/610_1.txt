This paper claims to provide a comprehensive analysis of different defensive strategies against various adversary models in the context of deep neural networks (DNNs) and adversarial examples. The authors evaluate the robustness of several defensive methods, including the adversarial retraining framework (RAD), AutoEncoder stacked with Classifier (AEC), Improved AutoEncoder stacked with Classifier (IAEC), and Distillation, against different adversary models such as Fast Gradient Sign, Coordinate Greedy, and Adam.
I decide to accept this paper with minor revisions. The main reason for this decision is that the paper provides a thorough analysis of different defensive strategies against various adversary models, which is a significant contribution to the field of adversarial machine learning. The authors also propose an improved AutoEncoder stacked with Classifier (IAEC) method, which shows promising results in defending against adversarial examples.
The supporting arguments for this decision include the fact that the paper provides a clear and well-structured presentation of the problem, the proposed methods, and the experimental results. The authors also provide a comprehensive review of related work, which demonstrates their understanding of the current state of research in this area. Additionally, the experimental results show that the proposed RAD method outperforms other defensive methods in terms of robustness against different adversary models.
However, there are some minor issues that need to be addressed. For example, the paper could benefit from a more detailed discussion of the limitations of the proposed methods and the potential avenues for future research. Additionally, some of the figures and tables could be improved for better clarity and readability.
To improve the paper, I suggest that the authors provide more insights into the tradeoff between robustness and accuracy on normal data, as well as the computational cost of the proposed methods. I also ask the authors to clarify the following questions:
* How do the authors plan to extend the proposed methods to more complex datasets and real-world applications?
* What are the potential limitations of the proposed RAD method, and how can they be addressed in future research?
* How do the authors plan to balance the tradeoff between robustness and accuracy on normal data, and what are the implications of this tradeoff for real-world applications?