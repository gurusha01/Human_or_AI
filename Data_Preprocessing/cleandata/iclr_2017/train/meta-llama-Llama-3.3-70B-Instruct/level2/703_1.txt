This paper presents Tartan (TRT), a hardware accelerator for inference with Deep Neural Networks (DNNs) that exploits the variable per-layer precision requirements of DNNs to deliver execution time proportional to the precision used per layer. The authors claim that TRT outperforms a state-of-the-art bit-parallel accelerator by 1.90× without any loss in accuracy, while being 1.17× more energy efficient.
I decide to Accept this paper, with the main reasons being:
1. The paper tackles a specific and well-motivated problem in the field of DNN acceleration, which is the varying precision requirements across different layers.
2. The approach is well-supported by experiments on image classification CNNs, demonstrating significant performance and energy efficiency improvements over a state-of-the-art bit-parallel accelerator.
The supporting arguments for this decision include:
* The paper provides a clear and detailed explanation of the TRT architecture and its components, including the Serial Inner-Product Units (SIPs) and the Dispatcher and Reducer units.
* The experimental results demonstrate the effectiveness of TRT in reducing execution time and energy consumption, while maintaining accuracy.
* The paper discusses the limitations of the current work, including the assumption that each layer fits on-chip and the lack of exploration of memory compression techniques.
Additional feedback to improve the paper includes:
* Providing more details on the methodology used to determine the per-layer precision profiles, and how these profiles are used to configure the TRT architecture.
* Exploring the potential benefits of combining TRT with other techniques, such as pruning and quantization, to further improve performance and energy efficiency.
* Investigating the applicability of TRT to other types of neural networks and machine learning algorithms.
Questions to the authors:
* Can you provide more information on how the per-layer precision profiles are determined, and how these profiles are used to configure the TRT architecture?
* How do you plan to address the limitation of assuming that each layer fits on-chip, and what are the potential implications of this assumption on the scalability of TRT?
* Have you considered exploring the potential benefits of combining TRT with other techniques, such as pruning and quantization, to further improve performance and energy efficiency?