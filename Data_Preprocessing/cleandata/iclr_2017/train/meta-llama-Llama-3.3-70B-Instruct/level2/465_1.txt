This paper presents a comprehensive study on the transferability of adversarial examples in deep neural networks, specifically focusing on large models and a large-scale dataset, ImageNet. The authors investigate both non-targeted and targeted adversarial examples, and propose novel ensemble-based approaches to generate transferable targeted adversarial examples.
The paper claims to contribute to the field by: (1) conducting an extensive study of transferability over large models and a large-scale dataset, (2) proposing ensemble-based approaches to generate transferable targeted adversarial examples, and (3) demonstrating the effectiveness of these approaches in attacking a black-box image classification system, Clarifai.com.
Based on the content of the paper, I decide to accept this paper. The reasons for this decision are two-fold. Firstly, the paper presents a thorough and well-motivated study on the transferability of adversarial examples, which is a crucial aspect of deep learning security. The authors provide a clear and concise overview of the problem, and their experimental results are well-organized and easy to follow. Secondly, the proposed ensemble-based approaches demonstrate significant improvements over existing methods in generating transferable targeted adversarial examples, which is a notable contribution to the field.
The supporting arguments for this decision include: (1) the paper's thorough evaluation of existing approaches for generating adversarial examples, (2) the proposal of novel ensemble-based approaches that demonstrate improved performance, and (3) the successful attack on Clarifai.com, which demonstrates the practical significance of the proposed approaches.
To further improve the paper, I provide the following feedback: (1) consider providing more detailed analysis on the geometric properties of the models, particularly on the decision boundaries of the targeted ensemble-based approaches, (2) include more examples of targeted adversarial examples that can mislead Clarifai.com to make predictions semantically similar to the target labels, and (3) discuss potential limitations and future directions of the proposed approaches.
Some questions I would like the authors to answer to clarify my understanding of the paper include: (1) How do the ensemble-based approaches perform when the number of models in the ensemble is varied? (2) Can the authors provide more insights on why the fast gradient-based approaches perform poorly in generating targeted adversarial examples? (3) How do the proposed approaches compare to other existing methods in terms of computational efficiency and scalability?