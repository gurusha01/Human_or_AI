This paper presents PixelCNN++, a modified version of the PixelCNN generative model, which introduces several key improvements, including a discretized logistic mixture likelihood, conditioning on whole pixels, downsampling, additional short-cut connections, and regularization using dropout. The authors claim that these modifications simplify the model structure and improve its performance, achieving state-of-the-art log-likelihood results on the CIFAR-10 dataset.
I decide to accept this paper, with the main reason being that the approach is well-motivated and supported by thorough experimental evaluations. The authors provide a clear and detailed explanation of their modifications, and the results demonstrate significant improvements over the original PixelCNN model.
The paper is well-structured, and the authors provide a comprehensive overview of the related work in the field. The experimental evaluations are thorough, and the authors provide a detailed analysis of the results, including ablation studies to demonstrate the effectiveness of each modification.
One potential area for improvement is the discussion of the limitations of the model. While the authors mention some limitations, such as the potential for overfitting, they could provide a more detailed analysis of the model's weaknesses and potential areas for future improvement.
To further improve the paper, I would suggest that the authors provide more visualizations of the generated images, particularly for the class-conditional model. Additionally, it would be helpful to include a more detailed comparison with other state-of-the-art generative models, such as GANs and VAEs.
Some questions I would like the authors to answer include: How do the authors plan to extend the model to other datasets and applications? What are the potential implications of using a discretized logistic mixture likelihood, and how does it compare to other likelihood models? How do the authors plan to address the issue of overfitting, and what are the potential consequences of using dropout regularization?
Overall, the paper presents a significant contribution to the field of generative modeling, and the authors provide a thorough and well-motivated explanation of their approach. With some minor revisions to address the limitations and provide more visualizations and comparisons, the paper has the potential to be a strong contribution to the conference.