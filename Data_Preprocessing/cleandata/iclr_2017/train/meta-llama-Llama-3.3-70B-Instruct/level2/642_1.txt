This paper explores the implications of numeric representation and precision of DNN model weights and activations on computational efficiency. The authors investigate unconventional narrow-precision floating-point representations and their impact on inference accuracy and efficiency. They propose a novel technique to efficiently traverse the large design space and find an optimal design, achieving an average speedup of 7.6Ã— with less than 1% degradation in inference accuracy on production-grade DNNs.
I decide to accept this paper, with the key reasons being the thorough exploration of the design space and the significant improvement in computational efficiency achieved by the proposed technique. The paper provides a comprehensive evaluation of the accuracy-efficiency trade-offs for various numeric representations and demonstrates the effectiveness of the proposed search method in finding optimal customized precision configurations.
The paper is well-motivated, and the approach is well-placed in the literature. The authors provide a clear and detailed explanation of the methodology and experiments, making it easy to follow and understand the results. The evaluation of the proposed technique on large-scale DNNs is a significant strength of the paper, as it demonstrates the practical applicability of the approach.
To further improve the paper, I suggest that the authors provide more details on the implementation of the proposed technique and its integration with existing deep learning frameworks. Additionally, it would be interesting to see an analysis of the energy consumption and area requirements of the proposed customized precision hardware.
Some questions I would like the authors to answer to clarify my understanding of the paper include: How do the authors plan to extend the proposed technique to other types of neural networks, such as recurrent neural networks or long short-term memory networks? How do the authors ensure that the proposed technique is robust to variations in the input data and network architecture? What are the potential applications of the proposed technique in real-world scenarios, such as edge computing or autonomous vehicles?