This paper claims to contribute to the field of deep learning by systematically exploring the regularization of neural networks through penalizing low entropy output distributions. The authors propose a confidence penalty, which acts as a strong regularizer in supervised learning, and connect it to label smoothing through the direction of the KL divergence. They evaluate the proposed confidence penalty and label smoothing on six common benchmarks, including image classification, language modeling, machine translation, and speech recognition, and find that both methods improve state-of-the-art models across benchmarks without modifying existing hyperparameters.
Based on the content of the paper, I decide to accept it. The two main reasons for this decision are: (1) the paper tackles a specific and well-motivated question, namely, the regularization of neural networks through output distributions, and (2) the approach is well-supported by experiments on multiple benchmarks, demonstrating the effectiveness of the proposed confidence penalty and label smoothing.
The paper provides a clear and well-structured presentation of the problem, related work, and proposed approach. The authors motivate the use of output regularizers and provide a thorough analysis of the confidence penalty and its connection to label smoothing. The experimental evaluation is comprehensive, covering multiple benchmarks and comparing the proposed methods to existing state-of-the-art models.
To further improve the paper, I suggest that the authors provide more detailed analysis of the results, including a discussion of the limitations of the proposed methods and potential avenues for future work. Additionally, it would be helpful to include more visualizations, such as plots of the gradient norms and entropy values, to provide a clearer understanding of the effects of the confidence penalty and label smoothing.
Some questions I would like the authors to answer to clarify my understanding of the paper include: (1) How do the authors choose the hyperparameters for the confidence penalty and label smoothing, and what is the sensitivity of the results to these hyperparameters? (2) Can the authors provide more insight into the relationship between the confidence penalty and label smoothing, and how they complement each other? (3) What are the potential applications of the proposed methods beyond the benchmarks evaluated in the paper, and how can they be extended to other domains?