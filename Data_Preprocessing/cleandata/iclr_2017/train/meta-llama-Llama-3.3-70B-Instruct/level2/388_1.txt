The paper introduces the Dynamic Coattention Network (DCN) for question answering, which addresses the limitation of single-pass deep learning models by allowing the model to recover from local maxima corresponding to incorrect answers. The DCN consists of a coattentive encoder that captures the interactions between the question and the document, and a dynamic pointing decoder that iterates over potential answer spans. The paper claims that the DCN achieves state-of-the-art results on the Stanford Question Answering dataset, with a single model obtaining an F1 score of 75.9% and an ensemble model obtaining an F1 score of 80.4%.
I decide to accept this paper, with the main reason being that it presents a novel and well-motivated approach to question answering, and the results demonstrate a significant improvement over previous state-of-the-art models. The paper is well-written, and the authors provide a clear explanation of the DCN architecture and its components. The experimental results are thorough, and the authors provide a detailed analysis of the model's performance on different question types and document lengths.
One of the strengths of the paper is the introduction of the coattentive encoder, which allows the model to capture the interactions between the question and the document in a more effective way. The dynamic pointing decoder is also a novel component, which enables the model to iteratively update its estimates of the answer span. The paper provides a clear explanation of how these components work together to improve the model's performance.
To further improve the paper, I would suggest that the authors provide more analysis on the limitations of the DCN, such as its performance on questions that require multiple sentences or complex reasoning. Additionally, it would be interesting to see a comparison with other state-of-the-art models on different question answering datasets.
Some questions I would like the authors to answer include: How does the DCN perform on questions that require multiple sentences or complex reasoning? Can the authors provide more analysis on the coattentive encoder and how it captures the interactions between the question and the document? How does the dynamic pointing decoder handle cases where there are multiple plausible answer spans? 
Overall, the paper presents a significant contribution to the field of question answering, and the results demonstrate a substantial improvement over previous state-of-the-art models. With some additional analysis and experimentation, the paper has the potential to be even stronger.