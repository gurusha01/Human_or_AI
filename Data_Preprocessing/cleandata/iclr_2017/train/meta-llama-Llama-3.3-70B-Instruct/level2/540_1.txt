This paper presents a systematic study on network morphism, a learning scheme that enables the transformation of a well-trained neural network into a new one with preserved network function. The authors investigate the problem of network morphism at a higher level, focusing on the morphing of convolutional layers into arbitrary modules. The paper claims to provide a theoretical upper bound for the capability of this learning scheme and demonstrates its effectiveness through extensive experiments on benchmark datasets.
I decide to accept this paper with the following key reasons: 
1. The paper tackles a specific and well-defined problem in the field of neural networks, and the approach is well-motivated and well-placed in the literature.
2. The paper provides a clear and concise formulation of the network morphism problem as a graph transformation process, and the proposed morphing algorithms for simple and complex modules are well-explained and supported by theoretical analysis.
The supporting arguments for the decision include:
* The paper provides a thorough review of related work on knowledge transfer and modularized network architectures, demonstrating a good understanding of the field.
* The proposed graph abstraction for network morphism is novel and effective, allowing for the formulation of the morphing process as a graph transformation problem.
* The experimental results on benchmark datasets demonstrate the effectiveness of the proposed morphing approach, achieving significant performance improvements with minimal extra computational cost.
Additional feedback to improve the paper includes:
* Providing more detailed explanations of the algorithms and theoretical analysis, particularly for the complex modules.
* Including more visualizations of the morphing process and the resulting network architectures to help illustrate the concepts.
* Discussing potential limitations and future directions of the proposed approach, such as its applicability to other types of neural networks or its potential for transfer learning.
Questions to be answered by the authors include:
* Can the proposed approach be extended to other types of neural networks, such as recurrent neural networks or generative adversarial networks?
* How does the proposed approach compare to other knowledge transfer methods, such as fine-tuning or weight sharing?
* Are there any potential applications of the proposed approach beyond image classification, such as object detection or segmentation?