The paper "Neural Architecture Search" presents a novel approach to designing neural network architectures using a recurrent neural network (RNN) as a controller. The controller generates model descriptions of neural networks and is trained with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. The authors demonstrate the effectiveness of their approach on two challenging benchmarks: CIFAR-10 and Penn Treebank.
I decide to accept this paper with two key reasons: (1) the approach is well-motivated and grounded in the literature, and (2) the empirical results are strong and demonstrate the potential of the method.
The authors provide a clear and concise overview of the related work, highlighting the limitations of existing methods and the benefits of their approach. The use of an RNN as a controller allows for flexible and variable-length architecture search, which is a significant improvement over existing methods. The authors also provide a detailed description of their method, including the training procedure and the use of reinforcement learning.
The empirical results are impressive, with the authors demonstrating that their approach can design novel architectures that rival the best human-invented architectures on both CIFAR-10 and Penn Treebank. The results are also well-supported by ablation studies and control experiments, which provide additional evidence for the effectiveness of the method.
To further improve the paper, I suggest that the authors provide more details on the computational resources required to train the controller and the child networks. Additionally, it would be helpful to include more visualizations of the generated architectures to provide a better understanding of the search process.
Some questions I would like the authors to answer to clarify my understanding of the paper include: (1) How did the authors choose the hyperparameters for the controller and the child networks? (2) Can the authors provide more details on the implementation of the reinforcement learning algorithm and the reward function used? (3) How do the authors plan to extend their approach to more complex tasks and larger datasets?
Overall, the paper presents a significant contribution to the field of neural architecture search and has the potential to impact the development of more efficient and effective neural network architectures.