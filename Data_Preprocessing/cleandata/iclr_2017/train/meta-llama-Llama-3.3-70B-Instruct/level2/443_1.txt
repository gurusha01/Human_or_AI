This paper proposes a novel approach to sequence-to-sequence transduction by formulating it as a noisy channel decoding problem. The authors use recurrent neural networks to parameterize the source and channel models, allowing them to leverage unpaired output data to improve performance. The paper claims that this approach outperforms direct models, especially when large amounts of unpaired output data are available.
I decide to accept this paper, with the main reason being that it presents a well-motivated and well-executed approach to sequence-to-sequence transduction. The paper is well-written, and the authors provide a clear explanation of their model, as well as thorough experimental evaluations on several tasks.
The supporting arguments for my decision are as follows. Firstly, the paper tackles a specific and well-defined problem in sequence-to-sequence transduction, and the proposed approach is well-motivated by the need to leverage unpaired output data. Secondly, the authors provide a thorough evaluation of their model on several tasks, including abstractive sentence summarization, machine translation, and morphological inflection generation. The results show that the noisy channel model outperforms direct models, especially when large amounts of unpaired output data are available.
To further improve the paper, I would like to see more analysis on the limitations of the proposed approach, as well as more comparisons to other related work. Specifically, I would like to know more about how the noisy channel model handles cases where the input and output sequences have different lengths or structures. Additionally, I would like to see more comparisons to other approaches that leverage unpaired output data, such as the work by Gülçehre et al. (2015) and Sennrich et al. (2016).
Some questions I would like the authors to answer are: (1) How do the authors plan to handle cases where the input and output sequences have different lengths or structures? (2) Can the authors provide more comparisons to other approaches that leverage unpaired output data? (3) How do the authors plan to extend their approach to other sequence-to-sequence tasks, such as dialogue generation or text generation? 
Overall, I think this paper presents a significant contribution to the field of sequence-to-sequence transduction, and I believe it has the potential to inspire further research in this area.