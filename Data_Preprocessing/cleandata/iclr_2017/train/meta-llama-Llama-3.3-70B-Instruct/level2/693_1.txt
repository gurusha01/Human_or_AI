This paper presents a new class of conditional deep generative models called generative matching networks, which are capable of fast adaptation to conditioning datasets. The authors propose a nonparametric matching procedure that enables the model to define the label space itself, extending the applicability of matching networks to unsupervised and semi-supervised settings.
I decide to accept this paper, with two key reasons for this choice. Firstly, the paper tackles a specific and well-defined problem in deep generative models, namely the necessity of extensive training and difficulties with generalization from small numbers of training examples. Secondly, the approach is well-motivated and placed in the literature, with a clear explanation of the limitations of existing methods and how the proposed model addresses these limitations.
The paper provides a thorough explanation of the background and related work, and the proposed model is well-described and evaluated on the Omniglot dataset. The results demonstrate the ability of generative matching networks to adapt to new concepts and datasets, and the model is shown to outperform several baselines. The authors also provide additional experiments and evaluations, including transfer to a new domain (MNIST) and classification tasks, which further demonstrate the potential of the proposed model.
To improve the paper, I suggest that the authors provide more details on the computational cost and efficiency of the proposed model, as well as a more thorough analysis of the limitations and potential drawbacks of the approach. Additionally, it would be helpful to see more visualizations and examples of the generated samples, to better understand the quality and diversity of the outputs.
Some questions I would like the authors to answer to clarify my understanding of the paper include: How does the choice of hyperparameters (e.g. number of attention steps, size of the conditioning dataset) affect the performance of the model? Can the authors provide more insight into the learned representations and features extracted by the model? How does the model perform on more complex datasets and tasks, such as image generation or text-to-image synthesis? 
Overall, the paper presents a significant contribution to the field of deep generative models, and the proposed model has the potential to be useful in a variety of applications. With some additional clarification and analysis, the paper could be even stronger and more impactful.