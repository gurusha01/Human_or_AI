This paper proposes a novel approach to question classification by utilizing answer data to improve question representation. The authors introduce Group Sparse Autoencoders (GSA) and Group Sparse Convolutional Neural Networks (GSCNNs) to encode answer information into question representation. The GSA is a neural network-based model that learns a dictionary with group sparse constraints, while the GSCNNs incorporate GSA into traditional convolutional neural networks to learn question representations with respect to their corresponding answers.
The paper claims that the proposed model shows significant improvements over strong baselines on four datasets. The authors argue that traditional question classification techniques do not fully utilize the well-prepared answer data, which has great potential for improving question representation.
I decide to accept this paper with the following reasons:
1. The paper tackles a specific question/problem in question classification, which is a well-defined and important task in natural language processing.
2. The approach is well-motivated, and the authors provide a clear explanation of the limitations of traditional question classification techniques and the potential benefits of utilizing answer data.
3. The paper supports its claims with empirical results on four datasets, demonstrating the effectiveness of the proposed model.
The supporting arguments for my decision include:
* The paper provides a thorough analysis of the limitations of traditional question classification techniques and the potential benefits of utilizing answer data.
* The authors propose a novel approach that combines the strengths of dictionary learning and sparse coding models with the flexibility of neural networks.
* The empirical results demonstrate the effectiveness of the proposed model, with significant improvements over strong baselines on four datasets.
Additional feedback to improve the paper includes:
* Providing more details on the datasets used in the experiments, such as the size of the datasets and the distribution of question categories.
* Discussing the potential applications of the proposed model beyond question classification, such as in other natural language processing tasks that involve utilizing external knowledge or context.
* Considering the use of other evaluation metrics beyond accuracy, such as F1-score or mean average precision, to provide a more comprehensive evaluation of the proposed model.
Questions I would like the authors to answer include:
* How do the authors plan to handle cases where the answer data is not well-prepared or is noisy?
* Can the authors provide more insights into the visualization of the projection matrix and activations in the GSA model, and how they relate to the question classification task?
* How do the authors plan to extend the proposed model to other natural language processing tasks that involve utilizing external knowledge or context?