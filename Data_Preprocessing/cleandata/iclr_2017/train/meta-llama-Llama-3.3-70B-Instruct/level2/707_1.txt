The paper proposes a general class of language models that treat reference as an explicit stochastic latent variable, allowing models to create mentions of entities and their attributes by accessing external databases and internal state. The authors claim that their model outperforms models based on deterministic attention in three tasks: dialogue modeling, recipe generation, and coreference-based language modeling.
I decide to accept this paper with two key reasons: (1) the paper presents a novel and well-motivated approach to modeling reference in language, and (2) the experimental results demonstrate the effectiveness of the proposed model in various tasks.
The paper provides a clear and well-structured presentation of the proposed model, including the architecture, training objective, and experimental setup. The authors also provide a comprehensive review of related work, highlighting the contributions of their approach. The experimental results are convincing, showing that the proposed model outperforms baseline models in terms of perplexity and BLEU score.
To further improve the paper, I suggest that the authors provide more analysis on the learned latent variables and their impact on the model's performance. Additionally, it would be interesting to see more qualitative examples of the generated text and how the model's performance varies across different tasks and datasets.
Some questions I would like the authors to answer include: (1) How do the learned latent variables relate to the underlying semantics of the tasks, and (2) Can the authors provide more insights into the optimization process and how the model avoids getting stuck in local optima? 
Overall, the paper presents a significant contribution to the field of natural language processing, and with some additional analysis and clarification, it has the potential to be a strong publication.