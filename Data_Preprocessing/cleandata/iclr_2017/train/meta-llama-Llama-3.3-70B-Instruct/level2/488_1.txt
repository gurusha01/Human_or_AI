This paper proposes an extension of adversarial and virtual adversarial training to the text domain, by applying perturbations to word embeddings in a recurrent neural network rather than to the original input itself. The authors claim that their method achieves state-of-the-art results on multiple benchmark semi-supervised and purely supervised tasks, and provides improved word embeddings.
I decide to accept this paper, with the main reason being that the approach is well-motivated and the results are impressive. The authors provide a clear explanation of the limitations of traditional adversarial and virtual adversarial training in the text domain, and their proposed method addresses these limitations effectively. The experimental results demonstrate the effectiveness of the proposed method, with significant improvements over the baseline methods.
The paper is well-written, and the authors provide a thorough review of related work. The proposed method is also straightforward to implement, and the authors provide code to facilitate reproduction of the results. One potential limitation of the paper is that the authors do not provide a detailed analysis of the learned word embeddings, beyond showing that they are improved in quality. However, this is a minor point, and overall the paper makes a significant contribution to the field.
To improve the paper, I suggest that the authors provide more detailed analysis of the learned word embeddings, such as visualizations or quantitative metrics. Additionally, it would be interesting to see the results of the proposed method on other text classification tasks, such as machine translation or question answering.
I have several questions for the authors to clarify their approach:
* Can you provide more details on how the word embeddings are normalized, and why this is necessary for the proposed method?
* How do you select the hyperparameter for the norm constraint on the adversarial perturbations, and is this hyperparameter sensitive to the specific task or dataset?
* Can you provide more insights into why the virtual adversarial training performs worse than the baseline on the Rotten Tomatoes dataset, and how this can be improved in future work?