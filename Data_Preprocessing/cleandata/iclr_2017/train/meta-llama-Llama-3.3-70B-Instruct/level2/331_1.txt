This paper presents a novel approach to transferring skills between morphologically different agents using invariant feature spaces. The authors propose a method for learning a common feature space between two agents, which can be used to transfer skills from one agent to another. The approach is based on the idea of learning a mapping between the state spaces of the two agents, such that the mapped states are similar in a common feature space.
The paper claims to contribute a formulation of the multi-skill transfer problem, a definition of the common feature space, and an algorithm for learning the maximally informative feature space for transfer between two agents. The authors evaluate their approach on several simulated robotic manipulation tasks, including transfer between robots with different numbers of links and transfer from a torque-driven arm to a tendon-driven arm.
Based on the provided information, I decide to accept this paper. The main reasons for this decision are:
1. The paper tackles a specific and well-defined problem in the field of reinforcement learning and robotics, which is the transfer of skills between morphologically different agents.
2. The approach proposed by the authors is well-motivated and based on a clear understanding of the problem and the relevant literature.
3. The experimental results presented in the paper demonstrate the effectiveness of the proposed approach in transferring skills between different robotic arms.
The supporting arguments for this decision include:
* The paper provides a clear and concise formulation of the multi-skill transfer problem and the common feature space.
* The authors propose a well-designed algorithm for learning the maximally informative feature space for transfer between two agents.
* The experimental results demonstrate the ability of the proposed approach to transfer skills between robots with different numbers of links and between a torque-driven arm and a tendon-driven arm.
* The paper provides a thorough comparison with other methods, including random projections, canonical correlation analysis (CCA), and unsupervised manifold alignment (UMA).
Additional feedback to improve the paper includes:
* Providing more details on the reinforcement learning algorithm used to learn the policies in the source and target domains.
* Discussing the potential limitations of the proposed approach and possible extensions to more complex scenarios.
* Considering the use of more advanced techniques, such as deep learning-based methods, to improve the performance of the proposed approach.
Questions to be answered by the authors include:
* How do the authors plan to extend their approach to more complex scenarios, such as transfer between multiple agents or transfer of multiple skills?
* How do the authors plan to handle situations where the two agents have different state and action spaces?
* Can the authors provide more details on the computational complexity of their approach and its potential applications in real-world scenarios?