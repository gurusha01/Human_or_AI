This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks. The algorithm is motivated by the local geometry of the energy landscape and aims to exploit the phenomenon of wide valleys in the energy landscape, which are known to generalize better. The authors introduce a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in sharp valleys.
The main claim of the paper is that Entropy-SGD outperforms state-of-the-art techniques in terms of generalization error and training time. The authors provide experimental results on convolutional and recurrent neural networks, demonstrating the effectiveness of their approach.
I decide to accept this paper because it tackles a specific question/problem, namely, how to optimize deep neural networks to achieve better generalization. The approach is well-motivated, and the authors provide a clear explanation of the local entropy concept and its connection to the energy landscape. The paper also provides a comprehensive analysis of the theoretical properties of Entropy-SGD, including its smoothness and stability.
The experimental results are convincing, showing that Entropy-SGD compares favorably to state-of-the-art techniques in terms of generalization error and training time. The authors also provide a detailed comparison with other optimization algorithms, such as SGD and SGLD, and demonstrate the superiority of Entropy-SGD.
To further improve the paper, I suggest that the authors provide more insights into the hyper-parameter tuning process, particularly for the scope parameter Î³. It would also be helpful to include more visualizations of the energy landscape and the behavior of the Entropy-SGD algorithm.
Some questions I would like the authors to answer are:
* How do the authors choose the hyper-parameters, such as the learning rate and the number of SGLD iterations?
* Can the authors provide more intuition on why Entropy-SGD performs better than SGLD, despite using a similar stochastic gradient estimator?
* How does the Entropy-SGD algorithm behave in cases where the energy landscape is highly non-convex, and what are the implications for generalization?