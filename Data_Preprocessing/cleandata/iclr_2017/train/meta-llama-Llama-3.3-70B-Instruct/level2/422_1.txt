The paper "Deep Variational Bayes Filters" presents a novel approach to learning state space models from raw non-Markovian sequence data. The authors introduce Deep Variational Bayes Filters (DVBF), a method that leverages stochastic gradient variational Bayes to overcome intractable inference distributions. The key contribution of this paper is the ability to enforce state-space model assumptions, allowing for reliable system identification and plausible long-term prediction of the observable system.
I decide to accept this paper, with two key reasons for this choice. Firstly, the paper tackles a specific and well-defined problem in the field of probabilistic modeling and filtering of dynamical systems. The authors provide a clear and well-motivated approach to addressing this problem, and the results demonstrate the effectiveness of their method. Secondly, the paper is well-written, well-organized, and provides sufficient details for reproducibility.
The supporting arguments for this decision include the fact that the paper provides a comprehensive review of related work, clearly outlining the limitations of existing approaches and the advantages of the proposed method. The authors also provide a detailed description of the DVBF algorithm, including the reparametrization of the transition model and the derivation of the lower bound objective function. The experimental results demonstrate the effectiveness of DVBF in recovering latent spaces with full information, and the comparison with existing methods (e.g., Deep Kalman Filters) shows the superiority of the proposed approach.
To further improve the paper, I suggest that the authors provide more insight into the choice of hyperparameters and the optimization process. For example, how was the inverse temperature schedule chosen, and what is the effect of different batch sizes on the performance of the algorithm? Additionally, it would be interesting to see more experiments on different types of data, such as audio or natural language sequences.
I would like the authors to answer the following questions to clarify my understanding of the paper: (1) Can you provide more details on the computational complexity of the DVBF algorithm, and how it compares to existing methods? (2) How do you handle cases where the true posterior distribution is multimodal, and the variational approximation is not sufficient? (3) Can you provide more insight into the interpretation of the learned latent spaces, and how they relate to the underlying physical quantities of the system?