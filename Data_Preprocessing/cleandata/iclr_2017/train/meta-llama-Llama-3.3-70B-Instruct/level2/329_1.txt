This paper proposes an augmented training procedure for generative adversarial networks (GANs) that addresses the shortcomings of the original GAN framework, particularly in generating "object-like" samples from diverse image collections. The authors introduce a denoising auto-encoder to estimate and track the distribution of discriminator features, which are used to propose high-level targets for the generator. The approach, called denoising feature matching, is shown to improve the quality of generated samples, as measured by the Inception score, on several datasets, including CIFAR-10, STL-10, and ImageNet.
I decide to accept this paper, with the primary reason being that the approach is well-motivated and grounded in the literature. The authors provide a clear explanation of the limitations of traditional GANs and how their proposed method addresses these limitations. The use of a denoising auto-encoder to estimate the distribution of discriminator features is a novel and interesting idea, and the authors provide a thorough analysis of the benefits and limitations of this approach.
The paper supports its claims through a series of experiments on several datasets, which demonstrate the effectiveness of the proposed method in generating high-quality samples. The authors also provide a detailed analysis of the results, including a comparison with other state-of-the-art methods, which helps to establish the validity of their approach.
To further improve the paper, I would suggest that the authors provide more details on the implementation of the denoising auto-encoder, including the architecture and training procedure. Additionally, it would be helpful to see more examples of generated samples, particularly for the ImageNet dataset, to better understand the quality of the results.
Some questions I would like the authors to answer to clarify my understanding of the paper include: (1) How did the authors choose the hyperparameters for the denoising auto-encoder, such as the number of hidden layers and units? (2) Can the authors provide more insight into the effect of the corruption noise on the performance of the denoising auto-encoder? (3) How does the proposed method compare to other GAN variants, such as those that use semi-supervised or conditional architectures? 
Overall, the paper presents a well-motivated and well-executed approach to improving the quality of GAN-generated samples, and I believe it makes a valuable contribution to the field.