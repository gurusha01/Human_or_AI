This paper presents a novel approach to mining full-fledged logical theories from relational embeddings, which are low-dimensional representations of knowledge bases. The authors propose a method that casts the semantics of logical operators into the space of embeddings, allowing for the mining of theories that support all propositional logic connectives, including conjunction, disjunction, and negation. The approach is based on a sparse reconstruction problem, which is solved using compressed sensing algorithms.
I decide to accept this paper, with the main reason being that it presents a well-motivated and novel approach to theory learning from relational embeddings. The paper is well-structured, and the authors provide a clear and concise explanation of their method, including the mathematical formulations and the empirical evaluation.
The approach is well-supported by the empirical analysis, which showcases the advantages of the proposed method over existing approaches. The results demonstrate that the method can mine satisfactory theories in realistic knowledge bases, and that it outperforms existing methods in terms of F-score and per-rule recall.
One of the strengths of the paper is that it provides a clear and concise explanation of the background material, including the notation and the required mathematical concepts. The authors also provide a comprehensive review of related work, which helps to situate their approach within the broader context of theory learning and relational embeddings.
To improve the paper, I suggest that the authors provide more details on the computational complexity of their approach, including the time and space requirements. Additionally, it would be helpful to provide more insights into the interpretability of the mined theories, including the meaning and significance of the rules and the logical connectives.
Some questions that I would like the authors to answer include: How do the authors plan to extend their approach to handle more complex logical connectives, such as implication and equivalence? How do the authors plan to evaluate the scalability of their approach to larger knowledge bases and more complex theories? What are the potential applications of the proposed approach, and how do the authors plan to demonstrate its usefulness in real-world scenarios?
Overall, I believe that this paper presents a significant contribution to the field of theory learning and relational embeddings, and that it has the potential to inspire further research in this area. With some minor revisions to address the above suggestions, I believe that the paper is ready for publication.