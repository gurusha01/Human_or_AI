This paper presents a novel approach to developing end-to-end learned interactive dialogue agents that can learn from both responding to questions and asking questions. The authors design a simulator and a set of synthetic tasks in the movie question answering domain, allowing a bot to interact with a teacher to address issues such as question clarification, knowledge operation, and knowledge acquisition.
The paper claims to demonstrate that a learner can benefit from asking questions in both offline and online reinforcement learning settings, and that the learner improves when asking questions. The authors also validate their approach on real data using Amazon Mechanical Turk, observing similar results.
I decide to accept this paper, with the main reason being that it presents a well-motivated and well-executed approach to developing interactive dialogue agents. The paper is well-written, and the authors provide a clear and concise explanation of their methodology and results.
The approach is well-supported by experiments, which demonstrate the effectiveness of the proposed method in both simulator and real-world settings. The use of Mechanical Turk to collect real data adds credibility to the results and demonstrates the potential for practical applications.
One potential limitation of the paper is that the tasks and datasets used are limited to the movie question answering domain. However, the authors acknowledge this limitation and suggest that their approach can be extended to other domains.
To improve the paper, I suggest that the authors provide more analysis of the results, particularly in terms of the trade-offs between the benefits of asking questions and the costs of doing so. Additionally, the authors could explore the potential for using other reinforcement learning algorithms or techniques to improve the performance of the bot.
Some questions I would like the authors to answer include:
* How do the results vary across different domains and tasks?
* What are the implications of the proposed approach for developing more general-purpose dialogue agents?
* How can the authors extend their approach to handle more complex and open-ended conversations?
Overall, I believe that this paper presents a significant contribution to the field of dialogue agents and has the potential to inspire further research in this area.