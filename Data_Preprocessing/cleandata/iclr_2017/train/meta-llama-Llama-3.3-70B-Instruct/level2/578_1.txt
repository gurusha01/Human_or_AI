This paper presents a comprehensive study on the invariance and equivariance properties of Convolutional Neural Networks (CNNs) trained with various input transformations. The authors empirically measure the invariance and equivariance of 70 CNNs across 10 types of transforms for two large datasets, ILSVRC and RVL-CDIP. The results show that CNNs can learn invariance to all transforms tried, and this invariance/equivariance extends somewhat to transforms outside the training range.
The paper claims to contribute to the understanding of how data augmentation affects the internal representation of CNNs, and how the representation can be improved to be more robust to transformations. The authors propose a novel loss function that aims to improve CNN equivariance, and demonstrate its effectiveness in improving both equivariance and performance on untransformed images.
I decide to accept this paper, with two key reasons for this choice. Firstly, the paper presents a thorough and well-designed experimental study that provides valuable insights into the invariance and equivariance properties of CNNs. The results are well-supported by empirical evidence and are consistent with the claims made by the authors. Secondly, the paper proposes a novel loss function that has the potential to improve the robustness of CNNs to transformations, which is an important problem in computer vision.
The supporting arguments for my decision include the fact that the paper is well-written, well-organized, and easy to follow. The authors provide a clear and concise introduction to the problem, and the related work is thoroughly discussed. The experimental methodology is sound, and the results are presented in a clear and intuitive manner. The proposed loss function is novel and has the potential to improve the state-of-the-art in computer vision.
To improve the paper, I suggest that the authors provide more analysis on the limitations of their approach, and discuss potential avenues for future work. Additionally, it would be helpful to include more visualizations of the results, such as plots or figures that illustrate the invariance and equivariance properties of the CNNs.
I would like the authors to answer the following questions to clarify my understanding of the paper: 
1. Can you provide more details on how the proposed loss function is implemented, and how the hyperparameters are chosen?
2. How do the results of the paper relate to other work on adversarial robustness and domain adaptation?
3. Can you provide more analysis on the computational cost of the proposed approach, and how it compares to other methods for improving CNN robustness? 
Overall, I believe that this paper makes a significant contribution to the field of computer vision, and has the potential to improve the robustness of CNNs to transformations. With some minor revisions to address the limitations and provide more analysis, I believe that this paper is ready for publication.