This paper introduces the concept of Frame-based convolutional networks, which extends the traditional pixel basis to a more general notion of frames, allowing for non-orthogonal and overcomplete representations. The authors argue that this approach can improve the expressiveness of convolutional neural networks (CNNs) and demonstrate its effectiveness on various tasks, including image classification, edge detection, and video classification.
The main claims of the paper are: (1) Frame-based CNNs can outperform traditional CNNs on image classification tasks, (2) Dynamic Steerable Frame Networks (DSFNs) can effectively regularize CNNs and improve their performance on tasks that require local invariance, and (3) DSFNs can be used to separate pose and feature learning in CNNs.
I decide to accept this paper, with the main reason being that it presents a novel and well-motivated approach to improving the expressiveness of CNNs. The paper provides a clear and thorough explanation of the theoretical background, and the experimental results demonstrate the effectiveness of the proposed method.
The supporting arguments for my decision are: (1) The paper provides a comprehensive review of the related work, demonstrating a good understanding of the current state of the field. (2) The theoretical framework is well-established, and the authors provide a clear explanation of the concepts of frames, steerability, and Lie groups. (3) The experimental results are convincing, demonstrating the effectiveness of the proposed method on various tasks.
However, I would like to see some additional feedback and clarification on the following points: (1) How do the authors plan to extend this work to more complex tasks, such as object detection and segmentation? (2) Can the authors provide more insights into the choice of frames and their impact on the performance of the network? (3) How does the computational cost of the proposed method compare to traditional CNNs?
Some questions I would like the authors to answer are: (1) Can you provide more details on the implementation of the Pose-Generating network and the Dynamic Filtering mechanism? (2) How do you plan to address the issue of overfitting in the DSFNs, especially when dealing with small datasets? (3) Can you provide more visualizations and examples of the learned transformations and features in the DSFNs?