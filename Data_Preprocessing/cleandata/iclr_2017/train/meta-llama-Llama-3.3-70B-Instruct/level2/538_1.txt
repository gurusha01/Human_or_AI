The paper proposes a novel architecture, called neural equivalence networks (EQNETs), for learning continuous semantic representations of mathematical and logical expressions. The main claim of the paper is that EQNETs can effectively learn to represent semantic equivalence between expressions, even when they are syntactically very different. The authors support this claim through an exhaustive evaluation on a diverse class of symbolic algebraic and boolean expression types, showing that EQNETs significantly outperform existing architectures.
I decide to accept this paper for the following reasons: 
1. The paper tackles a fundamental problem in machine learning and artificial intelligence, which is representing and inferring procedural knowledge. 
2. The approach is well-motivated, and the authors provide a clear explanation of the limitations of existing methods and how EQNETs address these limitations.
The authors provide a thorough evaluation of their approach, including a comparison with several baseline models and an analysis of the impact of different components of the EQNET architecture. The results show that EQNETs perform dramatically better than existing architectures, and the authors provide a detailed analysis of the reasons for this improvement.
To further improve the paper, I would suggest the following: 
1. Provide more insight into the learned representations: While the authors provide some visualizations of the learned representations, it would be helpful to have a more detailed analysis of what the representations capture and how they relate to the semantic equivalence of the expressions.
2. Explore the application of EQNETs to more complex domains: The authors demonstrate the effectiveness of EQNETs on a range of symbolic algebraic and boolean expression types, but it would be interesting to see how the approach performs on more complex domains, such as natural language processing or computer vision.
Some questions I would like the authors to answer to clarify my understanding of the paper are: 
1. How do the authors plan to address the issue of scaling EQNETs to more complex expressions, where the number of possible equivalence classes grows exponentially?
2. Can the authors provide more details on the hyperparameter tuning process and how the optimized hyperparameters were selected?
3. How do the authors think EQNETs could be used in practice, for example, in applications such as automated theorem proving or program synthesis?