This paper presents a novel approach to training artificial agents to seek information efficiently in partially-observed environments. The authors propose a general problem setting and develop a collection of tasks that require agents to search for fragments of information to achieve specific goals. They combine deep architectures with techniques from reinforcement learning to build agents that can solve these tasks.
The main claims of the paper are: (1) the authors develop a general problem setting for training and testing the ability of agents to gather information efficiently, (2) they propose a collection of tasks that require agents to search for fragments of information to achieve specific goals, and (3) they demonstrate that their agents can learn to search actively and intelligently for new information to reduce their uncertainty and exploit information they have already acquired.
I decide to accept this paper with the following reasons: 
1. The paper tackles a specific and well-defined problem, which is the ability of agents to seek information efficiently in partially-observed environments. 
2. The approach is well-motivated and placed in the literature, drawing from previous work on attention models, reinforcement learning, and information-seeking behavior. 
3. The paper provides empirical evidence that the proposed agents can learn to search actively and intelligently for new information, and the results are scientifically rigorous.
The supporting arguments for the decision are as follows: 
The paper provides a clear and concise introduction to the problem setting and the proposed approach. The authors motivate their work by discussing the importance of information-seeking behavior in artificial agents and the limitations of current attention models. The paper also provides a thorough review of related work, highlighting the connections to previous research on attention models, reinforcement learning, and information-seeking behavior.
The experimental results are impressive, demonstrating that the proposed agents can achieve state-of-the-art performance on several tasks, including cluttered MNIST, BlockWorld, and CelebA. The authors also provide a detailed analysis of the results, highlighting the strengths and weaknesses of their approach.
Additional feedback to improve the paper includes: 
- Providing more details on the implementation of the proposed approach, such as the architecture of the neural networks and the hyperparameters used.
- Discussing the potential applications of the proposed approach to real-world problems, such as robotics or natural language processing.
- Comparing the proposed approach to other state-of-the-art methods for information-seeking behavior, such as active learning or transfer learning.
Questions to be answered by the authors include: 
- How do the authors plan to extend their approach to more complex and dynamic environments?
- Can the authors provide more insights into the learned policies and the decision-making process of the agents?
- How do the authors plan to address the potential limitations of their approach, such as the reliance on a fixed set of questions or the assumption of a partially-observed environment?