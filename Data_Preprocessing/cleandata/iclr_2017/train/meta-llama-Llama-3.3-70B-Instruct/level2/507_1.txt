The paper proposes a language-agnostic method for generating sets of semantically similar clusters of entities along with sets of "outlier" elements, which can be used to perform an intrinsic evaluation of word embeddings in the outlier detection task. The authors create a gold-standard dataset, WikiSem500, and evaluate multiple state-of-the-art embeddings, showing a correlation between performance on this dataset and performance on sentiment analysis.
I decide to accept this paper, with two key reasons for this choice. Firstly, the paper presents a novel and well-motivated approach to generating a dataset for intrinsic evaluation of word embeddings, addressing some of the limitations of existing datasets. Secondly, the authors provide a thorough evaluation of their dataset, including a comparison with existing datasets and an analysis of the correlation between performance on their dataset and downstream tasks.
The paper is well-written, and the authors provide a clear and detailed description of their approach, including a formalization of their method in Appendix A. The evaluation is comprehensive, and the authors provide a thorough analysis of the results, including a discussion of the limitations of their approach. The paper also provides a useful contribution to the field, as the proposed dataset can be used to evaluate and improve word embeddings.
To improve the paper, I suggest that the authors provide more details on the construction of the WikiSem500 dataset, including the specific heuristics used to filter out clusters and outliers. Additionally, the authors could provide more analysis on the correlation between performance on their dataset and downstream tasks, including a discussion of the implications of their findings for the development of word embeddings.
I would like the authors to answer the following questions to clarify my understanding of the paper: (1) Can you provide more details on the construction of the WikiSem500 dataset, including the specific heuristics used to filter out clusters and outliers? (2) How do you plan to extend your approach to construct datasets for syntactically similar clusters of items, and what are the potential challenges and limitations of this approach? (3) Can you provide more analysis on the correlation between performance on your dataset and downstream tasks, including a discussion of the implications of your findings for the development of word embeddings?