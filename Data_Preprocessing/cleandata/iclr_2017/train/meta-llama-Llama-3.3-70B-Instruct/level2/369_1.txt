This paper proposes a novel neural network quantization method called Trained Ternary Quantization (TTQ), which compresses network weights to ternary values. The authors claim that their method achieves higher accuracy on the CIFAR-10 and ImageNet datasets, with minimal loss of accuracy compared to full-precision models. They also demonstrate that their ternary models can be compressed by 16Ã—, making them more suitable for deployment on mobile devices.
I decide to accept this paper, with the main reason being that the approach is well-motivated and supported by thorough experiments. The authors provide a clear explanation of their method, including the use of trained scaling coefficients and layer-wise thresholds, and demonstrate its effectiveness on several benchmark datasets.
The supporting arguments for this decision include the fact that the authors provide a comprehensive review of related work, including binary and ternary weight networks, and demonstrate how their method improves upon these existing approaches. They also provide detailed experimental results, including comparisons to full-precision models and other state-of-the-art quantization methods.
One potential limitation of the paper is that the authors do not provide a detailed analysis of the computational complexity of their method, including the time and memory requirements for training and deploying the ternary models. Additionally, they do not explore the potential applications of their method beyond image classification, such as object detection or segmentation.
To improve the paper, I suggest that the authors provide more details on the computational complexity of their method, including the number of parameters and computations required for training and deploying the ternary models. They should also consider exploring the potential applications of their method beyond image classification, and provide more analysis on the trade-offs between model size, accuracy, and computational complexity.
Some questions I would like the authors to answer include: (1) How do the trained scaling coefficients and layer-wise thresholds affect the accuracy and computational complexity of the ternary models? (2) Can the authors provide more details on the implementation of their method, including the specific hardware and software platforms used for training and deploying the ternary models? (3) How do the authors plan to extend their method to other applications beyond image classification, and what potential challenges or limitations do they anticipate?