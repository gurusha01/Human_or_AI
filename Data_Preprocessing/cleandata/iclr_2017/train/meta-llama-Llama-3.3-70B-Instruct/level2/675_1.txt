This paper presents a novel approach to sequence learning, called Incremental Sequence Learning (ISL), which involves gradually increasing the length of the sequences used for training as the network learns to predict the early parts of the sequences. The authors demonstrate that ISL significantly improves sequence learning performance, reducing the test error by 74% and achieving a 20-fold speedup in computation time compared to regular sequence learning.
The paper is well-motivated, and the authors provide a clear explanation of the background and related work in incremental and curriculum learning. The experimental setup is thorough, and the results are convincing, with ISL outperforming three comparison methods. The analysis of the results is also detailed, and the authors provide evidence that the improvement in generalization performance is due to the ability of the recurrent neural network (RNN) to build up internal representations of the sequences.
I decide to accept this paper, with two key reasons for this choice: (1) the paper presents a novel and effective approach to sequence learning, and (2) the experimental results are thorough and convincing.
The supporting arguments for this decision are as follows: (1) the paper provides a clear and well-motivated introduction to the problem of sequence learning and the proposed approach, (2) the experimental setup is thorough and well-designed, with multiple comparison methods and a detailed analysis of the results, and (3) the authors provide evidence that the improvement in generalization performance is due to the specific ability of the RNN to build up internal representations of the sequences.
Additional feedback to improve the paper includes: (1) providing more details on the hyperparameter tuning process, (2) exploring the application of ISL to other sequence learning tasks, and (3) analyzing the computational cost of ISL compared to regular sequence learning.
Questions I would like the authors to answer include: (1) How did the authors choose the threshold value of 4 for the RMSE, and (2) Can the authors provide more details on the implementation of the Feed-Forward Neural Networks (FFNNs) used in the comparison experiments? 
Overall, this is a well-written and well-researched paper that presents a significant contribution to the field of sequence learning. With some minor revisions, it has the potential to be a strong publication.