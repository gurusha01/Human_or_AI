This paper presents a novel framework for investigating the ability of neural networks to perceive visual details not explicitly present in the input, inspired by the human visual system's ability to fill in missing information. The authors propose a defoveating autoencoder (DFAE) architecture, which learns to reconstruct high-detail images from low-detail, foveated inputs. The paper claims that DFAEs can compensate for missing details by learning global feature functions, allowing them to fill in some of the missing details, such as shape and color.
I decide to accept this paper, with the main reason being that it presents a well-motivated and novel approach to studying the perception of visual details in neural networks. The paper is well-placed in the literature, drawing inspiration from the human visual system and related work in denoising autoencoders and image super-resolution.
The paper supports its claims with a series of experiments, including qualitative and quantitative evaluations of the DFAE's ability to reconstruct images from various types of foveated inputs. The results show that DFAEs can indeed fill in missing details, such as shape and color, and that the network's performance improves when a small fovea of high-resolution input is available. The authors also provide a detailed analysis of the learnt features and reconstruction accuracy, which helps to understand the network's behavior.
To improve the paper, I suggest that the authors provide more discussion on the limitations of their approach and potential avenues for future research. For example, they could explore the use of more complex architectures, such as convolutional neural networks, or investigate the application of DFAEs to other domains, such as audio or text processing. Additionally, the authors could provide more details on the training procedure and hyperparameter tuning, to facilitate reproducibility.
Some questions I would like the authors to answer to clarify my understanding of the paper include: How do the DFAEs perform on more complex datasets, such as ImageNet? Can the authors provide more insight into the nature of the global feature functions learnt by the network? How do the DFAEs compare to other approaches, such as denoising autoencoders or image super-resolution methods, in terms of performance and computational efficiency?