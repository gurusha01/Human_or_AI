This paper proposes a novel approach to training neural networks with noisy labels by introducing a noise adaptation layer. The authors claim that their method can learn the noise distribution from the noisy data without using any clean data, and that it can be easily combined with any existing deep learning implementation.
I decide to accept this paper, with two key reasons for this choice. Firstly, the approach is well-motivated and placed in the literature, with a clear explanation of the problem of label noise and the limitations of existing methods. Secondly, the paper provides comprehensive experimental results on several datasets, demonstrating the effectiveness of the proposed method in comparison to other noise-robust approaches.
The supporting arguments for this decision are as follows. The paper provides a thorough review of the literature on label noise, highlighting the importance of the problem and the need for effective solutions. The proposed method is based on a probabilistic framework, which is well-suited to modeling the uncertainty of noisy labels. The experimental results are extensive and well-designed, with a clear comparison to other methods and a thorough analysis of the results.
However, there are some limitations to the paper. The method is not scalable to large class-sets, and the authors acknowledge this as a future research direction. Additionally, the paper could benefit from a more detailed analysis of the phase transition phenomenon observed in the results.
To improve the paper, I suggest that the authors provide more details on the initialization of the noise adaptation layer, and explore the use of other optimization techniques to improve the convergence of the network. Additionally, the authors could consider evaluating the performance of the proposed method on tasks with large class-sets, and exploring the application of the method to other domains such as natural language processing.
I would like to ask the authors to clarify the following points: (1) How do the authors plan to address the scalability issue of the method to large class-sets? (2) Can the authors provide more insights into the phase transition phenomenon observed in the results? (3) How do the authors plan to evaluate the performance of the proposed method on tasks with large class-sets? 
Overall, the paper is well-written, and the proposed method is a significant contribution to the field of deep learning. With some revisions to address the limitations and provide more details on the experimental results, the paper has the potential to be a high-quality publication.