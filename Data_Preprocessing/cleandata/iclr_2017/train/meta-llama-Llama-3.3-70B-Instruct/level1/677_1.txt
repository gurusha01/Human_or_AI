Summary of the Paper
The paper proposes an unsupervised method for learning feature representations of graph-structured data using an encoder-decoder model. The approach is based on the skip-thought model, which has been successfully used in natural language processing to learn vector representations of sentences. The authors adapt this model to graph-structured data by training the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs that are structurally and functionally similar to nearby locations in feature space. The proposed method is evaluated on several real-world datasets and achieves good results against state-of-the-art techniques.
Decision
I decide to Accept this paper with minor revisions. The main reasons for this decision are that the paper tackles a specific and well-motivated problem, the approach is well-placed in the literature, and the results are scientifically rigorous and support the claims made by the authors.
Supporting Arguments
The paper tackles the problem of feature representation learning for graph-structured data, which is a well-motivated and important problem in the field of machine learning. The approach is based on the skip-thought model, which has been successfully used in natural language processing, and the authors provide a clear and well-motivated adaptation of this model to graph-structured data. The results are scientifically rigorous and support the claims made by the authors, with a thorough evaluation on several real-world datasets and a comparison to state-of-the-art techniques.
Additional Feedback
To improve the paper, I suggest that the authors provide more details on the experimental setup, such as the hyperparameter tuning process and the computational resources used. Additionally, it would be helpful to include more visualizations of the learned graph embeddings to provide a better understanding of the results. Finally, the authors may want to consider exploring other applications of the proposed method, such as link prediction or clustering, to demonstrate its versatility.
Questions for the Authors
To clarify my understanding of the paper, I have the following questions for the authors:
1. Can you provide more details on the random walk generation process and how the parameters lmin and lmax are chosen?
2. How do you handle graphs with different sizes and structures in the training set?
3. Can you provide more insights into the visualization of the graph embeddings and how they relate to the structural and functional properties of the graphs?