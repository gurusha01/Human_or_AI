Summary of the Paper
The paper proposes a novel approach to developing end-to-end learned interactive dialogue agents that can learn from both responding to questions and asking questions. The authors design a simulator and a set of synthetic tasks in the movie domain that allow a learner (bot) to interact with a teacher to address issues such as question clarification, knowledge operation, and knowledge acquisition. The paper explores how a bot can benefit from interaction by asking questions in both offline supervised settings and online reinforcement learning settings. The results show that the bot improves its performance when asking questions, and the approach is validated on real data using Amazon Mechanical Turk.
Decision
I decide to Accept this paper with minor revisions. The paper tackles a specific and well-motivated problem, and the approach is well-placed in the literature. The results are promising, and the paper provides a thorough analysis of the experiments.
Supporting Arguments
The paper addresses a crucial aspect of developing intelligent dialogue agents, which is the ability to learn from interactions with users. The authors provide a clear motivation for their work, highlighting the limitations of current dialogue systems that focus on learning through fixed supervised signals rather than interacting with users. The paper also provides a thorough review of related work, positioning their approach as a natural extension of previous research.
The experiments are well-designed, and the results are convincing. The paper shows that the bot improves its performance when asking questions, and the approach is validated on real data using Amazon Mechanical Turk. The analysis of the results is thorough, and the paper provides insights into the benefits and limitations of the approach.
Additional Feedback
To improve the paper, I suggest the authors provide more details on the implementation of the simulator and the synthetic tasks. Additionally, the paper could benefit from a more detailed analysis of the results, including a discussion of the limitations of the approach and potential avenues for future research.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on the implementation of the simulator and the synthetic tasks?
2. How do you plan to address the issue of scalability, given the limited size of the training dataset?
3. Can you provide more insights into the analysis of the results, including a discussion of the limitations of the approach and potential avenues for future research?