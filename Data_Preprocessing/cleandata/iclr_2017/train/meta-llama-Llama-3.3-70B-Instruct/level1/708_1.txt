This paper claims to contribute to the field of adversarial attacks on deep neural networks by presenting simple and effective black-box adversarial attacks. The authors propose two approaches: a random pixel perturbation method and a greedy local-search method. The paper demonstrates the effectiveness of these approaches in generating adversarial images that can fool state-of-the-art convolutional neural networks.
I decide to accept this paper with two key reasons: (1) the paper tackles a specific and important problem in the field of deep learning, and (2) the approach is well-motivated and supported by extensive experimental results.
The paper provides a clear and well-structured presentation of the problem, related work, and the proposed approaches. The authors demonstrate the effectiveness of their methods on several datasets and network architectures, and provide a thorough analysis of the results. The paper also discusses the limitations of the proposed approaches and potential directions for future work.
To support my decision, I provide the following arguments: (1) the paper addresses a critical issue in deep learning, which is the vulnerability of neural networks to adversarial attacks; (2) the proposed approaches are simple, yet effective, and do not require any knowledge of the network architecture or parameters; and (3) the experimental results demonstrate the superiority of the proposed methods over existing approaches.
To improve the paper, I suggest the following additional feedback: (1) provide more details on the implementation of the greedy local-search method, such as the choice of hyperparameters and the stopping criterion; (2) discuss the potential applications of the proposed approaches beyond adversarial attacks, such as data augmentation or robustness evaluation; and (3) consider comparing the proposed methods with other black-box attack methods, such as the one proposed by Papernot et al. (2016b).
I would like the authors to answer the following questions to clarify my understanding of the paper: (1) How did you choose the hyperparameters for the greedy local-search method, and what is the sensitivity of the results to these hyperparameters? (2) Can you provide more insights into the relationship between the pixels perturbed by the greedy local-search method and the saliency map of the image? (3) How do you think the proposed approaches can be extended to other types of neural networks, such as recurrent neural networks or generative adversarial networks?