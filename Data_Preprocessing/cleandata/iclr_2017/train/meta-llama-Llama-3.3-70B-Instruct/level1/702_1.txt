Summary of the Paper
The paper presents two novel Recurrent Neural Network (RNN) based architectures for extractive summarization of documents. The Classifier architecture sequentially accepts or rejects each sentence in the original document order, while the Selector architecture picks one sentence at a time in any arbitrary order. The models jointly capture the notions of salience and redundancy of sentences and are highly interpretable. The authors show that their models reach or outperform state-of-the-art supervised models on two different corpora.
Decision
I decide to Accept this paper with minor revisions.
Reasons for the Decision
The paper tackles a specific and well-defined problem in the field of natural language processing, and the approach is well-motivated and placed in the literature. The authors provide a clear and detailed description of their models and experiments, and the results are promising. The paper also provides a good analysis of the strengths and weaknesses of the two architectures and suggests conditions under which each of them can deliver optimal performance.
Supporting Arguments
The paper provides a thorough review of the related work in the field, and the authors clearly explain the differences between their approach and existing methods. The experiments are well-designed, and the results are presented in a clear and concise manner. The authors also provide a good discussion of the implications of their results and suggest future directions for research.
Additional Feedback
To improve the paper, I suggest that the authors provide more details about the hyperparameter tuning process and the sensitivity of the models to different hyperparameters. Additionally, it would be helpful to include more qualitative analysis of the results, such as examples of summaries generated by the models and a discussion of their quality. Finally, the authors may want to consider adding more related work on recent advances in extractive summarization, such as the use of pre-trained language models.
Questions for the Authors
1. Can you provide more details about the pseudo ground-truth generation process and how it affects the performance of the models?
2. How do the models perform on documents with different structures, such as documents with multiple sections or documents with a non-sequential structure?
3. Can you provide more analysis of the learned importance weights and how they relate to the performance of the models?