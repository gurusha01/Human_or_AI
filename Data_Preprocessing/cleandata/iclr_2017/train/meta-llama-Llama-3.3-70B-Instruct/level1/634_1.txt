Summary
The paper introduces a novel approach called Layerwise Origin-Target Synthesis (LOTS) that can be used for multiple purposes, including visualizing the internal representation of an input at any layer of a deep neural network (DNN), assessing the stability of the captured internal feature representations, and generating a large number of diverse adversarial examples for each input. The authors demonstrate the effectiveness of LOTS on two well-known DNNs, LeNet and VGG Face, and show that it outperforms previous adversarial generation techniques in terms of both performance and adversarial robustness.
Decision
I decide to Accept this paper with the following key reasons:
1. The paper tackles a specific and important problem in the field of deep learning, namely, the vulnerability of DNNs to adversarial examples.
2. The approach is well-motivated and well-placed in the literature, with a clear explanation of the limitations of previous techniques and the advantages of LOTS.
Supporting Arguments
The paper provides a thorough analysis of the related work and clearly explains the limitations of previous techniques, such as the fast gradient sign (FGS) method and the hot/cold approach. The authors also provide a detailed explanation of the LOTS approach and its advantages, including its ability to generate a large number of diverse adversarial examples and its potential to improve the robustness of DNNs. The experimental results demonstrate the effectiveness of LOTS on two well-known DNNs, LeNet and VGG Face, and show that it outperforms previous adversarial generation techniques in terms of both performance and adversarial robustness.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the computational complexity of the LOTS approach and its potential applications in real-world scenarios. Additionally, it would be interesting to see a comparison of LOTS with other visualization techniques, such as saliency maps and feature importance, to better understand its strengths and limitations.
Questions for the Authors
1. Can you provide more details on the computational complexity of the LOTS approach and its potential applications in real-world scenarios?
2. How does LOTS compare to other visualization techniques, such as saliency maps and feature importance, in terms of its ability to provide insights into the internal representation of DNNs?
3. Have you considered applying LOTS to other types of DNNs, such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs), and if so, what were the results?