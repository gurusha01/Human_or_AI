Summary of the Paper
The paper proposes a novel sparse coding method called Support Regularized Sparse Coding (SRSC), which captures the locally linear manifold structure of high-dimensional data. SRSC encourages nearby data points to share dictionary atoms, resulting in sparse codes that preserve the geometric information and manifold structure of the data. The authors also propose a fast encoder, Deep-SRSC, which approximates the sparse codes generated by SRSC using a feed-forward neural network. The paper demonstrates the effectiveness of SRSC and Deep-SRSC through extensive experimental results on various datasets, including USPS, COIL-20, COIL-100, and UCI Gesture Phase Segmentation.
Decision and Reasons
Based on the review, I decide to Accept the paper. The main reasons for this decision are:
1. The paper tackles a specific and well-motivated problem in sparse coding, which is to capture the locally linear manifold structure of high-dimensional data.
2. The approach is well-placed in the literature, and the authors provide a clear and thorough explanation of the proposed method, SRSC, and its relationship to existing sparse coding methods.
3. The paper provides extensive experimental results that demonstrate the effectiveness of SRSC and Deep-SRSC on various datasets, including comparisons to other state-of-the-art methods.
Supporting Arguments
The paper provides a clear and well-structured presentation of the proposed method, SRSC, and its theoretical analysis. The authors also provide a thorough explanation of the optimization algorithm and its convergence properties. The experimental results are extensive and demonstrate the superiority of SRSC and Deep-SRSC over other methods in various clustering tasks.
Additional Feedback
To further improve the paper, I suggest the authors consider the following:
1. Provide more insights into the choice of hyperparameters, such as the weight for the support regularization term and the number of nearest neighbors for the KNN graph.
2. Investigate the scalability of SRSC and Deep-SRSC to larger datasets and more complex tasks, such as image classification and object detection.
3. Consider applying SRSC and Deep-SRSC to other domains, such as natural language processing and recommender systems, to demonstrate their broader applicability.
Questions for the Authors
1. Can you provide more details on the computational complexity of SRSC and Deep-SRSC, and how they compare to other sparse coding methods?
2. How do you choose the hyperparameters for SRSC and Deep-SRSC, and are there any guidelines for selecting these parameters in practice?
3. Have you considered applying SRSC and Deep-SRSC to other tasks, such as semi-supervised learning and transfer learning, and if so, what are the preliminary results?