Summary
This paper introduces MusicNet, a large-scale music dataset consisting of hundreds of freely-licensed classical music recordings with instrument/note annotations, resulting in over 1 million temporal labels. The authors define a multi-label classification task to predict notes in musical recordings and benchmark several machine learning architectures, including learning from spectrogram features, end-to-end learning with a neural net, and end-to-end learning with a convolutional neural net. The experiments show that end-to-end models trained for note prediction learn frequency selective filters as a low-level representation of audio.
Decision
I decide to Accept this paper with two key reasons: (1) the paper tackles a significant problem in music research by introducing a large-scale dataset and benchmarking various machine learning architectures, and (2) the approach is well-motivated and placed in the literature, with a clear explanation of the methodology and results.
Supporting Arguments
The paper provides a thorough introduction to the problem of note prediction in musical recordings and the need for a large-scale dataset. The authors also provide a detailed explanation of the dataset construction, including the alignment of recordings with digital scores and the annotation process. The experiments are well-designed, and the results are clearly presented, showing that end-to-end models can learn effective low-level representations of audio. The paper also provides additional analysis, including error analysis and precision-recall curves, which strengthens the claims made by the authors.
Additional Feedback
To improve the paper, I suggest that the authors provide more details on the evaluation protocol, including the metrics used to evaluate the models and the hyperparameter tuning process. Additionally, it would be helpful to include more visualizations of the learned features and to discuss the potential applications of the MusicNet dataset in music research. I would also like to see more comparison with other state-of-the-art methods in music research.
Questions for the Authors
I would like to ask the authors to clarify the following points:
* How did the authors select the specific composers and instruments included in the MusicNet dataset?
* Can the authors provide more details on the alignment process, including the specific dynamic time warping algorithm used and the parameters tuned?
* How do the authors plan to maintain and update the MusicNet dataset in the future, and what are the plans for making the dataset available to the research community?