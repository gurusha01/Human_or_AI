Summary
The paper proposes a novel approach to learn a simple, low-dimensional state representation of the world from images acquired by a robot using a neural network. The approach utilizes "robotic priors" as loss functions to guide the learning process, which are implemented through a siamese network. The authors demonstrate the effectiveness of their approach by learning a one-dimensional representation of a Baxter head position from raw images, achieving a 97.7% correlation between the learned representation and the ground truth.
Decision
I decide to Accept this paper, with the main reason being that the approach is well-motivated and supported by a thorough literature review. The use of robotic priors as a means to incorporate prior knowledge about the world into the learning process is a novel and interesting idea.
Supporting Arguments
The paper provides a clear and concise introduction to the problem of state representation learning and motivates the use of robotic priors as a solution. The related work section provides a thorough overview of the existing literature on state representation learning, unsupervised learning, and the use of priors in neural networks. The experimental results demonstrate the effectiveness of the proposed approach, and the discussion section provides a clear analysis of the results and limitations of the approach.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the implementation of the siamese network and the robotic priors. Additionally, it would be interesting to see more experimental results, such as learning more complex representations or using real images for training. The authors may also want to consider using a reinforcement learning algorithm to measure the quality of the learned representation, as mentioned in the discussion section.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on how the robotic priors are formalized as cost functions and implemented through the siamese network?
2. How do you plan to extend the approach to learn more complex representations, such as objects positions in three dimensions?
3. Have you considered using other types of neural networks, such as recurrent neural networks or graph neural networks, to learn state representations?