Summary of the Paper's Claims and Contributions
The paper proposes a novel deep learning model, GRU-D, to effectively handle missing values in multivariate time series data. The model captures informative missingness by incorporating masking and time interval directly inside the GRU architecture. The authors claim that their model outperforms existing approaches, including GRU-mean, GRU-forward, and GRU-simple, on both synthetic and real-world healthcare datasets. They also demonstrate the effectiveness of their model in online prediction and model scalability with growing data size.
Decision and Key Reasons
Based on the review, I decide to Accept the paper. The two key reasons for this decision are:
1. The paper tackles a specific and important problem in time series analysis, namely handling missing values in multivariate time series data. The authors provide a clear motivation for their work and demonstrate the effectiveness of their approach.
2. The paper provides a well-motivated and well-placed approach in the literature, building on existing work on GRU models and imputation methods. The authors also provide a thorough evaluation of their model on various datasets and tasks, demonstrating its superiority over existing approaches.
Supporting Arguments
The paper provides a clear and concise introduction to the problem of handling missing values in time series data, highlighting the importance of informative missingness. The authors also provide a thorough review of existing approaches, including imputation methods and GRU models. The proposed GRU-D model is well-motivated and effectively captures the informative missingness in the data. The empirical evaluation of the model on various datasets and tasks demonstrates its effectiveness and superiority over existing approaches.
Additional Feedback and Questions
To further improve the paper, I suggest that the authors provide more details on the implementation of their model, including the hyperparameter tuning process and the computational resources required. I also suggest that the authors provide more insights into the interpretability of their model, including the role of the decay rates and the masking vector.
Some questions I would like the authors to answer include:
* How do the authors plan to extend their approach to handle missing-not-at-random data, as mentioned in the future work section?
* Can the authors provide more insights into the relationship between the decay rates and the missing patterns in the data?
* How do the authors plan to apply their approach to other domains, such as finance or climate science, where missing values are also a significant problem?