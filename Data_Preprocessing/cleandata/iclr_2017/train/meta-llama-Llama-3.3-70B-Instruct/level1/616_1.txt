Summary
The paper proposes a weakly supervised inversion machine that generates imaginations of hidden representations in images, which can then be rendered to reconstruct the original image. The model uses a generator network to predict imaginations, a renderer to project these imaginations back to the input image, and a discriminator to impose distribution matching between the imaginations and retrieved relevant memories. The authors demonstrate the effectiveness of their approach on three computer vision tasks: image in-painting, intrinsic image decomposition, and figure-ground layer extraction.
Decision
I decide to Accept this paper, with two key reasons for this choice. Firstly, the approach is well-motivated and placed in the literature, addressing the limitations of existing methods that rely on paired supervision or hand-designed priors. Secondly, the paper provides extensive experimental results that support the claims, demonstrating the effectiveness of the proposed model on various tasks and comparing favorably to baseline methods.
Supporting Arguments
The paper tackles a specific and important problem in computer vision, namely inverse problems, and proposes a novel solution that leverages data-driven priors and adversarial distribution matching. The authors provide a clear and detailed explanation of their model, including the generator, renderer, and discriminator architectures, as well as the memory retrieval engine. The experimental results are thorough and well-organized, demonstrating the effectiveness of the proposed model on various tasks and datasets.
Additional Feedback
To further improve the paper, I suggest that the authors provide more analysis on the generalization of their model to unseen data, such as measuring the performance on test images with increasing dissimilarity between memories in the database and input images. Additionally, the authors may consider exploring the application of their model to video data, as mentioned in the conclusion, to demonstrate its potential in more complex and dynamic scenarios.
Questions for the Authors
To clarify my understanding of the paper, I would like to ask the authors the following questions:
1. Can you provide more details on the memory retrieval engine, such as how the relevant memories are selected and how the engine is trained?
2. How do you handle cases where the input image has multiple possible imaginations, such as in the figure-ground layer extraction task?
3. Can you provide more analysis on the trade-off between the reconstruction loss and the adversarial loss, and how the hyperparameter Î² is chosen?