The paper presents a novel approach to policy search in stochastic dynamical systems using model-based reinforcement learning with Bayesian neural networks (BNNs) that include stochastic input variables. The authors propose an algorithm that uses random roll-outs and stochastic optimization for learning an optimal policy from the predictions of BNNs. The paper claims to achieve state-of-the-art results in several benchmark problems, including the Wet-Chicken problem, gas turbine control, and an industrial benchmark.
Based on the provided information, I decide to Accept this paper. The two key reasons for this choice are:
1. The paper tackles a specific and relevant problem in the field of reinforcement learning, which is policy search in stochastic dynamical systems. The approach proposed by the authors is well-motivated and addresses the limitations of existing methods.
2. The paper provides a thorough evaluation of the proposed algorithm on several benchmark problems, including real-world applications. The results demonstrate the effectiveness of the approach and its ability to outperform other methods in certain scenarios.
The supporting arguments for this decision include:
* The paper provides a clear and concise introduction to the problem and the proposed approach, making it easy to understand the context and the contributions of the work.
* The authors provide a detailed description of the algorithm and its components, including the use of BNNs with stochastic inputs and the optimization of the policy using stochastic gradient descent.
* The experimental evaluation is thorough and well-designed, including a comparison with other methods and an analysis of the results.
To improve the paper, I would suggest the following additional feedback:
* Provide more insight into the choice of hyperparameters and the sensitivity of the results to these choices.
* Consider adding more details on the computational complexity of the algorithm and its scalability to larger problems.
* It would be interesting to see more analysis on the uncertainty estimates provided by the BNNs and how they relate to the performance of the policy.
Some questions I would like the authors to answer to clarify my understanding of the paper include:
* Can you provide more details on the implementation of the BNNs and the optimization of the policy using stochastic gradient descent?
* How do you choose the hyperparameters for the BNNs and the policy optimization algorithm?
* Can you provide more insight into the results on the industrial benchmark problem, including the specific challenges and opportunities in this domain?