The paper proposes a novel extension of variational autoencoders (VAEs) called epitomic variational autoencoders (eVAEs) to address the problem of model over-pruning in VAEs. The authors claim that eVAEs can overcome this issue by learning multiple shared subspaces that have learned specializations, allowing for increased utilization of the model capacity to model greater data variability.
I decide to accept this paper with the following key reasons:
1. The paper tackles a specific and well-defined problem in the field of VAEs, which is the over-pruning of model capacity.
2. The approach is well-motivated and placed in the literature, with a clear explanation of the limitations of existing methods and how eVAEs address these limitations.
3. The paper provides qualitative and quantitative results on MNIST and TFD datasets, demonstrating the effectiveness of eVAEs in overcoming over-pruning and improving generative performance.
Supporting arguments for the decision include:
* The paper provides a clear and concise explanation of the eVAE model, including the generative process, recognition network, and training algorithm.
* The experimental results demonstrate the advantages of eVAEs over VAEs and other baseline models, including improved generative performance and increased utilization of model capacity.
* The paper provides a thorough discussion of related work, including other approaches to addressing over-pruning in VAEs and the advantages of eVAEs over these methods.
Additional feedback to improve the paper includes:
* Providing more detailed explanations of the recognition network and training algorithm, including the use of the reparameterization trick and the approximation of the discrete variable y.
* Including more visualizations of the learned subspaces and the generated samples, to provide a better understanding of the eVAE model's capabilities.
* Discussing potential limitations and future directions of the eVAE model, including applications to other datasets and tasks.
Questions to be answered by the authors include:
* Can you provide more details on the implementation of the eVAE model, including the specific architectures used for the encoder and decoder networks?
* How do the learned subspaces in the eVAE model relate to the underlying structure of the data, and can you provide more insights into the specializations learned by each subspace?
* Have you explored other applications of the eVAE model, such as image generation or data imputation, and if so, what are the results?