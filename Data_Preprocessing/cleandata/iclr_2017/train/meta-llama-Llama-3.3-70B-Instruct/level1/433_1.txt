Summary
The paper presents a novel approach to unsupervised learning of probabilistic models using real-valued non-volume preserving (real NVP) transformations. The authors introduce a class of bijective functions that enable exact and tractable density evaluation, inference, and sampling. The model is demonstrated to be competitive with other generative methods on four natural image datasets, including CIFAR-10, Imagenet, LSUN, and CelebA.
Decision
I decide to Accept this paper, with two key reasons for this choice. Firstly, the paper tackles a specific and challenging problem in machine learning, namely unsupervised learning of probabilistic models, and presents a well-motivated approach to address this problem. Secondly, the paper provides a thorough and rigorous evaluation of the proposed model, including experimental results on multiple datasets and comparisons with other state-of-the-art methods.
Supporting Arguments
The paper provides a clear and well-structured introduction to the problem of unsupervised learning and the limitations of existing approaches. The authors then present a detailed and technical description of the proposed real NVP transformations, including the change of variable formula, coupling layers, and multi-scale architecture. The experimental results demonstrate the effectiveness of the proposed model in terms of sample quality, log-likelihood, and latent space semantics.
Additional Feedback
To further improve the paper, I suggest that the authors provide more intuition and visualizations to help understand the properties and behavior of the real NVP transformations. Additionally, it would be interesting to see more applications and extensions of the proposed model, such as using it for semi-supervised learning or incorporating it into other probabilistic models.
Questions for the Authors
To clarify my understanding of the paper, I would like to ask the authors the following questions:
1. Can you provide more insight into the choice of the specific form of the coupling layers and the multi-scale architecture?
2. How do the authors plan to address the potential limitations of the model, such as the need for a fixed prior distribution and the computational cost of computing the Jacobian determinant?
3. Can you provide more details on the implementation of the batch normalization technique and its impact on the training process?