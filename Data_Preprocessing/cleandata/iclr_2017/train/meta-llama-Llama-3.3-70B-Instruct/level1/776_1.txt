Summary of the Paper's Contributions
The paper presents a novel approach to machine translation decoding, which allows for iterative improvements to an initial guess translation. The authors propose a convolutional neural network model that predicts discrete substitutions to an existing translation based on an attention mechanism over both the source sentence and the current translation output. This approach enables the model to revisit and correct previous decisions, leading to improved translation accuracy.
Decision and Key Reasons
I decide to Accept this paper, with the key reasons being:
1. The paper tackles a specific and well-motivated problem in machine translation, namely the inability of existing models to revisit incorrect decoding decisions.
2. The approach is well-placed in the literature, building upon existing work in attention-based translation models and iterative refinement techniques.
Supporting Arguments
The paper provides a clear and well-structured presentation of the proposed approach, including a detailed description of the model architecture and training procedure. The experimental results demonstrate the effectiveness of the approach, with improvements of up to 0.4 BLEU on the WMT15 German-English translation task. The use of oracle experiments provides additional insights into the potential benefits of the approach, highlighting the importance of confidence estimation in determining whether a substitution will improve translation accuracy.
Additional Feedback and Suggestions
To further improve the paper, I suggest that the authors consider providing more detailed analysis of the types of errors that are corrected by the iterative refinement process. Additionally, it would be interesting to see experiments with different initial guess translations, such as the output of a neural translation system, to demonstrate the generality of the approach. Finally, the authors may want to consider exploring the application of their approach to other natural language processing tasks, such as text summarization or dialogue generation.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on the computational cost of the iterative refinement process, and how it compares to traditional decoding algorithms?
2. How do you plan to address the potential issue of over-correction, where the model makes too many substitutions and degrades translation accuracy?
3. Have you considered using other evaluation metrics, such as METEOR or TER, to assess the effectiveness of the approach?