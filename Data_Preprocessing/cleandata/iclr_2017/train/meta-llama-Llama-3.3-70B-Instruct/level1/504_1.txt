Summary: The paper proposes a method for learning perceptual reward functions from a few visual demonstrations of a task, leveraging the abstraction power of intermediate visual representations learned by deep models. The approach enables the identification of key intermediate steps of a task and the automatic discovery of the most discriminative features for identifying these steps. The resulting reward functions are dense and smooth, allowing an RL agent to learn to perform the task in real-world settings.
Decision: Accept
Reasons: The paper tackles a significant problem in reinforcement learning, namely the design of reward functions and exploration time, and proposes a well-motivated approach that leverages the power of deep learning. The method is well-placed in the literature, building on existing work in inverse reinforcement learning and deep reinforcement learning. The paper provides a clear and detailed explanation of the approach, including the use of pre-trained deep models, recursive video segmentation, and feature selection.
Supporting arguments: The paper presents a thorough evaluation of the approach, including qualitative and quantitative results on two real-world tasks (door opening and liquid pouring) and a real-world robotic door opening task. The results demonstrate the effectiveness of the approach in learning reward functions that can be used by an RL agent to perform the task. The paper also provides a detailed analysis of the failure cases and discusses potential avenues for future work.
Additional feedback: To further improve the paper, it would be helpful to provide more details on the hyperparameter tuning process and the selection of the pre-trained deep model. Additionally, the paper could benefit from a more detailed comparison with existing methods in inverse reinforcement learning and deep reinforcement learning. The authors may also want to consider exploring the application of the approach to more complex tasks and domains.
Questions for the authors: 
1. Can you provide more details on the selection of the pre-trained deep model and the hyperparameter tuning process?
2. How do you plan to address the potential limitations of the approach, such as the reliance on pre-trained deep models and the need for a large number of demonstrations?
3. Can you provide more insights into the failure cases and how you plan to improve the robustness of the approach?