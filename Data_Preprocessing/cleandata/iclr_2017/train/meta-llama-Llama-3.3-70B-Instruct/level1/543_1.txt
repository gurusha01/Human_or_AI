Summary
The paper proposes a JavaScript-based matrix library and deep learning framework that can run on web browsers, utilizing GPGPU via WebCL for accelerated computation. This approach enables deep learning on ordinary personal computers and smartphones without the need for dedicated computer systems or software installation. The authors demonstrate the practicality of their framework by training large-scale convolutional neural networks, such as VGGNet and ResNet, and achieve significant performance gains compared to existing JavaScript-based libraries.
Decision
I decide to Accept this paper, with the main reason being that the approach is well-motivated and tackles a significant problem in the field of deep learning, which is the need for accessible and efficient computation on non-dedicated systems. The paper provides a thorough implementation of the matrix library and deep learning framework, and the experimental results demonstrate the effectiveness of the approach.
Supporting Arguments
The paper is well-placed in the literature, and the authors provide a clear overview of the related work in distributed computing and deep learning. The implementation of the matrix library and deep learning framework is thorough, and the use of WebCL for GPGPU acceleration is a key innovation. The experimental results demonstrate significant performance gains compared to existing JavaScript-based libraries, and the authors provide a clear discussion of the limitations and potential future directions.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the optimization techniques used to improve the performance of the matrix multiplication kernel, as this is a key bottleneck in the computation. Additionally, the authors may want to consider exploring more advanced parallelization strategies to further improve the performance of the distributed training. It would also be helpful to provide more information on the potential applications of this framework, such as in areas like computer vision or natural language processing.
Questions for the Authors
To clarify my understanding of the paper, I would like to ask the authors the following questions:
* Can you provide more details on the optimization techniques used to improve the performance of the matrix multiplication kernel?
* How do you plan to address the communication overhead in the distributed training, and what strategies do you propose to reduce the communication bottleneck?
* What are the potential applications of this framework, and how do you envision it being used in practice?