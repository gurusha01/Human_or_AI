This paper tackles the specific question of how robust and structured the representations learned by Convolutional Neural Networks (CNNs) are, and how the data shapes these internal network representations. The authors empirically measure the invariance and equivariance properties of a large number of CNNs trained with various types of input transformations.
I decide to accept this paper for the following key reasons: 
1. The approach is well-motivated, building on existing literature on visualization techniques for interpreting internal representations and the importance of data augmentation for top CNN performance. 
2. The paper supports its claims with extensive experiments, measuring invariance and equivariance properties for 70 CNNs across 10 types of transforms for two large datasets, and providing additional results and analysis to further understand the representation distance between different CNNs.
The authors provide a thorough analysis of their results, including the effects of different transformation types and magnitudes on the learned representations, and the relationship between representation distance and transformation type. They also propose a novel loss function to improve CNN equivariance, which shows promising results in some cases.
To further improve the paper, I would like the authors to clarify a few points: 
- How do the results generalize to other CNN architectures and datasets?
- Can the authors provide more insight into why some transformation types are more effective at improving equivariance than others?
- How does the proposed loss function compare to other existing methods for improving CNN robustness and equivariance?
Additionally, I would like to see more discussion on the implications of the findings for real-world applications, such as image classification, object detection, and segmentation, and how the results can be used to design more robust and efficient CNNs. 
Overall, the paper provides a comprehensive and well-executed study on the invariance and equivariance properties of CNNs, and I believe it makes a valuable contribution to the field of deep learning.