The paper proposes a novel approach to answering non-factoid questions by constructing answers using a neural network model. The model, called Neural Answer Construction Model, incorporates semantic biases behind questions into word embeddings and simultaneously learns the optimum combination of answer sentences as well as the closeness between questions and sentences. The authors claim that their model achieves 20% higher accuracy in answer construction than the current best answer selection method.
I decide to Accept this paper with two key reasons: (1) the approach is well-motivated and fills a significant gap in the current state-of-the-art methods for answering non-factoid questions, and (2) the experimental results demonstrate the effectiveness of the proposed model in constructing accurate answers.
The paper provides a clear and detailed explanation of the proposed model, including the incorporation of semantic biases into word embeddings and the use of a joint neural network to learn sentence selection and combination. The authors also provide a thorough evaluation of their model using a dataset from a Japanese QA site, Oshiete goo, and demonstrate its superiority over existing methods.
To further improve the paper, I would like to see more analysis on the following aspects: (1) the impact of using different types of semantic biases, such as categories or titles, on the performance of the model, and (2) the effectiveness of the model in handling questions that are significantly different from those in the training dataset.
Some questions I would like the authors to answer to clarify my understanding of the paper include: (1) How do the authors plan to extend their model to generate complete answers, and (2) What are the potential applications of the proposed model beyond the love advice service in Oshiete goo? Additionally, I would like to see more examples of the constructed answers and their corresponding questions to better understand the quality of the generated answers.