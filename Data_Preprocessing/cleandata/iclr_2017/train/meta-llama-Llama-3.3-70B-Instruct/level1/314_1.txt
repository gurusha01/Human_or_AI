Summary of the Paper's Contributions
The paper presents a novel approach to sensorimotor control in immersive environments, utilizing a high-dimensional sensory stream and a lower-dimensional measurement stream. The authors propose a supervised learning technique that leverages the cotemporal structure of these streams to train a sensorimotor control model. The approach enables learning without a fixed goal at training time and pursuing dynamically changing goals at test time. The authors demonstrate the effectiveness of their approach through extensive experiments in three-dimensional simulations based on the classical first-person game Doom, outperforming state-of-the-art deep reinforcement learning formulations.
Decision and Key Reasons
I decide to Accept this paper, with two key reasons:
1. The paper tackles a specific and important problem in sensorimotor control, providing a well-motivated and innovative approach that departs from traditional reinforcement learning formulations.
2. The authors provide extensive experimental evidence demonstrating the effectiveness of their approach, including a significant advantage over state-of-the-art deep reinforcement learning methods and successful generalization across environments and goals.
Supporting Arguments
The paper is well-structured, and the authors provide a clear and concise introduction to the problem, background, and related work. The proposed approach is thoroughly explained, and the experimental evaluation is comprehensive and well-designed. The results are impressive, with the authors' approach outperforming state-of-the-art methods in several scenarios. The paper also provides a detailed analysis of the importance of vectorial feedback and predicting measurements at multiple temporal offsets.
Additional Feedback and Questions
To further improve the paper, I would like the authors to:
* Provide more insight into the computational complexity of their approach and its potential scalability to more complex environments.
* Discuss potential limitations and challenges of their approach, such as handling high-dimensional action spaces or dealing with partial observability.
* Consider adding more visualizations or illustrations to help readers understand the experimental setup and results.
* Answer the following questions:
	+ How do the authors plan to extend their approach to handle continuous action spaces or more complex goal specifications?
	+ Can the authors provide more details on the architecture and training procedure of the predictor network, including the choice of hyperparameters and optimization algorithms?
	+ How do the authors envision their approach being applied to real-world problems, such as robotics or autonomous driving?