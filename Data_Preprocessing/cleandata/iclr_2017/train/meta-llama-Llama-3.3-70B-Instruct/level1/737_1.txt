The paper "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size" proposes a novel deep convolutional neural network (CNN) architecture called SqueezeNet, which achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. The authors also demonstrate that SqueezeNet can be compressed to less than 0.5MB, making it 510x smaller than AlexNet.
I decide to accept this paper for several reasons. Firstly, the paper tackles a specific and well-motivated problem: reducing the number of parameters in CNNs while maintaining accuracy. The authors provide a clear and concise overview of the advantages of smaller CNN architectures, including reduced communication overhead during distributed training, less bandwidth required for exporting models, and improved feasibility for deployment on FPGAs and other hardware with limited memory.
Secondly, the approach is well-placed in the literature, building upon existing work on model compression and CNN architecture design. The authors provide a thorough review of related work, including model compression techniques such as singular value decomposition, network pruning, and deep compression. They also discuss the design of CNN microarchitectures and macroarchitectures, including the use of 1x1 and 3x3 filters, and the organization of layers and modules.
Thirdly, the paper supports its claims with extensive experimental results, including evaluations of SqueezeNet on ImageNet and comparisons with other state-of-the-art models. The authors also provide a detailed analysis of the design space of SqueezeNet-like architectures, including the impact of squeeze ratio, filter dimensions, and bypass connections on model size and accuracy.
To further improve the paper, I suggest that the authors provide more details on the training protocol used for SqueezeNet, including the batch size, learning rate, and parameter initialization. Additionally, it would be interesting to see more experiments on the application of SqueezeNet to other datasets and tasks, such as fine-grained object recognition and autonomous driving.
Some questions I would like the authors to answer include: How did the authors choose the specific values for the metaparameters used in the design space exploration, such as basee, incre, and pct3x3? Can the authors provide more insight into the trade-offs between model size, accuracy, and computational efficiency in SqueezeNet? How do the authors plan to extend SqueezeNet to other applications and domains, and what challenges do they anticipate in doing so?