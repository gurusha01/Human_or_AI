Summary of the Paper
The paper proposes a novel method for training neural networks called "mollification," which is inspired by continuation methods and smoothing techniques. The approach involves starting with a simpler model and gradually transitioning to a more complex one by annealing the noise injected into the system. The authors demonstrate the effectiveness of their method on various tasks, including deep MLPs, LSTMs, and convolutional neural networks, and show that it can improve the generalization performance of the models.
Decision
I decide to Accept this paper, with the following key reasons:
1. The paper tackles a specific and important problem in deep learning, namely the optimization of highly non-convex neural network objectives.
2. The approach is well-motivated and placed in the literature, drawing on ideas from continuation methods and smoothing techniques.
Supporting Arguments
The paper provides a clear and well-written introduction to the problem of optimizing deep neural networks, and motivates the need for new approaches. The authors provide a thorough review of related work and clearly explain how their approach differs from existing methods. The experimental results are impressive, demonstrating the effectiveness of the mollification method on a range of tasks.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the implementation of the mollification method, including the choice of hyperparameters and the annealing schedule. Additionally, it would be helpful to include more analysis of the results, such as ablation studies to understand the contribution of different components of the method. Finally, I would like to see more discussion of the potential limitations and future directions of the work.
Questions for the Authors
1. Can you provide more details on how the mollification method is implemented in practice, including the choice of hyperparameters and the annealing schedule?
2. How do you choose the initial value of the noise parameter, and how do you anneal it during training?
3. Can you provide more analysis of the results, such as ablation studies to understand the contribution of different components of the method?
4. How do you think the mollification method could be extended to other types of neural networks, such as recurrent neural networks or generative adversarial networks?