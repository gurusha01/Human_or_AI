Summary
The paper presents a comprehensive analysis of neural architectures for reading comprehension tasks, specifically focusing on the emergence of "predication structure" in the hidden state vectors of certain neural readers. The authors propose that the hidden state vectors can be viewed as a concatenation of a "predicate vector" and a "constant symbol vector", and provide empirical evidence to support this claim. They also introduce a new class of models, called "pointer annotation readers", which explicitly mark the occurrences of candidate answers in the input passage, and demonstrate that these models can achieve state-of-the-art performance on the Who-did-What dataset.
Decision
I decide to accept this paper, with the main reason being that it provides a thorough and well-motivated analysis of the neural architectures for reading comprehension tasks, and presents a novel and interesting perspective on the emergence of predication structure in the hidden state vectors. The paper is well-written, and the experiments are carefully designed and executed.
Supporting Arguments
The paper tackles a specific and well-defined problem in the field of natural language processing, and provides a clear and concise overview of the relevant literature. The authors' proposal of the predication structure in the hidden state vectors is well-motivated and supported by empirical evidence, and the introduction of the pointer annotation readers is a novel and interesting contribution to the field. The experiments are carefully designed and executed, and the results are clearly presented and discussed.
Additional Feedback
To further improve the paper, I would suggest that the authors provide more detailed analysis of the results, and discuss the implications of their findings for the broader field of natural language processing. Additionally, it would be helpful to include more visualizations and illustrations to support the presentation of the results. Finally, I would like to see more discussion of the potential limitations and future directions of the work.
Questions for the Authors
I would like to ask the authors to clarify the following points:
* Can you provide more details on how the predication structure is learned during training, and what are the key factors that influence its emergence?
* How do the pointer annotation readers compare to other state-of-the-art models for reading comprehension tasks, and what are the advantages and disadvantages of using these models?
* Can you provide more discussion on the potential applications of the predication structure and the pointer annotation readers in other natural language processing tasks, such as question answering and text summarization?