Summary of the Paper's Contributions
This paper explores the similarity between human visual perception and the computations of deep neural networks (DNNs) trained on large-scale image recognition tasks. The authors investigate whether the learned computations of DNNs can be used to estimate perceptual loss and whether they exhibit similar properties to human perception, such as sensitivity to image changes, segmentation, crowding, and shape interactions. The results show that DNNs can be used to predict human perceptual thresholds and that the computations of DNNs exhibit similarities to human perception, particularly in the mid-to-end stages of computation.
Decision and Key Reasons
Based on the review, I decide to Accept this paper. The two key reasons for this decision are:
1. The paper tackles a specific and well-motivated question, namely, whether the computations of DNNs can be used to estimate perceptual loss and exhibit similarities to human perception.
2. The paper provides a thorough and well-executed analysis of the similarity between human visual perception and DNN computations, including a range of experiments and comparisons with human psychophysical data.
Supporting Arguments
The paper provides a clear and well-structured introduction to the problem, including a review of related work and a clear statement of the research question. The methods section is thorough and well-documented, including details of the DNN architectures used, the experimental setup, and the analysis procedures. The results section presents a range of findings, including the correlation between DNN computations and human perceptual thresholds, and the similarity between DNN computations and human perception in terms of segmentation, crowding, and shape interactions.
Additional Feedback and Questions
To improve the paper, I would suggest the following:
* Provide more discussion of the implications of the findings for our understanding of human visual perception and the development of more effective computer vision systems.
* Consider adding more analysis of the limitations of the current study and potential avenues for future research.
* Provide more detail on the specific DNN architectures used and the training procedures employed.
* Consider adding more comparisons with other machine learning models or computational models of human vision.
Some questions I would like the authors to address in their response include:
* How do the authors think the findings of this study could be used to improve the development of more effective computer vision systems?
* What are the implications of the study's findings for our understanding of human visual perception, particularly in terms of the role of mid-to-end stage computations?
* How do the authors plan to address the limitations of the current study and extend the findings to more complex and realistic visual stimuli?