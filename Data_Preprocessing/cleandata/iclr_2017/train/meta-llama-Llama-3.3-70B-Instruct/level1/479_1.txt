Summary
The paper proposes a novel computational hypothesis testing framework based on memory-augmented neural networks (MANN) for language comprehension tasks. The framework involves a hypothesis testing loop that iteratively refines a previously formed hypothesis to generate new hypotheses. The authors apply this approach to cloze-type question answering tasks using Neural Semantic Encoders (NSE) and achieve state-of-the-art results on two benchmark datasets, Children's Book Test (CBT) and Who-Did-What (WDW).
Decision
I decide to Accept this paper with two key reasons: (1) the approach is well-motivated and grounded in cognitive science, and (2) the experimental results demonstrate significant improvements over previous state-of-the-art models.
Supporting Arguments
The paper tackles a specific question of how to model hypothesis testing in language comprehension tasks, which is a crucial aspect of human reasoning. The authors provide a clear and well-structured explanation of their approach, which is inspired by the cognitive process of hypothesis testing in the human brain. The use of MANN and NSE architectures is well-justified, and the experimental results demonstrate the effectiveness of the proposed approach. The paper also provides a thorough analysis of the results, including visualizations of the query regression process, which helps to understand the model's behavior.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the hyperparameter tuning process and the sensitivity of the model to different hyperparameters. Additionally, it would be interesting to see more analysis on the types of questions that the model struggles with and how the hypothesis testing loop helps to improve performance on those questions. The authors may also consider providing more comparisons with other state-of-the-art models and analyzing the differences in their approaches.
Questions for the Authors
To clarify my understanding of the paper, I would like to ask the authors the following questions:
1. Can you provide more details on how the memory key and gating states are updated during the query regression process?
2. How do you handle out-of-vocabulary words in the input queries and documents?
3. Have you considered applying the proposed approach to other language comprehension tasks, such as reading comprehension or natural language inference?