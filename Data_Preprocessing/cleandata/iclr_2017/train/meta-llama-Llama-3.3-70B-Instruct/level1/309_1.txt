Summary
The paper introduces a novel deep reinforcement learning agent, called UNREAL, which learns to predict and control various features of the sensorimotor stream by solving multiple reinforcement learning problems simultaneously. The agent uses auxiliary control tasks, such as pixel control and feature control, to develop a more effective representation, and auxiliary reward prediction tasks to focus the representation on important aspects of the task. The UNREAL agent significantly outperforms the previous state-of-the-art on Atari and Labyrinth tasks, achieving a mean speedup of 10Ã— in learning and averaging 87% expert human performance on Labyrinth.
Decision
I decide to Accept this paper, with two key reasons: (1) the paper tackles a specific and important problem in reinforcement learning, which is to improve the efficiency and robustness of learning in complex environments, and (2) the approach is well-motivated and supported by extensive experimental results on multiple tasks.
Supporting Arguments
The paper provides a clear and well-structured introduction to the problem and the proposed approach. The authors motivate the use of auxiliary control tasks and reward prediction tasks, and provide a detailed description of the UNREAL agent architecture. The experimental results are extensive and demonstrate the effectiveness of the UNREAL agent on multiple tasks, including Atari and Labyrinth. The paper also provides a thorough analysis of the results, including ablation studies and comparisons to other state-of-the-art methods.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the hyperparameter tuning process and the sensitivity of the results to different hyperparameter settings. Additionally, it would be interesting to see more analysis on the learned representations and how they relate to the task-specific features. Finally, the authors may want to consider providing more discussion on the potential applications of the UNREAL agent to real-world problems.
Questions for the Authors
To clarify my understanding of the paper, I have the following questions for the authors:
* Can you provide more details on the implementation of the pixel control and feature control auxiliary tasks, and how they are integrated into the UNREAL agent architecture?
* How do you select the hyperparameters for the UNREAL agent, and what is the sensitivity of the results to different hyperparameter settings?
* Can you provide more analysis on the learned representations and how they relate to the task-specific features, and how do you think this can be used to improve the performance of the UNREAL agent?