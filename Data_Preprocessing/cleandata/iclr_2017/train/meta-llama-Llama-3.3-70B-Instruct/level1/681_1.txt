Summary
The paper proposes a scalable version of the state-of-the-art deterministic time-invariant feature extraction approach, namely the scattering network. The authors extend the scattering network to allow the use of higher-order nonlinearities and extract nonlinear and Fourier-based statistics, leading to more discriminative time-invariant features. The framework is derived in the Fourier domain, enabling fast computations and sparse storage, resulting in a linear complexity in the input size.
Decision
I decide to Accept this paper, with two key reasons: (1) the approach is well-motivated and placed in the literature, and (2) the paper supports its claims with theoretical and empirical results.
Supporting Arguments
The paper provides a clear and detailed explanation of the scattering network and its extensions. The authors demonstrate the effectiveness of their approach through a supervised audio classification task, achieving state-of-the-art results. The use of sparse matrices and Fourier domain computations enables efficient storage and memory management, making the framework suitable for large-scale applications.
Additional Feedback
To further improve the paper, I suggest the authors provide more insights into the choice of hyperparameters, such as the number of layers and the quality criteria. Additionally, it would be beneficial to explore the application of this framework to other domains, such as image classification, to demonstrate its generalizability.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. How do the authors plan to extend this framework to deeper neural networks, and what are the potential challenges?
2. Can the authors provide more details on the computational tricks involved in the Fourier domain, and how they achieve linear complexity?
3. How do the authors plan to address the issue of class imbalance in the dataset, and what techniques can be used to improve the classification accuracy?