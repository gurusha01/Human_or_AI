Summary
The paper introduces the Hierarchical Compositional Network (HCN), a directed generative model that can discover and disentangle the building blocks of binary images without supervision. The HCN model is a multilayer generative model with features defined at each layer, and it uses max-product message passing (MPMP) for inference and learning. The paper demonstrates the effectiveness of the HCN model on various tasks, including unsupervised feature learning, supervised classification, and missing value imputation.
Decision
I decide to Accept this paper with the following key reasons:
1. The paper tackles a specific and well-defined problem in the field of computer vision and machine learning, which is the discovery and disentanglement of building blocks in binary images.
2. The approach is well-motivated and placed in the literature, with a clear explanation of the limitations of existing models and the advantages of the proposed HCN model.
3. The paper provides a thorough evaluation of the HCN model on various tasks and datasets, including synthetic and real-world data, and demonstrates its effectiveness in comparison to other state-of-the-art models.
Supporting Arguments
The paper provides a clear and detailed explanation of the HCN model, including its architecture, inference, and learning algorithms. The use of MPMP for inference and learning is a key contribution of the paper, and the authors demonstrate its effectiveness in handling the "explaining away" phenomenon in loopy factor graphs. The experimental results are thorough and well-presented, and they demonstrate the ability of the HCN model to learn meaningful features and perform well on various tasks.
Additional Feedback
To further improve the paper, I suggest the following:
* Provide more details on the implementation of the HCN model, including the specific architectures and hyperparameters used in the experiments.
* Consider adding more comparisons to other state-of-the-art models, including those that use different inference and learning algorithms.
* Provide more insights into the interpretability of the learned features and the compositional hierarchy of the HCN model.
Questions for the Authors
I would like the authors to clarify the following points:
* How does the HCN model handle cases where the building blocks are not binary, but rather continuous or multi-valued?
* Can the HCN model be extended to handle more complex tasks, such as image segmentation or object detection?
* How does the choice of hyperparameters, such as the number of layers and features, affect the performance of the HCN model?