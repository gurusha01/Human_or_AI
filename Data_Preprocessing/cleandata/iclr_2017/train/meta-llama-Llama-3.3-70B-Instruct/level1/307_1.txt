Summary
The paper proposes a testbed to evaluate end-to-end dialog systems in goal-oriented applications, specifically in the context of restaurant reservation. The authors design a set of five tasks that require manipulating sentences and symbols to conduct conversations, issue API calls, and use the outputs of such calls. They evaluate several learning methods, including rule-based systems, classical information retrieval models, supervised embeddings, and end-to-end Memory Networks, on these tasks. The results show that Memory Networks outperform other baselines, but still struggle with interpreting knowledge about entities and presenting results to the user.
Decision
I decide to Accept this paper with minor revisions. The paper tackles a specific and important problem in the field of dialog systems, and the approach is well-motivated and well-placed in the literature. The authors provide a thorough evaluation of several learning methods on a range of tasks, and the results are scientifically rigorous.
Supporting Arguments
The paper makes a significant contribution to the field of dialog systems by providing a testbed for evaluating end-to-end dialog systems in goal-oriented applications. The authors' approach is well-motivated, as they recognize the limitations of traditional dialog systems and the potential of end-to-end dialog systems. The evaluation of several learning methods on a range of tasks provides a comprehensive understanding of the strengths and weaknesses of each approach. The results are scientifically rigorous, as the authors use a range of metrics, including per-response and per-dialog accuracy, to evaluate the performance of each method.
Additional Feedback
To improve the paper, I suggest that the authors provide more analysis of the results, particularly in terms of the strengths and weaknesses of each learning method. Additionally, the authors could provide more details on the implementation of the Memory Networks, such as the hyperparameters used and the number of hops. Finally, the authors could consider providing more examples of the predictions made by the Memory Networks, to give a better understanding of how the model works.
Questions for the Authors
I would like the authors to clarify the following points:
* How did the authors select the hyperparameters for the Memory Networks, and what was the effect of varying the number of hops on the performance of the model?
* Can the authors provide more examples of the predictions made by the Memory Networks, particularly on the tasks where the model struggled, such as Task 3 and Task 5?
* How do the authors plan to extend the testbed to other goal-oriented applications, and what are the potential challenges and limitations of doing so?