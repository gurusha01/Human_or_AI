Summary
The paper presents PixelCNN++, a modified version of the PixelCNN generative model, which introduces several improvements, including a discretized logistic mixture likelihood, conditioning on whole pixels, downsampling, additional short-cut connections, and regularization using dropout. The authors demonstrate the effectiveness of these modifications with state-of-the-art results on the CIFAR-10 dataset.
Decision
I decide to Accept this paper, with the main reason being that the approach is well-motivated and supported by thorough experimental evaluations. The authors provide a clear and detailed explanation of their modifications and demonstrate their effectiveness through ablation studies and comparisons to the original PixelCNN model.
Supporting Arguments
The paper tackles a specific question of improving the PixelCNN model, and the approach is well-placed in the literature, building upon previous work on generative models and image modeling. The authors provide a thorough evaluation of their modifications, including ablation studies and comparisons to the original PixelCNN model, which demonstrates the effectiveness of their approach. The results show that the modified model achieves state-of-the-art performance on the CIFAR-10 dataset, and the authors provide a clear and detailed explanation of their modifications.
Additional Feedback
To further improve the paper, I suggest that the authors provide more visualizations of the generated images, particularly for the class-conditional model, to better demonstrate the quality of the generated images. Additionally, it would be interesting to see more analysis on the effect of the discretized logistic mixture likelihood on the model's performance, and how it compares to other likelihood models. The authors may also consider providing more details on the implementation of the model, such as the specific architecture and hyperparameters used, to facilitate reproducibility.
Questions for the Authors
To clarify my understanding of the paper, I would like to ask the authors the following questions:
1. Can you provide more details on the implementation of the discretized logistic mixture likelihood, and how it is computed in practice?
2. How do you choose the number of mixture components for the logistic mixture likelihood, and what is the effect of varying this number on the model's performance?
3. Can you provide more visualizations of the generated images for the class-conditional model, and how do they compare to the unconditional model?
4. How do you plan to extend the PixelCNN++ model to other datasets and applications, and what are the potential challenges and limitations of this approach?