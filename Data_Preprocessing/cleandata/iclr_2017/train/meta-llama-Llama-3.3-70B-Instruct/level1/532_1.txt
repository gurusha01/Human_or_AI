Summary of the Paper's Contributions
The paper proposes a novel framework called Neural Data Filter (NDF) that uses deep reinforcement learning to automatically and adaptively select training data for Stochastic Gradient Descent (SGD) in deep neural networks. NDF casts the SGD training process as a Markov Decision Process (MDP) and uses policy gradient methods to learn a data filtration policy that maximizes future accumulative reward, such as validation accuracy. The authors demonstrate the effectiveness of NDF on several tasks, including image classification and text understanding, and show that it can achieve comparable accuracy to standard SGD while using less data and converging faster.
Decision and Key Reasons
I decide to Accept this paper, with the key reasons being:
1. The paper tackles a specific and important problem in deep learning, namely, how to efficiently select training data for SGD.
2. The approach is well-motivated and grounded in the literature, drawing on ideas from curriculum learning, self-paced learning, and reinforcement learning.
Supporting Arguments
The paper provides a clear and well-structured presentation of the NDF framework, including the mathematical formulation of the MDP and the policy gradient algorithms used to learn the data filtration policy. The authors also provide empirical results on several tasks, demonstrating the effectiveness of NDF in improving the convergence speed of SGD while maintaining comparable accuracy. Additionally, the paper discusses related work and highlights the novelty and significance of the proposed approach.
Additional Feedback and Questions
To further improve the paper, I suggest that the authors:
* Provide more insight into the behavior of the learned data filtration policy, such as what types of data are being filtered at different stages of training.
* Investigate the use of more advanced critic functions in the actor-critic algorithm to improve the performance of NDF.
* Consider applying NDF to more tasks and models, such as convolutional neural networks (CNNs) for image classification.
Some questions I would like the authors to answer include:
* How does the choice of reward function affect the performance of NDF?
* Can NDF be used in conjunction with other optimization algorithms, such as Adam or Adagrad?
* How does the computational cost of NDF compare to standard SGD, and are there any potential bottlenecks in the implementation?