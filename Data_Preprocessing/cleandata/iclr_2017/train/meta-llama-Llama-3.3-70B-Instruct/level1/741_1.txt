Summary
This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks (CNNs). The authors propose a novel protocol to test whether a CNN can understand game concepts, such as a chess board grid, winning rules, and two sides, by training a classification network on rendered tic-tac-toe chessboard images with weak labels and analyzing the learned representations using class activation mapping (CAM). The paper claims to provide positive answers to three questions: (1) can a CNN figure out game concepts under weak supervision, (2) is cross-modal supervision applicable for higher-level semantics, and (3) can CAM activate at non-salient regions.
Decision
I decide to accept this paper with some minor revisions. The main reasons for this decision are: (1) the paper tackles a novel and interesting problem, and (2) the experimental results are well-motivated and provide some insights into the capabilities of CNNs.
Supporting Arguments
The paper is well-organized and easy to follow, with a clear introduction to the problem and related work. The experimental design is sound, and the results are thoroughly analyzed and interpreted. The use of CAM to visualize the learned representations is a nice touch, and the results provide some interesting insights into how CNNs can learn to recognize game concepts under weak supervision. The paper also provides some quantitative evaluation protocols to support the claims made in the paper.
Additional Feedback
To improve the paper, I would suggest the following: (1) provide more details on the training process, such as the hyperparameters used and the optimization algorithm employed, (2) consider adding more experiments to test the robustness of the results, such as using different CNN architectures or larger datasets, and (3) provide more discussion on the implications of the results and potential future work.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions: (1) How did you select the hyperparameters for the CNN, and did you try other architectures or optimization algorithms? (2) Can you provide more details on the quantitative evaluation protocols, such as how you selected the most activated patch and how you normalized the representation and ideal activation map? (3) How do you think the results would generalize to more complex games or larger datasets, and what are some potential limitations of the approach?