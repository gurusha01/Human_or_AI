Summary
The paper presents Deep Generalized Canonical Correlation Analysis (DGCCA), a method for learning nonlinear transformations of multiple views of data, such that the resulting transformations are maximally informative of each other. DGCCA combines the flexibility of nonlinear representation learning with the statistical power of incorporating information from many independent sources. The authors derive an efficient stochastic optimization algorithm for solving the DGCCA problem and evaluate its performance on two distinct datasets and three downstream tasks, demonstrating its effectiveness in learning informative representations.
Decision
I decide to Accept this paper, with two key reasons for this choice: (1) the paper tackles a specific and important problem in multiview representation learning, and (2) the approach is well-motivated and supported by theoretical and empirical evidence.
Supporting Arguments
The paper clearly addresses the limitations of existing multiview learning techniques, such as Deep CCA and Generalized CCA, which are restricted to learning representations from no more than two views or strictly linear transformations of the input views. The authors provide a thorough derivation of the DGCCA objective and its gradient, which is essential for training the neural networks. The experimental results demonstrate the effectiveness of DGCCA in learning informative representations, outperforming existing methods in several downstream tasks.
Additional Feedback
To further improve the paper, I suggest the authors provide more insights into the interpretation of the learned representations and the relationships between the different views. Additionally, it would be interesting to explore the application of DGCCA to other domains and tasks, such as image-text matching or multimodal sentiment analysis. The authors may also consider providing more details on the computational complexity and scalability of the DGCCA algorithm.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more intuition on why the DGCCA objective is effective in learning informative representations, and how it relates to other multiview learning techniques?
2. How do you select the hyperparameters for the DGCCA algorithm, and what is the sensitivity of the results to these hyperparameters?
3. Can you provide more details on the computational resources required to train the DGCCA models, and how they scale with the size of the input data?