The paper "Attentive Recurrent Comparators" presents a novel approach to estimating the similarity of a set of objects by cycling through them and making observations. The authors propose a model that combines attention and recurrence to learn to focus on the salient aspects needed to ascertain similarity. The model, called Attentive Recurrent Comparators (ARCs), is shown to perform comparably to Deep Convolutional Siamese Networks on various visual tasks and achieves state-of-the-art performance on the Omniglot dataset for one-shot classification.
I decide to Accept this paper with two key reasons: (1) the approach is well-motivated and placed in the literature, and (2) the paper supports its claims with correct and scientifically rigorous results. The authors provide a clear and thorough explanation of their model and its components, and the experimental results demonstrate the effectiveness of the approach.
The paper provides a thorough analysis of the model's performance and compares it to other state-of-the-art methods. The results show that ARCs outperform other methods on the Omniglot dataset, achieving an error rate of 1.5% in the one-shot classification task, which is a 2-3x reduction compared to the previous best models. The paper also provides a qualitative analysis of the model's behavior, showing that it learns to focus on the salient aspects of the objects being compared.
To improve the paper, I suggest that the authors provide more details on the computational cost of the model and its potential applications to other modalities. Additionally, it would be helpful to see more analysis on the robustness of the model to different types of noise and variations in the input data.
I would like to ask the authors to clarify the following points: (1) How does the model handle cases where the objects being compared have different sizes or aspect ratios? (2) Can the model be extended to handle more than two objects being compared simultaneously? (3) How does the model's performance change when using different types of attention mechanisms or recurrent neural network architectures? Answering these questions would provide more insight into the model's capabilities and limitations, and would help to further improve the paper.