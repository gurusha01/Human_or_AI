This paper proposes a novel approach to code completion for dynamically typed programming languages, such as JavaScript, using neural network techniques. The authors formulate the code completion problem as a sequential prediction task over the traversal of a parse-tree structure and present several LSTM-based models that leverage both token-level and structural information.
The paper claims to contribute to the field of code completion by introducing a new approach that outperforms the state-of-the-art method, which is based on decision tree techniques. The authors evaluate their models on a large corpus of JavaScript code and demonstrate that their approach can achieve better prediction accuracy, especially for longer programs.
I decide to accept this paper for several reasons. Firstly, the paper tackles a specific and relevant problem in the field of software development, which is code completion for dynamically typed languages. The approach proposed by the authors is well-motivated and grounded in the literature, and they provide a clear and concise explanation of their methodology.
Secondly, the authors provide a thorough evaluation of their models, including a comparison with the state-of-the-art approach, and demonstrate that their approach can achieve better performance on several metrics, including next non-terminal and next terminal prediction tasks. The results are promising and suggest that the proposed approach can be effective in practice.
Thirdly, the paper is well-written and easy to follow, with clear explanations of the methodology, experiments, and results. The authors also provide a thorough discussion of the related work and the limitations of their approach, which demonstrates a good understanding of the field and the challenges involved.
To further improve the paper, I would suggest that the authors provide more details on the implementation of their models, including the specific hyperparameters used and the training procedures. Additionally, it would be interesting to see more analysis on the types of errors made by the models and how they can be improved.
Some questions I would like the authors to answer to clarify my understanding of the paper include: How do the authors plan to handle out-of-vocabulary tokens in their approach? Can the authors provide more insights into the types of programs that their approach is most effective for? How do the authors plan to integrate their approach with existing code completion engines and IDEs?