Summary
The paper proposes a novel approach to convolutional neural networks (CNNs) by introducing the concept of frames, which are a generalization of orthogonal bases. The authors argue that the traditional pixel basis used in CNNs is not the best choice for representing signals and show that using suitable frames can improve performance. They also introduce Dynamic Steerable Frame Networks (DSFNs), which combine the advantages of steerable function spaces with the power of neural network function estimators. The DSFNs are shown to outperform traditional CNNs and other state-of-the-art methods on several tasks, including edge detection and video classification.
Decision
I decide to Accept this paper with minor revisions. The paper presents a well-motivated and well-written introduction to the concept of frames in CNNs, and the experimental results demonstrate the effectiveness of the proposed approach.
Supporting Arguments
The paper tackles a specific question/problem by introducing a new concept (frames) and demonstrating its potential to improve CNN performance. The approach is well-motivated, and the authors provide a clear explanation of the benefits of using frames. The experimental results are convincing, and the comparison to other state-of-the-art methods is thorough. The paper also provides a good discussion of related work and potential future directions.
Additional Feedback
To further improve the paper, I suggest the authors provide more details on the computational cost of the proposed approach and its potential applications to other problem domains. Additionally, it would be helpful to include more visualizations of the learned transformations and features to better understand the behavior of the DSFNs. The authors may also consider providing more analysis on the robustness of the approach to different types of noise and perturbations.
Questions for the Authors
1. Can you provide more details on the computational cost of the proposed approach and how it compares to traditional CNNs?
2. How do you plan to extend the approach to other problem domains, such as volumetric medical imaging videos of moving organs?
3. Can you provide more visualizations of the learned transformations and features to better understand the behavior of the DSFNs?
4. How robust is the approach to different types of noise and perturbations, and are there any potential limitations or failure cases?