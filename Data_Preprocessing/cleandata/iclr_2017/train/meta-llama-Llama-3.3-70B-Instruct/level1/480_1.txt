Summary
The paper proposes a framework for detecting action patterns from motion sequences and modeling the sensory-motor relationship of animals using a generative recurrent neural network. The network has a discriminative part for classifying actions and a generative part for predicting motion, allowing it to learn from both labeled and unlabeled sequences. The authors demonstrate the effectiveness of their framework on two types of data: fruit fly behavior and online handwriting, showing that motion prediction improves action classification, especially when labels are scarce, and that the model can generate realistic simulations and discover high-level phenomena such as writer identity and fly gender.
Decision
I decide to Accept this paper with two key reasons: (1) the approach is well-motivated and placed in the literature, and (2) the paper supports its claims with thorough experiments and analysis.
Supporting Arguments
The paper tackles a specific question of detecting action patterns from motion sequences and modeling the sensory-motor relationship of animals, which is a challenging problem in the field of behavioral science. The authors propose a novel framework that combines a discriminative and generative recurrent neural network, allowing it to learn from both labeled and unlabeled sequences. The experiments demonstrate the effectiveness of the framework on two types of data, showing that motion prediction improves action classification and that the model can generate realistic simulations. The analysis of the hidden states of the model also shows that it can discover high-level phenomena such as writer identity and fly gender.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the hyperparameter tuning process and the choice of model architecture. Additionally, it would be interesting to see more comparisons with other state-of-the-art methods in the field. The authors may also consider providing more visualizations of the simulated trajectories and the hidden states of the model to help illustrate the results.
Questions for the Authors
I would like to ask the authors to clarify the following points: (1) How did they choose the number of bins for motion prediction, and what is the effect of changing this hyperparameter? (2) Can they provide more details on the training process, such as the batch size, sequence length, and number of epochs? (3) How do they plan to extend their framework to more complex data, such as human motion capture with 1st person video as sensory input?