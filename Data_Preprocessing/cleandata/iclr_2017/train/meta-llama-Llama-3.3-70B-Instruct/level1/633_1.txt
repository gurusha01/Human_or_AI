This paper proposes a novel approach to cooperative training of two probabilistic models, a descriptor network and a generator network, both parameterized by convolutional neural networks (ConvNets). The descriptor network is an exponential family model or an energy-based model, while the generator network is a nonlinear version of factor analysis. The authors introduce a cooperative training algorithm, called CoopNets, which interweaves the maximum likelihood training algorithms of the two networks. The CoopNets algorithm allows the two networks to feed each other synthesized data, enabling them to learn from each other and improve their performance.
I decide to accept this paper for several reasons. Firstly, the paper tackles a specific and interesting problem in the field of probabilistic modeling and deep learning. The approach proposed by the authors is well-motivated and grounded in the literature, drawing on ideas from generative adversarial networks (GANs) and variational auto-encoders (VAEs). Secondly, the CoopNets algorithm is carefully designed and theoretically justified, with a clear explanation of its convergence properties. The authors provide a thorough analysis of the algorithm's behavior, including its relationship to contrastive divergence and the learning objective of Kim & Bengio (2016).
The experimental results presented in the paper are also impressive, demonstrating the effectiveness of the CoopNets algorithm in learning high-quality generative models for image data. The authors evaluate their approach on several benchmark datasets, including CelebA and Imagenet, and show that it outperforms other state-of-the-art methods in terms of image synthesis and completion tasks.
To further improve the paper, I would suggest that the authors provide more details on the implementation of the CoopNets algorithm, including the specific architectures used for the descriptor and generator networks, as well as the hyperparameter settings. Additionally, it would be helpful to include more visualizations of the synthesized images, to give a better sense of the quality and diversity of the generated data.
Some questions I would like the authors to clarify include: (1) How do the authors choose the number of Langevin steps and the learning rate for the CoopNets algorithm? (2) Can the authors provide more insight into the relationship between the CoopNets algorithm and other approaches to generative modeling, such as GANs and VAEs? (3) How do the authors plan to extend the CoopNets algorithm to more complex data types, such as videos or 3D models?