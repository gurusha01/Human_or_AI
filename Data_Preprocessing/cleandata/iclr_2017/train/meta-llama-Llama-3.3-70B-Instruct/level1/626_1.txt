Summary of the Paper
The paper proposes a method to compute the preimage of activities at arbitrary levels in a deep rectifier network. The preimage is defined as the set of inputs that result in the same node activity. The authors demonstrate that for fully connected multi-layer rectifier networks, the preimage set can be characterized and computed using a procedure that disregards the effects of max-pooling. The paper also discusses the implications of this concept for understanding the efficiency of deep learning networks and designing more efficient training algorithms.
Decision
I decide to Accept this paper with some revisions. The main reason for this decision is that the paper tackles a specific and well-motivated problem in the field of deep learning, and the approach is well-placed in the literature. The authors provide a clear and detailed procedure for computing the preimage, and the results are scientifically rigorous.
Supporting Arguments
The paper is well-organized and easy to follow, with clear explanations of the concepts and notation. The authors provide a thorough review of the related work and demonstrate a good understanding of the field. The procedure for computing the preimage is well-motivated and supported by mathematical derivations. The paper also discusses the implications of the preimage concept for understanding the efficiency of deep learning networks and designing more efficient training algorithms.
Additional Feedback
To improve the paper, I suggest that the authors provide more empirical evidence to support their claims. While the paper provides a clear and detailed procedure for computing the preimage, it would be helpful to see some experimental results that demonstrate the effectiveness of this approach. Additionally, the authors could provide more discussion on the limitations of their approach and potential avenues for future work.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
* Can you provide more details on how the preimage concept can be used to design more efficient training algorithms?
* How do you plan to extend this work to convolutional networks, and what are the potential challenges and limitations of this approach?
* Can you provide more empirical evidence to support the claim that the preimage concept can be used to understand the efficiency of deep learning networks?