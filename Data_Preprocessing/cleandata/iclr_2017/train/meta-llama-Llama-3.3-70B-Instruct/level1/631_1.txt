Summary of the Paper's Contributions
This paper proposes a novel neural network architecture, called Layer-RNN (L-RNN), which combines traditional convolutional layers with recurrent neural networks (RNNs) to learn multi-scale contextual information. The authors demonstrate the effectiveness of L-RNNs in image classification and semantic segmentation tasks, showing that they can achieve comparable or superior performance to state-of-the-art methods while using fewer parameters.
Decision and Key Reasons
Based on the review, I decide to Accept this paper. The two key reasons for this decision are:
1. Well-motivated approach: The authors provide a clear motivation for using RNNs within layers to learn contextual information, and their approach is well-placed in the literature.
2. Strong empirical results: The authors demonstrate the effectiveness of L-RNNs in two tasks, image classification and semantic segmentation, and provide detailed comparisons with other state-of-the-art methods.
Supporting Arguments
The paper provides a thorough introduction to the concept of L-RNNs and their architecture, which is easy to follow. The authors also provide a detailed analysis of the results, including ablation studies and comparisons with other methods. The use of L-RNNs in pre-trained CNNs is a particularly interesting aspect of the paper, as it shows that the approach can be used to fine-tune existing models and improve their performance.
Additional Feedback
To further improve the paper, I would suggest the following:
* Provide more visualizations of the learned features and activations of the L-RNNs to help understand how they capture contextual information.
* Consider adding more experiments on other tasks, such as object detection or image generation, to demonstrate the versatility of L-RNNs.
* Provide more details on the computational cost and training time of L-RNNs compared to other methods.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
* Can you provide more details on how the L-RNNs are initialized and trained, particularly in the case of pre-trained CNNs?
* How do the authors plan to extend the L-RNN approach to other tasks and domains, such as natural language processing or speech recognition?
* Are there any plans to release the code and models used in the paper to facilitate reproducibility and further research?