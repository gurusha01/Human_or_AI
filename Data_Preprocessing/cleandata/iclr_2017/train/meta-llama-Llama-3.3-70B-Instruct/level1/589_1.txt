Summary
The paper introduces the Graph Convolutional Recurrent Network (GCRN), a deep learning model that predicts structured sequences of data. GCRN combines convolutional neural networks (CNN) on graphs to identify spatial structures and recurrent neural networks (RNN) to find dynamic patterns. The authors propose two GCRN architectures and apply them to two practical problems: predicting moving MNIST data and modeling natural language with the Penn Treebank dataset. The experiments show that exploiting simultaneously graph spatial and dynamic information about data can improve both precision and learning speed.
Decision
I decide to Accept this paper with two key reasons: (1) the approach is well-motivated and placed in the literature, and (2) the paper supports its claims with correct and scientifically rigorous results.
Supporting Arguments
The paper tackles a specific question/problem of predicting structured sequences of data, which is a well-studied area in the literature. The authors provide a clear and concise introduction to the problem and the proposed solution. The approach is well-motivated, and the authors provide a thorough review of the related works. The paper supports its claims with empirical results on two datasets, demonstrating the effectiveness of the proposed GCRN models.
Additional Feedback
To improve the paper, I suggest the authors provide more details on the implementation of the GCRN models, such as the hyperparameter settings and the computational resources used. Additionally, the authors could provide more analysis on the results, such as the comparison of the performance of the two proposed GCRN architectures and the analysis of the learned graph structures.
Questions
I would like the authors to answer the following questions to clarify my understanding of the paper:
1. Can you provide more details on the construction of the adjacency matrix A in the moving MNIST dataset?
2. How did you choose the hyperparameters for the GCRN models, and what is the sensitivity of the results to these hyperparameters?
3. Can you provide more analysis on the learned graph structures in the natural language modeling task, and how they relate to the semantic meaning of the words?