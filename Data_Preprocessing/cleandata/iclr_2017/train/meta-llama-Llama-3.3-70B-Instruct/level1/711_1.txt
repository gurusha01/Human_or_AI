Summary
The paper presents a novel approach to extractive question answering, focusing on the SQUAD dataset where answers can be arbitrary strings from the supplied text. The authors propose a model architecture called RASOR, which efficiently builds fixed-length representations of all spans in the evidence document using a recurrent network. The model scores explicit span representations, significantly improving performance over other approaches that factor the prediction into separate predictions about words or start and end markers.
Decision
I decide to Accept this paper, with the primary reason being that the approach is well-motivated and supported by rigorous experimental results. The authors demonstrate a significant improvement in performance over previous state-of-the-art models, with a 5% increase in exact match and 3.6% increase in F1 score.
Supporting Arguments
The paper tackles a specific and well-defined problem in natural language understanding, and the approach is well-placed in the literature. The authors provide a clear and detailed explanation of their model architecture, including the use of recurrent span representations and question-focused passage word embeddings. The experimental results are thorough and well-analyzed, with comparisons to other published systems and ablation studies to investigate the importance of different components.
Additional Feedback
To further improve the paper, I suggest that the authors provide more insight into the failure cases of their model, such as the example shown in Figure 2. Additionally, it would be interesting to see more analysis on the attention mechanisms used in the model, such as the passage-independent and passage-aligned question representations. The authors may also consider exploring alternate architectures that provide input to the recurrent span representations, as mentioned in the conclusion.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on the computational resources required to train the RASOR model, and how it compares to other state-of-the-art models?
2. How do you plan to address the issue of overpredicting answer spans with more than 8 words, as shown in Figure 2?
3. Can you provide more insight into the benefits of using both passage-independent and passage-aligned question representations, and how they complement each other in the model?