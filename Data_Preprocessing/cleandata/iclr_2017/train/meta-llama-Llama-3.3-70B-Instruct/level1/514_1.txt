Summary
The paper introduces a simple permutation equivariant layer for deep learning with set structure, which can be used for both supervised and semi-supervised learning tasks. The layer is designed to be indifferent to permutations of instances in the input set, and is achieved through a parameter-sharing scheme. The authors demonstrate the effectiveness of this layer in several tasks, including point cloud classification, set anomaly detection, and improved red-shift estimation using clustering information.
Decision
I decide to Accept this paper, with two key reasons for this choice. Firstly, the paper tackles a specific and well-motivated problem, namely the need for permutation equivariant layers in deep learning with set structure. Secondly, the authors provide a clear and well-supported approach to solving this problem, with a simple and efficient implementation of the permutation equivariant layer.
Supporting Arguments
The paper provides a thorough introduction to the concept of permutation equivariance and its importance in deep learning with set structure. The authors also provide a clear and concise explanation of the permutation equivariant layer, including its mathematical formulation and implementation details. The experimental results demonstrate the effectiveness of the layer in several tasks, including point cloud classification and set anomaly detection. The authors also provide a thorough comparison with existing methods, including graph convolutional networks and fully connected layers.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the computational complexity of the permutation equivariant layer, particularly in comparison to existing methods. Additionally, it would be helpful to see more experimental results on the robustness of the layer to variations in the input set size and structure. Finally, the authors may want to consider providing more discussion on the potential applications of the permutation equivariant layer in other domains, such as natural language processing and computer vision.
Questions for the Authors
I have several questions for the authors to help clarify my understanding of the paper and provide additional evidence to support their claims. These include:
* Can you provide more details on the implementation of the permutation equivariant layer, particularly in terms of the parameter-sharing scheme and the computation of the layer's output?
* How does the permutation equivariant layer compare to existing methods, such as graph convolutional networks, in terms of computational complexity and performance?
* Can you provide more experimental results on the robustness of the layer to variations in the input set size and structure, particularly in the context of point cloud classification and set anomaly detection?
* What are the potential applications of the permutation equivariant layer in other domains, such as natural language processing and computer vision, and how might it be adapted for these tasks?