Summary
The paper presents a method to prune convolutional neural networks (CNNs) while improving inference speed. The authors propose a high-performance sparse convolution design that takes advantage of arbitrary sparsity patterns and outperforms dense convolution even with moderate sparsity. They also develop a performance model that projects speedups over different sparsity levels and on different computing platforms. The model guides a new pruning algorithm, Guided Sparsity Learning (GSL), which fuses the awareness of speedup potential into sparsity learning. The authors demonstrate the effectiveness of their approach on AlexNet and GoogLeNet on various platforms, achieving 3.1-7.3Ã— convolution speedups.
Decision
I decide to Accept this paper with the following key reasons:
1. The paper tackles a specific and important problem in the field of deep learning, namely, improving the inference speed of CNNs while reducing their size.
2. The approach is well-motivated and placed in the literature, building upon existing work on pruning and sparse convolution.
Supporting Arguments
The paper provides a clear and concise explanation of the problem and the proposed solution. The authors demonstrate a good understanding of the limitations of existing pruning methods and the challenges of sparse convolution. The performance model and the GSL algorithm are well-described and evaluated on various platforms. The results show significant speedups and demonstrate the effectiveness of the approach.
Additional Feedback
To further improve the paper, I suggest the authors provide more details on the implementation of the sparse convolution design and the GSL algorithm. Additionally, it would be helpful to include more comparisons with other state-of-the-art pruning methods and to discuss the potential applications of the proposed approach in real-world scenarios.
Questions for the Authors
1. Can you provide more insights into the choice of hyperparameters for the GSL algorithm and how they affect the performance of the model?
2. How do you plan to extend the performance model to cover other FLOP-reduction methods, such as FFT and tensor factorization?
3. Can you discuss the potential limitations of the proposed approach and how they can be addressed in future work?