Summary
The paper proposes a novel approach to object recognition, called Transformational Sparse Coding (TSC), which learns object features jointly with their transformations from data. This approach addresses the limitations of current deep learning methods, which either discard location information or require explicit learning of transformed features, leading to combinatorial explosion. The authors introduce a tree structure to represent common transformations in data, allowing for efficient learning of features and transformations.
Decision
I decide to Accept this paper, with two key reasons for this choice:
1. The approach is well-motivated and addresses a significant problem in object recognition, providing a novel solution that combines the benefits of sparse coding and transformation learning.
2. The paper provides empirical evidence to support the claims, demonstrating that TSC can learn interesting features from natural image patches with performance comparable to traditional sparse coding.
Supporting Arguments
The paper provides a clear and concise introduction to the problem, motivating the need for a new approach. The proposed TSC model is well-explained, and the use of a tree structure to represent transformations is a clever solution to the problem of combinatorial explosion. The experimental results demonstrate the effectiveness of the approach, showing that TSC can learn features that are comparable to traditional sparse coding while requiring significantly fewer degrees of freedom.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the optimization process, particularly on how the transformation parameters are learned and how the tree structure is constructed. Additionally, it would be interesting to see more examples of learned features and transformations, as well as a more detailed comparison with other state-of-the-art methods.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on how the tree structure is constructed, and how the transformation parameters are learned?
2. How do you handle cases where the transformation parameters are not well-defined, such as when the feature is not present in the image?
3. Can you provide more examples of learned features and transformations, and demonstrate how they can be used for object recognition tasks?