Summary
The paper proposes a novel approach to boosting generative models, where models are trained in sequence to correct earlier mistakes. The algorithm can leverage many existing base learners, including recent latent variable models, and allows the ensemble to leverage discriminative models trained to distinguish real from synthetic data during sample generation. The authors demonstrate the effectiveness of boosting on density estimation, sample generation, and unsupervised feature learning on real and synthetic datasets.
Decision
I decide to Accept this paper with two key reasons: (1) the paper tackles a specific and important problem in generative modeling, and (2) the approach is well-motivated and supported by theoretical conditions and empirical results.
Supporting Arguments
The paper provides a clear and well-structured presentation of the boosting framework for generative models. The authors derive theoretical conditions under which incorporating a new model to the ensemble will improve the fit and demonstrate the effectiveness of boosting on various tasks. The empirical results show that the proposed approach can outperform baseline models without incurring significant computational overhead. The paper also provides a thorough discussion of related work and potential future directions.
Additional Feedback
To further improve the paper, I suggest that the authors provide more detailed explanations of the model architectures and parameter settings used in the experiments. Additionally, it would be helpful to include more visualizations of the generated samples and feature representations learned by the boosted generative models. The authors may also consider exploring more sophisticated models and datasets in future work.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more intuition on why the boosting approach is effective in correcting earlier mistakes in generative modeling?
2. How do the authors plan to address the potential issue of overfitting in the boosted generative models, especially when using discriminative models as intermediate models?
3. Can you discuss the potential applications of the proposed framework beyond the tasks evaluated in the paper, such as image and video generation, and natural language processing?