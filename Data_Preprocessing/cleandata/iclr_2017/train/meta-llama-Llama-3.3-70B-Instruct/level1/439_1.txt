Summary
The paper proposes a novel approach to solving programming competition-style problems using deep learning. The authors introduce a framework called Learning Inductive Program Synthesis (LIPS), which trains a neural network to predict properties of the program that generated the outputs from the inputs. The neural network's predictions are then used to augment search techniques from the programming languages community, resulting in significant speedups over non-augmented baselines and a Recurrent Neural Network approach.
Decision
I decide to Accept this paper, with the main reason being that the approach is well-motivated, and the results demonstrate a substantial improvement over existing methods. The paper tackles a specific question/problem, which is how to make progress on program induction using machine learning techniques. The authors provide a clear and well-structured presentation of their approach, and the empirical results show an order of magnitude speedup over strong baselines.
Supporting Arguments
The paper supports its claims through a series of experiments that demonstrate the effectiveness of the LIPS framework. The authors show that their approach can solve problems of difficulty comparable to the simplest problems on programming competition websites, which is a significant achievement. The paper also provides a thorough analysis of the neural network's performance, including an investigation of which program instructions tend to get confused by the network.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the neural network architecture and the training procedure. Additionally, it would be interesting to see more examples of programs that can be synthesized using the LIPS framework, as well as a more detailed analysis of the search techniques used. Furthermore, the authors could discuss potential limitations of their approach and provide more insights into how it can be extended to more complex programming problems.
Questions for the Authors
1. Can you provide more details on how the neural network is trained, including the dataset used and the hyperparameters tuned?
2. How do you plan to extend the LIPS framework to more complex programming problems, such as those requiring dynamic programming or search?
3. Can you provide more insights into the conditional confusion matrix analysis, and how it can be used to improve the neural network's performance?