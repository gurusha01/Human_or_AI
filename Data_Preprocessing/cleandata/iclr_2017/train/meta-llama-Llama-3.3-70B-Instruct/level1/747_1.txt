Summary of the Paper's Claims and Contributions
The paper proposes a novel method, called Interior Gradients, for quantifying feature importance in deep neural networks. The authors argue that traditional methods, such as gradients, often fail to capture feature importance due to saturation in the network. They introduce the concept of interior gradients, which are gradients of counterfactual inputs constructed by scaling down the original input. The authors demonstrate the effectiveness of their method on various networks, including the GoogleNet architecture for object recognition, a ligand-based virtual screening network, and an LSTM-based language model. They also provide a theoretical framework for evaluating attribution methods, including two desirable axioms: Sensitivity and Implementation Invariance.
Decision and Key Reasons
Based on the review, I decide to Accept the paper. The key reasons for this decision are:
1. The paper tackles a specific and important problem in machine learning, namely, quantifying feature importance in deep neural networks.
2. The authors propose a well-motivated and novel approach, Interior Gradients, which addresses the limitations of traditional methods.
3. The paper provides a thorough evaluation of the method on various networks and datasets, demonstrating its effectiveness and robustness.
Supporting Arguments
The paper provides a clear and concise introduction to the problem of feature importance in deep neural networks. The authors motivate their approach by highlighting the limitations of traditional methods, such as gradients, and demonstrating the widespread presence of saturation in deep networks. The proposed method, Interior Gradients, is well-explained and easy to understand. The evaluation section provides a comprehensive analysis of the method's performance on various networks and datasets, including comparisons with other attribution methods.
Additional Feedback and Questions
To further improve the paper, I suggest the authors consider the following:
* Provide more insights into the choice of counterfactual inputs and the scaling parameter Î±.
* Discuss the potential limitations and challenges of applying Interior Gradients to other types of networks or datasets.
* Consider providing more visualizations and examples to illustrate the effectiveness of the method.
Some questions I would like the authors to address are:
* How do the authors plan to extend their method to handle feature interactions and correlations?
* Can the authors provide more details on the computational efficiency of their method compared to other attribution methods?
* How do the authors envision their method being used in practice, particularly in scenarios where interpretability and explainability are crucial?