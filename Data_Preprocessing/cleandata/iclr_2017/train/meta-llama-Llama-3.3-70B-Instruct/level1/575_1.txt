Summary
The paper proposes a differentiable version of Canonical Correlation Analysis (CCA), which enables backpropagation through the computation of CCA projection matrices. This allows CCA to be used as a building block within multi-modality neural networks, optimizing the network to minimize the cosine distance of the correlated CCA projections. The authors demonstrate the effectiveness of this approach in cross-modality retrieval experiments on two public image-to-text datasets, outperforming Deep CCA and a multi-view network with freely-learned projections.
Decision
I decide to Accept this paper, with the main reason being that the approach is well-motivated and supported by experimental results. The paper tackles a specific problem in multi-modality learning and provides a novel solution that improves upon existing methods.
Supporting Arguments
The paper is well-structured and clearly explains the background and motivation for the proposed approach. The authors provide a thorough review of related work, including Deep CCA and other multi-modality learning methods. The experimental results are convincing, demonstrating the effectiveness of the proposed approach in cross-modality retrieval tasks. The authors also provide additional insights into the learned representations, showing that the proposed approach can lead to improved retrieval performance even when the correlation between the representations is not maximized.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the computational complexity of the proposed approach and its scalability to larger datasets. Additionally, it would be interesting to see more experiments on other multi-modality learning tasks, such as multi-modal classification or regression. The authors may also consider providing more visualizations of the learned representations to help illustrate the benefits of the proposed approach.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on the optimization process, including the choice of hyperparameters and the convergence criteria used in the experiments?
2. How do you handle the case where the input data has a large number of missing values or outliers, which could affect the estimation of the covariance matrices?
3. Have you considered applying the proposed approach to other multi-modality learning tasks, such as multi-modal classification or regression, and if so, what were the results?