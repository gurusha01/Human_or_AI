Summary
The paper proposes a novel approach to sequence generation with recurrent mixture density networks (RMDNs) using a physiologically plausible model of handwriting as a feature representation. The authors build on recent results in handwriting prediction and focus on generating sequences that possess the statistical and dynamic qualities of handwriting and calligraphic art forms. They preprocess the input training data using the Sigma Lognormal model, which provides a concise and meaningful representation of the handwriting trajectory. The authors then train RMDN models to predict virtual targets and dynamic parameters, and demonstrate the effectiveness of their approach through various experiments, including one-shot learning and style transfer.
Decision
I decide to accept this paper, with two key reasons for this choice. Firstly, the paper tackles a specific and interesting problem in the field of sequence generation, and the authors' approach is well-motivated and grounded in the literature. Secondly, the paper provides a thorough and well-structured presentation of the methodology and experiments, and the results demonstrate the effectiveness of the proposed approach.
Supporting Arguments
The paper provides a clear and concise introduction to the problem and the proposed approach, and the authors demonstrate a good understanding of the relevant literature. The methodology is well-described, and the experiments are thorough and well-designed. The results are impressive, particularly in terms of the ability to generate handwriting sequences that are similar to the input data, and the style transfer capabilities. The paper also provides a good discussion of the limitations and potential future directions, which demonstrates the authors' awareness of the potential applications and challenges of their approach.
Additional Feedback
To further improve the paper, I would suggest that the authors provide more details on the implementation of the Sigma Lognormal model and the RMDN architecture, as well as more visualizations of the generated handwriting sequences. Additionally, it would be interesting to see more experiments on the robustness of the approach to different types of input data and noise. Finally, the authors may want to consider providing more discussion on the potential applications of their approach, such as in handwriting recognition, synthesis, and analysis.
Questions for the Authors
I would like to ask the authors to clarify the following points:
* Can you provide more details on the preprocessing step, particularly on how the Sigma Lognormal model is used to reconstruct the handwriting trajectory?
* How do you handle the case where the input data is noisy or incomplete?
* Can you provide more visualizations of the generated handwriting sequences, particularly for the one-shot learning and style transfer experiments?
* How do you plan to extend this approach to other types of sequence generation tasks, such as speech or music synthesis?