Summary
The paper proposes a novel approach to training neural networks with noisy labels by adding an additional softmax layer to model the noise distribution. This approach optimizes the same likelihood function as the Expectation-Maximization (EM) algorithm, but within the framework of neural networks. The authors demonstrate the effectiveness of their approach on several datasets, including MNIST and CIFAR-100, and show that it outperforms existing methods.
Decision
I decide to Accept this paper, with two key reasons for this choice: (1) the approach is well-motivated and placed in the literature, and (2) the paper provides strong empirical evidence to support its claims.
Supporting Arguments
The paper tackles a specific and important problem in machine learning, namely, training neural networks with noisy labels. The approach is well-motivated by the need to develop robust methods that can handle noisy data, which is a common problem in many real-world applications. The authors provide a clear and concise overview of the related work and demonstrate a good understanding of the existing literature. The empirical results are strong and demonstrate the effectiveness of the proposed approach on several datasets.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the computational complexity of their approach and its scalability to large datasets. Additionally, it would be interesting to see more analysis on the phase transition phenomenon observed in the results. The authors may also want to consider evaluating their approach on datasets with larger class-sets to demonstrate its effectiveness in more challenging scenarios.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on the initialization of the noise adaptation layer and its impact on the convergence of the network?
2. How do you plan to address the scalability issue of the proposed approach when dealing with large class-sets?
3. Can you provide more insights into the phase transition phenomenon observed in the results and its implications for the proposed approach?