Summary
The paper proposes a novel training objective for neural networks, called Neural Graph Machines (NGMs), which combines the strengths of neural networks and label propagation. The objective function biases the neural network to learn similar hidden representations for nodes connected by an edge on a graph, allowing it to leverage both labeled and unlabeled data. The authors demonstrate the efficacy of NGMs on various tasks, including multi-label classification, text classification, and semantic intent classification, using different neural network architectures.
Decision
I decide to Accept this paper, with two key reasons: (1) the paper tackles a specific and important problem in semi-supervised learning, and (2) the approach is well-motivated and supported by extensive experiments.
Supporting Arguments
The paper provides a clear and concise introduction to the problem of semi-supervised learning and the limitations of existing methods. The authors propose a novel objective function that combines the strengths of neural networks and label propagation, and demonstrate its effectiveness on various tasks. The experiments are well-designed and comprehensive, covering different neural network architectures and tasks. The results show that NGMs outperform baseline methods, including a two-stage approach using graph embeddings and a linear classifier.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the construction of the graphs used in the experiments, including the choice of edge weights and node features. Additionally, it would be interesting to see more analysis on the effect of the hyperparameters, such as the balance between the labeled and unlabeled data, on the performance of NGMs. Finally, the authors may want to consider exploring the application of NGMs to other tasks, such as node clustering and link prediction.
Questions for the Authors
To clarify my understanding of the paper, I would like to ask the authors the following questions:
* Can you provide more details on the construction of the graphs used in the experiments, including the choice of edge weights and node features?
* How do you choose the hyperparameters, such as the balance between the labeled and unlabeled data, and what is the effect of these hyperparameters on the performance of NGMs?
* Have you considered exploring the application of NGMs to other tasks, such as node clustering and link prediction?