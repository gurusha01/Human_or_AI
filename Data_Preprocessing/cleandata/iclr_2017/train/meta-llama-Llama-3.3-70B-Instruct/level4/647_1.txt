This paper introduces the RIMs framework, which unfolds the variational inference process. 
The author asserts that the innovation stems from decoupling the model and inference procedure, enabling end-to-end MAP inference, as demonstrated through image restoration experiments.
Although unrolling inference is not a novel concept, the author presents an intriguing viewpoint on the 'model-free' setup, where the model and inference are intertwined and can be learned jointly.
However, I disagree with the authors' comparison to [1] and [2], as both have predefined MAP inference problems that do not necessarily require a separate step. In fact, neither [1] nor [2] involves a predefined prior model or an explicit prior evaluation step, as illustrated in Fig. 1(a). Instead, their implementation follows a similar procedure to the proposed method, which can be explained by Fig. 1(c), where the entire inference process becomes a learnable neural network with implicitly defined energy through parameter learning.
Furthermore, the use of a specific RNN block architecture (GRU) and non-linearity (tanh) in the proposed method restricts its flexibility and implicitly defines a particular family of variational energy and inference algorithms, similar to [1] and [2].
In light of this, I share a similar sentiment with R1 that the novelty of the proposed method is somewhat limited. Additionally, the authors should provide further discussion on the chosen architecture and non-linearity to strengthen their contribution.