This manuscript introduces a novel approach to learning nonlinear dynamical systems using variational inference. In contrast to the deep Kalman filter, the proposed method explicitly learns a state space model, ensuring that the latent state captures all relevant information for predictions, rather than implicitly relying on observations. The experimental results demonstrate that this method is more effective in learning meaningful representations of sequence data.
The proposed Deep Variational Bayesian Filter (DVBF) is well-motivated, and the presentation is generally clear. The experiments yield interesting results on illustrative toy examples, and I believe the contribution is interesting and potentially useful, warranting recommendation for acceptance.
However, the method of Johnson et al. (2016), known as SVAE, deserves more in-depth discussion than the brief two sentences provided, given its apparent similarity to the DVBF. Both methods impose a Markovianity assumption and can handle comparable problems. The primary algorithmic difference appears to be that the SVAE's q network predicts potentials, whereas the DVBF's q network predicts innovations. It would be beneficial to explore the tradeoffs between these two approaches. The justification provided in Section 2.2 for predicting innovations, citing the goal of solving control-related tasks, is not entirely clear.
It is also unclear why SVAEs do not fulfill all the desiderata outlined in the Introduction. Given the public availability of the SVAE code, a comparative analysis in the experiments could provide valuable insights.
Furthermore, the role of uncertainty regarding the variable v is somewhat perplexing. In theory, the transition parameters could be estimated using maximum likelihood, which would involve fitting a point estimate of v. However, the approach taken involves integrating out v as part of the marginal likelihood, which suggests the ability to model different dynamics for different sequences. If this interpretation is correct, it seems counterintuitive that the q distribution for v is data-independent, as specified in Equation (9), rather than depending on the data.