This manuscript proposes a generative model for image patches, utilizing a dictionary-based approach where elements are subjected to gated linear transformations prior to combination. The transformations are theoretically grounded in Lie group operators, although in practice, they are implemented as a set of fixed linear transformations. The authors motivate this approach as a means to learn a hierarchical representation of transformations, yet the experiments presented are limited to a single layer, with the exception of a supplementary toy example in the appendix.
The underlying motivation for this algorithm is compelling, bearing resemblance to group or block sparse coding implementations. However, the restriction to linear transformations is somewhat disappointing. The experimental evaluations, which demonstrate the learning of Gabor-like or center-surround features, are simplistic and would have been considered underwhelming even five years ago, let alone by today's standards.
Several specific points warrant attention:
- Notation consistency with common machine learning literature practices would be beneficial, potentially by designating $x$ as inputs, $w$ as network weights, and reserving $z$ or $a$ for latent variables, to facilitate quicker model interpretation by the reader.
- Equations should be numbered for easier reference.
- In Section 2.2, the fixed nature of the transformation seems at odds with its representation as a function of $x$.
- Section 2.3's updated text introduces confusion regarding the use of Lie groups and matrix exponentials in the algorithm, which requires clarification.
- An alternative approach to addressing local minima issues, as seen in Sohl-Dickstein (2010), involves introducing blurring operators that correspond to each transformation, allowing gradient descent to navigate around local minima by operating at coarser scales.
- In Section 3.2, the term "degrees of freedom" should be explicitly defined, preferably in terms of model parameters rather than latent coefficients. It would be insightful to compare reconstruction errors while controlling for either the number of model parameters or latent variables.
- The potential for a convolutional adaptation of this algorithm, which could enhance its suitability as a generative model for entire images, is an intriguing avenue for future exploration.
Following the rebuttal, while appreciative of the authors' response, my overall assessment remains largely unchanged.