This manuscript presents an exploration of pointer-network neural networks applied to referring expressions within the context of three specific language modeling tasks: modeling dialogues, recipes, and news articles. The proposed approach, when conditioned on co-reference chains, demonstrates superior performance compared to standard sequence-to-sequence models that utilize attention mechanisms.
At its core, the proposed model is a variant of pointer networks equipped with copy mechanisms, as previously explored by Gulcehre et al., Gu et al., and Ling et al. in 2016. These models have been adapted to account for reference chains, with the primary architectural innovations being 1) the restriction of the pointer mechanism to focus exclusively on co-referenced entities, 2) the application of the pointer mechanism to two-dimensional arrays (such as tables), and 3) the incorporation of supervised alignments during training. While these adaptations hold practical value, they represent relatively minor contributions from a purely architectural standpoint.
The empirical contributions of this work are centered on the evaluation of perplexity across the three aforementioned language modeling tasks. Although perplexity is a standard metric for language modeling, its reliability as a proxy for performance in dialogue modeling and recipe generation is questionable. Furthermore, the datasets for the dialogue and recipe tasks are notably small compared to those typically used in standard language modeling tasks, which complicates the assessment of the impact of the proposed models in these contexts. It is plausible that a standard sequence-to-sequence model with attention, given sufficient data, could achieve comparable performance by learning to align referring entities on its own. The language modeling task on news articles (using the Gigaword dataset) yields the most conclusive results; however, the non-standard nature of the dataset and the limited baseline comparisons restrict the broader implications of these findings.
The manuscript also contains several errors, including mathematical inaccuracies, grammatical mistakes, and typographical errors. Specifically:
- Equation (1) lacks a summation over $z_i$.
- There are grammatical errors, such as "into the a decoder LSTM," which should be "into the decoder LSTM," and "denoted as his," which should be "denoted as."
- Typos, including "torkens" instead of "tokens" and "if follows that the next token" instead of "the next token," are present.
- In the "COREFERENCE BASED LANGUAGE MODEL" subsection, the meaning of $M$ is not clarified.
- The definition of $sc$ as the attribute of each column lacks specificity, implying that $sc$ should be a one-hot vector, which needs clarification.
- Phrases such as "the weighted sum is performed" should be corrected to "the weighted sum is computed," and "a attribute" should be "an attribute."
- The paragraph on Pointer Switch contains an error, where $p(z{i,v} |s{i,v}) = 1$ should be $p(z{i,v} |s{i,v}) = 0$.
- The "Table Pointer" paragraph likely refers to an outer-product instead of a cross-product, as the equations do not add up otherwise.
Additional comments and questions arise:
- Regarding the "Attention based decoder," it is unclear whether the attention is computed using word embeddings or the hidden states of the sentence encoder, and whether it applies to the previous turn of the dialogue or the entire dialogue history. Clarification on this point is necessary.
- The advantage of using an "Entity state update" rule over a pointer network or copy network, as employed in the dialogue and recipe tasks, is not clearly elaborated. Further explanation on this choice is warranted.
- The Related Work section contains an inaccuracy, stating that most task-oriented dialogue models embed seq2seq models in traditional dialogue systems, whereas the proposed model queries the database directly. However, there are task-oriented dialogue models, such as the one presented by Wen et al. in "A Network-based End-to-End Trainable Task-oriented Dialogue System," that do query databases during natural language generation, making this statement not entirely accurate.