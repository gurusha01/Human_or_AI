This paper proposes two extractive document summarization models, namely the classifier architecture and the selector architecture, which leverage sequential classification or ranking to select candidate sentences for summarization. The experimental results demonstrate performance that is either superior to or comparable with the state-of-the-art (SOTA).
Technical comments:
- The "positional importance" component in equation (1) raises questions about its significance. It would be beneficial to assess the model's performance without this component, particularly in the context of discussing the impact of document structure when the model is trained on shuffled orders but tested on the original order.
- Similarly, the necessity of the "content-richness" component in equation (1) is questionable, given that the score function already incorporates a salience measure that evaluates the importance of $h_j$ relative to the entire document.
- Regarding the dynamic summary representation in equation (3), it is unclear why different updating equations are used for training and testing. Using the same equation for both procedures could enhance consistency, as the model is aware of the decisions made by the decoder during testing.
- Section 5 is a compelling part of the paper, effectively highlighting the distinctions between the two architectures and providing convincing evidence.
- The decoding algorithm employed in this study is somewhat simplistic, which is disappointing. At the very least, incorporating beam search into both models could potentially yield improved results.