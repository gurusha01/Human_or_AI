This paper proposes a solution to the issue of interpretable representations, with a specific focus on Sum Product Networks (SPNs). The authors contend that SPNs are robust linear models capable of learning components and their combinations, yet their representations have not been fully utilized through the generation of embeddings.
Strengths:
- The concept presented is intriguing, and the development of interpretable models and representations is a crucial area of research.
- The notion of generating embeddings to interpret SPNs is innovative.
- The experiments conducted are noteworthy, although they could be further expanded.
Weaknesses:
- The authors' contributions are not entirely transparent, and several claims require substantiation. For instance, SPNs are inherently interpretable due to the bottom-up propagation of information from visible inputs, which can be visualized at each stage, as well as the top-down parse, which has been previously visualized (Amer & Todorovic, 2015). Furthermore, Proposition one asserts that MPNs are ideal encoder-decoders because max nodes always possess a single maximum value; however, the authors have not addressed scenarios where the node is uniformly distributed or contains multiple equal values. It is unclear whether the authors encountered such cases and whether they adequately addressed all edge cases.
- A more comprehensive comparison could have been made against state-of-the-art generative models, such as Generative Adversarial Networks (GANs), Generative Stochastic Networks (GSNs), and Variational Autoencoders, rather than limiting the comparison to Restricted Boltzmann Machines (RBMs) and Neural Autoregressive Distribution Estimator (NADE).
I recommend that the authors allocate time to evaluate their approach against the suggested methods and ensure that their contributions are clarified and overstated claims are eliminated. I concur with the comments raised by Anon-Reviewer1.