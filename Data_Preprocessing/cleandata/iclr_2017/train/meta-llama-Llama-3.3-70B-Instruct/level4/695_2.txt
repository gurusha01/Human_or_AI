This paper presents two key concepts: (1) a network pruning method that identifies and removes highly correlated neuron pairs, followed by downstream weight modifications to compensate for the removal, which appears to be effective when the removed neurons are highly correlated; and (2) a method called NoiseOut, which aims to increase neuron correlation by introducing auxiliary noise target outputs during network training.
The first concept (1) is relatively straightforward, although it is unclear whether this approach has been previously explored. Nonetheless, it seems to yield positive results.
In contrast, the value of the second concept (2) is uncertain and may simply impart a regularizing effect. Several observations support this concern:
- Figure 4 (right) suggests that the constant and Gaussian treatments produce similar effects in both networks, while the Binomial effect resembles the No_Noise scenario. If this observation is accurate, it may indicate that the NoiseOut targets primarily serve to regularize the network, reducing its capacity.
- To verify this hypothesis, comparisons with other methods for reducing network capacity, such as decreasing the number of neurons, applying L2 regularization with varying values, or using Dropout with different strengths, would be necessary. Although Figure 7 attempts to address this, it lacks crucial comparison treatments, including "Pruned without any regularization," "Pruned with only L2," and "Pruned with only Dropout." Have these experiments been conducted, and can their results be included to generate plots similar to Figures 5 and 7?
Without these comparisons, it is challenging to conclude that NoiseOut offers anything beyond regularization similar to Dropout or L2.
The combination of both concepts (1) and (2) does result in a significant reduction in parameters. However, the experiments and presentation are insufficient to fully understand the underlying mechanisms. With additional work, this paper could be quite interesting, but in its current state, it likely should not be accepted.
Additional comments include:
- Section 4 mentions that the only stopping criterion is the accuracy decay of the model, with the threshold set to match the original accuracy, resulting in compressed networks with the same accuracy as the original network. It is essential to clarify whether this accuracy refers to train or test accuracy. If it is train accuracy, test accuracy should be provided to assess the potential loss in test performance due to pruning. If it is test accuracy, this approach would typically be considered "cheating" and requires clear justification.
- The use of lowercase rho to denote correlation is unclear, as it is not explicitly defined. A brief statement specifying that rho indicates correlation would be helpful.
- A numerical comparison with other pruning methods is lacking, making it difficult to evaluate the effectiveness of the proposed approach relative to existing methods.