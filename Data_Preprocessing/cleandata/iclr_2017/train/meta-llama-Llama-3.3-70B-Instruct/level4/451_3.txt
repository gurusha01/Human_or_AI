This study sheds light on the topology and geometry of deep networks, with a theoretical examination of the former and an empirical investigation of the latter. Although the contributions are narrowly focused (concentrating on ReLU networks with a single hidden layer and proposing a heuristic for calculating the normalized geodesic), the findings are novel and noteworthy, offering a potential foundation for further research in this domain.
Strengths:
1. The paper presents novel theoretical insights into the existence of "poor" local minima in ReLU networks with a single hidden unit, which depend on both input distribution properties and the size of the hidden layer.
2. It introduces a heuristic algorithm for computing the normalized geodesic between two solution points, providing a measure of the curvature of the path connecting them.
Weaknesses:
The analysis is limited in scope, focusing on specific aspects of topology and geometry.
1. The investigation is restricted to ReLU networks with a single hidden layer, which may not be representative of the deeper architectures commonly used in practice, thereby limiting the applicability of the results.
2. The normalized geodesic criterion has limitations in capturing the ease of connecting two equally good points, as it may overlook factors such as narrow valleys that can pose significant challenges to gradient-based optimization algorithms. Furthermore, the proposed algorithm for computing the normalized geodesic relies on a greedy heuristic, which raises concerns about the reliability of the estimated geodesics obtained using this method.
Despite these limitations, it is essential to acknowledge the complexity of the problems addressed in the paper, and I believe the contributions to be valuable and intriguing, offering a starting point for more in-depth explorations in this area.