The authors introduce RASOR as a solution to identifying the optimal answer span for a given question, with a primary focus on modeling the interplay between the question and answer spans. While the concept presented is sensible, it does not represent a significant breakthrough. The analysis provided is engaging and potentially beneficial. However, it would be beneficial for the authors to conduct a more in-depth examination of various boundary prediction models and provide a more compelling argument for the necessity of global score modeling for answer spans.
At its core, RASOR functions by globally normalizing and ranking the scores of potential answer spans. This is achieved through the use of LSTMs to model the hidden vectors of all words, followed by the formation of text span representations by concatenating the hidden vectors of the start and end words of each span. Although the approach is logical, it lacks novelty. Furthermore, the results in Table 6 indicate that the improvement over end-point prediction is modest.
The authors' decision to conduct several analytical experiments is commendable, as some of these experiments yield intriguing insights. For instance, the importance of question-independent representation to performance is highlighted. To further enhance the analysis, it would be enlightening to understand the factors contributing to the current model's superiority over Match-LSTM. Is this attributed to hyper-parameter tuning or the incorporation of question-independent representation?
A notable advantage of the proposed model is its relative simplicity, which suggests that the techniques employed could be effectively combined with other recently proposed methods.