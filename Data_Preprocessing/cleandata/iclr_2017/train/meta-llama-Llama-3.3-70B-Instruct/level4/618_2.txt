I regret the delay in submitting my review.
The initial section of the paper focuses heavily on the technical aspects, but would benefit from a higher-level discussion on the method's objectives and the limitations it aims to overcome. As I understand it, the primary novel contribution of the paper is the proposal to learn group parameterizations rather than fixing them a priori, applying this concept to Steerable Frames instead of common spatial filters as seen in De Brabandere et al. Please correct me if I have misinterpreted this contribution.
The first claimed contribution suggests that general frame bases are more suitable for representing sensory input data than the commonly used pixel basis. However, experiments on Cifar10+ indicate that this may not be universally true. Treating the basis as a hyperparameter requires an extensive search to determine that the Gauss-Frame yields better results. I assume this does not imply that the Gauss-Frame is always superior, as the evidence presented is limited to a single network. Perhaps the first contribution should be rephrased. Additionally, is the "Pixel" network representation adjusted for the larger number of parameters? As a potential user of this method, I am interested in the runtime considerations.
I strongly recommend improving Figure 3, as it uses the notation "w" in multiple contexts and combines boxes, single symbols, and illustrative figures, making it time-consuming to decipher the figure and its flow.
In summary, the paper is generally clear and technically sound, but its readability could be enhanced. For instance, the introduction of frames at the beginning lacks motivation and may be unclear to those unfamiliar with the concept. This work falls into the category of methods that incorporate knowledge about filter transformations into the network architecture, which has both algorithmic and practical aspects. While this is a possible approach to the problem, after reading the paper, I was left wondering what insights I had gained, and I did not feel inspired to integrate or build upon this work. I lacked understanding of the transformational parameters relevant to the problem. Unlike the spatial transformer network paper, which was weaker in technical elegance but provided valuable insights into the feature transformation learned by the algorithm, this paper does not offer similar insights. For example, Table 2 only shows that one of four choices works better empirically. What is it about the x^py^p and Hermite frames that the ResNet is unable to recover from? It is possible to construct network architectures that are a superset of both, potentially avoiding inferior performance.
The algorithm is clear, but it bears similarities to the Dynamic Filter Networks paper. Unfortunately, I am not convinced about the usefulness of this particular formulation. I would expect a stronger paper with more insights into transformations, comparisons to standard techniques, and a clear delineation of when this approach is advisable.