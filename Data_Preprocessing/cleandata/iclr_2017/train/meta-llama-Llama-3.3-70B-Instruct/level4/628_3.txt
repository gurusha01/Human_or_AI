This manuscript introduces Submodular Sum Product Networks (SSPNs) and presents an efficient inference algorithm for approximating the most probable variable labeling in the model, with a primary application in scene parsing. SSPNs are defined by an energy function that combines a grammar component, representing a hierarchical label structure, and a Markov Random Field (MRF) component, encoding spatial label smoothness. The authors propose a move-making algorithm, similar in concept to fusion moves, which iteratively improves a solution by exploring a large neighborhood of alternative segmentations and solving an optimization problem to select the optimal neighbor. Empirical results demonstrate that the proposed algorithm outperforms belief propagation and alpha expansion in terms of energy minimization, while also being significantly faster.
The paper is well-written, with a clearly defined model and a well-presented algorithm, accompanied by a thorough analysis of runtime and behavioral guarantees. The algorithm appears to be effective in minimizing the energy of SSPN models.
However, I have reservations about the paper's suitability for ICLR. The model's reliance on a highly structured, human-defined energy function, followed by inference, seems to contradict the core idea of learning representations. I fail to see a connection between the proposed approach and the concept of learning representations. Furthermore, while the algorithm exhibits faster performance than alternatives, the processing times of 1-287 seconds per image limit its applicability to tasks like training ConvNets.
Additionally, the paper lacks a comparison of the model's segmentation performance with alternative models, instead focusing solely on energy values and training data evaluations.
In conclusion, although this is a well-crafted paper that merits publication in a reputable machine learning conference, I believe it is not an ideal fit for ICLR due to its mismatch with the conference's focus on learning representations.