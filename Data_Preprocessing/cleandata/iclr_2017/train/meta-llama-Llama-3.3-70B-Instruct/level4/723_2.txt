This manuscript proposes a handwriting recognition system utilizing a Long Short-Term Memory (LSTM) model to predict "open bigrams," which are bigrams of characters that may or may not have intervening letters, from handwriting data. These open bigrams are then employed in a decoding step to predict the written word. The experimental results suggest that this system performs slightly better than a baseline model that utilizes Viterbi decoding. However, I have several significant concerns regarding this paper:
- The claim of being "cortical inspired" is problematic. Instead, the concept of open bigrams appears to be inspired by psychology and cognitive science, as they seem to aid in word recognition, as demonstrated by Touzet et al. (2014). The implied connection to cortical characteristics, drawing analogies between deep neural networks for object recognition and the visual cortex, lacks a foundation in neuroscience. Is there direct evidence from neuroscience that open bigrams constitute a separate layer in the cortex for handwriting recognition tasks? The authors' reference to Dehaene's work is a proposal, and more findings from cognitive neuroscience research on reading are needed to substantiate these claims. Furthermore, the statement that "deep neural networks are based on a series of about five pairs of neurons layers" is misleading, potentially referring to Krizhevsky's AlexNet, and it is not accurate to imply that all deep neural networks require five layers. The claim that ten layers is "quite close to the number of layers of an efficient deep NN" is also unsubstantiated, as it depends on the specific network and task.
- The model description is unclear. Although Appendix A.3 provides a brief overview of the setup, it lacks essential details, such as the objective function, and does not explain why the network output is only considered every two consecutive time steps. This omission is problematic, as the paper focuses on the decoder rather than the entire problem, effectively measuring the ease of reconstructing a word from its open bigrams, which has limited relevance to handwriting recognition. In fact, the example on page 4 demonstrates that handwriting is not necessary to illustrate the open bigram hypothesis, leading me to question the choice of tasks. If the focus is solely on the decoding mechanism, why were these specific tasks chosen?
- The comparison to the baseline model is unfair. The Viterbi decoder only has access to unigrams, whereas the proposed model has access to more information and only marginally outperforms the baseline. Did the Viterbi model have access to word boundary information, which contributed to the open bigram model's performance? A comparison to a model that incorporates unigrams, bigrams, and boundary markers, such as rnn_0,1', would be more meaningful. Additionally, the dataset appears to be biased in favor of the proposed approach, with longer words and limited diversity. I am not convinced that this paper demonstrates the effectiveness of open bigrams in handwriting recognition.
Although I appreciate the idea behind this paper, I remain unconvinced by its claims.
Minor points:
- There are numerous typos throughout the manuscript, including "independant" (Fig.1), "we evaluate an handwritten", ", hand written words [..], an the results", "their approach include", "the letter bigrams of a word w is", and "for the two considered database".
- Incorporating the frequency of bigram occurrences could potentially improve the decoding process by normalizing over the full counts instead of binary occurrence counts.
- The results in Table 5 are identical to those in Table 2, with the addition of edit distance and SER, which is confusing and warrants clarification.