I appreciate the opportunity to review this submission, which presents a thought-provoking discussion. While the underlying concepts appear to be well-founded, the experimental design seems somewhat simplistic, and additional empirical support would be beneficial to strengthen the arguments.
Strengths:
- The proposed approach appears to reduce training time, a crucial aspect of deep learning, although this comes at the cost of increased model complexity.
- The paper provides a solid theoretical foundation for sum-product functions, which underlies the compositional architecture. This framework theoretically allows for the use of any semiring and kernel, reducing the need for manual model structure design, a significant challenge in existing convolutional neural networks.
Weaknesses:
- The experiments are limited to the relatively simple NORB dataset. While analyzing a model's behavior on simpler datasets can be informative, it is essential to provide empirical evidence from more complex datasets, such as Imagenet, to compare the compositional kernel approach fairly with convolutional neural networks.
Minor Comments:
- In Section 3.4, the claim that CKMs capture object symmetries seems to lack sufficient justification, warranting further elaboration to support this assertion.