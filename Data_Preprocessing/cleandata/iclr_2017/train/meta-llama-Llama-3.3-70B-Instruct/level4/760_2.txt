This manuscript proposes a method for learning object representations through the composition of templates derived from binary images, utilizing a hierarchical model that combines AND, OR, and POOL operations. The learning process involves approximate inference with MAX-product BP, followed by a heuristic thresholding of activations to achieve binary values.
The topic of learning interpretable, hierarchical representations is intriguing, particularly in the context of modern convolutional neural networks, and this paper offers valuable insights. However, several concerns need to be addressed:
1. The paper lacks a thorough discussion and citation of relevant literature, claiming to be the first to learn interpretable parts. A comparison with existing works, such as the compositional hierarchies by Sanja Fidler, AND-OR graphs by Leo Zhu and Alan Yuille, and AND-OR templates by Song-Chun Zhu's group, is necessary. The claim of being the first to discover such parts should be retracted.
2. The experimental evaluation is restricted to simplistic datasets. A more comprehensive assessment, including real images and well-established benchmarks, as well as a comparison with other generative models like VAE and GANS, would be beneficial.
3. A discussion on the relationship, differences, and advantages of the proposed approach compared to sum-product networks and grammars would provide additional context.
Further comments include:
- The claim that inference is feed-forward after learning is misleading, as message passing implies a recurrent network architecture.
- The algorithm and technical discussion should be relocated from the appendix to the main body of the paper.
- The introduction's assertion that compression is proof of understanding is disputed and should be removed.
- A discussion relating the proposed approach to the Deep Rendering model would be enlightening.
- The satisfaction of constraints during message passing is not clearly explained, and the difficulty of optimizing constraints with max product is well-known. The authors should elaborate on how they address this challenge.
- The learning and inference algorithms appear to be highly heuristic, with arbitrary choices (e.g., clipping to 1, selective message passing). An analysis of these decisions would be informative.
- The process described is not equivalent to a single backward pass.
A reconsideration of the score will be made in light of the authors' responses to these concerns.