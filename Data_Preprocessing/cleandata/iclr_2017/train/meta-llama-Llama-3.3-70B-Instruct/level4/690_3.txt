This paper has several areas that require attention:
1- The significance of finding 2 is questionable, as it appears to be somewhat obvious; however, the authors seem to place more importance on it than warranted, as evident in the discussions.
2- The validity of finding 1 is compromised by its reliance on Fig 4, which is plagued by noise and lacks error analysis, making it challenging to assess the robustness of this result. Intuitively, one would expect the power usage trend to align with Fig 3, but the noise level obscures the ability to determine whether the null hypothesis of no correlation between batch size and power consumption can be rejected in favor of the alternative hypothesis.
3- The paper's presentation is not accessible to colorblind readers or those using black and white printers, which is a significant oversight.
Overall, while this paper provides a decent overview of the current state of the art in vision architectures, it fails to offer substantial new insights. The most notable aspect is the clear demonstration that VGG models are a poor choice in resource-constrained environments, often serving as a benchmark for model compression algorithms due to the ease of achieving significant improvements, a point that many researchers overlook when selecting models for evaluation.