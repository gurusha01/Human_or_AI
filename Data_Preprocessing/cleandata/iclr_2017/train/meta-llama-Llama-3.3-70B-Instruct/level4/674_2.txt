The authors introduce a theoretical framework for examining the recoverability of sparse activations in deep network intermediate layers, leveraging tools from compressed sensing. They establish a connection between the computations performed by a convolutional neural network (CNN) and a specific recovery algorithm, namely Iterative Hard Thresholding (IHT), and provide proofs of necessary conditions for recoverability. Additionally, they offer detailed empirical evidence demonstrating the practical validity of these conditions.
This paper is well-structured and presents an innovative perspective on the effectiveness of current CNN architectures. The authors provide a concise yet sufficient overview of compressed sensing fundamentals, clearly present their primary result linking feed-forward networks and IHT (a notable finding), and transition smoothly to a comprehensive experimental section. The introductory analysis in Section 3 is particularly effective, as it conveys the underlying rationale for the method's efficacy using straightforward and accessible mathematical concepts, a rarity in theoretical papers. The experimental design exhibits a logical progression from artificial distributions to a realistic setup, with complexity increasing in incremental steps.
However, several aspects require refinement. Firstly, while the handling of ReLU non-linearities is adequate, the assumption that max-pooling non-linearities pose no significant issues warrants further discussion, particularly regarding the inversion process (e.g., using pooling switches). 
The established relationship between feed-forward networks and Algorithm 1 presupposes tied weights. It may be beneficial to acknowledge that this result is more robust in the context of recurrent neural networks (RNNs), where tied weights are an inherent design feature.
Although it may seem obvious, a brief clarification that the reconstruction algorithm is intended to be applied sequentially to each layer, with activations in each layer based on the preceding one (in back-propagation order), could enhance reader understanding.
Lastly, the filter coherence measure should be defined mathematically or supported by an appropriate reference to ensure clarity.