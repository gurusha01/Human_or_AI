This manuscript explores the application of semi-supervision to impart meaning to deep generative models characterized by multiple stochastic nodes. From a methodological standpoint, the approach does not introduce fundamentally new concepts, bearing a strong resemblance to the semi-supervised framework established by Kingma et al., with the extension to more than two latent nodes being relatively straightforward. The methodology employs a classical auxiliary variable technique to ensure the inference network for variable y is trained across all data points by treating y as a latent variable with an observation, which can be either the actual observation if y is observed or uninformative if y is unobserved. An alternative strategy involves distinguishing between the inference used for learning the generative model, which may discard inference over observed y, and a separate inference process aimed at 'exercising' the model. This involves approximating the complex probability p(y|x) within the model using a simpler distribution q(y|x), effectively inferring the target distribution p(y|x) for data where only x is available. The results presented are robust, albeit on relatively simple datasets. Overall, the paper is well-written and engaging but falls short in terms of innovative methodological contributions.
Minor comments:
- The title appears somewhat generic in relation to the paper's content. The stark contrast drawn between deep generative models and graphical models seems unwarranted, as deep generative models can be considered a subset of graphical models, distinguished primarily by their learnability and lack of interpretability compared to classical graphical models. Moreover, the presence of multiple stochastic variables is not unique to graphical models, as evidenced by models like DRAW, Deep Kalman Filter, and Recurrent VAE. The use of the term 'structure' is also problematic, as the paper's focus lies more in disentangling and semantically enriching the latent representation of a generative model through supervision, rather than imparting structure to the models themselves, which is a matter of debate.