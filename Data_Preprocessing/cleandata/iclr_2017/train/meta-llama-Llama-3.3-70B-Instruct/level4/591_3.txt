This paper proposes the concept of "sample importance" to quantify the influence of individual training examples on deep neural network training, calculated as the squared L2 norm of the gradient summed over specific layer parameters or all parameters, yielding the "overall importance" when aggregated over time. The authors utilize this metric to distinguish between easy and hard examples and examine their impact during training and on layer depth.
Upon reviewing the paper, several concerns arise. Primarily, the validity of "sample importance" as a meaningful metric is questionable. The magnitude of gradients fluctuates significantly during the learning process, making it challenging to draw conclusive comparisons between the summation of gradients over time for different examples. For instance, gradients typically exhibit higher norms at the onset of training than at convergence, which renders equal weighting of each gradient problematic. A thought experiment illustrates this issue: if the learning rate is excessively high, training may not converge, rendering sample importance ill-defined. The dependence of this measure on the learning rate and the use of the L2 norm are also problematic. Alternatively, the "input Fisher" norm, which reflects the sensitivity of the classifier to the input, may be more suitable. However, summing Fisher norms over time may not yield meaningful insights.
The experimental analysis also raises concerns. The authors' claim that output layers are primarily learned during the early stages of training is not supported by the data, particularly for CIFAR-10 and potentially MNIST, as sample importance remains high across all layers throughout training. Additionally, the dominance of the input layer in the sample importance measure, due to its larger number of parameters, may lead to biased conclusions. Different model architectures might have yielded alternative findings. The failure to leverage sample importance to create an improved curriculum learning strategy further undermines the significance of this measure.
The strengths of the paper include its extensive experimental component. However, the weaknesses outweigh the strengths, as sample importance is a heuristic that lacks rigorous justification, provides limited insight into neural network training, and fails to inform curriculum learning effectively.