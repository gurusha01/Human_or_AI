This paper presents a novel approach to enhancing pre-trained networks for a specific task by introducing an additional inference path tailored to another task, serving as an alternative to the conventional fine-tuning method.
Advantages:
-The proposed method is straightforward and well-explained, making it easily comprehensible.
-Given the widespread use of standard fine-tuning, any improvements or analyses of this technique are likely to be of broad interest.
-The experiments are conducted across multiple domains, including vision and natural language processing.
Disadvantages:
-The introduction of additional modules results in a substantial increase in computational cost, doubling the parameters and roughly tripling the computation required by the original network, as observed in the "stitched" network. However, the paper does not address these costs, which significantly impacts the method's practicality for real-world applications where performance is crucial.
-Considering the substantial additional costs, the core idea is not adequately validated. To confirm that the improved performance is genuinely attributed to the unique aspects of the proposed technique, rather than simply the increased capacity of the network, additional baselines are necessary:
(1) Allowing the original network weights to be learned for the target task, in conjunction with the additional module, to verify that freezing the original weights provides a distinct form of regularization.
(2) Training the full module or stitched network from scratch on the source task and then fine-tuning it for the target task, to verify the usefulness of having a set of weights that never encounters the source dataset.
-The method is not evaluated on ImageNet, which is the most common domain for pre-trained network fine-tuning. The results on CIFAR may not be representative of the method's practical usefulness in computer vision applications, as improved performance on CIFAR does not always translate to ImageNet.
Overall, while the proposed idea is intriguing and potentially promising, its current evaluation is insufficient to convince me that the performance gains are not solely due to the use of a larger network. The lack of evaluation on ImageNet also raises concerns about its real-world applicability.
===============
Edit (1/23/17): Upon re-examination, I noted that the Stanford Cars experiment does involve transfer learning from ImageNet. However, this experiment only demonstrates late fusion ensembling, a conventional approach, whereas the true novelty of the paper lies in the "stitched network" idea. Furthermore, the results in this case are underwhelming, merely showing that an ensemble of ResNet and VGG outperforms VGG alone, which is expected given ResNet's strength as a base network. A more convincing demonstration of the stitched network idea on ImageNet, comparing it to VGG-only or ResNet-only fine-tuning, could potentially strengthen the paper, but the current experiments do not adequately validate the proposed technique in my opinion.