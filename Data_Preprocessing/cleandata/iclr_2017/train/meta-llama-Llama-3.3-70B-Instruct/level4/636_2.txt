The primary finding of this paper is that employing dropout leads to an increase in neuronal variance, and compensating for this variance in parameter initialization and test-time batch normalization statistics yields improved performance, as demonstrated through a series of convincing experiments.
This discovery holds significant importance due to its broad applicability to numerous models prevalent in the literature. Although the concept is not entirely new, having been previously noted that simplified dropout approximations at test time fall short of achieving the accuracy of full Monte Carlo dropout, the paper's contribution remains valuable.
However, further experimental validation would strengthen the paper. Notably:
- The test-time correction for dropout variance may have implications beyond batch normalization. In standard dropout scenarios without batch normalization, only the mean is corrected at test time by scaling activations. It would be beneficial to investigate whether variance correction also enhances performance in these cases.
- A comparison between the proposed dropout variance correction and Monte Carlo dropout at test time, which involves averaging predictions over multiple random dropout masks, would provide additional insight into the efficacy of the suggested approach.