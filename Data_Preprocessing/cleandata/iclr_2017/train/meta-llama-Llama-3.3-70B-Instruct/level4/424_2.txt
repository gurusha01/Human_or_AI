This manuscript introduces a general framework for optimizing complex functions through a series of approximations, which can potentially accelerate the optimization process if the approximations are well-behaved. The authors then apply this concept to a neural network formulation, where the network can adapt to simpler forms under high noise levels and regain its full capacity as training progresses and noise decreases.
The underlying idea and motivation of this paper are intriguing and well-founded. As I previously inquired, I was interested in exploring the connection to shaping methods in reinforcement learning (RL). Although the authors argue that their approach differs from traditional shaping methods, which modify the problem itself, I concur that both methods share the common goal of solving a series of optimization problems with increasing difficulty. Therefore, I strongly recommend including a discussion that highlights the distinctions between shaping, curriculum learning, and the proposed approach, as the relationships between these concepts are not entirely clear.
The presentation of the neural network method lacks clarity, which hinders the overall understanding of the paper. To improve this, I suggest the following:
- Algorithm 1 is introduced without sufficient context, making it difficult to comprehend at the point of reference.
- The steps leading to Equation 25 should be explained more clearly and connected to steps 1-6 in Algorithm 1.
- The function u(x) should be explicitly defined before introducing u*(x).
The experimental evaluations raise several concerns. The authors should discuss why their method is not effective in solving more challenging network training problems, such as thin and deep networks. Specifically:
- The multilayer perceptrons (MLPs) used in the experiments (Parity and Pentomino) are relatively shallow, and a more suitable test would involve training thin networks with systematically increasing depth, as network depth is a well-known optimization challenge.
- The claim that "learning the mapping from sequences of characters to word embeddings is a difficult problem" is made without reference.
- In cases where the gain is primarily due to the regularization effect, the method should be compared to other weight noise regularization methods.
- A comparison to highway networks is also suggested, given the similarities in Equation 22, as they may automatically adapt their behavior from simple to complex networks during training.
- In the CIFAR-10 experiment, it is unclear whether the mollified model uses residual connections, and if so, why. Additionally, it is puzzling that the mollified net trains slower than the residual and stochastic depth networks, which contradicts the MLP results.
In summary, while the ideas and developments in this paper are promising, further work is necessary to address the concerns and clarify the presentation, making it a more convincing accept.