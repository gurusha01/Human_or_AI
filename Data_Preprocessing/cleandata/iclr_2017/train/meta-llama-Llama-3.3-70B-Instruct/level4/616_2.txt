This paper presents a novel approach that learns a latent representation of input image(s) and jointly optimizes a reconstruction loss and an adversarial loss (Eq (1)) using nearest neighbors from an image repository, referred to as "memory". The proposed framework is applied to three distinct tasks: (i) image in-painting, (ii) intrinsic image decomposition, and (iii) figure-ground layer extraction, with qualitative results provided for each task.
The proposed model exhibits promising aspects, particularly in its ability to reason about image composites by matching them against a repository of images, drawing parallels with earlier work such as "Segmenting Scenes by Matching Image Composites" presented at NIPS 2009. However, due to limitations in overall clarity and evaluation, I am unable to fully endorse the paper.
Detailed comments are as follows:
A significant limitation of the paper is the lack of quantitative evaluation of the proposed approach. A comparison with existing methods for intrinsic image decomposition, such as SIRFS, and benchmarking on the "intrinsic images in the wild" dataset, would be essential.
The writing throughout the paper is often vague and confusing. For example, the term "memory database" is ambiguous and ultimately appears to refer to a simple collection of images. Similarly, the concept of "imagination" is not clearly defined. On page 4, the function R(M,x) is defined with both the database and input image as arguments, yet Fig 2 does not depict the input image as an input to R. The contributions outlined on page 3 require clarification, as phrases like "Relevant memory retrieval for informative adversarial priors" are unclear. Furthermore, Fig 3 seems inconsistent with Fig 2, as the module for the "memory database" is absent. Additional details about the fully-convolutional discriminator would be beneficial, potentially including a cost function.