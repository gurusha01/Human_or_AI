The concept of learning a unified embedding by leveraging all available multimodal information about a product is intriguing and holds promise for enhancing recommender systems, particularly in scenarios where limited data is available. The proposed approach of combining multiple modalities is novel, and a successful solution could have significant implications. However, several aspects of the proposed architecture appear to be less than optimal:
1. One of the primary advantages of neural network-based systems is their ability to be trained end-to-end in a joint manner. In contrast, the proposed approach relies heavily on pre-trained modules for different modalities, which may be justified when training data is scarce. Nevertheless, with 10 million product pairs in the Amazon dataset, it seems feasible to train the system jointly, and the lack of such an approach is a notable limitation. This aspect is not discussed in the paper, and it would be beneficial to explore the potential of joint fine-tuning.
2. The introduction of "pairwise residual units" is unclear and lacks sufficient motivation. If understood correctly, this formulation applies a ReLU layer to the concatenated modality-specific embeddings, resulting in a new similarity measure that can be added to the similarity obtained from direct concatenation. A more straightforward approach would be to use an additional fully-connected layer to combine the modality-specific embeddings into a final, potentially lower-dimensional embedding. This alternative should be presented as a baseline to demonstrate the effectiveness of the pairwise residual unit, as the provided explanation is not convincing, particularly regarding the claimed reduction in parameter count.
3. A more minor concern is the choice of TextCNN for text embedding vectors, which seems reasonable, although an LSTM-based approach may also be worth exploring. However, the details of how TextCNN is utilized are not clearly presented in the paper. The authors mention that it operates on the concatenation of the first 10 words of the title and product description, which may not be sufficient to capture a significant amount of information, especially for product descriptions.
The paper could benefit from more thorough motivation for the design choices made. Additionally, it is unclear whether the comparisons presented accurately reflect the state-of-the-art on this dataset, as only one competing technique is discussed, and there is a lack of evaluation on more challenging cold-start scenarios.
A minor detail is the incomplete reference in the second paragraph of page 3, which simply states "(cite Julian)".