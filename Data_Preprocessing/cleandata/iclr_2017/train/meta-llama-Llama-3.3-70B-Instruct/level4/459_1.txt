The paper presents a noteworthy framework that utilizes Tucker and Tensor train low-rank tensor factorization to facilitate parameter sharing in multi-task learning, yielding an appealing and well-structured approach.
The proposed framework has merit and is aesthetically pleasing. 
However, given that multi-task learning is a extensively researched area, the paper's focus on straightforward classification tasks raises questions about the necessity of employing deep learning techniques for such simple datasets. A comprehensive comparison with existing shallow multi-task learning methods is essential to demonstrate the advantages of the proposed deep approach, particularly in relation to its performance on the dataset. The authors' decision to overlook these methods appears to be based on speculation, and it remains unclear whether the proposed framework offers significant improvements over straightforward regularization techniques, such as the nuclear norm. Moreover, the concept of nuclear norm regularization can be readily integrated into deep learning frameworks, as gradient descent is a ubiquitous optimization method across various approaches.