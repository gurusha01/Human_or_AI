This paper explores the Hessian in deep learning, revealing that the eigenvalue distribution tends to cluster around zero, with non-zero eigenvalues correlated to input data complexity. The discussions and experiments presented are largely engaging and informative. Nevertheless, there is considerable room for improvement in the current manuscript.
Quality:
The arguments and findings in the paper would benefit from more rigorous experimentation and comprehensive analysis. Conducting experiments outlined in the conclusion would significantly enhance the paper. Additional suggestions for improvement include:
1. Incorporating comparative plots of eigenvalue distributions for other machine learning methods would provide valuable context and insights into the unique characteristics of deep learning.
2. Normalizing weights prior to Hessian calculation is crucial to avoid misleading results due to scaling issues.
3. Investigating a quantitative measure of Hessian singularity could facilitate more conclusive interpretations, as visual inspections of plots may be inconclusive.
4. Including plots of the Hessian during the optimization process is essential, as the Hessian's behavior during this phase is of primary interest, rather than its state after convergence.
Clarity:
1. The absence of figure references in the main text hinders the reader's ability to contextualize each figure. For instance, Figure 1 lacks clarity on whether the Hessian is calculated at the onset of optimization or post-convergence.
2. The text within figures is excessively small, rendering it difficult to read and interpret the results.