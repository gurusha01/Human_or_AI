This paper investigates the challenge of adapting a policy learned in a simulated environment to a real-world system. The authors propose an approach that utilizes an ensemble of simulated source domains in conjunction with adversarial training to develop a robust policy capable of generalizing across multiple target domains.
In general, the paper addresses a compelling problem and presents a viable solution. However, the implementation of adversarial training differs from its application in other recent studies, such as those involving Generative Adversarial Networks (GANs). To enhance clarity, additional details on certain components, as highlighted during the question and answer session, would be beneficial. Furthermore, including results from alternative policy gradient methods, even if their performance is suboptimal (e.g., Reinforce), as well as comparisons with and without the baseline on the value function, would provide valuable insights for the research community.