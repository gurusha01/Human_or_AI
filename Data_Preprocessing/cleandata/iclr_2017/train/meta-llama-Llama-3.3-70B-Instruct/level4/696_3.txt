The paper presents an analysis of various recently developed machine readers, revealing that certain models can leverage entity markers to their advantage, given that the same marker consistently refers to the same entity. While I generally appreciate analysis-focused papers, I found the argument put forth in this submission to be somewhat unclear.
The experimental results on the Stanford reader, which demonstrate the beneficial impact of entity markers on the model's performance on WDW, are noteworthy and caught my attention. However, I encountered difficulties with the paper's organization and overall narrative. The authors appear to attempt to explain the observed behavior through the concept of "structures," but the success of this endeavor is uncertain. The definition and explanation of these "structures" remain ambiguous to me, making section 4 challenging to follow.
Furthermore, the core message and implications of this paper are not entirely clear. It is uncertain whether the authors are suggesting that entity marking should be incorporated into machine reading models, or if models should be designed to concurrently handle entity references. The role of linguistic features in this context and the potential for utilizing linguistic structures to address reference issues also require clarification.
In summary, although the analysis itself is intriguing, I believe the paper would benefit from a more targeted and coherent argument to effectively convey its key findings and implications.