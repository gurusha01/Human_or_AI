This paper presents a novel approach to optimizing Deep Neural Networks (DNNs) for information seeking tasks by leveraging Generalized Advantage Estimation (GAE) within a reinforcement learning framework, where the method explicitly incentivizes information gain to foster exploration.
While both GAE and DNNs have been previously applied to reinforcement learning, the unique aspect of this work lies in its explicit incorporation of information gain modeling. However, the paper lacks sufficient empirical evidence to convincingly demonstrate the advantages and broad applicability of the proposed methodology. A direct comparison with existing reinforcement learning frameworks that do not account for information gain is notably absent. For instance, the cluttered MNIST experiment attempts to draw a comparison with the work of Mnih et al. (2014), albeit with outdated references and under two distinct settings, where the inputs differ between the two methods. This discrepancy makes it challenging to discern the primary factor contributing to the observed performance differences.
The experimental section is overly complex and difficult to navigate. The presentation of results would be significantly improved by the inclusion of a summary table to clearly outline the key findings, enhancing the overall clarity and readability of the section.