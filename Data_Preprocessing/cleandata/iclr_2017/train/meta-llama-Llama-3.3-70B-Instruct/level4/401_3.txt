EDIT: Updated score. See additional comment.
I find the core concept of the paper to be compelling, particularly the observation presented in Section 3.0, which reveals numerous predictable patterns in the independent evolution of weights during neural network training. The potential to leverage a simple neural network for predicting weights and thereby accelerating training is indeed promising.
However, the current paper's technical quality falls short of expectations, and I strongly encourage the authors to conduct a more rigorous analysis of their approach. To this end, I propose the following specific suggestions:
- The discoveries outlined in Section 3.0, which underpin the proposed method, should be explicitly and clearly articulated within the paper, rather than being presented as anecdotal evidence.
- A critical concern with the paper is the lack of detailed information regarding the training of the Introspection network I. Crucial questions remain unanswered, including the network's training, validation, and test performance, as well as the requisite level of training efficacy necessary for it to be useful in expediting training. These are essential considerations for anyone seeking to adopt this approach.
- Another significant issue pertains to the omission of baseline comparisons. It is essential to investigate whether simpler models, such as linear or quadratic models, or even basic heuristic rules for adjusting weights, could yield comparable results. Such comparisons are vital for understanding the complexity of the weight evolution learned by the neural network.
- I disagree with the authors' decision to utilize default TensorFlow example hyperparameters, as mentioned on OpenReview. There is no scientific justification for this choice. Instead, the authors should first identify hyperparameters that yield satisfactory results within a reasonable timeframe and use these as a baseline. Subsequently, they should demonstrate the benefits of incorporating the introspection network in accelerating training and achieving comparable outcomes.
- The authors' statement on OpenReview, indicating that they also explored RNNs as the introspection network but encountered difficulties with small state sizes, warrants further clarification. What specific challenges did they encounter, and how did these impact the network's performance? I find it surprising that a large state size would be necessary for this task, and even if it were, this would not necessarily preclude evaluation due to memory constraints, as the RNN could be operated in 'mini-batch' mode. In general, I believe that other baselines are more critical than RNNs.
- A question regarding jump points arises: 
The Introspection network I is trained on SGD trajectories. When utilizing I to accelerate training at multiple jump points, if the input weights cross previous jump points, I receives input data from a weight evolution that deviates from SGD, having been modified by I. This appears problematic, although it seemingly does not affect the experiments. This issue highlights the importance of establishing robust baselines. It is possible that I is performing a relatively simple task that is not significantly impacted by this concern.
Given the intriguing nature of the main idea, I am willing to revisit my score if the authors address the aforementioned concerns.