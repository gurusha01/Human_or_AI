This manuscript introduces a collection of methods under the umbrella of "sampling generative models", with a focus on examining the learned latent space and generating output images with specific properties for Generative Adversarial Networks (GANs). However, the paper lacks a clear, unified message or concept, instead presenting a series of techniques that yield visually appealing results. While the manuscript contains some intriguing ideas, it is also plagued by several issues.
The concept of spherical interpolation is noteworthy, but upon closer examination, its validity is questionable. The proposed slerp interpolation equation (page 2) implicitly assumes that the two points q1 and q2 are located on the same sphere, where the parameter theta represents the angle corresponding to the great arc connecting the two points. Nevertheless, the latent space of a GAN, regardless of whether it is trained with a uniform or Gaussian distribution, does not conform to a spherical distribution, and many points exhibit varying distances from the origin. The author's justification for this approach relies on the fact that in high-dimensional spaces, even with a uniform distribution, most points lie on a thin shell within the unit cube. Although this is true, as the outer shell occupies most of the volume, it does not imply that the data density is greater in the outer shell than in the inner region. In a uniform distribution, the data density should be uniform everywhere, and a point on the outer shell is not more likely than a point in the inner region. In contrast, under a Gaussian model, the data density is higher at the center and decreases significantly towards the outer regions. If we have a robust model of the data, sampling the most likely points from the model should yield plausible-looking samples. In this context, spherical interpolation should not outperform traditional linear interpolation. The questions and answers suggest that the author may not fully appreciate this distinction. The results presented in the paper appear to indicate that spherical interpolation is visually superior, but it is challenging to draw concrete conclusions from only three pairs of examples. If this is indeed the case, it may indicate a flaw in our understanding of the learned model.
In addition to these concerns, the J-diagram and nearest neighbor latent space traversal seem to be effective methods for exploring the latent space of a learned model. The attribute vector section, which focuses on transforming images into new ones with desired attributes, is also interesting and provides novel approaches to making the GAN latent space more interpretable.
Overall, I believe that most of the techniques proposed in this paper are useful visualization tools. However, the contributions are primarily related to the design of these visualizations, rather than the technical and model aspects. The spherical interpolation provides the only mathematical equation in the paper, but its correctness is debatable. Furthermore, the visualization tools lack quantitative evaluation, which may suggest that these results are more artistic than scientific.