This paper presents a straightforward approach to pruning filters in two architectural types, aiming to reduce execution time.
Strengths:
- The method remarkably preserves accuracy on widely-used models for ImageNet and Cifar10 datasets.
Weaknesses:
- The selection criteria based on low L1 or L2 norm lacks justification, and two crucial baselines are missing: 1) random filter pruning, and 2) pruning filters with low activation pattern norms on the training set.
- A direct comparison with numerous existing pruning and speedup methods is absent.
- Although FLOPs are reported, the empirical speedup achieved by this method is unclear, which is a key concern for researchers interested in these methods. The omission of wall-clock speedup is notable, given its ease of measurement, raising suspicions about its absence.