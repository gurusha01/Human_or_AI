This paper proposes a method for learning approximate data structures through the use of neural networks, specifically ConvNets, which are trained to emulate the behavior of abstract data structures by minimizing an L2 loss function that enforces adherence to the axioms of the target data structure. For instance, when a neural network is trained to mimic a stack, the loss function measures the discrepancy between the sequence of elements popped from the stack and the expected sequence, as illustrated in Figure 1.
However, several significant issues are identified:
- The approach to learning a stack data structure appears to offer no distinct advantage over a sequence-to-sequence RNN trained on an input sequence such as 8, 6, 4 to predict the output sequence 4, 6, 8.
- The paper fails to adequately acknowledge and compare with prior research on learning fundamental data structures and axioms, including seminal works from the 1990s such as [Das et al. 1992] and [Wiles & Elman 1995], as well as more recent contributions like [Graves et al. 2014], [Joulin & Mikolov 2015], and [Kaiser & Sutskever 2016].
- The use of MNIST digits instead of a simpler categorical distribution on numbers introduces unnecessary complexity.
- Most critically, the experimental section lacks the rigor needed to substantiate the paper's claims. While the figures provided are clear, there is a notable absence of comparative analyses and any quantitative assessment of the "success rate" of learning these data structures, particularly with respect to the number of training examples or the length of input sequences. As of the current version (December 9th, 2016), the paper relies on anecdotal evidence that is insufficient to support its assertions.
Although the research direction is intriguing, the paper's experimental shortcomings make it unsuitable for publication in ICLR in its current form.