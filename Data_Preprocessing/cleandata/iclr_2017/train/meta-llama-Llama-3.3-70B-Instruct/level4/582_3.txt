The paper presents a novel approach to integrating diverse content, such as images and text, into recommender systems. Although various features have been utilized in the past to enhance recommender systems, the originality of this work lies in its introduction of a general framework for combining arbitrary feature types.
One of the strengths of this paper is its ambitious and relatively novel idea of combining multiple heterogeneous feature types into a single recommender system. While previous studies have attempted to incorporate various feature types to improve recommender systems, successfully integrating different feature types remains a challenging task.
However, there are several aspects of the paper that seem somewhat ad-hoc. Notably:
-- The system is constructed by combining multiple components, each trained separately and then integrated through an additional learning stage. Although this approach is straightforward and likely to be effective, it shifts the focus of the contribution from end-to-end learning, which is a primary emphasis of this conference, to system building.
-- This modularity makes it difficult to determine the model's ability to generalize to arbitrary feature types, such as audio or video features. Incorporating such features would require significant implementation efforts, rather than simply being able to add them to the system and expect it to function.
The authors' responses to pre-review comments address some of these concerns, although some of the justifications are not entirely persuasive. For instance, it would be more convincing to use consistent baselines across all tables, rather than omitting some due to the claim that the point had already been made elsewhere.
Overall, the attempt to combine multiple feature types in real-world recommender system datasets is commendable. Nevertheless, the strength of the baselines is uncertain, as they appear to be more akin to ablation experiments than comparisons to state-of-the-art recommender systems.