This paper presents Edward, a probabilistic programming language developed on top of TensorFlow and Python, which encompasses a wide range of contemporary probabilistic machine learning methods.
Quality:
The Edward library is commendable for its extensive collection of modern probabilistic inference techniques, made accessible in a user-friendly manner. The paper provides a concise overview of key techniques, particularly from a representation learning perspective, along with two experiments demonstrating the implementation of various modern variational inference methods and GPU-accelerated Hamiltonian Monte Carlo (HMC). 
To enhance the first experiment, providing a direct link to the complete, reproducible code would be beneficial. The HMC experiment is satisfactory, although characterizing Stan as a hand-optimized implementation may be misleading, as the code is not optimized for the specific model and hardware configuration used. Instead of making unsubstantiated claims, a head-to-head comparison against Stan on a single core, followed by a separate report on the additional speedups gained from parallelization and GPU acceleration, would be more informative. This would also enable readers to estimate the method's performance on different hardware configurations.
Clarity:
The paper is generally well-written and easy to follow, with numerous helpful code examples. However, it is sometimes unclear what parts of the code are missing. Providing a machine-readable companion, such as a Jupyter notebook, with complete, runnable code for all examples would be extremely helpful, making it easier for readers to copy and paste the code.
Originality:
The Edward library is a distinctive collection of probabilistic inference methods. However, the paper's novelty is potentially compromised by previous publications from the same group, particularly Tran et al. (2016a), which covers similar material from a different perspective. It is unclear whether this other paper has been published or submitted elsewhere.
Significance:
Edward is likely to have a significant impact on the field of Bayesian machine learning and deep learning.
Other comments:
In Section 2, a distinction is drawn between specialized languages (including Stan) and Turing-complete languages like Edward. This distinction seems unfair, as Stan is also believed to be Turing-complete. Furthermore, no proof is provided to support the claim of Edward's Turing-completeness.