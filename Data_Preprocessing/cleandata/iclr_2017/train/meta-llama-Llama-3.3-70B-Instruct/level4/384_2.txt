This paper proposes a deep neural network architecture for machine comprehension on the SQuAD dataset, building upon the match-LSTM and Pointer Net models. The match-LSTM component generates attention over each word in the question for each word in the passage and aggregates these matchings, while the Pointer Net produces answers by either generating words or predicting start and end tokens. The experimental results demonstrate that both variants of the proposed model surpass the baseline presented in the SQuAD paper. Additionally, the paper provides some analysis of the results, including performance variations across answer lengths and question types.
The strengths of this paper include:
1. The introduction of a novel end-to-end model for machine comprehension, eliminating the need for hand-crafted features.
2. A significant improvement in performance over the SQuAD paper's baseline.
3. Insightful analyses of the results, such as better performance for short answers and the difficulty of answering "why" questions.
However, there are some weaknesses and areas for improvement:
1. The paper lacks quantitative analysis on the impact of attention modeling in match-LSTM and the answer pointer layer, making it desirable to compare model performance with and without attention in these components.
2. Further insight into the significant performance gap between the boundary model and sequence model in the answer pointer layer would be beneficial.
3. An analysis of the proposed model's performance for questions requiring different types of reasoning (as outlined in table 3 of the SQuAD paper) would provide valuable insights into the model's strengths and weaknesses.
4. Clarification is needed on why the activations resulting from {h^p}i and {h^r}{i-1} in G_i (equation 2) are repeated across the dimension of Q, rather than learning different activations for each dimension.
5. It is unclear why Bi-Ans-Ptr was not used in the ensemble model (last row in table 2), given its 1.2% improvement in F1 score.
6. A more detailed discussion and comparison of the DCR model (in table 2) would be appreciated.
In summary, this paper presents a reasonable end-to-end model for machine comprehension on the SQuAD dataset, achieving significant improvements over the baseline. Nevertheless, additional analyses, ablation studies, and insights are necessary to fully understand the contributions of attention, the performance differences between models, and the impact of reasoning complexity on the proposed model's performance.