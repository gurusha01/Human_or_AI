Paper Summary 
This manuscript explores the application of adversarial and virtual adversarial training techniques to Long Short-Term Memory (LSTM) networks for text classification tasks. Given the discrete nature of text inputs, adversarial perturbations are applied to the normalized word embeddings. The authors present comprehensive experimental results, which demonstrate the effectiveness of these approaches.
 Review Summary 
The paper is well-structured and adequately referenced. The extension of adversarial training to text data, although straightforward, is a meaningful contribution. The experimental section is thorough, featuring comparisons with alternative strategies. The proposed methodology is both simple and effective, making it easily implementable based on the provided description.
 Detailed Review 
The manuscript is clear and concise. However, I have several suggestions regarding the experimental design and connections to prior research:
Experiments:
- It would be beneficial to include a Support Vector Machine (SVM) baseline in Table 2, as well as for other datasets, potentially referencing the work by S Wang and C Manning (2012).
- Considering the application of masking noise (i.e., dropping words) as an additional baseline could provide valuable insights. This approach has been shown to outperform dropout and Gaussian noise in text applications, such as denoising autoencoders.
- The results in Table 5 indicate that virtual adversarial training performs worse than the baseline. I am unsure if this outcome is due to the tuning of epsilon or potential issues with validation reliability. Could you clarify this discrepancy?
Related Work:
Drawing parallels between the proposed approach and existing methods like SVM and transductive SVM could enhance the discussion. These methods achieve similar outcomes to adversarial training by maximizing the margin, effectively moving examples towards the decision boundary in the direction of increasing loss gradient.
Furthermore, exploring the connection between adversarial training and contrastive divergence could provide additional context. The adversarial samples generated in this work bear resemblance to the one-step Markov Chain samples from contrastive divergence, as discussed in Bengio (2009). Related techniques, such as those aiming to explicitly cancel the Jacobian at data points (e.g., Rifai et al., 2011), could also be relevant.
 References 
Marginalized Denoising Autoencoders for Domain Adaptation. Minmin Chen, K Weinberger.
Stacked Denoising Autoencoders. Pascal Vincent. JMLR 2011.
Learning invariant features through local space contraction, Salah Rifai, Xavier Muller, Xavier Glorot, Gregoire Mesnil, Yoshua Bengio and Pascal Vincent, 2011.
Learning Deep Architectures for AI, Yoshua Bengio 2009
Large Scale Transductive SVMs. Ronan Collobert et al 2006
Optimization for Transductive SVM.  O Chapelle, V Sindhwani, SS Keerthi JMLR 2008