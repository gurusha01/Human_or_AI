This manuscript explores the concept of multi-sense embeddings and presents a method for learning these representations using aligned text across multiple languages. The authors also suggest that incorporating additional languages can enhance word sense disambiguation by mitigating ambiguities that persist across language pairs. Although this concept is not entirely novel, the proposed approach to learning multi-sense embeddings through the utilization of multilingual data is noteworthy.
However, the paper has several shortcomings. The model description is overly complex, obscuring an otherwise straightforward idea that could be conveyed more succinctly. More critically, the comparison with existing work is inadequate, making it challenging to objectively assess the proposed model's merits.
To strengthen this paper, the authors should evaluate the learned embeddings in downstream tasks and compare them to other published methods. Currently, the manuscript primarily presents relative results between model variants, supplemented by t-SNE plots that do not significantly contribute to the narrative. A more comprehensive evaluation would substantially enhance the paper's impact and credibility.