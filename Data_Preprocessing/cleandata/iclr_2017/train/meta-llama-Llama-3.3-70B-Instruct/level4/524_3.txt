This paper presents a innovative approach to data augmentation, wherein the authors augment intermediate feature representations rather than the input data itself. The methodology utilizes sequence auto-encoder based features and explores various augmentation techniques, including random perturbation, feature interpolation, and extrapolation. The results demonstrate that augmenting the feature space, particularly through extrapolation, yields notable accuracy improvements compared to the authors' baseline, across three sequence classification tasks and the MNIST and CIFAR-10 datasets.
To further enhance the paper, several key questions and suggestions arise:
a) The proposed augmentation technique is applied to a learned auto-encoder based feature space, referred to as the 'context vector', which is then used to train classification models. It would be beneficial to investigate the application of this feature space augmentation directly to the classification model during training, potentially across multiple layers. Additionally, exploring the suitability of convolutional neural network (CNN) architectures for feature space augmentation would be valuable, given their current status as state-of-the-art in many image and sequence classification tasks.
b) When employing interpolation or extrapolation-based augmentation, it is worth considering the incorporation of nearby samples from competing classes. This is particularly relevant for extrapolation-based augmentation, where examining the proximity of extrapolated features to competing classes compared to the original features could yield interesting insights.
c) The consistent degradation in accuracy observed with random interpolation or nearest neighbor interpolation-based augmentation is counterintuitive. The authors should provide an explanation for this phenomenon, as it contradicts expectations.
d) The results on MNIST and CIFAR-10 are inconclusive, with error rates on CIFAR-10 exceeding 30% and a surprising degradation in accuracy on MNIST when applying input space data augmentation. To draw more meaningful conclusions, it may be necessary to extend the feature space augmentation concept to CNN-based models, which currently achieve state-of-the-art performance on these datasets.