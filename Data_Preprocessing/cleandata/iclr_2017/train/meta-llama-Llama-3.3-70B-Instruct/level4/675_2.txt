The submitted paper introduces a novel approach to learning sequence predictors, building upon the concepts of incremental and curriculum learning. By initially presenting simpler samples and gradually increasing complexity during training, the authors define complexity as the length of training sequences, assuming that longer sequences require more intricate internal representations and are thus more challenging to learn.
The paper focuses on sequence prediction from primed prefixes, with experiments conducted on a custom dataset extracted from MNIST. The idea presented is intriguing and worthy of attention, with notable aspects including the evaluation section, where the authors conduct ablation studies to mitigate potential side effects and compare their proposed learning strategy to alternative approaches.
However, a major concern lies in the evaluation methodology. Given the broad claim, testing the method on a single, non-standard dataset derived from MNIST is insufficient. To substantiate the proposed algorithm's effectiveness, it is essential to conduct experiments on multiple public datasets and apply it to different domains.
The paper's length is excessive and should be significantly condensed. The section on transfer learning from prediction to classification appears to be a separate topic, lacking a clear connection to the paper's primary contribution.
The presentation and organization of the paper could be enhanced, as the current sequential structure and tone resemble a student's report. Specifically, the lengthy, unnumbered equation on page 6 requires clearer explanations, including breakdowns of each term and symbol, as well as distinctions between predicted variables and ground truth observations, given the supervised learning context.
Additionally, there are discrepancies between the names in Table 2 and the descriptions provided in Section 4. The calculation of the "Best value for the average over 10 runs" is unclear and warrants further explanation.