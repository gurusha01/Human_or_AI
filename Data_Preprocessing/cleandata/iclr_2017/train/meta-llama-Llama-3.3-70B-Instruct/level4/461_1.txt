This manuscript proposes a semi-supervised learning framework that promotes feature invariance to random perturbations in the network and/or input data. The authors introduce two distinct models: one that imposes an invariance constraint between different model and input instantiations within a single training iteration, and another that applies invariance to features for the same input across multiple training steps using cumulative exponential averaging. Experimental evaluations on CIFAR-10 and SVHN datasets yield notable improvements, with similar gains observed in both cases. Additionally, the authors explore an application demonstrating some robustness to label corruption.
The discussion of recent work by Sajjadi et al., which shares a similar philosophy, serves to validate the findings presented in this paper. However, a major suggestion for improvement is the inclusion of experiments on larger datasets, as CIFAR and SVHN are relatively small test cases. For scenarios with abundant unlabeled data, it would be beneficial to conduct tests with datasets comprising over 1 million samples, with 1,000 to 10,000 labeled examples, as this is a common scenario when labels are scarce.
Furthermore, the current implementation restricts data augmentations to translations and horizontal flips (for CIFAR), which, although standard, may not fully leverage the model's potential to exploit random sampling. Investigating the model's performance with a broader range of augmentations and fewer labels could provide valuable insights. The authors' decision to limit the system to a specific set of augmentations may overlook potential discoveries, such as the differing handling of horizontal flips between the two model variants.
In general, the approach appears to be straightforward and yields reasonable results, but more comprehensive and large-scale experiments would be necessary to thoroughly understand its performance characteristics.
A minor remark: the paper references "dark knowledge" when explaining the results, for instance, at the bottom of page 6. While this serves as a motivational tool, a more concrete analysis of the results might be possible. For example, the consistency term could be shown to encourage feature invariance to stochastic sampling more strongly than a classification loss alone, providing a more nuanced understanding of the model's behavior.