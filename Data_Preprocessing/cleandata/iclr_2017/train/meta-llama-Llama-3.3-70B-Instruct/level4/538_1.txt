The authors present a novel approach to learning symbolic expression representations, which is thoroughly evaluated against similar methods and well-motivated. 
As previously noted, I believe the authors could enhance the justification for their subexpforce loss, providing a more comprehensive explanation for its inclusion.
On page 6, the authors reference a comparison with a two-layer MLP without residual connections. To further strengthen the analysis, I suggest adding a direct comparison between models with and without the subexpforce loss, while maintaining residual connections and normalization.
My primary concern lies with the evaluation metric, which appears to be precision calculated on a per-query basis. I recommend adopting more standard metrics, such as precision-recall or ROC, as they would provide more informative insights. The current metric may introduce biases, as larger equivalence classes can lead to better performance due to the increased likelihood of random expressions matching the query, which is not accounted for in the denominator.