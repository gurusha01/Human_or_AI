I regret the delay in submitting this review and appreciate the authors' responses to my initial inquiries.
This paper presents an enhanced version of the PixelCNN generative model, incorporating several improvements, including the utilization of dropout and skip connections, as well as more notable modifications such as the adoption of an alternative likelihood model and multiscale analysis. The results demonstrate state-of-the-art likelihood performance on the CIFAR-10 dataset.
In summary, the primary contribution of this work lies in its refinement of autoregressive-type models, such as PixelCNN, which boast the advantage of having their likelihood evaluated in closed form. A key differentiator among these models is the approach used to model the conditional likelihood of a pixel given its causal neighborhood:
- One line of research, exemplified by the work of Theis et al. (2012, 2015), models the conditional distribution as a continuous density over real numbers. However, this approach is limited by its failure to account for the discrete, quantized nature of observed pixel intensities, and its assignment of probability mass outside the valid range of pixel intensities.
- In contrast, van den Oord and colleagues have proposed modeling the conditional likelihood as an arbitrary discrete distribution over the 256 possible pixel intensity values. While this approach avoids the limitations of continuous likelihoods, it may be inefficient and wasteful.
- The authors propose a middle ground, retaining the discretized nature of the conditional likelihood while restricting the discrete distribution to those whose cumulative distribution function (CDF) can be modeled as a linear combination of sigmoids. This approach is sensible and novel, yet it does not strike me as particularly groundbreaking or significant.
The second notable modification is the introduction of downsampling and multiscale modeling, as opposed to dilated convolutions. The authors' primary motivation for this change is to reduce computational time while preserving the model's multiscale flexibility. They also incorporate shortcut connections to mitigate potential information loss during downsampling. However, I do not find this modification to be especially innovative, as multiscale image analysis with autoregressive generative models has been explored in previous works, such as Theis et al. (2012).
Overall, I feel that this submission lacks substantially new ideas and reads more like a documentation of a specific implementation of an existing concept rather than a presentation of novel research.