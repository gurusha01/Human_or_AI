This manuscript introduces a multi-view learning approach that linearly projects input data from different views to align their neighborhood relationships, specifically the transition probabilities, across views.
The paper is well-motivated, offering a fresh perspective on multi-view learning from an information retrieval standpoint. However, several concerns arise:
- The algorithm's time complexity, as presently formulated, is notably high, as observed in the last paragraph of page 4. This complexity may explain the reliance on small datasets and linear projections in the experiments.
- The proposed method exhibits desirable properties, such as not requiring uniform dimensionality across view projections, which is a commendable aspect. Although it more directly captures neighborhood relationships compared to CCA-based methods, it does not directly optimize conventional retrieval criteria, like ranking-based metrics. In contrast, the contrastive loss function presented in Hermann and Blunsom's work (ICLR 2014) represents a relevant information retrieval approach that warrants discussion and comparison.
A primary concern with this paper lies in its experimental design. As previously noted, linear mappings are preferable over nonlinear mappings for dimension reduction only in limited scenarios. The authors argue that linear projections offer better interpretability, but this claim lacks empirical support within the paper. Interpretability can also be achieved through visualizing projections to understand the input variations reflected along specific dimensions, a common practice in nonlinear dimension reduction methods.
While the approach can be generalized to nonlinear projections, the absence of experiments involving nonlinear projections and comparisons with nonlinear CCA variants and other multi-view learning algorithms restricts the paper's impact.