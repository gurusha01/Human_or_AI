This manuscript presents a novel generative model that leverages an annealing process, wherein transition probabilities are directly learned to maximize a variational lower bound on the log-likelihood. While the concept is innovative and intriguing, the paper would benefit from more comprehensive quantitative validation and a more in-depth discussion of its connection to existing research.
The proposed method bears a strong resemblance to AIS and RAISE, sharing significant mathematical structure. Consequently, a more detailed examination of these algorithms and their relationship to the variational walkback method is necessary, rather than a cursory mention in the related work section. As I understand it, the proposed approach essentially extends RAISE by learning transition probabilities instead of relying on fixed probabilities based on an existing MRF. This extension is noteworthy, but the connection to prior work requires clarification.
The analysis in Appendix D appears to be flawed. It derives a formula for the ratio of prior and posterior probabilities under the assumption of constant temperature, which results in a large ratio. However, when the temperature varies, the analysis should follow Neal (2001), yielding a different outcome.
One of the primary advantages of the method is its optimization of a variational lower bound on the log-likelihood. More accurate estimates can be achieved using importance sampling, and it would be straightforward to report log-likelihood estimates for this method. I am surprised that such estimates are not provided, especially given the abundance of prior results on MNIST that could be used for comparison. A natural baseline for comparison would be RAISE, allowing for an assessment of whether learning transitions provides a significant benefit.
I believe the fundamental idea presented in this paper has merit, and I would consider revising my evaluation if the aforementioned issues are addressed in a revised version.
Minor comments include:
* The characterization of training undirected graphical models as requiring sampling from MCMC chains in the inner loop of training for each example seems inaccurate, as the standard algorithm, PCD, typically involves only a single step per mini-batch.
* Some methods discussed in the related work section lack citations.
* The method is justified in terms of "carving the energy function in the right direction at each point," but I am unsure if this accurately reflects the method's purpose. Isn't the primary goal of the method to optimize a lower bound on the log-likelihood, thereby learning a globally correct allocation of probability mass?