This study explores a joint learning framework where tasks are organized in a hierarchical structure based on their complexity, with experimental assessments conducted on part-of-speech tagging, chunking, dependency parsing, semantic relatedness, and textual entailment. The end-to-end model demonstrates improved performance over models trained exclusively on target tasks.
However, despite the significance of the hypothesis presented in this work, the experimental evaluation falls short in several aspects:
Firstly, a basic multi-task learning baseline should be established, devoid of any task hierarchy, to rigorously test the hypothesis that tasks should be ordered by complexity.
Secondly, the inclusion of the chunking test set in the dependency parsing training data renders the results related to chunking with JMT_all uninformative.
Thirdly, the model's inability to guarantee well-formed dependency trees compromises the fairness of the results presented in Table 4.
A minor concern is that chunking, although annotated at the word level, is not a word-level task; rather, it is a structured prediction task aimed at learning a structured annotation over a sequence, as noted in previous research.
Reference: [1]