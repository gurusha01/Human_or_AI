This paper investigates the tradeoff between performance, area, energy, and model accuracy in the design of custom number representations for deep learning inference, utilizing common image-based benchmarks such as VGG and Googlenet to demonstrate that custom floating point representations with fewer than 16 bits can yield improvements in runtime performance and energy efficiency, albeit with a slight compromise in model accuracy.
Questions:
1. Does the proposed custom floating point representation accommodate support for denormal numbers?
2. Is the custom floating point unit operated at the same frequency as the baseline 32-bit floating point unit, and if not, what frequencies are employed and how do these differences impact the overall system design, particularly in terms of data feeding from memory to the floating point units?
Comments:
1. It is recommended that the IEEE half-precision floating point format (1-bit sign, 5-bit exponent, and 10-bit mantissa) be used as a baseline for comparison, as 32-bit floats are recognized as excessive for DNN inference and major hardware vendors already support IEEE half-precision floats.
2. The claim of achieving a certain level of energy savings by switching to a custom floating point representation may be misleading, as while the floating-point unit itself may consume less energy due to the smaller operand bit-width, a significant portion of total energy expenditure is attributed to data movement between memories, which may not be directly impacted by reductions in floating-point unit energy consumption.
3. Similarly, it should be explicitly stated that the claimed speedup pertains only to the floating point unit and may not translate to an overall workload speedup, as although compute unit speedup scales roughly quadratically with bit-width, bandwidth requirements scale linearly, potentially leading to memory bandwidth starvation and necessitating a reevaluation of speedup and energy savings claims.
4. The authors should also address the complexities and overheads associated with data accesses and the design of system buses/data paths when employing non-byte-aligned number representations, as the benefits of custom representations, such as a 14-bit representation, may be partially offset by the additional overhead of supporting non-byte-aligned memory accesses.