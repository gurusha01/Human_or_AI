The paper presents a sophisticated approach to compressing and reconstructing deep networks, incorporating additional parameters to minimize memory usage. 
The authors demonstrate the superiority of their complex method over a simpler hashed net proposal, but a crucial consideration arises: do the memory comparisons account for the extra parameters required by the reconstruction network? If not, the experimental evaluation may be biased.
Given that the hashing and reconstruction processes will likely overshadow the feed-forward and back-propagation updates in terms of computational overhead, a comparison of the running times of the two methods is essential. While hashed nets have a relatively straightforward running time analysis, the introduction of an additional bottleneck is noteworthy. The authors should provide an analysis of the impact on running time, as modest improvements may be outweighed by significant computational costs. The lightweight nature of this method is not convincingly demonstrated, and it is unclear whether the added complexity is justified. If complex compression and reconstruction methods are permissible, numerous off-the-shelf alternatives could be employed, albeit at a substantial computational cost.