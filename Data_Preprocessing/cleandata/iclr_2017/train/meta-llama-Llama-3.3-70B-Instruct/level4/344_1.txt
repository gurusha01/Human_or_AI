The paper proposes a novel learning algorithm for managing complex battle scenarios in real-time strategy games, focusing on a specific sub-problem within the broader RTS context. The assumptions and limitations outlined, such as the greedy MDP and distance-based action encoding, are well-defined and reasonable for this particular problem.
A key contribution of this work is the introduction of a zero-order optimization algorithm for structured exploration, which represents a promising application of zero-order optimization in conjunction with deep learning for reinforcement learning. The motivation for this approach is well-supported by arguments similar to those presented in DPG. The results demonstrate a clear advantage over traditional Q-learning and REINFORCE, which is plausible given the context. However, the evaluation is confined to the RTS domain, and it would be beneficial to see the algorithm's performance in other domains to assess its broader applicability. The complexity of the RTS domain makes it challenging to predict the potential benefits of this zero-order approach in other areas. Perhaps the authors could provide additional discussion to clarify the motivations behind this choice.
Certain design decisions appear arbitrary and are justified solely by their practical effectiveness. For instance, the use of only the sign of w / Psi_{theta}(s^k, a^k) and the omission of the argmax operation for action selection are not thoroughly explained. It is possible that these choices help maintain the values within a specific range, but it seems that valuable information may be lost by only considering the sign. The authors may want to explore truncating or normalizing w/Psi to preserve more information. Furthermore, statements such as the importance of maxpooling and tanh nonlinearity, as well as the preference for Adagrad over RMSprop, are presented without sufficient elaboration or supporting evidence, leaving the reader wondering about the underlying reasons.
The presentation of the paper could be improved by providing more context for certain ideas. For example, the definition of f(\tilde{s}, c) on page 5 lacks explanation of the w vector, leaving the reader uncertain about its origin and purpose. A brief sentence explaining its role or referring to the section where it is fully described would help clarify its context. Additionally, the comment on page 7 regarding the sampling of a single u for an entire episode is unnecessary, as this information is already mentioned in the preceding text and is clear from the pseudo-code.
Finally, there is a minor error in the text, where "perturbated" should be corrected to "perturbed". 
After the response period, no rebuttal was entered, and therefore, the review remains unchanged.