This paper presents two distinct RNN-based architectures for extractive document summarization, namely "Classify" and "Select". The "Classify" model processes the entire document and then re-examines each sentence to make a binary decision regarding its inclusion. In contrast, the "Select" model reads the document in its entirety and iteratively selects the most relevant sentence. Both models rely on the assumption that ideal extractive summaries exist and employ a pseudo ground-truth generation method, similar to that used by Svore et al. (2007) and other related works.
In general, the contributions of this paper appear to be a modest extension of the work by Cheng & Lapata (2016), with comparable or inferior performance. The topic of single document extractive summarization seems somewhat unremarkable, given that even 14 years ago, in DUC 2002, existing models struggled to outperform the lead baseline, which simply selects the initial sentences of the document. It is unfortunate that this paper does not tackle the more intriguing challenges of abstractive summarization or apply its proposed approach to multi-document summarization. Furthermore, the need to limit the maximum sentence length to 50 characters suggests that the model may have difficulty scaling to more complex inputs.