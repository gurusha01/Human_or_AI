This paper tackles the issue of erroneous labels in supervised training, presenting a well-formulated problem and a novel solution. 
However, the experimental validation is somewhat restricted, making it challenging to assess the efficacy of the proposed approach, particularly in terms of its scalability to a large number of classification targets and its continued effectiveness.
It would be insightful, for instance, to compare the proposed method's performance to training with a smaller but high-quality dataset to determine its relative benefits.
The results in Figure 2 suggest that the proposed method performs optimally with increasing data when the noise fraction remains below a certain threshold, but its performance deteriorates significantly once this threshold is exceeded. A more in-depth analysis and justification of this phenomenon, whether it is coincidental or an inherent characteristic of the method, would be highly beneficial.