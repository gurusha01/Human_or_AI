This paper presents a novel generative model that leverages real-valued non-volume preserving transformations to facilitate efficient and exact inference and sampling of data points. 
The authors employ the change-of-variable technique to derive a model distribution of the data from a simple prior distribution on a latent variable, achieving this by carefully designing the bijective function used in the technique to obtain a triangular Jacobian that enables efficient computation.
The development of generative models with tractable inference and efficient sampling is a vibrant area of research, and this paper makes a significant contribution to this field. 
Although the results do not surpass the state-of-the-art, they are nonetheless competitive, and the proposed method is innovative and worthy of exploration as it attempts to bridge the gap between auto-regressive models, variational autoencoders, and generative adversarial networks.
The authors provide a clear discussion of the differences and similarities between the proposed model and other types of generative models that are currently being actively researched. 
In comparison to autoregressive models, the proposed approach offers rapid sampling, while it provides a tractable log-likelihood evaluation compared to generative adversarial networks. 
Additionally, the inference is exact when compared to variational autoencoders, and the learning process is tractable when compared to deep Boltzmann machines. 
It is evident that the goal of Real NVP is to bridge the gap between existing popular generative models.
The paper includes a range of interesting experiments that demonstrate the capabilities of the proposed technique, and making the code available online would undoubtedly contribute to the field; it would be beneficial to know if there are plans to release the code. 
A minor typo was found in Section 3.7, where the text reads "use apply" batch normalization, which appears to be an error.