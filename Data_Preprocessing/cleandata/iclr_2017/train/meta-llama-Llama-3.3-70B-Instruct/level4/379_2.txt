This paper introduces an innovative approach to handling dynamic computation graphs, which emerge when input data dynamically influences computation, as seen in LSTMs. The authors propose a strategy of "unrolling" operations at each step, enabling a novel form of input batching.
The concept presented is original, and the results demonstrate its potential. To enhance the clarity of the presentation, I suggest omitting portions of Section 3, "A combinator library for neural networks", as the technical details, although interesting, do not contribute to understanding the paper's core idea. The experimental results on the Stanford Sentiment Treebank are, in my opinion, not supportive of the paper's claim regarding speed and are somewhat confusing. Notably, the presented ensemble sets a new state-of-the-art on both subtasks, but this achievement is likely due to ensemble averaging rather than the framework or model, as suggested by the comparison of lines 4 and 2 in Table 2. I would appreciate a more transparent argument in this regard.
Following the authors' update on January 17th, which included revisions that significantly improved the argumentation, I have increased my rating to 8, reflecting the now clear and compelling presentation.