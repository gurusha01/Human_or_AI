This paper examines the ring-based AllReduce approach for multi-GPU data parallel training of deep neural networks.
Comments
1) The term "linear pipeline" may cause confusion among readers, as it is commonly referred to as the ring-based approach in AllReduce literature; the authors should adopt the standard terminology to facilitate easier understanding.
2) Although the cost analysis of ring-based AllReduce has been previously established in the literature, this paper applies the analysis to multi-GPU deep net training and demonstrates that scaling is independent of the number of GPUs.
3) It is worth noting that the ring-based AllReduce approach is already implemented in NVIDIA's NCCL library, despite the authors' claim that their implementation predates the NCCL implementation.
4) The technique of overlapping communication and computation has been previously utilized in systems such as TensorFlow and MXNet; the proposed schedule partially exploits this overlap by performing backpropagation of t-1 while executing reduction, but the dependency pattern can be further leveraged using a dependency scheduler, considering the forward pass of layer t depends on the update of parameters of layer t from the previous iteration.
5) As this paper focuses on analyzing AllReduce techniques, a more comprehensive analysis comparing tree-shaped reduction, ring-based approaches, and all-to-all approaches would be beneficial; notably, the discussion of the all-to-all approach is absent in the current paper.
In summary, this paper discusses existing AllReduce techniques for data parallel multi-GPU training of deep neural networks, presenting a cost analysis based on existing results; while the findings may not be surprising, as they follow from established AllReduce analyses, they may still be helpful to some readers, and the paper can be viewed as a baseline work. However, the analysis of AllReduce techniques could be further improved, as suggested in comment 5.