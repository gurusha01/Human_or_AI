This paper presents an intriguing approach, with a well-defined algorithm, a clearly identified problem, and robust results that appear both convincing and reasonable. 
Methods leveraging SMBO for hyperparameter optimization have historically faced challenges in effectively utilizing convergence during training, and this work offers a novel perspective on a non-SMBO alternative - although, as another reviewer noted, it bears significant resemblance to the previously published successive halving algorithm, which somewhat diminishes its originality. Nonetheless, I am eager to experiment with this method. I remain guardedly hopeful that this straightforward alternative to SMBO could mark the first significant breakthrough in model search for the discerning practitioner since the establishment of random search as a superior approach to grid search.