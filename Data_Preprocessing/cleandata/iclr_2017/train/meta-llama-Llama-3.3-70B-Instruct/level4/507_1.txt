This manuscript presents a novel dataset for assessing word representations, focusing on the task of outlier detection, also referred to as word intrusion, which involves identifying the word that does not belong in a set of semantically related words. Initially proposed by Camacho-Collados & Navigli in 2016 as a means to evaluate word representations, the primary contribution of this work lies in the introduction of a multilingual dataset spanning five languages, automatically generated from the Wikidata hierarchy. In this dataset, entities categorized under the same class are grouped into clusters, with outliers sampled at varying distances within the hierarchical structure. The authors also propose several heuristics aimed at filtering out less interesting clusters from the dataset.
The development of robust evaluation tools for word representations is a crucial endeavor. The newly introduced dataset has the potential to be a valuable addition to existing resources, although a definitive assessment is challenging based solely on the manuscript. A notable concern is the lack of in-depth discussion and comparison with existing methodologies, particularly beyond word similarity datasets. It would be enlightening to explore the advantages of this evaluation dataset in relation to established ones, such as word analogies. Furthermore, the proposed evaluation task bears a significant resemblance to entity typing, a connection that is not explored in the paper.
In general, contributing resources for the evaluation of word representations is of paramount importance to the research community. However, my stance on this submission is somewhat equivocal. I remain unconvinced about the clear benefits of the proposed dataset over existing resources. Additionally, it appears that existing tasks like entity typing may already capture similar aspects of word representations. Ultimately, considering the focus and content of the paper, it might be more appropriate to submit it to the Language Resources and Evaluation Conference (LREC) rather than the International Conference on Learning Representations (ICLR).