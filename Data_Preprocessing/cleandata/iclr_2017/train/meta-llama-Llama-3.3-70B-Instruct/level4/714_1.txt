This manuscript employs the approach introduced by Jonschkowski & Brock to acquire a low-dimensional state representation, which is embodied as the final layer of a neural network. The experimental framework utilizes this method to learn a one-dimensional state representation of a simulated robot's head position from artificially generated images.
The pursuit of learning state representations remains a vibrant and beneficial area of research, particularly in interactive domains like robotics. Nevertheless, the methodology presented appears to lack innovation beyond the work of Jonschkowski & Brock. The primary contribution of this paper lies in its experimental assessment, which is limited to a single task. This assessment evaluates the correlation between the learned state representation and the ideal state representation for the task, namely the robot's head position.
As the authors themselves acknowledge, the experimental component is preliminary and restricted, focusing on a straightforward task with a one-dimensional learned representation and a two-dimensional discrete action space. To render the experiments more convincing, comparisons with preceding methods, such as those proposed by Lange et al. in 2012, Watter et al. at NIPS 2015, and Finn et al. at ICRA 2016, which also learn state representations from raw images, are essential. Additionally, a comparison using Principal Component Analysis (PCA) on the images would be particularly useful, especially for simple tasks. Without such comparisons, assessing the efficacy of the method is not feasible.
Furthermore, as highlighted in the pre-review questions, the discussion of related work should be expanded to include an examination of other state representation learning methods, such as those presented by Watter et al. at NIPS 2015, Finn et al. at ICRA 2016, and van Hoof et al. at IROS 2016.
In conclusion, this paper is hindered by a lack of novelty and significance, as it implements an existing method and only demonstrates results on a single, simple task. The absence of comparative analyses renders the results difficult to interpret. The inclusion of more complex tasks and experimental comparisons would substantially enhance the paper. Moreover, this manuscript does not offer any novel contributions to the field of state representation learning for addressing challenges within this domain. One notable strength is that the paper is, in general, well-written and clear.