The paper proposes a novel approach to addressing the instability issue in generative adversarial networks by enabling the generator to anticipate the discriminator's evolving decision boundary over time, thereby preventing mode collapse. This well-written paper effectively motivates its solution to a significant open problem and presents robust experiments that substantiate its claims. The methodology is more refined than existing ad-hoc solutions commonly employed to stabilize GANs in practice. However, I have three primary concerns that temper my enthusiasm for the method's success, which, if addressed, would make this paper a strong candidate for acceptance.
1) I remain uncertain whether the proposed effect could be replicated by an alternative procedure: training the discriminator for an extended period of K steps during generator updates (equivalent to the unrolling steps in the current experiments), then reverting the K discriminator updates after the generator update and performing a single new update step instead. Although I briefly reviewed the response to Reviewer 2, which seems to suggest a similar setup was explored by halting gradient flow at a specific point, I believe this may not be entirely equivalent.
2) My attempt to reproduce the simple MNIST example using a fully connected network instead of an RNN generator was unsuccessful. Even with 30-40 steps of discriminator unrolling, the generator exhibited mode-seeking behavior or failed to train. This outcome could be due to an implementation error, the peculiarities of the RNN generator, or the absence of batch normalization. If the latter two factors are responsible, it would imply that the proposed approach relies on specific discriminator and generator architectures, which warrants discussion. The code for my reproduction attempt can be found at the provided link.