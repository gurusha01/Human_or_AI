The authors present a novel approach to visualizing deep neural network predictions, and their manuscript provides valuable insights into the problem. The application to medical images is a notable strength, as it moves beyond the typical examples using ImageNet. However, I have several questions and concerns that warrant further discussion.
1. The authors acknowledge the limitation of approximating the conditional probability of a feature $xi$ using its marginal distribution $p(xi)$, as noted in Section 3.1. They advocate for translation invariance, assuming the pixel's appearance is determined by its local neighborhood. Nevertheless, it is well-established that global context significantly influences pixel semantics, as demonstrated in works like "Objects in Contexts" and "ParseNet". This limitation does not necessarily undermine their approach but is a crucial consideration. I suggest the authors revisit equation (4) and empirically evaluate the impact of incorporating global context.
2. Figure 7 illustrates the distribution over the top 3 predictions before and after softmax normalization. As expected, softmax normalization transforms relatively uniform distributions into delta functions. I am unsure if there are additional implications or insights to be gleaned from this figure, and further clarification would be beneficial.
3. (Removed, as the original review had only three points, and the third point was labeled as "4. Finally")
 
4. In Section 4.1, the authors report that analyzing a single image with GoogleNet on a GPU requires 30 minutes. This computational expense seems excessive and may render the algorithm impractical for analyzing large datasets. I would appreciate an explanation for this high computational cost and potential strategies for mitigating it to make the algorithm more feasible for statistical analysis.