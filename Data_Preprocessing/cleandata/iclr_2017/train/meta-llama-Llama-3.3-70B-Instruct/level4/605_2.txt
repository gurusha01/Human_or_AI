The authors present a variational autoencoder-based approach for a particular type of tree-generating model, which appears to be a reasonable generative model for trees, although its motivation could be more thoroughly explained, especially considering the extension beyond context-free grammars, and a more detailed justification is needed if this tree specification has no prior references.
Given the specified tree model, it is intuitive to define a tree model encoder; however, the chosen posterior distribution does not align with the prior's structure, as it introduces coupling between distant variables in the tree, which undermines the rationale for this specific form and suggests that a more general network architecture could be a viable alternative for comparison.
The method employs sensible, differentiable functions for encoding the network, and the conducted tests are indicative, although the results show minimal distinction from the approaches being tested, raising questions about the most appropriate evaluation metric.
In terms of significance, while the work holds potential for future impact, it currently appears somewhat preliminary due to lacking motivation, an unmotivated choice of a tree-structured encoder, and insufficient comparisons with other methods. Moreover, the current motivation for the model is limited, and there is a notable absence of comparisons with more tractable models that do not rely on variational autoencoders.
Regarding originality, the work is novel, but the necessity of this originality is not clearly demonstrated at this point.
The clarity of the presentation is good, making the content accessible.
The experiments, while sensible in their design, are not extensive enough to be conclusive, indicating a need for further investigation to solidify the findings.