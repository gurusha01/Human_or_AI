This paper presents a novel approach to iteratively refine translation hypotheses, offering several advantages, including the ability to condition on both "left context" and "right context", which can lead to more efficient and accurate decoding. The authors' motivation is rooted in the fact that human translators and text generators often employ a refinement process when generating outputs.
The proposed idea is significant and currently underrepresented in neural network models, making this paper a valuable contribution to the field. However, despite its importance, the lack of in-depth analysis suggests that the paper is not yet ready for final publication. For instance, the authors could further contextualize their work by exploring connections to prior research in NLP, MT, and other areas of ML. Specifically, the model presented in Section 3 can be interpreted as a globally normalized, undirected translation model trained using a pseudo-likelihood objective, which bears similarities to traditional discriminative translation models that utilized "undirected" features. The decoding algorithm, in this case, resembles a standard greedy hill-climbing algorithm, albeit with an additional heuristic model for selecting the variable to update.
One of the primary criticisms is that the limitations of the model are not adequately discussed. For example, the proposed editing procedure is unable to remove or insert words from a translation, which is a significant limitation, as missing or extra words are common issues in baseline models. Furthermore, the standard objections to absolute positional models versus relative positional models are particularly relevant to this work and should be addressed.
Overall, this paper represents an initial step in an intriguing direction, but it requires more thorough analysis to demonstrate its value. A more comprehensive analysis may also lead to the development of important model variants, such as determining whether a global translation model or a post-editing model that fixes outputs with more complex operations is more ideal.
In terms of related work, the authors could benefit from situating their research within the broader context of existing literature. The concept of iterative refinement has been explored in other complex output spaces, such as the DRAW model and conditional adversarial network models. In NLP, stochastic hill-climbing approaches, like those used in parsing, and structured prediction cascades have been proposed. The use of an explicit error model is novel in the context of correction, but similar ideas can be found in discriminative word lexicon models and neural versions of the same.
Some specific suggestions for improvement include clarifying the representation of the target sentence in distributional space, specifying the training data for the model in Section 3, and justifying the use of a fixed-sized window for representing the target word in context. Additionally, the relationship between the training objective and pseudo-likelihood could be explored, and alternative decoding algorithms or analyses of the proposed decoding objective could be considered.
The model in Section 4 conditions on the true context of a position in the true target, the current target guess, and the source, but the rationale for this model is unclear, particularly since only two of these variables are available at test time. The replacement of yref with yg also requires further justification. By addressing these limitations and providing a more comprehensive analysis, the authors can strengthen their contribution and demonstrate the value of their proposed approach.