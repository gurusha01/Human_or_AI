This paper presents several methods for sampling visualizations from generative models, such as VAEs and GANs, with high-dimensional latent spaces. Notably, the authors emphasize the concentration of probability mass in high-dimensional Gaussian distributions within a thin hyper-shell of a specific radius, leading to the proposal of spherical interpolations, or great arcs, as an alternative to traditional linear interpolations. Additionally, they introduce visualization techniques for analogies and methods to reinforce structure in VAE latent spaces.
I struggle to provide a definitive recommendation for this paper. While I found it engaging and consider applying some of the proposed techniques, such as spherical interpolations and J-diagrams, in my own future work, it is clear that this paper deviates from the typical format of machine learning submissions. It neither introduces a novel model, training methodology, nor offers theoretical or empirical insights, and its scientific rigor and depth fall short of expectations for an ICLR submission. However, the paper provides more than just a collection of useful heuristics. Considering its potential impact, I believe it warrants a broader audience, although I question whether ICLR is the most suitable platform for it.