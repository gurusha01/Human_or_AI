This manuscript introduces an information-theoretic framework for unsupervised learning, grounded in the infomax principle. The primary objective of this principle is to maximize the mutual information between the input and output. The authors propose a two-stage algorithmic approach to learning within this framework. Initially, they utilize an asymptotic approximation of the mutual information to decompose the global objective into two sub-objectives, which can be solved in closed form. These solutions then serve as initial estimates for the global solution, which are subsequently refined using the gradient descent algorithm.
Although the underlying narrative and derivations presented in the paper appear to be theoretically sound, the clarity and presentation of the material could be enhanced. For instance, providing a high-level overview of the results and a concise explanation of the derivation strategy before delving into the step-by-step derivations would be beneficial. The detailed aspects of the derivations, which may obscure the core message of the results, could be relegated to later sections or even appended to a supplementary section.
Several clarifications are suggested for the authors' consideration:
1. On page 4, in the last paragraph, it is stated that maximizing I(X;R) will result in maximizing I(Y;R) and I(X,Y^U). While the former claim is supported by the equality in equation 2.20, the latter is related through a bound in equation 2.21. Given the potential gap between I(X;R) and I(X,Y^U), it is questionable whether maximizing the former indeed maximizes the latter.
2. In the paragraph preceding section 2.2.2, the use of dropout to prevent overfitting is likened to an attempt to reduce the rank of the weight matrix. However, no further explanation is provided to justify this assertion. Elaboration on this point would be beneficial.
3. At the end of page 9, the authors mention discussing the optimal solution of C for two specific cases. However, it appears that only local optima can be guaranteed due to the nonconvexity of constraint 2.80 (a quadratic equality). If achieving the global optimum is not feasible, the wording should be adjusted accordingly to reflect this limitation.