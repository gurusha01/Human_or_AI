This manuscript can be viewed as an implementation of the concept of learning to take advice, originally introduced by AI pioneer John McCarthy and later explored in depth by researchers such as Jack Mostow in the context of the card game Hearts. The core idea revolves around an agent receiving high-level guidance on problem-solving and subsequently deriving a low-level policy from it, mirroring the human learning process in complex tasks across various domains, such as driving, where instructors provide abstract advice (e.g., maintaining a safe distance from the preceding vehicle).
The proposed approach employs a sophisticated neural deep learning controller architecture, although the presentation of its details is somewhat obscure and convoluted. A more straightforward methodology might have enhanced clarity, particularly in the initial stages of explanation. However, the experimental evaluation is limited to a simplistic 2D maze environment, which raises questions about the scalability of the approach to more intricate tasks commonly addressed in contemporary deep reinforcement learning research, such as those involving Atari games or physics simulators.
Overall, the manuscript presents an intriguing concept, but the description of the solution is marred by complexity, and the experimental framework is inadequate due to its restriction to a less challenging 2D grid world domain, which falls short of the expectations typically associated with deep RL research.