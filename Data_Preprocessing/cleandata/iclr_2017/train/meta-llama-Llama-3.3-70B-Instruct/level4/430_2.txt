This paper presents an intriguing approach to jointly learning automatic segmentation of words into subwords and their corresponding acoustic models. The training process treats word segmentation as a hidden variable that is dependent on both the acoustic representations and other factors, but during decoding, it relies solely on maximum approximation. 
The authors demonstrate notable improvements over character-based results; however, a comparison with word segmentation methods that do not assume a dependency on acoustic representations is lacking. It's worth noting that using only text-based segmentation would simplify the task into two independent components, for which several publicly available tools could be utilized and cited. Some of these tools can leverage unigram probabilities of words to enhance their segmentation capabilities.
The observed improvements seem to stem from the utilization of longer acoustic units, which impose stronger acoustic constraints and potentially reduce search confusion, hinting at the effectiveness of full-word models. Furthermore, having fewer tokens increases their probability due to reduced multiplication of probabilities. An interesting thought experiment would be to consider an extreme scenario where all possible segmentations (including mixtures of word fragments, characters, and full words) are feasible. In such a case, would the proposed model still opt for word fragments, especially given that the WSJ task involves a closed vocabulary? 
It would be valuable to demonstrate that the subword model can outperform a full-word model (which does not require segmentation). The model estimates p(z_t|x,z), and exploring this aspect further could provide deeper insights into the model's capabilities and limitations.