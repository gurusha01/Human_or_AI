This manuscript presents a theoretical framework for guaranteeing the convergence of training error, with a broadly applicable result that encompasses a wide range of neural network models. The core concept involves approximating the training loss using its linear approximation, leveraging its convexity to draw upon established results from online learning literature.
The paper demonstrates novelty in utilizing Taylor approximation, significantly simplifying the analysis of model behavior. However, two primary concerns arise regarding the main result, Theorem 2.
1. The convergence of the Taylor optimum is uncertain. Although the authors acknowledge the path-dependent nature of the upper bound, the proof in Appendix 3 attempting to establish convergence contains errors. Specifically, Lemma 2 only shows that the difference between successive Taylor optima approaches zero, which is a weaker condition than being a Cauchy sequence and insufficient to guarantee convergence.
2. The left-hand side of Equation (3), denoted as L3, does not accurately represent the training error. An upper bound on this average error does not ensure convergence of the training error. For instance, considering gradient descent where each minibatch is the entire training set, convergence of the training error requires lim{n -> \infty} l(f{w^n}(x_0^n), y^n). The convergence of L3 is necessary but not sufficient to imply training error convergence.
A minor concern with Theorem 2 is that achieving the O(1/\sqrt{n}) rate necessitates selecting a specific learning rate, as larger or smaller rates (on the order of n) lead to significantly worse regret. However, the experimental learning rates in the paper do not align with the theorem's requirements.
In summary, the paper has a strong motivation and exhibits novelty, with potential for development into a quality manuscript. Nevertheless, due to the aforementioned issues, including a flawed proof, the paper is not yet ready for publication.