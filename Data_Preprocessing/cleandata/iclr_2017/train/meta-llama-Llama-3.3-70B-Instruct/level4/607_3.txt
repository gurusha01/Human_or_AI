This paper proposes a TEM-HAM architecture for video captioning, which utilizes a two-level attention mechanism by having the HAM module attend to the outputs of the TEM module during description generation. The model's performance is evaluated on the Charades and MSVD datasets.
1. Quality/Clarity: Unfortunately, the paper's writing is subpar and challenging to comprehend. Upon closer examination, the TEM module in Section 3.1 appears to be a straightforward attention-based frame encoder, similar to those presented by Bahdanau et al. (2015) or Xu et al. (2015). The decoder in Section 3.3 is a standard LSTM with log likelihood. However, the HAM module in Section 3.2, which is the novel component, is not well-described. It seems to be an attention-based LSTM where the attention is conditioned on the decoder state and the TEM LSTM outputs. Several minor issues detract from the paper's clarity, including notational inconsistencies in the use of bold font in equations and text, as well as unclear explanations of certain variables, such as fm. The authors' description of fm is confusing, and it is only later revealed in Section 3.3 that f_m refers to a standard LSTM. The paper's sloppiness is further evident in Table 1, where the number of significant digits is inconsistent, and in Table 2, where the horizontal line's semantics are not explained.
2. Experimental Results: The ablation study yields mixed results when incorporating TEM and HAM into the model. Focusing on the METEOR metric, which has been shown to have the highest correlation with human evaluations in the COCO paper, the addition of TEM+HAM improves the model's performance from 31.20 to 31.70. However, the significance of this improvement is unclear, particularly given the small test set of 670 videos. Furthermore, the METEOR score reported by Pan et al. (2016a) is higher (33.10 vs. 31.80), but this discrepancy is not addressed in the text. This is surprising, as the authors claim to have achieved state-of-the-art results.
3. Originality/Significance: The paper introduces an additional layer of attention over a standard sequence-to-sequence setup, which is argued to alleviate the burden on the LSTM's memory. While this concept is moderately novel, the experimental results do not convincingly demonstrate its value. If the paper had simplified the standard model instead of increasing its complexity, it would be more likely to be viewed favorably.
Minor: In response to the authors' comment regarding the confusion about Figure 1, a diagram has been created to clarify the issue and facilitate a more detailed discussion.