This study investigates neural models for sentence summarization, employing a read-again attention model and a copy mechanism that enables direct copying of word representations from source sentences. The experimental results show that the model achieves superior performance on the DUC dataset. However, the paper is poorly written, with several confusing points, unsubstantiated claims, and incomplete experimental results.
Detailed comments:
- The read-again attention mechanism lacks a clear explanation of its advantages over traditional attention models. It is unclear how reading the same sentences multiple times would impact performance, and a comparison with stacked LSTM models having the same number of parameters is absent. Furthermore, the experiment section does not include model ablation studies.
- The necessity of using two input sentences is unclear, particularly since the Gigaword dataset is a source-to-compression dataset that typically involves single sentences. A comparison between the model's performance with single-sentence and two-sentence inputs is needed.
- The copy mechanism raises concerns, such as how it handles multiple instances of the same word in the source sentences. According to equation (5), only one vector is copied to the decoder, which may lead to issues. In contrast, hard copy mechanisms do not have this problem. Moreover, the experiment section lacks a comparison between the hard copy mechanism and the proposed vector copy mechanism.
- The discussion on vocabulary size seems tangential to the main topic and lacks evidence to support its relevance to the vector copy mechanism. Without such evidence, this section appears trivial and unnecessary.
- The experimental evaluation is inconsistent, as the model is compared to state-of-the-art models on the DUC dataset but only to weaker baseline models (ABS Rush et al. (2015) and GRU) on the Gigaword dataset. It is misleading to claim that the model achieves state-of-the-art performance in summarization without more comprehensive comparisons.
Additionally, there are typographical errors, including "Tab. 1." which should be "Table 1.", and "Fig. 3.1.2.?" which appears to be a formatting issue.