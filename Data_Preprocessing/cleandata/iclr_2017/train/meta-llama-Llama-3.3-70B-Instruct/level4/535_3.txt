1) Summary
The authors present a novel video captioning approach that leverages a 3D convolutional neural network (C3D) encoder in conjunction with a long short-term memory (LSTM) decoder. A key aspect of this work is the exploration of attention mechanisms that operate at both the spatio-temporal level and the layer level, facilitating feature abstraction.
2) Contributions
+ The implementation of an attention mechanism is well-justified and effectively handles the varying dimensions of C3D feature maps, including space, time, and features.
+ The paper provides compelling quantitative and qualitative results across three demanding datasets (Youtube2Text, M-VAD, MSR-VTT), clearly demonstrating the advantages of the proposed attention mechanisms.
+ A noteworthy comparison between soft and hard attention mechanisms reveals a slight performance edge for the softer attention mechanism, which is also simpler, in this specific context.
3) Suggestions for improvement
Hypercolumns comparison:
As previously discussed during the pre-review inquiry, conducting a comparison with hypercolumns would be a valuable addition, allowing for a more comprehensive understanding of the proposed model's efficacy in relation to existing methodologies.