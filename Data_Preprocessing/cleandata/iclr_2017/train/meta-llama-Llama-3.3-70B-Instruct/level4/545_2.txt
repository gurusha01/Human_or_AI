The authors present a novel approach to enhance an SVM variant with numerous virtual instances, yielding promising initial results. The paper is engaging, with a well-designed methodology, but contains partially unsubstantiated and potentially misleading assertions.
Strengths:
- The methodology is thoughtful, with sensible design choices
- The approach may be useful for smaller datasets (n < 10,000) with significant statistical structure
- The connections to sum-product literature are notable
Weaknesses:
- The claims regarding scalability are unclear
- The paper fails to provide a comprehensive narrative about the properties and applicability of the proposed method
- The experiments are preliminary
The scalability claims are particularly ambiguous. The paper repeatedly highlights the lack of scalability as a drawback for convnets, but it appears that the proposed CKM is less scalable than a standard SVM. SVMs often handle fewer training instances than deep neural networks, and the scalability advantages seem limited to training sets with fewer than 10,000 instances. Furthermore, the idea of performing 10^6 operations to create virtual instances for 10^4 training points and 100 test points is daunting. The scalability claims need to be expanded and clarified, particularly considering that scalability is a significant drawback of using SVMs on modern datasets.
The paper suffers from a lack of clarity and presentation issues. Critical details are often missing, and broad claims, such as suggesting that CKMs could eclipse convolutional neural networks, are misleading. Convnets are a type of multilayer perceptron, and they have different relative advantages. The paper would benefit from providing more precise information and removing unsubstantiated claims.
The potential robustness of CKMs to adversarial examples is an interesting aspect, but it would be useful to compare this to other approaches that make deep nets more robust. The idea of using virtual instances with deep networks is also worth exploring. A significant advantage of SVMs is that they can achieve good performance with minimal human intervention, but CKMs seem to require extensive intervention in terms of architecture and virtual instance creation.
The experiments provide some insights but are limited. A more comprehensive evaluation of the proposed method's properties and limitations is necessary, including a greater range of datasets and training and test sizes. Comparisons to other methods, such as SVMs with Gaussian kernels or convnet features, would also be beneficial.
The methodology is original and worthy of exploration, but its significance is not demonstrated. The paper's quality is high in terms of thoughtful methods and insights, but it suffers from broad claims and a lack of precise detail. In summary, the paper requires more specific details, full disclosure of the method's applicability, and precise advantages and limitations. Code would be helpful for reproducibility.