The authors propose a straightforward optimization approach that involves incorporating gradient noise according to a predefined schedule and evaluate its effectiveness on several recently introduced neural networks designed for simulating computer logic, including end-to-end memory networks, neural programmers, and neural random access machines.
Given that optimization for these networks has received relatively less attention compared to more conventional architectures, a dedicated study on this class of models is timely and valuable. The results consistently demonstrate improved optimization outcomes when noise is added to the training process.
However, a limitation of the paper is the lack of clarity on whether the proposed optimization strategy enables the learning of genuinely effective models or merely outperforms models that do not utilize noise. A comparison with existing literature results would be beneficial to assess the strategy's efficacy.
For instance, in the MNIST experiments presented in Section 4.1, the optimization procedure achieves an average accuracy of approximately 92% in the most favorable scenario, which falls short of demonstrating a meaningful problem representation (as a linear model could potentially attain similar accuracy). Although the architecture is intentionally designed to be challenging to optimize (with 20 layers of 50 hidden units), it would be more insightful to explore a scenario where increased depth actually enhances problem-solving capabilities.