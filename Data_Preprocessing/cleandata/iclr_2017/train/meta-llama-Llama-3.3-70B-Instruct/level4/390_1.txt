This paper is well-structured and presents an intriguing concept, making for an engaging read. 
Initially, I found the formalism to be somewhat challenging to comprehend without the aid of concrete examples, particularly in regards to Figure 1A, where the specific roles of components such as the controller, control, optimizer, and the objective of optimization were not immediately clear. The inclusion of algorithmic details, potentially in the form of boxes, especially in the context of the experiments, would have enhanced clarity. Additionally, providing an overview of existing models that align with the proposed conceptual framework could further facilitate understanding.
The work by Snoek, Larochelle, and Adams on Practical Bayesian Optimization of Machine Learning Algorithms, which suggests optimizing based on expected improvement per second to balance computational cost and performance, could be an interesting case study within the context of the presented framework.
The experimental results are clearly presented and effectively demonstrate the utility of the metacontroller. It would be interesting to explore the outcomes of incorporating a larger number of metaexperts in future studies.