The authors propose a multimodal dataset modeling approach utilizing a VAE with a dedicated inference network for each possible combination of missing and present modalities, which is then evaluated on the MNIST and CelebA datasets.
However, the use of MNIST as a multimodal dataset is questionable, as it is treated as such by designating labels as an additional modality to be modeled via a variational autoencoder, a choice that seems counterintuitive.
Furthermore, since the modalities are always present and never actually missing, the practical applicability of the proposed method remains uncertain.
Additionally, the reported differences in log-likelihoods among various models are negligible and may be attributed to random fluctuations rather than meaningful distinctions.
The second experimental setup presents log-likelihood values for models that were not optimized for log-likelihood, making it unclear what insights can be gleaned from this comparison, as it does not provide a straightforward basis for evaluation.