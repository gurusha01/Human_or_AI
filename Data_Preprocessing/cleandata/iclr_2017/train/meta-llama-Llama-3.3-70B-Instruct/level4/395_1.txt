The authors introduce a novel software package for probabilistic programming, leveraging recent advancements in deep learning tools. This package exhibits significant potential to revolutionize the field of probabilistic modeling by enabling rapid prototyping and iteration of ideas. The incorporation of composability principles and the extension of inference to Hamiltonian Monte Carlo (HMC), beyond traditional variational inference (VI), further enhance the package's appeal.
However, the practicality of any probabilistic programming language (PPL) is contingent upon its ability to tackle real-world use cases, which was not adequately demonstrated in the submission. Although numerous code snippets are provided, most remain unevaluated. Notably, the Dirichlet process mixture model example (Figure 12) and the GAN example (Figure 7) require empirical validation to ascertain the efficacy of the proposed black-box inference tools. Similarly, it is essential to demonstrate the convergence of the GAN example when optimized with real data. To establish the package's practicality, empirical demonstrations of these examples are necessary. Currently, only a variational autoencoder (VAE) with various inference techniques has been evaluated, which can be readily implemented using existing TensorFlow (TF) tools.
Presentation-wise, several improvements can be made:
* Enhancing the paper's presentation by incorporating more signaling to prepare readers for upcoming explanations would be beneficial. For instance, on page 5, the introduction of qbeta and qz without prior explanation could be improved by mentioning that an example will follow.
* The authors should consider explaining the implementation of layers and the handling of KL divergence in VI within the preface.
* Clarifying the optimized values and the changes that occur during inference (prior to section 4.4) would be helpful, as this was unclear for most of the paper.
Regarding experiments:
* The omission of runtime reporting in Table 1 is notable.
* The authors encountered "difficulties around convergence" with analytical entropies; however, it is unclear whether the provided toolbox includes diagnostic tools for inference issues.
* The results of HMC in the experiment at the bottom of page 8 are not fully reported, with only runtime provided.
* The ease of implementing inference (e.g., HMC) without full control over the computational graph structure and sampler is unclear.
* A comparative table evaluating the performance (runtime, predictive log likelihood, etc.) of various inference tools on multiple models would be highly insightful.
* The choice of benchmarks for the Model Zoo is uncertain, given the lack of standardized benchmarks in probabilistic modeling. The authors should specify the datasets to be used for comparing models, such as the Dirichlet process mixture model.
Minor comments include:
* In Table 1, comparing to Li & Turner with alpha=0.5 (equivalent to Hellinger distance) would be more appropriate, as they concluded this value performs best.
* The handling of discrete distributions (e.g., Figure 5) is unclear.
* The variable x_real is not defined in Figure 7.
* Highlighting M in Figure 8 would be beneficial.
* A comma instead of a period is needed after "rized), In" on page 8.
In conclusion, while the software developments presented are exciting and push towards practical and accessible "inference for all," the submission's current form warrants a score of 5. The authors must address the aforementioned concerns to demonstrate the package's practicality and establish its potential to transform the field of probabilistic modeling.