The paper presents a revised DAE objective function, which aims to minimize the distance between the mapped representation of the corrupted input and the representation of the original input. This approach combines elements of denoising autoencoders (DAE) and contractive autoencoders (CAE), although a comparison to the latter is notably absent. As a result, the contribution appears to be relatively incremental. Similar to CAE, the proposed method requires additional external constraints, such as tied weights or batch normalization, to prevent representation collapse. While the authors have addressed this issue in an added paragraph, a more rigorous formal analysis is warranted. It is concerning that these external constraints are not inherently derived from the authors' information-theoretic framework, which raises questions about the validity and completeness of the proposed formal motivation. Furthermore, the information-theoretic interpretation of the extra regularization, including the role of the lambda parameter, remains unclear.
The experimental evaluation of the approach is limited and yields underwhelming results. The empirical support is based on a small number of experiments using synthetic and small-scale data. Notably, the modified DAE's performance on MNIST is consistently outperformed by the original DAE, except for a single specific setting of lambda, where the difference is barely statistically significant, given the error bars. This casts doubt on the significance of the reported improvement, highlighting the need for more comprehensive and convincing empirical evidence.