This paper presents a novel approach to finding an optimal decoder for binary data using a min-max decoder on the binary hypercube, subject to a linear constraint on the correlation between the encoder and the data. The proposed method ultimately yields an optimal decoder expressed as the logistic of the Lagrangian W multiplied by the encoding e. 
Given the weights of the 'min-max' decoder W, the paper determines the best encoding for the considered data distribution by minimizing the error as a function of the encoding. The optimization is then alternated between the encoding and the min-max decoding, initiated with random weights W.
In terms of clarity, the paper could benefit from a clearer distinction between the real data (x in section 3) and the worst-case data simulated by the model (x in section 2), which would enhance the overall readability.
Regarding significance, the paper is generally well-received, although some concerns arise regarding the nature of the optimum achieved through the alternating optimization process. The implementation of a single-layer network and the use of correlation constraints, while convenient for derivation, raise questions about the strength of the linear relation between the encoding and the data as a modeling constraint. This constraint may not be substantially different from what Principal Component Analysis (PCA) would achieve.
Several questions and suggestions arise from this:
- How does the performance of PCA compare on these tasks, potentially using a simple sign function for decoding, which relates to one-bit compressive sensing?
- What are the outcomes if the algorithm is initialized with PCA weights or weighted PCA weights for W?
- Have experiments been conducted on more complex datasets, such as CIFAR, to further assess the method's efficacy?