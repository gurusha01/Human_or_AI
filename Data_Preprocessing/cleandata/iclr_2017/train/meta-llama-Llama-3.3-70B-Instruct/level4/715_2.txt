This manuscript presents two approaches to pruning deep neural networks, allowing for the removal of entire feature maps and kernel connections with minimal impact on classification accuracy. 
However, several concerns arise:
1)	The proposed methodology appears somewhat simplistic, as the pruning masks are primarily determined through straightforward random sampling, which may limit the novelty and scalability of the approach.
2)	The experimental results primarily focus on classification rates and ideal complexity, whereas a paper centered on enhancing computational efficiency should also provide insights into practical time consumption. It is well-established that reducing the number of operations does not necessarily lead to decreased computational time on highly parallel platforms, such as GPUs.
3)	Improving computational efficiency is more crucial for large-scale models, such as those used in ImageNet classification, than for smaller models like those used in MNIST or CIFAR. Regrettably, results for large-scale networks are absent from the manuscript.
4)	Regarding the logical validity of the proposed method, it is essential to consider whether training a reduced-size network from scratch, without transferring knowledge from a pre-trained larger network, could yield comparable accuracy. If so, this would suggest that the hyperparameters of the original network are suboptimal, and experimental results are necessary to justify the necessity of feature map pruning.
It is worth noting that a smaller network may indeed be more generalizable than a larger one.
----------------------------------------------
Comments on the authors' response:
I appreciate the authors' detailed response to my comments.
1)	I maintain my stance that the proposed methods lack sophistication.
2)	The inclusion of GPU implementation results is a positive development. However, it is crucial to assess whether the convolution implementation is efficient compared to existing toolboxes like Torch, Caffe, or TensorFlow.
3)	While experiments on Cifar-100 are more informative than those on Cifar-10, they still fall short of demonstrating large-scale applicability, where speedup is more critical. ImageNet and Places datasets serve as examples of large-scale datasets that would be more relevant.
4)	The authors failed to address the critical question regarding the validity of the proposed methods, which is essential to establish the merit of their approach.