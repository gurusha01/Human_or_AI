The paper introduces the Gated Multimodal Unit, a fundamental component for connectionist models designed to process multiple modalities.
Referring to Figure 2, in the bimodal scenario, the model generates weighted activation through the gains of gating units. It would be beneficial to clarify how this weighting is maintained in the multi-modal case. Specifically, the equation for h in Section 3.1 should be elaborated upon for the multi-modal scenario. Additionally, the choice of tanh nonlinearity over alternatives like RELU warrants explanation; was this selection based on experimental optimization?
A discussion on handling missing data when one or more modalities are unavailable during testing would be valuable. It is unclear whether the current model can adapt to fewer modalities. The synthetic example suggests this might be feasible, and including relevant numbers in Table 2 could provide insight.
The synthetic experiment should include a comparison with a fully-connected MLP model of similar complexity, featuring at least two hidden units (to match the GMU's two units per modality) followed by logistic regression. This comparison would help assess the capability to draw decision boundaries.
A more comprehensive discussion on related work, particularly concerning mixture of experts models and multiplicative RNN models [1], would be beneficial. The conceptual similarity between these models and the proposed Gated Multimodal Unit is noteworthy. Furthermore, the gating unit in LSTM could potentially serve a similar role when multiple modalities are combined in the input.
Overall, the paper presents an interesting concept, and the associated dataset (to be released) is also of interest.
Minor comments and typos:
- Section 3.3: The text should read "layers and an MLP" instead of "layers and a MLP".
- The review is submitted with apologies for the unacceptable delay.
[1] Multiplicative LSTM for sequence modelling by B Krause, L Lu, I Murray, S Renals.