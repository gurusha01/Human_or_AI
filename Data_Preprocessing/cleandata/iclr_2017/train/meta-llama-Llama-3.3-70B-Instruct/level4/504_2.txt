This paper presents a novel approach to learning vision features as intermediate rewards for guiding robot training in real-world environments. Given the limited number of human demonstration sequences, the authors first fragment these sequences to ensure feature invariance across sequences, then cluster and identify the most discriminative features on these fragments to construct the reward function, leveraging features from pre-trained deep models.
The concept appears straightforward and effective in selecting suitable reward functions. Figure 6 provides a compelling comparison, although the inclusion of error bars would enhance its clarity. However, the baselines, particularly those related to vision, could be stronger. For instance, the random reward in Table 2, which simply outputs true or false, seems somewhat arbitrary and may not constitute a robust baseline, despite its surprisingly decent performance. A more robust baseline might involve using random or simpler image feature extraction methods, such as binning features and selecting the most frequent ones, which could be less discriminative than the proposed features. It would be interesting to explore whether a simpler vision-based approach could yield a similarly performing reward function, potentially rendering the intricate steps of segmentation and clustering unnecessary.