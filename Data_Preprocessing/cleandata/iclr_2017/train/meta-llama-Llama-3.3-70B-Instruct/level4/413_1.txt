This manuscript proposes an approach to enhance the efficiency of deep networks processing sequential correlated inputs by selectively computing changes between consecutive inputs. The paper is well-structured and the methodology is ingenious, with a notable connection to spiking networks. Although the concept is intriguing, its advantages remain largely theoretical, and implementation on current hardware may not be feasible. Furthermore, I hypothesize that incorporating a sparse slowness penalty into the training process of deep networks could yield substantially greater computational reductions, potentially overshadowing the benefits of the proposed method.