UPDATE:
Upon reviewing the arxiv version of the paper, I found it to be more comprehensive and rigorous, with Figure 3 providing valuable insights. However, my assessment of the conference submission remains unchanged. To effectively convey the core message, I recommend focusing on the ParMAC algorithm and removing or appending non-essential extensions and theoretical remarks to an appendix. Additionally, an extra page should be allocated to thoroughly explain the algorithm. It is also crucial to clearly acknowledge the relationship between the arxiv paper and the submission, highlighting that the latter is a condensed version.
ORIGINAL REVIEW:
The submission introduces ParMAC, a distributed variant of the Method of Auxiliary Coordinates (MAC). 
Related Work: The section on convex ERM and methods would benefit from citing general communication-efficient frameworks, such as COCOA (Ma et al.) and AIDE (Reddi et al.), as they align closely with the practical objectives of this paper. Some cited works seem less relevant and could be omitted.
Section 2, which explains MAC, is well-written, but the discussion on MAC and EM appears unnecessary. 
Section 3 is less clear, with notation being introduced at various points, making it difficult to follow. A brief summary or paragraph on notation in the introduction would be helpful. The paragraph discussing data distribution assumes prior knowledge, which is not provided until later. The term "submodel" is unclear, and a more precise example referencing equations (1) and (2) would be beneficial. As understood, there are P independent sets of submodels that traverse machines in a circular fashion, but their initialization and the algorithm's single output are unclear. This lack of clarity is a significant issue.
The later paragraphs on extensions, model for speedup, convergence, and topologies are unclear. It is uncertain whether these contributions are novel, as the authors refer to other works for details. If novel, the explanations are insufficient, particularly the speedup part, which contains undefined quantities like T(P). If not novel, the explanations do not provide enough insight compared to a condensed version. The claim of recovering original convergence guarantees seems strong but is not adequately justified. The topologies section contains vague statements, including the claim of achieving "true SGD" without explanation.
The experimental section suggests ParMAC is interesting for binary autoencoders but does not provide conclusive evidence for other models. ParMAC is only compared to itself, focusing on scaling properties, without consideration of alternative methods.
The conclusion contains overly strong or misleading statements. The claim of analyzing parallel speedup and convergence is unsubstantiated, and the statement that the convergence properties of MAC remain "essentially unaltered" in ParMAC is unsupported.
In summary, while ParMAC appears relevant for binary autoencoders, the presentation lacks clarity, making it impossible to recreate the algorithm used in experiments. The paper also contains several questionable claims, which detract from its overall validity.