This paper proposes an initial approach to addressing the challenging problem of "learning from a limited number of demonstrations". The authors contribute three key elements to this effort:
1. An unsupervised video segmentation method to identify intermediate steps in a process.
2. A reward function definition based on feature selection for each sub-task.
The strengths of the paper include:
+ It represents a pioneering attempt to tackle a highly complex problem, where a robot learns real-world tasks from a minimal number of visual demonstrations without requiring additional retraining.
+ The methodology is well-motivated, leveraging priors learned from object classification tasks (via deep network features) to address the issue of limited training examples.
+ As illustrated in Figure 3, the reward functions demonstrate interpretability and correlation with transitions between sub-tasks.
+ The division of videos into sub-tasks enables a video demonstration-based method to achieve performance comparable to a method requiring full instrumentation for complex real-world tasks, such as door opening.
However, several limitations are noted:
1. While unsupervised video segmentation serves as a good starting point for identifying sub-tasks, it is essential to reference and compare with existing works in this domain. Notably, video shot detection and shot segmentation techniques, which identify abrupt changes in videos to break them into visually diverse shots, could be augmented with CNN features. A survey by Yuan et al. (Trans. on Circuits and Systems for Video Tech, 2007) provides a comprehensive overview of relevant papers.
2. The authors' claim that identifying commonalities across demonstrations was unnecessary restricts the problem's scope and imposes specific constraints on the demonstrations. Previous literature, such as video co-segmentation (e.g., Tang et al., ECCV'14), utilizes these commonalities for unsupervised video segmentation.
3. The proposed unsupervised temporal video segmentation approach is only compared to a simple random baseline for a limited number of sample videos. Given the extensive literature in this domain, it is challenging to assess the novelty and significance of the proposed approach based on these experiments.
4. The authors hypothesize that "sparse independent features exist that can discriminate a wide range of unseen inputs" and implement this intuition through their feature selection strategy. However, the validity of this hypothesis is not adequately demonstrated experimentally. For instance, a comparison to a simple linear classifier for sub-tasks would have been informative.
In summary, the paper presents a straightforward approach based on the idea that recognizing sub-goals in an unsupervised manner can facilitate learning from few visual demonstrations. Although this is a well-motivated first step towards a challenging task, the methods and claims presented in the paper require more rigorous analysis and comparison to robust baselines.