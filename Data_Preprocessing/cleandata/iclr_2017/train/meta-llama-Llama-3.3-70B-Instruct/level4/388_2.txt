This paper introduces a novel deep neural network architecture designed for question answering tasks on the SQuAD dataset, comprising a coattention encoder and a dynamic pointer decoder. The encoder generates parallel attention over both the question and the document, enabling the learning of co-dependent representations. The decoder iteratively predicts the start and end tokens of the answer, aiming to reduce errors by escaping local maxima through multiple iterations. At the time of writing, the proposed model achieved state-of-the-art results on the SQuAD dataset. The paper also provides analyses of results, including performance across various question types, document, question, and answer lengths, as well as ablation studies such as limiting the decoder to a single iteration.
The strengths of the paper include its well-motivated approach, focusing on co-attention to the document and question, and the iterative answer production. The novel model architecture and reasonable design choices are also notable. Furthermore, the experiments demonstrate significant outperformance of existing models on the SQuAD dataset. The analyses and ablation studies offer valuable insights into the modeling design choices.
However, several areas require further clarification or investigation. Firstly, to understand the impact of additional iterations in the decoder, it would be beneficial to report the mean F1 score for questions converging at each iteration, along with the number of questions converging at that iteration. Secondly, the frequency of instances like Question 3 in Figure 5, where the model fails to decide between local maxima despite multiple iterations, should be reported. Thirdly, comparing the performance with and without attention modeling in the encoder would help estimate its contribution. Fourthly, analyzing the model's performance on questions requiring different types of reasoning, as outlined in Table 3 of the SQuAD paper, would highlight the model's strengths and weaknesses in reasoning. Fifthly, there seems to be a discrepancy in the ablation study comparing the proposed model to Wang and Jiang (2016), specifically regarding the attention mechanism; clarification is needed to ensure a proper comparison. Lastly, a minor error in Section 2.1, where "n" and "m" are swapped in explaining the Document and Question encoding matrix, should be corrected.
In summary, the paper presents an innovative and effective model for question answering on the SQuAD dataset, outperforming existing models. However, additional analyses and an ablation study are suggested to deepen the understanding of the model's functioning and its potential improvements.