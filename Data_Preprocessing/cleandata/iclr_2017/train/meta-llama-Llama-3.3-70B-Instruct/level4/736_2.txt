I appreciate the authors' response and would like to reiterate my concerns. The proposed method still requires more comprehensive experimental validation, particularly in scenarios where training from scratch is necessary, rather than relying solely on pre-trained ImageNet models. A thorough comparison with state-of-the-art methods using toy datasets, as seen in studies like Bousmalis et al. (2016) and Ganin & Lempitsky (2015), would be invaluable. This omission prevents me from upgrading my assessment.
The paper introduces a novel approach by adapting batch normalization for domain adaptation purposes. It demonstrates that batch-specific means and variances can serve as domain discriminators, leading to the concept of adapting to the target domain by substituting source dataset statistics with those from the target dataset.
In my assessment, this work is better suited for a workshop rather than the main conference due to several key concerns:
1. The central idea, although straightforward, is somewhat obscured by the paper's presentation, which could have been more concise and direct, such as highlighting the main contribution in the abstract.
2. The use of a more powerful base CNN may significantly contribute to the reported improvements, raising the need for a comparative analysis against other methods to validate the effectiveness of the proposed technique. Such a comparison should ideally include scenarios where models are trained from scratch, not just leveraging pre-trained networks, to provide a comprehensive evaluation.