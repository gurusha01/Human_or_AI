This manuscript is well-structured and effectively conveys its central idea, making it a pleasure to read.
The key aspects of the paper, along with my concerns, can be encapsulated as follows:
1. The authors discuss how synchronous algorithms are hindered by struggling nodes, which can cause delays. However, in my experience with cloud services like Amazon EC2, such issues are rare, whereas they can occur on shared university clusters when nodes are heavily utilized by multiple users. It is possible that dedicating nodes to specific jobs could mitigate this concern, but I am uncertain about the cluster setup used to generate Figures 3 and 4. Additionally, I wonder about the number of experiments conducted, as my own experience suggests that most iterations yield timely gradients from all nodes, with only occasional delays. The increasing curve shape implies potential communication implementation issues, possibly due to serialization; using MPI_Reduce might yield faster results, even with waiting for the slowest node.
2. Asynchronous algorithms reduce waiting times but may converge slower and require special care to avoid divergence due to stale gradients. While they offer guarantees for convex functions, their performance with non-convex deep neural networks (DNNs) is less clear.
3. The proposed method involves taking gradients from the first "N" workers out of "N+b" available workers. My concern lies in the potential bottleneck of the parameter server, which could become a limiting factor. However, for smaller node numbers and deep DNNs, communication overhead might not exceed 30% of the runtime.
My primary concern revolves around the experimental design. Since different batch sizes typically require adjusted learning rates, I question how the learning rates and other parameters were tuned for figures like Figure 5. The provided formulas in (A2) could introduce bias, and tuning parameters like "\gamma, \beta" for each "N" might offer a more representative outcome. It would be beneficial to conduct experiments multiple times and report average, best, and worst-case behaviors to rule out coincidental results.