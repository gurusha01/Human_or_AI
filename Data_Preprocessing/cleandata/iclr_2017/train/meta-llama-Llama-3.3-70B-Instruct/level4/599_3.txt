The authors present a recurrent neural network (RNN) approach for classifying time-series data with missing values, leveraging potential information contained within these gaps. This method employs a straightforward linear imputation technique for missing values, utilizing learnable parameters, and incorporates time-intervals between missing values to adjust the downstream RNN computations. The authors provide evidence that their approach surpasses plausible baselines on real-world datasets of modest size. The paper's clarity is notable.
In my opinion, the authors' strategy for addressing missing values appears suitable for their target application domain, where data scarcity necessitates the use of compact models. However, I remain uncertain whether the advantages of this method would translate to larger datasets, where more robust, less specialized multi-layer RNN architectures are viable alternatives.