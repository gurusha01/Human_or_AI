The authors have done a commendable job of incorporating additional references and conducting baseline experiments, which has enhanced the overall quality of the paper.
This paper proposes a hybrid architecture for predicting time series, focusing on the slope and duration of linear trends. The architecture combines a 1D convnet for local time series analysis and an LSTM for analyzing time series of trend descriptors. The features from the convnet and LSTM are merged into an MLP to predict either the slope or the duration of the next trend in a 1D time series. The methodology is evaluated on three relatively small datasets.
Summary:
Although the paper is well-written and presents an intriguing approach, it suffers from several methodological flaws that require additional experiments to rectify.
Pros:
The concept of extracting upward or downward trends from time series is noteworthy, although ideally, these trends should be learned rather than relying on ad-hoc techniques, particularly in a submission to a prestigious conference like ICLR.
Methodology:
* In Section 3, the prediction of "either the duration or the slope" of the trend is unclear. Predictions are only valid if both slope and duration are predicted jointly, and the losses should be combined during training.
* Throughout the paper, predicting the slope and duration of trends jointly is essential. Predicting a time series without specifying the prediction horizon is meaningless, as the interpretation of the prediction varies significantly with the duration of the trends. Predictions at specific horizons are necessary.
* In general, time series prediction for applications like trading and load forecasting is incomplete without making decisions based on the predictions. A trading strategy would differ substantially for short-term, noisy oscillations versus long-term, stable trends. An evaluation in terms of trading profit/loss should be added for each baseline, including naive baselines.
* A crucial baseline is missing: directly connecting the convnet to the LSTM without ad-hoc trend extraction by feeding the local time series to the convnet.
* The convnet -> LSTM architecture requires an analysis of the convnet filters and the representation of trend predictions.
* Trend prediction/segmentation by the convnet could be incorporated as an additional supervised loss.
* A detailed analysis of the trend extraction technique is lacking.
* In Section 5, the SVM baselines concatenate local trend and local time series vectors, but the same approach is not used for LSTM baselines, and the convnet only operates on local time series. This inconsistency needs clarification.
* A significant "naive" baseline is missing: assuming the next local trend slope and duration are equal to the previous local trend slope and duration.
Missing References:
The related work section is incomplete, omitting crucial studies on hybrid convnet + LSTM architectures, notably:
Vinyals, Oriol, et al. "Show and tell: A neural image caption generator." CoRR, abs/1411.4555, 2014.
Donahue, Jeff, et al. "Long-term recurrent convolutional networks for visual recognition and description." CoRR, abs/1411.4389, 2014.
Karpathy, Andrej, et al. "Large-scale video classification with convolutional neural networks." CVPR, 2014.
Organization:
* Section 3 lacks an explanation for selecting the maximal tolerable variance in each trend segment. The appendix should be integrated into the main paper for better clarity.
* Section 4 is unnecessarily lengthy, detailing well-known aspects of convnets and LSTMs. The unique aspect of concatenating $lk$ and $sk$ could be more succinctly presented, potentially moving detailed equations to the appendix.
Additional Questions:
* In Section 5, the number of datapoints in each dataset should be specified, as merely listing the number of local trends is insufficient for understanding the dataset's size and complexity.
Typos:
* On page 5, "duration and slop" should be corrected to "duration and slope".