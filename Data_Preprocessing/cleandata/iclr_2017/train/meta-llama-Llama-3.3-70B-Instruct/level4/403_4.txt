Paper Summary 
This manuscript presents a formalization of the necessary properties for indexing memory-augmented neural networks, including the integration of addressing with read and write operations. Furthermore, it introduces a framework that utilizes any Lie group as the addressing space, with experimental results provided for algorithmic tasks.
 Review Summary 
The paper provides a unified and formalized approach to memory addressing requirements, enabling the maintenance of differentiable memories. The proposed framework offers a generic methodology for constructing addressing mechanisms. However, when compared to key-value networks, potential drawbacks of the approach include the unbounded number of memory cells and the lack of incentive to reuse indexes, which may render it impractical.
 Detailed Review 
The manuscript is well-structured and clearly written, with suitable references to related work. The unified presentation of memory-augmented networks is concise and contributes to the cohesion of the field. The proposed approach is introduced in a straightforward manner, demonstrating its power and reusability. One notable omission is the lack of discussion on the growing memory as a potential drawback, which should be explicitly addressed and analyzed in terms of its impact on efficiency and scalability.