This paper presents a thorough examination of various CNN architectures for image retrieval, with a focus on assessing different design choices. Notably, the authors do not propose or evaluate end-to-end learning frameworks in their analysis.
From a technical standpoint, the contribution of the paper is well-defined, especially in light of the forthcoming clarifications regarding the handling of multiple scales in the representation. Nevertheless, some ambiguity remains as to whether the multi-scale setting would yield distinct results for full and cropped queries.
The paper's emphasis on comparing baseline CNN architectures for image retrieval is noteworthy, although recent studies have demonstrated the efficacy of learning end-to-end representations tailored to this task, achieving impressive results (as seen in the work by Gordo et al., "End-to-end Learning of Deep Visual Representations for Image Retrieval"). The authors argue that their work is complementary to such studies, as they investigate the performance of networks pre-trained on image classification tasks. They also posit that image retrieval is more challenging than image classification due to the use of features originally trained for classification. While this argument has some merit, the superiority of end-to-end training in practice, as evidenced by recent papers, raises questions about the applicability and usefulness of the authors' analysis in this context.