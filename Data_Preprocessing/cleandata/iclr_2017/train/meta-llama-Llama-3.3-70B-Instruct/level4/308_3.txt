SUMMARY 
This manuscript explores crucial challenges associated with training generative adversarial networks, examining the implications of utilizing an asymmetric divergence function and identifying sources of instability in GAN training. It subsequently introduces a novel approach based on smoothening to address these issues.
PROS 
The paper presents a strong theoretical foundation, poses intriguing questions, and provides satisfactory answers. It leverages concepts from analysis and differential topology in an innovative manner, offering potential pathways to mitigate instability in GANs.
CONS 
The manuscript is somewhat lengthy and technically dense. Certain sections and consequences require further development, which is acceptable as a direction for future research.
MINOR COMMENTS
- Consider condensing Section 2.1, potentially by relocating proofs to an appendix.
- Section 3 offers an intuitive, straightforward, and effective solution.
- On page 2, the second bullet point implies that P_g is smaller than the data distribution at some other point x, resulting in a non-zero KL divergence.
- A minor correction is needed on page 2: "for not generating plausibly looking pictures" should be revised to "for generating not plausibly looking pictures".
- Lemma 1 could be generalized further.
- Theorem 2.1 appears to be a fundamental concept in analysis, potentially allowing for a reference to replace the proof.
- In Theorem 2.4, a reminder about the definition of p(z) would be beneficial.
- Similar to Theorem 2.1, Lemma 2 seems to be basic analysis, where a reference could suffice in place of the proof. Additionally, specifying the domain of the random variables would enhance clarity.
- A typographical error "relly" should be corrected to "rely".
- Theorem 2.2 lacks clarification on whether the closed manifolds have boundaries.
- Corollary 2.1 references "assumptions of Theorem 1.3", but Theorem 1.3 is not found in the text.
- In Theorem 2.5, "Therefore" could be replaced with "Then" for improved flow.
- A minor punctuation correction is needed in Theorem 2.6, where "Is a..." should be "is a".
- The numbering of theorems is confusing and could be revised for better organization.