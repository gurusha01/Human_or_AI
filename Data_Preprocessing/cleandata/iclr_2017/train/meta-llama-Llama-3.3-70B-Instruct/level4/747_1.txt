This manuscript introduces a novel approach, termed interior gradients, to assess feature importance in deep neural networks, where the interior gradient is defined as the gradient computed on a scaled input version, and the integrated gradient is obtained by integrating these interior gradients across all scaling factors. The visualization of integrated gradients, in comparison to standard gradients, on real images fed into the Inception CNN demonstrates a more intuitive representation of feature importance.
Although the motivation and qualitative examples presented are compelling, the paper falls short in providing both qualitative and quantitative comparisons with existing research. The standard gradient serves as the sole baseline for qualitative comparison, despite the paper referencing several other relevant studies (including DeepLift, layer-wise relevance propagation, and guided backpropagation) that address the same issue of feature importance. The absence of a comparison with these methods is a significant limitation of the paper. In my opinion, the manuscript is not suitable for publication in its current form due to the lack of these essential comparisons, a concern that was also raised in my pre-review inquiry and remains unaddressed.