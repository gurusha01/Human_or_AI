This manuscript builds upon the Spin Glass analysis introduced by Choromanska et al. (2015a) and applies it to Residual Networks (Res Nets), yielding novel insights into the dynamic ensemble behavior of Res Nets, as well as its connection to Batch Normalization and the topological characteristics of the loss surface of Res Nets.
The paper is well-structured and provides numerous intuitive explanations of the results. Although the technical contributions are an extension of the Spin Glass model analysis by Choromanska et al. (2015a), the revised version could potentially eliminate one of the unrealistic assumptions, and the analysis provides novel dynamic ensemble results and a connection to Batch Normalization, offering more insightful results regarding the structure of Res Nets.
To disentangle the effect of batch normalization on ensemble features, it is crucial to demonstrate this dynamic behavior in a regime without batch normalization. The authors claim that a steady increase in the L2 norm of the weights will maintain this feature; however, the setting for Figure 1 is restrictive and does not provide sufficient empirical evidence to support this claim. Including results on CIFAR 10 without batch normalization to demonstrate the effect of increasing the L2 norm and providing results that support the claims made in Theorem 4 would strengthen the paper.
This work provides a preliminary rigorous framework for analyzing the inherent structure of state-of-the-art Res Net architectures and their variants, which could potentially stimulate more significant results towards a careful understanding of current state-of-the-art models. Rather than solely focusing on improving the performance of Res Nets through intuitive incremental heuristics, it is essential to progress based on a solid understanding of these models.
Several questions and suggestions for improvement arise from this work:
- The issue of unrealistic assumptions in spin glass analysis for neural network landscapes was posed as an open problem in COLT 2015. Can you discuss how this problem affects your analysis?
- Is the assumption that the minimum of equation (12) should hold realistic?
- Choromanska (AISTATS 2015) supports claims with both theoretical and empirical results, but your work lacks such analysis. Can you provide empirical results to support your claims?
- What is the empirical setup used for Figure 1?
- The Fractal Net paper on arXiv claims that residuals are incidental. Can you elaborate on this claim based on your framework? What about densely connected convolutional networks (Huang, 2016)?