The authors have expanded upon their existing causal discovery method (Chalupka et al 2016) by incorporating sparsity assumptions through regularization techniques. This extension is applied to a unique, privately-held dataset from Sutter Health, presenting an intriguing research direction. However, upon review, the presentation appears disorganized, the methodological innovation seems relatively modest compared to the standard of ICLR submissions, and the core findings (or possibly the data itself) are insufficient to adequately address causal questions.
Initially, the presentation lacks clarity, as the focus oscillates between an exclusive emphasis on healthcare data, using it as a motivational example, and neglecting it altogether. Furthermore, Algorithm 1 is introduced without clear reference or justification for its necessity. Figure 2 is deemed unnecessary for this audience. The primary methodological advancement, outlined in Section 2.1 (Causal regularizer), is introduced amidst simplistic examples and lacks clear terminology or standard methodological foundations. Crucial data and results in Section 3.1 are relegated to the appendices, contributing to a disjointed reading experience. Additionally, the paper assumes a high level of familiarity with the Chalupka preprint, which may hinder its ability to stand alone. 
Moreover, despite the presentation not emphasizing technical contributions, the lack of methodological innovation is a concern. Essentially, the previous method has been modified by adding a regularization objective, which, although not inherently flawed, does not introduce a significant technical novelty that the community cannot replicate. 
Fundamentally, the experiments fail to convincingly address the central question of causality. While they demonstrate the expected behavior of regularization (influencing weights as anticipated), the results do not provide meaningful quantitative evidence that causality has been learned. This concern was briefly addressed, but the discussion highlights the technical challenges and impossibility of obtaining a suitable dataset for validation. If such a dataset is unattainable, it may be premature to present this work, as the lack of validation undermines its credibility.
In conclusion, although this effort is sincere, it falls short in several critical areas, warranting further refinement to enhance its clarity, methodological innovation, and experimental validation.