This paper presents a novel approach to language modeling by integrating knowledge base facts, allowing the model to generate words from either the full vocabulary or relevant KB entities at each time step.
The authors evaluate their method using the newly created WikiFacts dataset, which aligns Wikipedia articles with Freebase facts, and propose a modified perplexity metric that penalizes the likelihood of unknown words.
At a high level, the paper's motivation is compelling, as named entity words are crucial for downstream tasks but challenging to learn solely through statistical co-occurrences. The incorporation of KB facts could provide a valuable source of information for this purpose.
However, the paper's details, particularly in Section 3, are difficult to follow, and the writing requires significant improvement. 
- The definitions of $f{symbkey}$, $f{voca}$, and $f_{copy}$ are not clearly stated.
- The notation $w^v$ and $w^s$ is confusing.
- The calculation of $e_k$ appears to be the average of all previous fact embeddings, but this needs to be explicitly clarified.
- In the equation $(ht, ct) = f{LSTM}(x{t-1}, h{t-1})$, the variable $ct$ seems to be unused.
- The concept of "fact embeddings" is not well-defined, although it is later explained as the concatenation of relation and entity (object) entities. For anchor or "topic-itself" facts, it is unclear whether the embedding for special relations is learned and the entity embeddings from TransE are utilized.
Regarding the generation of words from KB entities (fact description), the approach of generating a symbol position first seems counterintuitive. Most entities consist of multiple words, and preserving their order is essential. Additionally, incorporating prior information, such as the common practice of referring to "Barack Obama" as simply "Obama", could be beneficial.