This paper addresses a significant gap in the deep learning literature by exploring maximum entropy approaches, which model information through constraints rather than data. Despite their validity, flexible maximum entropy neural models have received limited attention due to the challenges of optimizing such models, including the need to establish the effect of constraints on a distribution and formulate its entropy. The authors propose using invertible neural models to solve the maximum entropy network problem, leveraging normalizing flows to provide unbiased estimators for entropy. The key contributions of this work include recognizing the potential of normalizing flows for entropy estimation, implementing the resulting Lagrangian as a relaxation of an augmented Lagrangian, and addressing practical optimization issues. 
As far as I am aware, this approach is novel and demonstrates a natural and sensible method for tackling maximum entropy problems, with clear evaluations on several models. Although sufficient experiments have been conducted to establish the method's appropriateness, it would be beneficial to include an example showcasing the clear benefits of flexible flow transformations. Further discussion on computational and scaling aspects, as well as appropriate use cases, would also be valuable. It seems that this approach may be more suitable for model learning rather than inferential settings with known models and instance-based constraints.
The paper is well-structured, and the quality of the work is good, providing a novel basis for flexible maximum entropy models. The clarity is good, and the originality is refreshing, making a significant contribution to model development. However, it is unclear whether this method will become widely used.
Some minor issues need to be addressed, including labeling all equations for reference. On page 4, "algorithm 1" should be capitalized to "Algorithm 1." The update for overcoming stability issues appears somewhat opaque and warrants further clarification on its effectiveness in resolving residual stability problems. Additionally, the support of p is not thoroughly discussed, and it would be beneficial to include this in the general treatment rather than just the specific example. The Dirichlet example explicitly maps to the required support, but this may be non-trivial for more complex constraints and invertible models with known Jacobians.
Overall, it is pleasing to see a natural approach being taken to tackle this question, and with some revisions to address the minor issues, this paper has the potential to make a significant impact in the field. 
Quality: Good, sound paper providing a novel basis for flexible maximum entropy models.
Clarity: Good.
Originality: Refreshing.
Significance: Significant in model development terms, although its future usage is uncertain.