UPDATE: The authors have successfully addressed all my concerns in the revised paper, prompting me to increase my score and now recommend acceptance.
--------------
This manuscript integrates recent advancements in variational autoencoders and autoregressive density modeling through the proposed PixelVAE model. Notably, it demonstrates the capability to match the negative log-likelihood (NLL) performance of a PixelCNN using a PixelVAE with a significantly shallower PixelCNN decoder.
The concept of leveraging a VAE to capture global structure and a PixelCNN decoder to model local structure is well-founded and has the potential to mitigate the issue of blurry reconstructions and samples commonly associated with VAEs. The hierarchical image generation experiments are particularly noteworthy.
I have several suggestions and concerns regarding the manuscript:
1) It would be beneficial to include an experiment that demonstrates the use of a PixelCNN as the decoder in a VAE leads to improved disentanglement of high-level factors of variation in the hidden code. For instance, training a PixelVAE and a VAE on MNIST with a 2D hidden code, visualizing the 2D hidden code for test images, and color-coding each hidden code based on the digit could illustrate better separation of digits in the PixelVAE representation. A comparison of semi-supervised classification performance between VAE and PixelVAE would also enhance the manuscript's quality.
2) A similar concept is presented in the concurrent ICLR submission "Variational Lossy Autoencoder." Incorporating a discussion and comparison of these works into the manuscript would be interesting and valuable.
3) Although the answers to the pre-review questions provided clarity on the architecture details, I still recommend that the authors include the exact architecture details of all experiments in the manuscript and/or make the code publicly available. The current presentation lacks clarity, making the experiments challenging to reproduce.
4) As mentioned in my pre-review question, including two sets of MNIST samples, potentially in an appendix, one generated by PixelCNN and the other by PixelVAE with the same PixelCNN depth, would help illustrate that the hidden code in PixelVAE effectively captures the global structure.
Addressing these concerns would lead to an increased score from me.