The authors present a semi-supervised approach for neural networks, drawing inspiration from label propagation techniques.
Upon examination, the proposed method bears a striking resemblance to the one outlined in (Weston et al, 2008), which the authors reference via a 2012 paper. Notably, the optimized objective function in equation (4) is identical to equation (9) in (Weston et al, 2008).
A potential point of novelty lies in the authors' suggestion to utilize the adjacency matrix as input to the neural network in the absence of other features, demonstrating promising results on the BlogCatalog dataset.
The experimental evaluation of text classification employs neighbors derived from word2vec average embeddings to construct the adjacency matrix. However, the reported accuracies are unimpressive when compared to the performance reported in (Zhang et al, 2015). The final experiment involves semantic intent classification on a custom dataset, where neighbors are identified using a word2vec metric.
In essence, the paper offers limited extensions to the original work presented in (Weston et al, 2008), effectively rebranding the algorithm without introducing substantial scientific innovation. Furthermore, the experimental section is lacking in comprehensive baselines, which undermines the convincingness of the results.