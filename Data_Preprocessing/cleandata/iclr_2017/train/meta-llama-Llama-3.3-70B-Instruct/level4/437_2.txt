This paper presents a modified version of the A3C model, where agents are executed on multiple CPU cores while the computationally intensive model computations are offloaded to a GPU, resulting in a notable speedup. The authors conduct a series of analyses to demonstrate the achieved acceleration.
I appreciate the authors' efforts in addressing the questions and revising the paper to enhance clarity. The proposed modification to the original algorithm is intriguing, and Section 5 provides an in-depth examination of GPU utilization across various configurations. However, a significant limitation of the paper is the lack of more comprehensive experiments in multiple Atari and non-Atari domains, as well as the absence of multiple plots for multiple runs to observe potential instabilities. Stability is a crucial concern in reinforcement learning, and the most effective algorithms should be able to yield good results across diverse domains. I acknowledge the constraints imposed by computational resources, particularly in academic settings outside of industry leaders like Nvidia.