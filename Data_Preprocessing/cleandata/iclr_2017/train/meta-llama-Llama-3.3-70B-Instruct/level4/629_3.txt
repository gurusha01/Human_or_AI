The manuscript presents several intriguing correlations between the image representations in state-of-the-art object recognition networks and findings from human visual psychophysics, including:
1) A demonstration that the mean L1 distance in the feature space of specific CNN layers can predict human noise-detection thresholds in natural images.
2) The observation that, for three different 2-AFC tasks with varying difficulty levels for humans, the mutual information between decision labels and quantized CNN activations tends to be higher in the easier conditions.
3) A replication of the general bandpass nature of contrast/frequency detection sensitivity in humans.
Although these findings appear noteworthy, they also seem somewhat anecdotal, with some results potentially being trivial (e.g., those in point 2). To strengthen the argument, it is essential to investigate which aspects of the CNN contribute to these findings. One approach could be to incorporate robust baseline models for comparison. As previously suggested, one such baseline could be a reasonable low-level vision model. Another interesting direction would be to compare the results for the same network at different training stages.
By doing so, it may be possible to discern which parts of the reported results can be reproduced by simple low-level image processing systems, which parts are due to the general deep network architecture, and which parts arise from the powerful computational properties (object recognition performance) of the CNNs.
In conclusion, establishing correspondences between state-of-the-art CNNs and human vision is a potentially fruitful approach. However, to make a convincing argument that the found correspondences are non-trivial, it is crucial to demonstrate that non-trivial aspects of the CNN lead to the reported findings, which was not adequately done. Therefore, the contribution of the paper is limited, as it is unclear whether the findings reveal a unique relationship between high-performing CNNs and the human visual system.
UPDATE:
I appreciate the extensive revisions and the inclusion of several suggested baselines. The results of the baseline models often raise additional questions and increase the complexity of the interpretation, but this reflects the complexity of the topic and makes the work more valuable.
One further suggestion: The experiments with the CaffeNet snapshots show that the direct relationship between CNN performance and prediction accuracy of biological vision, as known from Yamins et al. (2014) and Cadieu et al. (2014), does not necessarily hold in the presented experiments. I believe this should be discussed in the paper.
Overall, I think the paper now constitutes a decent contribution relating state-of-the-art CNNs to human psychophysics, and I would be happy to see this work accepted. I have raised my rating for this paper to 7.