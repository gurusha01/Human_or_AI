The subject matter of this paper, which focuses on model-based reinforcement learning (RL) utilizing a learned model, is both relevant and contemporary. The manuscript is well-structured and clearly written. However, upon examination, the findings presented appear to be somewhat incremental in nature. The approach of enhancing the frame prediction network with an additional component that predicts rewards is a logical and reasonable extension. Nevertheless, both the methodology and the results lack novelty and surprise, considering that the foundational work by [Oh et al. 2015] has already demonstrated the ability to learn and successfully increment score counters in predicted frames across multiple games.
The potential application of the learned joint model of frames and rewards to model-based RL, as outlined by the authors, is an aspect that warrants further exploration, and I am eager to see the outcomes of this proposed approach.