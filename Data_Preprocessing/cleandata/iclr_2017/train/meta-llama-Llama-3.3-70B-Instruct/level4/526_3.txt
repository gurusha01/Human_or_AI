This work presents an intriguing derivation of a bound that satisfies a regret bound, accompanied by empirical evidence on the CIFAR-10 dataset for cross-entropy loss and autoencoders for MSE loss. Notably, the empirical comparison between observed training loss and Taylor loss reveals that the performance of an optimizer, in terms of training loss, correlates with the difference between these two losses; the better the optimizer performs, the smaller this difference tends to be. Furthermore, the regret loss is demonstrated to hold across various network scales, including layer, neuron, and whole network levels.
The utilization of Taylor approximation offers insights into the activation configurations of the network and their connection to optimization challenges at loss surface kinks. An empirical investigation into the exploration of the activation surface by SGD, Adam, and RMSprop optimizers suggests that increased exploration leads to improved training loss. 
It is worth noting, although not crucial to the paper's core, that the relatively weaker performance of SGD might be attributed to its fixed learning rate; adjusting this through annealing could potentially enhance performance and possibly lead to more exploration and a tighter correlation between actual and Taylor loss.
To strengthen the empirical studies, incorporating a cross-validation set could be beneficial, as the ultimate goal is to make statements about the generalization capabilities of the resulting networks.
Additionally, there appears to be a notation inconsistency regarding the subscript on the Jacobian, which changes to \(a_l\); clarification on this point would be helpful.