This manuscript provides a theoretical framework for applying transformation groups to convolutional neural networks (CNNs), accompanied by empirical evidence demonstrating more efficient utilization of network parameters. 
The concept of steerability is intuitively appealing and appears to be a crucial idea worthy of development, with roots tracing back to seminal work by Simoncelli, Freeman, Adelson, Perona, Greenspan, and others in the early 1990s. The authors' approach, grounded in a formal group theory treatment, offers a novel perspective. However, upon closer examination, the core idea seems relatively straightforward: the feature representation of a transformed image should be equivalent to the transformed feature representation of the original image. Given the restriction to discrete groups, such as rotations of 0, 90, 180, and 270 degrees, the introduction of group theoretic formalisms appears somewhat excessive, and it is unclear what significant benefits this provides. A more substantial challenge lies in implementing continuous transformations, and if the theory could offer guidance in this direction, it would be highly valuable.
Furthermore, the experimental methodology is not transparent, making it difficult to replicate the authors' implementation of capsules or transformation groups. A more detailed description of the experiments would be necessary to fully understand and reproduce the results presented.