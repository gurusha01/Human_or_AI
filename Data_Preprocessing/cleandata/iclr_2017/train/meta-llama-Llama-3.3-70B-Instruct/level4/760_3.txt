This manuscript introduces a generative framework for producing binary images by combining a set of binary features at specific locations, which are then merged using a logical OR operation. A hierarchical extension allows features or classes to have multiple possible templates, with variables controlling the active template in each layer. A joint probability distribution is defined over both feature appearance and instance/location variables.
The overarching objective of this research is intriguing, as the extraction of semantically meaningful features could enable compositionality in image generation. However, it is uncertain whether the proposed approach would yield such results. The learned features, or building blocks, may not necessarily possess semantic meaning. For instance, in the context of text, the discovered features might not correspond to letters, but rather to sub-units or other meaningless components.
The current implementation of the model has limitations, as it is restricted to modeling binary image patterns. The experiments, conducted on synthetic data and MNIST digits, demonstrate the method's ability to recover structure and achieve effective classification on compositional synthetic data. Nevertheless, the test errors on MNIST data are substantial and surpass those of a convolutional neural network (CNN), except when synthetic data corruption is introduced. To strengthen the paper, further research is needed to enhance the method's capability to handle natural images or inherent data variations.