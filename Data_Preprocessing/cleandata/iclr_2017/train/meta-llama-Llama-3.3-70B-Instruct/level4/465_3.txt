I reviewed the manuscript as of December 7th.
Summary:
The authors explore the concept of transferability of adversarial examples in deep networks, confirming its existence in large models while highlighting the challenges of manipulating networks to produce specifically desired labels through adversarial perturbations. Additionally, they demonstrate the feasibility of real-world attacks on a vision web service and investigate the geometric properties of adversarial examples.
Major Comments:
1. The paper presents a plethora of results, making it unclear what the primary message is. With 15 pages of content and an additional 9 pages of results in the Appendix, which are extensively discussed in the main body, the paper's length is notable. Although the conference does not have a strict page limit, I believe this exceeds the spirit of a conference publication. While I do not reject the paper solely based on its length, I consider it a drawback due to the importance of clear presentation. If accepted, I suggest the authors condense the paper further, beyond the 13 pages available elsewhere, to improve clarity. I have identified sections that could be trimmed to achieve this.
2. The section on geometric understanding bears similarities to the results presented in 'Adversarial Perturbations of Deep Neural Networks' by Warde-Farley and Goodfellow (2015), as seen in Figure 1.2. It is unclear what new insights the authors provide beyond these existing results. If there are additional findings, the authors should emphasize them to differentiate their work.
3. The authors build upon observations made by Goodfellow et al (2014) and Szegedy et al (2013), demonstrating the susceptibility of large-scale models to adversarial perturbations, a point also noted by Kurakin et al (2016). Furthermore, they show that attempting to manipulate images into specific, desired labels through adversarial means is more challenging.
4. The demonstration of targeting a real-world vision API is compelling, but it is not clear what this adds to the existing work by Papernot et al (2016). 
In my understanding, the most novel result in this paper, not previously described in the literature, is the unique difficulty of performing adversarial manipulation to convert an image into a particular, desired label. The other results appear to expand on existing literature, and the authors need to better articulate what makes these results unique and contributes to the field beyond previous work.
Areas to Trim the Paper:
- Table 1 can be omitted, with other results either cited or included in the text as Top-1 numbers.
- Section 2.2.1 can be condensed and heavily cited.
- The panels in Figure 2 could be overlaid to facilitate comparison.
It is unclear if the authors have revised the paper since its initial submission, but the current manuscript spans 16-24 pages, depending on how sections are categorized as the Appendix. Despite the absence of a strict page limit for this conference, the paper's length is notably longer than the suggested 8-page limit.