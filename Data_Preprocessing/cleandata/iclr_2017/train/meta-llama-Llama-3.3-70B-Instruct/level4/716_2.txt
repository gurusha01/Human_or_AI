This paper proposes a real-time semantic segmentation network leveraging an encoder-decoder architecture that incorporates various existing techniques to enhance performance and speed. 
However, I have concerns that the design decisions appear to be largely heuristic, lacking a comprehensive ablation study to substantiate each choice. 
Furthermore, the majority of the components utilized are not novel to the community, including indexed pooling, dilated convolution, PReLu, steerable convolution, and spatial dropout. The concepts of 'early down-sampling' and 'decoder size' are straightforward trade-offs between speed and performance, achieved by reducing the size or depth of layers. 
The comparison of performance and inference is limited to a relatively weak baseline, SegNet, which diminishes the paper's convincingness. On public benchmarks, the proposed model fails to achieve results comparable to state-of-the-art models. As noted by another reviewer, there exist more efficient models with similarities to SegNet. 
While the speed-up improvement is notable, it is reasonable considering the components employed. Nevertheless, the significant sacrifice in performance on certain benchmarks undermines the effectiveness of these optimizations. 
One impressive aspect is the model's size of 0.7MB, which has practical implications for deployment on mobile devices. However, the paper lacks analysis on the trade-off between model size and performance, as well as the design decisions leading to model size reduction. Additionally, there is no report on memory consumption during the inference stage, a crucial factor for embedded systems. 
Although this paper may have practical value for designing segmentation networks on embedded systems, I do not believe it contributes novel, insightful ideas worthy of discussion at ICLR, from either the perspective of model compression or semantic segmentation.