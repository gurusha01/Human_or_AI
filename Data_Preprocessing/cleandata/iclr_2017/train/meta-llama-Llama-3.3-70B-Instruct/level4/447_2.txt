This paper aims to examine the behavior of dialogue agents when responding to factoid questions that require querying an oracle for additional information, which can be viewed as an interaction between the agent and a 'teacher'. The investigated problem is of significant importance, and the authors have created a synthetic environment to test their agent, demonstrating a key strength in evaluating various environment combinations where knowledge is missing or the teacher's question contains misspellings, and exploring different methods for the agent to request extra information.
A notable concern is that many tasks may be overly simplistic, such as the AQ question paraphrase, and the presented environment seems limited and far removed from the richness of linguistic structures found in human-chatbot interactions. The paper might be more effectively positioned as a test of agents' basic reasoning and question-answering capabilities rather than dialogue. Nevertheless, the ground-up approach, starting with simple environments, is worthy of analysis and contributes interestingly to this direction. The inclusion of human experiments would significantly enhance the paper's convincingness.
Additional considerations include the simulation's limitation in addressing the first mistake a learner can make during dialogue, such as struggling to understand the surface form of the dialogue partner's text, which is currently restricted to word misspellings. Since the models used do not operate at the character level, this represents only a fraction of the ways an agent can misinterpret context. Further discussion on plans to scale this up to more realistic settings would be valuable. The updated score reflects the addition of Mechanical Turk experiments, which is a positive development.