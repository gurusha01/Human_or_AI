This manuscript presents a novel Bayesian neural network framework designed to predict learning curve values during the training process of machine learning models. As an exploratory study, its long-term objective is integration into a Bayesian optimization system, but currently, the focus is on evaluating the prediction quality. The work expands on previous research by Domhan in 2015 by utilizing information from all tested hyperparameter settings, rather than solely extrapolating from a single learning curve. Additionally, it investigates two Markov Chain Monte Carlo (MCMC) methods for inference: Stochastic Gradient Langevin Dynamics (SGLD) and Stochastic Gradient Hamiltonian Monte Carlo (SGHMC), although it is unclear if these methods were also explored in the 2015 study.
The overall performance of the proposed method appears to be positive, particularly in the initial stages of the learning curves where data is scarce. As anticipated, sharing knowledge across curves proves beneficial in such scenarios. However, one untested regime that could provide valuable insights is when some curves in the training set are fully or mostly observed, potentially highlighting the advantages of information sharing.
A concern with this approach is its computational timing. With training times ranging from 20 to 60 seconds, and considering up to 100 epochs, the total time spent training the Bayesian network could exceed 1.5 hours. This represents a significant fraction of the time required to train the model being tuned, which can take several hours.
The Bayesian network generates multiple predictions, as illustrated in Figure 2. It would be informative to assess the accuracy of these individual predictions. For instance, were the asymptotic values of the learning curves bounded, given that the predictions primarily focused on accuracy? If not, did the predicted values fall within the expected range of [0,1]?
Several minor queries and comments are outlined below:
- The axes in Figure 1 should be labeled as "validation accuracy" for clarity.
- In Figure 6, a description of "LastSeenValue" in the bottom left figure would be beneficial, despite its seeming self-explanatory nature. Additionally, it is puzzling that this metric is not used as a baseline in other parts of the study.
- Figures 7 and Table 1 raise questions about the scope of the predictions: are they limited to the final values of the curves, or do they encompass every value along each curve, conditioned on previous values?
- The choice of using only 5 basis functions warrants explanation. Does this limitation sufficiently capture the flexibility of the learning curves, or would incorporating more basis functions enhance or detract from the model's performance?