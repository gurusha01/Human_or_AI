This paper explores various modelling approaches for designing differentiable programming languages, presenting four key recommendations that are evaluated on a suite of 13 algorithmic tasks related to list operations, such as determining list length and retrieving the k-th element. These tasks are learned from input/output example pairs, with 5 examples used for training and 25 for testing.
A notable distinction between this work and existing differentiable architectures, including NTM, Neural GPU, and NRAM, lies in its objective of automatically generating code to solve given tasks.
However, the experimental component raises concerns, as a comparative analysis with neural networks discussed in the related work would be beneficial. Additionally, assessing the model's performance on problems commonly used by these neural architectures, such as sorting, merging, and addition, would provide valuable insights. The generalizability of this approach to programs that cannot be resolved using a prefix-loop-suffix structure also warrants further investigation.
It is also noteworthy that despite the simplicity of the tasks, the restricted solution structure, and the model's reliance on extensions to perform most of the work, the proposed model still fails to find solutions in a significant number of cases (e.g., the A+L model, which includes a "loop" extension, fails to solve the "list length" task in 84% of the runs).
The strengths of this work include its ability to generate code rather than relying on black-box neural architectures and its capacity to learn from a very small number of examples.
Conversely, the weaknesses encompass the model's limited success, its restriction to very simple tasks, and the absence of a comparative evaluation with neural architectures.