The author suggests utilizing low-rank matrices in both feedforward and recurrent neural networks (RNNs), specifically applying this approach to a Gated Recurrent Unit (GRU) and a feedforward highway network. Additionally, the author presents the passthrough framework as a contribution, which aims to describe both feedforward and recurrent networks. However, this framework appears to offer limited novelty compared to existing formalisms, such as those introduced by Long Short-Term Memory (LSTM) or highway networks.
An empirical evaluation is conducted across various datasets, including MNIST, memory and addition tasks, sequential permuted MNIST, and character-level Penn Treebank. Nevertheless, several issues are identified with the evaluation:
- The highway network experiment lacks a baseline comparison, making it challenging to assess the impact of low-rank parameterization. A comparison with a highway network that has a capacity bottleneck across layers, rather than in the gate functions, would be insightful. Furthermore, the selection process for hyperparameter values is not clarified.
- The character-level Penn Treebank experiment does not adhere to the same experimental setting as previous works, hindering direct comparison. The reported bits per character (bpc) perplexity seems relatively high for this dataset, raising questions about the performance of low-rank decomposition when applied to a stronger baseline.
- The author claims state-of-the-art performance in the memory task, but their approach employs more parameters than the uRNN (41K vs. 6.5K for the memory task), which introduces an unfair comparison. It would be valuable to investigate the performance of low-rank RNNs using a fixed 6.5K parameters. Generally, examining the impact of matrix rank on performance given a fixed state size would provide useful insights.
- Including the baseline and uRNN curves in Figure 2 for the memory and addition tasks would be beneficial for a more comprehensive understanding.
- The experiments do not provide clear guidance on when to use low-rank or low-rank + diagonal approaches.
Overall, the current evaluation is not entirely convincing, with the exception of the sequential MNIST dataset, highlighting the need for more rigorous and comprehensive experiments to support the author's claims.