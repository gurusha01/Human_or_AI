This manuscript investigates three language modeling applications that incorporate explicit reference expression modeling, namely dialogue, receipt generation, and coreferences. Although these tasks are crucial in NLP and the authors have conducted numerous experiments, the paper has several limitations:
1. The writing is unclear, making it challenging to comprehend certain details. Notably, there are apparent mathematical errors, such as the omission of the marginalization sum in Equation (1) and the incorrect assignment of P(z_{i,v}...) = 1 (which should be 0) in the pointer switch section on page 5.
2. The primary innovation appears to be the adaptation of existing techniques to accommodate 2-dimensional attention from tables and pointers to 2-D tables. This can be seen as a customization of existing work for specific tasks involving 2-D tables as input to a seq2seq model that utilizes both attention and pointer networks.
3. The empirical results are not definitive due to limitations such as relatively small dataset sizes or the absence of established baselines for certain novel applications, including recipe generation.
In its current form, this paper is more appropriate for a workshop setting rather than the main conference.