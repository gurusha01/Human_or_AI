This paper presents a VAE-based framework and training methodology that enables the generation of novel samples of a concept based on a set of exemplars provided to the model. The proposed architecture utilizes a recurrent neural network and an aggregation procedure, reminiscent of those employed in Matching Networks, to process the exemplar set and produce a "summary" representation. This summary is then used to condition a generative VAE model, which generates new samples that are similar in kind to the original exemplars. Notably, the aggregation and conditioning procedures demonstrate greater suitability for exemplar sets spanning multiple classes compared to straightforward averaging methods. Interestingly, the model exhibits generalization capabilities, successfully generating samples conditioned on samples from 2 classes and extrapolating to samples from 4 classes. The experimental evaluations, conducted on the OMNIGLOT dataset, yield convincing results. Although a direct comparison to prior works is not explicitly provided in the main text, the appendices offer a clarification, and a comparative analysis with similar architectures from previous studies is presented.