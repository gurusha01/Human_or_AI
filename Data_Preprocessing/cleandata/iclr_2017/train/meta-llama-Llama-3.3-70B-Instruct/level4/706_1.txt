The authors propose novel prior and approximate posterior distributions for variational autoencoders, which are compatible with the reparameterization trick and capable of capturing multiple modes. Additionally, they introduce a gating mechanism between the prior and posterior. The results demonstrate improvements in bag of words document modeling and dialogue response generation tasks.
However, the original abstract's claim that a unimodal latent prior cannot capture a multimodal marginal distribution is overly strong. While a unimodal prior may not be sufficient to model complex data distributions, the idea of using a piecewise constant prior and posterior is well-motivated. For instance, considering a VAE as a regularized autoencoder, a sphere-packing argument can be made for efficiently utilizing the code space. A hypercube-based tiling of latent code space is a sensible approach, although the authors do not thoroughly explore this concept.
The paper's discussion of multimodality is somewhat unclear, as there are three types of multimodality at play: multimodality in the observed marginal distribution, multimodality in the prior, and multimodality in the posterior for a given observation. The authors could provide more clarity on which types of multimodality their analysis demonstrates. Furthermore, the experiments on piecewise variable analysis do not show a clear correspondence between different components of the multimodal prior and different words, which is unsatisfactory.
The results on document modeling are impressive, but it is unclear how the learned variance and mean of the Gaussian prior contribute to the improved performance. An ablation analysis of the different components of the model would strengthen the experiments. Additionally, the strong improvements over the NVDM model are difficult to understand, and a more detailed analysis of the differences between the two models would be beneficial.
The finding that adding more constant components helps with document modeling is intriguing, and further qualitative analysis of the prior modes would be valuable. It would also be interesting to explore whether the posterior modes are highly separated and correspond to specific word senses. The experiments on dialogue modeling yield mostly negative results, but the observation that the piecewise constant variables encode time-related words and the Gaussian variables encode sentiment is noteworthy.
In conclusion, the piecewise constant variational family is a promising idea, although the paper's motivation and analysis could be improved. The experimental results on document modeling are strong, but more ablation analysis is needed to understand the contributions of the different components. The paper would benefit from a clearer discussion of the different types of multimodality and more experiments on standard datasets like MNIST to demonstrate the broad applicability of the proposed variational family. If the method can yield interpretable multiple modes, it would be a valuable contribution, even without absolute log-likelihood improvement.