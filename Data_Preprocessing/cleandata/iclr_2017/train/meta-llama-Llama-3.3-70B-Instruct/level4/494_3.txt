The authors present a dataset comprising proof steps in higher-order logic, extracted from a collection of proven theorems. The effectiveness of approaches like AlphaGo implies that, for challenging combinatorial problems, a carefully curated dataset of expert knowledge (in this case, sequences of subproofs) can serve as a foundation for achieving potentially superhuman performance. The development of superhuman automated theorem provers (ATPs) is undoubtedly highly valuable. Although the dataset is relatively smaller compared to the original Go datasets, it appears to be a promising initial step. However, as the ATP and higher-order logic aspects of this work fall outside my area of expertise, I am unable to assess the quality of these components.
It would be beneficial to see future research focus on scaling up the baselines and incorporating the networks into state-of-the-art ATPs. The ability of deep learning methods to adapt to larger datasets and leverage their potential suggests the possibility of an iterative approach to enhancing ATPs: as ATPs become more powerful, they may generate additional data in the form of newly proven theorems. While this prospect may be distant, it is nonetheless intriguing and warrants further exploration.