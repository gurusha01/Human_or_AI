This paper presents a compelling exploration of superoptimization, building upon the stochastic search approach of STOKE by integrating a learned stochastic search. Here, a neural network generates STOKE proposals based on program embeddings, and the authors employ REINFORCE to develop an MCMC scheme aimed at minimizing program cost. The clarity of the writing and the efficacy of the method are notable.
Comments and questions include:
- Is it accurate to interpret that only the features-to-proposal component of the stochastic computation graph is learned, while the remainder essentially retains the STOKE MCMC scheme? If so, does this mean the 'uniform' model is equivalent to STOKE and serves as the baseline, a point that could be explicitly stated for clarity?
- Were the authors considering the learning of features as an alternative to relying on pre-existing features, or was this approach deemed impractical due to the limited dataset size, which might hinder the generalizability of a feature extractor?
- A relevant reference in a different context is 'Markov Chain Monte Carlo and Variational Inference: Bridging the Gap' by Salimans et al., which proposes optimizing a stochastic computation graph representing an MCMC scheme using a variational (RL-based) criterion. Although the problem setting differs, utilizing HMC instead of MCMC, it might be worthwhile to cite this work as it shares a similar philosophy with 'meta-optimized' MCMC algorithms.