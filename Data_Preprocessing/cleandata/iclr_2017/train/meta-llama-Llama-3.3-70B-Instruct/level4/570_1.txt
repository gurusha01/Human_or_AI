This paper proposes a Neural Answer Construction Model for answering non-factoid questions, specifically love-advice questions, with two key features: incorporating semantic biases into word embeddings and optimizing sentence combinations in predicted answers. The model outperforms the baseline (Tan et al. 2015) by 20% relatively (6% absolutely) on a Japanese online QA service dataset. The paper also experiments with other baseline models.
The approach has several strengths, including reasonable motivations, such as understanding ambiguous word usage and generating new answers. The novelty of the paper lies in incorporating semantic biases into word embeddings, modeling sentence combinations, designing abstract scenarios for answers, and using attention mechanisms to emphasize important topics. The proposed method shows significant improvement over the current best method, and ablation studies provide insights into the contribution of different model components.
However, there are several weaknesses and suggestions for improvement. The determination of abstract patterns, such as sympathy, conclusion, and supplement, is unclear, and it is uncertain how much these patterns contribute to performance improvement. The use of abstract patterns may not be generalizable to other types of non-factoid questions, requiring hand-coding for each type. The paper lacks explicit analysis of the impact of combinational optimization between sentences on model performance. Additionally, the claim that the proposed method can generalize to out-of-domain questions needs experimental support.
The paper raises several questions, including the difference in ground-truth answers between answer selection and answer construction tasks, and the discrepancy in the accuracy of Attentive LSTM and QA-LSTM models. The human evaluation methodology is also unclear, and the use of human workers instead of experts may provide a more unbiased comparison of the proposed model and the QA-LSTM model. The qualitative examples in Table 4 suggest that the QA-LSTM model may provide more direct answers to questions.
Overall, the paper addresses an interesting and useful problem, but the use of abstract patterns and the lack of analysis on the contribution of different model components limit the generalizability and insights of the proposed approach. Further experimentation and analysis are needed to support the claims made in the paper and to provide a more comprehensive understanding of the proposed model's strengths and weaknesses.