This manuscript expands upon existing rate-distortion optimization techniques by applying them to deep neural network-based encoders and decoders, and by transitioning from a basic entropy encoding method to a more sophisticated adaptive entropy coding approach. Furthermore, it explores the connection between this method and variational autoencoders.
Considering that the fundamental rate-distortion optimization approach has been previously published, the innovative contribution of this submission may be somewhat limited (please correct me if I have overlooked a novel aspect). In certain respects, this work could be seen as a regression, as earlier research focused on optimizing a perceptual metric, whereas this paper utilizes Mean Squared Error (MSE). Nevertheless, the results demonstrate a noticeable improvement over JPEG 2000, and to my knowledge, no other learned encoding method has achieved this level of performance. The manuscript is exceptionally well-written.
However, Equation 10 appears to contain an error, and I believe the partition function should be dependent on g_s(y; theta), which would imply that this approach is not equivalent to a Variational Autoencoder (VAE) for non-Euclidean metrics.
It would be beneficial to understand the rationale behind optimizing for MSE rather than a perceptual metric, as was done in previous work. Given the authors' backgrounds, it is surprising that the evaluation was solely performed in terms of Peak Signal-to-Noise Ratio (PSNR).
The contribution of adaptive entropy coding, as opposed to the impact of deeper encoders and decoders, is not clearly discernible. This information seems crucial, and it would be interesting to see the performance without adaptation, as was presented in the previous paper. Additional details regarding the adaptive coder and its effects should be provided. If the authors can address this, I would be inclined to assign a higher score.