This manuscript proposes a recurrent approach leveraging attention mechanisms for one-shot learning, yielding remarkably strong experimental results on the Omniglot dataset that exceed human performance, which is somewhat unexpected given the reliance on conventional neural network components. The authors mention that their findings have been verified by others, including potentially Soumith Chintala, and they provide access to the source code.
Upon reviewing this paper, I am somewhat puzzled about the origin of the significant performance gains, as the methodology appears to overlap substantially with preceding research. To strengthen the argument, it would be beneficial for the authors to present results from a more comprehensive set of experiments, similar to those conducted in prior studies, such as matching networks. Additionally, an ablation study would provide valuable insights into the factors contributing to the model's exceptional performance.