This manuscript presents a novel framework, building upon the author's prior work, for learning compositional rules to generate improved music. The system comprises two primary components: a generative module (student) and a discriminative module (teacher). The generative module, based on Probabilistic Graphical Models, produces music adhering to learned rules, while the teacher module compares the generated music to the empirical distribution of exemplary music pieces (such as Bach's chorales) and suggests new rules for the student to learn, enabling improvement.
What distinguishes this framework from Generative Adversarial Networks (GANs) is the interpretability of both its generative and discriminative components. According to the manuscript, the system appears capable of learning sensible rules from composed music and applying them in subsequent iterations when trained using a curriculum approach. However, a notable omission is the lack of comparison between the proposed system and its predecessor, as well as with other baseline models, such as a simple LSTM generative model, which raises concerns.
The manuscript's readability is somewhat impaired due to two main factors: (1) the extensive use of specialized music terminology (e.g., Table 1 is unclear), which hinders understanding of the system's performance, and (2) the overly complex mathematical notation and concepts. For instance, on Page 4, the explanation of raw/high-level features, Feature-Induced Partition, and Conceptual Hierarchy essentially describes a non-overlapping hierarchical clustering in a 4-dimensional feature space. Moreover, the Informational Hierarchy seems to be merely a list of rules rather than a hierarchical structure. Clarifying these concepts in simpler terms would significantly enhance the manuscript's clarity.
In summary, the paper proposes an intriguing system that appears to be functional. Nonetheless, due to the aforementioned issues, I lack sufficient confidence to draw definitive conclusions.