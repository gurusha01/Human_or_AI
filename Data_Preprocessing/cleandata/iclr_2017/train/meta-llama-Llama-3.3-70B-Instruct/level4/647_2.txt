After carefully considering the authors' response to my initial inquiry, I remain unconvinced that the current manuscript demonstrates sufficient innovation to warrant acceptance to ICLR.
At its core, the paper proposes substituting traditional iterative algorithms for a specific class of problems (ill-posed image inverse problems) with discriminatively trained recurrent networks. However, as also noted by Reviewer 3, the concept of using unrolled networks for iterative inference is not novel, having been previously applied to replace CRF-type inference and solve image inverse problems (as referenced in my citations [1-3]). Therefore, I contend that the fundamental idea presented in the paper is not new, but rather an attempt to formalize it as an approach for inverse problems. Nevertheless, the analysis fails to provide a specific connection to inverse problems, merely demonstrating that the RIM can express gradient descent over a prior and likelihood objective.
I also found the claims regarding the advantages over prior approaches to be unconvincing. The comment on parameter sharing can be seen as a double-edged sword, as untying parameters might lead to improved performance over fewer iterations. Moreover, given the synthetic generation of the training set, learning a larger number of parameters does not appear to be a significant issue. I would argue that parameter sharing is an intuitive approach, and prior methods have deliberately chosen not to tie parameters to achieve better accuracy.
Similarly, the ability to handle different noise levels and scale sizes is not a unique benefit. A single model can be trained to handle multiple forms of degradation, although its performance may be compromised when trained for a specific degradation model or level. Crucially, the current experiments do not provide evidence that this is an inherent property of the RIM architecture. In fact, this claim seems to contradict one of the paper's motivations, which is to train the entire inference architecture end-to-end rather than relying on a single prior for different observation models.
While the proposed method may offer practical benefits beyond prior work, these advantages do not stem from the idea of simply unrolling iterations, which is not novel. I strongly recommend that the authors consider a substantial rewrite of the paper, including a detailed discussion of prior work that highlights the specific aspects of their recurrent architecture enabling better recovery for inverse problems, supported by experimental evidence. Furthermore, to substantiate the claim of solving inverse problems, the paper should consider a broader range of inverse tasks, such as in-painting, deconvolution, different noise models, and possibly working with multiple observations (e.g., for HDR).