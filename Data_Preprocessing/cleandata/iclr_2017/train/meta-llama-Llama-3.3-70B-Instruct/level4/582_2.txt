This paper presents a multimodal approach to learning a unified product representation for recommender systems by integrating various types of product content, such as review text, images, and co-purchase information. Although combining multiple information sources is a viable strategy for addressing data sparsity in recommender systems, I have several concerns regarding the proposed methodology:
1) The relevance of certain modalities to the recommendation task or item similarity is questionable. For instance, the cover images of books or movies, which are the product types used in the paper's experiments, do not provide significant insights into their content. The paper should provide a clear justification and demonstration of how different modalities contribute to the final task.
2) The relationship between the proposed joint product embedding and residual networks seems forced. Traditional residual layers consist of adding the original input vector to the output of a multilayer perceptron (MLP), comprising multiple affine transformations followed by nonlinearities, enabling the training of very deep neural networks (up to 1000 layers) due to improved gradient flow. In contrast, the pairwise residual unit in this paper adds the dot product of two item vectors to the dot product of the same vectors after applying a simple nonlinearity. The motivation behind this architecture is not clearly explained and lacks justification in the paper.
3) As a minor point, the use of the term "embedding" to describe the dot product of two items is unconventional. Typically, embeddings refer to vectors in R^n representing specific entities, whereas in this paper, it refers to the final output, rendering the output layer in Figure 2 redundant.
Ultimately, I believe the paper can be enhanced by providing more motivation for the architectural choices and being more concise in its description. Currently, the paper is excessively long (11 pages), and I strongly recommend shortening it to improve its overall clarity and impact.