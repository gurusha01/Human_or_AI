This manuscript presents two primary contributions: 
(1) the application of adversarial training to the ImageNet dataset, which significantly expands on previously explored datasets 
(2) a comprehensive comparison of various adversarial training approaches, with a notable emphasis on evaluating the transferability of these methods across different scenarios. Additionally, the authors identify and provide insight into the label leaking effect, a crucial finding that enhances our understanding of adversarial training.
The paper is well-organized, clearly articulated, and effectively evaluates and contrasts different adversarial training methods, shedding light on their interrelationships. The inclusion of a broad spectrum of empirical results facilitates a deeper understanding of the adversarial training process. Overall, this work makes a substantial contribution to the field's understanding of adversarial training, and I firmly believe that it is suitably positioned for presentation at ICLR.