This paper is both engaging and accessible, presenting a concise yet effective approach to enhancing the capabilities of Neural Programming Interpreters. By incorporating recursion, the authors demonstrate that NPI can achieve better generalization from a limited number of execution traces, showcasing the significant impact of a modest but substantial extension on the practicality of a machine learning method.
The use of consistent notation with the original Deepmind paper is also commendable, facilitating a seamless reading experience, particularly for those without expertise in this area, as it allows for easy reference to the original work.
One area that warrants further clarification is the generalization proof, which appears somewhat ambiguous. While the numerical examples provided can be comprehensively analyzed by iterating over all possible execution paths until the next recursive call, it is unclear how this method would generalize to continuous input spaces, such as the 3D car example from the original paper. It seems that proving generalization in the continuous case may remain intractable, and additional insight into this aspect would be beneficial.
Finally, the authors may consider releasing the source code to further support the dissemination and development of their work.