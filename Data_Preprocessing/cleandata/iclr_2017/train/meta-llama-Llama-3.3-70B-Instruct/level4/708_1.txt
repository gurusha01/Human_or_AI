Paper summary:
This study presents a novel algorithm for generating k-adversarial images by modifying a limited number of image pixels without requiring access to the classification network's weights.
Review summary:
The generation of adversarial images is a topic of significant practical and theoretical interest. Although this work proposes a new approach, it is hindered by several issues, including verbosity, disorganization, and experiments of limited interest, leading to unclear main conclusions. This line of work has potential but requires substantial rewriting to be suitable for ICLR.
Pros:
* The topic is intriguing
* The black-box setup is highly relevant
* Multiple experiments are conducted
* The study demonstrates that adversarial images can be created by flipping only 1-5% of pixels
Cons:
* The paper is overly long, yet key details are not adequately addressed
* Some experiments are of little interest
* Main experiments lack crucial measures or additional baselines
* The technical novelty is limited
Quality: The method description and experimental setup are subpar.
Clarity: The text is verbose and formal, yet mostly clear, but could be improved with concision.
Originality: While this exact type of experiment may not have been conducted before, the approach and results are not surprising.
Significance: The work is incremental, and the experimental issues limit its potential impact.
Specific comments:
* Reducing the paper's length by 30-40% is recommended to make the argumentation and descriptions more direct and to select only the important experiments.
* Section 4 is flawed, as the modified single pixel can have values far outside the [LB, UB] range, making the test sample clearly outside the training distribution.
* The [LB, UB] range is not specified, and p = 100 should be reported in proportion to [LB, UB] to be useful.
* The modification is done after normalization, which may not be realistic.
* Alg 2 should consider clamping to [LB, UB].
* Section 6 lacks clarity on how p is adjusted, and new variables are introduced, causing confusion.
* The paper should discuss what happens if p is not adjusted and if a simple greedy random search is used.
* The PTB computation in Section 6 is unclear, and the LocSearchAdv PTB value is not directly comparable to FGSM.
* The average number of model evaluations is not discussed, which is essential for claiming the effectiveness of black-box attacks.
* The number of network evaluations when adjusting or not adjusting p during optimization should be explored.
* The Top-k claim should be developed further or toned down, and more experiments should be provided.
* The paper should compare FGSM to other methods effective for batch-normalized networks and discuss why FGSM is not effective in this scenario.
* The conclusions from Section 6 should be more developed, and the baselines should be more comprehensive.
Minor comments:
* Footnotes are overused and should be incorporated into the main text.
* Key variables (e.g., p, r, LB, UB) should be repeated and explained throughout the text.
* Tables 1, 2, and 3 should be converted to figures.
* The last line of the first paragraph in Section 6 is uninformative.
* "Very tiny" should be replaced with "small".