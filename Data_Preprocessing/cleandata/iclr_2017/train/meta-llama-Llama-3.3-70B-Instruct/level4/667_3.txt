SUMMARY.
This manuscript proposes an approach to enhance medical concepts by incorporating their parent nodes within an ontology framework. 
The approach utilizes an attention mechanism focused on the parent nodes of a medical concept to generate a more comprehensive representation of the concept.
The underlying principle is that the attention mechanism will prioritize general concepts higher in the ontology hierarchy for less frequent medical concepts, while focusing on specific concepts for more frequent ones.
The attention mechanism is trained in conjunction with a recurrent neural network, and the model's accuracy is evaluated on two distinct tasks: predicting diagnosis categories at each time step and forecasting the likelihood of heart failure after a specified time step.
The results indicate that the proposed model performs effectively even in scenarios where data is limited.
----------
OVERALL JUDGMENT
The proposed model is straightforward yet intriguing, presenting ideas that are worthy of further exploration, although there are areas where the authors could improve.
For instance, the learning of concept representations within the ontology could be more sophisticated, potentially leveraging knowledge base factorization or graph convolutional approaches.
It is unclear why general knowledge base factorization methods are not applicable to ontology learning in this context.
Additionally, it seems unusual that the representations of leaf nodes are fine-tuned while those of inner nodes are not; a specific rationale for this decision would be beneficial.
The presentation of the paper is clear, and the qualitative evaluation provides valuable insights.
----------
DETAILED COMMENTS
Figure 2: It would be preferable to use a consistent image format with uniform resolution.