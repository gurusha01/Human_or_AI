The authors argue that the reviewers have a limited perspective on the number of parameters and accuracy fractions, and that the focus is solely on engineering aspects. However, this claim is debatable, as the paper's technical contribution is primarily the fractal network architecture, which is presented with intuitive claims rather than rigorous analysis. To substantiate these claims, the authors should either provide a thorough theoretical analysis with clear assumptions, accompanied by a small-scale empirical sanity check, or conduct a comprehensive empirical analysis with carefully designed experiments. Since the approach does not fall into the first category, it necessitates strong experimental evidence to support the intuitive claims without ambiguity.
The authors' rebuttal contains unsatisfactory responses, including manipulative arguments about the narrowness of the review and the dates of the baselines. The paper's primary claim is that fractal networks match or exceed the performance of state-of-the-art residual networks on CIFAR and ImageNet classification tasks. However, this comparison is incomplete, and the empirical study only evaluates accuracy against some baselines without designing experiments to analyze the differences between fractal and residual networks.
The expectation of a fair comparison is reasonable and not solely focused on accuracy fractions or the number of parameters. For instance, Veit et al. provide systematic empirical support for their claims about analyzing residual networks, which has been available on arXiv since May but is not cited in the paper. The preliminary sanity check in Table 4 and Figure 3 only compares fractal networks to plain networks and does not support claims about differences between residual and fractal networks.
The paper claims that fractal networks can scale to "ultra" deep networks, but the authors fail to report results for dozens of layers. They also claim that increased depth may slow training but does not decrease accuracy, although this is unclear due to the lack of results for deeper networks. In Table 3, the error increases as the depth increases to 160 layers. The number of parameters in the proposed architecture is significantly greater than state-of-the-art ResNet variants, which the authors argue is only slightly more.
In response to the lack of comparison to DenseNet, the authors argue that DenseNet cites FractalNet, but this is not a valid reason for omitting the comparison, as DenseNet was published in August and is known for achieving state-of-the-art results as a ResNet variant. The authors state that many variants only reported results on CIFAR/SVHN, making it difficult to compare, but there were clearly published results, such as those by Huang et al. in July.
The authors' claim about the "simplifying power" of fractal networks is unconvincing, as the training procedure is more complex, with many parameters that do not scale as well as baselines. The rebuttal does not provide satisfactory clarification or improvement, and the evaluation remains unchanged.
The paper proposes a new architecture that constructs a fractal structure using expand and join operations, arguing that large nominal network depth with many short paths is key to training "ultra-deep" networks, while residuals are incidental. However, the main bottleneck is the significantly higher number of parameters required for FractalNet, making it challenging to scale to "ultra-deep" networks. The authors' reply that Wide ResNets also require many parameters is incorrect, as ResNet and other ResNet variants can scale to depths of 110 with 1.7M parameters and 1202 with 10.2M parameters, which is much less than the number of parameters for depths of 20 and 40 in Table 1.
The comparison to baselines is unsatisfactory, making the authors' claims unconvincing. The authors also claim that drop-path provides improvement compared to layer dropping, but the results show that the empirical gain disappears when data augmentation techniques are applied. DenseNets should be included in the comparison, as they outperform most state-of-the-art ResNets on both CIFAR10 and ImageNet and require significantly less computation.
The paper has some interesting aspects, such as exploring the differences between fractal and residual networks, but the empirical results do not support the claims, and the large number of parameters makes the model restrictive in practice. The pros of the paper include providing an interesting architecture and investigating the differences to residual networks, which can stimulate promising analysis. However, the cons include the large number of parameters, lack of empirical evidence, and failure to show improvement for "ultra-deep" networks.
The authors should provide comparisons of depth, parameters, training times, and other relevant metrics to ResNet and its variants in Table 1 and Table 2. They should also elaborate on the scaling trick used to reduce the number of parameters and whether it can be applied to other depths. Additionally, the authors should report results for no augmentation for 40 layers and explain the choice of hyperparameters, such as B values and corresponding layers, and C values. The stability and sensitivity of the results to these parameters should also be discussed. Finally, the authors should elaborate on the cases where they could not achieve better results than the best ResNet variant in Table 1.