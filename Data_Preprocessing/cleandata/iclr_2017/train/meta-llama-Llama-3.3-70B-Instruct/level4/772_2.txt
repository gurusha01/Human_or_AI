The authors' investigation into utilizing pretrained CNNs for retrieval purposes involves an extensive evaluation of various parameters, with detailed comments available in the previously posted questions. In summary, this paper's contribution is limited, as it primarily concatenates existing methods and performs parameter tweaking to achieve state-of-the-art results. The key findings, such as using the last conv layer, applying PCA with whitening, and utilizing original image sizes, are not novel and have been previously established. 
The state-of-the-art results reported in the paper are somewhat misleading, as they are largely attributed to the use of the deeper VGG-19 network rather than the optimal choice of parameters. Furthermore, the paper's focus on a single network, VGG-19, raises concerns about the generalizability of the conclusions to other architectures, such as ResNet and Inception. The parameter tweaking was performed on the Oxford dataset, which may not yield the same conclusions if applied to other datasets, such as UKB.
A more accurate title for the paper would be "Optimal parameter values for VGG-19 on Oxford and Paris benchmarks." The lack of comparison with relevant works, such as Gordo et al. and Radenovic et al., is notable, despite the authors' argument that they did not want to train their networks. The paper's extensive experiments and grid search for parameters on the test set can be seen as a form of training, which undermines the authors' claim.
The paper's contribution to the field is questionable, as it does not provide significant new insights. The use of the last conv layer, original image sizes, and PCA with whitening are all established practices. The exploration of multi-scale pooling and the comparison of max/sum pooling with l1 or l2 normalization are not particularly novel, and the most interesting aspect of the paper is figure 3.
The paper's claim to provide "best practices for CNNs" is an overstatement, given its focus on a single architecture. The conclusions may not be applicable to other models, and the paper can be seen as a specialized study of VGG-19 rather than a general guide to CNNs. On a broader level, the paper's approach, which involves tweaking the inputs and outputs of pretrained CNNs, can be seen as more akin to using hand-engineered features than true deep learning.
Minor comments include the surprising statement that instance retrieval is harder than category retrieval, as well as inconsistencies in referencing styles. Overall, the paper's limitations and lack of novelty raise concerns about its suitability for presentation at a conference focused on learning representations. Future papers should strive to move beyond using CNNs as black boxes and explore more innovative approaches, such as training networks specifically for retrieval tasks or designing new architectures tailored to image retrieval.