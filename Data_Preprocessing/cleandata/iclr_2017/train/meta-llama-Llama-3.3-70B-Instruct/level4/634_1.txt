This manuscript introduces the Layerwise Origin Target Synthesis (LOTS) approach, which involves calculating the difference in representation at a specific layer within a neural network and then projecting this difference back into the input space using backpropagation. The authors explore two types of differences: linear scalings of a single input's representation and difference vectors between the representations of two inputs from different classes.
In the case of linear scalings, LOTS is utilized to visualize the representation of a particular input example, illustrating the effect of suppressing or magnifying the feature representation in the input space. Although this computation is intriguing, the value of the resulting visualizations is not entirely clear.
For difference vectors between inputs of different classes, LOTS is employed to generate adversarial examples by modifying an origin image to the point where its classification changes, while moving towards a target image. As anticipated, the required changes are smaller when targeting higher layers, with results approaching those of traditional adversarial image generation when targeting the final layer.
The paper presents an interesting foundational exploration, potentially suitable as a workshop contribution. However, the results may not be compelling enough to warrant a full paper at a premier conference like ICLR.
To enhance the manuscript, several suggestions are proposed:
- The authors claim that LOTS can be used to generate diverse adversarial examples for training more robust classifiers, but they do not conduct this experiment. Demonstrating the effectiveness of LOTS in comparison to existing methods, such as FGS, would significantly strengthen the paper.
- The architecture of the neural networks used, including the number of layers and their internal structure, is not specified. Providing this information would help clarify the results, such as the layer sequence in Figure 2.
- The application of LOTS to intermediate layers is shown in Figures 1-4, but the input and output layers are not included. Presenting the full range of results would support the interpretation of the findings, such as comparing perturbations in pixel space versus CONV1 space.
- The PASS score is mentioned without explanation, making it difficult to understand its significance. A brief explanation, including the relationship between PASS scores and perturbation severity, would be beneficial.
- The claim in Section 4.2 that lower convolutional layers of the VGG Face model capture semantically meaningful features is not supported by the results. Additional evidence or arguments are needed to substantiate this assertion.
Following the rebuttal and the addition of new experiments, the review score has been increased from 5 to 6, indicating that the paper now meets the acceptance threshold.