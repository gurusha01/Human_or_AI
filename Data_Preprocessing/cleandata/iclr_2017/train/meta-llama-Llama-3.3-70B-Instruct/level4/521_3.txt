The authors propose the utilization of chirplets as a foundation for modeling audio signals, accompanied by the introduction of a rapid chirplet transform to facilitate efficient computation. Additionally, they suggest pre-training CNN layers to emulate the chirplet transform of audio signals, drawing inspiration from concepts similar to those presented by Mallet et al. regarding scattering transforms. Although the paper is generally straightforward, there are instances where technical terms, such as AM-FM and MAP, are employed without explicit definition.
A key aspect of interest in this work is the application of the chirplet transform; however, my primary concern lies in the limited scope of the empirical evidence, which is predominantly confined to the domain of bird call classification. Moreover, the reported accuracy improvements within this domain are modest, with a comparison of 61% MAP for log-Mel features to 61.5% for chirplet transforms. To strengthen their argument, I recommend that the authors provide supplementary evidence demonstrating the generalizability of their approach to a broader range of audio tasks, including speech recognition.