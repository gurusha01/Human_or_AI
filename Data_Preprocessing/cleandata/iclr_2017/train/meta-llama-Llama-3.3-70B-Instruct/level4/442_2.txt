Review- Summary:
The paper "Deep Variational Information Bottleneck" delves into the optimization of neural networks for variational approximations of the information bottleneck (IB; Tishby et al., 1999), demonstrating its potential for regularization and enhanced robustness against adversarial attacks using the MNIST example.
Review:
The information bottleneck (IB) has significant potential for various crucial applications, including regularization, adversarial robustness, and privacy, as highlighted in the paper. Integrating IB with recent deep learning advancements to broaden its applicability is a commendable approach. However, given the theoretical contribution is largely a straightforward application of established concepts, a more comprehensive experimental section would be beneficial.
The proposed method enables the scaling of IB, and a more convincing demonstration of this capability would involve a larger problem set than MNIST. Furthermore, it remains unclear whether this approach would effectively regularize more complex, multi-layer networks. 
The absence of dropout in the quantitative comparison of robustness to adversarial examples (Figure 4) is notable. Additionally, the selection of 12 samples warrants explanation. The error bars in Figure 1(a) are also not provided.
On page 7, the authors state that the posterior covariance increases as beta decreases (potentially a typographical error, as it might imply an increase with beta). This assertion is challenging to verify based on Figure 1, due to differing scales.
A comparison with variational fair autoencoders (Louizos et al., 2016), which also aim to learn representations that minimize shared information with certain input aspects, could provide additional insights.
The paper is well-structured and clear, making it easy to follow.