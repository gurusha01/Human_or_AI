This paper presents a innovative adversarial framework for training a model from demonstrations in a third-person perspective, enabling it to perform tasks in a first-person view. The adversarial training approach is utilized to extract features that are independent of the novice-expert or third-person/first-person perspective, allowing the agent to apply the same policy from different viewpoints.
Although the concept is elegant and novel, making for an engaging read, additional experiments are necessary to validate the approach. A significant concern is the lack of a baseline comparison, such as training the model with images from the same viewpoint. It is expected that this approach would outperform the proposed method, but the extent of the difference is unclear. Furthermore, it is essential to investigate how the performance changes when the viewpoint gradually shifts from third-person to first-person. Another crucial question is whether the network simply memorizes the policy, potentially resulting in extracted features that are artifacts of the input image, which could implicitly capture time ticks in a domain-agnostic manner, yet still yield reasonable policy performance. Given that the experiments are conducted in a synthetic environment, this possibility cannot be ruled out. A straightforward verification would involve running the algorithm on multiple viewpoints, blurred or differently rendered images, and random initial conditions.
Further ablation analysis is also required. For instance, the gradient flipping trick employed in Equation 5 is not entirely convincing, and the experiments lack ablation analysis comparing GAN/EM-style training to the gradient flipping trick. Additionally, the results presented in Figures 4, 5, and 6 lack error bars, making them less convincing.