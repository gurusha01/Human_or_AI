This manuscript presents a comprehensive and analytical review of the current literature on reading comprehension, with a specific focus on examining the presence of logical structure, or predication, in recent models. The paper's approach is commendable, and the authors' efforts to categorize the disparate recent literature into two cohesive themes - "aggregation readers" and "explicit reference models" - are appreciated. The writing quality is excellent, with section 3 being particularly well-crafted. The authors' rephrasing of "logical structure" to "predication" and their subsequent clarification are also noteworthy and helpful.
However, some reservations regarding the paper's contribution persist. Firstly, the suitability of the chosen dataset in achieving the paper's objectives is questionable. Previous concerns have been raised about the CNN/DailyMail dataset (Chen et al., ACL'16), and it is unclear whether this dataset is ideal for investigating logical structure of interest. It is possible that the dataset may be more indicative of a lack of logical structure rather than its presence.
Furthermore, the discussion on predication could benefit from providing more practical implications for dataset and model design to better address reading comprehension challenges. A more detailed analysis of various types of reading comprehension challenges, the types of logical structure that are lacking in existing models and datasets, and specific directions for future focus would be more informative. This would enable the community to concentrate on the most critical areas, thereby enhancing the paper's overall impact.