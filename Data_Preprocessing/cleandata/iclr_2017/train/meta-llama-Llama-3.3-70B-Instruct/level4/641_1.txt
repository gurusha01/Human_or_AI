This paper introduces two approaches to wild variational inference, aiming to sample from the variational approximate distribution q without evaluating its density q(z), thereby enabling the consideration of more flexible distribution families. The proposed methods are applied to optimize the hyperparameters of the SGLD sampler, with experiments conducted on a 1-d Gaussian mixture distribution and Bayesian logistic regression tasks.
A key aspect of this work appears to be the connection between previous research on SVGD and KSD and the concept of inference networks, leveraging this connection for SGLD hyperparameter optimization. However, this contribution may be viewed as a relatively straightforward extension, and the experimental validation, limited to simplistic scenarios, fails to convincingly demonstrate the significance of the proposed model. Notably, the ability of particle-based methods to handle multimodality in more complex scenarios (beyond the simple 1-d Gaussian mixture case) remains unclear. Furthermore, the method still requires evaluating the true gradient of the target distribution (e.g., the posterior) for each sample z ~ q, posing a computational challenge for large datasets.
The experimental comparison, which considers the same number of update steps for each method, may not accurately reflect real-world performance, given the relatively low computational cost per update of SGLD. This disparity could become more pronounced for large datasets, where SGLD might facilitate many more updates per unit time than the proposed methods. The Bayesian logistic regression experiment, conducted on a 54-dimensional space with a nearly Gaussian posterior, seems insufficiently challenging. Incorporating Hamiltonian Monte Carlo (HMC) with automatic hyperparameter tuning, such as the no-u-turn sampler, could provide a more comprehensive evaluation.
The paper's clarity is a significant concern, as the exact contributions relative to prior works, including those by the authors, are not clearly articulated. Despite the simplicity of the main message, a substantial portion of the text is dedicated to reviewing previous research.
In summary, more substantial experiments involving high-dimensional, large-scale scenarios, along with improvements to the writing clarity, are recommended to strengthen the paper's impact and credibility.