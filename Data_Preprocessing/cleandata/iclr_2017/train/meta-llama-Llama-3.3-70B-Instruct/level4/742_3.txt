Here is a paraphrased version of the review:
Summary of the Paper
This paper explores the expressivity of neural networks by analyzing quantities related to their behavior. The authors focus on a random network and define the concept of "trajectory length" for a one-dimensional trajectory as it is embedded by the network's layers in a high-dimensional space. They derive growth factors as a function of the number of hidden units and layers, showing an exponential relationship with the number of layers. The authors connect this trajectory length to other quantities, including "transitions," "activation patterns," and "dichotomies." Based on this study, they suggest that training earlier layers in the network can lead to higher accuracy than training later layers, and provide experimental results on MNIST and CIFAR10 datasets.
Clarity
The paper is somewhat difficult to follow due to unclear motivations in the introduction and inconsistent definitions throughout the paper.
Novelty
The idea of studying trajectory length as a function of data transformation by a multilayer network is new and interesting. However, the relationship between trajectory length and transition numbers is only established through growth factors, making it challenging to understand the implications.
Significance
The analysis of activation patterns reveals only a weak connection to the geometry of the input set. A more in-depth study of the trajectory length could provide insights into how the network organizes the input set. The experimental results show that the network becomes contractive and selective during training, which could be further explored using the trajectory length as a measure to disentangle nuisance factors. A theoretical study of selectivity and contraction using trajectory length would be more appealing, particularly in the supervised setting where the network needs to be selective to the class label.
Detailed Comments
* Theorem 1: The definition of a one-dimensional input trajectory is missing, and the theorem's implications for neural network design and architecture are unclear. The connection to transitions in Theorem 2 is weak.
* Theorem 2: The proof is confusing due to unclear notation, particularly with regards to the expectations and weights. The recursion is also unclear, and it is uncertain whether the analysis applies to the case where the weights are fixed or random.
* Theorem 4 in the main text: It is unclear whether the proof is missing or if Theorem 4 refers to Theorem 6 in the appendix.
* Figures 8 and 9: The reduction in trajectory length during training may simply be a result of the network becoming contractive to enable mapping training points to labels, as seen in other studies on contraction in deep networks.