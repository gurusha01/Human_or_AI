The authors present a methodology for generating realistic images by initially creating the background and then, conditioned on the preceding layer, adding one or multiple foreground objects. Furthermore, an image transformer layer is incorporated to facilitate the modeling of diverse appearances.
It would be beneficial to include a discussion on the rationale behind choosing to predict the foreground along with its mask, rather than directly predicting the foreground. For instance, in the case of MNIST, the foreground appears to be irrelevant, whereas for CUB and CIFAR, the foreground contributes texture and color, and the mask ensures a sharp boundary. 
- Clarification is needed on whether the mask is a binary mask or an alpha blending mask.
- The model's ability to decompose images effectively and produce crisp foreground masks with minimal spurious elements is noteworthy, although some spurious elements are observed in CIFAR.
The proposed evaluation metric seems reasonable and well-founded. However, it is theoretically possible for a GAN to achieve a high score while generating images that are not recognizable to humans but are recognizable to the classifier network that produces P_g. This could occur if the generator encodes the class in a subtle manner, although this is unlikely given the adversarial training.
Figure 3 demonstrates that the decomposition is significantly improved when spatial transformers are used. Nevertheless, it also suggests that the foreground prediction and foreground mask may be largely redundant. The "niceness" of the decomposition appears to have minimal impact on the final results.
Moreover, the transformation layer seems to have a limited effect, as evidenced by the transformed masked foreground objects, which are primarily scaled down.
- The content of the 3rd and 6th columns in Figure 9 is unclear, and it is uncertain whether the final composed images are as poor as claimed.
Regarding the evaluation experiment using Amazon Mechanical Turk (AMT), it is unclear why providing users with L2 minimized NN matches is preferable to using random pairs.
It is assumed that the Adversarial Divergence for real images in Table 1 was not actually evaluated. It would be interesting to see how close to 0 multiple differently initialized networks are. Additionally, please provide details on how the confidences and standard deviations were generated, including the use of different training sets, initializations, evaluation sets, and the number of runs.