This manuscript presents a novel approach to model-based control of stochastic dynamical systems, leveraging policy search techniques. The methodology consists of two primary components: (1) learning the stochastic dynamics of the underlying system using a Bayesian deep neural network (BNN) that accommodates stochastic inputs, and (2) optimizing the policy through simulated rollouts from the learned dynamics. The BNN is trained using α-divergence minimization, a technique previously introduced by the authors. The approach is validated and compared on both simulated and real-world domains.
The paper is well-structured and easy to follow, with a clear and concise presentation of the methodology. The application of Bayesian neural networks with α-divergence is noteworthy and appears to be a novel contribution in this context. The resulting model-based control approach has significant practical implications, particularly in terms of the explainability provided by the system model for policy decisions. Overall, the paper makes a valuable contribution to the literature.
However, several questions and suggestions arise:
1. In Section 2.2, it would be beneficial to elaborate on how the random input z_n is utilized by the neural network. Is it simply concatenated with other inputs or subjected to special treatment?
2. The manuscript emphasizes the need for stochastic inputs, yet only a scalar input is provided throughout. Is this sufficient, or would higher-dimensional stochastic inputs be more effective? What are the computational challenges associated with incorporating such inputs?
3. The importance of the normality assumption in z_n and the establishment of the variance γ warrant further discussion.
4. The paper mentions that the neural network's hidden layers consist of rectifiers, but this fact is not further exploited. Is this assumption crucial for optimizing α-divergence, beyond its known benefits in mitigating the vanishing gradient problem?
5. In Equation (3), the denominator should be corrected to \mathbf{Y}.
6. A discussion on the computational complexity of training BNNs in Section 2.3 would provide valuable insight into their practical applicability.
7. A citation to the time embedding theorem, as well as guidance on choosing the embedding dimension, would be helpful between Equations (12) and (13).
8. Figure 1's subplots should include the corresponding reference letters used in the text on page 7.
9. In Section 4.2.1, it is unclear whether the gas turbine data is publicly available, and if so, where. Additional details, such as the dimensionality of variables Et, Nt, and A_t, would be beneficial.
10. The comparison with Gaussian processes could be strengthened by including variants that support stochastic inputs, such as the work by Girard et al. (2003), to provide similar modeling capabilities. At the very least, this line of research should be mentioned in Section 5.
References:
Girard, A., Rasmussen, C. E., Quiñonero Candela, J., & Murray Smith, R. (2003). Gaussian process priors with uncertain inputs-application to multiple-step ahead time series forecasting. Advances in Neural Information Processing Systems, 545-552.