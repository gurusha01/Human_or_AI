The proposal to account for the loss incurred during the binarization step via a proximal Newton algorithm is a commendable approach, addressing the omission of this loss in the evolving process of model compression, which has transitioned from a sequential train-and-binarize method to a concurrent train-and-compress paradigm. Preliminary results on smaller tasks demonstrate the potential benefits of this method. However, it would be beneficial to observe its performance on more substantial networks and complex tasks, particularly those requiring significant compression for deployment on embedded systems, as highlighted in the introduction. The discussion on exploding and vanishing gradients in the context of RNN experiments, specifically using LSTM and the cell error carousel, seems unnecessary. While there's an apparent attempt to link this to proposition 2, the connection between the observed degradation in binary connect and the discussed phenomena is not clearly established. The use of Adam in LSTM optimization raises questions about the necessity of gradient clipping; it's unclear whether the degradation of binary connect is inherently due to capacity limitations rather than optimization issues. For proposition 3.1, it would be more appropriate to include references to the proofs of theorem 3.1 and proposition 3.2 in the appendix for comprehensive understanding.