This paper presents a neural attention model featuring a learnable and differentiable sampling lattice, addressing a notable gap in existing research where sampling lattices are typically fixed. The concept bears resemblance to Spatial Transformer Networks (Jaderberg 2015), with a key distinction being the model's ability to learn the sampling lattice. Experimental results demonstrate the model's capability to learn a meaningful lattice for visual search tasks, with the learned lattice exhibiting similarities to human visual attention patterns.
However, a primary concern with the paper is the limited scope of the experiments. Currently, results are only reported on a modified version of the clustered MNIST dataset. To strengthen the paper, it would be beneficial for the authors to extend their experiments to real-world datasets such as the Toronto Face dataset, CUB bird dataset, and SVHN. For instance, applying the model to the Face dataset to learn attention to different facial parts for expression recognition, or to the CUB bird dataset for fine-grained classification, could provide more compelling evidence of the model's effectiveness. Given the authors' indication that the model can learn meaningful lattices on the MSCOCO dataset in their response to pre-review questions, incorporating these results into the paper would be advantageous.
Furthermore, the paper's comparative analysis is restricted to variants of the proposed model. To comprehensively demonstrate the advantages of the learned sampling lattice, comparisons with other relevant models such as Spatial Transformer Networks and DRAW on the same datasets would be necessary. This would provide a clearer understanding of the model's performance relative to existing methodologies.