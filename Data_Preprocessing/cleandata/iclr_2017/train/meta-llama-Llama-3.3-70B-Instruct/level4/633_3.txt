This paper introduces a novel cooperative training framework for two deep neural network-based probabilistic models, referred to as generator and descriptor networks, which are designed to process signals such as images. The proposed approach enables the two networks to train jointly, leveraging their complementary strengths: the generator network generates initial samples that serve as input for the descriptor network, while the descriptor network refines these samples to provide guidance for the generator network's training.
The concept of cooperative training presents an intriguing method for integrating the training of these two models. However, the empirical evaluation in the paper falls short in several aspects. Notably:
- The datasets used for training are extremely small, ranging from a single image to just 5-6 images. It is unclear why larger datasets were not utilized, and it appears that the limited size of the datasets may be leading to overfitting, which in turn obscures the true potential of the cooperative training approach.
- The majority of the experiments presented lack baseline results, making it challenging to assess the specific benefits of the proposed cooperative training method. Although comparisons are provided for face completion experiments, they are incomplete, as they do not include results from training the descriptor and generator networks separately or using other deep autoencoders. This omission makes it difficult to determine whether cooperative training yields significant improvements over individual training of the networks.
Additionally, the "related work" section would benefit from discussing the connection to variational autoencoders, as introduced by Kingma and Welling in 2013.
Despite the aforementioned limitations, the ideas presented in the paper have intuitive appeal and merit discussion at ICLR. The paper's quality would be substantially enhanced by incorporating more comprehensive baselines and addressing the issues related to training data size.