This paper presents a novel integration of memory networks with reinforcement learning, yielding an interesting and relatively innovative model. Although the experimental data is straightforward, the proposed approach shows promise. However, several questions arise regarding the model's capabilities and limitations:
1. How can the model be adapted to accommodate sentences with multiple variables, and what implications would this have on its performance?
2. In cases where the answer falls outside the predefined vocabulary, what strategies would the model employ to handle such out-of-vocabulary responses?
3. Further analysis of the curriculum learning component would be beneficial, as it plays a crucial role in the training of the reinforcement learning model, and additional insights into its implementation and effects would be valuable.
4. Regarding the training process, it would be helpful to clarify the method used for selecting data samples at each iteration, specifically whether this is done randomly or through a progressive approach from simple to increasingly complex examples.