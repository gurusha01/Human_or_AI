I appreciated the opportunity to review this submission, which presented a compelling discussion.
This paper was engaging and noteworthy, particularly in its approach to integrating approximate inference with the modeling process, rather than treating them as separate entities. Allowing users to choose their preferred inference method based on specific requirements and constraints is a valuable feature. As someone not extensively familiar with Probabilistic Programming Languages (PPL), it appears that this package is unique in its emphasis on compositional inference. The integration with TensorFlow is also an advantage, enabling the design of flexible computation graphs and leveraging GPU capabilities for parallel computation.
My primary inquiry pertains to the design of adaptable objective functions for learning hyperparameters, specifically those associated with delta-q distributions. While it is logical to categorize hyperparameter learning as inference when using Maximum A Posteriori (MAP) estimation, the introduction of alternative objective functions like Renyi divergences raises questions. Does the implementation require users to define a new inference method class whenever they wish to explore different loss functions, or is there a more streamlined approach to incorporating such variations?