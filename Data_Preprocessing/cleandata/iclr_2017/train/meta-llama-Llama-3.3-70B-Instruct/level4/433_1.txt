This manuscript proposes an innovative approach to training generative models, enabling exact inference, sampling, and log likelihood evaluation. The key concept involves constructing a triangular Jacobian matrix, which arises from applying the change of variables formula, thereby facilitating determinant calculation and learning. 
The authors effectively convey this central idea and propose a methodology to achieve it by introducing specialized "routings" between latent variables and data. These routings allow for a combination of identity transformations and complex functions of the input, such as deep neural networks, resulting in a Jacobian with a tractable structure. Furthermore, the authors demonstrate that cascading these routings can yield even more complex transformations.
The experimental evaluation of the model is thorough, with training conducted on multiple datasets, yielding impressive results in terms of sample quality and quantitative metrics. 
Future investigations could explore the applicability of this model to diverse tasks and examine whether the resulting latent representations can enhance performance in downstream tasks, such as classification or inference problems like image restoration.
In conclusion, the manuscript is well-written, the results are compelling, and the proposed model is intriguing. Based on the strengths of the paper, I am pleased to recommend its acceptance.