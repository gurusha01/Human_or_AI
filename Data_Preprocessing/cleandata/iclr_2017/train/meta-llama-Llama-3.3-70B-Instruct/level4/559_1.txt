This paper builds upon the matching networks introduced by Vinyals et al. at NIPS 2016, with a key modification: it represents each class using the mean of its learned embeddings, rather than utilizing the entire support set during testing. The training protocol and experimental setup closely mirror those of the original matching networks. However, the benefits of this approach over the original matching networks are not entirely clear to me. In the 1-shot scenario, the two methods appear to be equivalent, as there is only one example per class, making the mean embedding identical to the embedding itself. For the 5-shot scenario, while the original matching networks compute a weighted average of all examples, the additional computational cost is relatively modest, at most five times greater. The reported experimental results for prototypical nets show only marginal improvements over matching networks. Overall, I consider this work a simple, straightforward, and novel extension, but I remain unconvinced about its significant advantages.