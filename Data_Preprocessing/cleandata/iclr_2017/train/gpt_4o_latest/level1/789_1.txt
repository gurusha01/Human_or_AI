Review of the Paper
The paper introduces a novel Markov Chain Monte Carlo (MCMC) sampling process for generative autoencoders, addressing the mismatch between the learned latent distribution \( P̂(Z) \) and the prior \( P(Z) \). The authors propose that sampling from \( P̂(Z) \) via MCMC, rather than directly from \( P(Z) \), improves the quality of generated samples and interpolations. The paper also extends this MCMC process to denoising generative autoencoders, revealing the benefits of the denoising criterion. The contributions are well-motivated, and the experiments demonstrate the effectiveness of the proposed method in improving sample quality and reducing artifacts in both VAEs and AAEs.
Decision: Accept
The key reasons for this decision are:  
1. Novelty and Contribution: The paper provides a new perspective on sampling for generative autoencoders by introducing an MCMC-based approach, which is straightforward and can be easily integrated into existing models.  
2. Empirical Validation: The results convincingly show that MCMC sampling improves the quality of generated samples and highlights the benefits of the denoising criterion, which were previously less apparent.  
Supporting Arguments
1. Problem Definition and Motivation: The paper clearly identifies the issue of mismatch between \( P̂(Z) \) and \( P(Z) \) in generative autoencoders and motivates the need for improved sampling techniques. The connection to existing literature, including VAEs, AAEs, and denoising autoencoders, is thorough and well-placed.  
2. Methodological Soundness: The derivation of the MCMC sampling process and its convergence properties are rigorous. The extension to denoising autoencoders is a valuable addition, broadening the applicability of the method.  
3. Experimental Results: The experiments on CelebA and SVHN datasets effectively demonstrate the advantages of the proposed approach. Visual improvements in generated samples and interpolations are compelling, and the methodology for evaluation is sound.  
Suggestions for Improvement
1. Clarity in Presentation: While the paper is technically sound, the dense mathematical exposition could be made more accessible. For instance, a visual representation of the MCMC sampling process and its impact on the latent space would help readers better understand the method.  
2. Quantitative Metrics: The paper primarily relies on qualitative results (e.g., visual comparisons). Including quantitative metrics, such as Fréchet Inception Distance (FID) or Inception Score (IS), would strengthen the empirical claims.  
3. Ablation Studies: It would be helpful to include ablation studies to isolate the impact of MCMC sampling from other factors, such as the choice of regularization method or model architecture.  
4. Computational Overhead: The paper does not discuss the computational cost of the MCMC sampling process. A comparison of the trade-off between improved sample quality and additional computation would be valuable for practitioners.  
Questions for the Authors
1. How sensitive is the MCMC sampling process to the choice of the initial latent sample \( z0 \)? Does the quality of \( z0 \) significantly affect convergence or sample quality?  
2. Can the proposed MCMC process be extended to other generative models, such as GANs, that do not explicitly have an encoder?  
3. How does the method scale with higher-dimensional latent spaces or more complex datasets?  
Overall, the paper makes a meaningful contribution to the field of generative modeling, and with minor improvements, it could have an even greater impact.