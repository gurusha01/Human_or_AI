Review of the Paper: "Recurrent Mixture Density Network for Spatiotemporal Visual Attention"
Summary of Contributions
This paper introduces a novel spatiotemporal attentional model, the Recurrent Mixture Density Network (RMDN), designed to predict saliency maps in videos by leveraging human fixation data. The model combines 3D convolutional features for short-term spatial and temporal representation with a Long Short-Term Memory (LSTM) network for long-term temporal dependencies. The saliency maps are modeled as Gaussian Mixture Models (GMMs) and optimized via maximum likelihood estimation. The authors demonstrate that the predicted saliency maps not only achieve state-of-the-art performance on the Hollywood2 dataset but also generalize well to UCF101, improving action recognition accuracy. The paper highlights the efficiency of the RMDN, achieving fast inference times, and its ability to enhance video classification tasks by incorporating saliency maps into feature representations.
Decision: Accept
The paper is well-motivated, presents a novel and scientifically rigorous approach, and provides strong empirical evidence to support its claims. The key reasons for acceptance are:
1. Novelty and Contribution: The paper is the first to apply deep networks for spatiotemporal saliency prediction in videos, directly learning from human fixation data without relying on hand-crafted features.
2. Empirical Strength: The proposed model achieves state-of-the-art results in saliency prediction and demonstrates its utility in improving action recognition, even on unseen datasets.
3. Efficiency and Practicality: The method is computationally efficient, making it practical for real-world applications.
Supporting Arguments
1. Problem and Motivation: The paper addresses a well-defined problem—predicting spatiotemporal saliency in videos—and situates it effectively within the literature. The authors identify limitations in prior work, such as the reliance on hand-crafted features and the lack of long-term temporal modeling, and propose a clear solution.
2. Scientific Rigor: The methodology is thoroughly described, including the architecture of the RMDN, its training procedure, and the evaluation metrics. The experiments are comprehensive, comparing the proposed model against baselines and state-of-the-art methods, and demonstrating its superiority.
3. Results and Generalization: The results on Hollywood2 and UCF101 are compelling, showing both the accuracy of the saliency maps and their utility in downstream tasks. The generalization to unseen datasets further strengthens the paper's claims.
Suggestions for Improvement
1. Ablation Studies: While the paper includes some ablation studies (e.g., comparing LSTMs to RNNs), additional experiments could clarify the contribution of specific components, such as the GMM parameterization or the choice of 3D convolutional features.
2. Comparison with End-to-End Models: The paper could explore end-to-end models that jointly optimize saliency prediction and action recognition, as mentioned in the future work section.
3. Qualitative Analysis: While the paper provides quantitative results, more qualitative examples of saliency maps could help illustrate the model's effectiveness, particularly in challenging scenarios.
4. Broader Applications: The authors could discuss potential applications beyond action recognition, such as video summarization or anomaly detection, to highlight the broader impact of their work.
Questions for the Authors
1. How does the performance of the RMDN change with different numbers of Gaussian components (C) in the GMM? Are there diminishing returns with higher values of C?
2. Could the proposed model be extended to handle multi-modal saliency prediction (e.g., combining visual and audio cues)?
3. How sensitive is the model to the quality of the human fixation data used for training? Would noisy or sparse fixation data significantly degrade performance?
Overall, this paper makes a significant contribution to the field of video saliency prediction and its applications. The proposed RMDN is a well-designed and impactful model, and the paper is a strong candidate for acceptance.