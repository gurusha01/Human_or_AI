Review of the Paper
Summary of Contributions  
This paper introduces a neural attention model with a learnable retinal sampling lattice, trained on a visual search task to classify objects in cluttered scenes using minimal fixations. The authors demonstrate that the learned lattice resembles the eccentricity-dependent sampling structure of the primate retina, with a high-resolution fovea surrounded by a low-resolution periphery. They further explore how task constraints, such as the ability to zoom, influence the emergence of this structure. The paper provides insights into the functional benefits of such a sampling lattice for visual tasks and offers a novel approach to studying biological vision through deep learning.
Decision: Accept  
The paper is well-motivated, presents a novel contribution to the intersection of deep learning and biological vision, and provides scientifically rigorous results. The key reasons for acceptance are:  
1. The innovative approach of using a learnable retinal lattice to explore the emergence of biologically inspired sampling properties.  
2. The clear and thorough experimental results, which support the claims and provide meaningful insights into task-dependent visual processing.  
Supporting Arguments  
1. Problem and Motivation: The paper addresses an important and underexplored question: why the primate retina adopts an eccentricity-dependent sampling lattice. The authors motivate their work well by linking it to biological vision and prior neural attention models, highlighting the gap in understanding the emergence of such structures.  
2. Scientific Rigor: The experiments are carefully designed, with clear comparisons between model variants (fixed lattice, translation-only, and translation-and-zoom). The results are robust, showing that the learned lattice mimics biological properties and adapts to task constraints. The use of cluttered MNIST datasets with varying distractor and digit sizes adds complexity and realism to the task.  
3. Novelty and Contribution: The paper extends neural attention models by making the retinal sampling lattice learnable, a significant departure from prior work that assumes fixed input structures. This approach provides a data-driven method to study optimal sampling strategies, bridging the gap between artificial and biological vision.  
Suggestions for Improvement  
1. Biological Relevance: While the results are compelling, the paper could benefit from a more detailed discussion of how the findings generalize to naturalistic visual scenes. Future work could explore whether the learned lattice adapts similarly for tasks involving real-world images.  
2. Task Complexity: The visual search task is relatively simple, focusing on digit classification. Extending the model to more complex tasks, such as object detection in natural scenes, would strengthen the claims about the generality of the learned lattice.  
3. Interpretability: While the paper discusses the emergent properties of the lattice, additional visualizations or quantitative metrics (e.g., measuring the scale invariance of the lattice) could provide deeper insights into the learned structure.  
Questions for the Authors  
1. How does the learned retinal lattice perform on more complex datasets or tasks beyond cluttered MNIST?  
2. Could the model be extended to incorporate temporal dynamics, such as simulating saccadic eye movements over time?  
3. How sensitive are the results to the choice of hyperparameters, such as the number of kernels or the size of the initial lattice?  
Overall, this paper makes a valuable contribution to the field and opens up exciting avenues for future research at the intersection of deep learning and biological vision.