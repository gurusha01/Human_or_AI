Review of the Paper
Summary of Contributions
This paper addresses the critical issue of adversarial example transferability in deep neural networks, particularly focusing on large-scale datasets and models. The authors are the first to conduct an extensive study of both non-targeted and targeted adversarial examples using state-of-the-art models trained on ImageNet. They propose a novel ensemble-based approach to generate transferable adversarial examples, achieving significant success in transferring targeted attacks for the first time. The paper also provides geometric insights into adversarial transferability and demonstrates the practical implications of these findings by successfully attacking Clarifai.com, a black-box image classification system. The contributions are well-organized, and the results are both novel and impactful, advancing the understanding of adversarial transferability in large-scale settings.
Decision: Accept
The paper is recommended for acceptance due to its novel contributions, rigorous methodology, and practical significance. The key reasons for this decision are:
1. Novelty and Scope: The paper is the first to study targeted adversarial transferability on large-scale datasets and models, filling a critical gap in the literature.
2. Methodological Rigor: The ensemble-based approach is well-motivated and demonstrates significant improvements over existing methods, with both theoretical and empirical support.
Supporting Arguments
1. Problem Significance: The transferability of adversarial examples is a pressing concern for the robustness of machine learning systems, especially in black-box settings. By addressing this issue on large-scale datasets like ImageNet, the paper contributes to a highly relevant area of research.
2. Novel Insights: The discovery that targeted adversarial examples rarely transfer with existing methods and the subsequent success of the ensemble-based approach are significant findings. The geometric analysis further enhances the understanding of why transferability occurs.
3. Empirical Validation: The experiments are comprehensive, involving multiple state-of-the-art models and real-world attacks on Clarifai.com. The results are robust and convincingly demonstrate the effectiveness of the proposed methods.
4. Practical Relevance: The ability to generate transferable targeted adversarial examples has implications for both security and robustness in real-world applications, making the work highly impactful.
Suggestions for Improvement
While the paper is strong overall, the following points could enhance its clarity and impact:
1. Clarification of Geometric Analysis: The geometric findings, such as the orthogonality of gradient directions and decision boundary alignment, are intriguing but could benefit from more intuitive explanations or visualizations to aid understanding.
2. Comparison with Concurrent Work: The paper mentions concurrent work by Moosavi-Dezfooli et al. (2016) but does not provide a detailed comparison. A more explicit discussion of how the proposed methods differ or improve upon this work would strengthen the paper.
3. Broader Evaluation: While the results on Clarifai.com are impressive, evaluating the ensemble-based approach on additional black-box systems could further validate its generalizability.
4. Hyperparameter Sensitivity: The paper briefly mentions hyperparameters like learning rates and ensemble weights but does not explore their sensitivity. A discussion on how these parameters affect the results would be valuable.
Questions for the Authors
1. How sensitive are the results to the choice of models in the ensemble? For example, would including models with different architectures (e.g., transformers) improve transferability further?
2. Can the ensemble-based approach be extended to other domains beyond image classification, such as natural language processing or speech recognition?
3. The paper mentions that the decision boundaries align well across models. Could this alignment be quantified further, and does it hold for models trained on different datasets or tasks?
In conclusion, this paper makes a significant contribution to the field of adversarial machine learning. The proposed methods and findings are both novel and impactful, warranting its acceptance at the conference. Addressing the suggested improvements would further enhance the paper's clarity and generalizability.