Review
The paper addresses the problem of reading comprehension in question-answering tasks, specifically focusing on cloze-style datasets where answers must be derived from a given passage. It introduces the concept of "predication structure" in neural readers, positing that hidden state vectors can be decomposed into a predicate vector and a constant symbol vector. This structure is argued to conceptually link aggregation readers (e.g., Attentive Reader, Stanford Reader) with explicit reference readers (e.g., Attention-Sum Reader, Gated-Attention Reader). Additionally, the paper demonstrates that adding linguistic features to neural readers significantly improves performance, achieving state-of-the-art results on the Who-did-What dataset.
Decision: Accept
Key reasons for acceptance:
1. Novel Contribution: The paper introduces a compelling theoretical framework for understanding the logical structure of neural readers, supported by empirical evidence. This is a significant conceptual contribution to the field of machine reading comprehension.
2. Performance Impact: The addition of linguistic features and pointer annotations leads to state-of-the-art results on the Who-did-What dataset, demonstrating the practical utility of the proposed methods.
Supporting Arguments
1. Well-Motivated Approach: The paper is well-situated in the literature, providing a detailed review of existing datasets and models. The proposed predication structure bridges theoretical gaps between aggregation and explicit reference readers, offering a unified perspective on their mechanisms.
2. Rigorous Empirical Evidence: The paper provides extensive experimental results, including heatmaps, cosine similarity analyses, and performance comparisons across multiple datasets. These results convincingly support the claims about the emergence of predication structure and the benefits of linguistic features.
3. Practical Relevance: The proposed enhancements to neural readers, such as pointer annotations and linguistic features, are straightforward to implement and yield measurable improvements in performance.
Suggestions for Improvement
1. Clarity of Theoretical Framework: While the concept of predication structure is intriguing, the explanation of its emergence and mathematical formulation could be made more accessible. For instance, providing intuitive examples or visualizations of the decomposition would help readers grasp the idea more effectively.
2. Broader Evaluation: The experiments focus heavily on the Who-did-What dataset. Evaluating the proposed methods on additional non-anonymized datasets, such as SQuAD, would strengthen the generalizability of the findings.
3. Comparison with State-of-the-Art Models: While the paper achieves state-of-the-art results on Who-did-What, it would be helpful to compare the proposed models with recent transformer-based architectures, which dominate many reading comprehension benchmarks.
Questions for the Authors
1. How does the proposed predication structure generalize to non-cloze-style datasets, such as SQuAD or other open-domain question-answering tasks?
2. Did you explore the impact of different linguistic features in isolation? Which features contributed the most to the observed performance gains?
3. Could the proposed pointer annotation approach be extended to handle multi-word answers or phrases, as required in datasets like SQuAD?
Overall, this paper makes a strong theoretical and practical contribution to the field of reading comprehension and merits acceptance after addressing the suggested improvements.