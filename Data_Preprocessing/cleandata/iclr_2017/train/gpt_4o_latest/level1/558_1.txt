Review of the Paper
Summary of Contributions
This paper extends classical count-based exploration methods in reinforcement learning (RL) to high-dimensional and continuous state spaces by leveraging hashing techniques. The authors propose two approaches: static hashing using locality-sensitive hashing (LSH) and learned hashing using autoencoders. The paper demonstrates that these methods can achieve near state-of-the-art performance on challenging RL benchmarks, including continuous control tasks and Atari 2600 games with sparse rewards. The authors also provide an in-depth analysis of the factors that contribute to effective hash functions, such as granularity and domain-specific preprocessing. The proposed method is computationally efficient, simple to implement, and complementary to existing RL algorithms, offering a strong baseline for exploration in RL.
Decision: Accept
The paper should be accepted due to its simplicity, strong empirical results, and potential impact as a baseline for exploration in RL. The key reasons for this decision are:
1. Novelty and Practicality: The paper presents a novel yet straightforward generalization of count-based exploration methods, making them applicable to high-dimensional state spaces without requiring complex heuristics.
2. Strong Empirical Evidence: The proposed methods demonstrate competitive or superior performance on well-established benchmarks, including tasks with sparse rewards, which are notoriously challenging for RL algorithms.
Supporting Arguments
1. Well-Motivated Approach: The paper is well-situated in the literature, addressing a significant gap in exploration strategies for high-dimensional RL tasks. It builds on classical count-based methods and connects them to modern deep RL techniques, such as hashing and autoencoders.
2. Scientific Rigor: The experiments are thorough, covering a range of benchmarks and systematically analyzing key factors like hash function granularity and preprocessing. The results are convincing, showing that even simple hash functions can outperform more complex exploration strategies in certain cases.
3. Impact and Generality: The proposed method is simple, computationally efficient, and broadly applicable across different RL domains. It provides a strong baseline for future research in exploration.
Suggestions for Improvement
1. Clarity in Methodology: While the methodology is generally well-described, the paper could benefit from a clearer explanation of how hyperparameters (e.g., hash function granularity, bonus coefficient) are chosen and their impact on performance. A more detailed discussion of the trade-offs between static and learned hashing would also be valuable.
2. Comparison with Related Work: The paper could include a more direct comparison with pseudo-count-based methods (e.g., Bellemare et al., 2016) to highlight the advantages and limitations of the proposed approach.
3. Ablation Studies: While the paper analyzes granularity and preprocessing, additional ablation studies on the choice of hash functions (e.g., SimHash vs. other LSH methods) would strengthen the claims.
4. Theoretical Insights: The paper focuses primarily on empirical results. Adding theoretical insights or guarantees about the proposed method's performance (e.g., under specific conditions) would enhance its contribution.
Questions for the Authors
1. How sensitive is the performance of the proposed method to the choice of hash function? Could other LSH methods or clustering techniques further improve results?
2. The learned hashing approach uses autoencoders, which require additional training. How does this impact computational efficiency compared to static hashing?
3. Could the method be extended to multi-agent or partially observable RL settings? If so, what modifications would be necessary?
In conclusion, this paper makes a significant contribution to the field of RL by extending count-based exploration to high-dimensional spaces through hashing. Its simplicity, strong empirical results, and potential as a baseline justify its acceptance, while addressing the suggested improvements could further enhance its impact.