The paper presents a novel framework, Defoveating Autoencoders (DFAEs), to study how artificial neural networks can perceive and reconstruct high-detail images from low-fidelity, distorted inputs. Inspired by the human visual system, which processes visual input with varying acuity across the retina, the authors propose DFAEs as a means to investigate perceptual "filling-in" capabilities. The paper claims that DFAEs can reconstruct missing details such as shape, color, and contrast from systematically degraded inputs, though they struggle with high-frequency details like textures. The authors also explore the network's ability to generalize from global features and its limitations when reconstructing color and peripheral details. This work is positioned as a step toward both improving neural network architectures and understanding the mechanisms underlying human visual perception.
Decision: Accept
The paper should be accepted due to its novel and well-motivated approach to studying perceptual filling-in in neural networks, as well as its potential implications for both machine learning and neuroscience. The framework is clearly described, and the experiments are thorough, addressing a range of input distortions and providing insightful results.
Supporting Arguments:
1. Novel Contribution: The paper introduces DFAEs, a novel framework for studying perceptual filling-in, which is distinct from traditional denoising autoencoders or super-resolution methods. This innovation is well-motivated by the human visual system and fills a gap in the literature.
2. Scientific Rigor: The experiments are comprehensive, exploring various input distortions (e.g., downsampling, scotomas, and foveated inputs) and their effects on reconstruction accuracy. The authors provide both qualitative and quantitative analyses, demonstrating the network's ability to learn global features and compensate for missing details.
3. Broader Implications: The work has implications beyond engineering better networks, as it opens avenues for testing hypotheses about human visual perception. The discussion on potential future research directions, such as using DFAEs to model optical illusions, is particularly compelling.
Suggestions for Improvement:
1. Clarify the Role of Global Features: While the paper mentions that the network learns global features to infer missing details, it would benefit from a more detailed analysis of these features and their relationship to the input distortions. For example, are there specific patterns or shapes that the network consistently relies on?
2. Comparison with Human Perception: The paper draws inspiration from the human visual system but does not directly compare DFAE performance with human perceptual capabilities. Including such comparisons, even qualitatively, would strengthen the connection to neuroscience.
3. Broader Applicability: The experiments are limited to MNIST and CIFAR100 datasets. It would be helpful to discuss how the framework might generalize to more complex datasets or tasks, such as natural scene understanding or medical imaging.
4. Recurrent DFAEs: The paper briefly mentions the potential for recurrent DFAEs to handle sequences of foveations but does not explore this in depth. A preliminary experiment or discussion on the feasibility of this extension would be valuable.
Questions for the Authors:
1. How do the global features learned by the network differ between datasets (e.g., MNIST vs. CIFAR100)? Are there any insights into why certain features emerge under specific input distortions?
2. Could the framework be extended to convolutional architectures, which are more commonly used for image processing tasks? If so, how might this affect the results?
3. Have you considered testing DFAEs on tasks beyond image reconstruction, such as classification or segmentation, to evaluate their utility in practical applications?
4. How does the choice of loss function (e.g., PSNR vs. MSE) influence the network's ability to reconstruct missing details? Would other perceptually motivated loss functions improve performance?
In conclusion, the paper makes a significant contribution to the study of perceptual filling-in in neural networks and is well-positioned to inspire future research at the intersection of machine learning and neuroscience. With minor clarifications and extensions, the work could have even broader impact.