The paper introduces a novel optimization algorithm, Eve, which enhances the Adam optimizer by incorporating feedback from the objective function to adaptively adjust the learning rate. The authors propose a mechanism that tracks relative changes in the objective function using a running average, enabling the algorithm to dynamically scale the learning rate based on the optimization progress. The method is evaluated on a range of tasks, including training convolutional neural networks (CNNs) for image classification, recurrent neural networks (RNNs) for language modeling, and question answering. Experimental results demonstrate that Eve outperforms state-of-the-art optimization methods, including Adam, RMSProp, and SGD with momentum, across these benchmarks. The paper also provides an analysis of the behavior of the feedback mechanism during training, offering insights into its effectiveness.
Decision: Accept
The paper should be accepted because it presents a well-motivated and empirically validated improvement to a widely used optimization algorithm. The proposed method is simple, computationally efficient, and demonstrates consistent performance gains across diverse tasks. The authors provide thorough experimental evidence and analysis to support their claims.
Supporting Arguments:
1. Clear Problem Motivation: The paper identifies a critical limitation in existing stochastic gradient descent methods, particularly their inefficiency in handling plateaus and saddle points in the optimization landscape. The proposed feedback mechanism is well-motivated as a solution to this issue.
   
2. Strong Empirical Results: The experiments are comprehensive, covering multiple tasks (image classification, language modeling, and question answering) and comparing Eve against several baseline optimizers. Eve consistently achieves lower training loss and faster convergence, demonstrating its robustness and generalizability.
3. Scientific Rigor: The authors provide detailed descriptions of the algorithm, hyperparameters, and experimental setups. The analysis of the tuning coefficient (dt) offers valuable insights into the algorithm's behavior, further validating its design.
Suggestions for Improvement:
1. Theoretical Analysis: While the empirical results are compelling, the paper would benefit from a theoretical analysis of the proposed method. For example, a formal study of the convergence properties of Eve could strengthen its scientific foundation.
   
2. Broader Evaluation: Although the experiments are diverse, additional evaluations on larger-scale datasets (e.g., ImageNet) or more complex models (e.g., transformers) would further establish the scalability and applicability of Eve.
3. Ablation Studies: The paper could include ablation studies to isolate the contributions of individual components of the feedback mechanism, such as the effect of the thresholds (k, K) or the decay rate (β3).
Questions for the Authors:
1. How sensitive is Eve to the choice of its additional hyperparameters (β3, k, K)? Did you observe any significant performance degradation with suboptimal values?
2. Could the feedback mechanism be applied to other optimizers beyond Adam, such as SGD with momentum or second-order methods? If so, have you explored these extensions?
3. How does Eve perform in terms of computational overhead compared to Adam, particularly in large-scale settings?
In conclusion, the paper makes a meaningful contribution to the field of optimization for deep learning. The proposed Eve algorithm is both practical and effective, and the authors provide sufficient evidence to justify its utility. With minor improvements and additional theoretical insights, this work has the potential to make a significant impact.