The paper introduces Deep Generalized Canonical Correlation Analysis (DGCCA), a novel method for nonlinear multiview representation learning that extends canonical correlation analysis (CCA) to handle arbitrarily many views. DGCCA combines the flexibility of deep neural networks with the statistical power of multiview data, learning shared representations that maximize the correlation across views. The authors present a gradient-based optimization algorithm for DGCCA and evaluate its effectiveness on synthetic data, phoneme classification, and Twitter hashtag and friend recommendation tasks. Results demonstrate that DGCCA outperforms existing methods, such as linear GCCA and nonlinear two-view DCCA, in tasks that benefit from multiview representation learning.
Decision: Accept
The paper is well-motivated, addresses a significant gap in multiview learning, and provides strong empirical evidence for the effectiveness of DGCCA. The key reasons for acceptance are:
1. Novel Contribution: DGCCA is the first method to combine nonlinear representation learning with the ability to handle multiple views, addressing limitations of prior methods like DCCA and GCCA.
2. Empirical Rigor: The results on diverse datasets and tasks convincingly demonstrate the advantages of DGCCA over baseline methods, with clear improvements in downstream performance.
Supporting Arguments
1. Problem Significance: Multiview learning is a critical area in machine learning, with applications in multimodal data and social networks. The inability of existing methods to handle nonlinear relationships across more than two views is a well-recognized limitation, and DGCCA addresses this effectively.
2. Methodological Soundness: The derivation of the gradient for the GCCA objective and its integration into a deep learning framework are technically sound. The authors provide detailed explanations and pseudocode, ensuring reproducibility.
3. Empirical Validation: The experiments are comprehensive, covering synthetic data, phoneme classification, and social media recommendation tasks. The consistent performance gains over baselines (e.g., up to 4% improvement in phoneme classification accuracy) highlight the practical utility of DGCCA.
Suggestions for Improvement
1. Clarity of Presentation: While the paper is technically rigorous, some sections, particularly the gradient derivation and optimization details, are dense and could benefit from simplification or additional illustrative examples.
2. Comparison with Non-CCA Methods: Although the paper briefly discusses non-CCA multiview methods, a more detailed empirical comparison with these approaches (e.g., multiview spectral clustering or Siamese networks) would strengthen the claims.
3. Ablation Studies: It would be helpful to include ablation studies to isolate the contributions of different components of DGCCA, such as the choice of nonlinearity or the impact of varying the number of views.
4. Scalability Analysis: While the paper mentions the computational complexity of DGCCA, a more detailed discussion or experiments on scalability with larger datasets or higher-dimensional views would be valuable.
Questions for the Authors
1. How does the performance of DGCCA scale with the number of views? Are there diminishing returns as more views are added?
2. Could the authors elaborate on the choice of hyperparameters for the neural networks in DGCCA? How sensitive is the method to these choices?
3. How does DGCCA handle noisy or irrelevant views? Is there a mechanism to down-weight such views during training?
In conclusion, the paper makes a significant contribution to multiview learning by introducing DGCCA, a method that is both theoretically sound and empirically validated. With minor improvements in presentation and additional comparisons, this work has the potential to become a cornerstone in multiview representation learning.