Review
Summary of Contributions
The paper presents a novel approach to offline bilingual word vector alignment, introducing significant theoretical and practical advancements. The authors prove that the optimal linear transformation between word vector spaces should be orthogonal, derived using Singular Value Decomposition (SVD). They further propose an "inverted softmax" retrieval method to address the hubness problem, achieving substantial improvements in translation precision. Notably, the method demonstrates robustness by achieving 40% precision using a pseudo-dictionary constructed from identical character strings, eliminating the need for expert bilingual signals. Additionally, the paper extends its approach to sentence-level translation, achieving 68% precision in retrieving sentence translations from a large corpus. These contributions unify and enhance existing methods in the literature, offering a rigorous and scalable solution for offline bilingual vector alignment.
Decision: Accept
The paper makes a strong theoretical contribution by proving the necessity of orthogonal transformations and provides practical improvements in bilingual word vector alignment. The results are rigorously validated, demonstrating significant improvements over prior methods. The work is well-motivated, addresses a relevant problem in multilingual NLP, and introduces a robust, scalable approach that does not rely on expert bilingual resources.
Supporting Arguments
1. Theoretical Contribution: The proof that the optimal transformation is orthogonal is a significant theoretical insight, unifying existing methods and providing a rigorous foundation for offline bilingual vector alignment.
2. Practical Improvements: The inverted softmax and dimensionality reduction techniques improve translation precision from 34% to 43%, a substantial advancement over Mikolov's original method. The ability to achieve 40% precision using a pseudo-dictionary demonstrates the robustness and practicality of the approach.
3. Sentence-Level Translation: Extending the method to sentence-level translation with 68% precision is a noteworthy achievement, showcasing the versatility of the proposed approach.
4. Scientific Rigor: The experiments are comprehensive, comparing the proposed method against multiple baselines and evaluating performance across diverse datasets, including rare word translations and sentence retrieval tasks.
Suggestions for Improvement
1. Clarity on Computational Complexity: While the paper mentions the computational efficiency of SVD, a detailed comparison of runtime and scalability with other methods like CCA would strengthen the argument for its practicality.
2. Broader Language Pair Evaluation: The experiments focus on English-Italian translations. Extending the evaluation to more diverse language pairs, especially those with less lexical overlap, would provide stronger evidence of the method's generalizability.
3. Sentence Vector Limitations: The paper uses simple sentence vectors (sum of word vectors) for sentence translation. Exploring more sophisticated sentence embeddings (e.g., contextual embeddings) could further enhance performance and provide insights into the method's adaptability.
4. Error Analysis: A deeper analysis of failure cases, particularly for rare words and sentence translations, would help identify areas for future improvement.
Questions for the Authors
1. How does the computational complexity of the proposed method compare to other alignment techniques like CCA, especially for large vocabularies or corpora?
2. Have you tested the method on language pairs with different scripts (e.g., English-Japanese) or those with less shared vocabulary? If not, how do you anticipate the method would perform in such cases?
3. Could the inverted softmax be further optimized or combined with other retrieval techniques to improve performance on sentence-level translation tasks?
Overall, this paper makes a strong contribution to the field of multilingual NLP, combining theoretical rigor with practical advancements. With minor improvements and additional evaluations, it has the potential to become a foundational work in offline bilingual word vector alignment.