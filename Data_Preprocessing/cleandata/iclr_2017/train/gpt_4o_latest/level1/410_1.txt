Review of the Paper
Summary of Contributions
This paper addresses the critical problem of detecting misclassified and out-of-distribution (OOD) examples in machine learning models, particularly in real-world applications where silent failures can have severe consequences. The authors propose a simple yet effective baseline that utilizes maximum softmax probabilities to distinguish between correctly classified, misclassified, and OOD examples. They evaluate this baseline across diverse tasks in computer vision, natural language processing (NLP), and automatic speech recognition (ASR), demonstrating its generalizability. Furthermore, the paper introduces an auxiliary "abnormality module" that leverages internal network representations to improve detection performance in some cases. The authors also contribute standard tasks, datasets, and evaluation metrics (AUROC and AUPR) to facilitate future research in this area.
Decision: Accept
The paper makes a significant contribution by establishing a strong baseline for error and OOD detection, a relatively underexplored yet crucial area in AI safety. The work is well-motivated, scientifically rigorous, and broadly applicable across multiple domains. The inclusion of standard tasks and metrics provides a foundation for future research, making this paper a valuable resource for the community.
Supporting Arguments
1. Well-Motivated Problem: The paper highlights the real-world implications of silent failures in machine learning models, particularly in high-stakes domains like healthcare. The problem is framed within the broader context of AI safety, making it highly relevant.
2. Strong Baseline: The proposed baseline, based on softmax probabilities, is simple yet effective, achieving high AUROC and AUPR scores across diverse datasets and tasks. This simplicity ensures reproducibility and accessibility for future research.
3. Scientific Rigor: The paper evaluates the baseline and abnormality module using a wide range of datasets and architectures, ensuring robustness. The results are statistically validated, and the experimental setup is clearly described, enabling reproducibility.
4. Room for Improvement: The abnormality module demonstrates that the baseline can be surpassed in some cases, encouraging further exploration. The authors also suggest several promising research directions, such as leveraging intra-class variance and fine-grained detection.
Suggestions for Improvement
1. Baseline Limitations: While the baseline is effective, its reliance on softmax probabilities may not generalize well to all architectures or tasks. The authors could discuss scenarios where the baseline might fail or perform suboptimally.
2. Abnormality Module: The abnormality module shows promise but is not consistently superior to the baseline. A more detailed analysis of when and why the module outperforms the baseline would strengthen the paper.
3. Broader Evaluation: The paper focuses on specific datasets and architectures. Including results for more complex tasks (e.g., large-scale vision or NLP datasets) would enhance the generalizability of the findings.
4. Confidence Metrics: The appendix introduces metrics for evaluating confidence models, but their practical utility is not fully explored. A more detailed discussion of these metrics in the main text would be beneficial.
Questions for the Authors
1. How does the baseline perform on more complex, state-of-the-art architectures (e.g., transformers or vision models like ViT)?
2. Could the abnormality module be extended to tasks beyond those tested, such as reinforcement learning or generative models?
3. How sensitive is the baseline to the choice of threshold for AUROC and AUPR metrics? Would alternative metrics (e.g., calibration error) provide additional insights?
In conclusion, this paper makes a valuable contribution to the field by addressing a critical problem with a simple and effective baseline, while also paving the way for future research. With minor improvements and clarifications, it has the potential to become a foundational work in error and OOD detection.