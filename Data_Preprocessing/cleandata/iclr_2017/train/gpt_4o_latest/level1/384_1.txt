Review
Summary of Contributions
The paper proposes two novel end-to-end neural network models for machine comprehension of text, specifically targeting the challenges posed by the SQuAD and MSMARCO datasets. The models combine match-LSTM, previously developed for textual entailment, with Pointer Networks to address the unique requirements of these datasets, such as variable-length answers and the need for attention-based reasoning. The authors introduce two variants: a sequence model that generates answers token by token and a boundary model that predicts the start and end points of the answer span. The boundary model achieves state-of-the-art performance on the MSMARCO dataset and competitive results on SQuAD. Additionally, the paper provides insights into the effectiveness of attention mechanisms and offers an ablation study to highlight the impact of various architectural choices. The authors also make their code publicly available, facilitating reproducibility and further research.
Decision: Accept  
The paper is well-motivated, methodologically sound, and provides significant contributions to the field of machine comprehension. The boundary model's state-of-the-art performance on MSMARCO and competitive results on SQuAD demonstrate the effectiveness of the proposed approach. The integration of match-LSTM and Pointer Networks is novel and well-placed in the literature, addressing gaps in existing methods. The experimental results are rigorous, and the ablation studies provide valuable insights into the model's behavior.
Supporting Arguments
1. Problem Relevance and Novelty: The paper addresses a critical challenge in machine comprehension by focusing on datasets with variable-length answers and human-generated questions. The use of match-LSTM for question-passage alignment and Pointer Networks for answer generation is innovative and well-suited to the task.
2. Empirical Rigor: The experiments are thorough, covering both SQuAD and MSMARCO datasets. The boundary model's superior performance on MSMARCO and its ability to overcome early stop prediction issues in the sequence model are compelling.
3. Scientific Contribution: The paper not only proposes effective models but also provides detailed analyses, such as the impact of attention mechanisms and answer length on performance. These insights are valuable for future research.
Suggestions for Improvement
1. Clarity of Presentation: While the technical details are comprehensive, the paper could benefit from more concise explanations in the methodology section. For instance, the descriptions of match-LSTM and Pointer Networks could be streamlined for better readability.
2. Error Analysis: The paper identifies "why" questions and multi-sentence reasoning as challenging areas but does not delve deeply into why the models struggle with these cases. A more detailed error analysis could provide actionable insights for future work.
3. Comparison with State-of-the-Art: While the boundary model achieves competitive results, a more detailed comparison with other state-of-the-art models, including their strengths and weaknesses, would strengthen the paper's claims.
4. Dataset Generalization: The paper focuses on SQuAD and MSMARCO but does not explore how well the models generalize to other datasets. Including results or discussions on additional datasets would enhance the paper's impact.
Questions for the Authors
1. How does the model handle questions requiring multi-sentence reasoning, and what architectural changes might address this limitation?
2. Could the proposed models be adapted to handle datasets with more complex answer types, such as those requiring external knowledge or reasoning beyond the passage?
3. Have you considered incorporating pre-trained language models, such as BERT or GPT, into your architecture to further improve performance?
Overall, the paper makes a strong contribution to the field of machine comprehension and is recommended for acceptance with minor revisions to improve clarity and depth of analysis.