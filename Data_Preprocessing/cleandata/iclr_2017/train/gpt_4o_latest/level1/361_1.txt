Review
Summary of Contributions
The paper addresses the problem of improving hyperparameter optimization for deep neural networks by leveraging learning curve predictions. Specifically, it proposes the use of Bayesian neural networks (BNNs) to model learning curves, introducing a specialized "learning curve layer" to enhance prediction accuracy. The contributions are as follows:
1. A study of BNNs for learning curve prediction, focusing on their reliability and uncertainty estimates.
2. Development of a novel neural network architecture with a learning curve layer that incorporates parametric models for improved predictions.
3. Empirical comparison of different BNN sampling methods, showing that stochastic gradient Hamiltonian Monte Carlo (SGHMC) outperforms others.
4. Demonstration that the proposed model outperforms existing methods (e.g., Domhan et al., 2015) in predicting both partially observed and unobserved learning curves.
5. Integration of the model into the Hyperband framework, resulting in faster convergence to optimal hyperparameter configurations compared to traditional Bayesian optimization and random sampling.
Decision: Accept
The paper makes a significant contribution to the field of hyperparameter optimization by introducing a novel and effective approach for learning curve prediction. The proposed method is well-motivated, rigorously evaluated, and demonstrates clear improvements over existing baselines. The integration of the model into Hyperband is particularly impactful, as it addresses the practical challenge of reducing computational costs in hyperparameter tuning.
Supporting Arguments
1. Well-Motivated Approach: The paper builds on prior work in Bayesian optimization and learning curve prediction, addressing key limitations of existing methods (e.g., reliance on black-box models or fixed parametric assumptions). The introduction of a learning curve layer is a novel and well-justified extension.
2. Rigorous Evaluation: The authors conduct extensive experiments on diverse datasets (e.g., CNNs, FCNs, VAEs) and compare their method against strong baselines, including Gaussian processes, random forests, and other BNN approaches. The results consistently demonstrate superior performance in terms of mean squared error, log-likelihood, and optimization speed.
3. Practical Impact: The integration of the model into Hyperband showcases its practical utility, achieving faster convergence to optimal configurations while maintaining computational efficiency.
Suggestions for Improvement
1. Clarity of Presentation: The paper is dense, and some sections (e.g., derivations in Section 2.2) could benefit from additional explanation or visual aids to improve accessibility for a broader audience.
2. Comparison with Simpler Models: While the paper demonstrates that LastSeenValue performs surprisingly well for partially observed curves, it would be helpful to include a discussion of when the proposed method is most advantageous (e.g., under high noise or non-convergent curves).
3. Ablation Studies: An ablation study isolating the impact of the learning curve layer would strengthen the claim that it is a key contributor to the model's success.
4. Scalability: The computational overhead of training BNNs with SGHMC is briefly mentioned but not quantified. A discussion of scalability to larger datasets or more complex architectures would be valuable.
Questions for the Authors
1. How sensitive is the proposed method to the choice of hyperparameters for the Bayesian neural network itself (e.g., architecture, sampling method)?
2. Can the learning curve layer be generalized to other types of iterative optimization processes beyond neural network training?
3. How does the method perform in scenarios with extremely noisy or highly irregular learning curves, where parametric assumptions may break down?
Overall, the paper is a strong contribution to the field and merits acceptance, provided the authors address the minor concerns outlined above.