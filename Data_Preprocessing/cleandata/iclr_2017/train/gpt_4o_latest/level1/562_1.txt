The paper proposes Generative Adversarial Parallelization (GAP), a framework for training multiple GANs (or their variants) simultaneously while periodically swapping their discriminators. This approach aims to address two key challenges in GAN training: mode collapse (where GANs fail to cover all modes of the data distribution) and training instability. The authors argue that by decoupling the generator-discriminator pairing, GAP improves convergence, mode coverage, and generalization. They also introduce an improved Generative Adversarial Metric (GAM-II) to evaluate GANs quantitatively. The paper provides empirical evidence on synthetic and real-world datasets, demonstrating that GAP outperforms traditional GANs in terms of mode coverage and generalization.
Decision: Accept
Key reasons for this decision are:  
1. Novelty and Contribution: The proposed GAP framework is a novel and well-motivated approach to addressing mode collapse and training instability in GANs. The idea of leveraging parallelization and discriminator swapping is innovative and aligns with trends in distributed deep learning.  
2. Empirical Support: The results convincingly demonstrate that GAP improves mode coverage and generalization across multiple datasets. The use of GAM-II as an evaluation metric strengthens the scientific rigor of the claims.  
Supporting Arguments:  
- The paper is well-grounded in the literature, identifying key limitations of GANs and positioning GAP as a solution. The discussion of mode coverage and overfitting in GANs is insightful and highlights the relevance of the proposed method.  
- The experiments are thorough, covering both synthetic and real-world datasets. The visualizations and metrics (e.g., GAM-II, t-SNE) effectively support the claims of improved mode coverage and generalization.  
- The flexibility of GAP to work with different GAN architectures (e.g., DCGAN, GRAN) and its potential as a regularization technique are compelling contributions.  
Suggestions for Improvement:  
1. Quantitative Mode Coverage Metric: While the paper provides qualitative evidence of improved mode coverage, a quantitative metric would strengthen the claims. The authors could explore recent advances in mode coverage evaluation for generative models.  
2. Ablation Studies: It would be helpful to include ablation studies to isolate the contributions of individual components of GAP, such as the impact of swapping frequency or the number of parallel GANs.  
3. Scalability Analysis: The paper briefly mentions the use of GPUs and inter-GPU communication. A more detailed analysis of the computational overhead and scalability of GAP on larger datasets or more complex architectures would be valuable.  
4. Broader Implications: The discussion could be expanded to explore the implications of GAP for other adversarial frameworks, such as multi-agent reinforcement learning or adversarial domain adaptation.  
Questions for the Authors:  
1. How sensitive is GAP to the choice of hyperparameters (e.g., swapping frequency, number of GANs)? Are there guidelines for selecting these parameters?  
2. Can GAP be extended to asynchronous training, and if so, how would this impact its performance and stability?  
3. How does GAP perform on more complex datasets (e.g., ImageNet) or tasks beyond image generation, such as text or video generation?  
4. Could the improved generalization observed in GAP-trained discriminators be leveraged for downstream tasks, such as semi-supervised learning?  
Overall, the paper presents a significant contribution to the field of GANs, and with minor improvements, it has the potential to make a strong impact.