Review
The paper proposes a novel approach to address the issue of polysemy in vector-space word representations by introducing "fuzzy paraphrases" annotated with degrees of reliability. These degrees are used to probabilistically eliminate less reliable paraphrases during the learning process, thereby reducing noise introduced by polysemous words. Unlike prior works that generate multiple vectors per word sense, this method retains a single vector per word, making it more practical for real-world applications. The authors demonstrate the effectiveness of their approach through extensive experiments, showing improvements over prior methods across multiple benchmarks.
Decision: Accept
The paper is well-motivated, presents a novel contribution to the field, and provides strong empirical evidence to support its claims. The key reasons for acceptance are:  
1. The proposed method addresses a significant problem (polysemy) in a practical and innovative way, avoiding the need for additional preprocessing like word sense disambiguation.  
2. The experimental results convincingly demonstrate that the method outperforms prior works across multiple benchmarks, including MEN, SimLex, and word analogy tasks.  
Supporting Arguments
1. Problem and Motivation: The paper clearly identifies the challenge of noise introduced by polysemous words in lexicon-based word vector learning. The motivation to retain a single vector per word for practical usability is well-articulated and addresses a gap in the literature.  
2. Novelty and Methodology: The use of fuzzy paraphrases, annotated with reliability scores derived from bilingual similarity, is a novel and scientifically sound approach. The dropout mechanism based on these scores is an elegant solution to the problem.  
3. Empirical Rigor: The authors conduct extensive experiments with multiple benchmarks, varying parameters, and corpus sizes. The results consistently demonstrate the superiority of the proposed method over simpler baselines and prior works. The analysis of parameter effects and corpus size is thorough and insightful.  
Suggestions for Improvement
1. Clarity of Presentation: While the methodology is innovative, some sections (e.g., the mathematical formulation of the dropout function) are dense and could benefit from clearer explanations or illustrative examples.  
2. Broader Evaluation: The paper primarily focuses on benchmarks for word similarity and analogy tasks. Including evaluations on downstream NLP tasks (e.g., text classification or machine translation) would strengthen the practical relevance of the method.  
3. Ablation Studies: While the paper compares the proposed method to simpler baselines (e.g., using all paraphrases or none), additional ablation studies isolating the impact of specific components (e.g., the choice of bilingual similarity as the reliability metric) would provide deeper insights.  
Questions for the Authors
1. How sensitive is the method to the quality of the lexicon (e.g., PPDB2.0)? Would the approach generalize well to other lexicons or ontologies?  
2. The paper mentions that the proposed method involves randomness. Could you elaborate on how this randomness affects reproducibility and whether any steps were taken to mitigate variability in results?  
3. Have you considered extending the fuzzy paraphrase approach to other types of embeddings, such as contextualized word embeddings (e.g., BERT)?  
Overall, this paper makes a valuable contribution to the field of word representation learning and addresses a practical challenge in an innovative way. With minor improvements in clarity and broader evaluation, it could have even greater impact.