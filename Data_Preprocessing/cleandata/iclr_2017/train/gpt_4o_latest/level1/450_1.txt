Review of the Paper
Summary of Contributions
The paper introduces Classifier Two-Sample Tests (C2ST), a novel approach to two-sample testing that leverages binary classifiers to distinguish between two distributions. The authors claim that C2ST offers several advantages over traditional methods, including interpretable test statistics, automatic feature learning, and simple null distributions. The paper makes four key contributions: (1) a theoretical analysis of the properties of C2ST, including its asymptotic distributions and testing power; (2) empirical comparisons with state-of-the-art two-sample tests on synthetic and real-world datasets; (3) applications of C2ST for evaluating generative models like GANs; and (4) a novel use of C2ST in causal discovery through conditional GANs. The paper is well-written, and the proposed method is both innovative and practical, with strong empirical results supporting its claims.
Decision: Accept
The paper is a strong candidate for acceptance due to its novel and well-motivated methodology, rigorous theoretical analysis, and extensive empirical validation. The key reasons for this decision are:
1. Novelty and Impact: The use of binary classifiers for two-sample testing is a relatively unexplored area, and the paper demonstrates its potential to outperform existing methods in both accuracy and interpretability.
2. Empirical Rigor: The experiments are thorough, covering a wide range of scenarios, including synthetic data, real-world applications, and generative model evaluation. The results consistently show that C2ST is competitive or superior to state-of-the-art methods.
Supporting Arguments
1. Well-Motivated Approach: The paper builds on established concepts in two-sample testing and machine learning, bridging the gap between statistical testing and representation learning. The motivation for using classifiers is clearly articulated, and the theoretical analysis (e.g., power and asymptotic distributions) is sound and aligns with empirical findings.
2. Comprehensive Experiments: The authors evaluate C2ST on diverse tasks, including independence testing, distinguishing between real and synthetic data, and causal discovery. The results demonstrate that C2ST achieves strong performance across these tasks, often outperforming traditional methods like MMD and ME tests.
3. Interpretability: The interpretability of C2ST, through classifier uncertainty and feature importance, is a significant advantage, especially in applications like causal discovery and GAN evaluation.
Suggestions for Improvement
While the paper is strong overall, the following points could further enhance its clarity and impact:
1. Comparison with Other Classifier-Based Approaches: While the paper mentions prior work on classifier-based two-sample testing, it would be helpful to include direct comparisons with these methods to highlight the specific advantages of C2ST.
2. Scalability Analysis: The paper could discuss the computational complexity of C2ST, especially for high-dimensional data or large sample sizes, and compare it to kernel-based methods like MMD.
3. Robustness to Classifier Choice: The authors use neural networks and k-NN classifiers in their experiments. A discussion on how the choice of classifier affects the performance and interpretability of C2ST would be valuable.
4. GAN Evaluation: The paper notes that pixel-level differences dominate two-sample tests for GAN evaluation. While the use of ResNet features mitigates this issue, a more detailed discussion on how to address overfitting in GANs would strengthen this section.
5. Causal Discovery: The causal discovery experiments are promising but rely on ensembling CGANs due to instability in training. Exploring ways to stabilize training or discussing the limitations of this approach would make this contribution more robust.
Questions for the Authors
1. How sensitive is C2ST to the choice of classifier? Would simpler classifiers (e.g., logistic regression) suffice in some cases, or is the flexibility of neural networks critical?
2. Can C2ST handle imbalanced sample sizes (e.g., |SP| â‰  |SQ|)? If so, how does this affect the test statistic and power?
3. In the GAN evaluation experiments, how does C2ST compare to other evaluation metrics like Inception Score or FID in terms of correlation with visual quality?
4. Could the proposed method be extended to multi-sample testing (e.g., comparing more than two distributions)? If so, how might this be implemented?
Overall, this paper makes a significant contribution to the field of two-sample testing and its applications. The proposed C2ST method is well-motivated, rigorously analyzed, and empirically validated, making it a valuable addition to the literature.