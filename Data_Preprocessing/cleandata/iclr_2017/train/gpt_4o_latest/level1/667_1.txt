Review of "GRAM: A Graph-based Attention Model for Healthcare Predictive Modeling"
Summary of Contributions
The paper introduces GRAM, a novel graph-based attention model designed to address two critical challenges in healthcare predictive modeling: data insufficiency and interpretability. GRAM leverages hierarchical information from medical ontologies to enhance deep learning models by representing medical concepts as weighted combinations of their ancestors using an attention mechanism. This approach allows GRAM to generalize effectively in scenarios with limited data and produce interpretable representations aligned with medical knowledge. The authors demonstrate GRAM's superior performance compared to baseline models across three predictive tasks: sequential diagnosis prediction (using Sutter and MIMIC-III datasets) and heart failure prediction. Notably, GRAM achieves up to 10% higher accuracy for rare diseases and 3% improved AUC for heart failure prediction, while requiring significantly less training data. The paper also provides qualitative insights into GRAM's attention behavior and its ability to generate medically interpretable embeddings.
Decision: Accept
Key reasons for acceptance:
1. Novelty and Impact: GRAM introduces a well-motivated and innovative approach to incorporate domain knowledge from medical ontologies into deep learning models, addressing a critical bottleneck in healthcare predictive modeling.
2. Empirical Rigor: The paper provides strong empirical evidence, demonstrating GRAM's superior performance under data insufficiency and its interpretability advantages over baseline methods.
Supporting Arguments
1. Well-Motivated Approach: The paper is well-grounded in the literature, identifying key limitations of existing deep learning models in healthcare (e.g., data requirements and lack of interpretability). The use of medical ontologies as a knowledge prior is both logical and impactful. The attention mechanism is thoughtfully designed to adaptively balance specificity and generality based on data availability.
2. Robust Experimental Results: The experiments are thorough and demonstrate GRAM's effectiveness across diverse datasets and tasks. The 10% accuracy improvement for rare diseases and 3% AUC gain for heart failure prediction are significant, particularly given the challenges of data insufficiency in healthcare.
3. Interpretability and Insights: The qualitative evaluations, including t-SNE visualizations and attention behavior analysis, convincingly show that GRAM produces interpretable representations aligned with medical ontologies, a critical requirement for healthcare applications.
Suggestions for Improvement
1. Scalability: While the paper briefly discusses GRAM's training overhead (50% more time per epoch than RNN), it would be helpful to provide more details on how this overhead scales with larger datasets or more complex ontologies.
2. Comparison with Other Ontology-Based Methods: The paper could benefit from a deeper comparison with alternative methods that incorporate domain knowledge, such as graph convolutional networks or Laplacian regularization approaches.
3. Ablation Studies: While the importance of the initialization scheme is discussed, additional ablation studies isolating the contributions of the attention mechanism and the knowledge DAG would strengthen the claims.
4. Generalizability Beyond Healthcare: The authors could briefly discuss whether GRAM's methodology could be applied to other domains with hierarchical data, such as biology or social sciences.
Questions for the Authors
1. How does GRAM handle inconsistencies or missing relationships in the medical ontology? For example, if certain parent-child relationships are incomplete or incorrect, how does this impact the model's performance?
2. Could GRAM be extended to incorporate other types of relationships (e.g., causal or treatment relationships) beyond the parent-child hierarchy in medical ontologies?
3. How does the choice of ontology (e.g., CCS vs. SNOMED-CT) affect GRAM's performance? Are there specific characteristics of an ontology that make it more suitable for GRAM?
Overall, this paper makes a significant contribution to healthcare predictive modeling by addressing key challenges with an innovative and well-supported approach. With minor improvements, it has the potential to further advance the field.