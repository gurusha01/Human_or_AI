The paper introduces an end-to-end learning method for image compression that optimizes rate-distortion performance through a novel relaxation technique. The proposed method employs a nonlinear analysis and synthesis transformation inspired by biological neurons, trained on a database of natural images. The results demonstrate superior rate-distortion performance compared to JPEG and JPEG 2000, with significant improvements in visual quality across all bit rates.
Decision: Accept
The paper is recommended for acceptance due to its novelty, thorough analysis, and compelling results. The proposed method not only advances the state of the art in image compression but also provides a biologically-inspired approach that achieves superior visual quality.
Supporting Arguments:
1. Problem Tackled: The paper addresses the fundamental problem of lossy image compression, focusing on the trade-off between rate (bit usage) and distortion (image quality). The authors propose a method that jointly optimizes these competing objectives using a continuous relaxation of the quantization process.
   
2. Novelty and Motivation: The use of generalized divisive normalization (GDN) transforms, inspired by biological visual systems, is a key innovation. This approach is well-motivated and builds on prior work in both image compression and neural modeling. The connection to variational autoencoders is insightful, though the method is distinct in its focus on discrete compression.
3. Scientific Rigor: The paper provides a robust empirical evaluation, comparing the proposed method to JPEG and JPEG 2000 using both objective metrics (MSE, MS-SSIM) and qualitative visual analysis. The results are convincing, showing consistent improvements in rate-distortion performance and visual quality. The use of actual bit rates, rather than entropy estimates, strengthens the validity of the claims.
Suggestions for Improvement:
1. Broader Comparisons: While the method is compared to JPEG and JPEG 2000, it would be valuable to include comparisons with more recent neural compression methods, such as those by Toderici et al. (2016). This would position the work more clearly within the current landscape of learned compression techniques.
2. Ablation Studies: The paper could benefit from additional analysis of the contributions of individual components, such as the GDN/IGDN transforms. For instance, how does performance change when simpler nonlinearities (e.g., ReLU) are used?
3. Efficiency Considerations: While the method is computationally efficient at inference time, the training process is resource-intensive. A discussion on potential strategies to reduce training costs or adapt the method for real-time applications would be beneficial.
Questions for the Authors:
1. How does the method perform on datasets with significantly different statistics from the training set (e.g., medical images or satellite imagery)?
2. Could the proposed relaxation technique be adapted for other types of data compression, such as video or audio?
3. Is there a theoretical explanation for why the GDN/IGDN transforms outperform simpler activation functions like ReLU in this context?
In summary, this paper makes a significant contribution to the field of image compression by introducing a novel, biologically-inspired approach that achieves state-of-the-art performance. With minor improvements and additional comparisons, it has the potential to be a landmark work in learned compression.