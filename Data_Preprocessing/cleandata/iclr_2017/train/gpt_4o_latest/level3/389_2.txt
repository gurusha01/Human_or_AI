The paper introduces SampleRNN, a novel hierarchical recurrent neural network for raw audio generation, trained end-to-end and evaluated on speech and music datasets. The authors highlight its ability to model long-term dependencies in audio waveforms while maintaining computational efficiency. The model outperforms baselines, including a reimplemented WaveNet, in both likelihood and human evaluations. The hierarchical structure, with modules operating at different temporal resolutions, is a key innovation that enables SampleRNN to handle the high temporal resolution of audio data effectively. The paper also explores the impact of truncated backpropagation through time (TBPTT) and demonstrates that subsequence lengths as short as 512 samples (~32 ms) are sufficient for training, despite the long-range dependencies in the data.
Decision: Reject  
While the paper presents a promising approach with strong empirical results, several critical issues limit its acceptance. The lack of detailed architectural descriptions, insufficient discussion of counterintuitive results, and questionable baseline comparisons undermine the scientific rigor of the work.
Supporting Arguments:  
1. Architectural Details: The paper lacks sufficient detail about key architectural parameters, such as the "r" values and the number of units per layer. This omission makes it difficult to replicate the results or compare computational costs with other models like WaveNet.  
2. Baseline Comparisons: The surprising performance of the vanilla RNN (LSTM) over WaveNet raises concerns about the validity of the WaveNet reimplementation. The authors acknowledge computational constraints but fail to provide sufficient justification or discussion of how these constraints might have impacted the results.  
3. Counterintuitive Findings: The 2-tier SampleRNN outperforming the 3-tier model is unexpected, given the importance of long-range temporal correlations in audio. This result is not adequately discussed, leaving a gap in understanding the model's behavior.  
Additional Feedback:  
- Conditional Generation: The potential for conditional generation is an exciting avenue but is only briefly mentioned. A more thorough exploration or comparison with models like WaveNet in this context would strengthen the paper.  
- Upsampling Method: The choice of using separate linear projections for upsampling is not well-motivated. Alternative methods, such as linear interpolation or nearest neighbor upsampling, should be discussed.  
- 8-bit Encoding: The use of 8-bit linear PCM instead of mu-law encoding, which reportedly improves fidelity, is another missed opportunity for comparison.  
- Softmax for Discretized Input: The use of softmax lacks proper referencing, which could mislead readers into perceiving it as a novel contribution.  
Questions for Authors:  
1. Can you provide more details on the architectural parameters of SampleRNN, including the "r" values and the number of units per layer?  
2. How do you explain the counterintuitive performance of the 2-tier model over the 3-tier model?  
3. Could you clarify the computational differences between your WaveNet reimplementation and the original WaveNet? How might these differences have affected the results?  
4. Why was mu-law encoding not explored, given its reported benefits in prior work?  
In summary, while the paper introduces an innovative model with promising results, the lack of clarity in key areas and insufficient discussion of critical findings prevent it from meeting the standards for acceptance. Addressing these issues could significantly improve the paper's quality and impact.