Review of the Paper: Submodular Sum-Product Networks for Scene Understanding
Summary of Contributions
This paper introduces Submodular Sum-Product Networks (SSPNs), a novel extension of Sum-Product Networks (SPNs) tailored for scene understanding tasks. The key innovation lies in incorporating submodular unary and pairwise potentials into SPNs, enabling efficient parsing of images into arbitrary-shaped regions. The authors propose INFERSSPN, a new inference algorithm that leverages submodularity to compute the approximate MAP state of SSPNs efficiently. Empirical evaluations on the Stanford Background Dataset (SBD) demonstrate that INFERSSPN achieves comparable accuracy and energy to α-expansion while being exponentially faster. The paper also provides theoretical guarantees for the efficiency and convergence of INFERSSPN, making it a significant contribution to the field of structured probabilistic models.
Decision: Reject
While the paper presents a novel and promising extension of SPNs, it falls short in several critical areas that hinder its readiness for publication. Specifically, the lack of discussion on SSPN structure learning, limited experimental evaluations, and insufficient generative process details weaken the overall contribution.
Supporting Arguments for the Decision
1. Strengths:
   - The formulation of SSPNs is novel and addresses the intractability of traditional SPNs for complex tasks like scene understanding.
   - The proposed INFERSSPN algorithm is both theoretically sound and computationally efficient, with clear advantages over existing methods like α-expansion and belief propagation.
   - The empirical results on SBD demonstrate the practical utility of SSPNs, particularly in terms of inference speed.
2. Weaknesses:
   - Lack of Structure Learning: The paper does not address how the structure of SSPNs can be learned from data, which is a critical aspect of deploying the model in real-world applications. Without this, the proposed approach feels incomplete.
   - Limited Experimental Scope: The evaluations are restricted to the SBD dataset and do not include comparisons with other state-of-the-art methods or datasets like BSD for hierarchical segmentation. This limits the generalizability of the findings.
   - Generative Process Details: The paper briefly mentions the generative process of SSPNs but does not provide sufficient clarity or depth. This omission makes it difficult to fully understand the model's underlying assumptions and applicability.
Suggestions for Improvement
1. Expand Experimental Evaluations: Include additional datasets (e.g., BSD) and comparisons with more diverse baselines to demonstrate the robustness and generalizability of SSPNs.
2. Address Structure Learning: Provide a discussion or preliminary results on learning the structure of SSPNs from data. This would significantly enhance the practical relevance of the work.
3. Clarify Generative Process: Elaborate on the generative process of SSPNs, including how the grammar is constructed and its implications for different tasks.
4. Improve Exposition: Some parts of the paper, such as the explanation of the hierarchical parsing process, are confusing and require clearer illustrations and descriptions.
Questions for the Authors
1. How do you envision learning the structure of SSPNs in practice? Are there any preliminary results or insights you can share?
2. Why were datasets like BSD or other hierarchical segmentation benchmarks not included in the evaluation? How do you expect SSPNs to perform on these datasets?
3. Could you provide more details on the scalability of SSPNs with respect to grammar size and dataset complexity?
In conclusion, while the paper introduces a promising direction for extending SPNs, it requires additional work to address its current limitations and strengthen its experimental and theoretical contributions.