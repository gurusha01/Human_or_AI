Review of the Paper
Summary of Contributions
This paper introduces a novel framework for learning algorithmic tasks using neural networks, leveraging the divide-and-conquer principle. The authors propose a recursive architecture with two key components: a "split" module that partitions inputs and a "merge" module that combines outputs. The framework is designed to optimize not only for accuracy but also for computational complexity in a fully differentiable manner. The paper demonstrates the potential of this approach on tasks such as sorting and planar convex hulls, showing that the model can generalize to larger input sizes and operate with weak supervision (input-output pairs only). The authors argue that the scale-invariance property of their architecture enables parameter sharing across scales, facilitating efficient learning and generalization.
Decision: Reject
While the research direction is promising and addresses an important problem, the paper suffers from significant shortcomings that hinder its readability, clarity, and scientific rigor. The primary reasons for rejection are:
1. Lack of Clarity and Organization: The paper is difficult to read due to poor organization and inconsistent flow between high-level concepts and low-level implementation details.
2. Insufficient Motivation for Scale Invariance: The scale-invariance property, a cornerstone of the proposed method, is not well-motivated for many relevant problems, leaving its applicability unclear.
3. Incomplete Methodology: The explanation of how discrete choices in training are backpropagated is inadequate, which raises concerns about the scientific rigor of the proposed approach.
Supporting Arguments
1. Clarity and Presentation: The paper lacks a clear problem formulation and schematic overview, making it challenging to follow the proposed methodology. The absence of a tabular summary or illustrative examples of problems solved by the method further detracts from its readability.
2. Scientific Rigor: The methodology does not adequately explain how the discrete decisions in the split and merge operations are handled during backpropagation. While the authors mention weak supervision and scale invariance, the technical details provided are insufficient to evaluate the correctness and robustness of the approach.
3. Motivation and Applicability: The scale-invariance property is not convincingly justified for the tasks under consideration. Although the authors claim that this property enables generalization, its relevance to broader algorithmic tasks is unclear.
Additional Feedback for Improvement
1. Improve Readability: The paper would benefit from a major rewrite to improve its organization and clarity. A clear problem statement, a schematic overview of the architecture, and a tabular summary of the tasks and results should be included.
2. Motivate Scale Invariance: Provide a stronger theoretical or empirical justification for the scale-invariance property, particularly in the context of the tasks studied.
3. Clarify Methodology: Expand on how discrete choices in the split and merge operations are backpropagated. If approximations or assumptions are made, these should be explicitly stated and justified.
4. Include Examples and Results: Add illustrative examples of the problems solved by the method, along with a comparison to baseline approaches. This would help establish the practical utility of the proposed framework.
5. Address Disorganization: Avoid abrupt transitions between high-level concepts and low-level implementation details. Separate these sections clearly to maintain a logical flow.
Questions for the Authors
1. How does the proposed method handle the non-differentiability of discrete decisions in the split and merge operations? Are there any approximations or surrogate losses used?
2. Can you provide more examples of tasks where the scale-invariance property is critical for success? How does it compare to other inductive biases like translation invariance in CNNs?
3. How does the performance of your method compare to existing baselines for sorting and convex hull tasks, both in terms of accuracy and computational complexity?
In conclusion, while the paper explores an important and promising direction, its current form lacks the clarity, rigor, and motivation needed for acceptance. A major revision addressing these issues is necessary to make the contributions more accessible and scientifically robust.