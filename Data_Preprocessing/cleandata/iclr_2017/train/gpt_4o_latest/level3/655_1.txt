Review
Summary of Contributions
The paper proposes a novel distributed transfer learning framework for deep convolutional networks that addresses two key challenges: optimization complexity due to non-convexity and class imbalance between original and target domains. The authors introduce a re-weighting scheme inspired by Dempster-Shafer theory and the confusion matrix, which uses Basic Probability Assignment (BPA) to boost the performance of weak classifiers. Additionally, the paper suggests separately fine-tuning individual convolutional filters to reduce optimization complexity. Experimental results on MNIST, CIFAR, and SVHN datasets demonstrate consistent improvements over conventional transfer learning approaches.
Decision: Reject
The paper is rejected primarily due to (1) insufficient validation of its key claims and (2) poor presentation quality, which hinders comprehension. While the proposed re-weighting idea is interesting and has potential, the paper lacks the scientific rigor and clarity necessary for acceptance.
Supporting Arguments
1. Insufficient Validation of Claims:  
   - The necessity of separately learning convolutional filters to address non-convexity is not validated through an ablation study. Without such evidence, it is unclear whether this step is critical to the proposed method's success.
   - The explanation of using both training and validation sets to compute BPA is unconvincing. The paper does not provide a theoretical or empirical justification for this choice, leaving the approach's effectiveness in question.
2. Experimental Weaknesses:  
   - The handling of dataset differences (e.g., CIFAR's three-channel images vs. MNIST's single-channel images) is not explained, raising concerns about the reproducibility and fairness of the experiments.
   - While the experimental results show improvements, the paper does not compare its method against other state-of-the-art transfer learning techniques, making it difficult to assess its relative contribution.
3. Poor Writing and Presentation:  
   - The paper suffers from numerous typos and unclear explanations, particularly regarding the construction of training sets for weak classifiers. This significantly detracts from the reader's ability to understand and evaluate the proposed method.
   - Key details, such as the algorithm's computational complexity and scalability, are omitted.
Suggestions for Improvement
1. Validation and Analysis:  
   - Conduct an ablation study to demonstrate the necessity of separately learning convolutional filters. This would clarify the contribution of this step to the overall performance.
   - Provide a detailed justification for using both training and validation sets to compute BPA. Include experiments comparing this approach to alternatives (e.g., using only the training set).
2. Experimental Design:  
   - Clearly explain how dataset differences (e.g., image channels, resolution) are handled during experiments. This would improve transparency and reproducibility.
   - Compare the proposed method against state-of-the-art transfer learning techniques to contextualize its performance.
3. Writing and Presentation:  
   - Revise the paper to eliminate typos and improve clarity. Focus on clearly explaining the construction of training sets for weak classifiers and the overall methodology.
   - Include a discussion of the computational complexity and scalability of the proposed approach.
Questions for the Authors
1. Why is it necessary to separately learn convolutional filters? Could the same performance improvement be achieved with joint optimization?
2. How does the proposed method handle differences in dataset characteristics, such as the number of image channels or resolution?
3. Why is BPA computed using both training and validation sets? Would using only the training set lead to worse performance?
While the paper presents an interesting idea, it requires significant improvements in validation, experimental design, and presentation to meet the standards of the conference.