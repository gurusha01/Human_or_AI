Review of the Paper
Summary of Contributions
This paper proposes a novel statistical model for character-level language modeling, parameterized by a program in a domain-specific language (DSL). The approach combines DSL-based program synthesis with count-based parameter learning, distinguishing it from standard neural network methods like LSTMs. The authors highlight several advantages of their model, including faster query times, human interpretability, and the ability to easily add or remove training samples. Experimental results demonstrate strong performance on structured datasets (e.g., Linux Kernel), though the model lags behind neural methods on less structured tasks (e.g., Hutter Prize Wikipedia). The paper also provides a detailed description of the DSL syntax and discusses the synthesis procedure using Markov Chain Monte Carlo (MCMC) techniques.
Decision: Reject
While the paper introduces an innovative approach with promising results, it has significant shortcomings in contextualization, methodological clarity, and empirical rigor. These issues limit its potential impact and make it unsuitable for acceptance in its current form.
Supporting Arguments for Decision
1. Lack of Contextualization in Related Work: The paper does not adequately situate its contributions within the broader programming languages (PL) literature. While it references prior work on program synthesis and neural networks, it fails to provide a comprehensive comparison to existing DSL-based or hybrid approaches. This omission weakens the motivation for the proposed method.
2. Vague Description of the Synthesis Procedure: The MCMC-based synthesis process is only briefly described, leaving critical questions about its efficiency and scalability unanswered. Given the complexity of program synthesis, a more detailed explanation is necessary to evaluate the feasibility of the approach.
3. Empirical Results and Gaps: The model demonstrates strong performance on code modeling tasks but falls short on the Hutter task compared to neural methods. While the authors acknowledge this limitation, they do not provide sufficient analysis or discussion on why the model underperforms in unstructured settings or how it could be improved.
4. Missing Training Details: Table 1 lacks essential information about the hardware and training setup, making it difficult to reproduce the results or assess the computational efficiency of the proposed method.
Suggestions for Improvement
1. Enhance Related Work Section: Provide a more thorough discussion of prior work in DSL-based program synthesis and its applications to language modeling. Highlight how the proposed method advances the state of the art.
2. Clarify the Synthesis Procedure: Include a detailed explanation of the MCMC-based synthesis process, with specific examples and computational benchmarks. Address potential efficiency concerns explicitly.
3. Improve Human Interpretability Examples: The paper claims that the DSL-based model is human-interpretable but does not provide sufficiently compact or convincing examples. Adding clear, real-world examples of interpretable programs would strengthen this claim.
4. Expand Empirical Analysis: Investigate the reasons behind the performance gap on the Hutter task and explore potential extensions to improve results on unstructured datasets. Additionally, provide a more detailed comparison of the model's query time and memory usage against baselines.
5. Include Training Details: Update Table 1 to include hardware specifications, training time, and other relevant setup details to improve reproducibility.
Questions for the Authors
1. How does the expressiveness of the proposed DSL compare to other DSLs used in program synthesis tasks? Could the DSL be extended to handle more complex tasks without compromising efficiency?
2. What specific challenges did you encounter when applying the model to unstructured datasets like the Hutter Prize Wikipedia? How might these challenges be addressed in future work?
3. Could you provide a more detailed breakdown of the computational cost of the MCMC-based synthesis process? How does it scale with larger datasets or more complex DSLs?
In summary, while the paper introduces an innovative and potentially impactful approach, its current shortcomings in contextualization, methodological clarity, and empirical rigor prevent it from being accepted. Addressing these issues would significantly strengthen the paper and its contributions to the field.