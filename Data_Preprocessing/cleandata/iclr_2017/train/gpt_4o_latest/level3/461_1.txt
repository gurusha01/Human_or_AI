Review
Summary of Contributions
This paper introduces a semi-supervised learning approach called "self-ensembling," which leverages feature invariance to stochastic perturbations in neural networks. The authors propose two model variants: the Π-model, which enforces consistency within a single training step, and temporal ensembling, which aggregates predictions across epochs using exponential averaging. The approach is evaluated on CIFAR-10 and SVHN datasets, achieving state-of-the-art results in semi-supervised learning benchmarks. The method demonstrates robustness to corrupted labels and improves classification accuracy even in fully supervised settings. The simplicity and efficiency of the approach, combined with its ability to handle noisy labels, are notable strengths.
Decision: Accept
The paper is well-motivated, presents a novel yet simple approach, and demonstrates strong empirical results on standard benchmarks. However, the lack of experiments on larger datasets and limited exploration of data augmentations are areas for improvement.
Supporting Arguments
1. Specific Problem Tackled: The paper addresses the challenge of semi-supervised learning, where only a small portion of the training data is labeled. This is a critical problem in real-world applications where labeled data is scarce.
   
2. Motivation and Placement in Literature: The work is well-placed in the context of related literature, drawing connections to prior methods like the Γ-model, transform/stability loss, and bootstrapping. The authors clearly articulate how their approach simplifies and extends these methods, particularly through the use of temporal ensembling.
3. Empirical Support for Claims: The results on CIFAR-10 and SVHN are compelling, with significant reductions in error rates compared to prior methods. The robustness to corrupted labels is a valuable contribution, as demonstrated by experiments with varying levels of label noise. However, the absence of experiments on larger datasets like ImageNet limits the generalizability of the findings.
Suggestions for Improvement
1. Experiments on Larger Datasets: Extending the evaluation to larger, more complex datasets (e.g., ImageNet) would strengthen the paper's claims and demonstrate scalability in real-world scenarios.
   
2. Broader Data Augmentations: The experiments are limited to basic augmentations like translations and horizontal flips. Exploring more diverse augmentations (e.g., rotations, color jittering) could provide deeper insights into the method's robustness and generalization.
3. Analysis of Consistency Term: While the use of "dark knowledge" is acceptable, a more concrete analysis of the consistency term's effects on feature learning and decision boundaries would enhance the paper's theoretical contributions.
4. Comparison to GAN-based Methods: Given the recent success of GANs in semi-supervised learning, a direct comparison to GAN-based approaches would contextualize the performance of self-ensembling.
Questions for Authors
1. How does the method scale to larger datasets with millions of unlabeled samples? Have you tested the approach on datasets like ImageNet or similar?
2. Did you observe any limitations or failure modes in scenarios with extremely high label noise (e.g., >50%)?
3. Could the consistency term be extended to incorporate uncertainty estimates, as hinted at in the discussion of temporal ensembling?
In summary, this paper makes a strong contribution to semi-supervised learning with a simple and effective approach. Addressing the suggested improvements would make it even more impactful.