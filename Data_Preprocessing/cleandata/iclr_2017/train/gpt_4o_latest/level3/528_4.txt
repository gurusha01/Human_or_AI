The paper presents a novel exploration of designing differentiable programming languages to improve the success of gradient descent in learning programs from input-output examples. It proposes four key recommendations—automatic memory management, structured control flow, immutability of data, and type systems—drawing inspiration from functional programming. The authors empirically demonstrate that incorporating these features significantly enhances the success rate of learning programs compared to existing baselines. While the study is well-executed and provides valuable insights, it is heavily focused on programming language design, with limited emphasis on learning-specific contributions.
Decision: Reject
Key Reasons for Rejection:
1. Limited Learning-Specific Contributions: While the paper is novel in its focus on differentiable programming languages, its primary contributions lie in programming language design rather than advancing the state of machine learning. This makes it a better fit for a programming language or systems conference rather than ICLR, which emphasizes learning-specific innovations.
2. Dependency on Non-Public Tools: The reliance on Terpret, a tool that is not yet publicly available, raises concerns about reproducibility and accessibility for the broader research community.
Supporting Arguments:
- The paper provides a well-motivated discussion on the challenges of program synthesis and the potential of differentiable programming languages. However, the emphasis on programming language constructs (e.g., memory management, type systems) overshadows the learning aspects, such as generalization or robustness of the learned programs.
- The empirical evaluation is thorough, but the lack of comparison with non-code-generating alternatives (e.g., neural architectures for algorithm learning) limits the justification for the proposed setup.
- The results, while promising, do not clearly demonstrate how the proposed framework advances learning capabilities beyond traditional program synthesis methods like λ².
Additional Feedback for Improvement:
1. Clarify the Learning Contributions: The paper would benefit from a stronger focus on how the proposed recommendations impact learning performance, such as generalization to unseen data or scalability to more complex tasks.
2. Reproducibility: The authors should prioritize releasing Terpret or provide sufficient implementation details to ensure reproducibility.
3. Broader Comparisons: Including comparisons with non-code-generating models (e.g., Neural Turing Machines, Neural GPUs) would strengthen the case for the proposed approach.
4. Target Audience: The paper might be better positioned for a programming languages or systems conference, where its contributions to language design would be more appreciated.
Questions for the Authors:
1. How does the proposed framework compare with non-code-generating models in terms of generalization and learning efficiency?
2. Are there plans to release Terpret, and if so, when?
3. Can the authors provide more insight into the scalability of the approach for tasks involving more complex data structures or perceptual inputs?
While this paper offers a novel perspective on differentiable programming languages, its limited focus on learning-specific contributions and dependency on non-public tools make it a less suitable fit for ICLR. Addressing these concerns could significantly enhance its impact and relevance.