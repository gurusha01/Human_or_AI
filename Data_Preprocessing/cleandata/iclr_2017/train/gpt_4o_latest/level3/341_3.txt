Review of "Unsupervised Third-Person Imitation Learning"
Summary of Contributions
This paper introduces a novel approach to imitation learning, extending it to third-person scenarios where the demonstrator and learner operate from different perspectives. The primary contribution lies in leveraging adversarial training to develop a policy that is robust to perspective differences, enabling agents to learn from third-person demonstrations without requiring explicit state-action correspondences. The authors propose a domain-invariant feature extraction mechanism using adversarial domain confusion, combined with multi-time step inputs to improve learning stability. The method is validated on three simulated environments (Pointmass, Reacher, and Inverted Pendulum) and demonstrates competitive performance compared to first-person imitation learning and reinforcement learning baselines. The paper also highlights the sensitivity of the approach to hyperparameters and camera angle variations, providing insights into its robustness and limitations.
Decision: Accept
The paper makes a significant contribution to the field of imitation learning by addressing a novel and practical problem: unsupervised third-person imitation learning. The approach is well-motivated, builds on recent advances in adversarial training and imitation learning, and is clearly explained. The experimental results support the claims, demonstrating the feasibility of the proposed method and its competitiveness with existing baselines. However, there are areas for improvement, particularly in the presentation of results and additional comparisons, which could enhance the paper's impact.
Supporting Arguments
1. Novelty and Motivation: The problem formulation is novel and addresses a critical limitation of traditional imitation learning, which relies on first-person demonstrations. The connection to transfer learning and domain adaptation is well-articulated, and the use of adversarial training to achieve domain-invariant features is innovative.
2. Methodology: The proposed algorithm is clearly described, with a well-structured formulation that builds on prior work in generative adversarial imitation learning (GAIL). The use of domain confusion and multi-time step inputs is a thoughtful extension to handle third-person scenarios.
3. Experimental Validation: The experiments are comprehensive, covering multiple environments and providing insights into the algorithm's strengths and limitations. The comparisons with baselines, including reinforcement learning and first-person imitation learning, are appropriate and demonstrate the method's effectiveness.
Additional Feedback for Improvement
1. Comparative Analysis: The inclusion of additional comparisons in Figure 3, as suggested in the reviewer guidelines, would significantly enhance the paper's impact. Specifically:
   - Comparing third-person imitation learning with standard first-person imitation learning applied to the same agent (upper performance bound).
   - Evaluating the performance gap when applying first-person imitation learning data to a different agent.
   - Comparing third-person imitation learning with reinforcement learning using agent-specific data.
2. Clarity of Results: While the results are promising, the presentation could be improved. For instance, the reward scales in Figure 9 make it difficult to compare methods directly. Including normalized performance metrics or additional visualizations would help readers better interpret the results.
3. Generalization to Real-World Settings: The paper focuses on simulated environments with relatively simple tasks. While this is a reasonable starting point, discussing potential challenges and extensions to more complex, real-world domains (e.g., robotics) would strengthen the paper's broader applicability.
4. Code and Reproducibility: The inclusion of a GitHub link is commendable, but providing more details about the implementation (e.g., hyperparameters, training time) in the main text or appendix would improve reproducibility.
Questions for the Authors
1. How does the proposed method handle scenarios where the perspective differences are more extreme (e.g., significant occlusions or entirely different viewpoints)?
2. Could the approach be extended to handle multi-agent or collaborative third-person imitation learning tasks?
3. How does the method scale to higher-dimensional observation spaces, such as those encountered in real-world robotics or autonomous driving?
In conclusion, this paper addresses an important and underexplored problem in imitation learning, presenting a well-motivated and methodologically sound solution. With minor revisions to enhance the clarity and depth of the experimental analysis, this work has the potential to make a strong impact on the field.