Review of the Paper
Summary of Contributions
This paper presents an end-to-end image compression framework that extends rate-distortion optimization to deep neural network-based encoders/decoders and adaptive entropy coding. The authors explore connections to variational autoencoders (VAEs) and propose a biologically-inspired nonlinear transformation (Generalized Divisive Normalization, GDN) to improve compression performance. The method achieves better rate-distortion performance than JPEG and JPEG 2000, with significant improvements in visual quality, as supported by MS-SSIM evaluations. The paper also demonstrates the feasibility of the proposed method as a complete lossy compression system by reporting actual bit rates instead of entropy estimates.
Decision: Reject  
Key Reasons:
1. Limited Novelty: The core approach, including the use of GDN and end-to-end optimization for compression, has been previously published. The paper's focus on MSE instead of perceptual metrics (e.g., MS-SSIM) represents a step backward, especially given the authors' prior work on perceptual optimization.
2. Technical Issues: Equation 10 appears incorrect, as the partition function should depend on \( g_s(y; \theta) \), which undermines the equivalence to VAEs for non-Euclidean metrics. This error raises concerns about the theoretical rigor of the paper.
3. Unclear Contributions: The relative impact of adaptive entropy coding versus deeper encoders/decoders is insufficiently analyzed. The lack of detailed comparisons with prior work makes it difficult to assess the novelty and significance of the adaptive coder.
Supporting Arguments
1. Limited Novelty: While the use of GDN and deep neural networks for compression is effective, it has already been explored in prior work by the same authors. The decision to optimize for MSE instead of perceptual metrics is surprising and detracts from the potential impact of the work.
2. Empirical Performance: Despite the limitations, the method demonstrates superior performance compared to JPEG 2000 and other learned methods, particularly in terms of visual quality. However, the lack of perceptual evaluations beyond MS-SSIM (e.g., user studies or other perceptual metrics) weakens the claims of "dramatic improvement in visual quality."
3. Technical Concerns: The incorrect formulation of Equation 10 and the lack of clarity regarding the adaptive coder's contribution suggest that the theoretical and empirical aspects of the paper require further refinement.
Suggestions for Improvement
1. Clarify Contributions: The paper should explicitly disentangle the contributions of adaptive entropy coding and deeper encoders/decoders. Comparative experiments with prior work are necessary to highlight the novelty and significance of the proposed approach.
2. Perceptual Metrics: Given the authors' expertise, optimizing for perceptual metrics (e.g., MS-SSIM) instead of MSE would likely yield more impactful results. Including perceptual evaluations beyond MS-SSIM, such as user studies, would strengthen the claims of improved visual quality.
3. Technical Corrections: Address the issue with Equation 10 and ensure that the theoretical connections to VAEs are valid, particularly for non-Euclidean metrics.
4. Details on Adaptive Coder: Provide more implementation details and analysis of the adaptive entropy coder, including its impact on performance relative to existing methods.
Questions for the Authors
1. Can you clarify the role of adaptive entropy coding in the observed performance improvements? How does it compare to prior entropy coding methods?
2. Why was MSE chosen as the optimization metric, given that perceptual metrics like MS-SSIM are more aligned with visual quality?
3. How does the incorrect formulation of Equation 10 affect the validity of the results? Can you provide a corrected version and discuss its implications?
While the paper demonstrates strong empirical results, addressing the above concerns would significantly enhance its novelty, rigor, and overall impact.