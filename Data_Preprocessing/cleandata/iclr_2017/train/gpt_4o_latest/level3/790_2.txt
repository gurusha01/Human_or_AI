Review of the Paper
Summary of Contributions
The paper presents a novel exploration of applying adversarial training to cryptographic tasks, specifically focusing on the Alice-Bob-Eve communication scenario. The authors demonstrate that neural networks can learn to perform encryption and decryption tasks without being explicitly programmed with cryptographic algorithms. The work extends this idea to selective protection, where neural networks learn what information to encrypt to meet privacy goals while maximizing utility. The paper is well-written, with clear explanations of the concepts, prior literature, and experimental results. The proposed approach is creative and has potential implications for both cryptography and privacy-preserving machine learning.
Decision: Reject
While the paper introduces an interesting and innovative application of adversarial training to cryptography, the decision to reject is based on the following key reasons:
1. Unclear Experimental Setup: The experimental details in Section 3, particularly the role of Bob reconstructing D-public and how this differs from the scenario in Section 2, are insufficiently explained. This lack of clarity makes it difficult to evaluate the validity and generalizability of the privacy-related application.
2. Incomplete Results: The paper acknowledges that Eve should be stronger than Alice and Bob to compensate for the missing key, but results addressing this are not yet included. This omission weakens the empirical support for the claims.
Supporting Arguments
1. Unclear Experimental Setup: The privacy-related application in Section 3 introduces additional complexity, such as the generation of D-public and its interaction with Eve's objectives. However, the description of how Bob reconstructs D-public and how this differs from the symmetric encryption task in Section 2 is vague. Without a clear distinction, it is challenging to assess whether the proposed approach effectively addresses the stated goals of selective protection.
2. Eve's Strength: In cryptographic settings, adversaries are typically modeled as being as strong as possible within computational limits. The paper notes that Eve should be stronger than Alice and Bob but does not provide results for this scenario. This omission leaves a gap in the evaluation of the robustness of the proposed method.
3. Real-World Applicability: The paper assumes that the key length can be longer than the message length, which is uncommon in real-world cryptographic systems. While the authors argue that this likely does not affect the results, this assumption may limit the practical relevance of the work.
Additional Feedback for Improvement
1. Clarify Experimental Details: Provide a more detailed explanation of the experimental setup in Section 3, particularly the role of Bob and how D-public is reconstructed. Clearly distinguish this scenario from the symmetric encryption task in Section 2.
2. Strengthen Eve's Role: Include results where Eve is modeled as a stronger adversary, as this would better align with cryptographic standards and improve the robustness of the evaluation.
3. Address Key-Length Assumptions: Discuss the implications of the key length being longer than the message length in more detail, and consider experiments with shorter keys to evaluate the method's performance in more realistic settings.
4. Expand Real-World Applications: While the paper is exploratory, adding examples or discussions of potential real-world applications (e.g., privacy-preserving machine learning or secure multi-party computation) would enhance its impact and relevance.
Questions for the Authors
1. Can you provide more details on how Bob reconstructs D-public in Section 3? How does this differ from the symmetric encryption task in Section 2?
2. Have you considered experiments where Eve is given additional computational resources or training iterations to simulate a stronger adversary? If so, what were the results?
3. How does the assumption of longer key lengths affect the generalizability of the proposed method to real-world cryptographic systems?
4. Could you elaborate on the potential use cases for selective protection beyond the artificial dataset used in the experiments?
In summary, while the paper introduces a creative and promising approach, addressing the major concerns about the clarity of the experimental setup and the strength of the adversary is necessary for it to be ready for acceptance.