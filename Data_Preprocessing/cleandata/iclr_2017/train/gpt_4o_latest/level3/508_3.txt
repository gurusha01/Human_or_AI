Review of the Paper: Shift Aggregate Extract Networks (SAEN)
Summary of Contributions
This paper introduces the Shift Aggregate Extract Network (SAEN), a novel neural network architecture for learning hierarchical graph representations, specifically targeting social network data. The authors propose a method to decompose graphs into multi-level hierarchies (H-hierarchical decompositions) and compute vector representations for objects at each level using the Shift, Aggregate, and Extract (SAE) schema. Additionally, the paper presents a domain compression algorithm to exploit symmetries in hierarchical decompositions, reducing memory usage and computational runtime. Empirical evaluations on six social network datasets demonstrate competitive or superior performance compared to state-of-the-art methods, with significant runtime improvements due to compression.
Decision: Reject
The paper is not ready for publication in its current form due to critical issues in clarity, technical explanation, and experimental reproducibility. While the proposed ideas are promising, the lack of detailed descriptions and missing references for key components hinder a thorough evaluation of the approach.
Supporting Arguments for Decision
1. Clarity of Key Components: 
   - The R_l,π convolutions in Section 2.1 are poorly explained, particularly the role and meaning of the labels π. This ambiguity makes it difficult to understand the hierarchical decomposition process and its novelty compared to existing methods.
   - The SAEN structure in Section 2.2 is inadequately described. The choice to sum member representations in the "Shift" step, rather than averaging them, is not justified, leaving doubts about the rationale behind this design decision.
   - The compression technique in Section 2.3 is unintelligible. The assumption that multiple objects with identical representations can be collapsed without loss of information is not adequately supported or explained.
2. Experimental Reproducibility:
   - The "Ego Graph Neural Network" (EGNN) used in experiments is not sufficiently described or referenced. The lack of clarity about "ego graph patterns" and their role in the H-hierarchical decomposition prevents a proper assessment of the experimental setup.
   - While the paper claims state-of-the-art results, the absence of detailed hyperparameter tuning strategies and baseline comparisons for certain datasets weakens the empirical rigor.
3. Literature Placement:
   - The paper does not adequately position SAEN within the broader context of graph neural networks and graph kernels. While some related works are mentioned, the novelty of SAEN compared to existing hierarchical graph representation methods is not clearly articulated.
Suggestions for Improvement
1. Clarify Rl,π Convolutions: Provide a more detailed explanation of the Rl,π relations, including the role of π and how it contributes to the hierarchical decomposition. Use illustrative examples or diagrams to make this concept more accessible.
2. Improve SAEN Schema Description: Justify the design choices in the SAE schema, particularly the summation in the "Shift" step. Discuss alternative aggregation methods and their potential impact on performance.
3. Explain Domain Compression: Elaborate on the assumptions underlying the compression technique and provide theoretical or empirical evidence to validate its effectiveness.
4. Detail Experimental Setup: Include a comprehensive description of the "Ego Graph Neural Network" and its relevance to the experiments. Clearly outline the hyperparameters and baseline configurations for reproducibility.
5. Expand Related Work: Discuss how SAEN compares to other hierarchical graph neural networks and graph kernel methods, emphasizing its unique contributions.
Questions for the Authors
1. What is the specific role of the π labels in R_l,π convolutions, and how do they differ from traditional graph decomposition methods?
2. Why was summation chosen over averaging in the "Shift" step of the SAE schema? Have alternative aggregation methods been tested?
3. How does the domain compression technique handle cases where objects with identical representations may not be truly equivalent in the context of graph classification?
4. Can you provide more details or references for the "Ego Graph Neural Network" used in the experiments?
By addressing these issues, the paper could significantly improve its clarity, rigor, and impact.