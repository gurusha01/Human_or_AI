Review of the Paper
Summary of Contributions
This paper introduces the Hierarchical Compositional Network (HCN), a novel generative model designed to learn interpretable hierarchical template representations from binary image data without supervision. The HCN employs a directed graphical model with binary latent variables and utilizes max-product message passing (MPMP) for inference and learning. The authors demonstrate that HCN can disentangle compositional building blocks of binary images, offering a structured and interpretable representation. Notably, the HCN forward pass functionally resembles a convolutional neural network (CNN) with binary weights, enabling tasks such as classification, inpainting, and denoising. The paper also highlights the scalability challenges of the proposed method, particularly with larger datasets and natural images, and provides experimental results on small-scale synthetic and MNIST datasets.
Decision: Reject
The decision to reject is based on two primary concerns: (1) the limited scope of the experiments, which are restricted to small-scale binary data, raising questions about the scalability and applicability of the method to real-world, natural image datasets, and (2) insufficient discussion of related work, particularly grammar-based methods and other hierarchical feature learning approaches, which limits the contextualization of the proposed method within the broader literature.
Supporting Arguments
1. Strengths:
   - The paper proposes a novel approach to hierarchical feature learning using binary latent variables and MPMP, which is an interesting contribution.
   - The method demonstrates strong interpretability, with learned features that align with human intuition about compositional building blocks.
   - The connection between HCN and CNNs is insightful, offering a bridge between generative and discriminative models.
2. Weaknesses:
   - Experimental Limitations: The experiments are limited to small-scale synthetic datasets and MNIST, which are not representative of real-world image data. The scalability of the method to larger, more complex datasets remains unproven.
   - Clarity of Techniques: The technical details, particularly the intuitions behind the MPMP schedule and the hierarchical structure, are not adequately explained. This makes the method difficult to reproduce and understand for a broader audience.
   - Related Work: The paper does not sufficiently discuss related techniques, such as grammar-based methods and other hierarchical generative models. This omission weakens the paper's positioning within the existing literature.
   - Broader Applicability: The focus on binary data limits the generalizability of the method. While the authors briefly mention preprocessing for grayscale data, this aspect is not explored in depth.
Suggestions for Improvement
1. Scalability and Real-World Data: Extend the experimental evaluation to include larger and more complex datasets, such as natural images, to demonstrate the scalability and robustness of the method.
2. Clarity of Presentation: Provide clearer explanations of the MPMP schedule, the hierarchical structure, and the intuitions behind key design choices. Visual aids or pseudocode could help make these aspects more accessible.
3. Discussion of Related Work: Include a thorough discussion of grammar-based methods, AND-OR graphs, and other hierarchical generative models to better contextualize the contributions of the paper.
4. Broader Applicability: Explore extensions of the method to non-binary data, such as grayscale or RGB images, and evaluate its performance in these settings.
5. Efficiency: Address the computational complexity of the method, particularly the memory requirements for MPMP, and propose optimizations or approximations to make the approach more practical.
Questions for the Authors
1. How does the method scale to larger datasets and more complex images, such as natural images? Have any preliminary experiments been conducted in this direction?
2. Can the MPMP inference procedure be parallelized or optimized to reduce computational overhead?
3. How does the method compare to grammar-based approaches or AND-OR graphs in terms of both performance and interpretability?
4. Could the proposed method be extended to handle continuous or real-valued data directly, without relying on binary preprocessing?
5. What are the specific limitations of the method when applied to tasks beyond classification, such as inpainting or denoising, for real-world datasets?
In conclusion, while the paper presents an interesting and novel approach to hierarchical feature learning, its limitations in scalability, clarity, and contextualization within the literature prevent it from making a strong case for acceptance at this time. Addressing these issues in a future submission could significantly strengthen the work.