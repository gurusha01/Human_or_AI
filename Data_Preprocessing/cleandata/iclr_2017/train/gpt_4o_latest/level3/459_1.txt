Review of the Paper
Summary of Contributions
The paper proposes a novel framework for multi-task learning (MTL) using Tucker and Tensor Train low-rank tensor factorization to enable parameter sharing across tasks in deep neural networks. The authors aim to generalize shallow MTL approaches based on matrix factorization to deep learning by learning cross-task sharing structures at every layer in a data-driven manner. The framework is designed to handle both homogeneous and heterogeneous MTL settings, reducing the need for manual architecture design. Experimental results on datasets like MNIST, AdienceFaces, and Omniglot demonstrate the framework's efficacy in achieving better or comparable performance to user-defined MTL architectures and single-task learning (STL).
Decision: Reject  
Key Reasons:
1. Lack of Comparison with Shallow MTL Methods: The paper dismisses shallow MTL methods without providing sufficient empirical evidence to validate the superiority of the proposed deep learning approach. A direct comparison with shallow methods, particularly those using simpler regularizations like the nuclear norm, is missing.
2. Questionable Necessity of Deep Learning for Simple Tasks: The datasets used (e.g., MNIST) involve relatively simple classification tasks, raising doubts about whether deep learning is necessary or justified for these problems. The paper does not adequately address this concern.
Supporting Arguments
- Motivation and Literature Placement: While the paper is well-motivated in terms of addressing the limitations of user-defined sharing in deep MTL, it does not sufficiently position itself against shallow MTL methods. The claim that deep learning is inherently superior is not substantiated through rigorous comparisons.
- Empirical Validation: The experimental results focus on comparisons with STL and user-defined MTL architectures but omit a direct evaluation against shallow MTL methods. The authors briefly mention that shallow methods perform worse on MNIST, but this is based on outdated PCA features rather than modern CNN-based features, which undermines the argument.
- Scientific Rigor: The paper does not explore whether simpler regularizations like the nuclear norm could achieve similar results within a deep learning framework. This omission leaves the novelty and utility of the proposed tensor factorization approach partially unverified.
Suggestions for Improvement
1. Include Comparisons with Shallow MTL Methods: To strengthen the paper, the authors should include direct comparisons with state-of-the-art shallow MTL methods using modern feature representations (e.g., CNN features). This would provide a fairer evaluation of the proposed framework's benefits.
2. Clarify the Necessity of Deep Learning: The authors should justify the use of deep learning for simple datasets like MNIST by either demonstrating significant performance gains or showing that shallow methods fail to generalize in these settings.
3. Explore Simpler Regularizations: The paper could investigate whether simpler regularizations, such as the nuclear norm, can be extended to deep learning and how they compare to the proposed tensor factorization methods.
4. Provide More Theoretical Insights: The paper could benefit from a deeper theoretical analysis of why Tucker and Tensor Train decompositions are particularly well-suited for MTL in deep networks compared to other factorization methods.
Questions for the Authors
1. Why were shallow MTL methods not included in the experimental comparisons, especially with modern CNN-based features?
2. Can the proposed framework handle tasks with significantly different data distributions or complexities? If so, how does it compare to shallow methods in such scenarios?
3. Have you considered extending simpler regularizations like the nuclear norm to deep learning, and how would they compare to the proposed tensor factorization approach?
In conclusion, while the paper presents an interesting framework, the lack of comparisons with shallow methods and insufficient justification for the use of deep learning on simple tasks weaken its contributions. Addressing these gaps would significantly improve the paper's impact and clarity.