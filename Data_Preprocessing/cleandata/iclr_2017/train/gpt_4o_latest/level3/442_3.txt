Review of the Paper: "Deep Variational Information Bottleneck"
Summary of Contributions
The paper presents a novel application of the Information Bottleneck (IB) principle to deep neural networks, introducing the "Deep Variational Information Bottleneck" (Deep VIB). This approach leverages variational inference and the reparameterization trick to optimize the IB objective efficiently, enabling its application to high-dimensional, continuous data. The authors demonstrate that Deep VIB-trained models outperform other regularization techniques in terms of generalization and robustness to adversarial attacks. The paper also draws connections between VIB and Variational Autoencoders (VAEs), highlighting the differences in their objectives and interpretations. Experimental results on MNIST and ImageNet datasets showcase the effectiveness of the proposed method in classification tasks and adversarial robustness.
Decision: Reject
While the paper introduces a promising idea and provides strong experimental results, the presentation suffers from significant clarity issues, particularly in the mathematical derivations and notations. Additionally, the connection to prior work, such as Chalk et al. (2016), requires further scrutiny to ensure the claimed novelty. These issues undermine the accessibility and rigor of the paper, making it unsuitable for acceptance in its current form.
Supporting Arguments for Decision
1. Novelty and Experimental Results: The application of the IB principle to deep neural networks is commendable, and the experimental results are promising. The method demonstrates clear advantages over baseline regularization techniques, particularly in adversarial robustness. However, the novelty claim relative to Chalk et al. (2016) is not adequately substantiated. The authors should provide a more detailed comparison to ensure the originality of their contributions.
2. Clarity and Presentation: The paper's presentation is a major drawback. The use of notations (e.g., \(p\) and \(q\)) is inconsistent and confusing, particularly in the definitions of \(p(y|x)\) and \(q(y|z)\). This makes it difficult for readers to follow the derivations and understand the modeling procedure. Bayesian readers, in particular, may find the presentation uncomfortable due to the lack of clarity in the variational approximations and prior assumptions.
3. Connection to VAEs: While the connection between VIB and VAEs is intriguing, the differences between the two frameworks are not explained with sufficient intuition. A clearer exposition of how VIB extends or diverges from VAEs would strengthen the paper's theoretical contribution.
4. Typos and Errors: Several typos and inconsistencies were noted, including in Equations 9-11 (confusion between \(q(y|z)\) and \(q(z|y)\)) and Figure 2 (mislabeling of "smaller" vs. "larger"). These errors further detract from the paper's readability and rigor.
Suggestions for Improvement
1. Clarify Notations and Derivations: Revise the mathematical presentation to ensure consistency and clarity. Clearly define all terms and notations, and avoid contradictory definitions (e.g., \(p(y|x)\) as the predictive distribution).
2. Strengthen the Connection to Prior Work: Provide a detailed comparison to Chalk et al. (2016) and other related works to establish the novelty of the proposed method. This is critical for the paper's acceptance.
3. Improve the Explanation of VIB vs. VAE: Offer better intuition and theoretical insights into the differences between VIB and VAEs. Highlight the unique aspects of VIB that make it suitable for the proposed applications.
4. Address Typos and Errors: Carefully proofread the manuscript to eliminate typos and inconsistencies, particularly in equations and figures.
Questions for the Authors
1. Can you provide a more detailed comparison to Chalk et al. (2016) to clarify the novelty of your contributions?
2. How does the choice of variational approximations (e.g., \(q(y|z)\) and \(r(z)\)) affect the performance of VIB? Are there alternative approximations that could be explored?
3. Could you elaborate on the intuition behind the differences between VIB and VAEs, particularly in terms of their objectives and applications?
In summary, the paper introduces a promising approach with strong experimental results but requires significant improvements in clarity, rigor, and positioning within the literature. Addressing these issues would greatly enhance the paper's impact and accessibility.