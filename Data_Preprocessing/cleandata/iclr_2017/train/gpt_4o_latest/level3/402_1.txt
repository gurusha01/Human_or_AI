Review of the Paper
Summary of Contributions
This paper introduces HYPERBAND, a novel algorithm for hyperparameter optimization that leverages adaptive resource allocation to speed up random search. The authors claim HYPERBAND is simple, flexible, and theoretically sound, offering significant speedups over Bayesian optimization methods. The algorithm builds on the SUCCESSIVEHALVING framework and addresses the tradeoff between the number of configurations evaluated and the resources allocated per configuration. The paper provides empirical results across various machine learning tasks, demonstrating HYPERBAND's competitive performance, and briefly discusses its theoretical underpinnings.
Decision: Reject
The primary reasons for this decision are: (1) the experiments and comparisons are not conducted rigorously or fairly, and (2) the paper lacks clarity in its contributions, both theoretical and empirical. Below, I elaborate on these points.
Supporting Arguments
1. Unfair Experimental Comparisons:
   - The comparison between HYPERBAND and CVST is flawed as HYPERBAND was run for a shorter duration, leading to worse mean results. A fair comparison with equal runtimes is necessary to validate the claims of speedup and performance.
   - The inconsistent use of the parameter \( \eta \) in different experiments raises concerns about whether HYPERBAND's performance depends on careful tuning. The authors should evaluate the impact of using a consistent \( \eta \) value (e.g., \( \eta = 4 \)) across all experiments.
2. Unclear Contribution:
   - The paper does not clearly articulate whether its primary contribution is theoretical (e.g., bounds on performance) or empirical. The theoretical analysis is deferred to another paper, and the bounds presented are trivial to replicate. This lack of clarity diminishes the paper's novelty.
3. Performance Concerns:
   - HYPERBAND fails to outperform SUCCESSIVEHALVING with its most aggressive setting (\( b = 4 \)) in all experiments. This suggests that SUCCESSIVEHALVING is preferable in practice, undermining the paper's claim of HYPERBAND's superiority.
4. Omission of Relevant Comparisons:
   - The paper does not compare HYPERBAND to multi-task Bayesian optimization methods, which are closely related and have shown significant speedups in hyperparameter optimization. This omission weakens the empirical evaluation.
5. Overselling in the Introduction:
   - The introduction portrays HYPERBAND as a novel approach while ignoring prior work on multitask Bayesian optimization and adaptive resource allocation (e.g., Hoeffding Races). This misrepresentation detracts from the paper's credibility.
Suggestions for Improvement
1. Fair Comparisons:
   - Ensure that all algorithms are run for equal durations or budgets to provide a fair basis for comparison. Address the impact of varying \( \eta \) values explicitly and justify the chosen settings.
2. Clarify Contributions:
   - Clearly state whether the paper's primary contribution is theoretical, empirical, or both. If theoretical, include a detailed analysis; if empirical, ensure rigorous and comprehensive experiments.
3. Expand Related Work:
   - Include comparisons to multitask Bayesian optimization methods and prior work on adaptive resource allocation, such as Hoeffding Races. Acknowledge these works in the introduction to provide proper historical context.
4. Empirical Analysis:
   - Provide a deeper analysis of why HYPERBAND fails to outperform SUCCESSIVEHALVING in certain settings. Discuss the practical implications of this finding.
5. Theoretical Insights:
   - If theoretical bounds are a contribution, include a detailed derivation in the main paper rather than deferring it to another work. This will strengthen the paper's theoretical foundation.
Questions for the Authors
1. Why was HYPERBAND run for a shorter duration than CVST in the experiments? How would the results change with equal runtimes?
2. What is the rationale behind using different \( \eta \) values across experiments? Would a consistent \( \eta = 4 \) lead to more stable results?
3. Why were multitask Bayesian optimization methods excluded from the comparisons? How does HYPERBAND's performance compare to these methods?
4. Can you provide more details on the theoretical bounds for HYPERBAND? How do these bounds compare to those for SUCCESSIVEHALVING?
By addressing these concerns, the paper could significantly improve its rigor and impact. However, in its current form, the paper does not meet the standards for acceptance.