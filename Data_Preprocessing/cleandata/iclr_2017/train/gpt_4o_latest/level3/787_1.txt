Review of the Paper
The paper introduces the Semantic Embedding Model (SEM), a novel approach to multi-label classification that models labels as draws from a multinomial distribution, with parameters derived from nonlinear functions of instance features. Unlike previous methods, SEM assumes the underlying parameters of the labels are low-rank rather than the label matrix itself. The authors propose a Gauss-Siedel mini-batch adaptive gradient descent algorithm for training and introduce a marginal fitting strategy to handle large label sets efficiently. Experimental results on eight datasets are presented, claiming superior performance and faster training times compared to state-of-the-art methods.
Decision: Reject
While the paper is well-written and presents a clear methodology, the decision to reject is based on two primary reasons: (1) the lack of experimental significance in results compared to NNML and other baselines, particularly on large datasets, and (2) limited conceptual novelty, as the core ideas—low-rank assumptions and neural network-based modeling—are incremental extensions of prior work.
Supporting Arguments
1. Problem and Motivation: The paper addresses the scalability and accuracy challenges in multi-label learning. While the motivation to move beyond low-rank label matrix assumptions is valid, the distinction between low-rank label parameters and low-rank label matrices is not convincingly justified. The practical implications of this distinction remain unclear.
2. Experimental Results: The results on large datasets (e.g., Delicious, EurLex) do not demonstrate a clear and significant improvement over NNML or SLEEC. While SEM-K shows promise in some metrics, the gains are marginal and inconsistent across datasets. Furthermore, the comparison with NNML, a neural network-based baseline, is not thoroughly explored, especially given that SEM's training algorithm is more complex.
3. Conceptual Novelty: The use of a multinomial distribution and nonlinear mappings via neural networks is not a groundbreaking contribution. The proposed marginal fitting strategy for large label sets is a practical improvement but does not introduce fundamentally new ideas to the field.
Suggestions for Improvement
1. Clarify the Low-Rank Assumption: The paper should provide a deeper theoretical or empirical analysis of why assuming low-rank label parameters is advantageous over low-rank label matrices. This distinction needs to be substantiated with more compelling evidence.
2. Strengthen Experimental Comparisons: The results should include statistical significance tests to validate claims of superiority. Additionally, a more detailed analysis of SEM's performance relative to NNML, particularly in terms of computational complexity and scalability, would strengthen the paper.
3. Broaden Baseline Comparisons: While the authors compare SEM to state-of-the-art methods, including older baselines or simpler approaches could help contextualize the performance gains and highlight SEM's strengths.
4. Address Practical Implications: The paper should discuss the practical trade-offs of SEM's increased training complexity compared to simpler methods. For instance, how does SEM scale with extremely large datasets or high-dimensional feature spaces?
Questions for the Authors
1. Can you provide more insights into the practical benefits of assuming low-rank label parameters rather than low-rank label matrices? How does this assumption impact the model's generalization ability?
2. How does SEM compare to NNML in terms of training time and computational resource requirements, particularly for large datasets?
3. The marginal fitting strategy is an interesting addition. Could you elaborate on how the choice of β (number of negative labels) affects performance across datasets with varying label cardinalities?
4. Have you considered alternative nonlinear mappings (e.g., deeper architectures or other activation functions) for the instance-to-label latent space mapping? If so, how do they compare to the sigmoid-based approach?
In conclusion, while the paper presents a well-structured and methodologically sound approach, the lack of experimental significance and limited conceptual novelty make it unsuitable for acceptance in its current form. Addressing the above concerns could significantly strengthen the contribution.