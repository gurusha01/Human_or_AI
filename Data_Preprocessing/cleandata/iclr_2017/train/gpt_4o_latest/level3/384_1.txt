The paper presents an end-to-end neural architecture for machine comprehension of text, combining Match-LSTM for question-text representation and Pointer Networks (Ptr-Net) for answer location prediction. The authors propose two models: a sequence model that generates answers token by token and a boundary model that predicts the start and end positions of the answer span. The approach demonstrates significant improvements over prior work on the SQuAD dataset and achieves state-of-the-art performance on the MSMARCO dataset. The paper also provides insights into the attention mechanism and its role in reasoning.
Decision: Accept
Key Reasons for Decision:
1. Relevance and Contribution: The proposed method is well-aligned with the task of machine comprehension and introduces a novel combination of Match-LSTM and Ptr-Net. The boundary model, in particular, addresses the early stop prediction problem of the sequence model, showcasing moderate novelty.
2. Empirical Strength: The results on SQuAD and MSMARCO datasets are compelling. The boundary model achieves performance close to the state-of-the-art on SQuAD and outperforms existing methods on MSMARCO, demonstrating the effectiveness of the approach.
Supporting Arguments:
- The paper provides a thorough evaluation on two challenging datasets, with significant improvements over baseline methods. The inclusion of ablation studies and visualizations of attention weights adds credibility to the claims.
- The task framing and methodology are well-motivated, leveraging recent advances in neural architectures for text understanding. The integration of Match-LSTM and Ptr-Net is a logical and effective choice for the problem.
- The boundary model's ability to overcome the early stop issue in the sequence model is a notable contribution.
Additional Feedback for Improvement:
1. Generalizability: The paper does not address how the proposed models would perform in scenarios where the answer is not part of the input text. Future work could explore adaptations for such cases.
2. Dataset Generalization: While the results on SQuAD and MSMARCO are strong, it is unclear how well the models generalize to other datasets. Testing on additional datasets would strengthen the claims of robustness.
3. Experimental Design: The exclusion of the best-performing Bi-Ans-Ptr model from the ensemble evaluation is not justified. Clarifying this decision would improve the experimental rigor.
4. Related Work Discussion: The paper could draw parallels with tasks like visual question answering and query localization in images, which share conceptual similarities. This would provide a broader context for the proposed approach.
5. Typographical Error: There is a minor typographical error on Page 6, last paragraph ("missing '.'"), which should be corrected.
Questions for Authors:
1. Can the proposed models be adapted to handle questions where the answer is not explicitly present in the input text? If so, how?
2. Why was the Bi-Ans-Ptr model excluded from the ensemble evaluation? Would its inclusion improve the results further?
3. Have you tested the models on datasets beyond SQuAD and MSMARCO? If not, do you plan to explore this in future work?
In summary, the paper presents an interesting and well-executed approach to machine comprehension, with strong empirical results and moderate novelty. Addressing the concerns about generalizability and experimental design would further enhance its impact.