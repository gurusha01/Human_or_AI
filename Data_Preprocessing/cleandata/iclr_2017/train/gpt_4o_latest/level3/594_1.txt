Review of the Paper
Summary of Contributions
The paper proposes the use of low-rank and low-rank plus diagonal matrix parameterizations in Passthrough Networks, including GRUs and Highway Networks, as a means to reduce parameter complexity while maintaining memory capacity. It introduces a "Passthrough Framework" to describe feedforward and recurrent networks, aiming to unify architectures like LSTMs, GRUs, and Highway Networks under a common principle. The authors present empirical evaluations on tasks such as sequential MNIST, memory/addition tasks, and character-level language modeling on the Penn Treebank dataset. Notably, the paper reports competitive results on sequential MNIST and claims near state-of-the-art performance on memory tasks, albeit with significantly more parameters than baseline models like uRNN.
Decision: Reject  
While the paper introduces an interesting low-rank parameterization approach and achieves promising results on sequential MNIST, the overall contribution lacks sufficient novelty, and the empirical evaluation is unconvincing due to missing baselines, unfair comparisons, and unclear experimental setups.
Supporting Arguments for Decision
1. Novelty and Motivation:  
   The "Passthrough Framework" is not sufficiently novel, as it largely reiterates existing principles underlying LSTMs, GRUs, and Highway Networks. The proposed low-rank parameterization builds on prior work (e.g., Sak et al., 2014) but does not introduce a fundamentally new concept or demonstrate a clear theoretical advantage over existing methods.
2. Empirical Evaluation:  
   - The experiments lack rigor in several areas. For example, the Highway Network experiments do not include baseline comparisons, making it difficult to assess the impact of low-rank parameterization.  
   - The evaluation on the Penn Treebank dataset uses a different setup from prior works, preventing direct comparisons. Additionally, the reported perplexity is relatively high, suggesting suboptimal performance.  
   - Claims of state-of-the-art performance on memory tasks are undermined by the use of significantly more parameters than uRNN, making the comparisons unfair. Furthermore, the absence of baseline and uRNN curves in the memory/addition task results reduces clarity.  
3. Clarity and Practical Guidance:  
   The paper does not provide clear guidelines on when to use low-rank versus low-rank plus diagonal parameterizations. This lack of practical insight limits the applicability of the proposed methods.
Suggestions for Improvement
1. Strengthen Novelty:  
   Clearly articulate how the "Passthrough Framework" advances the understanding of existing architectures and why low-rank parameterization is a significant contribution beyond prior work. Consider including theoretical analysis to support the benefits of the proposed approach.
2. Improve Experimental Rigor:  
   - Include baseline comparisons for all tasks, particularly for Highway Networks and Penn Treebank experiments.  
   - Use consistent experimental setups to enable fair comparisons with prior work. For example, align the Penn Treebank evaluation with standard practices in the literature.  
   - Provide detailed results, including baseline and uRNN curves, for memory and addition tasks to improve clarity and reproducibility.
3. Practical Insights:  
   Offer guidelines or heuristics for selecting between low-rank and low-rank plus diagonal parameterizations. This would make the proposed approach more actionable for practitioners.
4. Address Parameter Efficiency:  
   Explore ways to achieve competitive performance with fewer parameters, particularly in memory tasks, to enable fairer comparisons with lightweight models like uRNN.
Questions for the Authors
1. How does the proposed low-rank parameterization compare to other parameter-efficient methods, such as sparsity-inducing techniques or structured matrix approaches?  
2. Can you provide more detailed insights into the trade-offs between low-rank and low-rank plus diagonal parameterizations?  
3. Why were baseline comparisons omitted for Highway Networks and Penn Treebank experiments?  
4. Could you clarify the rationale for using a different setup for Penn Treebank evaluation, and how this impacts the reported perplexity?  
By addressing these concerns, the paper could significantly improve its impact and clarity.