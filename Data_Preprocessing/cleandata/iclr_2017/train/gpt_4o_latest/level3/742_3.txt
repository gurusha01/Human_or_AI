Review
Summary of Contributions
This paper investigates the expressivity of deep neural networks by introducing the concept of trajectory length as a measure of expressivity. The authors theoretically and empirically demonstrate that trajectory length grows exponentially with network depth, linking it to other expressivity measures such as neuron transitions, activation patterns, and dichotomies. The paper also explores the implications of these findings for trained networks, suggesting that earlier layers have a greater influence on expressivity, supported by experiments on MNIST and CIFAR-10. Additionally, the paper highlights a trade-off during training between input-output map stability and expressivity.
Decision: Reject
The paper introduces a novel and potentially impactful concept—trajectory length as a measure of expressivity—but suffers from significant clarity issues and incomplete theoretical rigor. The lack of clear definitions, ambiguous notations, and missing proofs for key theorems (e.g., Theorem 4) undermine the paper's scientific rigor. Furthermore, the practical implications of trajectory length for neural network design and training are not well articulated, limiting its significance.
Supporting Arguments for Decision
1. Clarity Issues: The paper is difficult to follow due to unclear motivations in the introduction and ambiguous definitions throughout. For example, the definition of a 1D input trajectory is missing, and the notations in Theorem 2's proof are inconsistent, making it challenging to verify the claims.
2. Incomplete Theoretical Rigor: Theorem 4's proof is missing, and its relationship to Theorem 6 in the appendix is unclear. This omission raises concerns about the validity of the results. Additionally, the recursion in Theorem 2 is difficult to interpret due to inconsistent variable definitions (e.g., T and t).
3. Limited Practical Significance: While trajectory length is a novel concept, its practical implications for neural network design, training, or architecture optimization are not clearly articulated. The experiments on MNIST and CIFAR-10 are interesting but do not provide sufficient evidence to generalize the findings to broader settings.
Suggestions for Improvement
1. Improve Clarity: Clearly define key terms such as "1D input trajectory" and ensure consistent notations throughout the paper. Revise the introduction to better motivate the study and articulate the practical significance of trajectory length.
2. Complete Theoretical Proofs: Include the missing proof for Theorem 4 in the main text and clarify its relationship to Theorem 6 in the appendix. Ensure that all proofs are self-contained and accessible to the reader.
3. Strengthen Practical Implications: Provide a more detailed discussion of how trajectory length can inform neural network design or training strategies. For example, elaborate on how the findings could inspire new initialization schemes or pre-training methods.
4. Clarify Experimental Results: Address the potential confound in Figures 8 and 9, where the reduction in trajectory length during training may simply reflect the network becoming contractive, aligning with prior work. Explain how this aligns or diverges from existing literature.
Questions for the Authors
1. Can you provide a precise definition of a 1D input trajectory and clarify its role in your theoretical analysis?
2. Is Theorem 4 in the main text the same as Theorem 6 in the appendix? If so, why is the proof missing in the main text?
3. How do you address the potential confound that the reduction in trajectory length during training may simply reflect contraction rather than a novel phenomenon?
4. Can you elaborate on how trajectory length could be used to design better architectures or training methods, beyond the preliminary suggestions in the conclusion?
While the paper introduces a novel concept with potential, addressing the above issues is critical for its acceptance in a future iteration.