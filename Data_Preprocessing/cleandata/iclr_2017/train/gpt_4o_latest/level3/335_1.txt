Review of the Paper
Summary of Contributions
This paper introduces an information-theoretic framework for unsupervised learning of representations, leveraging the infomax principle to maximize mutual information (MI) between input and output. The authors propose a two-step algorithm: first, a hierarchical infomax approach to decouple the global objective into analytically solvable subgoals, and second, a gradient descent-based refinement to optimize the final objective. The method is demonstrated to work with complete, overcomplete, and undercomplete bases, and experimental results show its robustness and efficiency in learning representations from datasets like natural images and MNIST. The paper also highlights the biological plausibility of the model, incorporating constraints like membrane noise and energy limitations, and suggests potential extensions to deep networks.
Decision: Reject
While the paper presents an interesting framework and demonstrates promising results, several critical issues prevent its acceptance in its current form. These include a lack of clarity in presentation, insufficient justification for key claims, and gaps in theoretical rigor.
Supporting Arguments for Decision
1. Clarity and Presentation: The paper is dense with mathematical derivations, which overshadow the high-level intuition and motivation behind the proposed framework. For a broader audience, the authors should prioritize clear explanations of the core ideas and their implications before delving into technical details. For example, the hierarchical infomax approach and its biological relevance deserve more intuitive exposition in the main text.
2. Unsubstantiated Claims: The claim that maximizing \(I(X;R)\) also maximizes \(I(X; Y^U)\) is not adequately justified. The paper relies on approximations and assumptions (e.g., Proposition 1) that require further clarification and empirical validation. Additionally, the connection between dropout and the rank reduction of the weight matrix is mentioned but not rigorously explained or experimentally validated.
3. Theoretical Gaps: The assertion of obtaining an "optimal solution" for \(C\) in specific cases is misleading, as the presence of nonconvex constraints typically guarantees only local optima. This needs to be rephrased to avoid overclaiming.
4. Empirical Comparisons: While the proposed method is compared against existing approaches like ICA and sparse RBMs, the experimental results lack sufficient statistical rigor. For instance, it is unclear how hyperparameters were tuned across methods or whether the comparisons were conducted under equivalent conditions.
Additional Feedback for Improvement
1. Improve Accessibility: Introduce a dedicated section or subsection summarizing the intuition behind the hierarchical infomax approach and its advantages over existing methods. This will help readers unfamiliar with the mathematical details to grasp the significance of the work.
2. Clarify Dropout Connection: The link between dropout and rank reduction of the weight matrix is intriguing but underexplored. Provide a detailed explanation or experimental evidence to substantiate this connection.
3. Refine Claims: Reframe statements about "optimal solutions" to reflect the limitations imposed by nonconvexity. For example, clarify that the method provides a good approximation to the global optimum rather than guaranteeing it.
4. Expand Experiments: Include additional experiments to address the robustness of the method under varying conditions, such as noisy inputs or different datasets. Statistical analyses (e.g., confidence intervals) should accompany performance metrics to strengthen empirical claims.
Questions for the Authors
1. Can you provide a more detailed justification for the claim that maximizing \(I(X;R)\) also maximizes \(I(X; Y^U)\)? Are there specific conditions under which this equivalence holds?
2. How does the proposed method handle cases where the initial approximation from hierarchical infomax is far from the global optimum? Are there mechanisms to escape poor local optima?
3. Could you elaborate on the connection between dropout and rank reduction of the weight matrix? Is there empirical evidence supporting this claim?
4. How were hyperparameters tuned for the comparative methods in the experiments? Were the same datasets and preprocessing steps used across all methods?
In conclusion, while the paper proposes a novel and biologically inspired approach to unsupervised learning, significant revisions are needed to address clarity, rigor, and empirical validation before it can be considered for acceptance.