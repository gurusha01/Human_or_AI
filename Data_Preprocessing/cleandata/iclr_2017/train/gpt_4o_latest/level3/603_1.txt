Review of the Paper
Summary of Contributions
The paper addresses the problem of code completion for dynamically typed programming languages, specifically JavaScript, by proposing an LSTM-based model that traverses the Abstract Syntax Tree (AST) in a depth-first manner. The authors claim that their approach improves upon state-of-the-art decision-tree-based methods by achieving higher accuracy in next non-terminal and next terminal prediction tasks. The paper also explores joint prediction of non-terminals and terminals, as well as denying prediction for rare tokens (UNK). The results demonstrate modest improvements in prediction accuracy and runtime feasibility, suggesting the potential for real-time integration into IDEs. The authors position their work as a step toward leveraging deep learning for program synthesis and intelligent code completion.
Decision: Reject  
While the paper demonstrates incremental improvements over prior methods, it lacks sufficient novelty and depth to justify acceptance as a full paper. The proposed LSTM-based approach is a relatively straightforward application of existing techniques, and the claims of novelty, particularly regarding AST traversal and conditioning mechanisms, are not well-supported by the literature review or experimental results.
Supporting Arguments for Decision
1. Limited Novelty: The use of LSTMs for code completion is not novel, and the paper does not significantly advance the state of the art in terms of methodology. The depth-first traversal of the AST is a natural extension of prior work, and the paper does not explore alternative traversal strategies or architectures that could provide deeper insights or innovations.
   
2. Vague and Inaccurate Claims: The claim that prior methods examine only a limited subset of source code is misleading, as many existing approaches can condition on the entire AST. This undermines the paper's positioning of its contribution as a significant departure from prior work.
3. Evaluation Gaps: While the results show modest improvements in accuracy, the evaluation lacks critical metrics such as P(accurate | UNK is not ground truth), which would provide a clearer picture of the model's performance on non-UNK tokens. Additionally, the experiments do not explore the impact of alternative traversal orders or methods for handling UNK tokens, which could have strengthened the contribution.
4. Incremental Contribution: The improvements over state-of-the-art methods, while measurable, are relatively small (e.g., 3.8 points for non-terminals and 0.5 points for terminals). These gains, while useful, do not justify the paper as a significant contribution to the field.
Suggestions for Improvement
1. Explore Alternative Traversal Orders: The paper could investigate whether different traversal strategies (e.g., breadth-first or post-order) yield better results or provide additional insights into the code completion problem.
2. Address UNK Tokens More Robustly: The handling of UNK tokens is underexplored. The authors could experiment with more sophisticated mechanisms, such as subword tokenization or external knowledge bases, to improve predictions for rare tokens.
3. Clarify Claims: The authors should revise their claim about prior methods' limitations to accurately reflect the capabilities of existing approaches. This would strengthen the paper's positioning and avoid misleading comparisons.
4. Additional Metrics: Including metrics like P(accurate | UNK is not ground truth) would provide a more nuanced understanding of the model's strengths and weaknesses.
5. Broader Contextualization: The paper could benefit from a more thorough discussion of how its approach fits into the broader landscape of program synthesis and intelligent code completion, as well as its limitations and potential future directions.
Questions for the Authors
1. How does the proposed depth-first traversal compare to other traversal strategies in terms of prediction accuracy and runtime performance?
2. Can you provide additional evidence to support the claim that prior methods condition on only a limited subset of source code?
3. How does the model perform on non-UNK tokens specifically, and how does this compare to state-of-the-art methods?
4. Have you considered using subword tokenization or other techniques to address the challenges posed by rare tokens (UNK)?
5. What are the practical implications of the modest accuracy improvements for real-world IDE usage? Would these gains be noticeable to developers? 
This feedback is intended to help the authors refine their work and strengthen its contributions. While the current submission is not ready for acceptance, the problem addressed is important, and further exploration of the suggested directions could yield a more impactful contribution.