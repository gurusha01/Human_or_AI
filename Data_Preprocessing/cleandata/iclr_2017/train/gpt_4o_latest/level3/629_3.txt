Review
The paper presents an intriguing exploration of the parallels between image representations in convolutional neural networks (CNNs) and human visual psychophysics. The authors investigate whether the computations in CNNs trained on large-scale image recognition tasks exhibit similarities to human perceptual processes. Key findings include the predictive power of mean L1 distance in certain CNN layers for human noise-detection thresholds, the alignment of mutual information between CNN activations and human task difficulty in two-alternative forced-choice (2-AFC) experiments, and the reproduction of the bandpass nature of human contrast sensitivity in CNNs. These results suggest that CNNs may converge on computational principles similar to those underlying human perception, raising important questions about the relationship between artificial and biological vision systems.
Decision: Accept  
Key reasons for this decision include the paper's novel and well-motivated approach to bridging human psychophysics and CNN computations, as well as its scientifically rigorous results that are supported by empirical evidence. The updated version of the paper, which incorporates baseline models and training stage comparisons, strengthens the study's contributions and adds depth to the analysis.
Supporting Arguments  
The paper is well-placed in the literature, building on prior work that explores the convergence of biological and artificial vision systems. The authors employ a robust methodology, using psychophysical data and carefully controlled experiments to draw meaningful comparisons between CNNs and human perception. The inclusion of baseline models and comparisons across training stages enhances the validity of the findings and addresses initial concerns about anecdotal evidence. The results are compelling, particularly the demonstration of mid-computation layers in CNNs aligning with human perceptual sensitivity and the emergence of bandpass contrast sensitivity in CNNs. These findings contribute to both the fields of computer vision and cognitive neuroscience.
Additional Feedback  
While the paper is a strong contribution, there are areas for improvement. First, the authors should delve deeper into the CNN-specific aspects driving the observed results. For instance, what architectural or training features of CNNs lead to their alignment with human perception? Second, the paper would benefit from a discussion of deviations from prior studies on CNN performance and biological vision prediction, as this could contextualize the findings more effectively. Third, the authors should clarify the implications of the observed discrepancies, such as the lack of strong CNN correlates for 3D perception and symmetry, and explore whether these limitations stem from the feedforward nature of the networks.
Questions for the Authors  
1. Could you elaborate on the specific architectural features or training regimes of CNNs that might drive the observed similarities with human perception?  
2. How do your findings compare with prior studies that have reported discrepancies between CNNs and biological vision systems?  
3. Could the inclusion of recurrent architectures or unsupervised learning paradigms address the limitations observed in tasks involving 3D perception or symmetry?  
4. How robust are your findings across different datasets or tasks beyond those tested in this study?
Overall, this paper provides a meaningful contribution to understanding the intersection of artificial and biological vision systems. The suggested improvements and questions are intended to further refine and expand the scope of this promising research.