Review
Summary of Contributions
The paper systematically investigates retraining methods, specifically the Robust Adversarial Defense (RAD) and Improved AutoEncoder stacked with Classifier (IAEC), to enhance the robustness of classification networks against adversarial examples. The authors claim that RAD and IAEC outperform prior distillation-based retraining methods, achieving lower error rates and demonstrating resilience against a variety of adversarial attacks, including black-box attacks. The study introduces a cross-model evaluation framework to assess the generalization ability of defensive strategies and highlights the robustness of RAD and IAEC without introducing additional vulnerabilities. The experiments are conducted on MNIST and CIFAR-10 datasets, and the results suggest that RAD, in particular, is a promising direction for building universal defenses against adversarial examples.
Decision: Reject  
While the paper addresses an important problem and proposes promising methods, the lack of clarity, insufficient elaboration on key techniques, and incomplete performance comparisons undermine its overall impact. These issues make it challenging to fully assess the scientific rigor and contributions.
Supporting Arguments
1. Clarity and Cohesion: The paper lacks a cohesive narrative, making it difficult to follow the progression of ideas. While the results are listed, the connection between the methods, experiments, and conclusions is not clearly articulated. For example, the distinction between RAD and IAEC is not sufficiently emphasized, and the rationale for their design choices is underexplored.
   
2. Details of Methods: The descriptions of RAD and IAEC are insufficiently detailed. For instance, the construction of the autoencoder in IAEC and the role of the cross-entropy regularizer are not explained with enough depth. Diagrams or visualizations of the architectures could significantly aid understanding. Additionally, the iterative process of RAD and its convergence properties are only briefly mentioned without adequate theoretical or empirical justification.
3. Performance Comparisons: While the authors claim that RAD and IAEC outperform other methods, the performance comparisons are incomplete. For example, the paper does not provide a clear, side-by-side comparison of error rates across all methods for each dataset. Furthermore, the evaluation metrics for robustness (e.g., distortion required to mislead the classifier) are not consistently reported for all baselines.
4. Empirical Rigor: The cross-model evaluation and robustness against additional attacks are interesting contributions, but the experimental setup lacks sufficient detail. For instance, how the adversarial examples are distributed across training and testing phases is unclear. Additionally, the claim that RAD generalizes well across adversarial models is not fully substantiated with quantitative evidence.
Suggestions for Improvement
1. Clarity and Structure: Reorganize the paper to provide a clearer narrative. Begin with a concise problem statement, followed by detailed descriptions of RAD and IAEC, and then present the experimental results in a structured manner. Use diagrams to illustrate the architectures and workflows of RAD and IAEC.
2. Elaboration on Methods: Provide more details on the construction of RAD and IAEC, including the autoencoder architecture, the role of the cross-entropy regularizer, and the iterative retraining process. Include theoretical insights or proofs to support claims about convergence and robustness.
3. Comprehensive Comparisons: Include a clear table summarizing the performance of RAD, IAEC, and other baselines across all datasets and adversarial models. Ensure that all evaluation metrics, such as error rates and distortion thresholds, are consistently reported.
4. Experimental Details: Clarify the experimental setup, including how adversarial examples are generated and distributed. Provide more insights into the trade-offs between robustness and accuracy on clean data.
Questions for the Authors
1. Can you provide a detailed explanation of the autoencoder architecture used in IAEC, along with a diagram? How does the cross-entropy regularizer improve robustness?
2. How does RAD handle the trade-off between robustness and accuracy on clean data? Are there specific scenarios where RAD fails?
3. Can you include a more comprehensive comparison of RAD and IAEC with other retraining techniques, such as adversarial training and distillation, using consistent metrics?
4. How does the iterative retraining process in RAD converge, and what guarantees can you provide regarding its robustness?
By addressing these issues, the paper could significantly improve its clarity, rigor, and impact.