Review of the Paper
Summary of Contributions
This paper introduces a multi-view Bayesian non-parametric algorithm for learning multi-sense word embeddings by leveraging multilingual corpora. The key contributions are twofold: (1) the use of multilingual (more than two languages) distributional signals to improve sense disambiguation, and (2) a principled approach to infer a variable number of senses per word in a data-driven manner. The authors claim that their model achieves competitive performance on word sense induction (WSI) tasks using significantly less data compared to monolingual models. The paper also provides computational linguistics insights, such as the observation that less English-similar languages contribute more to disambiguation. The experimental results demonstrate improvements over baselines on intrinsic benchmarks, with qualitative analyses supporting the benefits of multilingual training.
Decision: Reject
While the paper presents an interesting and potentially impactful idea, it does not meet the standards for acceptance due to the following key reasons:
1. Lack of Clarity and Baseline Comparisons: The paper is difficult to follow, especially in its technical sections, and does not provide a clear comparison with the baseline model [1]. This makes it challenging to assess the true significance of the proposed approach.
2. Experimental Design Limitations: The proposed model is only a slight variation of prior work, and the experimental setup does not isolate which components (e.g., multilingual signal, Bayesian non-parametrics) drive the observed improvements. Additionally, a suggested baseline—training the baseline model [1] on pseudo-monolingual data—was not included, which would have provided a fairer comparison.
Supporting Arguments
- The observation that less English-similar languages contribute more to sense disambiguation is intriguing and aligns with prior linguistic studies. However, this insight is not explored in sufficient depth or validated rigorously.
- While the paper demonstrates improvements on intrinsic tasks like WSI, it does not evaluate the embeddings on downstream tasks, which limits its practical impact. Demonstrating utility in real-world NLP applications would have strengthened the paper.
- The qualitative analysis and PCA visualizations are helpful but are not sufficient to compensate for the lack of rigorous quantitative comparisons.
Suggestions for Improvement
1. Clarity and Presentation: The paper should be significantly revised for clarity, particularly in the technical sections. A more structured explanation of the model and its components would make the work accessible to a broader audience.
2. Baseline Comparisons: Include the suggested baseline of converting multilingual data to monolingual using alignment and training the baseline model [1] on this pseudo-monolingual data. This would isolate the contribution of multilingual signals.
3. Component Ablation: Conduct ablation studies to determine the impact of each component (e.g., multilingual signal, Bayesian non-parametrics) on the observed improvements.
4. Downstream Task Evaluation: Demonstrate the utility of the proposed embeddings on downstream NLP tasks, such as machine translation or semantic parsing, to establish broader applicability.
5. Language Family Analysis: While the paper discusses the effect of language family distance, a more systematic analysis with additional languages and domains would strengthen this claim.
Questions for the Authors
1. How does the proposed model compare to the baseline [1] when trained on pseudo-monolingual data created from multilingual corpora? This would help clarify the added value of the multilingual signal.
2. Can the authors provide more details on the parameter tuning process and its potential impact on the results, especially for the SCWS task where multilingual training underperformed?
3. How scalable is the proposed approach to larger datasets and higher-dimensional embeddings? Are there computational trade-offs compared to prior work?
In summary, while the paper introduces an interesting idea with potential, it requires significant improvements in clarity, experimental rigor, and evaluation to meet the standards of the conference.