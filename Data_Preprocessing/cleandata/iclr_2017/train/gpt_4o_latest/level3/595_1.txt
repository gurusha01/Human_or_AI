Review of the Paper
Summary of Contributions
This paper presents an innovative approach to improving density estimation for sparse text data using deep latent Gaussian models (DLGMs) or variational autoencoders (VAEs). The authors propose two key contributions: (1) the integration of tf-idf features into the inference process to incorporate global statistics, which is particularly beneficial for sparse data, and (2) a novel optimization strategy inspired by stochastic variational inference (SVI) that refines local variational parameters to improve gradient updates for generative parameters. Additionally, the paper introduces a method to derive interpretable, context-sensitive word embeddings from the Jacobian of the generative model, enabling introspection into the learned representations. The proposed methods are evaluated on multiple datasets, including text corpora and electronic health records (EHR), demonstrating improved held-out likelihood and meaningful embeddings.
Decision: Reject
While the paper introduces promising ideas, several issues in clarity, experimental rigor, and presentation hinder its acceptance. The primary reasons for rejection are: (1) insufficient clarity in the methodology, particularly in Algorithm 1, and (2) incomplete evaluation of the proposed word embeddings, including missing predictive task benchmarks and reproducibility concerns.
Supporting Arguments
1. Clarity Issues: The gradient computation in step 3 of Algorithm 1 and the role of initial local parameter predictions in step 5 are unclear. These ambiguities make it difficult to fully understand the optimization process and its impact on the generative model.
2. Sparse Data Insight: While the authors argue that sparse data exacerbates poor initialization in generative models, they do not provide sufficient theoretical or empirical justification for this claim. A deeper exploration of why sparsity specifically affects initialization would strengthen the paper.
3. Word Embedding Evaluation: The evaluation of word embeddings is incomplete. Table 2b lacks predictive task benchmarks, and the methodology for generating embeddings is vaguely described, raising reproducibility concerns. Without these evaluations, it is difficult to assess the utility of the embeddings beyond qualitative observations.
4. Figures 2a–2d: While the validation perplexity analysis and singular value spectrum are intriguing, the results are underexplained. For instance, the plateauing of M=1 models and the x-axis comparability in Figures 2a and 2b require further clarification. Similarly, the implications of the singular value analysis in Figures 2c and 2d are not fully explored.
Suggestions for Improvement
1. Clarify Algorithm 1: Provide detailed explanations for steps 3 and 5, including mathematical derivations and intuition. This will help readers understand the optimization process and its benefits.
2. Theoretical Justification for Sparse Data: Elaborate on why sparse data exacerbates poor initialization in generative models. This could include theoretical insights or controlled experiments isolating the effect of sparsity.
3. Embedding Evaluation: Include predictive task benchmarks (e.g., word similarity, analogy tasks) to quantitatively evaluate the embeddings. Provide a reproducible methodology for generating embeddings.
4. Figures and Analysis: Expand the discussion of Figures 2a–2d, addressing the plateauing behavior, x-axis comparability, and the implications of singular value spectra. This will help readers interpret the results more effectively.
5. Separate Contributions: Consider presenting the inference and embedding techniques as separate contributions. This would allow for a more focused exploration of each idea.
Questions for the Authors
1. Can you provide more details on the gradient computation in step 3 of Algorithm 1? How does it interact with the optimization of local variational parameters?
2. Why does sparse data exacerbate poor initialization in generative models? Can you provide empirical evidence or theoretical insights to support this claim?
3. How were the embeddings in Table 2b generated? Can you clarify the methodology to ensure reproducibility?
4. What is the significance of the plateauing behavior observed in M=1 models in Figures 2a and 2b? How does this relate to the optimization of local variational parameters?
In conclusion, while the paper introduces valuable ideas, addressing the above concerns is crucial to ensure clarity, rigor, and impact.