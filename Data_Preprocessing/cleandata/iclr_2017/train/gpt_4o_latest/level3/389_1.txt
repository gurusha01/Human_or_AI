Review of the Paper
Summary of Contributions
This paper introduces SampleRNN, a novel hierarchical model for unconditional audio generation that operates directly on raw waveforms. The proposed approach combines autoregressive multilayer perceptrons and recurrent neural networks (RNNs) at different temporal resolutions, enabling it to capture dependencies over long time spans while maintaining computational efficiency. The authors present three key contributions: (1) a hierarchical architecture that models dependencies at multiple time scales, (2) an empirical evaluation of different model components, and (3) human preference tests demonstrating that SampleRNN outperforms baseline RNNs and an in-house WaveNet implementation on subjective quality. The paper also explores the impact of various design choices, such as discrete output quantization and truncated backpropagation through time (TBPTT).
Decision: Reject
While the paper introduces an interesting hierarchical approach to audio generation, significant issues undermine its contribution. The primary reasons for rejection are: (1) insufficient detail in the description of the proposed model, and (2) unconvincing comparisons with WaveNet, which is a key baseline for this task. These issues limit the clarity and scientific rigor of the work.
Supporting Arguments
1. Insufficient Model Description: The paper lacks critical details about the architecture and training setup of SampleRNN. For example, while the hierarchical structure is described conceptually, the exact implementation of frame-level and sample-level modules, as well as the upsampling mechanism, is not fully clear. This makes it difficult to reproduce the results or assess the novelty of the approach.
   
2. Unconvincing Comparisons with WaveNet: The comparison with WaveNet is problematic for two reasons. First, the authors acknowledge that their WaveNet implementation differs from the original, which raises questions about the validity of the results. Second, the reported performance of SampleRNN is weaker than that of baseline LSTM-RNNs in some cases, which undermines the claim of superiority over existing methods.
3. Overemphasis on Comparisons: The paper dedicates significant space to comparing SampleRNN with WaveNet, but the results are inconclusive. A more productive focus would be on elaborating the unique aspects of SampleRNN and providing a deeper analysis of its components.
Suggestions for Improvement
1. Expand Model Description: The final version should include a more detailed explanation of the architecture, including hyperparameters, training procedures, and ablation studies. Visual aids, such as diagrams of the hierarchical structure, would enhance clarity.
   
2. Refocus the Narrative: Instead of emphasizing comparisons with WaveNet, the authors should focus on the novel aspects of SampleRNN, such as its hierarchical design and flexibility in handling long-term dependencies. This would better highlight the paper's contributions.
3. Improve Experimental Rigor: The authors should either use the original WaveNet implementation or clearly justify their design choices for the in-house version. Additionally, they should address why SampleRNN underperforms compared to baseline LSTM-RNNs in some cases.
4. Clarify Human Evaluation: The human preference tests are a strong point, but more details on the evaluation protocol (e.g., number of participants, statistical significance) would strengthen the results.
Questions for the Authors
1. Can you provide more details on the upsampling mechanism and how it interacts with the hierarchical modules?
2. Why does SampleRNN underperform compared to LSTM-RNNs in some cases? Have you investigated the reasons for this discrepancy?
3. How does the hierarchical structure of SampleRNN compare to WaveNet in terms of computational efficiency and scalability?
In conclusion, while the paper introduces a promising approach to audio generation, its lack of clarity and incomplete comparisons prevent it from meeting the standards of scientific rigor required for acceptance. Addressing these issues in a revised submission could significantly strengthen the work.