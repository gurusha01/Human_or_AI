Review of the Paper
Summary of Contributions
This paper introduces a novel problem setup for imitation learning: third-person imitation learning, where an agent learns to imitate expert demonstrations provided in a different observation space but with shared MDP dynamics. The authors propose a GAN-based approach that incorporates domain confusion losses to extract domain-agnostic features, enabling the agent to generalize across observation domains. The paper demonstrates the feasibility of this approach through experiments in three simulated environments (Point, Reacher, and Inverted Pendulum). The problem is timely and relevant, as it addresses the practical challenge of collecting first-person demonstrations, which are often expensive or infeasible. The proposed method has the potential to broaden the applicability of imitation learning, particularly in robotics and other real-world domains.
Decision: Reject
Key Reasons:
1. Insufficient Empirical Validation: The paper lacks rigorous empirical evidence to support its claims. It does not compare the proposed method against alternative approaches like behavioral cloning or evaluate the performance of existing IRL algorithms in the third-person setting. Additionally, the experiments fail to explore key parameters and design choices comprehensively.
2. Clarity and Writing Quality: The paper is hurriedly written, with overstatements in the introduction and grammatical inconsistencies that hinder readability. This detracts from the clarity of the contributions and makes it challenging to assess the technical rigor of the work.
Supporting Arguments
1. Empirical Weaknesses: While the experiments demonstrate that the proposed method can solve simple third-person imitation tasks, the lack of comparison with alternative methods (e.g., behavioral cloning or first-person IRL adapted to third-person settings) is a significant drawback. The authors also make unsubstantiated claims about the failure of existing IRL algorithms in the proposed setup without providing empirical evidence. Furthermore, the computational cost of TRPO training and the challenges of GAN training (e.g., instability, hyperparameter sensitivity) are not adequately addressed.
2. Misaligned Experimental Design: The experiments focus on demonstrating the feasibility of the proposed approach but do not align well with the paper's main theme of solving third-person imitation learning. For example, the sensitivity analysis of hyperparameters and camera angles is limited, and the variance in results is not thoroughly discussed.
3. Writing and Presentation: The paper's overstatements in the introduction (e.g., "surprisingly, we find that this simple approach has been able to solve the problems") and grammatical inconsistencies reduce its overall impact. Key experimental details, such as the process for generating expert trajectories and the nature of domain differences, are insufficiently explained.
Additional Feedback for Improvement
1. Empirical Comparisons: Include comparisons with baseline methods such as behavioral cloning, first-person IRL adapted to third-person settings, and other domain adaptation techniques. This would strengthen the empirical validation of the proposed approach.
2. Clarity on Experimental Details: Provide more details about the expert trajectory generation process, the nature of domain differences, and the variance in results. Discuss the computational cost of TRPO training and the stability of GAN training in greater depth.
3. Broader Exploration of IRL Adaptations: Instead of focusing solely on a GAN-based approach, explore how other IRL algorithms could be adapted to the third-person setting. This would provide a more comprehensive view of the problem space.
4. Writing Improvements: Revise the introduction to avoid overstatements and improve grammatical consistency throughout the paper. This will enhance readability and make the contributions clearer.
Questions for the Authors
1. Why were alternative approaches like behavioral cloning or first-person IRL adaptations not included in the experiments? How do you justify the lack of empirical comparisons?
2. Can you provide more details about the computational cost of TRPO training and the challenges of GAN training in your setup? How do these factors impact the scalability of your method?
3. How were the expert trajectories generated, and what specific domain differences were introduced in the experiments? Could these choices have influenced the results?
4. Why was the focus limited to a GAN-based IRL approach? Have you considered other IRL algorithms or domain adaptation techniques for third-person imitation learning?
In summary, while the paper addresses an important and relevant problem, the lack of empirical rigor, clarity in writing, and broader exploration of the problem space make it unsuitable for acceptance in its current form.