Review of the Paper
Summary of Contributions
This paper introduces a novel "unrolling" strategy for handling dynamic computation graphs (DCGs), enabling a new batching approach for inputs, termed dynamic batching. The proposed technique allows DCGs to be efficiently executed within static data-flow graph frameworks, such as TensorFlow, overcoming a significant limitation in existing deep learning libraries. The authors also present a high-level combinator library, TensorFlow Fold, which simplifies the implementation of DCG-based models. The paper demonstrates the utility of the approach through experiments on synthetic benchmarks and real-world datasets, including the Stanford Sentiment Treebank, achieving state-of-the-art performance on sentiment classification tasks. The work is innovative and addresses a critical bottleneck in the adoption of DCGs, offering both theoretical insights and practical tools.
Decision: Accept
The paper introduces a well-motivated and innovative solution to a longstanding problem in deep learning, with clear contributions to both methodology and tooling. While there are some concerns regarding the experimental results and clarity of certain sections, the overall impact of the work justifies acceptance. My decision is primarily based on the novelty of the dynamic batching algorithm and its potential to influence future research and practice.
Supporting Arguments
1. Novelty and Motivation: The dynamic batching approach is a significant contribution to the field, addressing a key limitation of DCGs in popular frameworks. The combinator library further enhances the usability of the technique, making it accessible to practitioners.
2. Clarity and Presentation: The updated revision (Jan. 17th) has improved the clarity of the paper, particularly in explaining the technical details of the batching algorithm and the library's design. This revision increased my confidence in the paper's quality.
3. Experimental Validation: While the results on synthetic benchmarks convincingly demonstrate the speedups achieved by dynamic batching, the performance on the Stanford Sentiment Treebank raises some concerns. The claimed speed improvements are not fully aligned with the reported results, and the state-of-the-art performance appears to be driven more by ensemble averaging than the proposed framework itself. However, these issues do not detract significantly from the paper's core contributions.
Suggestions for Improvement
1. Experimental Results: The authors should provide a more detailed analysis of the discrepancies between their claims and the observed speed improvements on the Stanford Sentiment Treebank. Additionally, isolating the contribution of the framework from ensemble averaging would strengthen the empirical validation.
2. Clarity in Section 3: Some technical details in Section 3 could be omitted or moved to an appendix to improve readability. For example, the recursive definitions and type system, while important, could be summarized more concisely.
3. Broader Evaluation: The paper would benefit from additional experiments on other datasets and tasks to demonstrate the generalizability of the proposed approach.
Questions for the Authors
1. Can you clarify the specific conditions under which the speed improvements on the Stanford Sentiment Treebank were measured? Were there any implementation or hardware constraints that might explain the discrepancies?
2. How does the dynamic batching algorithm handle edge cases, such as highly imbalanced trees or graphs with extreme topological variations? Are there any limitations in these scenarios?
3. Could you provide more details on the computational overhead introduced by the concat and gather operations? How does this scale with increasing graph size or batch size?
Overall, this paper makes a strong contribution to the field and is likely to have a lasting impact on the development and adoption of DCG-based models. With minor revisions and additional clarifications, it will be an excellent addition to the conference.