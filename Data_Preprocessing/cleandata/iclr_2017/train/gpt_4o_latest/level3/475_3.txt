Review of the Paper
Summary of Contributions
This paper introduces a novel approach for training variational autoencoders (VAEs) with discrete latent variables, addressing the challenge of backpropagation through discrete variables. The proposed method employs a shared smoothing transformation to enable gradient-based optimization. The framework integrates a restricted Boltzmann machine (RBM) as the prior model \( P(z) \), and utilizes autoregressive connections in both the generative and recognition models. The authors demonstrate the efficacy of their approach on several benchmark datasets, including MNIST, Omniglot, and Caltech-101 Silhouettes, achieving state-of-the-art performance. The paper is rich in ideas and provides a significant contribution to the field of unsupervised learning and probabilistic modeling.
Decision: Accept
The paper should be accepted for the conference, primarily due to its innovative approach to handling discrete latent variables in VAEs and its demonstrated empirical success. However, the complexity of the framework and the lack of ablation studies to isolate individual contributions are notable weaknesses that should be addressed.
Supporting Arguments
1. Specific Problem Tackled: The paper addresses a critical limitation in training VAEs with discrete latent variables. This is a well-recognized challenge in the literature, as backpropagation through discrete variables is generally not feasible. The proposed smoothing transformation is a novel and effective solution to this problem.
   
2. Motivation and Placement in Literature: The paper is well-motivated and builds on a strong foundation of prior work, including VAEs, RBMs, and autoregressive models. The authors provide a comprehensive review of related methods and clearly articulate the gap their work addresses. The introduction of a hierarchical structure and the use of smoothing transformations are both well-grounded in the literature.
3. Support for Claims: The empirical results on benchmark datasets are compelling and demonstrate the superiority of the proposed method over state-of-the-art approaches. However, the complexity of the framework makes it difficult to attribute performance gains to specific components. Separate experiments isolating the contributions of the RBM prior, autoregressive connections, and smoothing transformations would strengthen the paper.
Suggestions for Improvement
1. Ablation Studies: The paper would benefit from experiments that isolate the contributions of individual components, such as the RBM prior, the hierarchical structure, and the smoothing transformation. This would provide greater clarity on the source of performance improvements.
   
2. Complexity and Usability: While the complexity of the framework is justified by its performance, the authors should consider providing user-friendly, plug-and-play software to make the method accessible to a broader audience.
3. Clarity in Presentation: The paper is dense and could benefit from clearer explanations of key concepts, particularly the smoothing transformation and its role in enabling backpropagation. Visual aids or diagrams illustrating the smoothing process would enhance understanding.
4. Scalability: The authors should discuss the scalability of their approach to larger datasets and more complex models, such as those used in natural image generation (e.g., ImageNet).
Questions for the Authors
1. How does the performance of the model change when the RBM prior is replaced with a simpler prior, such as a Gaussian or a factorial Bernoulli distribution?
2. Can the smoothing transformation be generalized to other types of discrete latent variable models beyond VAEs?
3. What are the computational costs of the proposed method compared to standard VAEs and other state-of-the-art approaches?
4. Have you considered alternative architectures for the autoregressive connections in the generative and recognition models? How do these choices affect performance?
In conclusion, this paper presents a significant advancement in training VAEs with discrete latent variables. While there are areas for improvement, the novelty and empirical success of the proposed method make it a valuable contribution to the conference.