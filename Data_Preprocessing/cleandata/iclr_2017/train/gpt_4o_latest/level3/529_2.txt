Review
The paper introduces RL Tuner, a reinforcement learning (RL) framework designed to refine melodies generated by a pre-trained LSTM-based Note RNN. The authors aim to address common shortcomings of sequence models, such as lack of long-range structure and excessive note repetition, by combining maximum likelihood (ML) training with RL to impose music-theory-based constraints. The proposed method uses a reward function that balances adherence to music theory rules with the probabilities learned from the training data. The authors evaluate their approach through quantitative metrics and a user study, demonstrating that RL Tuner produces more musically pleasing melodies than the baseline Note RNN.
Decision: Reject
While the paper presents an interesting application of RL to music generation, it falls short in terms of methodological novelty and scientific rigor. The primary contribution lies in the application rather than the development of new techniques, and the treatment of music composition is overly simplistic. Additionally, the user study feels premature, as the generated melodies are only semi-plausible and do not convincingly demonstrate significant progress toward meaningful music composition.
Supporting Arguments
1. Strengths:
   - The paper identifies a well-defined problem in sequence modeling and proposes a reasonable solution by combining ML and RL.
   - The authors' efforts to craft music-theory-based rules and conduct a user study are commendable, and the results show improvement in targeted metrics such as reduced note repetition and better key adherence.
   - The connection to KL control and the exploration of generalized Î¨-learning and G-learning in this context are valuable contributions to the RL literature.
2. Weaknesses:
   - The proposed RL methodology is straightforward and closely resembles prior work in text modeling and dialogue generation. The novelty lies primarily in the application to music generation, which limits the paper's broader impact.
   - The treatment of music is naive, relying on overly simplistic rules that fail to capture the complexity and expressivity of real-world compositions. This limits the perceived utility of the approach.
   - The user study, while a good attempt, is premature. The generated melodies are still rudimentary, and the comparison to LSTM Shakespeare versus n-gram Shakespeare highlights the lack of depth in the results.
   - The term "composing" is used uncritically, which overstates the capabilities of the model. Statistical sequence modeling is not equivalent to artistic creation.
Additional Feedback for Improvement
1. Motivation and Justification: The paper should better justify why this specific application of RL to music generation is impactful. The authors should avoid relying solely on prior studies to motivate their work and instead articulate the unique challenges and opportunities in this domain.
2. Music Theory and Complexity: The music-theory-based rules are overly simplistic and do not reflect the richness of real-world compositions. Future work could explore more sophisticated representations of music, such as polyphony, dynamics, and phrasing, to produce more realistic outputs.
3. User Study: The user study could be expanded to include more participants and a broader range of evaluation criteria, such as emotional engagement or perceived creativity. Additionally, the authors should provide more details about the study design and participant demographics.
4. Terminology: The authors should use terms like "composing" and "melodic" cautiously to avoid overstating the capabilities of the model. A more accurate framing would be "statistical sequence generation with musical constraints."
5. Anticipating Criticism: The authors are encouraged to explicitly address potential criticisms, such as the simplicity of the rules and the limited scope of the application, and outline how they plan to address these limitations in future work.
Questions for the Authors
1. How do you justify the use of simplistic music-theory-based rules when music composition is inherently complex and context-dependent? Could these rules be extended or replaced with more sophisticated constraints?
2. The user study results suggest that the melodies are more pleasing, but how do you account for subjectivity in musical preferences? Would a larger or more diverse participant pool yield different results?
3. How does your approach compare to other state-of-the-art methods for music generation, such as those using generative adversarial networks (GANs) or transformers? Could these methods be integrated into your framework?
In summary, while the paper presents an enjoyable application of RL to music generation, it lacks sufficient methodological innovation and scientific rigor to warrant acceptance at this time. The authors are encouraged to refine their approach, expand their evaluation, and better articulate the broader impact of their work.