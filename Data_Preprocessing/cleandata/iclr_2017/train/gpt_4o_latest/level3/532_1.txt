Review of the Paper
Summary of Contributions
The paper introduces Neural Data Filter (NDF), a novel framework that leverages reinforcement learning to adaptively filter training data during Stochastic Gradient Descent (SGD) training of deep neural networks. The proposed method aims to accelerate convergence while maintaining comparable accuracy to standard SGD. The authors frame the data filtering process as a Markov Decision Process (MDP) and employ policy gradient methods (REINFORCE and Actor-Critic) to learn optimal filtering strategies. The experiments demonstrate the effectiveness of NDF on two tasks: IMDB sentiment classification using LSTMs and image classification on a corrupted MNIST dataset using a Multilayer Perceptron. The paper claims that NDF reduces the amount of training data required while achieving faster convergence and comparable performance to baseline methods.
Decision: Reject
The paper presents an interesting idea with potential, but the experimental results and methodological rigor fall short of the standards required for acceptance. The key reasons for rejection are:
1. Insufficient Experimental Validation: The experiments are limited to only two datasets (IMDB and MNIST), which are relatively small and simplistic. Testing on more diverse and complex datasets is necessary to validate the generalizability of the approach.
2. Lack of Baselines and Clarity in Results: The paper does not compare NDF against strong baselines such as more advanced curriculum learning or self-paced learning methods. Additionally, the experimental results lack clarity, with insufficient statistical analysis or detailed comparisons.
Supporting Arguments
1. Experimental Results Lack Clarity: While the paper claims faster convergence, the results are not presented with sufficient rigor. For example, the test accuracy curves (e.g., Figure 2 and Figure 5) lack confidence intervals, and there is no statistical significance analysis. Furthermore, the baselines (e.g., "Randomly Drop") are simplistic and do not represent state-of-the-art methods.
2. Limited Dataset Scope: The experiments are conducted on IMDB and a corrupted MNIST dataset, which are not representative of the challenges faced in modern deep learning tasks. Testing on larger and more diverse datasets, such as CIFAR-10, ImageNet, or large-scale NLP datasets, would strengthen the claims.
3. Concerns with SGD Tuning: The paper does not address the absence of a learning rate schedule or other SGD tuning techniques, which are standard practices for faster convergence. This omission raises questions about whether the observed improvements are due to NDF or suboptimal baseline implementations.
4. Lack of Interpretability: While the authors provide some analysis of the learned policies (e.g., feature weights in Table 1), the explanation of why certain data is filtered at different stages of training is insufficient. A deeper analysis would help validate the claims and provide insights into the behavior of NDF.
Suggestions for Improvement
1. Expand Experimental Scope: Test NDF on more diverse datasets, including larger and more complex tasks (e.g., CIFAR-10, ImageNet, or large-scale NLP datasets). This will help demonstrate the generalizability of the approach.
2. Add Stronger Baselines: Compare NDF against more advanced curriculum learning and self-paced learning methods. Additionally, include baselines with well-tuned SGD variants (e.g., with learning rate schedules).
3. Improve Result Clarity: Provide confidence intervals, statistical significance tests, and detailed comparisons in the experimental results. This will make the findings more robust and credible.
4. Analyze Policy Behavior: Offer a more detailed explanation of the learned policies, including what types of data are filtered at different stages and why. This would enhance the interpretability of the method.
5. Investigate Task-Dependent Success: Explore whether filtering training data is task-dependent and provide insights into when NDF is most effective.
Questions for the Authors
1. How does NDF perform on larger and more complex datasets, such as CIFAR-10 or ImageNet? Have you considered testing it on tasks beyond image and text classification?
2. Why was no learning rate schedule used in the experiments? Would incorporating standard SGD tuning techniques affect the observed improvements?
3. Could you provide more details on the computational overhead introduced by NDF, especially for large-scale datasets?
4. How does the performance of NDF compare to more advanced curriculum learning or self-paced learning methods beyond the simplistic baselines used in the paper?
In conclusion, while the idea of using reinforcement learning for data filtering is promising, the paper requires significant improvements in experimental validation, methodological rigor, and clarity of results to meet the standards of acceptance.