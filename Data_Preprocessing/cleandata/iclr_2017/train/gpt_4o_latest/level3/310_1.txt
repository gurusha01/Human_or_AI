The paper presents a novel framework for language learning through multi-agent communication, specifically in the context of referential games. The authors aim to address the limitations of passive supervised learning for conversational AI by proposing an interactive, emergent approach. The study demonstrates that two neural networks, acting as sender and receiver, can successfully develop a communication protocol to coordinate and identify target images. The paper also explores how modifying the game environment can induce more semantically meaningful and interpretable communication, and it introduces a strategy to ground the emergent language in natural language through supervised learning. This work contributes to the fields of multi-agent systems, game theory, and natural language processing by providing insights into how agents can bootstrap communication and align it with human semantics.
Decision: Accept.  
The paper is well-motivated, addresses a fundamental problem in AI, and provides rigorous experimental results to support its claims. The novelty of combining referential games with supervised learning to bridge the gap between emergent and human-interpretable language is particularly compelling.
Supporting Arguments:  
1. Problem Definition and Motivation: The paper tackles a critical question: how can agents develop a communication protocol that is both functional and interpretable? This is a well-motivated problem, as current supervised approaches fail to capture the interactive and functional aspects of communication. The authors situate their work effectively within the literature, referencing relevant studies in linguistics, game theory, and AI.  
2. Scientific Rigor: The experiments are thorough and methodologically sound. The authors demonstrate that agents can successfully coordinate, and they provide quantitative evidence (e.g., purity scores, t-SNE visualizations) to show that the emergent language captures high-level semantic properties. The integration of supervised learning further enhances the interpretability of the communication protocol, with human evaluations confirming its effectiveness.  
3. Impact: The proposed framework has the potential to advance conversational AI by fostering interactive, grounded communication. The results are promising and open avenues for future research, such as scaling the approach to more complex environments or tasks.
Additional Feedback for Improvement:  
1. Clarity of Presentation: While the experiments are well-executed, the paper could benefit from more concise explanations of the experimental setup and results. For instance, the distinction between the informed and agnostic sender could be clarified earlier in the text.  
2. Broader Evaluation: The paper primarily focuses on referential games. It would be valuable to discuss how this framework might generalize to other types of interactive tasks or domains.  
3. Human-Agent Interaction: While the grounding experiments are a step toward human-agent communication, the paper could explore more robust methods for evaluating how well humans can interact with the agents in real-world scenarios.  
4. Scalability: The authors mention potential extensions (e.g., multi-step communication, larger vocabularies), but a discussion on the computational scalability of the approach would strengthen the paper.
Questions for the Authors:  
1. How does the framework handle ambiguity or noise in the input data, and how robust is the emergent language in such scenarios?  
2. Could the approach be extended to multi-agent setups with more than two players, and what challenges might arise in such cases?  
3. How does the supervised grounding affect the agents' ability to generalize to unseen tasks or domains?  
Overall, this paper makes a significant contribution to the field and is worthy of acceptance. The proposed framework is innovative, and the results are both rigorous and impactful. With minor revisions, the paper could be even stronger.