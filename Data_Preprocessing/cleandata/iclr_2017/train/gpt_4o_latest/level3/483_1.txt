The paper proposes a novel recurrent deep neural network, termed Recurrent Mixture Density Network (RMDN), for predicting human fixation locations in videos as a mixture of Gaussians. The model is trained using maximum likelihood estimation on human fixation data and leverages both 3D convolutional features for short-term spatial-temporal relations and LSTM layers for long-term temporal dependencies. The authors claim state-of-the-art performance in saliency prediction on the Hollywood2 dataset and demonstrate the utility of their saliency maps in improving action recognition accuracy on Hollywood2 and UCF101 datasets.
Decision: Reject
Key Reasons for Rejection:
1. Insufficient Evaluation of Fixation Prediction Performance: The evaluation of fixation prediction performance is inadequate. There are discrepancies in the reported center bias performance between Table 1 and Table 2, raising concerns about the consistency and reliability of the results. Additionally, the paper does not convincingly demonstrate that the proposed model outperforms the center bias baseline, which is a critical benchmark in saliency prediction.
2. Unsubstantiated Claims of Human-Level Performance: The claim of achieving performance close to human-level accuracy (3.2% difference) is questionable. The reported difference between the model and the central bias in Table 1 is larger than the claimed difference with human performance, suggesting potential saturation issues in the AUC metric. This undermines the validity of the human performance comparison.
Supporting Arguments:
- While the proposed RMDN is an interesting contribution to spatio-temporal saliency prediction, the lack of rigorous evaluation metrics and clarity in benchmarking against state-of-the-art methods weakens the paper's impact.
- The application of saliency maps to action recognition is promising, but the unclear explanation of Table 3 and the differences between CONV5 and FC6 models make it difficult to assess the robustness of the results.
Additional Feedback for Improvement:
1. Clarify Evaluation Metrics and Benchmarks: The authors should provide a more detailed and consistent evaluation of saliency prediction performance, including a thorough comparison with state-of-the-art models and a clearer explanation of the discrepancies in center bias performance.
2. Address Human Performance Claims: The authors need to substantiate their claim of human-level performance with additional evidence, such as cross-validation experiments or alternative metrics that avoid saturation issues.
3. Improve Clarity in Results Presentation: The explanation of Table 3 and the differences between CONV5 and FC6 models should be expanded. Additionally, the rationale behind the choice of evaluation metrics and experimental setups should be made more explicit.
4. Correct Citation Misrepresentation: The paper misrepresents the work by KÃ¼mmerer et al. (2015) as not using fixation data, which is incorrect. This should be corrected to ensure proper attribution and accuracy in the literature review.
Questions for the Authors:
1. Can you clarify the discrepancies in center bias performance between Table 1 and Table 2? How do you ensure consistency in your evaluation?
2. How do you address the potential saturation issues in AUC when comparing your model to human performance?
3. Can you provide more details on the differences in saliency map usage between CONV5 and FC6 models and their impact on action recognition performance?
While the paper introduces a novel approach to spatio-temporal saliency prediction, addressing the above concerns is necessary for a more robust and convincing contribution.