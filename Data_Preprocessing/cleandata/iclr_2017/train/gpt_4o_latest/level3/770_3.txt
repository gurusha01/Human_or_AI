Review of the Paper
Summary of Contributions
The paper introduces the Neural Knowledge Language Model (NKLM), a novel approach to address the challenge of generating rare or unseen words in language modeling by incorporating symbolic knowledge from a knowledge graph (KG). The key innovation lies in the model's ability to predict whether a word should be generated from a fixed vocabulary or copied from a fact description in the KG, thereby effectively mitigating the unknown word problem. The authors also release a new dataset, WikiFacts, which aligns Freebase facts with Wikipedia descriptions, providing a valuable resource for future research. The experimental results demonstrate significant improvements in perplexity and a reduction in unknown word generation compared to traditional RNN-based language models. Additionally, the introduction of the Unknown-Penalized Perplexity (UPP) metric is a meaningful contribution to evaluating knowledge-based language models.
Decision: Reject
While the paper presents an innovative approach and achieves promising results, it falls short in several critical areas. The primary reasons for rejection are: (1) insufficient clarity in the presentation of the model, particularly in Section 3, where notations and equations are difficult to follow; and (2) a lack of demonstrated impact on practical applications such as Question Answering (QA) or dialogue systems, which would strengthen the case for the model's utility.
Supporting Arguments
1. Strengths:
   - The NKLM is a well-motivated and novel extension of RNN-based language models, addressing a significant limitation in handling rare or unseen words.
   - The release of the WikiFacts dataset is a valuable contribution to the community, enabling further research on knowledge-enhanced language modeling.
   - The experiments are thorough, with insightful visualizations (e.g., heatmaps) and clear evidence of performance gains in perplexity and unknown word reduction.
2. Weaknesses:
   - Clarity of Presentation: Section 3, which details the model, is difficult to parse due to unclear notations and overly dense explanations. For example, the hard decision in Equation 2 to select a single fact seems unrealistic for noisy or ambiguous text, such as social media data, but this limitation is not adequately discussed.
   - Practical Impact: While the model shows improvements in perplexity, its practical utility remains unclear. Demonstrating the model's effectiveness in QA or dialogue systems would significantly bolster its impact.
   - Terminology Confusion: Referring to entities as "topics" is misleading, as "topic" typically implies abstract concepts rather than specific Freebase entities.
   - Model Assumptions: The assumption that a fact must be predicted at every step is questionable, as natural language sentences often describe only a few facts. This could lead to inefficiencies in real-world applications.
   - Comparison with Alternatives: The paper lacks a comparison with character-level language models, which inherently address the unknown token problem and are a natural baseline for this task.
Suggestions for Improvement
1. Clarity: Revise Section 3 to improve the clarity of notations and provide intuitive explanations for key equations and mechanisms (e.g., the hard decision in Equation 2 and the use of position embeddings for copying knowledge words).
2. Practical Applications: Include experiments demonstrating the model's performance on downstream tasks such as QA or dialogue systems to highlight its practical relevance.
3. Terminology: Replace "topics" with a more precise term like "entities" to avoid confusion.
4. Model Assumptions: Discuss the implications of predicting a fact at every step and explore mechanisms to relax this assumption.
5. Baseline Comparisons: Add a comparison with character-level language models to provide a more comprehensive evaluation.
Questions for the Authors
1. How does the model handle ambiguous or noisy text where word-to-fact alignment is not straightforward (e.g., social media or informal text)?
2. Could the position embeddings for copying knowledge words be replaced with a more flexible mechanism, such as attention over the fact description? If so, how would this affect performance?
3. Have you considered evaluating the NKLM on tasks like QA or dialogue systems? If not, what challenges do you foresee in applying the model to these tasks?
4. How does the model's performance scale with larger or more diverse knowledge graphs beyond Freebase?
In conclusion, while the paper introduces a promising approach and makes valuable contributions, addressing the above concerns is essential to strengthen its clarity, practical impact, and overall contribution to the field.