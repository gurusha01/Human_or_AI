Review of the Paper
Summary of Contributions:
This paper introduces a novel deep character-level neural machine translation (DCNMT) model that addresses the limitations of word-level NMT models, such as large vocabulary issues and out-of-vocabulary (OOV) words. The proposed architecture consists of six recurrent neural networks, including a hierarchical decoder and a word encoder designed to learn morphemes and their combinations. The authors claim that their model achieves competitive BLEU scores compared to state-of-the-art character-level models while being more efficient in training. Additionally, the paper provides analyses demonstrating the model's ability to learn morphology and handle misspelled or nonce words. The work is well-written and includes detailed experiments on En-Fr and En-Cs translation tasks.
Decision: Accept
Key reasons for acceptance:
1. The authors have adequately addressed the initial concerns regarding insufficient comparison to prior work, particularly Luong & Manning (2016), and provided additional clarity in their revisions.
2. The paper offers meaningful insights into character-level modeling and morphology learning, which are valuable contributions to the field of neural machine translation.
Supporting Arguments:
1. Novelty and Motivation: While the novelty of the HGRU and R matrix is somewhat limited to symbolic frameworks like Theano and TensorFlow, the focus on character-level modeling and the hierarchical architecture is well-motivated. The paper highlights the advantages of character-level translation, such as addressing OOV issues and translating misspelled words, which are significant challenges in NMT.
2. Empirical Results: The BLEU scores reported for the proposed model are competitive, though slightly lower than Luong & Manning (2016). The efficiency of the training process and the ability to learn morphology are notable strengths. The analysis in Figure 5 convincingly demonstrates the model's capacity to detect morpheme boundaries.
3. Clarity and Writing: The paper is well-organized and clearly written, with detailed explanations of the model architecture and training process. The inclusion of visualizations and examples (e.g., Figure 5 and Table 2) enhances the readability and impact of the work.
Suggestions for Improvement:
1. Mechanisms for Morphology Learning: Although the paper claims that the model learns morphology, the title suggests a stronger focus on explicit mechanisms for learning morphemes or subword units. Adding constraints on weights to enforce morpheme boundary detection or incorporating objectives like Minimum Description Length (MDL) could strengthen the claims.
2. Comparison with Prior Work: While the authors have addressed some concerns about comparison to Luong & Manning (2016), the BLEU score discrepancy (19.6 vs. 17.0) remains notable. A deeper discussion of why the proposed model underperforms in BLEU scores despite its complexity would be helpful.
3. Model Complexity: The HGRU and hierarchical decoder, while innovative, appear over-complicated compared to simpler approaches like Luong & Manning (2016). Simplifying the architecture or providing a stronger justification for the added complexity could improve the paper.
4. Clarity in Figures: Annotating \( h_t \) in Figure 1, as suggested, would improve clarity for readers unfamiliar with the architecture.
Questions for the Authors:
1. How does the proposed model perform when trained for more epochs compared to Luong & Manning (2016)? Can the BLEU score gap be reduced with additional training?
2. Could the proposed architecture be adapted for frameworks like PyTorch or TensorFlow 2.0, where symbolic expressions are less relevant? If so, how would this impact the efficiency of the model?
3. Have you considered incorporating explicit objectives for morphology learning, such as MDL or other regularization techniques, to enforce the learning of morpheme boundaries?
Overall, this paper provides valuable insights into character-level modeling and morphology learning in neural machine translation. With minor improvements and clarifications, it has the potential to make a significant contribution to the field.