Review of the Paper
Summary of Contributions
The paper proposes a novel framework for distributed transfer learning in deep convolutional networks, aiming to address two key challenges: optimization complexity in highly non-convex objectives and class imbalance between original and target domains. The method involves fine-tuning individual convolutional filters separately, followed by boosting these distributed networks using a Basic Probability Assignment (BPA) derived from evidence theory. The authors claim that this approach reduces optimization complexity and improves performance on imbalanced datasets. Experiments conducted on MNIST, CIFAR, and SVHN datasets reportedly demonstrate the superiority of the proposed method over conventional transfer learning approaches.
Decision: Reject  
Key Reasons:  
1. Conceptual Ambiguity and Presentation Issues: The paper mixes several concepts, such as distributed learning, transfer learning, and evidence theory, in a way that makes the core ideas difficult to follow. The definitions of key terms like "distributed" and "transfer learning" are narrow and inconsistent with standard usage in the literature, leading to confusion.  
2. Methodological Flaws and Lack of Rigor: Algorithm 2 appears to incorrectly imply the use of test data during training, which violates standard machine learning practices. The distinction between training/validation and test sets is unclear, raising concerns about the validity of the reported results. Additionally, the BPA computation contradicts the stochastic gradient descent (SGD) paradigm, and no experimental evidence is provided to justify the computational feasibility of the proposed batch-based approach.
Supporting Arguments
1. Ambiguity in BPA and Class Imbalance Handling: While the paper claims that BPA addresses class imbalance, the explanation is unclear, and simpler methods like class-specific re-weighting are not considered as baselines. This weakens the argument for BPA's necessity and effectiveness.  
2. Experimental Reporting Gaps: The paper lacks any discussion of computational cost or timing for the proposed method, which is critical given the contradiction with SGD. Without such evidence, the practicality of the approach remains questionable.  
3. Presentation Issues: The paper is poorly organized, with ambiguous definitions and unclear explanations of key concepts. For example, the term "distributed" is used to refer to classifier ensembles rather than distributed training or computation, which is misleading.
Suggestions for Improvement
1. Clarify Key Concepts: Clearly define terms like "distributed" and "transfer learning" in the context of the paper. Ensure consistency with standard definitions in the literature.  
2. Address Methodological Issues: Revise Algorithm 2 to ensure that test data is not used during training. Clearly distinguish between training, validation, and test sets in both the methodology and experimental setup.  
3. Provide Computational Analysis: Include experiments that report on the computational cost and timing of the proposed method to demonstrate its feasibility.  
4. Simplify Class Imbalance Handling: Compare BPA with simpler methods like class-specific re-weighting to establish its relative advantages.  
5. Improve Presentation: Reorganize the paper for clarity and coherence. Ensure that the proposed method and its contributions are clearly explained without mixing unrelated concepts.
Questions for the Authors
1. How does the proposed BPA-based approach compare to simpler methods like class-specific re-weighting in addressing class imbalance?  
2. Can you provide experimental results on the computational cost and timing of the proposed batch-based BPA computation?  
3. How do you ensure that test data is not inadvertently used during training, as implied in Algorithm 2?  
4. Why was the term "distributed" chosen to describe classifier ensembles, and how does this align with standard usage in the literature?  
5. Could you clarify the rationale behind using BPA in a batch setting, given its apparent incompatibility with SGD?  
In summary, while the paper addresses an important problem in transfer learning, the conceptual ambiguity, methodological flaws, and lack of experimental rigor prevent it from making a convincing case for acceptance.