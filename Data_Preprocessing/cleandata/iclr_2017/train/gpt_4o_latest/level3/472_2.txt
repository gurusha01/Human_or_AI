Review of the Paper
Summary of Contributions
The paper introduces Support Regularized Sparse Coding (SRSC), a novel method to regularize sparse coding by encouraging neighboring data points to share similar dictionary atoms. This is achieved by incorporating a KNN-based clustering mechanism into the sparse coding framework. The authors also propose a neural network, Deep-SRSC, as a fast encoder to approximate the sparse codes generated by SRSC. The paper provides theoretical guarantees for the convergence of the optimization algorithm using proximal gradient descent and demonstrates the effectiveness of SRSC and Deep-SRSC through clustering experiments on small datasets.
Decision: Reject
The decision to reject is based on two primary reasons:
1. Insufficient Experimental Validation: The experimental results are limited to small datasets (USPS, COIL-20/100, UCI) with relatively small dictionary sizes (p=100 to p=500). This raises concerns about the scalability of the proposed method to larger, more complex datasets commonly used in modern machine learning tasks.
2. Weak Baseline Comparisons: The paper lacks comparisons to state-of-the-art image clustering methods and alternative baselines, which makes it difficult to assess the true performance gains of SRSC.
Supporting Arguments
1. Proposed Method: The idea of incorporating manifold structure into sparse coding via support regularization is interesting and well-motivated. The use of KNN-based clustering to enforce local smoothness is a novel contribution. However, the computational complexity of the algorithm is high, and while convergence is theoretically proven, the practicality of the method for large-scale applications remains unclear.
2. Experimental Results: While the authors report improvements in clustering accuracy and normalized mutual information (NMI), the gains are marginal, particularly for NMI. Furthermore, the choice of datasets (e.g., USPS, COIL-20/100) does not convincingly demonstrate the method's applicability to real-world, large-scale problems.
3. Test Set Usage: There is ambiguity in the experimental setup, as it is unclear whether hyperparameters were tuned using the test set. This raises concerns about the validity of the reported results.
4. Baseline Comparisons: The absence of comparisons with state-of-the-art clustering methods (e.g., deep clustering approaches) and alternative sparse coding techniques limits the paper's impact. The evaluation metrics focus solely on clustering tasks, neglecting direct assessments of sparse coding properties like reconstruction error or sparsity.
Suggestions for Improvement
1. Scalability: Demonstrate the scalability of SRSC and Deep-SRSC by applying them to larger datasets, such as ImageNet or CIFAR-100. This would provide stronger evidence of the method's practicality.
2. Baseline Comparisons: Include comparisons with state-of-the-art clustering methods, such as deep clustering approaches (e.g., DeepCluster, DEC), and other sparse coding techniques. This would contextualize the performance of SRSC.
3. Evaluation Metrics: Expand the evaluation to include metrics that directly assess sparse coding properties, such as reconstruction error, sparsity, or denoising performance.
4. Experimental Clarity: Clearly specify whether hyperparameters were tuned using the test set. Ensure that the experimental setup adheres to standard practices to avoid potential overfitting.
5. Performance Gains: Investigate why the improvements in NMI are small and provide insights into how the method could be enhanced to achieve more significant gains.
Questions for the Authors
1. How does SRSC perform on larger datasets with higher-dimensional data, such as ImageNet or CIFAR-100? Have you considered the computational feasibility of scaling the method?
2. Can you clarify whether hyperparameters were tuned using the test set? If so, how do you plan to address this issue in future experiments?
3. Why were state-of-the-art clustering methods not included as baselines? How does SRSC compare to deep clustering approaches like DEC or DeepCluster?
4. Have you considered evaluating SRSC on tasks beyond clustering, such as denoising or feature extraction, to highlight its versatility?
While the proposed method is theoretically sound and introduces an interesting idea, the lack of sufficient experimental validation and baseline comparisons limits its impact and applicability. Addressing these concerns would significantly strengthen the paper.