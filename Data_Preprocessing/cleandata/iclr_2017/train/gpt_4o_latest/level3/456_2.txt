Review of the Paper
Summary of Contributions
This paper introduces Central Moment Discrepancy (CMD) as a novel metric for matching probability distributions, specifically in the context of domain-invariant representation learning for unsupervised domain adaptation. CMD explicitly matches higher-order central moments of distributions, offering computational efficiency by avoiding kernel matrix computations required by Maximum Mean Discrepancy (MMD). The authors provide theoretical guarantees, proving that CMD is a metric and that convergence in CMD implies convergence in distribution. Empirically, CMD achieves state-of-the-art performance on domain adaptation tasks for the Amazon Reviews and Office datasets, outperforming MMD and other baselines. The paper also claims that CMD is less sensitive to hyperparameter tuning, particularly the choice of its key parameter \( K \), compared to MMD.
Decision: Reject
While the paper introduces a promising metric with strong theoretical foundations, the experimental evaluation lacks sufficient rigor to convincingly support the claims of CMD's superiority over MMD. The absence of comparisons with MMD using explicit raw moments and limited exploration of CMD's limitations (e.g., lack of kernelizability) weaken the paper's impact.
Supporting Arguments for Decision
1. Proposed Metric and Theoretical Contributions:
   - CMD is well-motivated and theoretically sound, with clear advantages in computational efficiency and explicit moment matching. The proofs establishing CMD as a metric and its implications for distribution convergence are significant contributions.
   - However, the lack of kernelizability limits CMD's applicability to scenarios where kernel-based methods excel, such as high-dimensional feature spaces.
2. Experimental Limitations:
   - The experiments only compare CMD to kernelized MMD, neglecting comparisons with MMD using explicit raw moments. This omission undermines the claim that CMD is superior to MMD in all settings.
   - The datasets used (Amazon Reviews and Office) are standard but relatively small in scale. The results may not generalize to larger, more complex datasets.
   - The paper claims CMD avoids kernel parameter tuning, but this only applies to kernelized MMD. Established methods for tuning kernel parameters (e.g., cross-validation) are not discussed in detail, making the comparison incomplete.
3. Hyperparameter Tuning:
   - While CMD's insensitivity to its \( K \) parameter is a strength, the unconventional approach to tuning the beta parameter is not well-justified. Simple heuristics or standard tuning methods should have been explored first to ensure fair comparisons.
4. Practical Challenges:
   - CMD's lack of kernelizability and the reliance on bounded activation functions may limit its applicability in real-world scenarios. These challenges are not adequately addressed in the paper.
Suggestions for Improvement
1. Expand Experimental Comparisons:
   - Include comparisons with MMD using explicit raw moments and other kernelized methods (e.g., linear-time MMD estimators). This would provide a more comprehensive evaluation of CMD's performance.
   - Evaluate CMD on larger and more diverse datasets to demonstrate its scalability and generalizability.
2. Address Practical Limitations:
   - Discuss CMD's lack of kernelizability in greater depth and explore potential workarounds or extensions to address this limitation.
   - Provide a clearer justification for the unconventional beta parameter tuning approach and compare it with standard heuristics.
3. Clarify Claims:
   - The claim that CMD avoids kernel parameter tuning should be qualified to apply only to kernelized MMD. The paper should also acknowledge the existence of established methods for kernel parameter tuning.
4. Additional Analysis:
   - Investigate CMD's sensitivity to other hyperparameters (e.g., the weighting parameter \( \lambda \)) and its performance with unbounded activation functions (e.g., ReLU).
Questions for the Authors
1. Why were comparisons with MMD using explicit raw moments omitted? How would CMD perform in such a setting?
2. Can CMD be extended to handle unbounded activation functions (e.g., ReLU) without requiring clipping or normalization?
3. How does CMD perform on larger datasets or in high-dimensional feature spaces where kernelized methods like MMD typically excel?
4. Could CMD be kernelized to address its current limitations in handling complex feature spaces? If not, why?
In conclusion, while CMD is a theoretically sound and computationally efficient metric, the experimental evidence provided in the paper is insufficient to fully validate its claims of superiority over MMD. Addressing the outlined limitations and expanding the scope of the evaluation would significantly strengthen the paper.