Review of the Paper
Summary of Contributions
This paper extends adversarial and virtual adversarial training, previously applied primarily to image classification tasks, to the text domain by introducing perturbations at the word embedding level in LSTM-based models. The authors demonstrate that this approach improves text classification performance on multiple datasets, achieving state-of-the-art results in both supervised and semi-supervised settings. The paper also provides qualitative analysis, showing that the proposed method enhances the quality of word embeddings and reduces overfitting. The method is simple, requiring only one additional hyperparameter, and is easy to implement. The authors support their claims with extensive experimental results across five datasets, including IMDB, RCV1, and DBpedia.
Decision: Accept
The paper is well-motivated, scientifically rigorous, and provides significant contributions to the field of text classification. The key reasons for acceptance are:
1. Novelty and Impact: The adaptation of adversarial and virtual adversarial training to text classification is novel and addresses the challenge of sparse, high-dimensional inputs in text data. The method achieves state-of-the-art results, demonstrating its practical impact.
2. Clarity and Simplicity: The paper is well-written, with clear explanations of the methodology and sufficient references to prior work. The proposed method is simple, requiring minimal additional computational overhead and hyperparameter tuning.
Supporting Arguments
1. Scientific Rigor: The experiments are thorough, covering multiple datasets and comparing the proposed method against strong baselines, including random perturbations and state-of-the-art models. The results consistently show the superiority of adversarial and virtual adversarial training.
2. Theoretical Insights: The paper draws meaningful connections between adversarial training and related concepts, such as transductive SVMs and contrastive divergence, providing a deeper understanding of the method's theoretical underpinnings.
3. Practical Relevance: The method's simplicity and effectiveness make it highly applicable to real-world text classification tasks, especially in semi-supervised settings where labeled data is scarce.
Suggestions for Improvement
1. SVM Baseline: Including an SVM baseline (e.g., S. Wang and C. Manning, 2012) would provide a more comprehensive comparison, especially given the discussion on the relationship between adversarial training and transductive SVMs.
2. Masking Noise Baseline: Adding a word-dropping (masking noise) baseline could strengthen the experimental analysis, as this technique is often effective for text data.
3. Virtual Adversarial Training Issue: The underperformance of virtual adversarial training in Table 5 warrants further investigation. The authors should clarify whether tuning epsilon or issues with validation contributed to this result.
4. Broader Applications: While the paper mentions potential applications in other text tasks (e.g., machine translation, question answering), providing preliminary results or a discussion on the feasibility of extending the method to these tasks would enhance its impact.
Questions for the Authors
1. Why does virtual adversarial training underperform the baseline in Table 5? Could this be due to insufficient tuning of the hyperparameter epsilon or unreliable validation?
2. Can you elaborate on the computational cost of adversarial and virtual adversarial training compared to the baseline methods? Is the additional overhead significant for large-scale datasets?
3. How sensitive is the method to the choice of the norm constraint for adversarial perturbations? Did you observe any trends across datasets?
Overall, this paper makes a strong contribution to the field of text classification and is well-suited for acceptance at the conference. The suggestions provided aim to further strengthen the work and address minor gaps in the experimental analysis.