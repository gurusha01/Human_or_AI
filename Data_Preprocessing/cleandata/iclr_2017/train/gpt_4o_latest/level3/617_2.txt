Review
Summary of Contributions
This paper proposes methods to accelerate gradient descent in distributed deep learning by introducing layer-wise asynchronicity. The authors present a novel asynchronous layer-wise gradient descent method that overlaps backpropagation computation with gradient synchronization. The approach is implemented using Caffe and evaluated on both a CPU-based InfiniBand cluster and an NVIDIA DGX-1 system. The paper claims a speedup of up to 1.7x over synchronous training while maintaining convergence and accuracy. The authors also explore delayed gradient updates as an alternative asynchronous method, highlighting its effectiveness in hiding communication latency.
Decision: Reject
The paper is not ready for acceptance at ICLR due to significant shortcomings in its methodology and evaluation. While the proposed methods are interesting, the lack of rigorous benchmarking and insufficient comparison to state-of-the-art methods undermine the contributions.
Supporting Arguments
1. Baseline Weakness: The paper compares its asynchronous methods to a synchronous baseline but does not benchmark against state-of-the-art parameter-server-based approaches, which are widely recognized as the current standard for distributed gradient descent. This omission makes it difficult to assess the true novelty and impact of the proposed methods.
2. Evaluation Gaps: The evaluation lacks wall-time measurements, which are critical for assessing real-world performance. While the paper reports speedups in terms of iterations per second, this metric alone is insufficient to evaluate practical utility, especially when communication overheads and hardware-specific optimizations are involved.
3. Scientific Rigor: The claims of equivalence to sequential methods and the theoretical improvements in speedup are not adequately supported by formal proofs or detailed analysis. Additionally, the paper does not discuss potential trade-offs, such as the impact of asynchronicity on convergence stability or accuracy in more complex scenarios.
Suggestions for Improvement
1. Comparison to State-of-the-Art: Include evaluations against parameter-server-based methods and other recent distributed gradient descent techniques. This would provide a clearer picture of the relative advantages and limitations of the proposed methods.
2. Wall-Time Measurements: Report wall-clock training times alongside iterations per second to provide a more comprehensive evaluation of the methods' practical performance.
3. Broader Dataset and Model Scope: While AlexNet and GoogLeNet are useful benchmarks, evaluating the methods on more modern architectures (e.g., ResNet or Transformer models) and larger datasets would strengthen the paper's relevance and applicability.
4. Theoretical Analysis: Provide a more rigorous theoretical foundation for the proposed methods, including proofs of equivalence to sequential methods and a detailed analysis of the trade-offs between asynchronicity and convergence.
5. Clarity in Presentation: The paper's organization could be improved by separating implementation details from the core methodological contributions. Additionally, the inclusion of more visual aids (e.g., diagrams of the asynchronous processes) would enhance readability.
Questions for the Authors
1. How does the proposed method compare to parameter-server-based approaches in terms of convergence speed and scalability?
2. What is the impact of layer-wise asynchronicity on convergence stability for deeper or more complex models?
3. Why were wall-time measurements omitted, and how do you plan to address this in future work?
4. Could the delayed gradient approach introduce divergence or instability in scenarios with larger delays or more compute nodes?
In summary, while the paper introduces an interesting approach to accelerate gradient descent, it falls short in terms of evaluation rigor and comparison to existing methods. Addressing these issues would significantly enhance the paper's contributions and readiness for publication.