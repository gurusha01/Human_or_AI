Review
The paper investigates the impact of various factors on the performance of convolutional neural networks (CNNs) for instance-level image retrieval, focusing on pre-trained networks rather than end-to-end learning frameworks. The authors conduct extensive experiments to evaluate five key factors—feature aggregation, output layer selection, image resizing, multi-scale representation, and PCA/whitening—and propose a novel multi-scale image representation method. They demonstrate that their approach outperforms state-of-the-art methods across four benchmark datasets, particularly in scenarios requiring compact image representations. Additionally, the paper introduces a "layer ensemble" technique that further boosts retrieval performance by combining features from different layers.
Decision: Reject
While the paper provides a thorough evaluation of pre-trained CNNs for image retrieval and introduces a novel multi-scale representation method, it fails to address critical aspects of modern image retrieval research. Specifically, the lack of engagement with end-to-end learning frameworks, which have shown superior performance in recent studies, limits the relevance and applicability of the findings. Furthermore, the unclear distinction between full and cropped queries and the incomplete discussion of feature reuse in classification versus retrieval tasks weaken the paper's theoretical grounding.
Supporting Arguments for Decision:
1. Limited Scope: The paper explicitly avoids end-to-end learning frameworks, which are increasingly central to image retrieval research. While the authors position their work as orthogonal to these approaches, they do not provide sufficient evidence that their findings are transferable to end-to-end settings. This omission raises doubts about the broader applicability of the proposed method.
   
2. Unclear Query Handling: The paper does not adequately clarify how full and cropped queries are handled in their experiments. This lack of transparency makes it difficult to assess the robustness of the proposed method across different query types.
3. Feature Reuse Argument: The authors argue that image retrieval is more challenging than classification due to feature reuse, but this claim is only partially convincing. The paper does not provide a rigorous theoretical or empirical basis to substantiate this assertion.
Suggestions for Improvement:
1. Incorporate End-to-End Learning: The authors should explore how their findings translate to end-to-end learning frameworks. This could involve fine-tuning pre-trained networks or integrating their multi-scale representation method into an end-to-end pipeline.
2. Clarify Query Distinctions: Provide a detailed explanation of how full and cropped queries are processed and evaluated. This would enhance the reproducibility and interpretability of the results.
3. Strengthen Theoretical Justifications: The claim that image retrieval is more challenging than classification due to feature reuse requires stronger theoretical grounding or additional empirical evidence.
4. Broader Comparisons: Compare the proposed method against end-to-end approaches to provide a more comprehensive evaluation of its effectiveness.
Questions for the Authors:
1. How do you envision your findings being applied to end-to-end learning frameworks? Could your multi-scale representation method be integrated into such models?
2. Can you provide more details on how full and cropped queries are handled in your experiments? How do these distinctions affect the reported results?
3. What specific evidence supports your claim that image retrieval is more challenging than classification due to feature reuse?
In summary, while the paper offers valuable insights into pre-trained CNNs for image retrieval, its limited scope and lack of engagement with end-to-end learning frameworks make it less impactful in the context of current research trends. Addressing the outlined concerns could significantly strengthen the paper's contributions.