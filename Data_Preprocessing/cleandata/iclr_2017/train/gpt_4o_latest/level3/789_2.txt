Review
Summary of Contributions
The paper introduces a novel Markov Chain Monte Carlo (MCMC) sampling process for generative autoencoders, aiming to improve the quality of generated samples by sampling from the learned latent distribution \( P̂(Z) \) rather than the prior \( P(Z) \). The authors argue that this approach addresses the mismatch between \( P̂(Z) \) and \( P(Z) \), which is often overlooked in existing methods. Additionally, the paper extends the proposed MCMC sampling process to denoising generative autoencoders, demonstrating its utility in revealing the benefits of the denoising criterion. The authors claim that the method is straightforward to implement and can be applied to existing generative autoencoders without modifying their training procedures.
Decision: Reject
The decision to reject is based on two primary reasons: (1) the paper's claims of novelty are overstated, as it fails to adequately situate its contributions within prior work, particularly that of Rezende et al. (2014), and (2) the empirical evidence provided in the figures does not convincingly support the effectiveness of the proposed method.
Supporting Arguments
1. Confusing and Nonstandard Notation: The paper's notation is difficult to follow, which hampers the reader's ability to fully understand the proposed method. This issue is compounded by a lack of clarity in distinguishing between regular sampling and the proposed Gibbs chain in both the text and figures.
2. Overlooked Related Work: The paper does not sufficiently address prior work, especially that of Rezende et al. (2014), which also explores sampling in generative autoencoders. The authors claim that their approach is novel but fail to clearly articulate how it differs from or improves upon existing methods.
3. Incorrect Claims: The paper incorrectly asserts that it is impossible to draw samples from \( q(z) \), which is not true. This undermines the credibility of the theoretical framework presented.
4. Empirical Evidence: Figures 3 and 4 fail to provide compelling evidence for the effectiveness of the proposed method. The visual improvements in generated samples after MCMC sampling are marginal and do not convincingly demonstrate the claimed benefits.
5. Lack of Explanation for Observed Spaces: The paper does not clarify whether the proposed analysis applies to continuous or discrete observed spaces, leaving a gap in its theoretical justification.
Suggestions for Improvement
1. Notation and Clarity: Revise the notation to align with standard conventions in the field and ensure that the methodology is clearly explained. Provide a more explicit comparison between regular sampling and the proposed Gibbs chain.
2. Related Work: Address prior work more thoroughly, particularly Rezende et al. (2014), and clearly articulate how the proposed method advances the state of the art.
3. Empirical Evidence: Improve the quality of the figures and provide quantitative metrics to support the claims. For example, include evaluations using standard generative model benchmarks such as FID or IS scores.
4. Theoretical Claims: Correct the erroneous claim about sampling from \( q(z) \) and provide a more rigorous theoretical justification for the proposed method.
5. Observed Spaces: Clearly specify whether the analysis applies to continuous, discrete, or both types of observed spaces.
Questions for the Authors
1. How does your method compare quantitatively to prior work, such as Rezende et al. (2014), in terms of sample quality?
2. Can you provide additional evidence, beyond visual inspection, to demonstrate the effectiveness of the proposed MCMC sampling process?
3. Does the proposed method generalize to discrete observed spaces, or is it limited to continuous spaces?
4. How sensitive is the proposed method to the choice of the initial latent sample \( z_0 \)?
While the paper addresses an important problem in generative modeling, the lack of clarity, insufficient empirical evidence, and failure to adequately situate the work within the existing literature make it unsuitable for acceptance in its current form.