The paper proposes a novel architecture, TEM-HAM, for video captioning that incorporates a two-level attention mechanism. The Temporal Model (TEM) captures the temporal structure of video frames, while the Hierarchical Attention/Memory (HAM) module introduces a memory-based attention mechanism to consider both local and global contexts when generating captions. The authors claim that this architecture improves the ability to model complex relationships in video captioning tasks and achieves state-of-the-art results on the MSVD and Charades datasets. The paper also highlights the generalizability of the proposed architecture to other sequence learning tasks.
Decision: Reject
The decision to reject is based on two primary reasons: (1) Clarity and Presentation Issues: The paper suffers from poor writing, notational inconsistencies, and insufficient explanation of key components, particularly the HAM module and its memory update mechanism. This lack of clarity makes it challenging to fully understand and evaluate the contributions. Additionally, tables and figures are inadequately explained and inconsistently formatted, further hindering comprehension. (2) Marginal Experimental Gains: While the proposed model achieves slight improvements in METEOR scores, the gains are not substantial enough to convincingly justify the added complexity of the architecture. The ablation studies also yield mixed results, raising doubts about the robustness of the claimed improvements.
Supporting Arguments:
1. Clarity Issues: The HAM module, a central component of the proposed architecture, is vaguely described, particularly in terms of how it updates memory states. The notation for key equations (e.g., Eq. 6â€“9) is inconsistent, and the role of variables like `f_m` is unclear. These issues make it difficult to replicate or validate the method.
2. Experimental Results: The reported state-of-the-art results are not compelling. While the METEOR score shows slight improvement, other metrics like BLEU and CIDEr do not consistently outperform existing methods. The ablation studies reveal that removing TEM or HAM components does not drastically degrade performance, suggesting limited synergy between the two modules.
3. Moderate Novelty: The introduction of a second attention layer to reduce LSTM memory burden is a reasonable idea, but it is not groundbreaking. Similar memory-based attention mechanisms have been explored in prior work, and the paper does not sufficiently differentiate itself from these approaches.
Suggestions for Improvement:
1. Clarity and Writing: Revise the paper for better readability. Provide detailed explanations of the HAM module and its memory update mechanism. Ensure consistent notation throughout the paper and clearly define all variables and terms.
2. Experimental Rigor: Strengthen the experimental results by including more datasets and metrics to demonstrate the generalizability of the model. Provide statistical significance tests to validate the improvements.
3. Presentation: Improve the quality and clarity of tables and figures. Each table and figure should be accompanied by a detailed explanation in the text.
4. Comparative Analysis: Provide a more thorough comparison with existing methods, particularly those that also use memory-based attention mechanisms. Highlight the specific advantages of TEM-HAM over these approaches.
Questions for the Authors:
1. Can you provide a more detailed explanation of how the HAM module updates its memory states and how these updates contribute to caption generation?
2. How does the proposed architecture handle long videos with significant temporal variations? Are there any limitations in terms of scalability?
3. Why do the ablation studies show only marginal performance differences when either TEM or HAM is removed? Does this suggest redundancy in the architecture?
In conclusion, while the paper introduces an interesting idea, the lack of clarity, marginal experimental gains, and moderate novelty do not meet the standards for acceptance at this time. Addressing the feedback provided could significantly improve the quality and impact of the work.