Review of the Paper
Summary of Contributions
This paper proposes a novel Layer-RNN (L-RNN) module that integrates recurrent neural networks (RNNs) within convolutional neural networks (CNNs) to capture long-range dependencies. The authors present three key contributions: (i) a hybrid architecture that interleaves CNNs and L-RNNs for multi-scale contextual learning, (ii) a method to fine-tune pre-trained CNNs by inserting L-RNNs without requiring retraining from scratch, and (iii) experimental validation on CIFAR-10 and PASCAL VOC12 datasets, demonstrating performance improvements in image classification and semantic segmentation tasks. The paper is well-written, with systematic evaluations and ablation studies supporting the proposed approach.
Decision: Reject
While the paper is clear and presents a practical, adaptable idea, the lack of significant novelty and limited experimental validation on broader datasets are key reasons for rejection. Additionally, some aspects of the evaluation and presentation raise concerns about the robustness of the claims.
Supporting Arguments
1. Novelty Concerns: The proposed approach is conceptually similar to prior work, particularly Bell et al. (2016) and Visin et al. (2015). While the paper introduces technical refinements, such as interleaving L-RNNs with CNNs and fine-tuning pre-trained networks, these contributions are incremental rather than groundbreaking.
2. Evaluation Limitations: The experiments on CIFAR-10, while thorough, are limited to a relatively small dataset. The absence of validation on larger datasets like ImageNet weakens the generalizability of the findings. Furthermore, the semantic segmentation results on PASCAL VOC12, while promising, lack comparisons with non-recurrent alternatives that add similar numbers of parameters.
3. Misleading Presentation: Table 3's comparison of FCN-8s and FCN8s-LRNN is misleading, as the prefix "FCN8s" does not correspond to the original work by Long et al. (2015). This could confuse readers and detracts from the paper's credibility.
4. Comparison with State-of-the-Art: Wide Residual Networks (WRNs) achieve better results on CIFAR-10 without recurrence, questioning the necessity of L-RNNs unless targeting shallow networks. The paper does not adequately address this comparison.
Additional Feedback for Improvement
1. Experimental Validation: Include experiments on larger datasets like ImageNet to demonstrate the scalability and generalizability of the proposed method. Additionally, compare L-RNNs with non-recurrent alternatives that add similar parameter counts to isolate the benefits of recurrence.
2. Clarify Contextual Claims: The claim that L-RNNs learn larger contextual ranges in FCN-8s is unclear, especially why this does not apply to FCN-32s. Provide more detailed explanations and visualizations to support this assertion.
3. Figures and Appendices: Address the missing Figures 2b and 2c, simplify Figure 4, and provide detailed learning rate schedules and training setups in the appendices for reproducibility.
4. Typos and Grammar: Correct minor grammatical issues, such as "maps ... is" instead of "maps ... are."
Questions for the Authors
1. How does the performance of L-RNNs compare to non-recurrent alternatives with similar parameter counts? Can you provide experiments isolating the effect of recurrence?
2. Why was ImageNet not included in the evaluation? Are there scalability concerns with the proposed architecture?
3. Can you clarify the rationale behind the contextual range claims for FCN-8s versus FCN-32s? Why does the L-RNN's benefit diminish in FCN-32s?
In conclusion, while the paper presents a practical and well-executed idea, the lack of significant novelty, limited validation, and some presentation issues prevent it from meeting the standards for acceptance. Addressing these concerns could make the work more impactful in future submissions.