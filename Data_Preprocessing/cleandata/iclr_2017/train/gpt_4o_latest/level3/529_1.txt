The paper proposes a novel approach to sequence modeling by combining Long Short-Term Memory (LSTM) networks with reinforcement learning (RL) to generate musically meaningful outputs. Specifically, the authors introduce "RL Tuner," which uses a pre-trained Note RNN to supply part of the reward function in an RL framework. This allows the model to refine its outputs by adhering to handcrafted music-theory-based rules while retaining information learned from data. The authors demonstrate that this method improves upon the baseline Note RNN by producing melodies that are more structured, harmonious, and subjectively pleasing.
Decision: Reject
While the paper presents an interesting and practical approach to improving music generation, the methodological limitations and lack of scalability outweigh its contributions. The primary reasons for rejection are: (1) the ad-hoc and simplistic nature of the handcrafted reward functions, which limits the generalizability of the approach, and (2) the reliance on LSTMs, which may not be the most suitable architecture for this task given the availability of more advanced models like dilated convolutional networks.
Supporting Arguments:
1. Strengths:
   - The use of handcrafted reward functions is a practical innovation, especially for scenarios where domain experts (e.g., musicians) prefer rule-based control over generated outputs.
   - The paper provides a thorough analysis of the model's behavior, with Table 1 offering valuable insights into the impact of the RL tuning process.
   - The combination of maximum likelihood training and RL is a promising direction for addressing common failure modes in sequence generation tasks, such as repetition and lack of structure.
2. Weaknesses:
   - The handcrafted reward functions, while effective for simple monophonic melodies, are overly simplistic and do not scale to more complex musical structures or polyphony. This limits the broader applicability of the approach.
   - The reliance on LSTMs is questionable, as alternative architectures like dilated convolutional networks or transformers have shown superior performance in sequence modeling tasks, including music generation.
   - The melodies generated, while improved, still fall short of being meaningful compositions. The lack of polyphony and expressive dynamics highlights the need for collaboration with trained musicians to refine the evaluation criteria and reward functions.
   - Figure 3 lacks real melody excerpts, which makes it difficult to evaluate the subjective quality of the outputs. The user study results are promising but insufficiently detailed to draw strong conclusions.
Suggestions for Improvement:
1. Explore more scalable and expressive reward functions that can handle polyphony and richer musical structures.
2. Evaluate the use of alternative sequence modeling architectures, such as transformers or convolutional networks, to determine if they can better capture the nuances of music generation.
3. Include real melody excerpts in the figures to allow for qualitative evaluation by readers.
4. Collaborate with musicians to design more sophisticated evaluation metrics and reward functions that align with professional standards of musicality.
5. Provide a more detailed discussion of the method's limitations, particularly its scalability and architectural choices.
Questions for the Authors:
1. How does the model perform when generating longer compositions or polyphonic music? Can the handcrafted reward functions be extended to handle these scenarios?
2. Why was the LSTM chosen over more modern architectures like transformers or dilated convolutional networks? Have these alternatives been tested?
3. Can you provide more details about the user study? For example, what criteria did participants use to evaluate the melodies, and how were they instructed to rate them?
In summary, while the paper demonstrates practical techniques for improving music generation, the limited novelty, scalability concerns, and reliance on outdated architectures make it unsuitable for acceptance in its current form. However, the work has potential and could be significantly strengthened with the suggested improvements.