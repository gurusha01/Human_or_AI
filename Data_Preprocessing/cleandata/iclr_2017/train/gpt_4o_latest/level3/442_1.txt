Review of the Paper: "Deep Variational Information Bottleneck"
Summary of Contributions
This paper introduces the "Deep Variational Information Bottleneck" (VIB), a novel adaptation of the Information Bottleneck (IB) principle for supervised learning using deep neural networks. By leveraging variational inference and the reparameterization trick, the authors propose a method that balances the tradeoff between compressing input information and preserving predictive power. The paper claims that VIB serves as an effective regularizer, improving generalization and robustness to adversarial attacks. The authors provide theoretical grounding, relate their method to prior work, and present experimental results on MNIST and ImageNet datasets, demonstrating the method's performance and robustness.
Decision: Reject
While the paper presents a novel and theoretically grounded approach, the experimental results and comparisons are insufficient to justify its acceptance. The method's competitiveness as a regularizer and its practical applicability remain unclear due to weak baselines and limited empirical evidence.
Supporting Arguments for Decision
1. Strengths:
   - Novelty: The adaptation of the IB principle to supervised learning using variational inference is innovative and well-motivated. The connection to variational autoencoders and prior work is clearly articulated.
   - Presentation: The paper is well-written, with a clear explanation of the method and its theoretical underpinnings. The experiments on adversarial robustness are compelling and highlight the potential of VIB in this domain.
   - Robustness to Adversarial Examples: The experiments convincingly demonstrate that VIB-trained models are more robust to adversarial attacks compared to deterministic baselines.
2. Weaknesses:
   - Competitiveness as a Regularizer: The paper does not provide sufficient evidence that VIB outperforms standard regularization techniques like dropout or batch normalization. For example, on MNIST, the reported error rate (1.13%) is only marginally better than prior work (1.17%) and worse than state-of-the-art methods.
   - Tuning Difficulty: The method introduces an additional hyperparameter (β), which requires careful tuning. The paper does not provide practical guidance on selecting β, making the method less accessible for practitioners.
   - Architectural Choices: The use of simple logistic regression for \( p(y|z) \) is not justified, and the impact of this choice on performance is unclear. Exploring more complex decoders could strengthen the results.
   - Limited Comparisons: The robustness experiments lack quantitative comparisons to external baselines, such as adversarial training or other robust regularization techniques. This omission makes it difficult to assess the practical significance of the robustness claims.
Suggestions for Improvement
1. Stronger Baselines: Compare VIB to a wider range of regularization techniques (e.g., dropout, label smoothing, weight decay) on multiple datasets. Include state-of-the-art results for context.
2. Hyperparameter Analysis: Provide a detailed analysis of the sensitivity of VIB to the choice of β and discuss strategies for selecting it in practice.
3. Architectural Justifications: Justify the use of simple logistic regression for \( p(y|z) \) and explore alternative architectures for the decoder.
4. Adversarial Training: Investigate the effects of combining VIB with adversarial training and evaluate its impact on robustness and variance in \( p(z|x) \).
5. Broader Experiments: Extend the experiments to more challenging datasets and tasks to demonstrate the generalizability of the method.
Questions for the Authors
1. How does VIB compare to adversarial training in terms of robustness to adversarial examples? Can the two methods be combined effectively?
2. What is the computational overhead of VIB compared to standard regularization techniques?
3. How does the choice of the decoder architecture (\( p(y|z) \)) affect the performance of VIB? Would a more expressive decoder improve results?
Conclusion
The paper introduces a promising method with strong theoretical foundations and potential applications in adversarial robustness. However, the lack of compelling empirical evidence and practical guidance limits its impact. Addressing the outlined weaknesses and expanding the experimental scope would significantly strengthen the paper.