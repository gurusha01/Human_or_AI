Review of the Paper
Summary
This paper presents an innovative application of neural networks, specifically LSTM-based models, for the task of code completion in dynamically typed programming languages, with a focus on JavaScript. The authors propose several neural network architectures that leverage structural information from Abstract Syntax Trees (ASTs) to predict the next non-terminal and terminal nodes in a program. The paper demonstrates that these models outperform the state-of-the-art decision tree-based methods, achieving improvements of 3.8% and 0.5% in next non-terminal and terminal prediction tasks, respectively. The authors also explore joint prediction, denying prediction for rare tokens (UNK), and runtime efficiency, showing the feasibility of deploying these techniques in real-time code completion engines.
Decision: Reject
While the paper introduces a novel application of neural networks to code completion and achieves promising results, it suffers from several critical issues that undermine its clarity and scientific rigor. The lack of clarity in key methodological aspects and the comparability of results, along with insufficient exploration of certain design choices, limit its contribution in its current form.
Supporting Arguments for Decision
1. Strengths:
   - The paper explores a novel domain (code completion for dynamically typed languages) and demonstrates the potential of neural networks in this area.
   - The use of ASTs to incorporate structural information into the prediction task is well-motivated and innovative.
   - The results show measurable improvements over state-of-the-art methods, and the runtime analysis suggests practical feasibility.
2. Weaknesses:
   - Methodological Clarity: The computation of NT2N+NTN2T top-5 accuracy is unclear. It is not specified whether this involves maximizing multiplied posterior probabilities or another approach. This ambiguity makes it difficult to assess the validity of the results.
   - Incomplete Exploration of Combinations: It is unclear whether all combinations of NT2N decisions with possible NTN2T outcomes were considered, which could impact the reported joint prediction accuracy.
   - Use of UNK: The decision to introduce UNK terminals later in the process, despite having a predefined lexicon size, limits the model's predictive capabilities early on. This design choice is not sufficiently justified.
   - Comparability of Results: The numbers compared in Section 5.5 (second paragraph) are not directly comparable, which undermines the validity of the conclusions drawn from these comparisons.
   - Hyperparameter Tuning: The paper does not adequately address how the optimal alpha value for UNK was determined, leaving a gap in understanding the trade-offs between overall accuracy and non-UNK accuracy.
Additional Feedback
1. Improving Clarity:
   - Provide a detailed explanation of how NT2N+NTN2T top-5 accuracy is computed to ensure reproducibility and clarity.
   - Clearly specify whether all combinations of NT2N and NTN2T decisions were explored during joint prediction.
2. UNK Handling:
   - Introduce the use of UNK terminals from the start to avoid limiting predictions early in the training process. This would allow for a more consistent evaluation of the model's capabilities.
   - Conduct a more thorough analysis of the impact of varying alpha values on the model's performance and provide a clear justification for the chosen value.
3. Comparability of Results:
   - Ensure that all numbers compared in Section 5.5 are directly comparable. If they are not, provide additional context or adjust the evaluation methodology.
4. Focus on Practical Implications:
   - While the runtime analysis is promising, more discussion on how these techniques could be integrated into real-world IDEs would strengthen the paper's practical relevance.
Questions for the Authors
1. How exactly is the NT2N+NTN2T top-5 accuracy computed? Does it involve maximizing multiplied posterior probabilities, or is another approach used?
2. Were all combinations of NT2N decisions with possible NTN2T outcomes considered during joint prediction? If not, how were the combinations selected?
3. Why was the use of UNK terminals introduced later in the process, despite the predefined lexicon size? How would the results change if UNK was used from the start?
4. How was the optimal alpha value for UNK determined? Could you provide more details on the trade-offs observed during this process?
In conclusion, while the paper has potential, addressing these issues is essential to ensure its clarity, rigor, and impact.