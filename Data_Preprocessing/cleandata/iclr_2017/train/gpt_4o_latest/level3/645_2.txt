The paper introduces Deep Generalized Canonical Correlation Analysis (DGCCA), a novel method for nonlinear multiview representation learning that extends Generalized CCA (GCCA) to deep neural networks. The primary contribution lies in deriving the gradient update for the GCCA objective, enabling efficient stochastic optimization. The authors demonstrate DGCCA's utility on synthetic and real-world datasets, showcasing its ability to outperform linear GCCA and two-view Deep CCA (DCCA) in tasks such as phoneme classification and Twitter hashtag recommendation. The paper claims DGCCA is the first method to combine nonlinear representation learning with multiview statistical power for arbitrary numbers of views.
Decision: Reject.  
Key reasons:  
1. The claim of DGCCA being the first nonlinear multiview representation learning method is inaccurate and overlooks prior work, particularly [R1], which already combines nonlinear representation learning with multiview statistical power.  
2. The related work section is sparse and fails to adequately situate DGCCA within the broader literature, omitting significant advances in two-view nonlinear representation learning.  
Supporting Arguments:  
While the derivation of the gradient update for the GCCA objective is a valuable technical contribution, the paper's novelty is overstated. [R1] introduces a nonlinear multiview representation learning method that supports more than two views, making it a critical baseline for comparison. The authors do not provide empirical or theoretical evidence to demonstrate DGCCA's superiority over [R1], leaving its practical utility unvalidated. Additionally, the related work section does not sufficiently discuss prior advancements in nonlinear CCA methods, which weakens the paper's positioning in the literature.  
Additional Feedback:  
1. Comparison with [R1]: The authors should include a thorough comparison with [R1], both theoretically and empirically, to clarify DGCCA's advantages.  
2. Related Work Expansion: The related work section should be expanded to include significant contributions in nonlinear two-view and multiview representation learning, such as kernel CCA and other deep learning-based methods.  
3. Empirical Evaluation: While the experiments demonstrate DGCCA's potential, the evaluation could be strengthened by including more diverse datasets and tasks. Additionally, the authors should provide a clearer discussion of why DGCCA outperforms linear GCCA and DCCA in specific scenarios.  
Questions for Authors:  
1. How does DGCCA compare to [R1] in terms of both performance and computational efficiency?  
2. Can you elaborate on the limitations of DGCCA, particularly in terms of scalability to high-dimensional data or large numbers of views?  
3. Why was [R1] omitted from the related work section, and how does DGCCA address its limitations, if any?  
Overall, while DGCCA presents an interesting extension of GCCA, the paper requires significant revisions to address the overstated claims, situate the work within the existing literature, and provide a more comprehensive evaluation.