Review of "Layerwise Origin Target Synthesis (LOTS)" Paper
Summary of Contributions:
The paper introduces the Layerwise Origin Target Synthesis (LOTS) method, a novel approach for analyzing and manipulating internal feature representations in deep neural networks (DNNs). LOTS serves three main purposes: (1) visualizing internal representations of inputs at any layer, (2) assessing the stability of learned features with respect to input classes, and (3) generating diverse adversarial examples by modifying internal representations. The authors demonstrate LOTS on the LeNet and VGG Face models, showcasing its ability to visualize feature representations, generate adversarial examples, and improve adversarial robustness through training. The paper positions LOTS as a generalization of existing adversarial generation techniques, offering greater diversity in perturbations and insights into network behavior.
Decision: Borderline Accept (Score: 6)
The paper presents an interesting and technically sound method with potential applications in visualization, adversarial robustness, and interpretability. However, the utility of the proposed visualizations remains unclear, and the experimental results, while promising, lack sufficient comparisons with state-of-the-art methods. The paper is borderline acceptable, contingent on addressing the following concerns.
Supporting Arguments:
1. Strengths:
   - The LOTS method is innovative and well-motivated, addressing both visualization and adversarial generation in a unified framework.
   - The experiments demonstrate the flexibility of LOTS in visualizing internal representations and generating adversarial examples across multiple layers.
   - The paper highlights the potential of LOTS for adversarial training, achieving improved robustness compared to baseline methods.
2. Weaknesses:
   - The utility of LOTS visualizations is not convincingly demonstrated. While the visualizations are intriguing, their practical significance for understanding or improving DNNs is unclear.
   - The experimental results lack direct comparisons with state-of-the-art adversarial generation methods, such as Fast Gradient Sign (FGS) or Projected Gradient Descent (PGD), particularly in terms of classifier robustness.
   - The network architecture and layer details used in experiments are insufficiently described, limiting reproducibility and interpretability.
   - The significance and interpretation of the PASS score, used to evaluate adversarial quality, are not adequately explained.
Suggestions for Improvement:
1. Experiments and Comparisons:
   - Conduct experiments comparing LOTS-generated adversarial examples with existing methods (e.g., FGS, PGD) to evaluate classifier robustness and adversarial quality.
   - Include results for applying LOTS to the input and output layers to provide a more comprehensive analysis of its capabilities.
2. Clarity and Reproducibility:
   - Provide detailed descriptions of the network architectures and layer configurations used in the experiments.
   - Clarify the definition, significance, and interpretation of the PASS score, particularly in relation to adversarial quality.
3. Visualization Utility:
   - Strengthen the argument for the semantic interpretability of lower convolutional layers by providing quantitative or qualitative evidence.
   - Explore practical applications of LOTS visualizations, such as debugging or improving network architectures.
Questions for the Authors:
1. How does LOTS compare to state-of-the-art adversarial generation methods in terms of classifier robustness and computational efficiency?
2. Can you provide more evidence or examples to support the claim that LOTS visualizations are semantically meaningful, particularly for higher layers?
3. How does the choice of target images affect the diversity and quality of adversarial examples generated by LOTS?
In conclusion, while the paper introduces an interesting and versatile method, additional experiments, comparisons, and clarifications are needed to fully establish its contributions and practical utility.