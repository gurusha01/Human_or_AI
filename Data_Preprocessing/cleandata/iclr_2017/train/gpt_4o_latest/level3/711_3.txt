The paper introduces RASOR, a novel model for extractive question answering, focusing on efficiently representing and scoring answer spans from a passage. By leveraging recurrent networks, RASOR computes fixed-length span representations and employs global score normalization, addressing limitations in previous models like Match-LSTM. The authors demonstrate that RASOR achieves a 5% improvement in exact match accuracy and a 3.6% improvement in F1 score over the best published results, significantly reducing the gap between baseline and human performance on the SQuAD dataset. The paper also highlights the importance of question-independent and passage-aligned representations in improving model performance.
Decision: Reject.  
While the paper presents an interesting and well-executed idea, the contribution is incremental rather than groundbreaking. The performance improvement over existing models, though measurable, is modest. Furthermore, the paper does not sufficiently clarify whether the observed gains are due to superior architecture or extensive hyperparameter tuning, leaving questions about the generalizability of the approach.
Supporting Arguments:  
1. Strengths:  
   - The paper is well-motivated and addresses a relevant problem in NLP, particularly for the SQuAD dataset.  
   - The use of global score normalization and explicit span representations is a logical and well-implemented improvement over greedy decoding methods.  
   - The analysis experiments are insightful, particularly in showing the complementary benefits of question-independent and passage-aligned representations.  
2. Weaknesses:  
   - The improvement over Match-LSTM, while significant in error reduction terms, is not transformative. The gains (5% exact match, 3.6% F1) may not justify the additional complexity introduced by RASOR.  
   - The paper does not convincingly address whether the improvements stem from architectural innovations or extensive hyperparameter tuning. This lack of clarity weakens the claim of RASOR's superiority.  
   - The model's simplicity, while a potential strength, is not explored in combination with other techniques, which could have strengthened its impact.
Suggestions for Improvement:  
1. Provide a more detailed comparison with Match-LSTM, focusing on whether the gains are due to architectural differences or better optimization (e.g., hyperparameter tuning).  
2. Explore combining RASOR with other techniques, such as co-attention mechanisms, to demonstrate its flexibility and potential for broader applicability.  
3. Include ablation studies to isolate the contributions of specific components, such as global normalization and span representations, to the overall performance.  
4. Address the scalability of RASOR for longer passages, as the quadratic computation of spans may become a bottleneck in real-world applications.
Questions for the Authors:  
1. How sensitive is RASOR's performance to hyperparameter choices compared to Match-LSTM?  
2. Can the authors provide more details on the computational efficiency of RASOR, particularly for longer passages?  
3. How does RASOR perform on other datasets or tasks, and is its architecture generalizable beyond SQuAD?  
In summary, while RASOR is a well-designed model with measurable improvements, the paper falls short of making a compelling case for its broader impact or novelty. Addressing the above concerns could significantly strengthen the contribution.