Review of "Deep Generalized Canonical Correlation Analysis (DGCCA)"
Summary of Contributions:
The paper introduces Deep Generalized Canonical Correlation Analysis (DGCCA), a novel method for nonlinear multiview representation learning that extends classical CCA approaches. DGCCA combines the flexibility of nonlinear transformations (from Deep CCA) with the ability to handle multiple views (from Generalized CCA). The authors present a stochastic optimization algorithm for DGCCA and evaluate its effectiveness on synthetic data, phonetic transcription, and Twitter hashtag and friend recommendation tasks. The results demonstrate that DGCCA outperforms existing methods, particularly in tasks requiring multiview representation learning. The authors also provide an open-source implementation, which is a valuable contribution to the community.
Decision: Reject
While the paper presents a promising method with clear empirical benefits, it falls short in several critical areas that hinder its acceptance. The primary reasons for rejection are the lack of a thorough complexity analysis and insufficient novelty in the methodological approach, as it largely builds on classical tools without exploring alternative solutions for combining views. Additionally, issues with experimental reproducibility and an incomplete related work section further weaken the paper.
Supporting Arguments:
1. Strengths:
   - The proposed DGCCA method is well-motivated and addresses a clear gap in multiview learning by enabling nonlinear transformations for arbitrarily many views.
   - The empirical results are promising, showing improvements in phonetic transcription and hashtag recommendation tasks.
   - The open-source implementation is a commendable step toward reproducibility and practical adoption.
2. Weaknesses:
   - Complexity Analysis: The paper lacks a detailed complexity analysis of the DGCCA optimization process. While the authors mention the time complexity of gradient computation, a comprehensive discussion of scalability with respect to the number of views, data dimensionality, and network architecture is missing.
   - Novelty: The method is primarily an extension of existing tools (Deep CCA and GCCA). The authors do not explore alternative strategies for combining views, such as attention mechanisms or other deep learning paradigms, which could enhance the novelty of the approach.
   - Experimental Reproducibility: The synthetic experiments are not described in sufficient detail, and the datasets used for real-world tasks are not made available. This limits the ability of other researchers to verify the results.
   - Incomplete Related Work: The related work section omits recent advances in multiview and multimodal learning, such as attention-based methods or contrastive learning approaches, which could provide a more comprehensive context for the proposed method.
Suggestions for Improvement:
1. Complexity Analysis: Include a detailed analysis of the computational and memory requirements of DGCCA, particularly in comparison to existing methods like DCCA and GCCA.
2. Novelty: Explore alternative approaches for combining views, such as using attention mechanisms or contrastive objectives, to enhance the methodological contribution.
3. Experimental Details: Provide more information about the synthetic experiments, including data generation processes and hyperparameter settings. Ensure that datasets for real-world tasks are publicly available to facilitate reproducibility.
4. Related Work: Expand the related work section to include recent advances in multiview/multimodal learning, such as contrastive learning, variational methods, and attention-based approaches.
5. Evaluation Metrics: While the paper uses reconstruction error and downstream task performance, additional metrics (e.g., correlation or alignment scores) could provide a more nuanced evaluation of the learned representations.
Questions for the Authors:
1. How does the computational cost of DGCCA scale with the number of views and the size of the datasets? Can DGCCA handle high-dimensional views with limited computational resources?
2. Did you explore alternative methods for combining views, such as attention-based mechanisms or contrastive learning objectives? If not, why were these approaches not considered?
3. Can you provide more details about the synthetic data generation process and the hyperparameters used in the experiments? Will the datasets for real-world tasks be made publicly available?
In summary, while DGCCA is a promising method with strong empirical results, the paper requires significant improvements in its theoretical analysis, novelty, and experimental reproducibility to meet the standards of the conference.