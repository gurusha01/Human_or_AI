Review of the Paper
The paper addresses the challenging problem of modeling relational time series, where observations are correlated both temporally within individual series and relationally across multiple series. The proposed model, Relational Dynamic model with Gaussian representations (RDG), introduces a novel latent variable approach inspired by deep learning. It incorporates Gaussian latent factors to model uncertainty and employs reconstruction error, latent state smoothness, and trajectory similarity regularization to capture temporal and relational dependencies. The paper claims to outperform state-of-the-art models in prediction accuracy while also providing uncertainty quantification, a valuable feature for applications requiring confidence intervals.
Decision: Reject
The decision to reject is primarily based on two key issues: (1) the lack of clarity in the presentation of the model and results, and (2) the unconvincing experimental validation. While the proposed approach is conceptually interesting, these weaknesses significantly hinder the paper's impact and scientific rigor.
Supporting Arguments
1. Strengths:
   - The paper tackles an important and underexplored problem, combining uncertainty modeling with deep learning-inspired methods.
   - The use of KL divergence for trajectory similarity regularization is clever, providing a simple and differentiable term to enforce relational constraints.
   - The model is flexible and compatible with other methods, such as variational autoencoders, which makes it extensible for future work.
2. Weaknesses:
   - Presentation Issues: The model definition is overly dense and lacks clarity, making it difficult to follow. Key components, such as the decoder and dynamic functions, are not explained intuitively. Additionally, the experimental results are presented in a fragmented manner, making it hard to draw solid conclusions.
   - Sparse Learning and Inference Details: The paper provides insufficient details on the learning process and inference mechanism. For example, how the hyperparameters (e.g., 位Dy, 位R) are tuned is not adequately discussed.
   - Experimental Validation: The experiments are conducted on small datasets with weak baselines (e.g., simple AR and FFNN models), which do not convincingly demonstrate the superiority of the proposed model. The reported improvements over RNNs and Kalman Filters are marginal, and the novelty over recurrent VAEs is unclear.
   - Positioning: The paper does not sufficiently differentiate itself from existing models, such as recurrent VAEs or deterministic latent variable models. The novelty appears incremental, as similar goals could be achieved with slight extensions of prior work.
Suggestions for Improvement
1. Clarity and Structure: Restructure the manuscript to improve readability. Provide an intuitive explanation of the model components before delving into mathematical details. Use diagrams to illustrate the architecture and flow of the model.
2. Learning and Inference: Include detailed descriptions of the learning process, hyperparameter selection, and inference steps. Discuss computational complexity and scalability.
3. Experimental Validation: Conduct experiments on larger, more diverse datasets and compare against stronger baselines, such as advanced recurrent VAEs or graph-based models. Provide statistical significance tests to validate the reported improvements.
4. Positioning: Clearly articulate the novelty of the approach and its advantages over existing models. Discuss scenarios where RDG would be particularly beneficial compared to alternatives.
Questions for the Authors
1. How does the proposed model scale to larger datasets or more complex relational graphs? Have you considered computational trade-offs?
2. Can you provide more details on the choice of baselines and why recurrent VAEs or graph-based models were not included in the comparisons?
3. How sensitive is the model to hyperparameter tuning, particularly 位Dy and 位R? Could you elaborate on the tuning process?
While the paper presents an interesting idea, the aforementioned issues need to be addressed to make it a strong contribution to the field.