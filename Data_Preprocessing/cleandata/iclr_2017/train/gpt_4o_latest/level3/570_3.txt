Review of the Paper
The paper proposes a neural architecture, referred to as the Neural Answer Construction Model, for answering non-factoid questions. It claims to address two key limitations of existing methods: the inability to handle contextual word ambiguities and the inability to generate new answers rather than selecting from pre-existing ones. The model incorporates semantic biases into word embeddings and employs a biLSTM-based framework to construct answers by combining conclusion and supplementary sentences. Experiments conducted on a Japanese love advice corpus demonstrate that the model outperforms existing baselines, achieving 20% higher accuracy in answer construction. Additionally, the model has been deployed in a real-world application, where its answers were rated twice as good as those of human contributors.
Decision: Reject
The primary reasons for rejection are the lack of sufficient technical novelty and limitations in the model's generalizability. While the paper demonstrates practical utility, its contributions are incremental and closely resemble QA-LSTM (Tan et al., 2015), with minor modifications such as the addition of semantic biases and fixed templates for sentence ordering. Furthermore, the reliance on a fixed answer structure template restricts the model's ability to dynamically learn sentence ordering, limiting its applicability to broader non-factoid QA datasets like InsuranceQA. The examples provided in Table 4 do not convincingly demonstrate a clear quality advantage over QA-LSTM, and the model may have an unfair advantage by explicitly knowing which sentences are conclusions and which are supplementary.
Supporting Arguments
1. Novelty: The model's architecture is largely derivative of QA-LSTM, with the primary additions being semantic bias in word embeddings and a fixed template for answer construction. The "word embedding with semantics" approach is essentially a variation of the paragraph vector model (Le & Mikolov, 2014) and does not introduce a fundamentally new concept.
2. Generalizability: The reliance on a fixed template for answer structure makes the model domain-specific and unsuitable for evaluation on widely-used non-factoid QA datasets. This limits its broader applicability and reduces its impact on the QA research community.
3. Empirical Evidence: While the model achieves higher accuracy on the love advice corpus, the examples in Table 4 do not convincingly demonstrate a significant qualitative improvement over QA-LSTM. The human evaluation results, though promising, are domain-specific and do not provide sufficient evidence of the model's general effectiveness.
Additional Feedback
1. The paper would benefit from a clearer articulation of its novelty compared to QA-LSTM and other existing methods. Specifically, the authors should clarify how their approach fundamentally advances the state of the art in non-factoid QA.
2. The reliance on a fixed template for answer construction is a significant limitation. Future work could explore dynamic learning of sentence ordering to improve the model's adaptability to diverse datasets.
3. The evaluation is limited to a single domain (love advice). Expanding the experiments to include other non-factoid QA datasets would strengthen the paper's claims about the model's generalizability.
4. The paper should address the potential unfair advantage of explicitly labeling conclusion and supplementary sentences, as this information is not typically available in real-world QA datasets.
Questions for the Authors
1. How does the proposed model perform on other non-factoid QA datasets, such as InsuranceQA or Quora? Can the fixed template approach generalize to these datasets?
2. How does the model handle cases where the predefined sentence types (e.g., conclusion, supplement) do not align with the structure of the desired answer?
3. Could the authors provide more detailed examples or qualitative analysis to illustrate the claimed improvements in answer quality over QA-LSTM?
4. How does the model's performance compare when the explicit labeling of conclusion and supplementary sentences is removed? Would it still outperform QA-LSTM?
While the paper demonstrates practical utility in a specific domain, its lack of technical novelty and limited generalizability make it unsuitable for publication at ICLR. Addressing the above concerns could significantly improve the paper's contribution to the field.