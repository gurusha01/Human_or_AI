Review of the Paper
Summary of Contributions
This paper proposes a JavaScript-based matrix and deep learning library that enables deep learning tasks to be performed on web browsers using GPGPU via the WebCL framework. The authors aim to democratize access to deep learning by eliminating the need for specialized hardware or software installation. The framework supports training large-scale CNNs, such as VGGNet and ResNet, and demonstrates distributed training using web browsers as clients. The work claims to provide a novel approach to distributed deep learning by leveraging widely available devices like personal computers and smartphones, with the source code made available as open-source software.
Decision: Reject
The paper is rejected primarily for two reasons:
1. Limited Alignment with ICLR's Scope: While the work may have utility in specific contexts, it does not advance the state of the art in deep learning, which is a core focus of ICLR. The contributions are more infrastructural than algorithmic, and the target audience for this work does not align well with the mainstream ICLR community.
2. Lack of Novelty in Core Contributions: The paper does not introduce new algorithms, significant methodological advancements, or UI/meta-design improvements for non-experts. The focus on JavaScript-based implementation, while novel in its context, is not a significant leap in deep learning research.
Supporting Arguments
1. Problem Relevance: The problem of making deep learning accessible on everyday devices is well-motivated, but it is not a pressing research question in the deep learning community. The paper primarily addresses engineering challenges rather than advancing theoretical or empirical understanding.
2. Methodology and Results: The methodology is sound, and the experiments are scientifically rigorous. The authors demonstrate the feasibility of training large-scale CNNs and distributed training using web browsers. However, the performance lags behind established frameworks like Caffe, and the distributed training results, while promising, are preliminary.
3. Positioning in Literature: The paper builds on prior work in JavaScript-based computation and distributed deep learning. However, it does not sufficiently differentiate itself from existing frameworks like ConvNetJS or OpenCL-based Caffe in terms of innovation or impact.
Suggestions for Improvement
1. Target Audience: Consider submitting this work to a conference or journal focused on software engineering, distributed systems, or web technologies, where the contributions may be more appreciated.
2. Algorithmic Contributions: To align better with ICLR, the authors could explore novel algorithms or optimization techniques tailored to the constraints of web-based environments, such as communication-efficient distributed training strategies.
3. Broader Impact: Highlight potential applications or case studies where this framework could enable new research or practical use cases, such as in education or low-resource settings.
4. Performance Improvements: Address the performance gap with established frameworks by optimizing matrix operations and exploring alternatives to WebCL, such as WebGPU or WebAssembly.
Questions for the Authors
1. How does the framework handle the inherent limitations of JavaScript, such as single-threaded execution, in large-scale distributed training scenarios?
2. What are the specific bottlenecks in communication and computation during distributed training, and how might they be mitigated in future work?
3. Could the framework be extended to support other types of neural networks or tasks beyond CNNs, such as transformers or reinforcement learning?
In conclusion, while the paper presents an interesting engineering effort, it does not meet the criteria for acceptance at ICLR due to its limited novelty and alignment with the conference's focus on advancing deep learning research.