Review
Summary of the Paper
This paper investigates the ability of convolutional neural networks (CNNs) to learn game concepts under weak supervision using tic-tac-toe as a toy problem. The authors train a CNN to classify game states and predict winning moves, leveraging Class Activation Mapping (CAM) to visualize the network's attention. The paper claims that the CNN learns key game concepts such as the grid structure, winning rules, and the presence of two players. It also explores the applicability of cross-modal supervision for higher-level semantics and demonstrates that CAM can activate on non-salient regions, such as empty spaces on the board. The authors argue that their results provide evidence of CNNs' ability to hierarchically collect contextual information and learn complex concepts under weak supervision.
Decision: Reject  
Key Reasons:
1. Lack of Contextual Placement in Literature: The paper does not adequately relate its findings to existing work in reinforcement learning (RL) or visualization techniques, such as saliency maps in Deep Q-Networks (DQNs). This omission weakens the paper's broader relevance and novelty.
2. Unclear and Unsubstantiated Claims: Several claims, such as the inability of Simonyan et al.'s saliency maps to activate on grid squares, are unsupported by evidence. Additionally, the distinction between "what to do" and "what will happen" is unclear and appears redundant in this context.
Supporting Arguments
1. Novelty and Insights: The paper introduces an innovative approach by deriving actions from visualization techniques, demonstrating how CNNs leverage context for predictions. Using tic-tac-toe as a simplified domain to study attention mechanisms is a promising and insightful idea. However, the significance of these insights is limited due to the lack of comparison with related work and insufficient grounding in the broader RL literature.
2. Methodological Gaps: Key implementation details, such as how CAM visualizations are generated for 18 classes and the creation of the test set, are missing. This lack of clarity raises concerns about reproducibility and the robustness of the conclusions.
3. Presentation Issues: The results in Section 7 are disconnected from earlier discussions, making it difficult to follow the narrative. Integrating these results with prior sections would improve clarity and flow.
Additional Feedback for Improvement
1. Comparison to Related Work: The paper should explicitly compare its approach to existing visualization techniques in RL, such as saliency maps in DQNs. This would help contextualize the contributions and highlight the novelty of the proposed method.
2. Clarify Claims: The authors should provide evidence to support their assertion that Simonyan et al.'s saliency maps cannot activate on grid squares. Additionally, the distinction between "what to do" and "what will happen" should be clarified or redefined to avoid redundancy.
3. Relevance of "Information": The discussion of "information" in Section 2.3 is vague and lacks justification. The authors should clearly define this term and explain its relevance to saliency maps and the broader context of the study.
4. Implementation Details: Provide more details on how CAM visualizations are generated for 18 classes and how the test set is created. This would enhance reproducibility and allow for a more rigorous evaluation of the approach.
5. Significance of Results: While the experiments are novel, their broader significance is unclear. The authors should better articulate how their findings contribute to advancing the understanding of CNNs' ability to learn complex concepts under weak supervision.
Questions for the Authors
1. How does your approach compare to saliency maps in DQNs or other visualization techniques in reinforcement learning? Could you provide quantitative or qualitative comparisons?
2. What evidence supports your claim that Simonyan et al.'s saliency maps cannot activate on grid squares? Could you clarify this with examples or experiments?
3. Can you elaborate on the distinction between "what to do" and "what will happen"? How does this distinction impact the design and interpretation of your experiments?
4. How were the CAM visualizations for 18 classes generated, and how was the test set constructed? Could you provide more details to ensure reproducibility?
In conclusion, while the paper presents an interesting exploration of CNNs' ability to learn game concepts, it falls short in contextualizing its contributions within the broader literature and substantiating its claims. Addressing these issues would significantly strengthen the paper.