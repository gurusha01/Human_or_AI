Review of "Weakly Supervised Inversion Machine with Adversarial Imagination Priors"
Summary of Contributions
This paper proposes a novel framework for solving inverse problems in computer vision by generating latent image representations and optimizing reconstruction and adversarial losses. The model leverages a memory bank of images to guide the generation of "imaginations," which are intermediate representations such as albedo, shading, or inpainted scenes. The framework is applied to three tasks: image in-painting, intrinsic image decomposition, and figure-ground layer extraction. The authors claim that their approach works without paired supervision, relying instead on adversarial priors and memory retrieval mechanisms. Qualitative results are provided to demonstrate the model's performance.
Decision: Reject
The paper presents an interesting idea of leveraging memory-based adversarial priors for inverse problems, but it falls short in several critical areas. The lack of quantitative evaluation, unclear writing, and insufficient comparison with prior work make it difficult to assess the scientific rigor and contributions of the paper.
Supporting Arguments for the Decision
1. Lack of Quantitative Evaluation: While the paper provides qualitative results for the three tasks, it does not include quantitative comparisons with state-of-the-art methods. For example, intrinsic image decomposition results are not compared against established benchmarks like SIRFS or the Intrinsic Images in the Wild dataset. This omission makes it impossible to gauge the model's true effectiveness or its improvement over prior work.
   
2. Unclear Writing and Terminology: The paper suffers from vague and inconsistent terminology, such as "memory database" and "imagination," which are not clearly defined. Additionally, the figures and descriptions are inconsistent, further complicating comprehension. For example, the explanation of the fully-convolutional discriminator and cost function is insufficiently detailed, leaving the reader uncertain about the implementation specifics.
3. Insufficient Placement in Literature: While the paper draws parallels to prior work, it does not adequately position itself within the existing literature. For instance, the discussion of related work on intrinsic image decomposition and adversarial priors is superficial, and the novelty of the approach compared to prior methods is not convincingly articulated.
4. Unclear Contributions: The contributions of the paper are not well-delineated. While the idea of memory-guided adversarial priors is intriguing, the paper does not convincingly demonstrate how this approach outperforms or complements existing methods. The lack of clarity in the model's architecture and training process further detracts from the paper's impact.
Additional Feedback for Improvement
1. Quantitative Evaluation: The authors should include quantitative results for all three tasks, comparing their method against state-of-the-art baselines. Metrics such as PSNR, SSIM, or task-specific benchmarks would strengthen the paper's claims.
   
2. Clarity in Writing: The paper would benefit from a thorough revision to improve clarity and consistency. Key terms should be clearly defined, and the figures should align with the text descriptions. The explanation of the fully-convolutional discriminator and cost function should be expanded.
3. Stronger Positioning in Literature: The authors should better articulate how their work builds upon and differs from prior methods, particularly in areas like intrinsic image decomposition and adversarial learning.
4. Broader Evaluation: The paper could explore additional tasks or datasets to demonstrate the generality of the proposed framework. For example, including results on video-based tasks as mentioned in the conclusion could strengthen the paper.
Questions for the Authors
1. How does the proposed method quantitatively compare to state-of-the-art approaches for intrinsic image decomposition, such as SIRFS or Intrinsic Images in the Wild?
2. Can you provide more details on the fully-convolutional discriminator architecture and how it stabilizes training?
3. How robust is the memory retrieval mechanism when the input image significantly differs from the examples in the memory bank?
4. Could you clarify the role of the "imagination spaces" and how they differ from traditional latent representations?
In conclusion, while the paper introduces an innovative concept, it requires significant improvements in evaluation, clarity, and positioning to meet the standards of a high-quality conference paper.