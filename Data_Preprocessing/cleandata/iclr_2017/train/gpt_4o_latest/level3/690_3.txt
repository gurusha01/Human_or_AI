Review of the Paper
Summary of Contributions
This paper provides a comparative analysis of state-of-the-art (SOTA) deep neural networks (DNNs) submitted to the ImageNet challenge, focusing on practical metrics such as accuracy, memory footprint, parameter count, operations count, inference time, and power consumption. The authors claim to offer insights into the trade-offs between these metrics, particularly for resource-constrained environments. They highlight several findings, including the hyperbolic relationship between accuracy and inference time, the use of operations count as a proxy for inference time, and the energy constraints that define an upper bound on accuracy and model complexity. The paper also introduces ENet, which is claimed to be highly efficient in terms of parameter utilization.
Decision: Reject
While the paper provides a reasonable review of SOTA vision architectures and highlights some practical considerations, it lacks significant new insights, and its scientific rigor is undermined by several issues. The key reasons for rejection are the lack of robustness in the presented results and the triviality of some findings.
Supporting Arguments
1. Robustness of Results: Finding 1, which claims a hyperbolic relationship between accuracy and inference time, relies on a noisy figure (Fig. 4) with no accompanying error analysis. This raises concerns about the reliability and reproducibility of the result. The absence of statistical rigor undermines the credibility of the findings.
   
2. Triviality of Findings: Finding 2, which states that power consumption is independent of batch size and architecture, is considered trivial. While the authors argue otherwise, this insight is not novel and does not significantly advance the field.
3. Accessibility Issues: The paper is not accessible to colorblind readers or those using black-and-white printers. This oversight is a significant drawback for a conference submission, as accessibility is a critical aspect of scientific communication.
4. Lack of Novelty: While the paper provides a comprehensive review of existing architectures, it does not offer substantial new insights or methodologies. The analysis largely reiterates known trade-offs without proposing innovative solutions or frameworks.
Suggestions for Improvement
1. Error Analysis and Statistical Rigor: Include error bars, confidence intervals, or other forms of error analysis for all figures, particularly Fig. 4, to substantiate the claims.
   
2. Novel Contributions: The paper would benefit from introducing a novel methodology, framework, or metric that advances the field rather than summarizing existing work.
3. Accessibility: Revise all figures and visualizations to ensure accessibility for colorblind readers and compatibility with black-and-white printing. For example, use patterns or distinct shapes instead of relying solely on color.
4. Clarity in Presentation: Some sections, such as the discussion of ENet, could be expanded to provide more detail on its design and performance relative to other architectures.
Questions for the Authors
1. Can you provide error analysis or statistical validation for Fig. 4 to support the claim of a hyperbolic relationship between accuracy and inference time?
2. How does ENet compare to other architectures in terms of real-world deployment scenarios, beyond parameter utilization? Are there benchmarks or case studies to validate its efficiency?
3. Why do you believe Finding 2 is non-trivial, and how does it contribute to the broader understanding of DNN efficiency?
In conclusion, while the paper addresses an important topic and provides a useful review of existing architectures, its lack of rigor, novelty, and accessibility prevents it from meeting the standards of the conference.