Review of the Paper
Summary of Contributions
This paper introduces a novel iterative refinement model for machine translation (MT) that improves upon traditional left-to-right decoding schemes by revisiting and refining earlier translation decisions. The proposed approach leverages convolutional neural networks with attention mechanisms to predict word substitutions, conditioned on both the source sentence and the current translation output. The authors extend this with a dual-attention model that incorporates the guess translation during training, reducing the distribution shift between training and testing. The iterative refinement process is guided by confidence-based heuristics, achieving a modest improvement of up to 0.4 BLEU on the WMT15 German-English dataset with minimal edits (0.6 substitutions per sentence). The work is inspired by human translation workflows and addresses a key limitation of existing MT systems: the inability to revise earlier decisions.
Decision: Reject  
While the paper presents an interesting idea and demonstrates modest improvements, it lacks sufficient depth in analysis and contextualization within the broader literature. The limited scope of the evaluation and the absence of critical discussions about the model's limitations and assumptions hinder its readiness for publication.
Supporting Arguments for the Decision
1. Significance and Novelty: The iterative refinement approach is a meaningful contribution to MT, aligning with iterative refinement trends in machine learning (e.g., DRAW, structured prediction cascades). However, the improvement of 0.4 BLEU is relatively small, and the paper does not convincingly argue why this gain is significant in practical settings.
   
2. Connections to Prior Work: The paper does not adequately situate its contributions within the broader literature. For example, connections to undirected translation models, Gibbs sampling, and automatic post-editing approaches are only briefly mentioned and not explored in depth. This weakens the paper's theoretical foundation and its positioning as a novel contribution.
3. Model Limitations and Assumptions: The inability to handle word insertions or deletions and the reliance on fixed-size windows for context are significant limitations. These design choices are not sufficiently justified, and their impact on the model's generalizability is not analyzed. Additionally, the conditioning on unavailable variables at test time (Section 4) raises practical concerns about the dual-attention model's applicability.
4. Experimental Analysis: While the experiments demonstrate the feasibility of the approach, the evaluation is narrow, focusing solely on phrase-based MT outputs. The paper does not explore how the model performs with neural MT outputs or other initial guess translations, which limits the generalizability of the findings. Furthermore, the training data description in Section 3 is ambiguous, and the rationale for certain design choices (e.g., fixed window representation) is not well-articulated.
Suggestions for Improvement
1. Broader Contextualization: Strengthen the connections to related work in NLP, MT, and ML, such as undirected translation models, hill-climbing algorithms, and automatic post-editing. Discuss how the proposed approach compares to and builds upon these methods.
2. Address Model Limitations: Explore extensions to the model that handle word insertions, deletions, or more complex editing operations. Justify the use of fixed-size windows and discuss alternatives, such as global context representations.
3. Clarify Assumptions: Explicitly state and analyze the model's assumptions, such as the fixed-size window and the pseudo-likelihood objective. Discuss how these assumptions impact the model's performance and applicability.
4. Expand Evaluation: Test the model on diverse initial guess translations (e.g., neural MT outputs) and analyze its performance across different datasets. Provide more detailed error analysis to highlight the strengths and weaknesses of the approach.
5. Terminology and Clarity: Clarify ambiguous terms like "distributional space" and ensure that all technical details (e.g., training data description) are explicitly explained.
Questions for the Authors
1. How does the model perform when applied to neural MT outputs or other types of initial guess translations? Could this lead to larger improvements in BLEU?
2. What are the specific challenges in extending the model to handle word insertions or deletions? Have you considered alternative architectures to address these limitations?
3. Can you provide more details on the training data in Section 3? How was the data preprocessed, and how does this impact the model's performance?
4. Why was a fixed-size window chosen for context representation? Have you explored global context representations, and if so, how do they compare?
5. Could you elaborate on the practical implications of the dual-attention model's conditioning on unavailable variables at test time? How does this affect real-world deployment?
By addressing these points, the paper could significantly improve its clarity, impact, and readiness for publication.