Review
Summary of Contributions
This paper introduces an augmented training procedure for Generative Adversarial Networks (GANs) that incorporates a denoising autoencoder to estimate and track the distribution of discriminator features. By leveraging the denoiser to guide the generator toward more probable feature configurations, the proposed method addresses key challenges in GAN training, such as mode collapse and difficulty in generating diverse, "object-like" samples. The authors demonstrate that the joint training of the generator with the denoising autoencoder provides auxiliary gradient information, improving the generator's performance. Empirical results on CIFAR-10, STL-10, and ImageNet datasets show qualitative and quantitative improvements, with higher Inception scores and visually recognizable objects in the generated samples. The paper also highlights the potential of this auxiliary information to enhance GAN training stability and robustness.
Decision: Accept
The paper is well-motivated, technically sound, and makes a meaningful contribution to improving GAN training. The use of a denoising autoencoder to provide auxiliary gradient information is novel and addresses practical challenges in GAN training, such as mode collapse and the generation of diverse samples. The empirical results support the claims, demonstrating improvements in both visual fidelity and quantitative metrics. However, the paper could benefit from additional discussion on related work, particularly Energy-Based GANs (EBGANs), to better contextualize the proposed approach.
Supporting Arguments
1. Novelty and Motivation: The paper introduces a novel approach to augment GAN training by leveraging denoising autoencoders, which is well-motivated and addresses known limitations of GANs. The idea of using auxiliary gradient information to guide the generator is compelling and has the potential to inspire further research in this direction.
2. Empirical Validation: The experimental results are robust and demonstrate clear improvements over baseline GANs. The use of the Inception score provides a quantitative measure of success, and the qualitative results show that the proposed method generates more diverse and recognizable objects.
3. Clarity and Presentation: The paper is well-written and clearly explains the methodology, experimental setup, and results. The inclusion of detailed architectural and training choices ensures reproducibility.
Suggestions for Improvement
1. Discussion on EBGANs: The paper briefly mentions Energy-Based GANs (EBGANs) but does not provide an in-depth comparison. Given the conceptual overlap, a more detailed discussion of EBGANs and their relationship to the proposed method would strengthen the paper.
2. Non-Stationarity of Features: The authors acknowledge that the non-stationarity of the feature distribution may limit the denoiser's effectiveness. Exploring techniques to mitigate this issue, such as historical averaging or more structured denoisers, could further improve the method.
3. Broader Applicability: While the paper focuses on unsupervised image synthesis, it would be interesting to discuss how the proposed method could be extended to conditional or semi-supervised GANs, as hinted in the discussion section.
4. Evaluation Metrics: While the Inception score is widely used, it has known limitations. Including additional metrics, such as Fréchet Inception Distance (FID), would provide a more comprehensive evaluation of the method's performance.
Questions for the Authors
1. How does the proposed method compare to EBGANs in terms of computational efficiency and performance? Could the denoising autoencoder be integrated into an EBGAN framework?
2. Did you observe any trade-offs between the stability of training and the diversity of generated samples when using the denoising feature matching objective?
3. How sensitive is the method to the choice of hyperparameters, such as the weight of the denoising loss (λ_denoise) or the architecture of the denoiser?
Overall, this paper makes a valuable contribution to the field of GAN research and provides a promising direction for improving the stability and diversity of GAN-generated samples. With minor revisions, it is well-suited for acceptance at the conference.