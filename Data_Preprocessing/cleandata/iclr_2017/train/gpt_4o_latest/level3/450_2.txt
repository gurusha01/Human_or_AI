Review of the Paper
Summary of Contributions
This paper introduces Classifier Two-Sample Tests (C2ST), a novel approach to two-sample testing that leverages binary classifiers to assess whether two samples are drawn from the same distribution. The authors derive theoretical properties of C2ST, including its null distribution and power, and demonstrate its interpretability and practical utility. The paper positions C2ST as a general and flexible alternative to traditional kernel-based methods like Maximum Mean Discrepancy (MMD). Furthermore, the authors showcase applications of C2ST in evaluating generative models, such as GANs, and in causal discovery using Conditional GANs (CGANs). The experiments demonstrate that C2ST achieves state-of-the-art performance in various scenarios, including independence testing, generative model evaluation, and real-world datasets. The paper also highlights the interpretability of C2ST through its learned features and predictive uncertainty.
Decision: Accept
The paper makes a compelling case for C2ST as a general, scalable, and interpretable method for two-sample testing. The key reasons for acceptance are:
1. Novelty and Timeliness: The paper addresses the limited impact of deep learning on hypothesis testing and proposes a classifier-based framework that bridges statistical testing and representation learning.
2. Theoretical and Empirical Rigor: The authors provide sound theoretical analysis and extensive empirical validation, demonstrating the advantages of C2ST over kernel methods in terms of power, flexibility, and interpretability.
Supporting Arguments
1. Well-Motivated Problem: The paper identifies limitations of existing two-sample tests, such as the need for fixed data representations and interpretability challenges, and proposes a classifier-based approach that overcomes these issues. The motivation is well-placed within the literature, particularly given the growing interest in deep learning for statistical tasks.
2. Theoretical Contributions: The derivation of the null distribution and power of C2ST is rigorous and provides a solid foundation for its use. The discussion of the bias-variance tradeoff in classifier selection is insightful and aligns with machine learning principles.
3. Empirical Validation: The experiments are comprehensive, covering synthetic and real-world datasets, independence testing, and generative model evaluation. The results consistently show that C2ST outperforms or matches state-of-the-art methods like MMD and ME in terms of power and interpretability.
4. Interpretability: The paper emphasizes the interpretability of C2ST, which is a significant advantage over kernel methods. The ability to identify where distributions differ and which features are most discriminative is practically valuable.
Suggestions for Improvement
1. Relationship to Kernel-MMD: While the paper critiques kernel-MMD's null distribution, it overlooks that linear kernel-MMD has a Gaussian null distribution. A more balanced comparison would strengthen the argument.
2. Choice of Linear Kernel-MMD: The use of linear kernel-MMD in comparisons is justified for computational efficiency, but quadratic kernel-MMD is more powerful. Including results for quadratic kernel-MMD would provide a fairer benchmark.
3. Arthur Gretton's Comment: Incorporating the suggested experiments comparing kernel-MMD and classifier thresholds would enhance the clarity and impact of the paper.
4. Causal Discovery: The causal discovery section is promising but underdeveloped. The authors could elaborate on the limitations of CGAN-based methods and provide more detailed comparisons with existing causal inference techniques.
Questions for the Authors
1. How does the performance of C2ST compare to quadratic kernel-MMD in terms of power and computational efficiency?
2. Can the authors provide more details on the stability of C2ST when using different classifiers, particularly deep neural networks with varying architectures?
3. How sensitive is C2ST to the choice of hyperparameters, such as the size of the test set and the classifier's capacity?
4. What are the limitations of using CGANs for causal discovery, and how do they compare to traditional additive noise models?
By addressing these points, the authors could further solidify the contributions and practical applicability of their work.