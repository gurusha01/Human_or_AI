Review
Summary of Contributions
This paper introduces a novel permutation-equivariant layer for deep learning, specifically designed to handle datasets with set structures. The authors propose a parameter-sharing scheme that ensures permutation equivariance, enabling the model to treat inputs as sets rather than vectors. The paper demonstrates the utility of this layer in supervised and semi-supervised tasks, including MNIST digit summation, point-cloud classification, set anomaly detection, and galaxy red-shift estimation. The authors claim that their approach is computationally efficient, with linear complexity in the size of the sets, and achieves state-of-the-art results in several tasks. The paper is clearly written, with promising empirical results, and provides a theoretical foundation for the proposed layer.
Decision: Reject
While the paper is clearly written and presents promising results, I am unable to confidently assess its correctness or significance due to its highly abstract presentation and my own limitations in understanding the mathematical formalism. The lack of grounding in concrete examples and the absence of clear explanations for key concepts make the paper inaccessible to a broader audience, including myself. I recommend leaving the accept/reject decision to reviewers with more expertise in this specific area.
Supporting Arguments
1. Strengths:
   - The paper is well-organized and clearly written, albeit in a highly abstract manner reminiscent of N. Bourbaki's style.
   - The empirical results are promising, demonstrating the effectiveness of the proposed layer in diverse applications.
   - The theoretical foundation, including proofs of permutation equivariance, appears rigorous.
2. Weaknesses:
   - The abstract formalism is not grounded with sufficient concrete examples, making it difficult to follow. For instance, the connection between convolution or inner product operations and the proposed layer is not clearly explained.
   - Key concepts such as "Cardinal" and "Cartesian convolution" are introduced without sufficient clarification in signal processing terms.
   - Symbols and relationships between variables (e.g., X, Square in Figure 2, x1, x{11}, x_{1,2}) are not adequately explained, leading to confusion.
   - The transition from sets to relations, functions, operators, and shift-invariant operators (e.g., convolutions) requires more detailed guidance.
   - Specific questions, such as the association of a 3x3 convolution with 9 relations, backward arrows, and cross-node arrows, remain unanswered.
Suggestions for Improvement
1. Accessibility: Simplify the presentation to make the paper accessible to a broader audience. Use concrete examples to illustrate key concepts. For instance, convolving a 1x5 signal with a 1x3 filter could clarify convolution filter parameters and spatial invariance.
2. Explanations: Provide clear explanations for terms like "Cardinal" and "Cartesian convolution" in the context of signal processing.
3. Figures and Symbols: Clarify the meaning of symbols and relationships in figures (e.g., X and Square in Figure 2, x1, x{11}, x_{1,2}).
4. Connections: Elaborate on the connection between convolution or inner product operations and the proposed layer.
5. Detailed Transitions: Provide more detailed explanations for the transition from sets to relations, functions, and operators.
Questions for the Authors
1. How does the proposed layer relate to traditional convolution operations? Can you provide a concrete example to illustrate this connection?
2. What do terms like "Cardinal" and "Cartesian convolution" mean in the context of signal processing?
3. Can you clarify the meaning of symbols such as X and Square in Figure 2 and the relationships between variables (e.g., x1, x{11}, x_{1,2})?
4. How does the 3x3 convolution relate to the 9 relations, backward arrows, and cross-node arrows mentioned in the paper?
5. Could you provide a simple example, such as convolving a 1x5 signal with a 1x3 filter, to clarify key concepts like convolution filter parameters and spatial invariance?
In conclusion, while the paper demonstrates potential, its abstract presentation and lack of accessibility hinder its evaluation. Addressing these issues would significantly improve the paper's clarity and impact.