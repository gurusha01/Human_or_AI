Review of the Paper
Summary of Contributions
The paper investigates the invariance, equivariance, and equivalence properties of CNN representations under various input transformations. It extends the work of Lenc & Vedaldi (2015) by conducting a large-scale empirical study across 70 CNNs, two datasets, and nine transformation types. The authors propose a novel loss function to improve equivariance and analyze the representation distances between CNNs trained with different transformations. The paper provides interesting observations, such as the grouping of transformations based on their effects on learned representations and the generalization of invariance to unseen transformation magnitudes.
Decision: Reject
The paper is not recommended for acceptance due to its lack of clear novelty, insufficient experimental rigor, and unclear main message. While the study is extensive and provides some interesting results, it falls short of making significant contributions to the understanding or improvement of CNN representations.
Supporting Arguments for Decision
1. Lack of Novel Insights: The paper primarily confirms known effects of data augmentation (e.g., improved invariance) without providing new theoretical or empirical insights. The proposed loss function for improving equivariance does not consistently yield better results, and the small values of \(\lambda1\) and \(\lambda2\) make it functionally equivalent to data jitter.
   
2. Limited Scope of Analysis: The focus on the FC7 layer is controversial, as this layer is closely tied to the classification layer (FC8). A broader analysis across multiple layers could provide deeper insights into the hierarchical structure of CNN representations.
3. Experimental Gaps: Key experiments lack crucial details or results. For instance, the classification error on the testing dataset is missing in the representation distance experiment, which is essential to validate the compatibility of representations. Similarly, the K-NN experiment lacks clarity on evaluation methodology and does not convincingly demonstrate compatibility across networks.
4. Unclear Main Message: Despite the extensive experiments, the paper fails to articulate a clear takeaway or actionable insights for the community. The results are descriptive rather than prescriptive, leaving the reader uncertain about the implications of the findings.
Suggestions for Improvement
1. Broaden Layer Analysis: Extend the analysis to include convolutional and earlier fully connected layers to understand how invariance and equivariance properties evolve across the network hierarchy.
2. Clarify Experimental Details: Provide missing details, such as classification error results for representation distance experiments and the evaluation methodology for the K-NN experiment.
3. Verify Equivariance Criterion: Experimentally validate the proposed equivariance criterion to demonstrate its effectiveness beyond simple data jitter.
4. Improve Presentation: Address minor issues such as missing units for angles (pages 1 and 5), misleading terminology for dropout (page 4), and the misrepresentation of diagonal elements in Figures 3a and 3b.
5. Articulate Key Insights: Focus on deriving actionable insights or theoretical contributions from the results. For example, explain why certain transformations (e.g., rotation, shear) lead to more structured representations and how this can be leveraged in practice.
Questions for the Authors
1. Why was the FC7 layer chosen for analysis, and how do you justify its relevance over other layers?
2. Can you provide classification error results for the representation distance experiments to validate the compatibility of representations under linear transformations?
3. How does the proposed loss function compare to standard data augmentation in terms of improving equivariance? Can you provide ablation studies to isolate the effects of \(\lambda1\) and \(\lambda2\)?
4. How was the K-NN experiment evaluated? Was it performed per test example, and how were the results aggregated?
In summary, while the paper addresses an important topic and conducts extensive experiments, it lacks novelty, rigor, and clarity in its contributions. With significant revisions and a stronger focus on actionable insights, the work could be more impactful in the future.