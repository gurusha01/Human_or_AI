The paper introduces a novel approach to rule mining in knowledge bases by leveraging relational embeddings and sparse recovery techniques, specifically using non-negative RESCAL. The authors propose a method that generalizes beyond observed facts, supports all propositional logic connectives (conjunction, disjunction, and negation), and aims to discover diverse and interpretable rules. The experimental results demonstrate promising performance compared to existing methods, showcasing improved F-scores and per-rule recall across multiple datasets. The paper positions itself as a step forward in embedding-based rule mining, addressing some limitations of prior work, such as redundancy and lack of expressiveness in mined rules.
Decision: Reject
While the paper presents an interesting and innovative approach, it suffers from several critical shortcomings that prevent its acceptance in its current form. The primary reasons for rejection are:  
1. Unclear Generality and Theoretical Foundations: The paper does not adequately define the underlying properties of the embedding space or the algorithm necessary for meaningful rule discovery. This lack of clarity raises concerns about the general applicability of the method to diverse knowledge bases and embedding techniques.  
2. Incomplete Evaluation: The paper does not evaluate the impact of the discovered rules on link prediction performance or explore how these rules enhance the original algorithm. Additionally, scalability concerns are not addressed, particularly regarding the exponential growth of parameters with the number of relationships and path length.
Supporting Arguments:  
- The experimental results, while promising, are limited to small datasets. The scalability of the approach to larger benchmarks like FB15k is questionable, given the exponential parameter growth. This is a significant limitation for practical applications.  
- The lack of link prediction evaluation is a missed opportunity to demonstrate the utility of the discovered rules in downstream tasks, which would strengthen the paper's claims.  
- The theoretical discussion does not sufficiently address the conditions under which the proposed method will succeed or fail, leaving open questions about its robustness and generalizability.
Additional Feedback for Improvement:  
1. Scalability: The authors should address the scalability of their method, either through theoretical analysis or empirical evaluation on larger datasets. Exploring techniques to mitigate the exponential parameter growth would be valuable.  
2. Link Prediction Evaluation: Including an evaluation of how the discovered rules improve link prediction performance would provide a more comprehensive assessment of the method's utility.  
3. Theoretical Foundations: A deeper exploration of the embedding space properties and the algorithm's requirements for meaningful rule discovery would enhance the paper's rigor and generalizability.  
4. Comparison to State-of-the-Art: The paper should compare its method to more recent state-of-the-art techniques, particularly those that address scalability and generalization in rule mining.
Questions for the Authors:  
1. How does the method perform on larger benchmarks like FB15k or YAGO? Have you considered any strategies to address the scalability challenges?  
2. Can you provide more insight into the properties of the embedding space that are critical for successful rule mining?  
3. How do the discovered rules impact the performance of downstream tasks like link prediction?  
4. What are the limitations of your approach when applied to embeddings generated by methods other than RESCAL?  
In summary, while the paper introduces a novel and promising approach, it requires significant improvements in theoretical grounding, scalability analysis, and evaluation completeness to be considered for acceptance.