The paper introduces PixelVAE, a novel generative model that combines the strengths of Variational Autoencoders (VAEs) and PixelCNNs to model natural image distributions. The authors propose a hierarchical structure with multiple latent variable layers and autoregressive decoders, which enables the model to capture both global and local image features effectively. The paper claims that PixelVAE achieves state-of-the-art performance on binarized MNIST, competitive likelihoods on 64Ã—64 ImageNet, and generates high-quality samples on the LSUN bedrooms dataset, all while requiring fewer computationally expensive autoregressive layers compared to PixelCNN. Additionally, the authors demonstrate that PixelVAE learns more compressed and disentangled latent representations than standard VAEs.
Decision: Reject
While the paper presents an interesting combination of VAE and PixelCNN, the contribution is incremental, and the results, though competitive, do not establish a clear state-of-the-art across challenging datasets. Furthermore, the paper suffers from significant clarity and reproducibility issues, which hinder its overall impact.
Supporting Arguments:
1. Strengths:
   - The integration of PixelCNN into the VAE framework is a promising idea, addressing the complementary weaknesses of the two models (VAEs struggle with fine details, while PixelCNN lacks a latent code).
   - The hierarchical latent variable structure is logical and aligns with prior work, enabling the model to capture multi-scale image features.
   - The reduction in the number of PixelCNN layers is a practical improvement, potentially reducing computational costs.
2. Weaknesses:
   - The likelihood results on natural image datasets (e.g., ImageNet and LSUN) are competitive but not state-of-the-art, limiting the novelty of the contribution.
   - The claim of computational efficiency due to fewer PixelCNN layers is not rigorously substantiated. A direct comparison with a PixelCNN model achieving similar likelihoods is missing.
   - The paper lacks clarity in its presentation. The model architecture and training details are difficult to follow, making reproduction challenging.
   - The exploration of the learned latent representations is brief and does not convincingly demonstrate their utility for downstream tasks or specific applications.
Suggestions for Improvement:
1. Clarity and Reproducibility: The paper should include a clearer description of the model architecture, training procedure, and hyperparameters. A diagram illustrating the hierarchical structure and the interaction between the VAE and PixelCNN components would greatly enhance understanding.
2. Efficiency Claims: Provide a detailed comparison of PixelVAE's computational cost (e.g., training time, memory usage) against PixelCNN models with comparable likelihoods.
3. Latent Representations: Strengthen the evaluation of the learned latent representations by demonstrating their utility in specific tasks, such as semi-supervised learning or disentanglement metrics.
4. Broader Validation: Extend the evaluation to additional datasets or tasks to better establish the generalizability and practical utility of PixelVAE.
Questions for the Authors:
1. Can you provide quantitative evidence supporting the claim that PixelVAE is computationally more efficient than PixelCNN for similar likelihoods?
2. How does the hierarchical structure contribute to the model's performance compared to a single-layer latent variable model?
3. Could you elaborate on the potential downstream applications of the learned latent representations, and how they compare to those from standard VAEs or PixelCNNs?
In summary, while the combination of PixelCNN and VAE is an intriguing direction, the paper requires stronger empirical results, clearer exposition, and a more rigorous evaluation of its claims to merit acceptance.