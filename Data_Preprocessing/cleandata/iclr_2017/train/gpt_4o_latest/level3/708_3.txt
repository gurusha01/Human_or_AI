Review of the Paper
Summary of Contributions
The paper proposes a novel method for generating adversarial examples in a black-box setting, where the adversary does not require knowledge of the network architecture or gradients. The authors introduce two approaches: a randomized single-pixel perturbation method and a more refined greedy local search algorithm. The latter addresses the shortcomings of the former by ensuring that perturbed images remain valid within the original image space. The method is evaluated on multiple datasets and architectures, demonstrating its effectiveness in generating adversarial examples with minimal perturbation. The authors also explore the relationship between perturbed pixels and saliency maps, and extend their method to handle stronger notions of misclassification (k-misclassification). The paper claims that the proposed method is computationally efficient, widely applicable, and capable of exposing vulnerabilities in deep convolutional neural networks.
Decision: Reject
Key reasons for rejection:
1. Overlap with Prior Work: While the paper claims novelty in its black-box adversarial attack approach, the proposed method overlaps significantly with existing work, particularly in the area of black-box adversarial setups. The lack of a clear distinction from prior methods, such as those by Papernot et al., weakens the contribution.
2. Experimental Design Issues: The initial experiments allow non-image-space outputs, rendering the results meaningless and unsurprising. While the greedy search procedure addresses this issue, its description is convoluted, and the motivation behind key components (e.g., PERT and CYCLIC) is unclear.
Supporting Arguments
1. Lack of Novelty: The paper positions itself as an improvement over existing black-box adversarial methods but does not adequately differentiate itself from prior work. For example, the claim that the method avoids the transferability assumption is interesting but not sufficiently substantiated with comparative experiments or theoretical insights.
2. Clarity and Conciseness: The description of the greedy search procedure is unnecessarily complex, making it difficult to follow. Additionally, the paper is verbose and could be significantly more concise without losing technical depth.
3. Experimental Weaknesses: The initial experiments allowing out-of-range pixel values undermine the validity of the results. While the greedy search procedure rectifies this, the motivation for its design choices (e.g., the use of PERT and CYCLIC) is not well-explained. Furthermore, the evaluation lacks a thorough comparison with state-of-the-art black-box methods, which would strengthen the claims of superiority.
Suggestions for Improvement
1. Clarify Novelty: Clearly articulate how the proposed method differs from and improves upon prior black-box adversarial attack methods. Provide a more detailed comparison with related work, both conceptually and experimentally.
2. Improve Experimental Design: Avoid experiments that allow non-image-space outputs, as they do not provide meaningful insights. Ensure that all evaluations are scientifically rigorous and aligned with real-world constraints.
3. Simplify Presentation: Streamline the description of the greedy search procedure and other technical components to improve readability. Consider using diagrams or pseudocode to clarify complex algorithms.
4. Provide Motivation: Explain the rationale behind key design choices, such as the use of PERT and CYCLIC, and demonstrate their necessity through ablation studies or theoretical analysis.
5. Expand Evaluation: Include comparisons with other black-box adversarial methods, particularly those that rely on transferability, to provide a stronger case for the proposed approach. Additionally, evaluate the method on a broader range of architectures and datasets to demonstrate generalizability.
Questions for the Authors
1. How does the proposed method compare quantitatively and qualitatively to other black-box adversarial methods, such as those by Papernot et al., in terms of success rate, perturbation size, and computational cost?
2. What is the theoretical or empirical justification for the use of PERT and CYCLIC in the greedy search procedure? Could simpler alternatives achieve similar results?
3. How does the method perform when evaluated on more complex architectures, such as transformers or large-scale vision models, beyond VGG and Network-in-Network?
4. Can the authors provide more insights into the relationship between the perturbed pixels and saliency maps? How does this relationship inform the design of the greedy search procedure?
In conclusion, while the paper addresses an important problem and proposes an interesting approach, significant improvements in clarity, experimental rigor, and differentiation from prior work are needed for it to make a meaningful contribution to the field.