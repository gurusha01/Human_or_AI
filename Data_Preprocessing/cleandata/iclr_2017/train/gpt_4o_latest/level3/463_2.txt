Review of the Paper
Summary of Contributions
This paper addresses the critical problem of training neural networks with noisy labels, proposing a novel approach that integrates a noise adaptation layer into the network architecture. By modeling the noise explicitly through an additional softmax layer, the method optimizes the likelihood function within the neural network framework, offering an alternative to the traditional EM algorithm. The proposed method is extended to account for noise dependent on both the correct labels and the input features, which is a significant departure from prior work that assumes independence between noise and features. Experimental results on MNIST and CIFAR-100 datasets demonstrate that the proposed approach outperforms baseline methods and existing noise-robust techniques. The authors also propose a sparse variant of their method to address scalability issues for large class sets.
Decision: Reject
While the paper introduces a well-formulated and novel solution to the problem of noisy labels, the experimental justification is insufficient to warrant acceptance. The lack of comprehensive evaluation on large-scale datasets and limited analysis of the observed performance degradation beyond a noise threshold are significant weaknesses. Additionally, the paper does not explore comparisons with training on smaller but high-quality datasets, which would provide valuable insights into the trade-offs of their approach.
Supporting Arguments
1. Strengths:
   - The problem of noisy labels is well-motivated, and the proposed method is novel in its use of a noise adaptation layer integrated into the neural network.
   - The theoretical formulation is rigorous, and the connection to the EM algorithm is clearly articulated.
   - The proposed sparse variant addresses scalability concerns, which is a practical consideration for real-world applications.
2. Weaknesses:
   - The experimental results are limited to MNIST and CIFAR-100, which are relatively small datasets. The scalability and effectiveness of the approach for large-scale classification tasks remain unclear.
   - Figure 2 indicates a sharp performance drop beyond a certain noise threshold, but the paper does not provide sufficient analysis or justification for this phenomenon.
   - The paper lacks a comparison with training on smaller, high-quality datasets, which could provide a baseline for assessing the trade-offs of using noisy data with the proposed method.
   - While the sparse variant is promising, its evaluation is limited, and the impact of sparsification on performance for extremely large class sets is not thoroughly explored.
Suggestions for Improvement
1. Experimental Scope: Extend the experiments to include larger datasets (e.g., ImageNet) to evaluate the scalability and robustness of the proposed method in real-world scenarios.
2. Noise Threshold Analysis: Provide a detailed analysis of the performance degradation observed beyond the noise threshold. Investigate whether this is due to limitations in the model architecture, optimization, or inherent properties of the method.
3. Comparison with High-Quality Data: Include experiments comparing the proposed method with training on smaller but high-quality datasets to highlight the trade-offs between data quantity and quality.
4. Ablation Studies: Conduct ablation studies to isolate the contributions of different components, such as the noise adaptation layer and the initialization strategies.
5. Sparse Variant Evaluation: Explore the performance of the sparse variant on datasets with extremely large class sets and provide a more detailed analysis of its computational efficiency.
Questions for the Authors
1. What is the computational overhead introduced by the noise adaptation layer, particularly for large-scale datasets? How does it compare to traditional EM-based approaches?
2. Can the proposed method handle scenarios where both labels and features are noisy? If so, how would the architecture need to be modified?
3. What insights can you provide regarding the sharp performance drop beyond the noise threshold observed in Figure 2? Is this a limitation of the method or an artifact of the experimental setup?
4. How does the proposed method perform when combined with data augmentation or semi-supervised learning techniques?
In summary, while the paper presents a novel and promising approach, the experimental limitations and lack of critical comparisons prevent it from meeting the standards for acceptance at this time. Addressing these concerns in a future submission could significantly strengthen the contribution.