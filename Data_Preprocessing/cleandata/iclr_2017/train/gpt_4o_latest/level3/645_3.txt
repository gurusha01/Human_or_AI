Review of "Deep Generalized Canonical Correlation Analysis (DGCCA)"
Summary of Contributions:
This paper introduces Deep Generalized Canonical Correlation Analysis (DGCCA), a novel method for multiview representation learning that combines the flexibility of nonlinear transformations via deep neural networks with the ability to incorporate information from multiple views. The primary contribution is the derivation of gradients for nonlinear encoding networks that project views into a shared latent space, enabling efficient optimization of the DGCCA objective. The authors demonstrate the utility of DGCCA through experiments on synthetic data, phoneme classification using the XRMB dataset, and hashtag/friend recommendation tasks on Twitter data. The results indicate that DGCCA outperforms linear GCCA and two-view DCCA in several scenarios, particularly when leveraging more than two views. The release of an implementation further enhances the practical impact of this work.
Decision: Accept
Key reasons for acceptance:
1. Novelty and Applicability: The paper addresses a significant gap in the literature by extending CCA-style methods to nonlinear, multiview settings, which has broad applicability in multimodal and multiview learning tasks.
2. Theoretical Rigor: The derivation of gradients for the DGCCA objective is both non-trivial and correct, as verified by the reviewer. This contribution is foundational for future work in nonlinear multiview learning.
Supporting Arguments:
1. Motivation and Placement in Literature: The paper is well-motivated, addressing limitations of existing methods like DCCA (restricted to two views) and GCCA (limited to linear transformations). It provides a clear comparison with prior work and situates DGCCA as a meaningful extension.
2. Experimental Validation: The experiments, though limited to small/medium datasets, are well-designed and demonstrate the advantages of DGCCA over baselines. For example, the phoneme classification task shows consistent improvements in accuracy, and the hashtag recommendation task highlights the benefits of nonlinear multiview learning.
3. Clarity and Writing: The paper is well-written, with a logical flow and sufficient detail in the methodology. The inclusion of pseudocode and gradient derivations in the appendices adds clarity.
Suggestions for Improvement:
1. Algorithm Description: The paper would benefit from an explicit algorithmic description of the DGCCA optimization process, particularly for updating the joint embeddings \( G \) and \( U \). While pseudocode is provided in the appendix, integrating a concise algorithm in the main text would improve accessibility.
2. Visualization Enhancements: Figures 3b and 4 have flipped x-axis colors/signs, which could confuse readers. Additionally, continuous rainbow-colored versions of Figures 2, 3, and 4 would improve the interpretability of the learned representations.
3. Empirical Scope: The experiments are limited to small/medium datasets. Evaluating DGCCA on larger, more complex datasets would strengthen the empirical claims and demonstrate scalability.
4. Evaluation Metrics: The paper could explore additional metrics, such as reconstruction error during training and mismatch metrics for cross-validation, to provide a more comprehensive evaluation of the learned representations.
5. Sensitivity Analysis: The method's sensitivity to regularization and hyperparameter selection raises questions about robustness. A deeper analysis of optimization metrics and hyperparameter tuning strategies would be valuable.
Questions for the Authors:
1. How does DGCCA perform on datasets with highly imbalanced or noisy views? Are there any mechanisms to handle such scenarios?
2. Could you elaborate on the computational efficiency of DGCCA, particularly for datasets with a large number of views or high-dimensional inputs? Are there any scalability limitations?
3. Have you considered alternative methods for regularizing the shared representation \( G \) to improve robustness to overfitting?
In conclusion, the paper makes a significant theoretical and practical contribution to the field of multiview learning. While there are areas for improvement, the novelty, rigor, and potential impact of DGCCA justify its acceptance.