Review of the Paper: "PALEO: An Analytical Performance Model for Scalable Deep Learning Systems"
Summary
This paper introduces PALEO, a simple yet effective analytical model designed to predict the computation time of deep neural networks (DNNs). The authors argue that PALEO leverages the declarative specifications of DNN architectures to estimate execution times across various hardware, software, and communication configurations. The model is validated through experiments on popular convolutional neural networks (CNNs) such as AlexNet, NiN, and Inception, demonstrating reasonable accuracy in both single-machine and distributed settings. The authors also highlight PALEO's utility in answering practical scalability questions, such as the trade-offs between different parallelization and communication strategies. The open-sourcing of PALEO further enhances its potential as a tool for practitioners.
Decision: Accept
The paper is well-motivated and makes a meaningful contribution by addressing an important problem in the field of scalable deep learning. While the experimental scope is somewhat limited, the model's accuracy and utility are convincingly demonstrated, and the additional experiments strengthen the paper's claims. My decision to accept is based on the novelty of the proposed model, its practical relevance, and the rigor of the presented results.
Supporting Arguments
1. Clear Problem Statement and Motivation: The paper tackles a well-defined and practical problem: predicting the computation time of DNNs to optimize their training and deployment. This is a critical issue in the field, especially as models grow in complexity and scale.
   
2. Novel Contribution: PALEO's analytical approach is novel in its ability to estimate execution times without requiring extensive benchmarking or implementation. This makes it a lightweight and scalable alternative to empirical profiling methods.
3. Experimental Validation: The authors validate PALEO on multiple CNN architectures and demonstrate its accuracy in predicting runtimes. The case studies, including comparisons with real-world scalability results, provide strong evidence for the model's robustness.
4. Practical Utility: The ability to model different hardware setups, parallelization strategies, and communication schemes makes PALEO a valuable tool for both researchers and practitioners.
Suggestions for Improvement
1. Broader Experimental Scope: While the results are promising, the experiments are limited to a few CNN architectures. Extending the evaluation to other model types, such as recurrent neural networks (RNNs), transformers, and generative adversarial networks (GANs), would provide stronger evidence of PALEO's generalizability.
2. Diverse Settings: The experiments could explore a wider range of configurations, including varying batch sizes, layer types, and hardware setups. This would help assess the model's robustness under diverse conditions.
3. Error Analysis: The paper could benefit from a more detailed analysis of cases where PALEO's predictions deviate from actual runtimes. For example, the underestimation of runtime for the 'fc6' layer in AlexNet could be further investigated.
4. Communication Overhead: While PALEO models communication schemes effectively, it would be helpful to include a discussion on how asynchronous or non-deterministic communication strategies might be incorporated in future work.
Questions for the Authors
1. How does PALEO handle emerging architectures like transformers or sparse neural networks, which may have different computational and communication patterns?
2. Could PALEO be extended to account for energy consumption or cost in addition to runtime?
3. How sensitive is PALEO to inaccuracies in the hardware parameters (e.g., FLOPS, bandwidth) provided by the user?
In conclusion, this paper makes a significant contribution to the field of scalable deep learning. While there is room for improvement in terms of experimental diversity and broader applicability, the proposed model is both innovative and practical, warranting acceptance.