Review of the Paper
Summary of Contributions
The paper proposes the Semantic Embedding Model (SEM), a simple yet effective multi-label learning algorithm that uses a one-layer hidden network with softmax (sigmoid) modeling. The authors introduce a Gauss-Seidel mini-batch adaptive gradient descent algorithm for optimization and propose a candidate label sampling strategy based on label frequency to improve efficiency when dealing with large label sets. Experimental results on eight real-world datasets demonstrate that SEM achieves better-than-state-of-the-art results in terms of both prediction quality and computational efficiency. The paper highlights SEM's ability to scale to large label sets and its competitive performance compared to existing methods.
Decision: Reject
While the paper demonstrates strong empirical performance, it falls short in terms of novelty and clarity of contributions. The lack of innovation in the model architecture and optimization method, coupled with questionable claims about non-asymptotic efficiency, make it difficult to justify acceptance. 
Supporting Arguments
1. Lack of Novelty: The proposed SEM employs a one-layer neural network and uses AdaGrad for optimization, both of which are well-established techniques. The alternating AdaGrad steps, while mentioned, are not convincingly shown to contribute significantly to performance. The label sampling strategy, though effective, is a relatively standard approach in the field.
   
2. Empirical Performance vs. Novelty: Despite achieving better-than-state-of-the-art results, the paper does not adequately explain why SEM outperforms existing methods. The empirical results are impressive but do not compensate for the limited theoretical contributions.
3. Efficiency Claims: The paper claims non-asymptotic efficiency improvements, but these are not rigorously substantiated. The trade-offs between implementation complexity and computational gains are not clearly addressed.
Additional Feedback for Improvement
1. Clarify Contributions: The paper should explicitly highlight what is novel about SEM compared to existing methods. If the novelty lies in the combination of techniques, this should be clearly articulated and supported with ablation studies.
2. Impact of Alternating AdaGrad Steps: The impact of the proposed alternating AdaGrad steps on performance should be empirically validated. A comparison with standard AdaGrad would help clarify its importance.
3. Efficiency Analysis: The claims about non-asymptotic efficiency should be supported with a more rigorous analysis. For example, the trade-offs between computational cost and implementation complexity should be quantified.
4. Broader Context: While the paper provides a detailed comparison with state-of-the-art methods, it would benefit from a more thorough discussion of how SEM fits into the broader landscape of multi-label learning. This would help contextualize its contributions.
Questions for the Authors
1. How does the alternating AdaGrad approach specifically contribute to the performance of SEM? Can you provide empirical evidence or ablation studies to isolate its impact?
2. The label sampling strategy is described as standard. Are there specific innovations in your implementation of this technique that differentiate it from existing methods?
3. Can you provide a more detailed analysis of the trade-offs involved in achieving the claimed efficiency improvements? Specifically, how does the implementation complexity scale with the size of the label set?
In summary, while the paper demonstrates strong empirical results, its limited novelty and lack of clarity regarding key contributions make it unsuitable for acceptance in its current form. Addressing the above concerns could significantly strengthen the paper.