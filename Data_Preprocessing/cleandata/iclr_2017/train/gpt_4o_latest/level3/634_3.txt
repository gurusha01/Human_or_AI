Review of the Paper
Summary of Contributions
This paper introduces the Layerwise Origin-Target Synthesis (LOTS) method, a novel approach for visualizing neural network features, assessing feature invariance, and generating diverse adversarial examples. The authors demonstrate the utility of LOTS on two well-known neural networks: LeNet for MNIST digit recognition and VGG for face recognition. The method is shown to provide insights into internal feature representations at different layers, assess the robustness of these features, and produce adversarial examples that can improve model robustness through adversarial training. The paper claims that LOTS generates more diverse adversarial examples compared to existing methods and achieves better adversarial robustness when used for training.
Decision: Reject
The primary reasons for rejection are the lack of sufficient quantitative results and comparisons with other methods, as well as unsubstantiated claims in certain sections of the paper. While the idea of LOTS is interesting and has potential, the current presentation and experimental validation are insufficient to warrant acceptance.
Supporting Arguments for Decision
1. Insufficient Quantitative Results and Comparisons: The paper does not provide enough quantitative evidence to convincingly demonstrate the superiority of LOTS over existing adversarial generation methods. While some comparisons are made, they are limited in scope and do not fully explore the advantages of LOTS in diverse scenarios or datasets. For example, the claim that LOTS outperforms other methods in adversarial training lacks robust statistical evidence.
2. Unclear Explanation of the PASS Score: The PASS score, a key metric used throughout the paper, is not adequately explained. While it is cited from prior work, the lack of a clear definition or justification for its use makes it difficult to assess the validity of the results. This undermines the scientific rigor of the paper.
3. Contradictory Claims in Section 4.1: The discussion on the impact of positive and negative perturbations on class changes is inconsistent. For MNIST, the claim that positive perturbations do not alter classifications is contradicted by results on the VGG Face dataset, where both positive and negative perturbations lead to class changes. This raises concerns about the generalizability of the method and the validity of the underlying assumptions.
4. Incorrect Claim About Lower Layers: The assertion that "LOTS cannot produce high-quality adversarial examples at lower layers" is not consistent with the results for MNIST, where lower-layer perturbations are shown to have high adversarial quality. This inconsistency further weakens the paper's claims.
5. Experimental Validation Post-Rebuttal: While the authors addressed some experimental concerns during the rebuttal phase, the improvements are incremental and do not fully resolve the aforementioned issues. The paper still lacks a comprehensive evaluation of LOTS across diverse datasets and tasks.
Suggestions for Improvement
1. Expand Quantitative Comparisons: Include more rigorous experiments comparing LOTS with state-of-the-art adversarial generation methods across multiple datasets and tasks. Provide statistical significance tests to strengthen claims.
2. Clarify the PASS Score: Provide a detailed explanation of the PASS score, including its mathematical formulation and relevance to the evaluation of adversarial examples.
3. Address Contradictions: Revisit and reconcile the contradictory claims about the impact of perturbations and the quality of adversarial examples at different layers. Clearly explain any dataset-specific behaviors.
4. Provide Visual and Quantitative Evidence: Include more visualizations and quantitative metrics to support the claims about the interpretability and utility of LOTS for feature visualization.
5. Broaden the Scope: Explore the applicability of LOTS beyond MNIST and VGG Face datasets to demonstrate its generalizability and robustness.
Questions for the Authors
1. Can you provide a formal definition and justification for the use of the PASS score? How does it compare to other perceptual similarity metrics?
2. Why do positive perturbations lead to class changes in VGG Face but not in MNIST? Is this behavior dataset-specific, or does it depend on the architecture?
3. How does LOTS perform on more complex datasets, such as CIFAR-10 or ImageNet? Have you considered evaluating it on tasks beyond classification, such as object detection or segmentation?
4. Can you clarify the claim that LOTS cannot produce high-quality adversarial examples at lower layers? How does this reconcile with the results for MNIST?
In conclusion, while the paper presents an interesting idea with potential, it requires significant improvements in experimental rigor, clarity, and scope to meet the standards of the conference.