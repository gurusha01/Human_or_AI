Review
Summary of Contributions
This paper investigates whether deep convolutional networks can be replaced with shallow networks without sacrificing accuracy, particularly in the context of image classification tasks. Using the CIFAR-10 dataset, the authors employ L2 regression on logit outputs for training shallow student models to mimic deep teacher models. The results demonstrate that shallow models require multiple convolutional layers to achieve comparable accuracy to deep convolutional networks, even with the same parameter budget. The authors challenge prior findings by Ba and Caruana (2014), showing that their conclusions do not generalize to CIFAR-10 when parameter budgets are constrained. The experiments are thorough, leveraging Bayesian optimization for hyperparameter tuning and employing state-of-the-art data augmentation techniques. The paper is clearly written, and its findings provide valuable insights into the necessity of depth and convolution in neural networks.
Decision: Accept
The paper should be accepted for publication. The key reasons for this decision are:
1. Significance of Results: The findings challenge prior influential work and provide strong empirical evidence that depth and convolution are critical for achieving high accuracy in image classification tasks like CIFAR-10, even under parameter constraints.
2. Scientific Rigor: The experiments are meticulously designed, with careful hyperparameter optimization and robust methodology, ensuring the validity of the results.
Supporting Arguments
1. Research Question and Motivation: The paper addresses an important and timely question about the trade-offs between depth and accuracy in neural networks. The motivation is well-grounded in the literature, particularly in light of prior claims by Ba and Caruana (2014) that shallow networks can mimic deep networks effectively.
2. Experimental Rigor: The authors employ state-of-the-art techniques, including Bayesian optimization and data augmentation, to ensure the robustness of their findings. The use of a strong teacher ensemble model (93.8% accuracy on CIFAR-10) further strengthens the validity of the results.
3. Clarity and Presentation: The paper is well-written and easy to follow, with detailed descriptions of the experimental setup and clear presentation of results.
Suggestions for Improvement
1. Generalizability: The paper's conclusions are based solely on the CIFAR-10 dataset, which is relatively simple compared to real-world datasets like ImageNet. Extending the experiments to more complex datasets would significantly enhance the paper's impact and generalizability.
2. Discussion of Limitations: While the authors acknowledge that shallow models perform poorly on CIFAR-10, a deeper discussion of why this might be the case (e.g., representational limitations, optimization challenges) would add depth to the analysis.
3. Comparison with Other Methods: The paper could benefit from a more detailed comparison with alternative approaches for training shallow models, such as knowledge distillation techniques that incorporate intermediate teacher representations (e.g., Romero et al., 2015).
Questions for the Authors
1. Have you considered testing your approach on more complex datasets like ImageNet to assess generalizability? If so, what are the preliminary results?
2. Can you provide more insights into why dropout negatively impacts the performance of student models trained via distillation? Is this effect consistent across all architectures?
3. Would incorporating intermediate teacher representations (e.g., hints) into the distillation process improve the performance of shallow models?
In conclusion, this paper makes a significant contribution to the understanding of depth and convolution in neural networks. While additional experiments on more complex datasets would strengthen the findings, the current results are compelling and merit publication.