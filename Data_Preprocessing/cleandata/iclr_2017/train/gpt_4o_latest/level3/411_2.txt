Review of the Paper
Summary of Contributions
This paper presents an innovative extension to stochastic search-based superoptimization (STOKE) by integrating a neural network to learn the proposal distribution, conditioned on program embeddings. The authors employ the REINFORCE algorithm to optimize the parameters of the proposal distribution, aiming to minimize the final program cost. The proposed method is validated on two datasets: the "Hacker's Delight" benchmark and a set of automatically generated programs. Results demonstrate significant improvements over the baseline STOKE implementation, with the learned proposal distributions achieving faster convergence and higher-quality optimizations. The paper also highlights the potential for broader applications of this approach to other stochastic search problems.
Decision: Accept
The paper makes a meaningful contribution to the field of program optimization by introducing a learning-based enhancement to stochastic search methods. The integration of neural networks into the MCMC framework is novel and well-motivated, and the empirical results convincingly demonstrate the effectiveness of the proposed approach. However, there are areas where additional clarification and exploration would strengthen the work.
Supporting Arguments
1. Clear Problem Definition and Motivation: The paper identifies a key limitation of existing stochastic superoptimization methods—their reliance on uninformed, static proposal distributions—and proposes a well-motivated solution using reinforcement learning. The analogy to paraphrasing in NLP is intuitive and helps contextualize the problem.
   
2. Empirical Validation: The experiments on both the "Hacker's Delight" benchmark and the more diverse synthetic dataset are thorough and demonstrate consistent improvements over the baseline. The learned proposal distributions not only outperform uniform sampling but also achieve better results with fewer iterations, highlighting the practical utility of the approach.
3. Writing and Presentation: The paper is clearly written, with a logical flow and sufficient technical detail to understand the methodology. The inclusion of stochastic computation graphs and detailed experimental setups enhances reproducibility.
Suggestions for Improvement
1. Clarification on Learning Scope: It is unclear whether the learning is limited to the features-to-proposal mapping while retaining the rest of the STOKE MCMC scheme. A more explicit discussion of what components are learned versus inherited from STOKE would be helpful.
2. Baseline Comparisons: The role of the "uniform" model as a baseline should be clarified. Is it the default STOKE implementation, or a modified version? Additionally, comparisons to other learning-based optimization methods, such as those by Salimans et al. (2015), would strengthen the related work discussion.
3. Feature Learning: While the authors acknowledge the use of pre-defined features due to data limitations, exploring the potential for learning features directly (e.g., through graph-based representations of programs) could be a valuable direction for future work.
4. Citations and Related Work: The paper could benefit from citing Salimans et al.'s work on optimizing MCMC schemes via variational criteria, as it aligns closely with the proposed approach. This would position the work more effectively within the broader literature.
Questions for the Authors
1. Could you elaborate on whether the learned proposal distribution is dynamically updated during optimization or remains fixed for each program?
2. How does the choice of program embeddings affect the performance of the MLP model? Have alternative embeddings, such as graph-based representations, been considered?
3. Could you provide more details on the synthetic dataset generation process? Specifically, how diverse are the generated programs in terms of structure and complexity?
Conclusion
This paper addresses a significant limitation in stochastic superoptimization and proposes a novel, well-motivated solution. While there are areas for clarification and further exploration, the empirical results and methodological contributions justify acceptance. The work has the potential to inspire further research in learning-based optimization for programs and stochastic search problems more broadly.