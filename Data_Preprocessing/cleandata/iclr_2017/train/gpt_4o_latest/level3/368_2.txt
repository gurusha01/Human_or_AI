The paper presents a novel approach to evaluating log-likelihoods for decoder-based generative models using Annealed Importance Sampling (AIS), validated through Bidirectional Monte Carlo (BDMC). It provides significant educational value by addressing key challenges in evaluating generative models, such as the inadequacy of Kernel Density Estimation (KDE) and the limitations of inspecting samples. The authors demonstrate AIS's superiority over existing methods, offering a robust framework for analyzing the performance of Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and Generative Moment Matching Networks (GMMNs). The paper also contributes empirical insights into overfitting, mode coverage, and the limitations of existing log-likelihood estimators, encouraging broader adoption of AIS in the field.
Decision: Reject
While the paper makes valuable contributions, it falls short in several areas that hinder its clarity and impact. The primary reasons for rejection are the insufficient explanation of AIS and the lack of clarity in key sections, which impede the reader's understanding of the methodology and results.
Supporting Arguments:
1. Insufficient Explanation of AIS: The description of AIS lacks depth, particularly in explaining why the algorithm works and its theoretical underpinnings. While the methodology is described, the intuition behind AIS and its advantages over simpler importance sampling methods are not adequately conveyed.
2. Figure 2 Confusion: The labeling and caption of Figure 2 are unclear, leading to confusion about the comparison between GAN, GMMN, and IWAE. This undermines the reader's ability to interpret the results effectively.
3. Model Evaluation Limitation: The paper relies heavily on reconstructions for model evaluation, which is insufficient. While the authors acknowledge this limitation, they do not provide a detailed discussion of its implications or alternative evaluation strategies.
Additional Feedback:
1. Reference Suggestion: The paper would benefit from citing MacKay's density networks (MacKay, 1995) to provide historical context for decoder-based generative models.
2. Posterior vs. Prior: The relevance of the posterior for importance sampling in Section 2.2 is unclear. The authors should improve the flow and clarify the connection between the posterior and AIS.
3. Log-Space Estimation: The claim in Section 2.3 about estimating \( p(x) \) in log-space due to underflow issues is poorly phrased. This section needs clearer language and justification.
4. Broader Applicability: While the paper focuses on MNIST, it would be helpful to discuss the generalizability of the proposed method to other datasets and modalities.
Questions for the Authors:
1. Could you provide a more intuitive explanation of why AIS outperforms KDE and IWAE in high-dimensional settings?
2. How does the choice of intermediate distributions in AIS affect the accuracy and computational cost of the log-likelihood estimates?
3. Can you elaborate on how the proposed method could be extended to other types of generative models or datasets beyond MNIST?
In summary, while the paper addresses an important problem and provides valuable insights, its lack of clarity and depth in key areas limits its potential impact. Addressing these issues could significantly strengthen the paper for future submissions.