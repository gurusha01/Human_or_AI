The paper proposes an autoencoder-based approach for lossy image compression, aiming to minimize reconstruction error and code length. The architecture employs a convolutional encoder and a sub-pixel convolutional decoder, leveraging techniques from super-resolution to improve efficiency. The authors address the non-differentiability of quantization and entropy rate estimation with innovative differentiable approximations, enabling end-to-end training. Experimental results demonstrate competitive performance with JPEG-2000 and superior results compared to RNN-based methods, evaluated using metrics like PSNR, SSIM, MS-SSIM, and a mean opinion score (MOS) test. The proposed method is computationally efficient, suitable for high-resolution images, and adaptable to diverse compression requirements.
Decision: Accept  
Key reasons for acceptance include the paper's compelling contribution to the field of neural network-based image compression and its competitive performance with established codecs like JPEG-2000. The innovative use of sub-pixel convolution in the decoder and the well-justified handling of quantization and rate estimation are significant strengths. The work is impactful, addressing a problem of high relevance to the community, and sets a strong foundation for future research.
Supporting Arguments  
1. Well-Motivated Approach: The paper clearly identifies the limitations of traditional codecs and the challenges of optimizing autoencoders for lossy compression. It builds on prior work (e.g., Balle et al. 2016) while introducing novel solutions for non-differentiability, making the approach both innovative and well-grounded in the literature.  
2. Empirical Rigor: The experiments are thorough, comparing the proposed method against strong baselines (JPEG, JPEG-2000, RNN-based methods) using multiple metrics. The inclusion of MOS testing adds a perceptual dimension to the evaluation, strengthening the claims.  
3. Practical Impact: The method's computational efficiency and adaptability to different bit rates and content types make it practical for real-world applications, such as streaming and archiving.
Suggestions for Improvement  
1. Incomplete Baselines: The paper does not compare its method to Balle et al. (2016) or fully implement Toderici et al. (2016b). Including these baselines would provide a more comprehensive evaluation and strengthen the empirical claims.  
2. Ablation Studies: While the paper discusses the benefits of sub-pixel convolution and incremental training, explicit ablation studies quantifying their contributions would enhance the clarity of the results.  
3. Perceptual Metrics: The paper mentions the potential for optimizing autoencoders for perceptual metrics but does not explore this direction. Future work could investigate this to further improve perceptual quality.
Questions for the Authors  
1. How does the proposed method perform on other datasets or non-natural images? Can the adaptability to specific content types be demonstrated empirically?  
2. Could you elaborate on the computational cost of training and inference compared to JPEG-2000 and RNN-based methods?  
3. What are the limitations of the current approach, particularly in terms of scalability to larger images or other media formats like video?  
Overall, this paper makes a strong contribution to the field of neural network-based image compression and is recommended for acceptance with minor revisions to address the above points.