Review of "Semantic Embedding Model for Multi-Label Learning"
Summary
The paper introduces the Semantic Embedding Model (SEM), a neural network-based approach for multi-label learning. SEM models labels as draws from a multinomial distribution parameterized by nonlinear transformations of input features. To handle large label sets, the authors propose fitting randomly chosen marginal label distributions instead of the full label distribution. The paper claims that SEM outperforms state-of-the-art methods (e.g., NNML, BMLPL, REmbed, SLEEC) in both prediction performance and training time. Experimental results on eight datasets demonstrate the model's scalability and effectiveness.
Decision: Reject
While the paper proposes an interesting approach, several critical issues undermine its contributions. Specifically, the lack of clarity in positioning SEM within the existing literature, insufficient empirical comparisons to simpler baselines, and ambiguous claims regarding the "semantic" nature of embeddings weaken the paper's scientific rigor.
Supporting Arguments
1. Orthogonality of Label Count Assumption: The authors claim that the assumption of a known number of labels to predict is orthogonal to their model. However, this assumption is fundamental to the problem formulation and affects the generalizability of SEM. The paper does not adequately address how SEM would perform in scenarios where the number of labels is unknown or varies dynamically.
2. Comparison to Baselines: The reviewer questions how SEM differs from a basic multi-layer perceptron (MLP) with a softmax output trained in a two-step approach. The lack of empirical comparisons to such a baseline leaves it unclear whether SEM's performance gains are due to its novel design or simply the use of standard neural network techniques.
3. Ambiguity in "Semantic" Embeddings: The term "semantic" implies meaningful relationships between embeddings, yet the paper provides no evidence of such semantics. The embeddings appear to be task-specific latent representations rather than semantically interpretable features.
4. Sampling Strategy: The proposed sampling strategy for marginal distributions is similar to Jean et al.'s work. While the authors mention differences, these are not explicitly highlighted or justified. A more detailed discussion is necessary to clarify the novelty of this contribution.
Additional Feedback
- Empirical Evaluation: The paper focuses on comparing SEM to state-of-the-art methods but neglects simpler baselines (e.g., MLP with softmax). Including these comparisons would strengthen the claims of SEM's superiority.
- Clarity of Contributions: The paper's novelty is obscured by a lack of clear differentiation from existing methods. For instance, the connection to Bayesian Exponential Family PCA is mentioned but not explored in depth.
- Scalability: While SEM is claimed to be scalable, the experiments do not thoroughly explore its performance on datasets with extremely large label sets (e.g., millions of labels). This would better establish its scalability claims.
Questions for the Authors
1. How does SEM perform when the number of labels to predict is unknown or varies across instances? Can the model adapt dynamically?
2. What distinguishes SEM from a standard MLP with softmax output? Could you provide empirical comparisons to this baseline?
3. What evidence supports the claim that the embeddings are "semantic"? Are there qualitative analyses or visualizations to demonstrate this?
4. How does the proposed sampling strategy differ from Jean et al.'s approach, and why is it better suited for multi-label learning?
In conclusion, while the paper presents an interesting approach, addressing the above concerns is necessary to establish its contributions more convincingly.