Review of the Paper
Summary of Contributions
This paper introduces a novel low-rank and low-rank plus diagonal parametrization for passthrough neural networks, aiming to reduce the number of trainable parameters while preserving memory capacity. The approach is applied to recurrent architectures such as GRUs and LSTMs, with experiments conducted on tasks like sequential MNIST, memory tasks, and language modeling. The authors claim competitive results, including a near state-of-the-art performance on the sequential permuted MNIST task. The work is positioned as an alternative to convolutional parametrizations and highlights the potential for combining the proposed methods with other architectural innovations.
Decision: Reject
The paper is rejected primarily for two reasons:
1. Unconvincing Results: The experimental results fall short of state-of-the-art performance on key benchmarks like sequential MNIST and memory tasks. While the approach demonstrates some utility, it does not consistently outperform competing methods such as uRNNs, especially in terms of convergence speed and parameter efficiency.
2. Increased Complexity: The introduction of an additional hyperparameter (the rank `d`) adds complexity to the model and training process, which is not sufficiently justified by the performance gains.
Supporting Arguments
1. Experimental Weaknesses: While the proposed low-rank plus diagonal GRU achieves competitive results on some tasks, it often requires more parameters than baseline models (e.g., uRNN) and converges more slowly. For instance, the memory task results show that the model requires significantly more updates than uRNN to achieve comparable performance. Similarly, on sequential MNIST, the proposed method does not surpass the best-reported results in the literature.
2. Hyperparameter Tuning: The additional rank hyperparameter introduces complexity, requiring careful tuning to balance parameter efficiency and performance. This undermines the simplicity and practicality of the approach, especially when compared to existing methods that achieve better results with fewer parameters.
3. Lack of Comprehensive Comparisons: The paper lacks direct comparisons with competing approaches in key tables and figures, such as uRNNs and other state-of-the-art methods. This omission makes it difficult to assess the relative merits of the proposed method.
Suggestions for Improvement
1. Stronger Experimental Validation: The authors should provide more compelling results, particularly on tasks like sequential MNIST and memory tasks, where state-of-the-art methods excel. Including additional benchmarks would also strengthen the paper.
2. Comparative Analysis: Tables and figures should include direct comparisons with competing approaches (e.g., uRNNs) to provide a clearer picture of the proposed method's strengths and weaknesses.
3. Justification of Complexity: The paper should better justify the introduction of the rank hyperparameter by demonstrating its impact on performance and parameter efficiency. A sensitivity analysis of the rank parameter would be helpful.
4. Broader Applicability: The authors could explore the utility of the proposed parametrizations in other domains or tasks, such as natural language processing or vision, to demonstrate broader applicability.
Questions for the Authors
1. How does the proposed method perform when combined with other architectural innovations, such as time-skip connections or recurrent batch normalization?
2. Can the authors provide a detailed comparison of computational efficiency (e.g., training time, memory usage) between the proposed method and uRNNs?
3. How sensitive is the performance to the choice of the rank hyperparameter `d`? Would an adaptive mechanism for determining `d` improve the practicality of the approach?
In conclusion, while the paper introduces an interesting idea, the experimental results and clarity of comparisons are insufficient to warrant acceptance at this stage. Addressing these issues would significantly strengthen the contribution.