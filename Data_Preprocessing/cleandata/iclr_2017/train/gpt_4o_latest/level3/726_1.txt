The paper introduces Information Dropout, a novel generalization of dropout motivated by the Information Bottleneck (IB) principle. The method injects noise into layer activations to control the flow of information, encouraging representations that are invariant to nuisances in the data. The authors establish theoretical links between information theory, representation learning, and variational inference, and demonstrate that Information Dropout unifies several existing dropout methods. Experimental results show small but consistent improvements over binary dropout, particularly on tasks like cluttered MNIST, where nuisance invariance is critical.
Decision: Accept
Key Reasons:
1. The paper provides a strong theoretical contribution by linking probabilistic variational methods and information-theoretic approaches, offering a fresh perspective on dropout methods.
2. The experimental results, while preliminary, demonstrate the potential of the proposed method, especially in scenarios with significant nuisance factors.
3. The paper is well-written, clear, and presents its ideas in a structured and accessible manner.
Supporting Arguments:
- Quality: The theoretical exposition is rigorous and well-grounded in the literature. The derivation of Information Dropout from the IB Lagrangian is novel and highlights the method's conceptual elegance. However, the experimental results, while promising, could be more robust, particularly on standard benchmarks like CIFAR-10, where comparisons with prior work are unclear due to the use of validation rather than test sets.
- Clarity: The paper is easy to follow, with clear explanations of the methodology and its connections to existing work. The figures and experimental setups are well-documented, though some additional details (e.g., error bars in Figure 3(b)) would enhance clarity.
- Originality: The use of the IB principle to derive a generalization of dropout is innovative. However, the final model closely resembles variational dropout, which slightly limits its novelty.
- Significance: The paper provides an alternative perspective on latent variable modeling and dropout, with potential implications for tasks requiring nuisance invariance. However, its practical impact is contingent on demonstrating significant performance improvements over simpler methods.
Suggestions for Improvement:
1. Experimental Validation: 
   - Use the test set for CIFAR-10 experiments to enable fair comparisons with prior work.
   - Include error bars in Figure 3(b) to provide a sense of variability in the results.
   - Compare Figure 2's activity maps with those of standard CNNs using binary dropout to better illustrate the advantages of Information Dropout.
2. Clarity and Presentation: 
   - Fix minor typos such as "expecially" → "especially" and "trough" → "through."
   - Verify the correctness of the H(y|z) expression, as a missing minus sign is suspected.
3. Broader Benchmarks: Extend experiments to additional datasets and tasks to better establish the method's generalizability and practical utility.
Questions for the Authors:
1. How does Information Dropout compare to binary dropout in terms of computational overhead during training and inference?
2. Can the method's performance be improved by tuning the β parameter dynamically during training, rather than fixing it?
3. How robust is Information Dropout to hyperparameter choices, such as the noise distribution and its variance?
In conclusion, this paper makes a valuable theoretical contribution and presents a promising method for learning nuisance-invariant representations. While the experimental results leave room for improvement, the paper's insights and potential warrant its acceptance.