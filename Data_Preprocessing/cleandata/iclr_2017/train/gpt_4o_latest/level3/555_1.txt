Review of the Paper
Summary of Contributions
This paper addresses the challenge of designing and evaluating deep neural network (DNN) architectures for supervised classification tasks, particularly in domains with limited prior knowledge. The authors propose a meta-learning approach to rank DNN architectures based on their predicted performance, leveraging topological features and early training dynamics. The paper also explores the effectiveness of DNN architectures with parallel layers and evaluates their transferability across multiple datasets. The contributions include a novel architecture generation method, a systematic evaluation of architectures on tabular datasets, and the introduction of meta-features for architecture ranking. The study highlights the potential of meta-learning to reduce computational costs in architecture search and provides insights into the design of DNNs for general classification problems.
Decision: Reject
While the paper tackles an interesting and relevant problem, it falls short in several critical areas. The experimental section is weak and lacks rigor, and the comparison with other approaches is insufficient. These shortcomings undermine the validity of the claims and limit the paper's contribution to the field.
Supporting Arguments for the Decision
1. Weak Experimental Section: The experimental setup is limited to 13 tabular datasets, which, while diverse, do not include widely recognized benchmarks. The absence of experiments on familiar datasets (e.g., MNIST, CIFAR-10) makes it difficult to contextualize the results within the broader literature. Additionally, the analysis of parallel architectures and their performance lacks depth, with no clear statistical significance reported for the observed trends.
2. Insufficient Comparison with Other Approaches: The paper does not adequately compare its meta-learning-based ranking method with existing architecture search techniques, such as neural architecture search (NAS) or Bayesian optimization. Without such comparisons, it is unclear how the proposed method advances the state of the art.
3. Unconvincing Arguments: The claims regarding the transferability of architectures across datasets and the superiority of parallel architectures are not well-supported. The results are presented without sufficient discussion of their implications or limitations, and the conclusions drawn often feel speculative.
Additional Feedback for Improvement
1. Expand Dataset Selection: Include experiments on familiar datasets like MNIST, CIFAR-10, or ImageNet to provide a baseline for comparison. Additionally, consider incorporating more underexplored datasets to strengthen the generalizability of the findings.
2. Strengthen Experimental Rigor: Provide statistical significance tests for the reported results, particularly for claims about parallel architectures and meta-learning performance. Include ablation studies to isolate the contributions of different meta-feature groups.
3. Improve Comparisons: Benchmark the proposed approach against state-of-the-art methods in architecture search and ranking. This will help clarify the novelty and effectiveness of the meta-learning approach.
4. Clarify Contributions: The paper should better articulate its key contributions and how they address gaps in the literature. For example, the novelty of using early training dynamics for ranking architectures should be emphasized and compared to related work.
Questions for the Authors
1. How does the proposed meta-learning approach compare to existing NAS methods in terms of computational efficiency and performance?
2. Why were familiar datasets excluded from the experimental evaluation? Would the proposed method generalize to image or speech datasets?
3. Can you provide more details on the statistical significance of the reported results, particularly for the performance of parallel architectures?
In conclusion, while the paper explores an important problem and presents some novel ideas, it requires significant improvements in experimental rigor, comparative analysis, and clarity of contributions to be considered for acceptance.