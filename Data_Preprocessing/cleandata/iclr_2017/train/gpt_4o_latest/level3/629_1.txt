Review of the Paper
Summary of Contributions
This paper investigates the computational similarities between human visual perception and deep neural networks (DNNs) trained on large-scale image recognition tasks. The authors present three key findings: (1) DNNs outperform simpler metrics in predicting human sensitivity to noise perturbations, with mid-computation layers showing the strongest correlation; (2) DNNs partially replicate human error patterns in visual processing tasks like segmentation and crowding, using an information-theoretic metric; and (3) DNNs exhibit contrast sensitivity patterns qualitatively similar to humans, with bandpass responses at low contrast and constant responses at high contrast. The paper's approach of linking psychophysical data to DNN computations is a commendable effort to bridge neuroscience and artificial intelligence, offering insights into the convergence of learned computations across biological and artificial systems.
Decision: Reject
While the paper presents an interesting exploration of DNN-human perceptual similarities, I recommend rejection due to (1) insufficient novelty and (2) significant issues in the presentation and depth of analysis.
Supporting Arguments
1. Lack of Novelty: The findings largely confirm existing knowledge that DNNs can model certain aspects of human vision. The paper does not introduce new methodologies or significantly advance our understanding of why or how these similarities emerge. Additionally, it does not differentiate between DNN architectures, leaving open questions about which design choices are critical for modeling human perception.
2. Missed Opportunities in Analysis: The 24% gap in explained variance between DNNs and humans in the noise discrimination task (Result 1) is a critical insight that could have been explored further. Instead, the paper shifts focus to Results 2 and 3, which are less impactful and lack sufficient quantitative rigor.
3. Presentation Issues: Quantitative results for Results 2 and 3 are unclear, with key figures (e.g., Figure 8) placed in the appendix, making it difficult to assess the claims. The qualitative comparison in Result 3 could have been strengthened with precise quantitative metrics, such as detailed contrast sensitivity curves.
Suggestions for Improvement
1. Deepen Analysis of Result 1: The authors should investigate the sources of the 24% gap in explained variance between DNNs and humans. For example, is this discrepancy due to architectural limitations, training data biases, or fundamental differences in biological and artificial learning?
2. Improve Quantitative Rigor: For Results 2 and 3, provide clear, quantitative comparisons between DNN and human performance. Include key figures in the main text and use metrics like R² or correlation coefficients to support claims.
3. Expand Discussion of DNN Architectures: The paper could explore how specific architectural features (e.g., depth, recurrent connections) influence the observed similarities, providing actionable insights for both AI and neuroscience communities.
4. Address Broader Implications: The discussion should consider the limitations of feedforward DNNs in modeling recurrent processes in human vision and propose future directions, such as incorporating recurrence or unsupervised learning.
Questions for the Authors
1. What factors contribute to the 24% gap in explained variance in Result 1? Could this be due to differences in how noise is represented in DNNs versus human perception?
2. Why were Results 2 and 3 prioritized over a deeper exploration of Result 1, which appears to be the most novel and impactful finding?
3. Can you provide quantitative metrics for the qualitative claims in Result 3? For example, how do the contrast sensitivity curves of DNNs compare to human data in terms of R² or other similarity measures?
4. How do different DNN architectures (e.g., ResNet vs. VGG) perform on these tasks, and what does this suggest about the role of architecture in modeling human perception?
In conclusion, while the paper takes an important step toward linking DNNs and human vision, it falls short in novelty, depth, and clarity, leaving significant room for improvement.