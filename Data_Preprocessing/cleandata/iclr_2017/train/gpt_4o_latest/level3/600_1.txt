The paper introduces a novel Group Sparse Autoencoder (GSA) framework and extends it into a Group Sparse Convolutional Neural Network (GSCNN) for question classification tasks. The key contribution lies in leveraging group-wise sparsity, informed by label-based supervision, to encode answer information into question representations. This approach is particularly innovative in combining inter- and intra-group sparsity constraints, as formalized in Equation (9), and embedding these into a CNN architecture for end-to-end training. The proposed method demonstrates significant improvements over baselines on datasets like Insurance and DMV, showcasing its potential for tasks involving hierarchical and overlapping question categories.
Decision: Reject
The primary reasons for rejection are the lack of clarity in the methodological exposition and insufficient empirical rigor in validating the claims. While the proposed GSA and GSCNN frameworks are conceptually interesting, the paper suffers from critical issues in clarity, experimental design, and baseline comparisons.
Supporting Arguments:
1. Clarity Issues: The paper fails to clearly explain whether only the p-th group's activation is used for reconstruction and how Equation (9) handles individual hidden representations. This ambiguity undermines the reader's ability to fully understand the proposed method. Additionally, Equation (7) contains a typo, missing a summation over p, which further detracts from the paper's technical rigor.
   
2. Baseline Comparisons: The experimental setup lacks fair comparisons. The paper compares GSCNN with standard CNNs but does not include baselines that incorporate classification objectives into autoencoders, such as sequential CNN + sparse autoencoder. This omission makes it difficult to isolate the benefits of the proposed method.
3. Empirical Validation: While the paper claims improvements in classification performance, it does not convincingly demonstrate that these gains extend beyond visual inspection. For instance, Figure 3(b) is unconvincing, as some filters do not clearly represent class-specific patterns. Moreover, the experiments lack control studies varying \(\alpha\) and \(\beta\) in Equations (7)-(9), which are critical hyperparameters for sparsity.
4. Missing References: The paper overlooks relevant prior work, such as Shang et al. (SDM 2016), which discusses block orthogonal matching pursuit for label-based discriminative dictionary learning. Including this reference could have provided a stronger foundation for the proposed method.
Additional Feedback:
1. End-to-End Training: The paper should clarify whether the GSCNN is truly end-to-end trainable, as it appears to rely on features extracted from pretrained CNNs. This dependency could limit the method's applicability.
   
2. Visualization and Results: The visualization in Figure 3(b) needs to be more compelling. The authors should provide quantitative metrics to substantiate claims about class-specific patterns in the learned filters.
3. Datasets: The paper would benefit from a more detailed discussion of dataset characteristics, particularly the hierarchical and overlapping structures in the Insurance and DMV datasets. This would help contextualize the improvements achieved.
4. Reproducibility: The authors should provide implementation details, including hyperparameters and training procedures, to ensure reproducibility.
Questions for Authors:
1. How does Equation (9) handle individual hidden representations, and is the sparsity constraint applied only at the group level or also at the individual level?
2. Can you clarify whether the GSCNN framework is fully end-to-end trainable, or does it rely on pretrained CNN features?
3. Why were comparisons with sequential CNN + sparse autoencoder or other classification-objective autoencoders omitted?
4. How robust are the results to variations in \(\alpha\) and \(\beta\) in Equations (7)-(9)?
While the paper presents an interesting idea, addressing these issues is essential to improve its clarity, rigor, and overall impact.