Review of "Can a Static Analyzer Be Learned from Data?"
Summary of Contributions
This paper explores the feasibility of learning a static analyzer using deep learning, specifically LSTMs, without relying on feature engineering. The authors design a toy programming language and task the models with determining whether variables in a program are defined before use. The paper demonstrates that LSTMs outperform traditional methods like HMMs, RNNs, and feature-based approaches, achieving high accuracy on this simplified problem. Additionally, the authors propose a language model to locate errors in code, showcasing the potential for practical applications. The paper positions itself as a preliminary step toward using machine learning for program analysis, emphasizing the resilience of learned models to small syntactic errors and their ability to provide useful error localization.
Decision: Reject  
Key Reasons:
1. Oversimplified Problem Setup: The use of a toy language and a trivial static analysis task (variable definition before use) significantly limits the paper's relevance to real-world static analysis challenges. The extreme simplicity undermines confidence in the approach's scalability or applicability to more complex programming languages and tasks.
2. Unconvincing Methodology: The problem posed can be solved with basic logic using a set data structure, making the use of an LSTM unsurprising and uninformative. The results, while high in accuracy, do not convincingly demonstrate the necessity or advantage of deep learning over traditional methods for this task.
Supporting Arguments
1. Problem Definition and Motivation: While the paper raises an interesting question about learning static analyzers from data, the chosen task—detecting undefined variables in a toy language—is overly simplistic. Static analysis in real-world programming involves far more complex constructs like functions, memory management, and modularity, which are entirely absent here. This limits the broader impact of the work.
2. Methodological Concerns: The authors acknowledge that the task can be solved using a simple set-based approach. The use of LSTMs, while effective, is neither surprising nor particularly innovative given the problem's simplicity. Furthermore, the reliance on annotated intermediate signals for training the differentiable data structure raises questions about the generalizability of the approach.
3. Results and Claims: While the LSTM achieves high accuracy, this is expected given the toy nature of the problem. The paper does not provide sufficient evidence that the approach would scale to realistic static analysis tasks. The claim that LSTMs are resilient to small syntactic errors is interesting but not rigorously analyzed.
Suggestions for Improvement
1. Expand the Problem Scope: To make the work more impactful, the authors should consider applying their approach to a more realistic programming language and a broader range of static analysis tasks. For example, handling functions, memory allocation, or control-flow analysis would provide stronger evidence of the method's utility.
2. Compare Against Baselines: A direct comparison with traditional static analysis tools or algorithms (e.g., symbolic execution or abstract interpretation) would help contextualize the results and highlight any advantages of the proposed approach.
3. Clarify the Role of Deep Learning: The authors should better justify why deep learning is necessary for this task. Demonstrating that LSTMs can learn non-trivial patterns beyond what a set-based approach can achieve would strengthen the contribution.
4. Address Scalability: The paper should discuss how the approach could scale to larger programs and more complex languages. This includes addressing challenges like variable naming diversity, program length, and the presence of advanced language features.
Questions for the Authors
1. How does the proposed approach handle more complex programming constructs, such as nested loops, functions, or recursion?
2. Can the authors provide evidence that the LSTM-based method generalizes to unseen programs with significantly different structures or variable naming conventions?
3. Why was a toy language chosen instead of a subset of an existing real-world language (e.g., Python or Java)?
4. How does the proposed method compare in terms of computational efficiency and accuracy to traditional static analysis techniques?
In summary, while the paper explores an intriguing idea, the oversimplified problem setup and lack of compelling justification for deep learning limit its contribution. Expanding the scope and providing stronger evidence of scalability and generalizability would significantly enhance its impact.