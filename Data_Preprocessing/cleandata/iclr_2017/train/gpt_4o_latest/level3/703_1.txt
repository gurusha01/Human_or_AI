Review of "Tartan: A Hardware Accelerator for Inference with Deep Neural Networks"
Summary of Contributions
The paper introduces Tartan (TRT), a hardware accelerator for deep neural network (DNN) inference that leverages bit-serial compute units to scale execution time and energy efficiency with the precision of input data. Unlike prior work, Tartan extends the bit-serial approach to both convolutional and fully-connected layers, enabling performance improvements for fully-connected layers—a limitation of earlier designs like Stripes. The authors claim that Tartan achieves up to 1.90× speedup and 1.17× energy efficiency improvement over DaDianNao (DaDN) without accuracy loss, while allowing for further trade-offs between accuracy and performance. However, this comes at the cost of a 3× area overhead compared to DaDN. The paper also explores a 2-bit processing variant to mitigate area overhead while maintaining competitive performance.
Decision: Reject
The primary reasons for rejection are: 
1. Limited novelty: The core innovation—bit-serial compute units—is incremental and heavily reliant on DaDianNao's architecture, with minimal architectural differentiation. 
2. Methodological concerns: The energy efficiency claims (17% improvement) lack rigorous validation and may fall within the margin of error.
3. Venue misalignment: The work's focus on circuit-level optimizations and area trade-offs makes it more suitable for a hardware or circuit design conference than an AI-focused venue.
Supporting Arguments
1. Problem and Motivation: The paper addresses the well-known challenge of exploiting reduced precision in DNNs for performance and energy gains. While this is a relevant and timely problem, the proposed solution—bit-serial compute units—has limited novelty. The concept of bit-serial computation has been explored in prior work (e.g., Stripes, Pragmatic), and the extension to fully-connected layers, while useful, does not represent a significant leap in innovation.
   
2. Methodology and Rigor: The methodology for energy estimation raises concerns. The claimed 1.17× energy efficiency improvement is modest and could be within the margin of error, especially given the lack of detailed sensitivity analysis or validation against real hardware. Additionally, the 3× area overhead is substantial and undermines the practicality of the design, particularly for large-scale deployment.
3. Results and Claims: While the performance improvements (up to 1.90× speedup) are promising, they are achieved at a high area cost. The trade-offs between area, performance, and energy efficiency are not adequately justified, and the results do not convincingly demonstrate a clear advantage over existing accelerators like DaDianNao or EIE.
4. Venue Suitability: The paper's emphasis on hardware-level details, such as register design and area overhead, aligns more closely with circuit design or computer architecture conferences. The AI community would benefit more from insights into how Tartan impacts broader AI tasks or enables new capabilities.
Suggestions for Improvement
1. Energy Methodology: Provide a more rigorous methodology for energy estimation, including sensitivity analysis and validation against real hardware or detailed simulation results.
2. Area Overhead: Address the 3× area overhead with a more detailed discussion of how it impacts scalability and deployment in real-world systems. The 2-bit processing variant is a step in the right direction but requires further exploration.
3. Broader Impact: Highlight how Tartan's precision-scalable design could enable new applications or improve training efficiency, beyond inference for CNNs.
4. Comparative Analysis: Include a more comprehensive comparison with state-of-the-art accelerators like EIE, Pragmatic, and Tensor Processing Units, focusing on trade-offs in performance, energy, and area.
Questions for the Authors
1. How was the 17% energy efficiency improvement validated, and what is the margin of error in your energy estimation methodology?
2. Can you provide more details on the 3× area overhead? How does this impact scalability for larger networks or multi-chip systems?
3. Have you considered evaluating Tartan on tasks beyond image classification, such as NLP or generative models, where fully-connected layers are more dominant?
4. How does Tartan compare to accelerators like EIE that exploit sparsity and pruning? Could these techniques be combined with Tartan for further gains?
In conclusion, while Tartan introduces an interesting extension of bit-serial computation to fully-connected layers, the limited novelty, methodological concerns, and misalignment with the conference's focus lead to a recommendation for rejection. The authors are encouraged to address these issues and consider submitting to a hardware-focused venue.