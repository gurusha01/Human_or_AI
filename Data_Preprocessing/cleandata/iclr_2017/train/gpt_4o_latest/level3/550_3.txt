Review
The paper introduces a modification to the denoising auto-encoder (DAE) objective by adding an additional term that explicitly enforces the encoder to perform the majority of the denoising. This new term minimizes the distance between the encoded representations of clean and corrupted inputs, promoting robustness in the encoding phase. To avoid trivial solutions caused by this term, the authors propose techniques such as tied weights or normalized Euclidean distance. The method is evaluated on synthetic 2D toy datasets and the MNIST dataset, demonstrating qualitative improvements in representation learning, particularly in over-complete scenarios.
Decision: Reject
While the paper presents an interesting modification to the DAE objective and is well-motivated, the contribution appears to be incremental and lacks sufficient empirical rigor to justify acceptance. Below, I outline the reasons for this decision and provide constructive feedback for improvement.
---
Supporting Arguments for the Decision
1. Incremental Contribution:  
   The proposed modification is conceptually similar to existing approaches, such as contractive auto-encoders and Siamese networks, which also aim to enforce robustness in the encoder. While the authors argue that their method is more general, this claim is not sufficiently substantiated through theoretical or empirical comparisons with these related methods.
2. Limited Empirical Validation:  
   The experiments are limited in scope. The use of 2D toy datasets is helpful for qualitative insights but insufficient to demonstrate the practical utility of the method. The MNIST evaluation is shallow, with only a single-layer DAE tested and no comparisons to state-of-the-art methods. Furthermore, the results are not compelling enough to demonstrate a significant advantage over the baseline DAE.
3. Trivial Solutions and Mitigation:  
   The authors acknowledge the risk of trivial solutions (e.g., shrinking encoder weights) and propose tied weights or normalized distance as remedies. However, these solutions are not rigorously analyzed or experimentally validated, leaving open questions about their effectiveness, especially in non-linear settings.
---
Additional Feedback for Improvement
1. Expand Empirical Evaluation:  
   To strengthen the paper, the authors should evaluate their method on more challenging and diverse datasets, such as CIFAR-10 or ImageNet, and compare it against state-of-the-art models like contractive auto-encoders and variational auto-encoders. Additionally, experiments with deeper architectures and fine-tuning could provide more meaningful insights.
2. Quantitative Metrics:  
   The paper would benefit from quantitative metrics (e.g., reconstruction error, classification accuracy, or mutual information) to rigorously compare the modified DAE against baselines and related methods. The current results are largely qualitative and lack statistical significance.
3. Theoretical Analysis:  
   The theoretical justification for the proposed objective could be expanded. For example, the authors could provide a formal analysis of how the additional term affects the encoder's capacity, robustness, and generalization.
4. Clarify Practical Implications:  
   The authors should discuss the practical implications of their method, such as computational overhead introduced by the new term and its scalability to large datasets or high-dimensional inputs.
---
Questions for the Authors
1. How does the proposed method compare quantitatively to contractive auto-encoders or other robustness-enforcing methods?  
2. Can you provide more rigorous evidence that tied weights or normalized distance effectively mitigate trivial solutions in non-linear settings?  
3. Why was MNIST chosen as the primary dataset for evaluation? Do you anticipate similar benefits on more complex datasets?  
4. How does the trade-off parameter Î» affect the performance across different datasets and architectures? Is there a systematic way to tune it?
---
In conclusion, while the paper is well-motivated and presents an interesting idea, it falls short in terms of novelty and empirical validation. Addressing the above points could significantly strengthen the contribution and make it more competitive for future submissions.