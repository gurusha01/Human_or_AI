Review of the Paper
Summary of Contributions
This paper introduces a novel framework for training and testing artificial agents in information-seeking tasks, where success depends on efficiently gathering and synthesizing information from partially observable environments. The authors propose a reinforcement learning-based approach that combines intrinsic and extrinsic rewards to encourage agents to actively reduce uncertainty and exploit acquired knowledge. The paper demonstrates the versatility of the proposed method through experiments on diverse tasks, including Cluttered MNIST, BlockWorld, CelebA, and Hangman. The authors also highlight a shift in perspective from passive attention mechanisms to active information-seeking strategies, which is a meaningful conceptual contribution. The writing is clear and provides sufficient implementation details for replication.
Decision: Reject
While the paper presents an interesting and potentially impactful idea, the evaluation is insufficiently rigorous to justify acceptance. The lack of meaningful comparisons to alternative methods and human performance, combined with the simplicity of the tasks, makes it difficult to assess the significance of the proposed approach.
Supporting Arguments for the Decision
1. Strengths:
   - The paper tackles an important and underexplored problem: enabling agents to actively seek information in a principled way.
   - The technical implementation is thoughtfully designed, leveraging modern reinforcement learning techniques and deep architectures.
   - The approach is tested across a range of tasks, showcasing its generality and adaptability.
   - The writing is clear and well-organized, making the methodology easy to follow and reproduce.
2. Weaknesses:
   - Limited Evaluation Depth: The paper does not provide sufficient comparisons to existing methods, such as other attention-based models or curiosity-driven exploration approaches. While the authors compare their method to random policies and upper-bound baselines, these are not sufficient to establish the superiority of the proposed approach.
   - Task Simplicity: The tasks used for evaluation, such as Cluttered MNIST and BlockWorld, are relatively simple and may not adequately demonstrate the scalability or robustness of the method in more complex, real-world scenarios. For example, the CelebA task involves only a subset of binary attributes, and the Hangman task lacks complexity in its linguistic structure.
   - Incomplete Results: The paper does not provide benchmarks against human performance or alternative methods, leaving the significance of the results unclear. Additionally, the results for some tasks (e.g., Hangman) are not thoroughly analyzed, making it hard to draw strong conclusions.
Suggestions for Improvement
1. Expand Evaluation: Include comparisons to state-of-the-art attention mechanisms, curiosity-driven exploration methods, and other information-seeking approaches. Additionally, provide benchmarks against human performance where feasible.
2. Increase Task Complexity: Test the proposed method on more challenging and realistic tasks to better demonstrate its practical utility and scalability.
3. Provide More Results: Include additional quantitative and qualitative analyses to strengthen the empirical evaluation. For example, analyze failure cases and discuss how the method could be improved to handle them.
4. Theoretical Insights: Provide a deeper theoretical analysis of why the proposed combination of intrinsic and extrinsic rewards leads to efficient information-seeking behavior.
Questions for the Authors
1. How does the proposed method compare to existing curiosity-driven exploration techniques, such as those based on intrinsic motivation or information gain?
2. Can the method scale to more complex environments, such as 3D simulations or real-world robotics tasks? If so, what modifications would be required?
3. How sensitive is the performance to the choice of intrinsic and extrinsic reward functions? Have you explored alternative formulations?
4. Could you provide more details on how the model handles failure cases, such as when it cannot find the required information within the given budget?
In summary, while the paper introduces an interesting idea and demonstrates initial promise, the lack of rigorous evaluation and the simplicity of the tasks make it difficult to assess the significance of the contribution. Addressing the identified weaknesses would greatly strengthen the paper.