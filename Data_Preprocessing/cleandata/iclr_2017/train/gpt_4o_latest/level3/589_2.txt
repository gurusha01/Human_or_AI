Review of "Graph Convolutional Recurrent Networks (GCRN)"
Summary of Contributions
This paper introduces the Graph Convolutional Recurrent Network (GCRN), a novel extension of recurrent neural networks (RNNs) to graph-structured data. The authors propose two architectures: Model 1, which applies graph convolution to input data, and Model 2, which extends this operation to both input data and hidden states. The paper evaluates GCRN on two tasks: video prediction using the movingMNIST dataset and language modeling using the Penn Treebank dataset. The authors claim that GCRN captures spatio-temporal dependencies effectively and improves learning speed. They also highlight the potential of isotropic graph filters to outperform classical 2D filters in certain scenarios.
Decision: Reject  
The primary reasons for rejection are the incremental nature of the contribution and the weak experimental results compared to prior works. While the idea of combining graph convolution with RNNs is interesting, the paper does not convincingly demonstrate its superiority or provide sufficient evidence to justify its claims.
Supporting Arguments
1. Incremental Contribution:  
   The proposed GCRN models build upon existing frameworks like ConvLSTM and graph convolutional networks (GCNs). While the integration of these ideas is novel, it lacks significant theoretical or methodological innovation. The paper does not introduce fundamentally new techniques but rather adapts existing ones to graph-structured data.
2. Weak Experimental Results:  
   - On the movingMNIST task, GCRN Model 2 outperforms a one-layer ConvLSTM but falls short compared to state-of-the-art methods like Video Pixel Networks. This undermines the claim of strong video prediction performance.  
   - On the Penn Treebank dataset, GCRN Model 1 performs worse than the baseline LSTM reported in Zaremba et al. (2014). While dropout regularization improves results, the overall performance remains subpar.  
   - The lack of direct comparability to prior work due to differences in experimental settings further weakens the validity of the results.
3. Unsubstantiated Claims:  
   The paper claims that GCRN improves learning speed and precision, but the evidence provided is insufficient. For instance, the claim that isotropic graph filters outperform classical 2D filters is not rigorously analyzed or generalized beyond the specific datasets used.
Suggestions for Improvement
1. Stronger Baselines and Comparisons:  
   The paper should include comparisons with more competitive baselines, such as multi-layer ConvLSTMs or state-of-the-art graph-based sequence models. Experimental settings should align closely with prior work to ensure fair comparisons.
2. Broader Evaluation:  
   The evaluation is limited to two datasets, one of which (movingMNIST) is synthetic. Testing on additional real-world datasets, such as sensor networks or fMRI data, would strengthen the paper's claims about generalizability.
3. Theoretical Insights:  
   The paper would benefit from a deeper theoretical analysis of why GCRN should outperform existing methods. For example, exploring the stability properties of graph-structured RNNs or the benefits of isotropic filters in different domains could provide valuable insights.
4. Model Efficiency:  
   Model 2 suffers from high dimensionality, which negatively impacts performance. The authors should explore techniques to reduce computational overhead, such as dimensionality reduction or parameter sharing.
Questions for the Authors
1. How does the choice of graph structure (e.g., k-nearest neighbors) impact the performance of GCRN? Have alternative graph construction methods been explored?  
2. Can the authors provide more detailed ablation studies to isolate the contributions of graph convolution versus standard RNN components?  
3. How does GCRN perform on datasets with naturally dynamic graph structures, such as social networks or traffic data?  
While the paper presents an interesting direction, it requires stronger experimental validation, clearer theoretical contributions, and broader applicability to justify acceptance.