Review of the Paper
Summary of Contributions
The paper introduces Neural Equivalence Networks (EQNETs), a novel architecture designed to learn continuous semantic representations (SEMVECs) of symbolic expressions. The key innovation lies in aligning recursive neural networks with parse tree structures to embed symbolic expressions, ensuring that semantically equivalent expressions are closer in the embedding space. The authors propose a max-margin loss function for training on equivalence-class datasets and introduce a subexpression forcing mechanism to enhance compositionality. Experimental results demonstrate that EQNETs outperform state-of-the-art baselines on custom datasets of boolean and polynomial expressions. The paper also provides qualitative insights through PCA visualizations, showing meaningful transformations in the embedding space, such as negation mappings analogous to word embedding analogies.
Decision: Reject
While the paper presents an interesting and technically sound approach to embedding symbolic expressions, the problem setting appears contrived, with limited real-world applicability. Additionally, several assumptions and design choices raise concerns about generalizability and practical utility.
Supporting Arguments for Decision
1. Problem Motivation and Applicability:  
   The task of embedding symbolic expressions with known semantic equivalences is niche, and the paper does not convincingly argue for its relevance to real-world applications. For instance, practical scenarios like equation search engines often require handling variable name equivalences, which the proposed method does not address.
2. Technical Concerns:  
   - The assumption that distinct variable names refer to different entities is restrictive and undermines the utility of EQNETs in broader symbolic reasoning tasks.  
   - The undecidability of equivalence for general symbolic expressions raises questions about the canonicalization method used to generate training data. This is a critical issue, as the quality of the embeddings heavily depends on the correctness of the equivalence classes.  
   - The "COMBINE" operation deviates from true residual connections, which might have mitigated gradient explosion issues more effectively.
3. Evaluation and Presentation:  
   - While the results are promising, the datasets used are synthetic and do not reflect the complexity of real-world symbolic reasoning tasks.  
   - Table 3 contains a potential equivalence error in the tf-idf entry, which undermines confidence in the evaluation rigor.  
   - Formatting issues, such as insufficient vertical spacing in Figure 4, detract from readability.
Suggestions for Improvement
1. Broader Applicability:  
   The authors should explore more practical use cases for EQNETs, such as their integration into symbolic computation systems or theorem provers. Addressing variable name equivalences would significantly enhance the method's applicability.
2. Canonicalization and Dataset Quality:  
   Provide a detailed explanation of the canonicalization process used to generate equivalence classes. This would clarify how the undecidability of equivalence is handled in practice.
3. Residual Connections:  
   Consider adopting true residual connections in the "COMBINE" operation to address gradient-related issues more robustly.
4. Evaluation on Real-World Data:  
   Extend the evaluation to include real-world datasets or tasks, such as symbolic integration or equation simplification, to demonstrate the method's practical utility.
5. Presentation Improvements:  
   Fix formatting issues and ensure that all tables and figures are error-free and easy to interpret.
Questions for the Authors
1. How does the method handle cases where variable names are semantically equivalent but syntactically different? Could this limitation be addressed in future work?  
2. What specific steps were taken to ensure the correctness of the equivalence classes in the training data, given the undecidability of the equivalence problem?  
3. Have you considered evaluating EQNETs on tasks beyond equivalence detection, such as symbolic simplification or theorem proving?  
While the paper introduces a novel and technically interesting approach, addressing the above concerns would strengthen its contribution and relevance to the broader AI community.