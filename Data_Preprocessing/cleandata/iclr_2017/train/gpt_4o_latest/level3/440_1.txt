Review of the Paper
The paper introduces a novel model-based control method for stochastic dynamical systems using Bayesian neural networks (BNNs) and policy optimization via simulated rollouts. The authors propose the use of stochastic input variables in BNNs to capture complex statistical patterns in transition dynamics, such as multi-modality and heteroskedasticity, which are often missed by alternative modeling approaches. The BNNs are trained using α-divergence minimization with α=0.5, a method that reportedly outperforms variational Bayes in terms of accuracy and robustness. The paper demonstrates the effectiveness of the approach on challenging benchmarks, including the Wet-Chicken problem, gas turbine control, and an industrial benchmark, achieving promising results.
Decision: Accept
The decision to accept this paper is based on two key reasons. First, the paper addresses an important and challenging problem in model-based reinforcement learning by proposing a novel and well-motivated approach that extends the capabilities of BNNs to handle complex stochastic dynamics. Second, the empirical results convincingly demonstrate the practical applicability and superiority of the proposed method over existing approaches, including Gaussian processes and variational Bayes.
Supporting Arguments
1. Novelty and Practical Impact: The introduction of stochastic input variables in BNNs represents a significant advancement in modeling stochastic dynamics. The use of α-divergence minimization with α=0.5 is a thoughtful choice that balances global and local posterior approximations, leading to improved performance. The practical implications, particularly in industrial applications such as gas turbine control, are well-articulated and impactful.
2. Empirical Validation: The experiments are comprehensive, covering both synthetic benchmarks and real-world industrial scenarios. The results consistently show that the proposed method outperforms alternatives in terms of predictive accuracy, robustness, and policy performance.
3. Clarity and Rigor: The paper is well-written, with a clear explanation of the methodology and detailed experimental setups. The inclusion of Algorithm 1 and the discussion of computational complexity provide transparency and reproducibility.
Additional Feedback for Improvement
1. Clarification on Random Input \(zn\): The paper should explicitly describe how the random input \(zn\) is incorporated into the BNN (e.g., concatenation with state-action pairs or other mechanisms). This would enhance the reader's understanding of the model architecture.
2. Stochastic Input Dimensionality: The paper should discuss whether a scalar stochastic input \(z_n\) is sufficient for capturing complex dynamics and address the computational challenges associated with higher-dimensional stochastic inputs.
3. Normality Assumption: The importance of the normality assumption for \(z_n\) and the method for determining variance \(\gamma\) should be elaborated. This would provide greater insight into the robustness of the approach.
4. Role of Rectifier Layers: The paper mentions rectifier layers but does not clearly explain their role beyond mitigating the vanishing gradient problem. Additional discussion on their contribution to α-divergence optimization would be valuable.
5. Comparative Analysis: While the paper compares its approach to Gaussian processes, it would benefit from a more detailed discussion of the limitations of Gaussian process variants that support stochastic inputs (e.g., Girard et al., 2003).
6. Minor Issues: Equation (3) contains a typo where the denominator \(\mathbf{y}\) should be corrected to \(\mathbf{Y}\). Subplots in Figure 1 should include the letters referenced in the text for clarity.
Questions for the Authors
1. How does the choice of α=0.5 in α-divergence minimization affect the computational complexity and convergence properties compared to other values of α?
2. Could the authors provide more details on the availability and preprocessing of the gas turbine dataset, particularly regarding the variables \(Et\), \(Nt\), and \(A_t\)?
3. How does the proposed method scale with higher-dimensional state-action spaces, and what are the implications for real-time applications?
Overall, this paper makes a strong contribution to the field of model-based reinforcement learning and is recommended for acceptance with minor revisions.