Review of the Paper
The paper investigates the impact of dropout on neuron variance and proposes corrective measures for weight initialization and Batch Normalization (BN) to address this issue. The authors demonstrate that dropout increases the variance of neuron inputs, which can hinder training and performance. They propose a new weight initialization method that adjusts for dropout rates and nonlinearity effects, as well as a simple post-training adjustment to BN variance estimates. These methods are shown to improve convergence and achieve state-of-the-art results on CIFAR-10 and CIFAR-100 without data augmentation.
Decision: Reject
While the paper addresses an important issue and provides meaningful insights, the decision to reject is based on two primary reasons: (1) the lack of novelty in the core observation, as similar issues with dropout-induced variance have been noted in prior work, and (2) insufficient experimental validation to fully support the claims. Below, I provide detailed reasoning and suggestions for improvement.
Supporting Arguments
1. Significance but Limited Novelty: The observation that dropout increases variance and requires correction is significant but not highly novel. Prior work has discussed variance-related challenges with dropout, and the proposed solutions, while useful, are incremental rather than groundbreaking.
2. Insufficient Experimental Validation: The experiments primarily focus on networks with both dropout and BN. However, the paper does not explore the proposed variance correction in networks without BN, which would be critical to demonstrate the general applicability of the method. Additionally, comparisons with Monte Carlo dropout at test time—a standard approach for handling dropout variance—are missing, leaving a gap in the evaluation.
3. State-of-the-Art Claims: While the paper claims state-of-the-art results on CIFAR-10 and CIFAR-100, it is unclear whether these gains are solely attributable to the proposed methods or other factors (e.g., hyperparameter tuning). More rigorous ablation studies are needed to isolate the impact of the proposed techniques.
Suggestions for Improvement
1. Broader Experimental Scope: Test the proposed variance correction in networks without BN to validate its generality. Additionally, include comparisons with Monte Carlo dropout at test time to contextualize the results.
2. Ablation Studies: Conduct detailed ablation studies to disentangle the contributions of the weight initialization and BN variance re-estimation techniques.
3. Clarify Novelty: Clearly articulate how the proposed methods advance beyond existing work on dropout variance correction. Highlight any theoretical or practical contributions that distinguish this work.
4. Additional Benchmarks: Evaluate the methods on a wider range of datasets and architectures to strengthen the claims of general applicability.
Questions for the Authors
1. How does the proposed weight initialization perform in networks without Batch Normalization? Does it still provide consistent variance stabilization and performance improvements?
2. Why was Monte Carlo dropout at test time not included as a baseline for comparison? How would the proposed methods compare in terms of accuracy and computational cost?
3. Can you provide more details on the hyperparameter tuning process for the CIFAR-10 and CIFAR-100 experiments? Were the same settings used across all methods?
In summary, while the paper addresses an important problem and proposes practical solutions, the lack of novelty and insufficient experimental validation prevent it from meeting the standards for acceptance at this time. Addressing the above concerns could significantly strengthen the work.