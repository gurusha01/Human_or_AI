Review of the Paper
Summary of Contributions
This paper investigates training strategies to improve the performance of Neural GPU models, focusing on curriculum learning and model scaling. The authors claim that these strategies enable Neural GPUs to solve more complex algorithmic tasks, such as decimal arithmetic and multi-operand expressions, and generalize to longer inputs. The paper also explores the failure modes of Neural GPUs, highlighting their limitations in handling highly structured inputs and adversarial cases. The authors provide empirical results and release the source code, which is commendable for reproducibility.
Decision: Reject
While the paper is well-written and contains extensive investigations, it falls short in several critical areas. The lack of meaningful comparisons to related architectures and the limited scope of experiments on toy tasks undermine the significance of its contributions. Additionally, the absence of positive results and unclear details about key experimental setups make it difficult to assess the robustness of the proposed strategies.
Supporting Arguments for Rejection
1. Misleading Title and Scope: The title suggests architectural advancements in Neural GPUs, but the paper focuses solely on training strategies. This misrepresentation could mislead readers about the paper's contributions.
   
2. Lack of Comparisons: The paper does not compare Neural GPUs with similar architectures like Grid LSTMs, Neural Turing Machines (NTMs), or Adaptive Computation Time models. Such comparisons are essential to contextualize the improvements and assess the broader impact of the proposed strategies.
3. Limited Experiments: The experiments are restricted to toy tasks like arithmetic operations, which do not convincingly demonstrate the utility of the proposed methods in real-world or more complex algorithmic settings.
4. Unclear Results: The paper reports no significant positive results, and it remains unclear what is missing to make the model work reliably. For instance, the failure to achieve perfect generalization or address failure cases in detail weakens the paper's conclusions.
5. Missing Details: Key details, such as the use of gradient noise and the sequence lengths in experiments, are either missing or insufficiently explained. This lack of clarity hinders reproducibility and understanding.
Suggestions for Improvement
1. Clarify the Scope: The title and abstract should accurately reflect the paper's focus on training strategies rather than architectural extensions.
   
2. Expand Comparisons: Include experiments comparing Neural GPUs to related architectures like Grid LSTMs, NTMs, and others to better position the work in the literature.
3. Broaden Experiments: Test the proposed strategies on more diverse and challenging tasks to demonstrate their general applicability and utility.
4. Address Failure Cases: Provide a detailed analysis of failure modes and propose potential solutions to improve generalization, especially for highly structured inputs.
5. Improve Clarity: Ensure all experimental details, such as the use of gradient noise and hyperparameters, are clearly documented.
Questions for the Authors
1. Why were comparisons to similar architectures (e.g., Grid LSTMs, NTMs) omitted? How do the proposed strategies compare in terms of performance and generalization?
2. Could you provide more details about the sequence lengths used in the experiments and the role of gradient noise in training?
3. What are the key factors preventing the model from achieving perfect generalization? Have you explored architectural modifications to address these limitations?
In summary, while the paper provides valuable insights into training Neural GPUs, its limitations in scope, experimental rigor, and clarity prevent it from making a strong contribution to the field. Addressing these issues could significantly improve the paper's impact.