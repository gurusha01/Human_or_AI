The paper introduces two novel architectures for extractive document summarization: the Classifier and Selector models. The Classifier sequentially determines sentence membership in the summary in the original document order, while the Selector freely selects sentences in any order. Both models leverage RNN-based frameworks and explicitly model abstract features such as salience, redundancy, and content richness, achieving interpretability and competitive performance. Experimental results demonstrate that these models perform comparably to or better than state-of-the-art (SOTA) methods on the Daily Mail and DUC 2002 datasets, with the Classifier architecture generally outperforming the Selector. The paper also provides insights into the conditions under which each architecture excels, particularly emphasizing the role of document structure.
Decision: Accept
The decision to accept is based on two key reasons: (1) The paper makes a significant contribution by proposing interpretable and empirically validated summarization models that achieve SOTA performance. (2) The comparative analysis of the two architectures and the exploration of their applicability to different scenarios (e.g., structured vs. unstructured text) provide valuable insights for the research community.
Supporting Arguments:
1. Well-Motivated Approach: The paper is well-situated in the literature, addressing a gap in interpretable neural architectures for extractive summarization. The inclusion of both Classifier and Selector models offers a comprehensive exploration of different strategies.
2. Empirical Rigor: The experimental results are robust, with evaluations on both in-domain (Daily Mail) and out-of-domain (DUC 2002) datasets. The models demonstrate competitive performance, and the authors provide thoughtful explanations for observed trends, such as the impact of document structure on model performance.
3. Interpretability: The explicit modeling of abstract features and the visualization of predictions enhance the interpretability of the models, making them more accessible for practical applications.
Suggestions for Improvement:
1. Positional Importance: The necessity of the "positional importance" component in Equation (1) is unclear. The authors should conduct experiments by training on shuffled document orders and testing on original orders to isolate its impact.
2. Content-Richness Component: The role of "content-richness" may overlap with salience. Ablation studies or additional analysis could clarify its unique contribution.
3. Decoding Algorithm: The current decoding algorithm is simplistic. Exploring beam search or other advanced techniques could potentially improve performance, especially for the Selector model.
4. Consistency in Equation (3): Using the same updating equation for training and testing could enhance the consistency of the dynamic summary representation.
Questions for the Authors:
1. How does the performance of the models change when the "positional importance" and "content-richness" components are removed individually? Could these features be redundant?
2. Have you considered incorporating beam search during inference for the Selector model? If so, what were the results?
3. Can the Selector architecture be extended to multi-document summarization or other unstructured text scenarios? Are there preliminary results or insights to share?
Conclusion:
The paper presents a strong contribution to the field of extractive summarization, offering interpretable and high-performing models. While there are areas for further clarification and improvement, the overall quality and significance of the work warrant acceptance.