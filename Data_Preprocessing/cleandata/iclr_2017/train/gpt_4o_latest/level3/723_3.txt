The paper explores a novel approach to handwritten word recognition inspired by cognitive neuroscience, leveraging cortical-inspired distant bigram representations as an alternative to standard neural network-based methods. The authors propose a decoding mechanism using cosine similarity in the open-bigram space and evaluate its performance against conventional sequential character recognition models. The results demonstrate that the open-bigram approach achieves comparable performance to traditional methods, with the added advantage of robustness to misrecognitions due to the redundancy in bigram representation. This work contributes to the field by introducing a biologically motivated framework for word recognition and providing insights into the potential of open-bigram representations.
Decision: Reject
While the paper presents an interesting and biologically inspired approach, it falls short in several critical areas that prevent it from meeting the standards for acceptance. The primary reasons for rejection are the insufficient comparison with standard methods and the lack of clarity and rigor in the experimental design and reporting.
Supporting Arguments:
1. Insufficient Comparison with Baselines: The comparison between the proposed open-bigram approach and standard methods is not detailed enough. While the paper claims comparable performance, it does not provide a thorough analysis of key metrics such as word error rates, precision, and recall across all models. Additionally, the complexity of the models, including the number of parameters, is not reported, making it difficult to assess the computational trade-offs.
2. Experimental Bias and Missing Analysis: The experiments focus on longer words, using only 70% of the data, which introduces potential bias. The authors do not provide a quantitative analysis of how this choice impacts the results. Furthermore, the exclusion of language models, which are standard in word recognition tasks, limits the generalizability of the findings.
3. Clarity and Notation Issues: Several terms and notations, such as "whole language method" and "rnn_d(x,t)," are not adequately explained, making the paper difficult to follow. Additionally, the precision and recall metrics in Table 2 are not directly comparable across different orders, and the lack of visual separation adds to the confusion.
Additional Feedback:
1. The unordered use of open-bigrams is motivated by cognitive research, but the authors should conduct experiments varying the order to assess its impact on recognition performance. This would strengthen the claims about the robustness of the representation.
2. The paper contains minor spelling and grammatical errors, as well as a typo in the first author's name in the references. These issues should be addressed to improve the overall presentation.
3. Including a language model in the evaluation would provide a more realistic benchmark and help contextualize the results within the broader landscape of handwritten word recognition research.
Questions for the Authors:
1. How does the model complexity (e.g., number of parameters) of the open-bigram approach compare to the baseline methods?
2. Can you provide a quantitative analysis of the impact of focusing on longer words and excluding 30% of the data?
3. How would the inclusion of a language model affect the performance of the proposed approach?
In summary, while the paper introduces an intriguing concept, it requires significant improvements in experimental rigor, clarity, and comparison with existing methods to be considered for acceptance.