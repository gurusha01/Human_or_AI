Review of the Paper
Summary of Contributions
This paper introduces a novel framework for two-sample statistical testing using binary classification, termed Classifier Two-Sample Tests (C2ST). The authors argue that C2ST offers advantages such as multi-dimensional testing, interpretable test statistics, and the ability to identify where distributions differ. The paper provides a theoretical analysis of C2ST, including its asymptotic properties and testing power, and empirically evaluates its performance against state-of-the-art alternatives. Additionally, the paper explores applications of C2ST in evaluating generative models, such as GANs, and proposes its use for causal discovery. The authors highlight the interpretability of C2ST through predictive uncertainty and feature importance, which can provide insights into the differences between distributions.
Decision: Reject
The decision to reject is based on two primary reasons:
1. Clarity and Presentation Issues: The paper is overly dense, attempting to cover too many topics (e.g., theoretical analysis, empirical evaluations, GAN evaluation, and causal discovery) in a single submission. This lack of focus hinders readability and comprehension. Splitting the work into two papers—one focusing on the theoretical and empirical aspects of C2ST and another on its applications—would significantly improve clarity.
2. Insufficient Experimental Explanation: While the paper includes numerous experiments, the lack of detailed explanations makes it difficult to assess the validity and reproducibility of the results. Key terms such as SCF, which are central to the comparisons, are left undefined, and the experiments assume prior familiarity with referenced works.
Supporting Arguments
1. Proposed Framework: The idea of leveraging binary classification for two-sample testing is intriguing and well-motivated. The framework's ability to provide interpretable results and adapt to multi-dimensional data is a notable contribution. However, the paper does not adequately address how C2ST compares to existing methods in terms of computational efficiency, a critical factor for large-scale applications.
2. Theoretical and Empirical Analysis: The theoretical analysis is rigorous, and the empirical results demonstrate the potential of C2ST. However, the experiments lack sufficient context and explanation, making it challenging to interpret the significance of the reported results. For example, the rationale behind the choice of classifiers (e.g., neural networks and k-nearest neighbors) and their configurations is not well justified.
3. Relevance to Representation Learning: While the paper claims relevance to the representation learning community, this connection feels tenuous. The focus on two-sample testing and statistical properties may appeal more to statisticians than to researchers in representation learning.
Suggestions for Improvement
1. Clarity and Focus: Consider splitting the paper into two focused submissions. The first could concentrate on the theoretical and empirical analysis of C2ST, while the second could explore its applications in GAN evaluation and causal discovery.
2. Experimental Details: Provide more detailed explanations of the experiments, including the choice of baselines, parameter settings, and the significance of the results. Define all key terms, such as SCF, to ensure accessibility to a broader audience.
3. Relevance to Representation Learning: Strengthen the connection to representation learning by explicitly discussing how C2ST can be integrated into representation learning workflows or how it advances the field.
Questions for the Authors
1. How does the computational efficiency of C2ST compare to kernel-based methods like MMD and ME, especially for large-scale datasets?
2. Could you clarify the definition and role of SCF in the experiments? Why was it chosen as a baseline?
3. How does the choice of classifier (e.g., neural networks vs. k-nearest neighbors) impact the performance of C2ST? Are there guidelines for selecting the most appropriate classifier for a given dataset?
4. In the context of GAN evaluation, how does C2ST handle mode collapse or other common GAN issues?
This paper presents a promising framework, but its current form lacks the focus and clarity needed for acceptance. Addressing the above concerns would greatly enhance its impact and accessibility.