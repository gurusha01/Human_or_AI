Review of the Paper
Summary of Contributions
The paper explores the feasibility of learning a static analyzer for a toy programming language using deep learning methods. The specific task is to determine whether all variables in a program are defined before use. The authors evaluate several approaches, including sequence classification models like LSTMs, and propose a novel "differentiable set" model to track defined variables. The results are promising, with the differentiable set model achieving 99.3% accuracy under sequence-level supervision and 99.7% under token-level supervision. Additionally, the authors train an LSTM language model to identify low-probability tokens as potential error sources, demonstrating the potential for providing useful error messages. The paper positions itself as a foundational step in applying deep learning to program analysis, bypassing traditional feature engineering.
Decision: Reject
While the paper introduces an interesting idea and demonstrates promising results, it is not yet ready for acceptance. The primary reasons for this decision are the overly simplistic experimental setup and the limited exploration of real-world applicability. The toy language and task lack the complexity of real-world programming scenarios, which limits the broader impact and relevance of the work. Furthermore, the paper does not adequately address whether the task requires deep reasoning or simpler heuristics, leaving open questions about the novelty and necessity of the proposed methods.
Supporting Arguments
1. Strengths:
   - The concept of learning a static analyzer from data is innovative and could inspire future research.
   - The differentiable set model is a simple yet effective tool for tracking defined variables, achieving near-perfect accuracy.
   - The use of a language model to provide error localization is a practical addition that enhances the utility of the approach.
2. Weaknesses:
   - The toy language and task are overly simplistic, lacking features like functions, memory, or modularity that are essential in real-world programming.
   - The paper does not convincingly demonstrate whether the task requires complex reasoning or can be solved with simpler methods, such as analyzing variable usage order.
   - The broader implications of the work are unclear, as the authors do not explore how their approach might scale to more complex languages or tasks.
Suggestions for Improvement
1. Expand the Scope: Extend the experiments to more realistic programming languages or tasks to demonstrate the practical applicability of the approach.
2. Clarify Reasoning Complexity: Provide a detailed analysis of whether the task requires deep reasoning or simpler checks. This would help clarify the novelty of the proposed methods.
3. Address Limitations: Discuss the challenges of scaling the approach to real-world scenarios, such as handling diverse variable names, memory management, or modular code.
4. Broader Context: Situate the work more clearly within the existing literature on program analysis and machine learning, highlighting how it advances the state of the art.
Questions for the Authors
1. How does the proposed method handle more complex code structures, such as nested loops or functions, which are common in real-world programming?
2. Could simpler rule-based methods or heuristics achieve similar performance on the given task? If not, why?
3. What are the main challenges in extending the differentiable set model to handle larger and more complex programming languages?
In conclusion, while the paper presents a promising direction, it requires significant refinement and expansion to address its current limitations and demonstrate broader applicability.