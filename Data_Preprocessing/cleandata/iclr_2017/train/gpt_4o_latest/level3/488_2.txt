Review of the Paper
Summary of Contributions
This paper extends adversarial and virtual adversarial training to text classification tasks using LSTM-based models. The authors propose applying perturbations to continuous word embeddings rather than discrete one-hot inputs, addressing the challenge of sparse, high-dimensional text data. The method demonstrates state-of-the-art performance on multiple benchmark datasets for both supervised and semi-supervised tasks. Additionally, the paper provides qualitative insights into the improved robustness of the learned embeddings and reduced overfitting. The work is significant as it adapts adversarial training, a well-established technique in image domains, to the text domain, showcasing its potential for broader applications.
Decision: Accept
The paper is well-written, addresses a meaningful problem, and demonstrates strong empirical results. The extension of adversarial training to text tasks is both novel and impactful, making it a valuable contribution to the field. The authors provide rigorous experimental evidence and clear explanations of their methodology, making the claims credible and scientifically sound.
Supporting Arguments
1. Problem Significance: The adaptation of adversarial and virtual adversarial training to text tasks is a non-trivial contribution. While adversarial training has been extensively explored in image domains, its application to text introduces unique challenges due to the discrete nature of text data. The authors' approach of perturbing word embeddings is a clever and practical solution that advances the state of the art in text classification.
   
2. Empirical Rigor: The paper demonstrates state-of-the-art performance across multiple datasets, including IMDB, Elec, RCV1, Rotten Tomatoes, and DBpedia. The results are consistent and robust, with clear comparisons to baseline and competing methods. The inclusion of qualitative analyses, such as improved word embedding quality, further strengthens the claims.
3. Clarity and Accessibility: The paper is well-structured and easy to follow. The authors provide sufficient background on adversarial training and virtual adversarial training, making the work accessible to a broad audience. The experimental setup and hyperparameters are detailed, ensuring reproducibility.
Suggestions for Improvement
1. Exploration of Simpler RNN Models: While the focus on LSTMs is justified, it would be insightful to explore the impact of adversarial training on simpler RNN architectures, such as vanilla RNNs or GRUs. This could help generalize the findings and assess the broader applicability of the method.
2. Analysis of Failure Cases: The paper briefly mentions that virtual adversarial training underperforms on the Rotten Tomatoes dataset due to the short length of labeled sentences. A deeper analysis of such failure cases could provide valuable insights into the limitations of the approach and guide future work.
3. Broader Applications: While the paper suggests potential applications in tasks like machine translation and question answering, no experiments are conducted in these areas. Including preliminary results or a discussion on how the method could be adapted to these tasks would strengthen the paper's impact.
Questions for the Authors
1. How does the proposed method scale with larger vocabularies or datasets with significantly longer sequences? Are there computational trade-offs compared to traditional adversarial training in image domains?
2. Could the authors elaborate on the choice of hyperparameters, particularly the norm constraint for adversarial perturbations? How sensitive are the results to this parameter?
3. Is there any evidence that the proposed method improves robustness to real-world adversarial attacks in text classification, or is the focus solely on regularization?
In conclusion, this paper makes a meaningful contribution by extending adversarial training to text tasks, achieving state-of-the-art results, and providing valuable insights into the method's effectiveness. While there are areas for further exploration, the work is well-executed and worthy of publication.