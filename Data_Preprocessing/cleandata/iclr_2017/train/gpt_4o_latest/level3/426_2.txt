Review of the Paper: Offline Bilingual Word Representation Learning
Summary of Contributions
This paper addresses the problem of offline bilingual word representation learning by aligning pre-trained monolingual embeddings without relying on direct word-to-word alignments. The authors unify existing approaches and provide theoretical justifications for the use of orthogonal transformations in this context. Key contributions include:
1. A theoretical framework proving that the optimal linear transformation between vector spaces should be orthogonal, derived using singular value decomposition (SVD).
2. Introduction of the "inverted softmax" to mitigate the hubness problem, improving translation precision.
3. Leveraging cognate words (identical character strings) to construct pseudo-dictionaries for languages with similar scripts, achieving competitive results without expert bilingual knowledge.
4. Extending the method to sentence-level tasks, demonstrating high precision in retrieving sentence translations from large corpora.
The paper demonstrates significant improvements over existing methods, such as Mikolov et al. (2013a) and Dinu et al. (2014), achieving state-of-the-art results in multiple experimental setups.
Decision: Accept
The paper is well-motivated, theoretically grounded, and empirically validated. Its contributions are significant, particularly in unifying existing methods and demonstrating the robustness of orthogonal transformations in low-resource scenarios. The proposed inverted softmax and sentence-level extensions further enhance its practical utility. However, minor clarifications and additional experiments are recommended to strengthen the presentation.
Supporting Arguments for Acceptance
1. Theoretical Rigor: The paper provides a solid theoretical foundation for offline bilingual word representation learning, proving the necessity of orthogonal transformations. This unification of prior work is a valuable contribution to the field.
2. Empirical Results: The proposed methods achieve substantial gains in translation precision, particularly in challenging scenarios such as using pseudo-dictionaries or sentence-level tasks. The results convincingly support the claims made in the paper.
3. Practical Impact: The ability to construct bilingual embeddings without expert bilingual signals or aligned corpora is highly impactful, especially for low-resource languages.
Suggestions for Improvement
1. Clarify Table 3 Header: The "word frequency" header in Table 3 is misleading. It would be helpful to explicitly state that the rows correspond to bins of word frequencies (e.g., "5k-20k most common words").
2. Include Precision @5 and @10 Results: For Table 6, precision @5 and @10 results should be included in the appendix to provide a more comprehensive evaluation of the retrieval performance.
3. Differentiate Rows in Table 6: The distinction between rows 3 and 4 in Table 6 (nearest neighbor vs. inverted softmax) should be clarified, particularly regarding why the inverted softmax underperforms in certain cases.
4. Combine Expert and Cognate Dictionaries: An additional experiment combining expert dictionaries and cognate-based pseudo-dictionaries would provide insights into their combined effectiveness and practical applicability.
5. Sentence Vector Quality: While the use of simple sentence vectors is effective, exploring more sophisticated sentence embeddings (e.g., using neural models) could further validate the robustness of the proposed method.
Questions for the Authors
1. Could you elaborate on why the inverted softmax underperforms for sentence retrieval in certain cases (e.g., Italian to English in Table 6)?
2. How does the method scale to language pairs with fewer cognates or more divergent scripts? Have you considered experiments on such language pairs?
3. Would combining expert dictionaries and pseudo-dictionaries improve performance, or do they provide redundant signals?
Overall, this paper makes a significant contribution to offline bilingual word representation learning and is recommended for acceptance after addressing the above clarifications and suggestions.