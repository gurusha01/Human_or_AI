Review
Summary of Contributions
This paper proposes a novel approach to two-sample testing by leveraging binary classifiers, termed Classifier Two-Sample Tests (C2ST). The authors argue that training a binary classifier to distinguish between two samples and using its test accuracy as a test statistic provides an effective and interpretable method for identifying distributional differences. The paper makes several contributions: (1) a theoretical analysis of the asymptotic properties and power of C2ST, (2) empirical validation across diverse tasks such as toy problems, GAN evaluation, and causal discovery, and (3) interpretability mechanisms through classifier features and predictive uncertainty. The work highlights the advantages of C2ST, including its simplicity, scalability, and ability to learn representations on the fly, while also showcasing its potential for applications in generative model evaluation and causal inference.
Decision: Accept
The paper presents a compelling case for using binary classifiers in two-sample testing, supported by both theoretical insights and strong empirical results. The contributions are significant, well-motivated, and likely to inspire further research in statistical testing, generative model evaluation, and causal discovery. However, the paper has a critical theoretical flaw that needs to be addressed before publication.
Supporting Arguments
1. Novelty and Significance: The idea of using binary classifiers for two-sample testing is relatively underexplored, and the proposed C2ST framework bridges statistical testing and representation learning in a novel way. The paper's focus on leveraging modern deep learning methods for interpretable and scalable testing is timely and impactful.
2. Theoretical Contributions: The asymptotic analysis of test power (Theorem 1) provides a solid foundation for understanding the behavior of C2ST. While the proof has issues (discussed below), the overall theoretical framework is valuable.
3. Empirical Validation: The experiments convincingly demonstrate the effectiveness of C2ST across various tasks. The results show that C2ST outperforms state-of-the-art alternatives in many scenarios, particularly in high-dimensional and complex data settings.
4. Interpretability: The interpretability of C2ST through classifier features and predictive uncertainty is a unique and practical contribution, making the method more accessible for real-world applications.
Major Concern and Suggested Fix
The key theoretical issue lies in the assumptions of Theorem 1. The authors incorrectly assume a Binomial distribution under the alternative hypothesis (H1), despite the terms being independent but not identically distributed. This undermines the validity of the power analysis. To address this, the authors should replace the Binomial assumption with a Poisson binomial distribution and use a variant of the central limit theorem to derive asymptotic normality. Importantly, the Binomial assumption is unnecessary for the proof, and the suggested fix would strengthen the theoretical rigor without altering the main results.
Additional Feedback for Improvement
1. Clarity on Theoretical Assumptions: Clearly state the assumptions underlying Theorem 1 and provide a detailed discussion of their implications. This will help readers better understand the limitations and applicability of the theoretical results.
2. Broader Comparison: While the empirical results are strong, additional comparisons with other interpretable two-sample tests (e.g., kernel-based methods with feature importance) would further contextualize the contributions.
3. Practical Guidelines: Provide more practical guidance on choosing classifiers and hyperparameters for C2ST, especially in high-dimensional settings. For instance, how does the choice of neural network architecture affect test power and interpretability?
4. Limitations: Discuss the limitations of C2ST more explicitly, such as potential overfitting in small-sample settings or sensitivity to classifier choice.
Questions for the Authors
1. How does the performance of C2ST vary with different types of classifiers (e.g., decision trees, SVMs) beyond neural networks and k-NN? Are there cases where simpler classifiers outperform neural networks?
2. Can the authors provide more details on the computational efficiency of C2ST compared to kernel-based methods, especially for large datasets?
3. How robust is C2ST to imbalanced sample sizes between the two distributions? Would additional preprocessing steps be required in such cases?
In summary, while the paper has a critical theoretical flaw, the proposed method is innovative, well-validated, and has significant potential for impact. Addressing the theoretical issue and incorporating the suggested improvements would make this work a strong contribution to the field.