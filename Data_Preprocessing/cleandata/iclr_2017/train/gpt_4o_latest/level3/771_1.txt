The paper proposes a novel method for addressing the polysemy problem in word embeddings by introducing "fuzzy paraphrases" that assign reliability scores to paraphrases and selectively use them during training. This approach aims to improve word vector quality while maintaining a single vector per word, avoiding the need for word sense disambiguation. The authors claim their method outperforms prior works and simpler baselines, particularly in medium and large corpora. The paper also explores parameter effects and compares its results to prior methods.
Decision: Reject
Key Reasons:
1. Weak Experimental Evidence: The experimental results fail to demonstrate significant improvements over simpler baselines, particularly in key tasks like analogy, where CBOW outperforms the proposed embeddings in semantic tasks. The omission of the "Enriched CBOW" model in the analogy task further weakens the evaluation.
2. Insufficient Model Justification: The paper does not adequately justify its model formulation or explore alternative approaches, leaving questions about the robustness and generalizability of the method.
Supporting Arguments:
While the proposed method is conceptually interesting and addresses a practical issue (polysemy) in word embeddings, its experimental validation is underwhelming. The results are inconclusive, with the proposed method showing inconsistent performance across benchmarks. For example, while it marginally outperforms in some cases, it underperforms in others, such as analogy tasks. Additionally, the claim of being the first to combine lexica and corpora for embeddings is misleading, as prior work exists in this area. The lack of exploration of alternative approaches or ablation studies further limits the paper's contribution.
The paper also suffers from presentation issues. The unconventional sentence structures and unclear table labels make it difficult to follow, and the language requires significant revision by a native English speaker. These issues detract from the clarity and impact of the work.
Suggestions for Improvement:
1. Experimental Evaluation: Include the "Enriched CBOW" model in all relevant tasks and provide a more comprehensive comparison with simpler baselines. Highlight statistically significant improvements, if any.
2. Model Justification: Provide a stronger theoretical or empirical rationale for the proposed method. Explore alternative formulations or ablation studies to validate the design choices.
3. Language and Presentation: Revise the paper for clarity and grammatical correctness. Ensure table labels are descriptive and self-explanatory.
4. Related Work: Correct the misrepresentation of prior work and better situate the proposed method within the existing literature.
Questions for the Authors:
1. Why was the "Enriched CBOW" model excluded from the analogy task evaluation? How does your method compare to it in this task?
2. Can you provide more detailed justification for the choice of the fuzzy paraphrase approach over other alternatives?
3. How does the proposed method perform on tasks beyond word similarity and analogy, such as downstream NLP tasks (e.g., text classification or machine translation)?
4. Have you considered the computational overhead introduced by the fuzzy paraphrase mechanism, and how does it compare to simpler methods?
In summary, while the paper introduces an interesting idea, it lacks sufficient experimental validation and theoretical grounding to warrant acceptance in its current form. I encourage the authors to address these issues and resubmit after significant revisions.