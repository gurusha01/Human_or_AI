Review
Summary of Contributions
The paper proposes a novel approach called Differentiable Canonical Correlation Analysis (DCCA), which extends traditional CCA by making it fully differentiable and integrating it as a layer within multi-view neural networks. Unlike Deep CCA, this formulation allows for gradient flow through the computation of CCA projection matrices, enabling optimization of task-specific objectives (e.g., cosine distance) alongside the CCA objective. The authors demonstrate the utility of this approach in cross-modality retrieval tasks on two public datasets (Flickr30k and IAPR TC-12), showing improvements over Deep CCA and freely-learned projection layers. The paper claims that Differentiable CCA could serve as a versatile building block for multi-modality tasks.
Decision: Reject
The paper introduces a promising idea, but the execution and presentation suffer from significant flaws. The unclear objective formulation, misuse of terminology, and insufficient empirical rigor undermine the paper's contributions.
Supporting Arguments for Decision
1. Unclear Objective Formulation: The paper fails to clearly articulate whether the proposed approach involves summing or interpolating the CCA and downstream objectives. This ambiguity makes it difficult to assess the theoretical soundness of the method.
   
2. Questionable Use of Cosine Distance: The choice of cosine distance as the top-layer objective is problematic. Without the CCA layer, cosine distance could fail to provide meaningful gradients, and the paper does not compare this choice to standard contrastive losses (e.g., Hermann & Blunsom), which are widely used in similar tasks.
3. Terminology Issues: The paper uses terms like "correlation" and "cross-correlation" loosely, without aligning them with their standard definitions. This lack of precision creates confusion and detracts from the scientific rigor of the work.
4. Unsubstantiated Claims: The claim that the approach is "fully differentiable" compared to regular CCA is not adequately clarified. Additionally, the relationship between cosine distance and correlation is misrepresented, as the claim does not align with how CCA treats vector dimensions.
5. Empirical Concerns: While the experimental results show some improvement, the paper does not provide sufficient comparisons to alternative methods or baselines. For example, it omits comparisons to contrastive learning approaches, which are relevant to cross-modality retrieval.
6. Presentation Issues: The paper contains minor typos (e.g., "prosed" instead of "proposed" and "allong" instead of "along"), which reflect a lack of attention to detail. These issues, while minor, further detract from the overall quality of the submission.
Additional Feedback for Improvement
1. Clarify Objective Formulation: The authors should explicitly define how the CCA and downstream objectives are combined (e.g., summation, interpolation, or another mechanism). A mathematical formulation would make this clearer.
2. Compare to Contrastive Losses: The paper should include comparisons to contrastive losses, such as those proposed by Hermann & Blunsom, to contextualize the benefits of the proposed approach.
3. Define Terminology: Terms like "correlation" and "cross-correlation" should be defined explicitly and used consistently throughout the paper.
4. Strengthen Empirical Validation: The authors should include more rigorous experiments, such as ablation studies and comparisons to state-of-the-art methods in cross-modality retrieval.
5. Improve Writing Quality: Address typographical errors and ensure that the writing is clear, precise, and professional.
Questions for the Authors
1. How exactly are the CCA and downstream objectives combined in the optimization process? Is it a weighted sum, interpolation, or another mechanism?
2. Why was cosine distance chosen as the top-layer objective, and how does it compare to contrastive losses in terms of performance and gradient stability?
3. Can you provide more details on how the claim of "full differentiability" is justified compared to regular CCA?
4. How does the proposed method perform when compared to contrastive learning approaches for cross-modality retrieval?
While the idea of Differentiable CCA is promising, the paper requires substantial revisions to clarify its contributions, address methodological concerns, and improve its empirical rigor.