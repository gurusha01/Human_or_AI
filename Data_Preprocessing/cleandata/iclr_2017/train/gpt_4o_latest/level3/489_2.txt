Review of the Paper
Summary of Contributions
This paper presents a novel framework for evaluating unsupervised sentence embedding models by analyzing their ability to encode three fundamental sentence properties: length, word content, and word order. The authors compare two prominent sentence embedding methods—Continuous Bag-of-Words (CBOW) and an Encoder-Decoder (ED) model with an LSTM encoder—while also offering limited insights into skip-thought vectors. The study reveals several counterintuitive findings, such as the surprising effectiveness of CBOW in encoding sentence length and word order, despite its lack of explicit sequence modeling. Additionally, the authors highlight the limitations of high-dimensional embeddings for word content tasks and provide evidence that BLEU scores are suboptimal indicators of encoder quality. The work contributes valuable insights into the inner workings of sentence embeddings and proposes a methodology that can be extended to other embedding models.
Decision: Accept
The paper is recommended for acceptance due to its novel methodology, actionable insights into sentence embeddings, and rigorous empirical evaluation. The findings are significant for the NLP community, as they challenge assumptions about simple models like CBOW and provide a framework for fine-grained analysis of embeddings. However, the discussion on word order experiments could be improved, and some aspects of the analysis warrant further exploration.
Supporting Arguments
1. Novelty and Relevance: The paper addresses a critical gap in the literature by moving beyond coarse-grained evaluations of sentence embeddings on downstream tasks. The proposed auxiliary prediction tasks offer a fine-grained understanding of what information is captured by embeddings, making the methodology broadly applicable.
   
2. Counterintuitive Findings: The discovery that CBOW encodes non-trivial information about sentence length and word order is both surprising and impactful. This challenges the assumption that CBOW, being permutation-invariant, cannot capture sequence-level properties.
3. Scientific Rigor: The experiments are well-designed, with balanced datasets and appropriate baselines. The authors also control for natural language statistics, ensuring that their findings are robust and generalizable.
4. Actionable Insights: The paper provides practical recommendations, such as the optimal dimensionality for different tasks and the limitations of BLEU scores for evaluating encoder quality. These insights are valuable for both researchers and practitioners.
Suggestions for Improvement
1. Word Order Analysis: The discussion on word order experiments is underdeveloped. The authors should explicitly address how natural language statistics influence the results and provide a deeper analysis of why CBOW performs well on this task.
2. Decoder Handicapping: The drop in word content accuracy for high-dimensional embeddings is intriguing. The authors should explore this further by handicapping the decoder, as suggested, to isolate the encoder's contribution.
3. Skip-Thought Vectors: While the inclusion of skip-thought vectors is appreciated, the comparison is limited due to differences in training corpus and embedding size. A more controlled comparison would strengthen the analysis.
4. Generalization: The authors acknowledge the limitations of their methodology in capturing higher-level syntactic and semantic properties. Future work could extend the framework to include tasks that measure these aspects.
Questions for the Authors
1. Can you provide more details on why CBOW embeddings degrade in word content accuracy at higher dimensions? Is this phenomenon observed across other datasets or tasks?
2. How do you envision extending your framework to evaluate higher-level properties, such as syntactic structure or semantic similarity?
3. Could you elaborate on the potential reasons why the LSTM encoder does not leverage natural language ordering statistics when encoding novel sentences?
4. Have you considered evaluating the proposed framework on additional sentence embedding models, such as transformers or contrastive learning-based methods?
In conclusion, this paper makes a significant contribution to understanding sentence embeddings and proposes a methodology with broad applicability. While there are areas for improvement, the strengths of the work far outweigh its limitations, making it a valuable addition to the conference.