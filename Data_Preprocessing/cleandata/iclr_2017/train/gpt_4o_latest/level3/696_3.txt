Review of the Paper
The paper investigates the role of entity markers in machine reading comprehension (MR) and presents experiments demonstrating their effectiveness in improving performance on the Who-Did-What (WDW) dataset using the Stanford Reader. The authors introduce the concept of "predication structure" to explain the logical decomposition of hidden state vectors in neural readers and propose that entity markers enhance reference resolution in MR models. The paper also explores linguistic features and pointer annotations as additional inputs to improve performance, achieving state-of-the-art results on the WDW dataset. These contributions are intriguing and highlight the potential of integrating linguistic insights into neural architectures for reading comprehension.
Decision: Reject
Key reasons for rejection:
1. The paper lacks clarity in its organization and overall message, making it difficult to follow the argument and fully understand the contributions.
2. The concept of "structures" (e.g., "predication structure") is not well-defined, leading to confusion in critical sections, particularly Section 4.
3. The paper does not provide a clear take-home message regarding the broader implications of entity markers and their integration with linguistic features in MR models.
Supporting Arguments
While the experimental results are promising, the paper suffers from significant issues in presentation and conceptual clarity. The introduction of "predication structure" is central to the paper, yet it is not adequately explained or rigorously justified. The lack of clear definitions and examples leaves the reader struggling to grasp the core ideas. Furthermore, the organization of the paper is disjointed, with key contributions buried in dense technical discussions. For instance, the relationship between aggregation readers and explicit reference readers is only partially explored, and the implications of this relationship are not clearly articulated. Additionally, while the experiments demonstrate the utility of entity markers, the paper does not sufficiently discuss how these findings could generalize to other MR tasks or datasets.
Suggestions for Improvement
1. Improve Conceptual Clarity: Clearly define "predication structure" and other key terms. Use concrete examples to illustrate the concepts and their relevance to MR models.
2. Reorganize the Paper: Streamline the presentation to ensure that the main contributions and findings are highlighted early and revisited throughout the paper.
3. Provide a Clear Take-Home Message: Summarize the broader implications of the findings, particularly regarding the integration of linguistic features and entity markers in MR models.
4. Address Generalizability: Discuss how the proposed methods and findings could be applied to other datasets or tasks beyond WDW.
5. Clarify Section 4: This section is critical but difficult to follow. Consider breaking it into smaller subsections with clear headings and explanations.
Questions for the Authors
1. Can you provide a more detailed explanation of "predication structure" and its empirical validation? How does it relate to the broader goals of MR?
2. How do the findings on entity markers generalize to non-cloze-style datasets or other MR tasks?
3. Could you elaborate on the practical implications of your results for designing future MR models? For example, how might entity markers be integrated into state-of-the-art architectures like transformers?
4. How do the proposed linguistic features compare to other methods for improving MR performance, such as pretraining on large-scale language models?
In summary, while the paper presents interesting findings, significant improvements in clarity, organization, and conceptual rigor are needed for it to be suitable for publication.