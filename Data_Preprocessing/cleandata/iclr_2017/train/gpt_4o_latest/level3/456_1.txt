Review
Summary of Contributions
This paper introduces a novel regularization method, Central Moment Discrepancy (CMD), for learning domain-invariant representations in unsupervised domain adaptation. CMD explicitly matches higher-order central moments of hidden activations across domains, providing a computationally efficient alternative to existing methods like Maximum Mean Discrepancy (MMD). The authors prove that CMD is a metric and demonstrate that convergence in CMD implies convergence in distribution. Empirical results on the Amazon reviews and Office datasets show that CMD achieves state-of-the-art performance on most tasks, outperforming MMD, Variational Fair Autoencoders (VFAE), and Domain-Adversarial Neural Networks (DANN). The method is shown to be robust to hyperparameter changes, eliminating the need for extensive tuning.
Decision: Reject
While the paper presents an interesting and computationally efficient approach to domain adaptation, several critical issues undermine its overall contribution. Specifically, the assumptions about independently distributed hidden activations and the unclear empirical support for performance improvements raise concerns about the validity and generalizability of the proposed method.
Supporting Arguments
1. Strengths:
   - The theoretical contributions are solid, with proofs establishing CMD as a metric and its implications for convergence in distribution.
   - CMD's computational efficiency compared to MMD is a notable advantage, especially for large datasets.
   - The method achieves competitive or superior performance on benchmark datasets, demonstrating its practical utility.
2. Weaknesses:
   - Assumption of Independent Activations: The method assumes that hidden activations are independently distributed, which is unrealistic for convolutional layers commonly used in deep learning. This limits the applicability of CMD to broader architectures.
   - Empirical Results: The performance gains reported in Table 2 for the Office dataset appear to be driven by a single class (mouse), as suggested by Figure 3. This undermines the claim of consistent improvements across tasks.
   - Adaptation Starting Point: The authors begin adaptation from dense layers for the image dataset, but the rationale for not starting from lower convolutional layers is unclear. This raises questions about whether CMD can effectively handle domain shifts in earlier feature representations.
Suggestions for Improvement
1. Clarify Assumptions: Address the assumption of independent activations and discuss its implications for convolutional architectures. Consider extending CMD to handle dependencies between activations.
2. Empirical Validation: Provide more detailed analysis to demonstrate that performance improvements are consistent across all classes and tasks, rather than being driven by specific cases.
3. Adaptation Strategy: Justify the choice of starting adaptation from dense layers and explore the feasibility of applying CMD to earlier layers.
4. Visualization: Improve the clarity of Figure 3 to better support the claims made in the text. Highlight the contributions of CMD to class-wise performance improvements.
Questions for Authors
1. How does CMD perform when applied to convolutional layers, where activations are typically not independent? Have you tested CMD on architectures with multiple convolutional layers?
2. Can you provide a more detailed breakdown of class-wise performance for the Office dataset to validate the claim of consistent improvements?
3. Why did you choose to start adaptation from dense layers for the image dataset? Would CMD be effective if applied to earlier layers, and if not, why?
While the paper has potential, addressing these issues is critical to ensure the robustness and generalizability of the proposed method.