Review
Summary of Contributions
This paper introduces a novel approach to learning compact binary representations by dynamically selecting a sparse subset of reliable experts for each variable, rather than relying on traditional opinion pooling methods like the logarithmic opinion pool. The proposed "dynamic partition model" assigns responsibility for individual variables to a single expert, which is dynamically determined based on the latent configuration. The authors present an "EM-like" algorithm for training the model, which alternates between inference and updating expert parameters. The paper demonstrates the model's ability to achieve accurate reconstructions of high-dimensional data with a small number of experts, supported by experiments on synthetic datasets, MNIST digits, Weizmann horses, and Caltech motorcycles. The authors also provide comparisons with other models, such as products of experts, sparse dictionaries, and autoencoders, highlighting the advantages of their approach.
Decision: Reject
The decision to reject this paper is based on two primary concerns: (1) the lack of clarity in the presentation of the model and algorithm, and (2) insufficient theoretical and empirical support for the claims made.
Supporting Arguments
1. Lack of Clarity in Model Definition: The paper does not provide a clear and formal definition of the joint model \( p(x, z) \). While the dynamic partitioning concept is intriguing, the mathematical formulation is fragmented and difficult to follow. For instance, the role of the latent variables \( h \) and their relationship with the joint probability is not adequately explained, leaving the reader uncertain about the overall structure of the model.
2. Unclear Objective Function in the Algorithm: The proposed "EM-like" algorithm lacks a well-defined objective function that guarantees improvement on the training data. While the authors describe updates for expert parameters and levels of expertise, there is no rigorous proof or empirical evidence that the algorithm converges to a meaningful solution or improves the likelihood consistently.
3. Similarity to Existing Work: The dynamic partitioning approach bears a strong resemblance to Hinton's "product of experts" and related models. While the authors argue for the advantages of their method, the novelty is somewhat diminished by the lack of a clear distinction from prior work. The comparisons with products of experts and other baselines are not sufficiently rigorous to establish the superiority of the proposed method.
4. Experimental Results: While the experiments demonstrate the model's ability to reconstruct data, the results are not compelling enough to justify the claims. For instance, the reconstructions for high-dimensional datasets like Weizmann horses and Caltech motorcycles are visually suboptimal, and quantitative metrics are not provided to compare performance rigorously.
Suggestions for Improvement
1. Provide a clear and formal definition of the joint model \( p(x, z) \), including the role of latent variables and how they interact with the data.
2. Clearly define the objective function for the proposed algorithm and provide theoretical guarantees or empirical evidence for its convergence and effectiveness.
3. Strengthen the experimental evaluation by including quantitative metrics (e.g., reconstruction error, likelihood) and comparing against a broader set of baselines.
4. Clarify the novelty of the approach relative to existing work, particularly Hinton's "product of experts" and related models. Highlight specific differences and advantages.
5. Improve the clarity and organization of the paper, particularly in the sections on inference and learning. The current presentation is dense and difficult to follow.
Questions for the Authors
1. Can you provide a formal definition of the joint model \( p(x, z) \) and explain how the latent variables \( h \) are integrated into the model?
2. What is the objective function for the "EM-like" algorithm, and how do you ensure that it improves the likelihood or another performance metric during training?
3. How does your approach differ fundamentally from Hinton's "product of experts"? Can you provide a theoretical or empirical comparison to highlight these differences?
4. Can you include quantitative performance metrics for the experiments, such as reconstruction error or likelihood, to support your claims more rigorously?
This review aims to provide constructive feedback to help the authors improve their work. While the paper introduces an interesting idea, significant revisions are needed to clarify the contributions and strengthen the theoretical and empirical support.