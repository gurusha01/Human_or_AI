Review of the Paper
Summary of Contributions
The paper introduces a novel multiview learning method aimed at maximizing cross-view similarity between neighborhoods of data samples. Unlike traditional Canonical Correlation Analysis (CCA), which focuses on maximizing coordinate correlations, the proposed approach directly optimizes for neighborhood relationships, making it particularly suited for information retrieval tasks. The method is linear but can detect nonlinear and local dependencies due to its focus on relationships rather than individual data coordinates. The authors demonstrate the method's effectiveness through experiments on synthetic and real-world datasets, showing improved performance in preserving cross-view neighborhood similarities. The paper also highlights the method's invariance properties and its extensibility to nonlinear transformations in future work.
Decision: Reject
While the paper proposes an interesting and potentially impactful approach, it suffers from significant clarity and methodological issues that undermine its contribution. The key reasons for this decision are:
1. Lack of Clarity on Computational Tractability: The paper does not adequately address the practical optimization challenges or the method's scalability, especially compared to CCA, which is computationally efficient and solvable exactly despite its nonconvex nature.
2. Overly Complex Synthetic Data Experiments: The synthetic data generation process is unnecessarily convoluted, making it difficult to assess the method's effectiveness. Simpler benchmarks would better illustrate the method's strengths.
Supporting Arguments
1. Optimization Challenges: While the authors report the computational cost of evaluating the objective function, they do not discuss the practical difficulty of optimizing it. The reliance on L-BFGS with penalties and multiple rounds suggests potential sensitivity to initialization and local optima, but this is not explored in depth. Furthermore, the time complexity analysis is limited to a naive implementation, with no empirical evidence of scalability provided.
2. Comparison to CCA: The paper positions the method as an alternative to CCA but does not convincingly argue its tractability. CCA is known for its computational efficiency, and the proposed method's advantages in handling nonlinear and local dependencies are not sufficiently quantified or contextualized.
3. Synthetic Data Issues: The rationale for the complex synthetic data generation process is unclear, and it detracts from the paper's focus. Simpler, more interpretable synthetic benchmarks could better demonstrate the method's ability to recover true subspaces and highlight its advantages over alternatives.
Suggestions for Improvement
1. Clarify Optimization and Scalability: Provide a detailed discussion of the optimization challenges, including sensitivity to initialization, convergence behavior, and dependence on problem dimensions. Empirical results on runtime and scalability would strengthen the paper.
2. Simplify Synthetic Data Experiments: Use simpler synthetic datasets to clearly demonstrate the method's ability to recover true subspaces. This would make the results more interpretable and compelling.
3. Address CCA's Limitations Explicitly: Provide a more detailed comparison to CCA, both theoretically and empirically, to justify the proposed method's advantages. Discuss scenarios where CCA fails and how the proposed method overcomes these limitations.
4. Clarify Results: The authors should explain why CCA fails to recover the true subspace in the experiments. Is this due to noise levels, lack of regularization, or other factors? A deeper analysis would provide valuable insights.
Questions for the Authors
1. How does the optimization process handle local optima, and how sensitive is the method to initialization?
2. Can the authors provide empirical runtime comparisons between the proposed method and CCA, particularly for high-dimensional datasets?
3. Why was the synthetic data generation process designed in such a complex manner? Could simpler benchmarks yield similar insights?
4. What specific noise levels or regularization settings cause CCA to fail in the experiments, and how does the proposed method address these issues?
In summary, while the paper presents an interesting idea, it requires significant improvements in clarity, experimental design, and theoretical justification to reach the standards of acceptance.