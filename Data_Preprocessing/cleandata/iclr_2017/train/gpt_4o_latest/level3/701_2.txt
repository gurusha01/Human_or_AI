Review
Summary of Contributions
This paper introduces a novel fine-tuning approach for neural networks by freezing the weights of a pre-trained model and augmenting it with additional trainable modules. The proposed modular architecture allows the original network to retain its learned representations while the added modules learn task-specific features, particularly in scenarios with limited data. The authors demonstrate the effectiveness of this approach across multiple domains, including image classification (CIFAR-10 to CIFAR-100, Stanford Cars), text classification (IMDB sentiment analysis), and small-data regimes. The results suggest that the modular approach outperforms traditional fine-tuning, especially when data is scarce, and provides complementary representations to the pre-trained network. The paper also introduces a "stitch network" variant, which integrates the new modules more tightly with the original network.
Decision: Weak Accept (Low Confidence)
The paper presents an interesting and promising idea, but the experimental validation is insufficient to fully support its claims. While the modular approach appears to be effective, the lack of comparisons with key baseline methods and limited empirical evidence weaken the strength of the conclusions.
Supporting Arguments
1. Strengths:
   - The modular approach is well-motivated and complements existing fine-tuning and transfer learning methods.
   - The experiments demonstrate the potential of the approach in small-data settings, where traditional fine-tuning often struggles.
   - The visualization of learned filters (Figure 3) provides qualitative insights into how the modules learn complementary features.
2. Weaknesses:
   - The paper lacks comparisons with critical baselines, such as ensemble methods or late fusion approaches, which are natural alternatives to the proposed method.
   - The claim in Section 3.2 that fine-tuning with limited data can hurt performance is valid but not adequately substantiated. Figure 4 provides some evidence, but additional experiments and statistical analysis are needed.
   - The modular approach increases the number of trainable parameters, which may confound the performance improvements. A more rigorous analysis of parameter efficiency is necessary.
   - Figure 3 suggests that some module filters fail to converge or learn uninformative features, but this issue is not discussed in detail.
Suggestions for Improvement
1. Baseline Comparisons: Include experiments comparing the modular approach with ensemble methods (e.g., combining predictions from multiple networks) and late fusion (e.g., combining a pre-trained network with a fine-tuned network). These comparisons would clarify the advantages of the proposed method.
2. Empirical Evidence: Provide more robust empirical evidence to support the claim that fine-tuning harms performance in small-data regimes. For example, compare the modular approach with fine-tuning across multiple datasets and report statistical significance.
3. Parameter Efficiency: Analyze the impact of the increased number of trainable parameters in the modular approach. Could a more compact module achieve similar results?
4. Filter Analysis: Address the issue of non-converging or uninformative filters observed in Figure 3. Is this a limitation of the approach, or can it be mitigated with better regularization or training strategies?
5. Broader Evaluation: Extend the evaluation to additional datasets or tasks to demonstrate the generalizability of the approach.
Questions for the Authors
1. How does the modular approach compare to ensemble methods or late fusion in terms of performance and computational cost?
2. Could the increased number of trainable parameters in the modular approach be a confounding factor in the reported performance gains?
3. How sensitive is the modular approach to the choice of architecture for the added modules? Have you explored more compact or lightweight module designs?
4. Can you provide more quantitative evidence to support the claim that fine-tuning harms performance with limited data?
In conclusion, while the paper introduces a compelling idea with promising results, it requires stronger experimental validation and comparisons with key baselines to fully establish its contributions.