Review of the Paper
The paper proposes a neural autoencoder-based framework for lossy image compression and decompression, achieving performance comparable to JPEG-2000. The authors highlight the flexibility of their approach, which can adapt to diverse content types and metrics, and its computational efficiency, making it suitable for high-resolution images. They address the challenge of non-differentiability in compression tasks by introducing a novel gradient approximation for quantization and entropy rate estimation. The paper also demonstrates competitive performance in terms of perceptual quality metrics like SSIM and MOS, particularly at higher bit rates, and emphasizes the potential of their method for domain-agnostic compression.
Decision: Reject
The decision to reject is primarily based on two reasons: (1) the lack of clear improvement over JPEG-2000 in terms of rate-distortion performance, which weakens the case for adopting a deep autoencoder-based approach, and (2) insufficient analysis of the underlying factors contributing to the observed performance, such as whether the benefits stem from a better coding scheme or an improved decoder. While the paper demonstrates some strengths, these issues limit its contribution to the field.
Supporting Arguments
1. Performance Comparison: Although the proposed method achieves comparable or slightly better results than JPEG-2000 in some perceptual quality metrics, it does not consistently outperform it across all metrics or bit rates. This undermines the argument for replacing a well-established codec with a neural autoencoder, especially given the computational and training overheads of the latter.
2. Analysis of Components: The paper does not adequately analyze the similarities and differences between the learned encoder and JPEG-2000. For example, it is unclear whether the observed benefits are due to the encoding process, the decoding process, or both. A deeper investigation into the performance on different textures or image types would strengthen the claims.
3. Baseline Comparisons: While the paper compares its method to JPEG and an RNN-based approach, the comparisons are limited. Stronger baselines, such as modern neural compression methods, should be included to contextualize the results.
Suggestions for Improvement
1. Deeper Analysis: Provide a detailed comparison of the learned encoder and JPEG-2000, particularly focusing on performance across various image textures and content types. This would help clarify the unique contributions of the proposed method.
2. Component Evaluation: Isolate the contributions of the encoder, decoder, and entropy coding scheme to determine which components drive the observed performance improvements.
3. Broader Baselines: Compare the proposed method against more recent neural compression techniques to better position it within the current state of the art.
4. Efficiency Metrics: Include a discussion of computational efficiency during training and inference, as this is a critical factor for practical adoption.
Questions for the Authors
1. How does the proposed method perform on images with diverse textures or non-natural content compared to JPEG-2000?
2. Can the authors provide an ablation study to isolate the contributions of the encoder, decoder, and entropy coding scheme?
3. What are the computational trade-offs (e.g., training time, inference latency) compared to traditional codecs like JPEG-2000?
While the paper presents an interesting approach to neural compression, addressing the above concerns would significantly strengthen its contribution and impact.