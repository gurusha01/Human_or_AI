Review of the Paper
Summary of Contributions
This paper provides a comprehensive and well-articulated review of generative adversarial networks (GANs) from the perspective of likelihood ratio estimation and divergence minimization. It frames GANs within the broader context of implicit generative models and establishes connections to related fields such as econometrics, approximate Bayesian computation, and density ratio estimation. The authors synthesize various approaches to density ratio estimation—class-probability estimation, divergence minimization, ratio matching, and moment matching—and highlight their relevance to GANs. The paper also discusses the challenges of likelihood-free inference and explores the hypothesis testing viewpoint as a unifying principle for learning in implicit generative models. While the paper does not propose a novel algorithm, it aims to provide a unifying framework that bridges gaps between different perspectives in the literature.
Decision: Reject
While the paper is well-written and provides a thorough overview of GANs and related concepts, it lacks significant novelty or a singular key idea that advances the field. As a unifying review, it is better suited for a journal or a survey article rather than a conference submission, which typically prioritizes novel contributions. Additionally, there are issues with the flow of the narrative, and some references and connections to prior work are either misplaced or underemphasized.
Supporting Arguments
1. Strengths: The paper excels in its exposition and provides a clear, accurate, and detailed overview of GAN theory. The use of the hypothesis testing framework to unify various approaches is insightful and could help researchers navigate the landscape of implicit generative models.
2. Weaknesses: The paper does not introduce a novel method, theoretical result, or empirical finding. Its primary contribution is a synthesis of existing ideas, which, while valuable, does not meet the bar for a conference submission. Furthermore:
   - The discussion around equations (13) and (14) feels disconnected from the main narrative, which affects the overall coherence.
   - The reference to KLIEP is misplaced after Eqn. (16) and should instead be associated with Eqn. (14).
   - The hypothesis testing angle, while interesting, is overstated and does not leverage tools from the hypothesis testing literature in a meaningful way.
Additional Feedback for Improvement
1. Reformulation of Eqn. (14): Consider reformulating Eqn. (14) as an unconstrained optimization problem using a Lagrange multiplier, which could make it solvable via stochastic gradient descent. This would enhance its practicality and relevance.
2. Highlighting Related Work: The contributions of Sugiyama and collaborators to density ratio estimation should be emphasized more prominently, particularly in the context of Eqn. (13). Additionally, the connection of Eqn. (15) to Least Squares Importance Estimation (LSIE) by Kanamori et al. (2009) and its potential link to the witness function in MMD should be explored further.
3. Flow and Narrative: The flow between sections, particularly around equations (13) and (14), needs improvement to maintain coherence. Consider integrating these discussions more seamlessly into the broader narrative on likelihood ratio estimation.
4. Typographical Errors: Correct the typo in "Csiszar divergence" and ensure all references are accurate and appropriately placed.
5. Evaluation Metrics: The paper discusses the challenges of evaluating generative models but does not propose concrete solutions. Including a discussion on potential evaluation metrics, such as those based on density ratio estimation, would be valuable.
Questions for the Authors
1. Can you clarify the practical implications of the hypothesis testing framework for GANs? Are there specific tools from the hypothesis testing literature that could be leveraged to improve GAN training or evaluation?
2. How does Eqn. (14) compare empirically to other objectives in terms of stability and performance? Have you considered testing its reformulation as an unconstrained optimization problem?
3. Why is the connection between Eqn. (15) and LSIE not explored in greater depth? Could this connection provide new insights or practical benefits for GAN training?
In conclusion, while the paper provides a valuable synthesis of existing ideas, its lack of novelty and coherence issues make it unsuitable for acceptance at this conference. However, with revisions and additional emphasis on practical contributions, it could serve as an excellent journal article or survey.