Review of the Paper
Summary of Contributions
This paper proposes the use of Bayesian neural networks (BNNs) to model learning curves for early termination in hyperparameter optimization, building on prior work with parametric learning curve models. The authors introduce a specialized "learning curve layer" to improve the predictive performance of BNNs and evaluate their approach against several baselines, including Gaussian processes, random forests, and parametric models. The paper also extends the Hyperband algorithm by incorporating the proposed BNN-based model to improve the efficiency of hyperparameter optimization. The authors demonstrate their method on multiple datasets, showing its ability to predict both partially observed and completely unobserved learning curves. While the results indicate incremental improvements over existing methods, the paper addresses a practical and relevant problem in the field of hyperparameter optimization.
Decision: Accept
The paper merits acceptance due to its practical focus on a real-world problem, its thorough experimental evaluation, and its incremental but meaningful contribution to the field. However, the paper's impact could be significantly enhanced by addressing some limitations in the experimental results and providing additional clarity in the evaluation metrics.
Supporting Arguments
1. Motivation and Relevance: The problem of early termination in hyperparameter optimization is highly relevant, as it can save significant computational resources. The proposed approach is well-motivated and builds on prior work in a logical and incremental manner.
2. Methodological Contribution: The introduction of a specialized learning curve layer within BNNs is a novel contribution that leverages domain-specific knowledge to improve predictions. This is a meaningful extension of existing parametric models.
3. Thorough Experiments: The paper evaluates its approach on multiple datasets and compares it against strong baselines, including Gaussian processes, random forests, and parametric models. The inclusion of both partially observed and unobserved learning curve predictions adds depth to the evaluation.
4. Practicality: Extending Hyperband with the proposed model demonstrates the practical utility of the approach, making it more applicable to real-world hyperparameter optimization tasks.
Suggestions for Improvement
1. Release of Code: The authors should release the code to enhance the reproducibility and practical impact of their work. This would allow practitioners to directly apply the proposed method in their own optimization pipelines.
2. Evaluation Metrics: The current results are underwhelming, with unclear evidence of significant speedups in hyperparameter optimization. The authors should include metrics such as "iterations to reach a fixed objective" and real-time performance to better quantify the time savings achieved by the proposed method.
3. Visualization: A histogram of termination times would provide valuable intuition about how many runs are terminated early and how early they are stopped. This would help clarify the practical benefits of the approach.
4. Clarity in Results: The paper should provide a more detailed discussion of why certain baselines, such as LastSeenValue, perform competitively in some scenarios. This would help contextualize the incremental improvements achieved by the proposed method.
Questions for the Authors
1. How does the computational overhead of using BNNs compare to simpler models like random forests or Gaussian processes? Does this overhead negate the time savings achieved through early termination?
2. Could the authors clarify how the proposed method performs in scenarios with highly noisy or non-monotonic learning curves? Are there specific datasets where the model struggles?
3. How sensitive is the performance of the proposed method to the choice of MCMC sampling method (e.g., SGHMC vs. SGLD)? Would alternative inference methods, such as variational inference, improve scalability?
In conclusion, while the paper presents incremental progress, it addresses an important problem with a well-motivated and practical approach. With some refinements and additional clarity, it has the potential to make a stronger impact in the field.