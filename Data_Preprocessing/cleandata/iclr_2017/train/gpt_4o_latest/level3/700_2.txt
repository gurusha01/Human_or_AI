Review of "Marginal Deep Architectures (MDA)"
Summary of Contributions:
The paper addresses the limitations of traditional deep learning models on small and mid-sized datasets by proposing a novel deep learning framework called Marginal Deep Architectures (MDA). The method leverages Marginal Fisher Analysis (MFA) for layer-wise initialization, followed by fine-tuning using techniques like backpropagation, dropout, and denoising. The authors claim that MDA outperforms both shallow feature learning models and state-of-the-art deep learning methods on small and mid-sized datasets across diverse domains such as image classification, speech recognition, and historical document understanding. The paper also explores the impact of architectural choices and hyperparameters on MDA's performance.
Decision: Reject
Key reasons for rejection:
1. Limited Novelty: The core component, Marginal Fisher Analysis (MFA), is not a novel contribution, and its stacking lacks theoretical or empirical justification.
2. Incomplete Comparisons: The paper excludes comparisons with deep architectures that use backpropagation across multiple layers, which contradicts the problem it aims to address. Additionally, the performance of randomly initialized models like CNNs or DBNs is not evaluated.
3. Clarity and Rigor: The paper lacks clarity in describing the model architecture and hyperparameter selection. Key implementation details, such as the integration of dropout with MFA, are omitted, and the writing requires significant improvement.
Supporting Arguments:
1. Motivation and Placement in Literature: While the paper highlights the challenges of deep learning on small datasets, the proposed solution does not convincingly address these issues. The stacking of MFA layers is presented as a key innovation, but the lack of theoretical justification or empirical analysis weakens the contribution. Moreover, the exclusion of standard deep learning baselines undermines the validity of the claims.
   
2. Experimental Results: The experimental results show that MDA performs well on small datasets, but the comparisons are incomplete. The omission of results for randomly initialized deep models (e.g., CNNs, DBNs) raises concerns about the robustness of the claims. Furthermore, the evaluation on a large-scale dataset (CIFAR-10) is limited and does not demonstrate significant advantages over existing methods.
3. Clarity and Writing: The paper is poorly written, with several implementation details missing. For example, the exact role of dropout and denoising in the MFA-based layers is unclear. Additionally, the description of the experimental setup and hyperparameter tuning lacks transparency, making it difficult to reproduce the results.
Suggestions for Improvement:
1. Theoretical Justification: Provide a theoretical analysis or empirical evidence to justify why stacking MFA layers is effective for deep architectures.
2. Comprehensive Comparisons: Include comparisons with standard deep learning models that use backpropagation across multiple layers, as well as randomly initialized models like CNNs or DBNs.
3. Clarity and Reproducibility: Improve the writing and provide detailed descriptions of the model architecture, hyperparameter selection, and implementation details. Clarify how techniques like dropout and denoising are integrated into the MFA-based layers.
4. Broader Evaluation: Evaluate the proposed method on a wider range of datasets, including large-scale datasets, to demonstrate its generalizability and scalability.
Questions for the Authors:
1. What is the theoretical basis for stacking MFA layers, and how does it address the limitations of traditional deep learning models?
2. Why were comparisons with deep architectures requiring backpropagation over multiple layers excluded?
3. How were hyperparameters (e.g., number of layers, dropout rate) selected, and how sensitive is MDA to these choices?
4. Can you provide more details on the integration of dropout and denoising into the MFA-based layers?
In conclusion, while the paper addresses an important problem, the lack of novelty, incomplete comparisons, and insufficient clarity significantly limit its contribution. Further theoretical and empirical work is needed to strengthen the proposed approach.