Review of the Paper
Summary of Contributions
This paper investigates the problem of transfer in reinforcement learning (RL) between morphologically distinct agents, such as robots with different link counts or actuation mechanisms. The authors propose a novel approach that leverages shared skills to construct invariant feature spaces, enabling skill transfer between agents. The method employs a three-layer neural network to learn nonlinear mappings into a shared latent space, which facilitates transfer by aligning the state distributions of optimal policies across agents. Experiments conducted in a physics simulator demonstrate the effectiveness of the approach in transferring skills between robots with different morphologies, including arms with varying link counts and actuation mechanisms. The paper highlights the importance of the shared-skills hypothesis and positions the work as a step toward enabling robots to learn from one another in complex, real-world scenarios.
Decision: Reject
While the paper addresses an important and underexplored problem in RL and presents a promising direction, it falls short in several key areas. The primary reasons for rejection are the lack of comparisons to modern transfer learning methods and the use of overly simplistic experimental domains, which limit the generalizability and impact of the findings.
Supporting Arguments
1. Lack of Comparisons to Modern Methods: The paper compares its approach to older techniques like CCA, kernel CCA, and manifold alignment but does not benchmark against more recent advancements in transfer learning, such as meta-RL, policy distillation, or adversarial domain adaptation. This omission makes it difficult to assess the true novelty and effectiveness of the proposed method relative to the state of the art.
2. Simplistic Experimental Domains: The experiments are conducted in a basic physics simulator with tasks like button pressing and block pulling. While these tasks are useful for proof-of-concept, they do not convincingly demonstrate the scalability of the method to more complex, real-world scenarios. Additionally, the choice of tasks does not fully exploit the potential of the proposed approach to handle diverse and challenging environments.
3. Limited Theoretical Development: The paper provides minimal theoretical grounding using Markov Decision Process (MDP) theory. A more rigorous analysis of the shared feature space's properties and its implications for transfer efficiency would strengthen the paper's contributions.
Suggestions for Improvement
1. Expand Experimental Comparisons: Include benchmarks against modern transfer learning methods, such as those leveraging meta-learning or adversarial techniques. This would provide a clearer picture of where the proposed method stands in the broader RL landscape.
2. Test in Complex Domains: Evaluate the approach in more realistic and challenging environments, such as high-dimensional robotic tasks or vision-based RL scenarios. This would demonstrate the method's scalability and practical applicability.
3. Enhance Theoretical Rigor: Provide a more detailed theoretical analysis of the shared feature space, including its properties, limitations, and potential extensions. This would help clarify the method's strengths and weaknesses.
4. Ablation Studies: Conduct ablation studies to isolate the contributions of different components, such as the neural network architecture, the alignment procedure, and the use of proxy tasks. This would provide deeper insights into the method's design choices.
Questions for the Authors
1. How does the proposed method compare to modern transfer learning techniques, such as policy distillation or meta-RL, in terms of sample efficiency and transfer quality?
2. Can the method handle scenarios where the shared skills are noisy or imperfectly aligned? If not, how could this limitation be addressed?
3. How does the choice of proxy tasks affect the quality of the learned feature space? Are there guidelines for selecting effective proxy tasks?
4. Could the method be extended to handle multi-agent transfer scenarios or continuous lifelong learning settings?
Conclusion
The paper addresses an important problem and proposes a promising approach, but it lacks sufficient empirical and theoretical rigor to warrant acceptance at this stage. Addressing the outlined limitations and questions would significantly strengthen the work.