Review
Summary of Contributions
The paper introduces a novel approach to knowledge transfer between neural networks by leveraging attention maps, specifically activation-based and gradient-based spatial attention maps. The authors propose methods to transfer attention from a teacher network to a student network, aiming to improve the latter's performance. The paper demonstrates consistent improvements across various datasets and architectures, including CIFAR and ImageNet. The proposed approach is positioned as an enhancement to standard knowledge distillation techniques, with the added benefit of providing insights into the interpretability of neural network attention mechanisms. The authors also make their code and models publicly available, which is commendable for reproducibility.
Decision: Reject
While the paper presents an interesting idea and demonstrates some improvements, the experimental results are not sufficiently compelling to warrant acceptance in their current form. The limited improvement over standard knowledge distillation, lack of comprehensive experiments on ImageNet, and insufficient evaluation in Section 4.2.2 weaken the paper's overall impact. Additionally, the claims of "significant improvement" are not fully supported by the provided results.
Supporting Arguments for Decision
1. Limited Improvement Over Baselines: The experimental results show only marginal improvements over standard knowledge distillation techniques. For example, on CIFAR-10, the test error reduction is modest, and on ImageNet, the improvement is limited to 1.1% top-1 accuracy. These gains, while positive, do not convincingly demonstrate the superiority of the proposed method.
   
2. Incomplete Experiments on ImageNet: The ImageNet experiments, a critical benchmark for evaluating the scalability and generalizability of the proposed method, are incomplete. The authors acknowledge that they did not tune hyperparameters or include attention transfer losses for all residual groups. This leaves the evaluation on large-scale datasets insufficiently explored.
3. Underdeveloped Evaluation in Section 4.2.2: The evaluation in Section 4.2.2 is underdeveloped, with limited analysis of the results and no comparison to other state-of-the-art methods. Extending this section with more detailed experiments and discussions would significantly strengthen the paper.
Suggestions for Improvement
1. Expand ImageNet Experiments: Conduct a more comprehensive evaluation on ImageNet, including tuning hyperparameters and applying attention transfer losses to all residual groups. This would provide a stronger case for the method's effectiveness on large-scale datasets.
   
2. Extend Section 4.2.2: Provide a more detailed analysis of the results, including comparisons with other knowledge transfer methods. This would help contextualize the improvements and highlight the unique contributions of the proposed approach.
3. Clarify "Significant Improvement" Claims: The paper frequently uses terms like "significant improvement," but the results do not always substantiate this claim. Provide statistical significance testing or more detailed comparisons to strengthen these assertions.
4. Additional Datasets: While the paper evaluates on CIFAR and ImageNet, additional experiments on diverse datasets (e.g., object detection or weakly-supervised localization) could demonstrate the broader applicability of the method.
Questions for the Authors
1. How does the proposed method compare to other recent attention-based knowledge transfer techniques in terms of computational cost and performance?
2. Why were the hyperparameters for ImageNet experiments not tuned, and how might this have impacted the results?
3. Could you provide more insights into why attention transfer outperforms full activation transfer in your experiments?
In summary, while the paper introduces an interesting idea and shows promise, the limited experimental rigor and incomplete evaluations prevent it from meeting the standards for acceptance at this time. Addressing the outlined weaknesses would significantly enhance the paper's impact and clarity.