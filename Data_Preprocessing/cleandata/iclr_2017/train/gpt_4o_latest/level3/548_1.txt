Review of the Paper
Summary of Contributions
The paper introduces a novel optimization technique called Charged Point Normalization (CPN), inspired by physics, to address the problem of saddle points in high-dimensional non-convex optimization. The method models the optimization process as a positively charged particle on an error surface, dynamically introducing a regularizer to repel the optimization trajectory from saddle points. Unlike existing methods, CPN does not rely on second-order information and is compatible with standard gradient descent algorithms. The authors claim that CPN improves optimization performance across various neural network architectures and datasets, including MNIST, CIFAR10, CIFAR100, and BABI. The paper also provides theoretical insights into the behavior of gradient descent around saddle points and demonstrates the efficacy of CPN through empirical experiments.
Decision: Reject
While the paper presents an innovative idea with potential, it suffers from significant weaknesses that undermine its scientific rigor and clarity. The primary reasons for rejection are the lack of sufficient justification for the proposed method and the inadequate experimental evidence to support the claims.
Supporting Arguments for the Decision
1. Insufficient Theoretical Justification: The derivation and explanation of the key equation (Equation 6) are unclear, and the implications of the proposed regularizer for optimization are not thoroughly analyzed. Variables like "p" and other parameters are poorly introduced, leaving the reader struggling to understand the mathematical foundation of the method.
2. Weak Experimental Validation: The experiments lack convincing evidence. For example, the results on CIFAR10 and CIFAR100 are not robust, as the method performs worse initially and only marginally outperforms standard methods later. Additionally, the lack of validation set results and hyper-parameter tuning undermines the reliability of the reported improvements.
3. Clarity and Presentation Issues: The paper is poorly written, with unclear figures (e.g., Figures 2 and 3) and inadequate explanations of key variables and equations. Formatting issues and a lack of flow further detract from the readability and comprehension of the paper.
4. Hyper-Parameter Selection: The discussion on hyper-parameter selection is superficial, and the authors admit to using arbitrary or minimally tuned values. This raises concerns about the reproducibility and generalizability of the results.
Suggestions for Improvement
1. Theoretical Clarity: Provide a more rigorous and detailed explanation of the proposed method, particularly Equation 6 and its implications for optimization. Clearly define all variables and parameters upfront.
2. Experimental Rigor: Include a broader range of experiments with stronger baselines and validation set results. Perform a comprehensive study on the sensitivity of CPN to its hyper-parameters.
3. Figures and Presentation: Improve the quality of the figures by adding proper labels, captions, and readability. Ensure that the paper is well-structured and flows logically.
4. Address Weaknesses: Discuss potential limitations of CPN, such as its increased memory requirements and numerical instability, in greater detail. Propose solutions or mitigations for these issues.
Questions for the Authors
1. How does backpropagation handle the dynamic parameters introduced by $\tilde{\mW}_i^t$ in the regularizer? Is backpropagation performed through these parameters?
2. How sensitive is the performance of CPN to the choice of hyper-parameters (e.g., $\beta$, $\lambda$, $p$)? Can you provide a detailed analysis or ablation study?
3. Why were validation set results omitted? How can we ensure that the reported improvements are not due to overfitting or dataset-specific artifacts?
In conclusion, while the idea of CPN is intriguing, the paper requires significant revisions to address its theoretical, experimental, and presentation shortcomings before it can be considered for acceptance.