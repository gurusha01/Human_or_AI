Review of the Paper
Summary of Contributions
The paper introduces a novel method, "Interior Gradients," to measure feature importance in deep neural networks by computing gradients of the output with respect to scaled versions of the input image (α * I) and aggregating these gradients across all scaling factors (α). The authors argue that this approach addresses the issue of gradient saturation in nonlinear models, which can obscure the importance of input features. The proposed method is simple to implement, architecture-agnostic, and satisfies desirable axioms like sensitivity and implementation invariance. The paper provides qualitative visualizations and limited quantitative evidence to demonstrate that the proposed method highlights relevant features more effectively than standard gradient-based methods. Applications to diverse domains, including image classification, ligand-based virtual screening, and language modeling, are discussed.
Decision: Reject  
The decision to reject is based on two primary reasons:  
1. Lack of Depth in Theoretical and Empirical Support: While the method is intuitive and easy to implement, the paper fails to provide a convincing theoretical explanation for why scaled inputs (faint images) emphasize relevant features. The empirical evaluation is heavily reliant on qualitative visualizations, with limited quantitative evidence to support the claims.  
2. Methodological and Presentation Issues: The proposed feature importance ranking is noisy, assumes pixel independence (an unrealistic assumption), and does not significantly advance our understanding of deep networks. Additionally, the paper is overly verbose, with unnecessary terminology and a lack of clarity in presenting key ideas early on.
Supporting Arguments
1. The paper's key observation—that faint images emphasize pixels on the object related to the correct class—is intriguing but insufficiently explained. The authors speculate on reasons but fail to provide rigorous theoretical backing or deeper insights into the phenomenon.  
2. The quantitative evaluation is limited to a small set of metrics (e.g., AOPC and bounding box overlap), which are not robust enough to validate the method's effectiveness across diverse tasks. The reliance on subjective "eyeballing" of visualizations further weakens the scientific rigor.  
3. The assumption of pixel independence in the feature importance ranking is a significant limitation, as it ignores interactions between pixels, which are critical in understanding deep networks.  
4. The paper's length (14-19 pages) is excessive for the simplicity of the idea, and the verbose writing detracts from the clarity of the contribution. The use of terms like "counterfactuals" for scaled images appears unnecessarily grandiose and could confuse readers.
Suggestions for Improvement
1. Provide a stronger theoretical foundation for why scaled inputs emphasize relevant features. For example, analyze the behavior of gradients under scaling in different network architectures.  
2. Expand the quantitative evaluation to include more robust metrics and larger datasets. Compare the proposed method against other state-of-the-art feature attribution techniques, such as DeepLIFT or LIME, to establish its relative advantages.  
3. Address the issue of pixel independence by exploring methods that account for feature interactions, such as grouping correlated features or modeling dependencies.  
4. Streamline the writing to improve clarity and conciseness. Avoid overloading the reader with unnecessary terminology and focus on presenting the core ideas succinctly.  
Questions for the Authors
1. Why do scaled inputs (faint images) emphasize relevant features? Can you provide a more rigorous theoretical explanation or empirical evidence to support this claim?  
2. How does the proposed method compare to other feature attribution techniques, such as DeepLIFT or LIME, in terms of quantitative performance and computational efficiency?  
3. Have you considered extending the method to account for feature interactions or dependencies, rather than assuming pixel independence?  
4. Could the method's reliance on scaling inputs lead to artifacts or biases in networks trained on datasets with specific intensity distributions?  
In summary, while the proposed method is simple and potentially useful, the lack of theoretical depth, limited empirical validation, and methodological shortcomings prevent it from meeting the standards of a top-tier AI conference. Addressing these issues could significantly strengthen the paper for future submissions.