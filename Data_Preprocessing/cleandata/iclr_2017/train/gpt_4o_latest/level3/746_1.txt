Review
Summary of Contributions
This paper introduces a novel neural architecture inspired by the divide-and-conquer principle, which leverages recursive split-and-merge operations to learn algorithmic tasks from input-output pairs. The proposed framework optimizes both accuracy and computational complexity in a differentiable manner, without requiring intermediate supervision. The authors demonstrate the efficacy of their approach on sorting and planar convex hull problems, showcasing the model's ability to generalize across scales. Key contributions include the recursive architecture design, the integration of complexity as an optimization objective, and preliminary empirical results validating the framework's potential.
Decision: Reject
While the paper presents an interesting and innovative approach, the decision to reject is primarily based on two key concerns:
1. Incomplete or Unclear Code Submission: The lack of access to the implementation or sufficient details about the code raises concerns about reproducibility. The empirical results hinge on the correctness of the implementation, and without access to the code, it is challenging to verify the claims.
2. Insufficient Empirical Validation: The experimental results, while promising, are limited in scope and lack comparisons with strong baselines. The absence of rigorous benchmarks undermines the strength of the empirical evidence.
Supporting Arguments
1. Motivation and Literature Placement: The paper is well-motivated and places itself appropriately in the context of existing literature. The divide-and-conquer principle is a compelling inductive bias, and the authors draw meaningful parallels to convolutional and recurrent architectures. However, the novelty of the approach could have been better highlighted by contrasting it with existing methods for algorithmic tasks, such as Pointer Networks or Neural GPUs.
   
2. Claims and Empirical Support: The claims regarding scale invariance, weak supervision, and complexity optimization are intriguing. However, the empirical results are limited to two tasks (sorting and planar convex hull), and the experiments lack comparisons with state-of-the-art methods. The reported metrics, while encouraging, do not provide sufficient evidence to establish the superiority or robustness of the proposed approach.
3. Reproducibility and Clarity: The paper's theoretical exposition is detailed, but the lack of access to the code or explicit pseudocode for key components (e.g., split and merge blocks) makes it difficult to assess the implementation. This is particularly concerning given the reliance on weak supervision and the complexity of the recursive architecture.
Additional Feedback
1. Expand Experimental Scope: Include comparisons with existing methods for algorithmic tasks, such as attention-based models or reinforcement learning approaches. This would strengthen the empirical validation.
2. Provide Implementation Details: Share the code or include detailed pseudocode for the split and merge modules. This would improve reproducibility and allow reviewers to verify the results.
3. Clarify Weak Supervision: The paper mentions "weak supervision" but does not provide sufficient detail on how the targets are propagated or how the lack of intermediate supervision impacts training. A more thorough explanation would be beneficial.
4. Complexity Analysis: While the paper discusses complexity optimization, it would be helpful to include quantitative comparisons of the model's complexity with baseline methods.
5. Future Work: The discussion section outlines promising directions for future work, but the paper would benefit from preliminary experiments on graph-based tasks or joint training of split and merge modules to demonstrate the framework's broader applicability.
Questions for the Authors
1. Can you provide access to the code or detailed pseudocode for the split and merge modules?
2. How does the model perform compared to existing methods like Pointer Networks or Neural GPUs on the same tasks?
3. How sensitive is the model to the choice of hyperparameters (e.g., βS, βM, αM)?
4. What is the impact of weak supervision on the model's convergence and generalization performance?
In summary, while the paper introduces an innovative framework with significant potential, the lack of reproducibility and limited empirical validation prevent it from meeting the standards for acceptance at this time. Addressing these concerns in a future submission could make this work a strong contribution to the field.