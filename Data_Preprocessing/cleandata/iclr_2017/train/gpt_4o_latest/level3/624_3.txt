Review of the Paper
Summary of Contributions
This paper investigates the failure modes of optimization in neural networks by constructing specific datasets and initialization schemes that lead to poor learning dynamics. The authors challenge the prevailing belief that neural networks are immune to bad local minima by presenting counterexamples where optimization fails. They analyze the error surface of rectified multi-layer perceptrons (MLPs) on finite datasets and demonstrate scenarios where bad initialization or suboptimal model configurations result in poor performance. The paper also introduces the "jellyfish" dataset, which highlights the difficulty of training small models on certain data structures. The authors provide theoretical propositions and empirical experiments to support their claims, including examples on MNIST and synthetic datasets.
Decision: Reject
The primary reasons for rejection are the limited practical relevance of the constructed examples and the unrealistic assumptions underlying the theoretical propositions. While the paper provides interesting theoretical insights, its findings are not well-aligned with real-world scenarios, where standard initialization heuristics and model configurations mitigate many of the issues discussed.
Supporting Arguments
1. Limited Practical Relevance: The paper's focus on highly constructed datasets and initialization schemes reduces its applicability to real-world problems. For instance, the "bad initialization on MNIST" experiment highlights issues that are largely avoided in practice using standard initialization methods like Xavier or He initialization. Similarly, the "jellyfish" dataset is an artificial construct that does not reflect the characteristics of typical datasets encountered in practice.
2. Unrealistic Assumptions: Proposition 4 assumes control over the mean of weight initialization, which is not feasible in standard neural network training pipelines, where weights are initialized with mean-zero distributions. Proposition 5 examines infinitely deep ReLU networks, which are not representative of practical architectures, where residual connections (e.g., ResNets) are commonly used to address vanishing gradients and optimization challenges.
3. Inappropriate Model Configurations: The choice of model size and depth for the "jellyfish" dataset is suboptimal, making the results less convincing. The authors do not provide sufficient justification for these design choices, which appear to exaggerate the observed failure modes.
Suggestions for Improvement
1. Broader Contextualization: The paper would benefit from a more thorough discussion of how its findings relate to standard practices in deep learning. For example, how do the proposed failure modes manifest under widely used initialization schemes and architectures like ResNets or Transformers?
2. Realistic Experiments: Including experiments on more realistic datasets and models would strengthen the paper's practical relevance. For example, testing the proposed failure modes on ImageNet or CIFAR-10 with standard architectures could provide more actionable insights.
3. Improved Model Selection: The choice of model size and depth should be better justified, particularly for the "jellyfish" dataset. Exploring whether larger or deeper models mitigate the observed issues would make the results more robust.
4. Clarification of Assumptions: The authors should explicitly acknowledge the limitations of their assumptions, such as the control over weight initialization mean, and discuss how these assumptions impact the generalizability of their findings.
Questions for the Authors
1. How do the proposed failure modes manifest when using standard initialization schemes like Xavier or He initialization?
2. Have you tested the "jellyfish" dataset with larger or deeper models to determine whether the observed failure modes persist?
3. Can the theoretical results (e.g., Proposition 4) be extended to more realistic initialization schemes with mean-zero distributions?
4. How do your findings generalize to modern architectures like ResNets or Transformers, which are designed to address optimization challenges?
In conclusion, while the paper provides valuable theoretical insights, its limited practical relevance and reliance on unrealistic assumptions make it unsuitable for acceptance in its current form. Addressing the above concerns could significantly enhance the paper's impact and applicability.