Review
Summary of Contributions
This paper proposes an extension of adversarial and virtual adversarial training to the text domain, specifically targeting semi-supervised text classification tasks. The key innovation lies in applying perturbations at the word embedding level rather than directly to the sparse, high-dimensional one-hot input vectors, making the approach more suitable for natural language processing (NLP) tasks. The authors demonstrate the effectiveness of their method on several benchmark datasets, achieving state-of-the-art or competitive results. They also provide qualitative analyses showing improved word embeddings and reduced overfitting during training. The paper is well-written, and the proposed method is simple yet effective, requiring the optimization of only one additional hyperparameter.
Decision: Reject  
While the paper demonstrates practical effectiveness and introduces a novel application of adversarial training to text classification, it lacks sufficient novelty on the algorithmic side and fails to provide adequate comparisons with prior work, particularly with SVM-based semi-supervised methods. These omissions make it difficult to assess the true contribution of the proposed approach relative to existing literature.
Supporting Arguments for the Decision
1. Lack of Theoretical and Experimental Comparison: The paper does not adequately compare its approach with prior semi-supervised learning methods, particularly SVM-based approaches such as those by Wang et al. (2012) on the IMDB dataset. While the authors mention the superiority of adversarial training over SVMs in passing, no direct experimental results or theoretical insights are provided to substantiate this claim. This omission weakens the paper's position in the broader semi-supervised learning literature.
   
2. Unclear Novelty: The core contribution—applying adversarial perturbations to word embeddings—is a straightforward adaptation of existing adversarial training methods. While this adaptation is well-motivated for NLP, it does not represent a significant algorithmic advancement. The novelty is further diluted by the lack of comparison with other semi-supervised approaches in text classification, such as those using CNNs or RNNs with view embeddings.
3. Limited Scope of Experiments: Although the experimental results are promising, the paper focuses primarily on text classification tasks and does not explore other potential applications in the text domain, such as machine translation or question answering. Additionally, the absence of comparisons with SVM-related baselines on datasets like IMDB limits the ability to contextualize the results.
Suggestions for Improvement
1. Comparative Analysis: Include experimental comparisons with prior SVM-based semi-supervised methods, particularly on datasets like IMDB, where such methods have been extensively studied. This would help clarify the advantages of the proposed approach over traditional techniques.
   
2. Broader Contextualization: Discuss the relationship between the proposed method and other semi-supervised learning approaches, such as generative models or transductive SVMs, in more depth. Highlight specific scenarios where adversarial training offers unique benefits.
3. Expanded Experiments: Evaluate the method on a broader range of NLP tasks, such as machine translation or question answering, to demonstrate its generalizability. Additionally, include ablation studies to isolate the impact of adversarial and virtual adversarial training on performance.
4. Theoretical Insights: Provide a theoretical discussion of why adversarial perturbations at the embedding level improve generalization in text classification tasks. This would strengthen the paper's contribution beyond empirical results.
Questions for the Authors
1. How does the proposed method compare to SVM-based semi-supervised approaches in terms of both accuracy and computational efficiency? Can you include results for such comparisons?
2. Why were datasets like IMDB not evaluated against prior SVM-related baselines, such as Wang et al. (2012)? Including these comparisons would provide a clearer picture of the method's effectiveness.
3. How sensitive is the proposed method to the choice of hyperparameters, particularly the norm constraint for adversarial perturbations? Could this sensitivity impact its applicability to other datasets or tasks?
4. Can the approach be extended to other NLP tasks, such as machine translation or question answering? If so, what modifications would be required?
In summary, while the paper presents a promising application of adversarial training to text classification, it falls short in terms of novelty, comparative analysis, and broader contextualization. Addressing these issues would significantly strengthen the paper's contribution.