Review of "Hybrid Deep Networks with Scattering Transform and Convnets"
Summary of Contributions
This paper proposes a novel hybrid deep learning architecture that incorporates a scattering transform as the initial layers of a deep network, followed by a standard convolutional neural network (CNN). The scattering transform provides local invariance to deformations, acts as a form of regularization, and reduces the number of learnable parameters in the model. The authors demonstrate that this hybrid approach achieves competitive performance on CIFAR-10, CIFAR-100, and STL-10 datasets, particularly excelling in low-data regimes. The scattering transform also ensures stability in the first layers, potentially improving robustness to adversarial perturbations. The paper includes a detailed theoretical analysis of the scattering transform's properties, empirical evaluations of the hybrid model, and a comparison with state-of-the-art architectures. Additionally, the authors release ScatWave, a GPU-accelerated library for computing scattering transforms.
Decision: Accept
The paper makes a meaningful contribution to the field of deep learning by demonstrating the benefits of combining predefined analytic representations (scattering transforms) with modern CNN architectures. The hybrid approach is particularly valuable in scenarios with limited data, where it outperforms fully supervised deep networks. The theoretical grounding of the scattering transform, coupled with its practical implementation and empirical validation, makes this work a strong candidate for acceptance. However, there are areas where the paper could be improved, as detailed below.
Supporting Arguments for Acceptance
1. Novelty and Motivation: The paper addresses a well-motivated problem—reducing the reliance on large datasets and computational resources in deep learning—by leveraging the scattering transform's stability and invariance properties. The integration of scattering transforms with CNNs is a novel approach that bridges analytic and learned representations.
   
2. Empirical Validation: The results on CIFAR-10, CIFAR-100, and STL-10 demonstrate that the hybrid model achieves competitive performance, particularly in low-data regimes. The experiments are thorough, with comparisons to both supervised and unsupervised baselines, as well as state-of-the-art models like Wide ResNets.
3. Theoretical Rigor: The paper provides a solid theoretical foundation for the scattering transform, including its stability properties and its ability to linearize small deformations. This adds credibility to the proposed approach.
4. Practical Contributions: The release of ScatWave, a GPU-accelerated library for scattering transforms, is a valuable resource for the research community.
Suggestions for Improvement
1. Adversarial Robustness Evaluation: While the paper claims that the scattering transform improves robustness to adversarial examples, no empirical evaluation of this claim is provided. Including experiments to assess adversarial robustness would strengthen the paper's impact.
2. Comparison with State-of-the-Art: Although the hybrid model is competitive, it does not surpass state-of-the-art architectures like Wide ResNets. A deeper discussion on the trade-offs between performance, computational efficiency, and robustness would provide more context for the results.
3. Scalability to Larger Datasets: The paper mentions extending the approach to ImageNet as future work. Preliminary results or a discussion on the challenges of scaling the hybrid model to larger datasets would be helpful.
4. Clarity in Writing: The paper is dense and highly technical, which may limit its accessibility to a broader audience. Simplifying some sections and providing more intuitive explanations of the scattering transform would improve readability.
Questions for the Authors
1. Have you conducted any experiments to evaluate the hybrid model's robustness to adversarial attacks? If so, what were the results?
2. How does the computational efficiency of the hybrid model compare to state-of-the-art architectures like Wide ResNets in terms of training and inference time?
3. What are the limitations of the scattering transform when applied to larger datasets like ImageNet, and how do you plan to address them in future work?
In conclusion, this paper offers a promising hybrid approach that combines the strengths of analytic and learned representations. While there are areas for improvement, the contributions are significant enough to warrant acceptance.