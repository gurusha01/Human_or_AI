Review of "Neural Graph Machines: Graph-Augmented Training for Neural Networks"
Summary of Contributions
The paper proposes the Neural Graph Machine (NGM), a training objective that incorporates graph regularization into neural network hidden representations. By leveraging both labeled and unlabeled data, the method biases neural networks to learn similar hidden representations for graph-connected nodes. The authors validate their approach across diverse neural network architectures (feedforward, CNNs, LSTMs) and tasks (multi-label classification, text categorization, semantic intent classification). Key empirical findings include the ability of graph-augmented training to significantly improve performance, such as enabling a 3-layer CNN to match the performance of a 9-layer CNN. Additionally, the method is shown to be effective across different graph types and scalable to large datasets.
Decision: Reject
While the paper demonstrates strong empirical results and provides a scalable implementation of graph-augmented training, its novelty is limited. The proposed method is largely an empirical extension of the work by Weston et al. (2012), with minimal theoretical or methodological innovation. The primary contribution lies in demonstrating the versatility of graph-augmented training across different network architectures and tasks, which, while valuable, does not meet the threshold for a significant contribution to the field.
Supporting Arguments for Decision
1. Lack of Novelty:  
   The core idea of incorporating graph regularization into neural networks is directly inspired by Weston et al. (2012). While the authors extend this approach to multiple architectures and tasks, the methodological contribution remains incremental. The paper does not introduce fundamentally new techniques or theoretical insights beyond the adaptation of an existing framework.
2. Empirical Focus:  
   The paper is primarily an empirical study, showcasing the effectiveness of graph-augmented training. While the results are impressive, they do not sufficiently differentiate the proposed method from prior work. For example, the use of adjacency matrices as inputs or the application to directed graphs is mentioned but not explored in depth.
3. Positioning in Literature:  
   The paper does not sufficiently contrast its contributions with recent advancements in graph neural networks (e.g., Graph Convolutional Networks or Graph Attention Networks). These methods also integrate graph structure into neural models but are not adequately discussed or compared against.
Suggestions for Improvement
1. Clarify Novel Contributions:  
   The authors should explicitly highlight how their work advances beyond Weston et al. (2012) and other graph-based neural methods. For example, are there theoretical guarantees or new insights into why the proposed objective generalizes well across architectures?
2. Broader Comparisons:  
   The paper should include comparisons with modern graph-based methods, such as Graph Neural Networks (e.g., Kipf & Welling, 2017; Velickovic et al., 2018). This would help contextualize the performance improvements and demonstrate the relevance of the proposed approach.
3. Theoretical Analysis:  
   A deeper theoretical exploration of the proposed objective function, such as its convergence properties or its impact on representation learning, would strengthen the paper. Additionally, the authors could analyze why unlabeled-unlabeled edges do not improve performance, as observed in their experiments.
4. Ablation Studies:  
   While the results are promising, more detailed ablation studies are needed to isolate the contributions of different components (e.g., the choice of distance metric, graph construction methods, or hyperparameters like Î±).
Questions for the Authors
1. How does the proposed method compare to modern graph-based neural architectures, such as Graph Convolutional Networks or Graph Attention Networks?  
2. Can the authors provide more theoretical insights into why graph-augmented training improves performance across architectures?  
3. Why do unlabeled-unlabeled edges fail to improve performance, and could this behavior vary across datasets or tasks?  
4. How does the method scale to extremely large graphs, where adjacency matrices may become infeasible to store or process?
Conclusion
While the paper provides a solid empirical demonstration of graph-augmented training, its contributions are incremental and lack sufficient novelty to warrant acceptance. Addressing the above concerns and situating the work more rigorously within the broader literature could significantly improve its impact.