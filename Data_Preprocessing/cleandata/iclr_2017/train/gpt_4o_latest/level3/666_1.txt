Review of the Paper
Summary of Contributions:
The paper introduces a novel k-shot learning framework called the Orthogonal Method of Grouping (OMG), which aims to address overfitting in pre-trained networks when training data is limited. The core idea is to group network parameters based on their activation similarities and enforce orthogonality among these groups to reduce the parameter space dimensionality. This grouping is achieved through a para-loss function that optimizes intra-group similarity and inter-group orthogonality. The proposed method is generalizable and can be integrated into existing architectures, such as VGG and ResNet, without altering their structure. The authors evaluate OMG on MNIST, ImageNet, and the Office dataset, claiming state-of-the-art performance in k-shot learning tasks.
Decision: Reject
The paper presents an interesting idea with potential, but it is not yet ready for publication. The key reasons for rejection are the lack of sufficient experimental rigor and inadequate comparisons with state-of-the-art k-shot learning methods.
Supporting Arguments for Rejection:
1. Insufficient Comparison with State-of-the-Art: The paper does not compare OMG with well-established k-shot learning methods such as Matching Networks (Vinyals et al., 2016) or Prototypical Networks. This omission makes it difficult to assess the true effectiveness of the proposed method relative to the current best practices in the field.
   
2. Inappropriate Evaluation Metric: The use of "accuracy difference" as the primary evaluation metric is problematic. Reporting raw accuracies would provide a clearer and more interpretable measure of performance, especially when comparing against baselines.
3. Experimental Details: The experimental setup lacks critical details, such as the specific hyperparameters used for k-shot learning tasks and the rationale behind certain design choices (e.g., group size selection). This makes the experiments difficult to reproduce.
4. Language and Formatting Issues: The paper contains numerous grammatical errors, awkward phrasing, and improperly formatted citations. These issues detract from the clarity and professionalism of the presentation.
Suggestions for Improvement:
1. Comparison with State-of-the-Art Methods: Include a thorough comparison with established k-shot learning approaches, such as Matching Networks, Prototypical Networks, and others. This will help position OMG within the broader literature and demonstrate its relative strengths and weaknesses.
2. Evaluation Metrics: Replace "accuracy difference" with raw accuracy values for all experiments. Additionally, consider reporting standard deviations or confidence intervals to account for variability in k-shot learning tasks.
3. Experimental Details: Provide a more detailed description of the experimental setup, including hyperparameter tuning, dataset splits, and computational resources. Clarify how group sizes are determined and justify the choice of specific datasets.
4. Language and Formatting: Revise the paper to address grammatical errors and improve readability. Ensure that all citations are properly formatted and consistent with conference guidelines.
Questions for the Authors:
1. How does OMG compare to state-of-the-art k-shot learning methods, such as Matching Networks or Prototypical Networks, in terms of both accuracy and computational efficiency?
2. How sensitive is the performance of OMG to the choice of group size? Can you provide a more detailed analysis of this hyperparameter?
3. Can you clarify the rationale behind using "accuracy difference" as the primary evaluation metric? Why not report raw accuracies directly?
In summary, while the proposed method is promising and has potential, the paper requires significant improvements in experimental rigor, comparisons, and presentation quality to be considered for publication.