Review of the Paper
Summary
This paper investigates the dynamic behavior of Residual Networks (ResNets) during training, revealing that they initially act as ensembles of shallow networks but transition to deeper ensembles as training progresses. The authors attribute this behavior to the scaling parameter \( C \), which increases over time, and demonstrate that this dynamic mechanism is largely driven by Batch Normalization. The paper employs generalized spin glass models to analyze the loss surface of ResNets and provides theoretical and experimental evidence for the dynamic depth behavior. The authors also explore the implications of this mechanism for optimization and critical points in the loss landscape.
Decision: Reject
While the paper addresses an interesting and important question about the dynamic behavior of ResNets, it suffers from several critical issues that undermine its clarity, rigor, and applicability. The two main reasons for rejection are: (1) the lack of clarity in the presentation, particularly due to overloaded and dense notation, and (2) concerns about the generalizability of the theoretical analysis to standard ResNets, as the analysis is based on a modified ResNet structure with multiple skipped layers.
Supporting Arguments
1. Clarity: The paper is highly notation-heavy, making it difficult to follow even for an expert reader. Overloaded notation and the relegation of key proofs to the appendix further hinder comprehension. Including summaries of proofs in the main text and simplifying the notation would significantly improve readability.
   
2. Applicability to Standard ResNets: The theoretical analysis is based on a modified ResNet structure with multiple skipped layers. This raises concerns about whether the conclusions can be generalized to standard ResNets, which typically use single-layer skips. The authors should clarify the implications of this structural difference.
3. Lemma 2: The sequence \( \beta \), which plays a critical role in the proof of Lemma 2, is not well-explained. This lack of clarity weakens the theoretical foundation of the paper.
4. Theoretical-Experimental Link: While the experiments convincingly demonstrate the increase in the scaling parameter \( C \), the theoretical link via Theorems 3 and 4 is less compelling due to simplifying assumptions in Section 4.2. These assumptions, such as independence between inputs and paths, are acknowledged as unrealistic, further limiting the applicability of the results.
Additional Feedback
1. Proof Summaries: Including concise summaries of key proofs in the main text would improve accessibility. For instance, a high-level explanation of Lemma 2 and its implications would help readers understand its significance without delving into the appendix.
2. Notation Overhaul: The paper would benefit from a more streamlined and consistent notation system. Overloaded symbols should be avoided, and a table summarizing all notations (as provided in the appendix) should be moved to the main text.
3. Experiments on Standard ResNets: To address concerns about generalizability, the authors should conduct experiments on standard ResNet architectures with single-layer skips. This would strengthen the paper's claims and broaden its relevance.
4. Discussion of Assumptions: The authors should provide a more detailed discussion of the simplifying assumptions in Section 4.2 and their impact on the results. For example, how do these assumptions affect the validity of Theorems 3 and 4?
Questions for the Authors
1. How does the analysis of the modified ResNet structure with multiple skipped layers extend to standard ResNets with single-layer skips? Are there any key differences in behavior?
2. Can you provide more intuition or explanation for the sequence \( \beta \) in Lemma 2? How is it derived, and why is it important?
3. How robust are the theoretical results to the relaxation of the simplifying assumptions in Section 4.2, particularly the independence assumptions?
4. Have you considered alternative methods to analyze the dynamic behavior of ResNets that do not rely on spin glass models?
In summary, while the paper tackles an intriguing problem and provides some valuable insights, its lack of clarity, questionable generalizability, and reliance on strong assumptions make it unsuitable for acceptance in its current form. Addressing these issues could significantly enhance the paper's impact and relevance.