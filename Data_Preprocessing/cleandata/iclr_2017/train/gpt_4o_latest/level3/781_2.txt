Review of the Paper
Summary
The paper introduces a novel approach to learning compact and interpretable distributed representations using a dynamic partition model. Unlike traditional methods that aggregate expert votes, this model assigns responsibility for each variable to the most reliable expert, dynamically adapting partitions based on active experts. The authors propose a smoothed version of the model for training and demonstrate its application to synthetic, MNIST, Weizmann horse, and Caltech motorcycle datasets. The approach aims to achieve sparse, disjoint expert responsibilities, with experiments showing promising results in reconstructing high-dimensional data using a small number of experts.
Decision: Reject
The paper is rejected primarily due to the following reasons:
1. Lack of Motivation and Clarity: The paper fails to clearly articulate the motivation, practical applications, and architectural details upfront, making it difficult to assess its significance and relevance.
2. Insufficient Scientific Rigor: The claims about expert variance and their disjoint responsibilities are not adequately substantiated, and the connection to dictionary learning—a key related area—is left unexplored.
Supporting Arguments
1. Unclear Exposition: The introduction and methodology sections are dense and fail to provide an intuitive understanding of the problem or the proposed solution. Key terms like "dynamic partitioning" and "expert variance" are not well-defined, and the exposition assumes familiarity with niche concepts without proper context.
   
2. Literature Gap: The paper does not adequately situate itself within the broader literature. While it mentions related works like products of experts and sparse dictionaries, the connection to dictionary learning and other representation learning paradigms is superficial. This omission weakens the theoretical foundation of the work.
3. Dataset Concerns: The use of the Weizmann horse dataset, which is small in size, raises concerns about the generalizability of the model. While the authors compare their approach to other methods on synthetic and MNIST datasets, the experiments lack sufficient diversity to validate the robustness of the proposed method.
4. Unsubstantiated Claims: Assertions about the model's ability to achieve disjoint expert responsibilities and its variance properties are not rigorously proven. The experiments, while visually compelling, do not provide quantitative metrics to support these claims.
Suggestions for Improvement
1. Clarify Motivation and Applications: The authors should clearly state the practical problem their model addresses and its potential applications. A comparison to existing methods in terms of computational efficiency, interpretability, or scalability would strengthen the paper.
2. Improve Exposition: Simplify the presentation of the model and provide intuitive explanations for key concepts. Including a diagram or visualization of the dynamic partitioning process would help readers grasp the methodology.
3. Expand Literature Review: Discuss the connection to dictionary learning and other relevant representation learning techniques in greater depth. This would situate the work more firmly within the existing body of research.
4. Strengthen Experiments: Use larger and more diverse datasets to demonstrate the model's generalizability. Provide quantitative metrics (e.g., reconstruction error, sparsity measures) to substantiate claims about the model's performance.
5. Address Variance Claims: Provide theoretical or empirical evidence to support the claims about expert variance and disjoint responsibilities. This could include a formal analysis or ablation studies.
Questions for the Authors
1. How does the proposed model compare to dictionary learning methods in terms of computational complexity and interpretability?
2. Can the authors provide quantitative metrics to validate the claim that the model achieves disjoint expert responsibilities?
3. How does the model handle scenarios where the factors of variation overlap significantly across variables?
4. What are the practical applications of this approach, and how does it perform in real-world tasks beyond reconstruction?
This feedback is intended to help the authors refine their work and address the identified shortcomings. While the paper introduces an interesting idea, it requires significant improvement in clarity, theoretical grounding, and experimental validation to meet the standards of the conference.