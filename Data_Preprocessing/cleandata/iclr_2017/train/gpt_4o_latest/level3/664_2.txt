Review of "Steganographic Generative Adversarial Networks (SGAN)"
Summary of Contributions
The paper introduces Steganographic Generative Adversarial Networks (SGAN), a novel application of GANs for generating image containers optimized for steganographic purposes. The authors propose a framework where the generator competes against both a discriminator and a steganalyzer to produce images that are not only visually realistic but also resistant to steganalysis. The paper demonstrates that SGAN-generated containers can significantly reduce the detection accuracy of steganalysis methods, including the HUGO algorithm. This work is thought-provoking and opens a new avenue for applying GANs in steganography, with meaningful benchmarks beyond subjective realism. The authors also explore the impact of random seed variability on steganalysis accuracy, providing valuable insights into the robustness of their approach.
Decision: Reject
While the paper is original and presents an exciting use case for GANs, it has several critical issues that prevent it from meeting the standards for acceptance. The primary concerns are the lack of clarity in methodology, insufficient experimental rigor, and unaddressed questions about practical applicability.
Supporting Arguments for Rejection
1. Clarity and Accessibility: The paper is difficult to follow, particularly for readers unfamiliar with steganography. Equation 4 introduces a non-differentiable black-box function, Stego(...), without adequately addressing how backpropagation is handled through it. This omission raises doubts about the feasibility of the proposed training process.
   
2. Experimental Concerns: The train/test split methodology is problematic. Using all 200k images for training SGAN while testing steganalysis on a separate set introduces inconsistencies and potential biases. The sensitivity of results to random seeds is acknowledged but not rigorously addressed, weakening the reliability of the findings.
3. Unsubstantiated Claims: The claim that SGAN can be tuned to deceive specific steganalysis algorithms is not convincingly demonstrated. The experiments focus solely on HUGO, leaving the generalizability of the approach unproven.
4. Practical Applicability: The paper lacks a clear explanation of how a trained SGAN would be used in real-world scenarios. A step-by-step workflow for practitioners is missing, which limits the accessibility and impact of the work.
Suggestions for Improvement
1. Clarify Methodology: Provide a detailed explanation of how backpropagation is performed through the Stego(...) function. If approximations or surrogate gradients are used, these should be explicitly described and justified.
2. Improve Experimental Rigor: Adopt consistent train/test splits and evaluate the sensitivity of results to random seeds more comprehensively. Consider testing SGAN on a broader range of steganographic algorithms beyond HUGO to strengthen claims of generalizability.
3. Enhance Practical Relevance: Include a detailed workflow or use case for practitioners unfamiliar with steganography. This could involve outlining how SGAN-generated containers would integrate into existing steganographic pipelines.
4. Address Contemporary GAN Challenges: Contemporary GANs often fail to fool discriminators effectively. The authors should explore whether combining a steganalyzer with a discriminator (e.g., S(x) = S(x) * D(x)) could make the task more challenging and improve the robustness of the approach.
Questions for the Authors
1. How is backpropagation handled through the Stego(...) function in Equation 4? Are surrogate gradients or other techniques used?
2. Why was the decision made to use all 200k images for training SGAN? How does this impact the generalizability of the results?
3. Can you provide evidence that SGAN can be tuned to deceive steganalysis algorithms other than HUGO? Have you tested it on WOW or S-UNIWARD as mentioned in your future work?
4. How would a practitioner unfamiliar with steganography use SGAN in a real-world application? Could you provide a step-by-step guide or workflow?
In conclusion, while the paper is innovative and has potential, significant revisions are required to improve its clarity, experimental rigor, and practical relevance.