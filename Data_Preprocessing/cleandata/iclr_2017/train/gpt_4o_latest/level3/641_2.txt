Review of the Paper
The paper proposes two methods for "wild variational inference," which aim to relax the requirement for tractable density functions in inference networks, enabling more flexible variational inference approaches. The authors build on prior work by Wang and Liu (2016) and Ranganath et al. (2016), introducing innovations such as using stochastic gradient Langevin dynamics (SGLD) as an inference network and leveraging kernelized Stein discrepancy (KSD) for optimization. The paper claims to improve the design of inference networks by automating step-size selection for SGLD, demonstrating its effectiveness on toy problems like Gaussian mixtures and Bayesian logistic regression.
Decision: Reject
The primary reasons for rejection are the incremental nature of the contributions and the lack of sufficient experimental validation. While the paper introduces some novel elements, such as the use of SGLD as an inference network and RKHS-based test functions, these innovations are not sufficiently distinct from prior work. Furthermore, the experiments are limited to toy problems and fail to address scalability, runtime, or performance on high-dimensional real-world datasets, which are critical for assessing the practical utility of the proposed methods.
Supporting Arguments:
1. Incremental Contribution: The concept of "wild variational inference" is not new and has been explored in prior work, such as Ranganath et al. (2016). The paper primarily reiterates existing methods and provides limited theoretical or empirical advancements. For instance, the use of SGLD as an inference network lacks novelty, as it closely resembles Salimans et al. (2015) with minor modifications to the training objective.
2. Scalability Issues: The kernel-based approach in Section 3.2, while analytically solving a problem from Ranganath et al. (2016), suffers from scalability challenges in high-dimensional settings. The paper does not propose advanced kernel designs or neural network parameterizations to address this limitation.
3. Limited Experiments: The empirical results are confined to toy problems, such as Gaussian mixtures and Bayesian logistic regression. The paper does not evaluate the methods on high-dimensional, real-world datasets, nor does it provide runtime comparisons or scalability analyses. This significantly limits the practical relevance of the proposed methods.
4. Misinterpretation of Prior Work: The authors appear to conflate handcrafted posterior approximations with algorithmic choices, leading to some misinterpretations of prior work on expressive variational families and inference networks.
Suggestions for Improvement:
1. Clarify Motivation and Novelty: The paper should better articulate its motivation and clearly distinguish its contributions from prior work. For example, how does the proposed use of SGLD as an inference network fundamentally differ from existing approaches?
2. Address Scalability: The kernel-based approach should be extended to handle high-dimensional settings. This could involve proposing advanced kernel designs or neural network parameterizations.
3. Expand Experiments: Include experiments on high-dimensional, real-world datasets to demonstrate the scalability and practical utility of the methods. Additionally, provide runtime comparisons with baseline methods.
4. Refine Terminology: The use of terms like "inference network" and "variational inference method" should align with established literature to avoid confusion.
Questions for the Authors:
1. How does the proposed Langevin inference network differ from Salimans et al. (2015) beyond the training objective? Could you clarify its novelty?
2. Have you considered alternative kernel designs or neural network parameterizations to address scalability issues in high-dimensional settings?
3. Why were the experiments limited to toy problems? Can the proposed methods handle real-world datasets, and if so, what are the expected runtime and performance trade-offs?
In summary, while the paper explores an interesting direction, it falls short in terms of novelty, scalability, and experimental rigor. Addressing these issues could significantly strengthen the work.