Review of the Paper
Summary of Contributions:
This paper consolidates recent literature on simple reading comprehension tasks, categorizing models into "aggregation readers" and "explicit reference readers," and explores their underlying structures and modifications. The authors present empirical evidence for the emergence of "predication structure" in aggregation readers, where hidden states are organized into predicate and constant symbol vectors. They also propose modifications, such as adding linguistic features, which yield state-of-the-art performance on the Who-did-What dataset. The paper provides a useful categorization of reading comprehension models, clarifies predicate structures, and introduces pointer annotation readers for non-anonymized datasets. This work is valuable for organizing the field and improving understanding of neural reader architectures.
Decision: Reject
Key Reasons:
1. Limited Scope and Focus: While the paper provides a useful categorization of models, its contributions are incremental and lack a clear focus. The discussion of predication structures is conceptually interesting but does not offer significant insights for future model development. Additionally, the CNN/Daily Mail dataset, a primary focus of the paper, has limited scope for performance improvements, as shown by prior work. The paper does not address more complex datasets requiring multi-hop inference, which limits its broader applicability.
2. Scattered Presentation: The paper's message is scattered, with multiple contributions that are not cohesively tied together. The exploration of predication structures, linguistic features, and dataset limitations feels fragmented, reducing the overall impact of the work.
Supporting Arguments:
- The categorization of models into aggregation and explicit reference readers is helpful in clarifying the landscape of reading comprehension research. However, this organizational effort might be better suited for a natural language processing-focused venue like TACL, where it could reach a more targeted audience.
- The empirical evidence for predication structures is intriguing but lacks practical implications for advancing model design. The proposed predicate structure is simple and does not address the challenges posed by more complex datasets or reasoning tasks.
- The paper does not engage with datasets requiring multi-hop inference or multi-evidence reasoning, such as MCTest or SQuAD, which are critical for advancing the field. This omission limits the relevance of the work to state-of-the-art challenges in reading comprehension.
Additional Feedback for Improvement:
1. Clarify Focus: The paper would benefit from a more focused narrative. For example, if the goal is to explore predication structures, the authors should delve deeper into their implications for model design and performance on diverse datasets.
2. Address Complex Datasets: Expanding the analysis to include datasets requiring multi-hop reasoning or more complex inference would make the work more impactful and relevant to current challenges in reading comprehension.
3. Improve Presentation: The paper's structure can be streamlined to better connect its contributions. For instance, the discussion of linguistic features and pointer annotations could be integrated into the broader narrative of improving aggregation readers.
4. Future Directions: The authors should explicitly discuss how their findings on predication structures and linguistic features can guide future model development, particularly for tasks requiring complex reasoning.
Questions for the Authors:
1. How does the proposed predication structure generalize to datasets requiring multi-hop reasoning or multi-evidence inference, such as MCTest or SQuAD?
2. Can the authors provide more concrete examples or visualizations of how the predication structure improves performance or interpretability in aggregation readers?
3. How do the proposed linguistic features and pointer annotations compare to state-of-the-art methods on more diverse datasets?
In summary, while the paper provides valuable organizational insights and intriguing empirical findings, its limited scope, scattered presentation, and lack of engagement with complex datasets make it unsuitable for acceptance in its current form.