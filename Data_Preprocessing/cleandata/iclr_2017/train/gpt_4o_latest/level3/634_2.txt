Review of the Paper
The paper introduces a novel Layerwise Origin-Target Synthesis (LOTS) method for generating diverse adversarial examples and analyzing the robustness of deep neural network (DNN) layers. The proposed approach serves three purposes: (1) visualizing internal feature representations of inputs at any layer of a DNN, (2) assessing the stability of learned features with respect to perturbations, and (3) generating diverse adversarial examples for improving model robustness through adversarial training. The authors demonstrate the utility of LOTS on two well-known networks, LeNet (for MNIST) and VGG Face (for face recognition), and claim that LOTS outperforms existing adversarial generation techniques in terms of robustness and performance improvements.
Decision: Reject
While the paper presents an interesting and original idea, the weaknesses in its analysis, experimental rigor, and presentation of results outweigh its contributions. The main reasons for rejection are the lack of depth in the analysis and insufficient experimental evidence to convincingly support the claims.
---
Supporting Arguments for the Decision:
1. Strengths:
   - The proposed LOTS method is conceptually sound and novel, offering a unique perspective on adversarial example generation by targeting intermediate layers.
   - Extending adversarial generation beyond classification tasks to applications like face recognition is an exciting direction.
   - The idea of visualizing layerwise perturbations to understand feature representations is valuable and aligns with the broader goal of improving interpretability in DNNs.
2. Weaknesses:
   - Shallow Analysis: The paper lacks a thorough exploration of key questions. For instance, while the authors claim that LOTS provides insights into layer robustness, they do not provide concrete metrics or detailed discussions to support this claim.
   - Limited Comparisons: The experimental results fail to comprehensively compare LOTS with state-of-the-art adversarial generation techniques. The authors mention methods like FGS and hot/cold but do not provide sufficient quantitative or qualitative evidence to demonstrate LOTS's superiority.
   - Unremarkable Visualizations: The visualizations presented are not particularly insightful or novel. They do not clearly illustrate how LOTS improves interpretability or understanding of DNNs compared to existing visualization techniques.
   - Lack of Meaningful Conclusions: While the paper introduces a novel idea, it does not draw actionable or insightful conclusions from its findings, leaving the reader uncertain about the broader implications of LOTS.
---
Suggestions for Improvement:
1. Deepen the Analysis: Provide a more detailed exploration of how LOTS contributes to understanding layer robustness. For example, quantify robustness using metrics or case studies and compare them across layers and models.
2. Strengthen Experimental Evidence: Include more comprehensive comparisons with existing adversarial generation methods, both in terms of adversarial quality (e.g., PASS scores) and downstream effects (e.g., robustness improvements).
3. Improve Visualizations: Make the visualizations more interpretable and meaningful. Highlight specific insights gained from LOTS that are not achievable with existing methods.
4. Draw Clearer Conclusions: Discuss the broader implications of LOTS, such as its potential applications in real-world systems or its role in advancing adversarial training techniques.
---
Questions for the Authors:
1. How does LOTS compare to state-of-the-art adversarial generation methods in terms of computational efficiency and scalability? Can it be applied to larger datasets or more complex models?
2. What specific insights about layer robustness were gained from using LOTS? Can you provide concrete examples or metrics to illustrate these insights?
3. The visualizations seem to lack interpretability. How do you envision LOTS being used by practitioners to better understand DNNs in practice?
4. Have you explored the impact of LOTS on adversarial robustness in real-world tasks, such as face verification or database matching? If so, what were the results?
By addressing these weaknesses and questions, the paper could significantly improve its impact and clarity.