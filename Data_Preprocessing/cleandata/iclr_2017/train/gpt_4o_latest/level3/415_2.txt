Review of the Paper
Summary of Contributions
The paper introduces OrthoReg, a novel regularization technique for convolutional neural networks (CNNs) that penalizes positive correlations between feature weights while leaving negative correlations unaffected. An alternative version of the regularizer penalizes all correlations. The key claim is that regularizing negatively correlated features hinders effective decorrelation, and the proposed method addresses this limitation. The authors validate their approach through experiments on benchmark datasets (MNIST, CIFAR-10, CIFAR-100, SVHN), showing modest improvements in test error rates over state-of-the-art models. The method is computationally efficient and particularly suited for fully convolutional neural networks. The paper also highlights the compatibility of OrthoReg with other regularization techniques like dropout and batch normalization.
Decision: Reject
While the paper presents an interesting idea and is well-executed in terms of experimental design, the contribution is incremental, and several issues limit its impact. The terminology and presentation introduce confusion, and the experimental results, while promising, lack sufficient statistical rigor and broader validation.
Supporting Arguments for Decision
1. Incremental Contribution: The proposed regularizer builds on existing feature decorrelation techniques, offering a modest improvement in performance. While the idea of excluding negative correlations is novel, the overall contribution is not groundbreaking.
2. Experimental Validation: The experiments demonstrate modest improvements, but the statistical significance of these results is questionable. For instance, the improvements on CIFAR-10 and CIFAR-100 are relatively small, and the global regularizer is only tested on MNIST, limiting its generalizability.
3. Terminology and Ambiguity: The use of terms like "local" and "global" to describe the regularizers is overly general and potentially misleading. Additionally, the inconsistent use of "features" to refer to both activations and filter weights creates unnecessary ambiguity.
4. Overlooked Aspects: The paper does not address the role of nonlinearities in achieving uncorrelated feature activations, which is a critical aspect of the problem. Furthermore, the assumption that positively correlated features are inherently undesirable is not sufficiently justified, as correlated features can be efficient in certain contexts (e.g., multi-bias approaches).
Additional Feedback for Improvement
1. Clarify Terminology: The authors should use more precise terms to describe the regularizers and consistently differentiate between activations and filter weights. This would improve the readability and clarity of the paper.
2. Broader Experimental Validation: The global regularizer should be tested on datasets beyond MNIST to assess its effectiveness. Additionally, statistical tests should be conducted to establish the significance of the reported improvements.
3. Nonlinearity Interactions: The impact of nonlinearities on feature decorrelation should be explicitly addressed, as this could influence the effectiveness of the proposed regularizer.
4. Role of Biases: The paper should discuss scenarios where positively correlated features might be beneficial and provide a more nuanced justification for penalizing them.
5. Regularization Dichotomy: The distinction between regularization methods that reduce capacity and those that do not seems arbitrary. A more rigorous definition of model capacity and its relationship to the proposed method would strengthen the paper.
Questions for the Authors
1. How do you justify the assumption that positively correlated features are always undesirable? Could there be scenarios where such correlations are beneficial?
2. Why was the global regularizer only tested on MNIST? Can you provide results on other datasets to demonstrate its broader applicability?
3. Have you considered the interaction between nonlinear activation functions and feature decorrelation? How might this impact the effectiveness of OrthoReg?
4. Can you provide statistical tests (e.g., p-values) to establish the significance of the reported improvements?
In summary, while the paper presents an interesting idea and is well-executed in parts, the incremental nature of the contribution, lack of clarity in terminology, and limited experimental validation make it unsuitable for acceptance in its current form. Addressing the outlined concerns could significantly strengthen the paper.