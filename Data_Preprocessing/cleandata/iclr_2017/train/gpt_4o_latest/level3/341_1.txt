Review
Summary of Contributions
This paper introduces a novel adversarial framework for unsupervised third-person imitation learning, addressing the challenge of training agents to replicate tasks demonstrated from a third-person viewpoint while performing them in a first-person perspective. The proposed approach leverages domain confusion and generative adversarial networks (GANs) to extract viewpoint-independent features, enabling policy transfer across domains. The authors demonstrate their method on three simulated environments (Point, Reacher, and Inverted Pendulum) and compare its performance against several baselines, including first-person imitation learning and standard reinforcement learning. The paper highlights the potential of third-person imitation learning to reduce the reliance on costly first-person demonstrations, which are often impractical to collect.
Decision: Reject
While the paper presents an innovative and promising approach, it falls short in providing sufficient experimental validation and clarity to support its claims. Key reasons for rejection are the lack of baseline comparisons, insufficient exploration of critical factors (e.g., gradual viewpoint changes), and incomplete empirical rigor (e.g., missing error bars and ablation studies).
Supporting Arguments
1. Novelty and Motivation: The paper addresses an important and underexplored problem in imitation learning, proposing a creative solution that combines GAN-based domain confusion with reinforcement learning. The motivation is well-articulated, and the work is positioned effectively within the literature.
2. Experimental Gaps: 
   - The paper lacks a baseline comparison where the model is trained with images from the same viewpoint. This would provide a clearer understanding of the added complexity introduced by third-person demonstrations.
   - The effect of gradually transitioning from third-person to first-person viewpoints is unexplored. This is a critical aspect of the problem and could offer insights into the robustness of the proposed method.
   - The experiments are limited to synthetic environments, which may introduce artifacts. Testing under more diverse conditions, such as blurred images or randomized environments, would strengthen the claims of generalization.
3. Empirical Rigor:
   - Error bars are missing in key figures (e.g., Fig. 4, 5, 6), making it difficult to assess the statistical significance of the results.
   - Ablation studies, particularly for the gradient flipping trick in Eqn. 5, are absent. This is necessary to validate the contribution of individual components of the framework.
4. Concerns About Generalization: The paper does not address the possibility that the network might memorize policies rather than learning generalizable features. Additional experiments, such as testing on unseen domains or tasks, would help alleviate this concern.
Suggestions for Improvement
1. Baseline Comparisons: Include a baseline where the model is trained with first-person images or from the same viewpoint as the test environment. This would help contextualize the performance of the proposed method.
2. Viewpoint Transition: Explore the effect of gradually changing the viewpoint from third-person to first-person during training. This could provide insights into the adaptability of the model.
3. Error Bars and Statistical Analysis: Add error bars to all performance plots and provide statistical significance tests to strengthen the empirical results.
4. Ablation Studies: Conduct ablation studies to isolate the contribution of key components, such as the domain confusion loss and the gradient flipping trick.
5. Real-World Validation: Extend the experiments to real-world scenarios or more complex environments to demonstrate the practical applicability of the approach.
6. Generalization Tests: Evaluate the model on unseen tasks or domains to ensure that it learns transferable features rather than memorizing specific policies.
Questions for Authors
1. How does the proposed method compare to a baseline trained with first-person data or from the same viewpoint? Can you provide quantitative results for this comparison?
2. Have you considered testing the model's robustness to noise, such as blurred images or randomized environmental conditions?
3. Could you clarify the role of the gradient flipping trick in Eqn. 5? How critical is it to the success of the method, and what happens if it is removed?
4. How would the model perform if the viewpoint transition from third-person to first-person were gradual rather than abrupt? Have you conducted any experiments in this direction?
In summary, while the paper introduces an exciting and novel approach, it requires stronger experimental validation and additional analysis to fully support its claims. Addressing the outlined concerns would significantly enhance its impact and credibility.