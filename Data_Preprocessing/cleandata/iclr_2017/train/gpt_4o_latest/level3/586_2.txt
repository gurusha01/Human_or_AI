Review of the Paper
Summary of Contributions
This paper investigates the Neural GPU model, focusing on its ability to generalize algorithmic tasks to inputs of arbitrary length. The authors propose two key improvements: curriculum training and increasing model size, both of which enhance the model's performance on tasks such as decimal arithmetic. The paper also identifies failure modes of the Neural GPU, particularly on highly structured inputs, and explores the impact of different input representations on performance. Through comprehensive experiments, the authors provide empirical insights into the Neural GPU's generalization capabilities and limitations, pushing the boundaries of learnable algorithms.
Decision: Reject  
While the paper presents valuable empirical findings and thorough experimentation, it lacks a coherent narrative and fails to provide sufficient theoretical or intuitive explanations for its key observations. This lack of clarity undermines the paper's potential impact and originality.
Supporting Arguments for Rejection
1. Lack of Coherent Message: The paper does not tie its findings into a unified narrative. For instance, while curriculum training is shown to be crucial, the authors fail to explain why this method is necessary or how it interacts with the Neural GPU's architecture. Similarly, the claim that larger models generalize better is presented without adequately addressing the possibility of underfitting in smaller models, which is a well-known phenomenon in machine learning.
   
2. Insufficient Theoretical Justification: Key claims, such as the equivalence of Neural GPUs to cellular automata and the necessity of O(n²) steps, are not rigorously justified. The analysis of O(n²) complexity overlooks the parallelism inherent in the Neural GPU, where certain operations could theoretically achieve O(log n) complexity. Additionally, the link between adversarial examples and algorithm learning is mentioned but not substantiated.
3. Limited Novelty: While the experiments are thorough, the insights provided are incremental rather than groundbreaking. The use of curriculum training and larger models to improve performance is not a novel contribution, as these techniques are well-established in the literature.
4. Empirical Gaps: The failure modes identified are intriguing but not deeply analyzed. For example, the authors note that the Neural GPU struggles with highly structured inputs but do not explore architectural modifications or training strategies to address this limitation.
Suggestions for Improvement
1. Strengthen Theoretical Foundations: Provide a rigorous analysis of the Neural GPU's computational complexity, particularly addressing the parallel nature of its operations. Additionally, clarify the claim that Neural GPUs are equivalent to cellular automata with stronger evidence or references.
2. Explain Curriculum Training: Offer a theoretical or intuitive explanation for why curriculum training is essential for the Neural GPU. This could involve analyzing the optimization landscape or the model's capacity to learn hierarchical representations.
3. Address Observed Limitations: Propose architectural modifications or alternative training strategies to mitigate the failure modes identified, such as issues with highly structured inputs or long carry operations.
4. Improve Clarity and Coherence: Reorganize the paper to present a more unified narrative. Clearly articulate the main contributions and how they advance the state of the art in algorithm learning.
5. Substantiate Introductory Claims: Provide evidence or references to support claims made in the introduction, such as the relationship between adversarial examples and algorithm learning.
Questions for the Authors
1. Why is curriculum training necessary for the Neural GPU, and how does it interact with the model's architecture or optimization process?
2. Can you provide a more detailed justification for the claim that Neural GPUs are equivalent to cellular automata?
3. How do you explain the observed failure modes, such as the inability to handle highly structured inputs or long carry operations? Have you considered architectural changes to address these issues?
4. Could the observed generalization of larger models simply be due to smaller models underfitting? How do you rule out this possibility?
In summary, while the paper provides useful empirical insights, its lack of theoretical rigor, novelty, and coherence limits its impact. Addressing these issues could significantly improve the paper's quality and contribution to the field.