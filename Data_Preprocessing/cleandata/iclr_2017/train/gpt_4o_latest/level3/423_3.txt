The paper proposes the Generative Multi-Adversarial Network (GMAN), an extension of GANs that incorporates multiple discriminators to improve training dynamics and sample quality. The authors argue that using multiple discriminators allows for more robust feedback to the generator, enabling training with the original minimax objective without the need for modifications. The paper explores a spectrum of discriminator roles, from "formidable adversary" (strongest discriminator) to "forgiving teacher" (soft-discriminator techniques), and introduces a novel metric, GMAM, to evaluate performance. Empirical results demonstrate that GMAN accelerates convergence, reduces variance, and produces higher-quality samples compared to standard GANs.
Decision: Accept
The paper makes a strong case for acceptance due to its innovative approach to GAN training and its demonstrated empirical benefits. The key reasons for this decision are:
1. Novelty and Contribution: The idea of using multiple discriminators in GAN training is innovative and addresses well-known challenges in GAN optimization, such as unstable training and mode collapse.
2. Empirical Validation: The results convincingly show that GMAN outperforms standard GANs in terms of convergence speed, stability, and sample quality across multiple datasets (MNIST, CIFAR-10, CelebA).
Supporting Arguments
1. Problem Tackled: The paper addresses the fundamental problem of unstable GAN training by introducing an ensemble of discriminators. This is a well-motivated problem, as GANs are notoriously difficult to train effectively.
2. Motivation and Literature Placement: The approach is well-grounded in the literature, building on prior work on adversarial training and GAN optimization. The authors provide theoretical insights and practical considerations for their multi-discriminator framework, situating their work within the broader context of GAN research.
3. Scientific Rigor: The claims are supported by both theoretical arguments and empirical evidence. The introduction of the GMAM metric provides a robust way to compare models, and the experiments are thorough, covering multiple datasets and variations of the proposed framework.
Additional Feedback for Improvement
1. Clarity on Soft-Discriminator Techniques: While the paper highlights the benefits of soft-discriminator techniques (e.g., averaging), the mathematical formulations could be explained more intuitively. For instance, the transition from max-based feedback to softmax-based feedback could benefit from more visual or conceptual explanations.
2. Scalability and Computational Overhead: The paper briefly mentions the computational cost of maintaining multiple discriminators but does not delve deeply into the trade-offs. A discussion on how the approach scales with increasing numbers of discriminators would strengthen the paper.
3. Ablation Studies: While the experiments are comprehensive, additional ablation studies isolating the impact of specific components (e.g., the role of λ in GMAN*) would provide deeper insights into the framework's effectiveness.
4. Broader Applications: The paper focuses on image generation tasks. Exploring the applicability of GMAN to other domains (e.g., text generation or reinforcement learning) could broaden its impact.
Questions for the Authors
1. How does the computational cost of GMAN scale with the number of discriminators, and how does this compare to standard GANs in terms of training time and resource requirements?
2. Could the authors provide more insights into the diversity among the discriminators? How critical is this diversity to the success of GMAN, and how is it ensured in practice?
3. How sensitive is the performance of GMAN to the choice of λ in the softmax formulation? Are there guidelines for selecting or tuning this parameter?
In conclusion, the paper presents a significant advancement in GAN research, with both theoretical and practical contributions. Addressing the feedback above would further enhance its clarity and impact.