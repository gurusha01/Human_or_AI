The paper introduces a novel Group Sparse Autoencoder (GSA) framework and integrates it into Convolutional Neural Networks (CNNs) to form Group Sparse Convolutional Neural Networks (GSCNNs) for question classification tasks. The authors claim that their approach leverages the hierarchical and overlapping structures in question categories and incorporates answer sets to refine question representations. The proposed method is evaluated on four datasets, demonstrating significant improvements over CNN baselines, particularly in multi-label classification tasks.
Decision: Reject
The primary reasons for rejection are the lack of sufficient empirical validation and the incremental nature of the contribution. While the idea of combining group-sparse autoencoders with CNNs is novel, the paper does not adequately justify the superiority of the proposed method through rigorous experimentation. Missing ablation studies and unclear baseline comparisons weaken the paper's claims.
Supporting Arguments:
1. Novelty and Motivation: The introduction of GSA as a neural network-based alternative to Sparse Group Lasso (SGL) is innovative, and the motivation to integrate it with CNNs for question classification is well-articulated. The use of answer sets to enhance question representations is a compelling idea, particularly for multi-label classification tasks. However, the novelty is incremental as it builds on existing concepts like sparse autoencoders and CNNs.
2. Empirical Validation: While the paper reports improvements over CNN baselines on four datasets, the experimental results lack depth. The absence of ablation studies makes it difficult to isolate the contributions of GSA and its integration with CNNs. Additionally, the baseline comparisons are not sufficiently detailed, leaving questions about the robustness and generalizability of the proposed method.
3. Writing Quality: The paper's writing is dense and occasionally unclear, which hampers comprehension. Key technical details, such as the initialization of the projection matrix and the training process, are not explained with sufficient clarity. Furthermore, the presentation of results could be improved to better highlight the method's strengths and limitations.
Suggestions for Improvement:
1. Ablation Studies: Include experiments that isolate the impact of GSA and its integration with CNNs. For example, compare GSCNNs with CNNs alone, GSA alone, and other sparse coding methods.
2. Baseline Comparisons: Provide more comprehensive and transparent comparisons with state-of-the-art methods. Clearly justify why CNNs are the only baseline considered and address potential limitations of this choice.
3. Clarity and Organization: Improve the paper's organization and writing to make it more accessible. For instance, provide a concise summary of the key contributions and results in the introduction.
4. Visualization and Analysis: While the visualization of GSA's behavior is a strength, additional qualitative analyses (e.g., case studies of misclassified questions) could provide deeper insights into the model's performance.
Questions for the Authors:
1. How does the proposed GSA compare to traditional sparse coding methods in terms of computational efficiency and scalability?
2. Can you provide more details on how the projection matrix is initialized and updated during training? How sensitive is the model to these initialization choices?
3. Why were ablation studies omitted, and how do you plan to address this in future work?
In conclusion, while the paper presents an interesting idea with potential, it falls short in empirical rigor and clarity, making it unsuitable for acceptance in its current form. Addressing the identified weaknesses could significantly enhance the paper's impact.