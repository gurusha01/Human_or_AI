The paper proposes a Neural Answer Construction Model specifically designed for answering non-factoid love-advice questions. It addresses two key challenges in existing QA systems: understanding word ambiguity in context and generating new answers rather than merely selecting from existing ones. The model incorporates semantic biases into word embeddings and optimizes sentence combinations using biLSTMs and an attention mechanism. Evaluations using a Japanese QA dataset demonstrate a 20% relative improvement in accuracy over the baseline (Tan et al., 2015). The paper also provides ablation studies to analyze the contributions of different components.
Decision: Accept  
The paper makes a novel and significant contribution to non-factoid QA by bridging the gap between answer selection and generation. The proposed model demonstrates substantial performance improvements and introduces innovative techniques, such as semantic bias incorporation and attention-based sentence combination. However, some aspects require clarification and further analysis.
Supporting Arguments:  
1. Novelty and Motivation: The paper tackles a well-motivated problem by addressing limitations in existing QA systems, such as context-dependent word ambiguity and the inability to generate new answers. The focus on love-advice questions is a practical application that highlights the model's utility.  
2. Technical Contributions: The integration of semantic biases, abstract scenario design, and attention mechanisms for sentence combination are novel and well-explained. These contributions advance the state-of-the-art in non-factoid QA.  
3. Empirical Validation: The model achieves a significant improvement over the baseline, with rigorous evaluations on a real-world dataset. Ablation studies further validate the importance of individual components.  
Suggestions for Improvement:  
1. Abstract Patterns: Clarify how abstract patterns for love-advice answers were determined and their specific impact on performance. The reliance on hand-designed patterns may limit generalizability to other domains.  
2. Generalization: Experimentally demonstrate the model's ability to handle out-of-domain questions to assess its broader applicability.  
3. Human Evaluation: Provide more details on the human evaluation process, including how expert ratings were combined. Additionally, consider evaluations with non-experts to reduce potential bias.  
4. Sentence Combination Analysis: Include explicit analysis of the impact of sentence combination optimization on overall performance.  
5. Model Discrepancy: Resolve the inconsistency in referring to QA-LSTM vs. Attentive LSTM as the current best method.  
Questions for the Authors:  
1. How were the abstract patterns for answer scenarios designed, and how transferable are they to other domains?  
2. Why does Attentive LSTM perform worse than QA-LSTM despite being labeled the best method in prior work?  
3. How does the model handle questions with no clear semantic bias or ambiguous categories?  
4. Could the model's attention mechanism be extended to handle longer and more complex answers?  
Overall, the paper addresses an important problem with innovative methods and demonstrates strong empirical results. While some clarifications and additional experiments are needed, the contributions justify acceptance.