Review of the Paper
Summary of Contributions
This paper proposes a novel neural network architecture utilizing competitive learning with recurrent neural networks (RNNs) to predict vehicle speed based on video and vehicle state inputs. The authors aim to extract potential driver intentions by training multiple RNNs in a competitive learning framework, where only the path with the minimum loss is updated during backpropagation. The proposed approach demonstrates a significant reduction in prediction error compared to a baseline architecture, with a reported squared error reduction to 1/25 of the conventional method. Additionally, the authors claim that the competitive learning mechanism can distinguish valid data from noisy or disturbance data, improving model robustness. The paper also explores the potential of competitive learning to extract multiple driving intentions, such as stopping, accelerating, or decelerating, which are validated on both training and test datasets.
Decision: Reject  
While the paper introduces an interesting competitive learning approach and demonstrates promising preliminary results, the lack of clarity in key methodological details and insufficient evidence to support some claims limit its contribution to the field. Below are the key reasons for this decision:
1. Unclear Methodology for Prediction Integration: The process for selecting the best-performing RNN at test time and integrating predictions is not well-explained. This raises concerns about the practical applicability of the approach in real-world driving scenarios.
2. Insufficient Evidence for Claims: The claim that the competitive learning framework extracts driver intentions is not rigorously validated. The paper would benefit from experiments on labeled datasets with explicit driver intention annotations (e.g., lane changes, stopping at stop signs).
3. Ambiguity in Performance Attribution: It is unclear whether the improved performance is due to the competitive learning scheme or simply the use of a larger model with more parameters. Comparative experiments with models of similar complexity are needed to isolate the contribution of the competitive framework.
Supporting Arguments
- The paper demonstrates a reduction in prediction error and provides visualizations of extracted driving intentions. However, these results are not sufficient to establish the robustness or generalizability of the approach.
- The competitive learning framework is novel in its application to supervised learning for driving behavior modeling, but the lack of comparison with alternative methods (e.g., inverse reinforcement learning or goal-based models) weakens the positioning of the work within the broader literature.
Suggestions for Improvement
1. Clarify Prediction Integration: Provide a detailed explanation of how the predictions from multiple RNNs are integrated at test time. Is the minimum-loss criterion used dynamically, or is there a fixed selection mechanism?
2. Rigorous Validation of Driver Intentions: Use labeled datasets with explicit driver intention annotations to validate the claim of extracting intentions. For example, scenarios involving lane changes, merging, or stopping at traffic signals could provide more concrete evidence.
3. Control for Model Complexity: Conduct experiments with models of similar parameter counts to isolate the impact of the competitive learning framework on performance.
4. Explore Alternative Approaches: Discuss and compare the proposed method with existing approaches for understanding driver intentions, such as inverse reinforcement learning or goal-based methods.
5. Generalization to Noisy Data: While the paper claims robustness to noisy data, this is not rigorously tested. Include experiments with artificially added noise to evaluate the model's performance under such conditions.
Questions for the Authors
1. How are the predictions from multiple RNNs integrated during test time? Is the minimum-loss criterion applied dynamically, or is there a fixed selection mechanism?
2. Can the authors provide evidence that the extracted driving intentions (e.g., stopping, accelerating) generalize to unseen scenarios or labeled datasets?
3. How does the competitive learning framework compare to simpler ensemble methods or models with similar parameter counts?
4. Could the authors elaborate on the role of pre-training in improving the performance of the competitive learning architecture? How sensitive is the model to the initialization of competitive layers?
In summary, while the paper presents an intriguing approach, addressing the above concerns and providing more rigorous validation would significantly strengthen its contribution.