Review of the Paper
Summary of Contributions
This paper introduces three training techniques for improving deep latent variable models (DLGMs) applied to sparse, high-dimensional data. These techniques include tf-idf weighting, iterative variational parameter optimization, and a novel method for interpretability improvement using Jacobian-based embeddings. The authors demonstrate that these methods address challenges in training DLGMs on sparse data, such as poor local optima and lack of interpretability, and evaluate their effectiveness on text, medical, and movie rating datasets. The interpretability method is particularly noteworthy, as it provides a means to extract meaningful embeddings from generative models, which are often criticized for their "black-box" nature. The paper provides both qualitative and quantitative evaluations, including perplexity improvements and embedding performance on semantic similarity tasks.
Decision: Reject
While the paper presents interesting ideas, the contributions are incremental and lack sufficient novelty or rigor to warrant acceptance. The primary reasons for rejection are:
1. Limited Novelty: Both tf-idf weighting and iterative optimization are well-known techniques in the literature. Their application to DLGMs is sensible but not groundbreaking.
2. Weak Quantitative Evidence for Interpretability: The interpretability improvement via Jacobian embeddings is intriguing, but the quantitative results are not compelling enough to demonstrate its utility compared to existing methods.
Supporting Arguments
1. Novelty and Motivation: 
   - The use of tf-idf weighting is a straightforward adaptation of a standard technique in information retrieval. While its utility for sparse data is clear, it does not represent a significant methodological advance.
   - Iterative variational parameter optimization is a reasonable approach, but it has been explored in prior work (e.g., Salakhutdinov & Larochelle, 2010; Hjelm et al., 2016). The paper's main contribution here is demonstrating its effectiveness on specific datasets, which is more of an empirical finding than a conceptual breakthrough.
   - The interpretability method using Jacobian embeddings is novel but underdeveloped. The qualitative results are promising, but the quantitative evaluations (e.g., on word similarity tasks) show only marginal improvements over baselines.
2. Empirical Rigor:
   - The paper provides extensive experiments on diverse datasets, which is commendable. However, the quantitative results for interpretability (e.g., Spearman rank correlations on WordSim353 and SCWS) are not competitive with state-of-the-art embedding methods that leverage local context.
   - The perplexity improvements from iterative optimization are dataset-dependent, with limited gains on smaller datasets. This raises questions about the generalizability of the approach.
3. Clarity and Placement in Literature:
   - The paper is well-written and places its contributions in the context of prior work. However, it does not sufficiently differentiate its methods from existing techniques, particularly for iterative optimization and tf-idf weighting.
Suggestions for Improvement
1. Strengthen the Novelty: The paper would benefit from a deeper exploration of the Jacobian-based interpretability method. For example, can the embeddings be used for downstream tasks like classification or clustering? How do they compare to embeddings derived from other generative models (e.g., Word2Vec, BERT) in more challenging benchmarks?
2. Expand Quantitative Evaluations: The interpretability results should be supported by more rigorous quantitative experiments. For example, the authors could evaluate the embeddings on tasks like analogy completion or contextual similarity in a more competitive setting.
3. Broaden the Scope of Applications: While the paper focuses on sparse data, it would be interesting to see whether the proposed techniques generalize to other types of data, such as dense or structured datasets.
4. Clarify Limitations: The paper should explicitly discuss the limitations of its methods, such as the computational cost of iterative optimization or the sensitivity of Jacobian embeddings to model hyperparameters.
Questions for the Authors
1. How do the Jacobian embeddings perform on downstream tasks (e.g., classification, clustering) compared to embeddings from other generative or discriminative models?
2. Can the interpretability method be extended to incorporate local context, which is known to improve embedding quality for tasks like word similarity?
3. What is the computational overhead of iterative optimization, and how does it scale with dataset size and model complexity?
In summary, while the paper addresses an important problem and presents some interesting ideas, the contributions are incremental, and the empirical evidence is insufficient to justify acceptance. Strengthening the interpretability method and providing more rigorous evaluations could make this work more impactful in the future.