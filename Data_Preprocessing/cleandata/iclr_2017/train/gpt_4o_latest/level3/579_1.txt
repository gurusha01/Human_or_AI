Review of the Paper
Summary of Contributions:
The paper proposes TreNet, a hybrid neural network architecture designed for predicting local trends in time series data. The model combines convolutional neural networks (CNNs) for extracting local features from raw data and long short-term memory networks (LSTMs) for capturing long-range dependencies in historical trends. A feature fusion layer integrates these representations to predict the slope and duration of local trends. The authors evaluate TreNet on three real-world datasets (Household Power Consumption, Gas Sensor, and Stock Transactions) and demonstrate that it outperforms baselines, including CNN, LSTM, Support Vector Regression (SVR), and Hidden Markov Models (HMM). The paper highlights the relevance of local trend prediction to practical applications such as financial markets and energy management, distinguishing it from traditional time series forecasting tasks.
Decision: Reject
While the paper introduces an interesting hybrid architecture and addresses a relevant problem, it falls short in several critical areas, including experimental rigor, justification of design choices, and placement within the broader literature. These limitations make the work unsuitable for acceptance at this time.
Supporting Arguments for the Decision:
1. Strengths:
   - The problem setting, focusing on local trend prediction rather than point forecasting, is thoughtful and relevant to real-world applications.
   - The hybrid architecture of TreNet is intuitive and leverages the complementary strengths of CNNs and LSTMs effectively, assuming the validity of the underlying assumptions.
   - The authors have addressed prior reviewer feedback by adding new experiments and improving baselines (e.g., ConvNet → LSTM).
2. Weaknesses:
   - Task Justification: The task formulation lacks strong justification. The authors presuppose the value of explicitly modeling trends (slope and duration) without demonstrating why these cannot be derived from standard time series forecasting methods.
   - Architecture Justification: The choice of architecture (e.g., CNN → LSTM vs. LSTM → CNN) is not well-motivated. Alternative configurations, such as raw → ConvNet → LSTM or {raw → ConvNet, trends} → MLP, are omitted, weakening the experimental rigor.
   - Baseline Comparisons: Key baselines, such as ConvNet → LSTM and other hybrid configurations, are missing. This omission raises concerns about whether TreNet's performance gains are genuinely attributable to its architecture or simply due to insufficient baseline tuning.
   - Independent Tuning: The identical architectures and hyperparameters for CNNs and LSTMs across TreNet and its baselines may disadvantage the baselines, as these models may require different configurations for optimal performance.
   - Literature Gap: The paper overlooks relevant literature on financial time series modeling, including probabilistic models and Gaussian processes, which could provide alternative approaches for trend prediction.
Additional Feedback for Improvement:
1. Experimental Rigor: 
   - Include additional baselines, such as raw → ConvNet → LSTM and {raw → ConvNet, trends} → MLP, to strengthen the experimental comparisons.
   - Test pure time series forecasting baselines (e.g., ARIMA, Prophet) to evaluate whether trends can be effectively derived without explicit modeling.
   - Provide ablation studies to assess the individual contributions of CNN, LSTM, and the feature fusion layer.
2. Task and Architecture Justification:
   - Justify why explicit modeling of trends (slope and duration) is necessary and cannot be achieved through standard forecasting methods.
   - Explain why the chosen architecture (CNN → LSTM) is superior to alternative configurations.
3. Literature Review:
   - Expand the related work section to include financial time series modeling literature, such as probabilistic models and Gaussian processes, to better position the work within the broader context.
4. Trend Extraction Validation:
   - Demonstrate the robustness of the trend extraction process (e.g., piecewise linear segmentation) and its impact on prediction performance.
Questions for the Authors:
1. Why were key baselines, such as raw → ConvNet → LSTM and {raw → ConvNet, trends} → MLP, omitted? How would TreNet compare to these configurations?
2. How does the performance of TreNet vary with different trend extraction methods? Is the proposed method robust to changes in segmentation thresholds?
3. Can the authors provide empirical evidence to justify the explicit modeling of trends (slope and duration) over standard forecasting methods?
4. How does the hybrid architecture generalize to multivariate time series or other domains beyond the datasets tested?
In summary, while the paper introduces a promising hybrid architecture for local trend prediction, it requires significant refinement in experimental design, architectural justification, and literature placement before being suitable for publication. The authors are encouraged to address these issues and consider resubmitting to a future conference.