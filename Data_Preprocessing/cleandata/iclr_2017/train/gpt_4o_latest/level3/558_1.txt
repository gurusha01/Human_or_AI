Review of the Paper
Summary of Contributions
This paper proposes a novel approach to extend count-based exploration methods to high-dimensional and continuous state spaces by leveraging hash functions. The authors demonstrate that simple hash-based discretization of states can provide an effective exploration bonus, achieving near state-of-the-art performance on several deep reinforcement learning (RL) benchmarks, including control tasks and Atari games. The paper also explores the use of learned hash functions via autoencoders to improve performance in image-based environments. The authors analyze the impact of hash function granularity and domain-specific feature engineering, showing that appropriate design choices can significantly enhance exploration performance. The method is computationally efficient and serves as a simple yet powerful baseline for exploration in sparse-reward environments.
Decision: Reject
While the paper presents an interesting and computationally efficient approach, it falls short in terms of novelty and empirical performance. The proposed method demonstrates limited improvements over prior approaches and underperforms compared to state-of-the-art methods like VIME in control tasks. Additionally, the scalability of the hashing approach to more complex environments is questionable, and the paper does not convincingly argue why hashing is preferable to readily available density estimation methods like PixelCNN, VAEs, or GANs.
Supporting Arguments
1. Strengths:
   - The paper provides a simple and computationally efficient baseline for exploration in RL, which is a valuable contribution for practitioners.
   - The experiments confirm the effectiveness of count-based exploration with proper density estimators, aligning with prior findings by Bellemare et al. (2016).
   - The approach shows promise in challenging tasks like Montezuma's Revenge, especially with domain-specific feature engineering.
2. Weaknesses:
   - The method's performance is inconsistent, with limited improvements over prior approaches and underperformance compared to VIME in control tasks.
   - The scalability of hashing to more complex environments is not well addressed. The reliance on hash functions may lead to suboptimal generalization in high-dimensional, visually complex tasks.
   - The argument that hashing is as practical as learning-based density estimators is not sufficiently substantiated. The paper does not provide a thorough comparison with methods like PixelCNN or VAEs, which are widely used for density estimation in RL.
   - The novelty of the approach is limited, as it primarily adapts existing ideas (e.g., count-based exploration and hashing) without introducing fundamentally new concepts.
Suggestions for Improvement
1. Empirical Comparisons: Provide a more comprehensive comparison with state-of-the-art exploration methods, including learning-based density estimators (e.g., PixelCNN, VAEs, GANs). This would help clarify the advantages and limitations of the proposed method.
2. Scalability Analysis: Address the scalability of hashing to more complex environments explicitly, possibly through experiments on more challenging benchmarks or theoretical analysis.
3. Ablation Studies: Include more detailed ablation studies to isolate the contributions of different components, such as static versus learned hash functions and the impact of hyperparameter choices.
4. Theoretical Insights: Strengthen the theoretical justification for using hash functions over other density estimation methods, particularly in terms of computational efficiency and generalization.
5. Clarity in Writing: Improve the clarity of the paper by reducing redundancy and providing more concise explanations of the methodology and experimental setup.
Questions for the Authors
1. How does the proposed method compare to learning-based density estimators like PixelCNN or VAEs in terms of computational cost and performance?
2. Can the authors provide more insights into the scalability of hashing to environments with highly complex state spaces, such as 3D visual environments or continuous control tasks with high-dimensional observations?
3. What are the limitations of the proposed method in terms of generalization across different types of RL tasks, and how might these be addressed in future work?
In conclusion, while the paper offers an interesting perspective on extending count-based exploration to high-dimensional spaces, it lacks sufficient novelty and empirical rigor to warrant acceptance in its current form. Addressing the above concerns could significantly strengthen the contribution and impact of the work.