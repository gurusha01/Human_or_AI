Review of the Paper
The paper proposes a semi-supervised learning framework, termed Neural Graph Machines (NGM), which combines label propagation and neural network training objectives to leverage both labeled and unlabeled data. The authors claim that the method is scalable, versatile, and effective across diverse tasks, including multi-label classification on social graphs, text categorization, and semantic intent classification. The paper introduces a graph-augmented training objective, demonstrates its applicability to various neural network architectures, and explores the use of adjacency matrices as inputs when node-level features are unavailable.
Decision: Reject
The primary reasons for rejection are the lack of novelty and insufficient empirical validation. The proposed method is nearly identical to the semi-supervised framework introduced by Weston et al. (2008), with minimal modifications. The paper fails to provide significant theoretical or methodological advancements to justify its contribution. Additionally, the experimental results are not compelling enough to establish the superiority of the proposed approach over prior work.
Supporting Arguments
1. Lack of Novelty: The proposed method essentially rebrands an existing algorithm (Weston et al., 2008) with minor adjustments, such as using adjacency matrices as inputs and combining multiple graphs. These changes, while practical, do not constitute a substantial contribution to the field. The authors themselves acknowledge the close connection to prior work.
2. Insufficient Baselines: The experiments lack robust comparisons with state-of-the-art methods. For instance, in text classification, the proposed method fails to outperform the baseline established by Zhang et al. (2015). The semantic intent classification experiment is conducted on a custom dataset, limiting its generalizability and broader relevance.
3. Empirical Weaknesses: While the BlogCatalog experiment shows some promise, the reliance on adjacency matrices as inputs is not novel and has been explored in prior work. The text classification and semantic intent experiments do not convincingly demonstrate the advantages of the proposed method.
Additional Feedback
1. Experimental Design: The paper should include more comprehensive baselines, such as recent graph neural network models (e.g., GraphSAGE, GCNs), to contextualize the performance of the proposed method. Additionally, the semantic intent classification experiment should be validated on publicly available datasets to enhance reproducibility and impact.
2. Clarity and Positioning: The paper could benefit from a clearer articulation of its contributions relative to prior work. The authors should explicitly highlight the novelty of their approach and provide a stronger theoretical justification for their modifications.
3. Graph Construction: The reliance on word2vec-based adjacency matrices for text classification raises questions about the robustness of the graph construction process. The authors should explore alternative graph construction methods or provide an analysis of how graph quality impacts performance.
Questions for the Authors
1. How does the proposed method compare to more recent graph-based semi-supervised learning methods, such as Graph Convolutional Networks (GCNs) or Graph Attention Networks (GATs)?
2. Can the authors provide more details on the scalability of the method, particularly for very large graphs with millions of nodes and edges?
3. How sensitive is the performance to the choice of hyperparameters (e.g., Î± values) and graph construction methods? Have the authors conducted an ablation study to analyze these factors?
In conclusion, while the paper addresses an important problem and demonstrates some practical applications, it lacks the novelty and empirical rigor required for acceptance at a top-tier AI conference. The authors are encouraged to refine their contributions, strengthen their experimental validation, and provide a clearer differentiation from prior work.