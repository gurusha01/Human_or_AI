Review of the Paper "LR-GAN: Layered Recursive Generative Adversarial Networks"
Summary of Contributions
This paper introduces LR-GAN, a novel generative adversarial network that explicitly models the layered structure of images by generating backgrounds and foregrounds separately and recursively. The method incorporates a spatial transformer to handle object appearance, shape, and pose, enabling the generation of contextually coherent images. The authors claim that LR-GAN produces more natural and human-recognizable images compared to DCGAN, with sharper boundaries and better object-background separation. The model is unsupervised and trained end-to-end, with experiments conducted on datasets like MNIST, CIFAR-10, and CUB-200. The paper also proposes new evaluation metrics, Adversarial Accuracy and Adversarial Divergence, to assess the quality of generated images.
Decision: Reject
While the paper presents an interesting approach to image generation and decomposition, several critical issues limit its acceptance. The main reasons for rejection are the lack of clarity in key experimental details and insufficient justification for design choices, which undermine the scientific rigor of the work.
Supporting Arguments
1. Strengths:
   - The proposed method's ability to decompose images into background and foreground layers, producing crisp masks with minimal spurious elements, is a significant contribution. This is particularly impressive given the unsupervised nature of the model.
   - The use of spatial transformers and explicit modeling of transformations (scaling, rotation, translation) adds interpretability and flexibility to the generated outputs.
   - The qualitative results, especially on CUB-200, demonstrate the model's potential for generating clear and contextually relevant images.
2. Weaknesses:
   - Unclear Mask Representation: The paper does not clarify whether the masks are binary or use alpha blending. This is critical for understanding how the model handles transitions between foreground and background.
   - Redundancy in Decomposition: As highlighted in Figure 3, the decomposition quality appears irrelevant for the final image quality. The paper does not adequately justify why decomposition is necessary if it does not significantly impact the final results.
   - Evaluation Metrics: While Adversarial Accuracy and Adversarial Divergence are novel, they could theoretically favor GANs that produce images unrecognizable to humans but identifiable by classifiers. This limitation is not addressed.
   - Minimal Impact of Transformation Layer: The ablation study suggests that the transformation layer primarily scales down masked objects, raising questions about its overall contribution to the model.
   - Lack of Clarity in Experiments: The AMT evaluation experiment is poorly explained, particularly the rationale for using L2-minimized nearest-neighbor matches over random pairs. Additionally, Table 1 does not evaluate Adversarial Divergence for real images, and details on confidence intervals and multiple runs are missing.
   - Dataset Relevance: The foreground-background decomposition is irrelevant for datasets like MNIST, which undermines the generalizability of the approach.
Additional Feedback
1. Foreground Prediction vs. Masking: The authors should discuss the trade-offs between predicting the foreground directly versus using a mask. This would help clarify the necessity of the mask generator.
2. Figure 9 Clarifications: The paper should explain the 3rd and 6th columns in Figure 9 and confirm whether the composed images are as poor as suggested.
3. Contextual Generation: While the results in Figure 17 are promising, the authors should provide quantitative evidence to support the claim that the model captures contextual dependencies between layers.
4. Comparison with Baselines: The comparison with DCGAN is insufficient. The authors should include more recent baselines and demonstrate the advantages of LR-GAN quantitatively and qualitatively.
5. Potential Applications: The paper briefly mentions potential applications in segmentation and object detection but does not explore these in depth. A more thorough analysis would strengthen the paper's impact.
Questions for Authors
1. Is the mask binary or does it use alpha blending? How does this choice affect the generated images?
2. Why is decomposition quality irrelevant for the final results, as suggested by Figure 3? Could the model achieve similar results without decomposition?
3. Why are L2-minimized nearest-neighbor matches used in the AMT study instead of random pairs? How does this choice affect the evaluation?
4. Can you provide details on the confidence intervals and standard deviations for the metrics in Table 1? Were these results averaged over multiple runs?
In summary, while the paper introduces an innovative approach to image generation, the lack of clarity in experimental details, insufficient justification for design choices, and limited evaluation weaken its overall contribution. Addressing these issues could significantly improve the paper's quality for future submissions.