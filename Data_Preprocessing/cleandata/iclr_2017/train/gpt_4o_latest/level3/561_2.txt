Review
Summary of Contributions
The paper proposes a novel approach to constructing a "tree of life" using hierarchical clustering based on features extracted from pretrained convolutional neural networks (CNNs). It leverages the high-level representations learned by CNNs to quantify visual similarity among species and uses three methods—Approximation Central Point (ACP), Minimum Spanning Tree (MST), and Multidimensional Scaling (MDS)—to construct phylogenetic trees. The authors evaluate their approach on small datasets, including fish, canine, and vehicle species, and claim that the results are competitive with human-level performance in visually clustering species. The paper also explores the potential of CNNs for non-biological hierarchical clustering, such as vehicles, and highlights the insights this work provides into deep neural network representations.
Decision: Reject  
Key Reasons:
1. Limited Technical Novelty: The proposed method relies heavily on standard techniques, such as pretrained CNNs and existing clustering algorithms, without introducing significant methodological innovation.
2. Insufficient Experimental Rigor: The experiments are conducted on small datasets with limited diversity, and the results are primarily qualitative, lacking robust quantitative evaluation or statistical significance.
Supporting Arguments
1. Problem Motivation and Placement in Literature: While the idea of leveraging CNN features for phylogenetic tree construction is interesting, the paper does not adequately address the limitations of using visual similarity as a proxy for biological relationships. The choice of WordNet as a reference tree is particularly problematic, as it is a lexical database and not designed for biological taxonomy. This undermines the biological relevance of the proposed method.
   
2. Experimental Design and Claims: The experiments are conducted on a narrow set of categories (e.g., fish, canines, vehicles), which limits the generalizability of the results. The lack of quantitative metrics (e.g., accuracy, precision-recall, or statistical tests) makes it difficult to assess the validity of the claims. While the authors state that MDS performs best among the three methods, this conclusion is not supported by rigorous analysis.
3. Technical Contributions: The paper primarily applies existing techniques (e.g., pretrained CNNs, cosine similarity, clustering methods) without substantial innovation. The use of CNN features for clustering is not new, and the paper does not provide significant advancements in methodology or theory.
Suggestions for Improvement
1. Expand Dataset and Evaluation: Conduct experiments on larger and more diverse datasets, including species with well-documented phylogenetic relationships. Incorporate quantitative metrics to evaluate the quality of the constructed trees.
2. Address Biological Relevance: Replace WordNet with a more suitable reference tree, such as one based on genetic or evolutionary data, to improve the biological validity of the results.
3. Clarify Novelty: Clearly articulate the methodological contributions and how they differ from existing work. For example, explore whether the proposed method offers advantages over traditional phylogenetic tree construction techniques.
4. Broaden Scope of Applications: While the vehicle tree is an interesting extension, the paper could explore additional domains (e.g., medical imaging or gene expression data) to demonstrate broader applicability.
5. Improve Presentation: Provide more detailed explanations of the methods and include visualizations or quantitative comparisons to support claims about the superiority of MDS over other methods.
Questions for the Authors
1. Why was WordNet chosen as the reference tree, given its known limitations for biological relationships? Could a more biologically relevant dataset be used?
2. How does the proposed method compare quantitatively to existing phylogenetic tree construction techniques, such as those based on genetic similarity?
3. Could the method be extended to incorporate non-visual features, such as genetic or textual data, to improve its biological relevance?
4. What specific insights into CNN representations were gained from this work, and how do they advance our understanding of deep learning?
In summary, while the paper explores an intriguing application of CNNs, it falls short in terms of technical novelty, experimental rigor, and biological relevance. Addressing these issues could significantly strengthen the contribution.