The paper proposes a novel Dense-Sparse-Dense (DSD) training strategy aimed at improving the optimization performance of deep neural networks (DNNs) by alternating between dense and sparse network training. The authors claim that DSD enhances model accuracy across various architectures, including CNNs, RNNs, and LSTMs, while maintaining the same network architecture during inference. The key contributions include improved accuracy through escaping saddle points, robustness to noise via sparsity, and richer representations from symmetry breaking. The method also highlights the redundancy in current training schemes, suggesting potential for more efficient training processes.
Decision: Accept  
The paper is recommended for acceptance due to its innovative approach and demonstrated applicability across diverse architectures and tasks. While the accuracy improvements are modest (2-3%), the method introduces a compelling framework for leveraging sparsity and re-densification to enhance optimization, which could inspire further research in model training and compression.
Supporting Arguments:  
1. Novelty and Motivation: The DSD training strategy is well-motivated and addresses a critical challenge in deep learningâ€”balancing model capacity and generalization. By iteratively pruning and re-densifying, the method provides a unique mechanism to escape saddle points and achieve better minima, as supported by empirical results.  
2. Applicability and Generalization: The experiments span a wide range of architectures (GoogLeNet, VGG-16, ResNet, NeuralTalk, DeepSpeech) and tasks (image classification, caption generation, speech recognition), demonstrating the method's broad applicability.  
3. Scientific Rigor: The paper provides extensive empirical evidence, including statistical significance tests, to validate the improvements achieved by DSD. The results are consistent across datasets and architectures, reinforcing the robustness of the method.  
Additional Feedback:  
1. Computational Cost: While the paper mentions that DSD incurs no inference overhead, the additional training phases (sparse and re-dense) increase computational cost. A more detailed analysis of the resource-performance trade-offs would strengthen the paper.  
2. Iterative DSD: The experiments suggest diminishing returns with repeated DSD iterations. A deeper exploration of the theoretical or practical limits of iterative DSD could provide valuable insights.  
3. Comparison with Alternatives: Although the paper compares DSD with conventional fine-tuning and learning rate decay, a more comprehensive comparison with other regularization techniques (e.g., dropout, distillation) would contextualize its contributions better.  
Questions for the Authors:  
1. How does the computational cost of DSD training compare to other regularization methods, such as dropout or weight decay, in terms of training time and resource usage?  
2. Can the sparsity ratio in the sparse phase be dynamically adjusted during training to optimize performance further?  
3. Are there specific architectures or tasks where DSD is less effective, and if so, why?  
Overall, the DSD training strategy is a promising contribution to the field, offering a novel perspective on improving optimization and generalization in deep learning. Addressing the above feedback could further enhance the paper's impact.