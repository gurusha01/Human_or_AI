This paper introduces MusicNet, a novel, large-scale dataset comprising over 30 hours of annotated classical music, which represents a significant contribution to the field of Music Information Retrieval (MIR). MusicNet addresses a critical gap in the MIR community by providing a publicly available dataset with dense temporal labels, enabling the application of modern machine learning techniques to music research. The dataset's scale and diversity, including 11 instruments and 10 composers, make it a valuable resource for training and evaluating supervised learning models. The authors also present baseline experiments on pitch detection, demonstrating the utility of MusicNet for low-level feature learning.
Decision: Accept.  
The primary reason for acceptance is the introduction of MusicNet, a unique and impactful dataset that has the potential to drive significant advancements in MIR. While the experimental results are relatively modest, the dataset itself is a major contribution that will benefit the research community.
Supporting Arguments:  
1. Novelty and Utility: MusicNet fills a critical gap in MIR by providing a large, labeled dataset comparable in scope to ImageNet in computer vision. This resource has the potential to catalyze progress in applying deep learning to music research, overcoming the limitations of smaller, less diverse datasets.  
2. Clarity and Rigor: The paper is well-written and provides a clear description of the dataset's construction, scope, and potential applications. The experiments are rigorously conducted, with appropriate evaluation metrics and analysis.  
3. Community Impact: The public availability of MusicNet ensures accessibility and reproducibility, making it a valuable resource for the broader MIR and machine learning communities.
Additional Feedback for Improvement:  
1. Expand Experimental Scope: The current experiments focus solely on pitch detection, a relatively simple task that does not fully showcase the dataset's potential. Future work should include diverse tasks, such as polyphonic transcription, instrument recognition, or high-level tasks like music genre classification, to highlight the dataset's versatility.  
2. Comparison with Prior Work: While the comparison of learned features with prior studies is favourable, it is limited to low-level tasks. A more comprehensive analysis, including higher-level tasks, would strengthen the paper's claims about MusicNet's utility.  
3. Dataset Bias: The dataset is skewed towards certain composers (e.g., Beethoven) and instruments (e.g., solo piano). While this is acknowledged, the authors could provide suggestions or tools for augmenting the dataset to address these biases.
Questions for the Authors:  
1. Can you elaborate on how MusicNet could be extended or augmented to support tasks beyond pitch detection, such as music generation or emotion recognition?  
2. How does the dataset handle variations in recording quality and microphone conditions, and how might these variations impact model training?  
3. Have you considered providing pre-trained models or benchmarks for high-level MIR tasks to encourage adoption of MusicNet?
In conclusion, while the experimental results are not groundbreaking, the introduction of MusicNet is a substantial and valuable contribution that justifies acceptance. The dataset's potential to advance MIR research is immense, and the paper lays a solid foundation for future work in this area.