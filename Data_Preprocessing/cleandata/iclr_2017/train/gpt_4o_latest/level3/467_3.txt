The paper introduces Bidirectional Generative Adversarial Networks (BiGANs), an extension of GANs that incorporates an inference path via an encoder and a joint latent/data space discriminator. The authors claim that BiGANs enable unsupervised feature learning by learning an inverse mapping from data to latent space, which can be useful for downstream supervised tasks. The paper provides theoretical guarantees that the encoder and generator are approximate inverses and evaluates the learned features on tasks like ImageNet classification and PASCAL VOC benchmarks. While the framework is elegant and theoretically grounded, the empirical results, though competitive, fall short of state-of-the-art performance.
Decision: Reject
Key Reasons:
1. Misalignment of Focus: The paper emphasizes GAN theory over its primary goal of demonstrating the utility of BiGANs for unsupervised feature learning. This misalignment detracts from the clarity and impact of the narrative.
2. Empirical Limitations: The results, while promising, are not state-of-the-art, and concerns about incomplete model convergence and potential nearest neighbor retrieval (as suggested by Figure 4) raise questions about the robustness of the learned features.
Supporting Arguments:
- The theoretical contributions are solid, showing that BiGANs share many properties with GANs while extending them to the joint latent/data space. However, the practical benefits of these properties remain unclear due to convergence issues.
- The empirical evaluation is thorough, covering both simple datasets (e.g., MNIST) and complex ones (e.g., ImageNet). However, the performance gap compared to contemporary self-supervised methods suggests room for improvement in training stability and architecture design.
- The potential issue of BiGANs performing nearest neighbor retrieval rather than meaningful feature learning, as highlighted in Figure 4, undermines the claim of learning semantically rich features.
Additional Feedback:
1. Reproducibility: While the paper is well-written, additional details on training specifics (e.g., learning rates, initialization strategies) would enhance reproducibility.
2. Clarity in Results: Highlighting the best performance numbers in Tables 2 and 3 would improve the clarity and accessibility of the empirical results.
3. Addressing Convergence: The authors should explore strategies to improve model convergence, as incomplete convergence limits the practical utility of BiGANs.
4. Feature Learning Validation: A more rigorous analysis of the learned features, beyond nearest neighbor retrieval, would strengthen the claim of meaningful feature learning.
Questions for Authors:
1. Can you clarify the extent to which the encoder and generator achieve the theoretical inversion properties in practice? Are there quantitative metrics to evaluate this?
2. What steps were taken to address the potential issue of nearest neighbor retrieval in Figure 4? Could alternative visualizations or metrics provide stronger evidence of meaningful feature learning?
3. How sensitive are the results to hyperparameters and architectural choices? Could alternative configurations improve performance?
In summary, while BiGANs are a promising framework with solid theoretical underpinnings, the empirical results and narrative alignment need significant improvement to justify acceptance. The paper lays a strong foundation for future work but does not yet achieve its stated goals convincingly.