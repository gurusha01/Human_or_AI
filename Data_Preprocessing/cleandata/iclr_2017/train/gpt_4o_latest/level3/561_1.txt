Review
Summary of the Paper
The paper proposes a method to construct a visual hierarchy of ImageNet classes using Convolutional Neural Networks (CNNs) and two inter-class similarity metrics: softmax probabilities and L2 distance between fc7 features. The authors explore three methods for constructing the hierarchy: Approximation Central Point (ACP), Minimum Spanning Tree (MST), and Multidimensional Scaling (MDS). The claimed contributions include the construction of a biology-inspired evolutionary tree and insights into the representations learned by deep neural networks. The authors demonstrate the ability of CNNs to group visually similar categories and suggest that deeper architectures improve the quality of these groupings. The paper also extends its method to non-biological categories, such as vehicles, to demonstrate generalizability. While the proposed approach is novel and provides an interesting perspective on deep representations, the paper lacks sufficient technical depth and validation, particularly in its claims of biological relevance.
Decision: Reject  
The paper is not ready for publication due to insufficient technical rigor, lack of quantitative validation for its biological claims, and shallow exploration of deep network representations.
Supporting Arguments
1. Insufficient Validation of Biological Relevance: The paper claims to construct a biology-inspired evolutionary tree, yet the constructed trees rely solely on visual similarity rather than evolutionary relationships. There is no quantitative evaluation or comparison with established phylogenetic trees based on genetic or evolutionary data, which undermines the biological relevance of the work.
   
2. Limited Insights into Deep Representations: While the paper suggests that deeper CNN architectures better group visually similar categories, this insight is neither novel nor deeply explored. The analysis of deep network representations is superficial and does not provide meaningful new understanding beyond the observation that deeper networks perform better.
3. Methodological Weaknesses: Among the three proposed methods for hierarchy construction, the ACP method performs poorly and is not well-justified. The MST and MDS methods show better results, but their superiority is not rigorously analyzed. Additionally, the choice of similarity metrics (softmax probabilities and fc7 features) is not sufficiently motivated or compared to alternative approaches.
4. Generalizability Claims: While the paper demonstrates the method's applicability to non-biological categories (e.g., vehicles), the results are anecdotal and lack systematic evaluation. The claim that the method is "highly competitive to human beings" is not substantiated with empirical evidence.
Suggestions for Improvement
1. Biological Validation: To strengthen the biological relevance of the proposed method, the authors should compare their constructed trees with established phylogenetic trees based on genetic data. Quantitative metrics, such as tree similarity scores, could be used for evaluation.
2. Deeper Analysis of Representations: The paper should provide a more thorough exploration of the representations learned by CNNs. For example, analyzing feature maps across layers or comparing different architectures in greater detail could yield more meaningful insights.
3. Alternative Similarity Metrics: The authors should explore and justify the use of alternative similarity metrics, such as cosine similarity or mutual information, and compare their performance with the proposed metrics.
4. Rigorous Evaluation: The generalizability claims should be supported by systematic experiments across diverse datasets and categories. Additionally, the performance of the three hierarchy construction methods should be rigorously analyzed and compared.
5. Clarification of Contributions: The paper should clearly delineate its contributions to computer vision and evolutionary biology. If the focus is on visual similarity, the claims about biological relevance should be toned down.
Questions for the Authors
1. How do the constructed trees compare quantitatively to established phylogenetic trees based on genetic data?  
2. Why were softmax probabilities and L2 distance chosen as similarity metrics, and how do they compare to other potential metrics?  
3. Can the authors provide more detailed insights into the representations learned by CNNs, beyond the observation that deeper networks perform better?  
4. How does the method scale to larger datasets or more complex hierarchies?  
5. Could the approach be extended to incorporate non-visual features, such as genetic data, to improve biological relevance?
By addressing these issues, the paper could significantly improve its technical depth, biological relevance, and overall impact.