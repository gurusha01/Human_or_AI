Review of the Paper
Summary
The paper proposes a novel framework for multitask deep reinforcement learning (RL) guided by symbolic policy sketches. These sketches provide high-level task structures without requiring detailed intermediate supervision, enabling the learning of modular subpolicies that can be shared across tasks. The proposed method employs a decoupled actor-critic training objective to optimize these subpolicies, which are then composed to form task-specific policies. The approach is evaluated on two environments: a maze navigation task and a simplified Minecraft-inspired crafting task. The results demonstrate that the method outperforms baselines in terms of learning efficiency and performance, while also enabling zero-shot generalization and adaptation to unseen tasks. The authors highlight the potential of their approach to induce reusable subpolicies and facilitate hierarchical RL with minimal supervision.
Decision: Reject  
While the paper presents an interesting idea and promising empirical results, it falls short in terms of clarity, novelty, and rigor. The following reasons underpin this decision:
1. Unclear Novelty: The paper builds on well-established concepts such as symbolic specifications, actor-critic methods, and shared representations. However, it does not clearly articulate its main contribution relative to prior work. The connection to existing frameworks like options or hierarchical abstract machines is acknowledged but not sufficiently differentiated.
   
2. Scalability and Practical Utility: The reliance on curriculum learning, while effective in the presented tasks, raises concerns about scalability to more complex real-world problems. The design of curricula is non-trivial and heavily dependent on domain knowledge, which limits the method's practical applicability.
Supporting Arguments
1. Experimental Details and Reproducibility: The experimental section lacks sufficient detail to ensure reproducibility, despite the availability of code. For example, the specifics of the environments, hyperparameter tuning, and task sampling procedures are not fully described. This makes it difficult to evaluate the robustness of the results or compare them to other methods.
2. Dependence on Curriculum Learning: The approach's reliance on curriculum learning is a significant limitation. While the authors demonstrate its utility in their experiments, they do not discuss how curricula could be automated or generalized for more complex tasks. This omission weakens the paper's claim of minimal supervision.
3. Overly Specific Algorithmic Choices: The description of the approach is tightly coupled to specific algorithmic implementations (e.g., decoupled actor-critic). A more general formalization could improve the paper's clarity and make it easier to connect with prior work.
Suggestions for Improvement
1. Clarify Novelty: Clearly define the unique contributions of the paper compared to existing methods. For example, how does the proposed framework differ from prior work on options or hierarchical RL? What specific challenges does it address that previous approaches do not?
2. Automate Curriculum Learning: Discuss potential strategies for automating curriculum design, such as leveraging unsupervised task clustering or adaptive task sampling. This would enhance the scalability and practical utility of the approach.
3. Improve Experimental Rigor: Provide more detailed descriptions of the experimental setup, including hyperparameters, environment configurations, and evaluation metrics. Additionally, include comparisons to more diverse baselines, such as methods that do not rely on symbolic sketches.
4. Generalize the Framework: Present the approach in a more general formalism that abstracts away from specific algorithmic choices. This would make the method more accessible and easier to extend.
Questions for the Authors
1. How does the proposed method scale to environments with significantly more complex tasks or larger state/action spaces? Have you considered testing on more challenging benchmarks?
2. Can you provide more details on the curriculum learning process? Specifically, how sensitive is the method to the choice of curriculum, and how might it be automated?
3. How does the approach perform in environments where symbolic sketches are noisy, incomplete, or unavailable? Could the framework be extended to infer sketches autonomously?
While the paper introduces an intriguing idea, addressing the above concerns would significantly strengthen its contribution and impact.