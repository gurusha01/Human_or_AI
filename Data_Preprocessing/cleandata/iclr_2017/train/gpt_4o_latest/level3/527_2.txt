Review
Summary of Contributions
The paper introduces the multiplicative LSTM (mLSTM), a hybrid recurrent neural network architecture that combines the factorized hidden-to-hidden transitions of multiplicative RNNs (mRNNs) with the gating mechanisms of LSTMs. The authors argue that this design allows for more expressive input-dependent transitions while retaining the long-term memory capabilities of LSTMs. The paper evaluates mLSTM on multiple character-level language modeling tasks, demonstrating modest improvements over standard LSTM and its variants. The authors also explore dynamic evaluation, achieving a test error of 1.19 bits/character on the Hutter Prize dataset, which they claim is a significant improvement over static baselines. The paper positions mLSTM as a more flexible and robust alternative for sequence modeling tasks, particularly in scenarios involving surprising inputs or multilingual data.
Decision: Reject  
Key Reasons:
1. Lack of Strong Novelty: While the combination of mRNN and LSTM is interesting, the architectural modifications are incremental and do not represent a significant conceptual breakthrough. The proposed tricks (e.g., reparameterization of weight matrices, modified output gate activation, parameter sharing) are not novel or critical to the model's performance.
2. Underwhelming Empirical Results: The performance improvements of mLSTM over LSTM are modest and often inconsistent across tasks. Furthermore, the reliance on dynamic evaluation to achieve competitive results undermines the standalone effectiveness of the proposed architecture.
Supporting Arguments
1. Limited Performance Gains: The architectural modifications and tricks combined do not yield substantial improvements over existing methods. For example, while mLSTM achieves a slight edge on some datasets, it is outperformed by other architectures in large-scale tasks, and its susceptibility to overfitting is evident.
2. Misleading Claims: The connection between dynamic evaluation and fast weights in Section 4.4 is misleading, as it assumes test label availability, which is not realistic in many practical scenarios. Additionally, dynamic evaluation is a general technique that could enhance other baseline models, making the comparison less compelling.
3. Incomplete Exploration: The authors do not investigate regularization techniques such as batch normalization, layer normalization, or zoneout, which are standard in the literature. This omission raises concerns about whether the reported results are robust or if the model's performance could be further improved with these techniques.
Suggestions for Improvement
1. Clarify the Role of Dynamic Evaluation: The authors should explicitly discuss how dynamic evaluation affects the comparison with baselines and whether it is a fair metric for assessing the standalone performance of mLSTM.
2. Explore Regularization: Incorporating and evaluating regularization techniques like batch normalization or zoneout could provide a more comprehensive understanding of the model's capabilities and limitations.
3. Strengthen Empirical Comparisons: The paper would benefit from a broader comparison with state-of-the-art models, particularly those that excel in large-scale language modeling tasks. Additionally, exploring word-level language modeling or other sequence modeling tasks could provide stronger evidence of the model's generalizability.
4. Address Misleading Assumptions: The authors should revise the discussion in Section 4.4 to avoid incorrect assumptions about test label availability and clarify the implications of dynamic evaluation.
Questions for the Authors
1. How does mLSTM perform when regularization techniques (e.g., batch normalization, layer normalization, zoneout) are applied? Could these techniques mitigate the overfitting observed in large-scale tasks?
2. Why was dynamic evaluation not applied to baseline models for a fairer comparison? How would the performance of LSTM and other baselines change under dynamic evaluation?
3. Can the authors provide more evidence to support the claim that mLSTM is better suited for recovering from surprising inputs? The results in Section 4.4 suggest only a marginal advantage.
4. Have the authors considered extending mLSTM to word-level language modeling or tasks with continuous inputs? If not, what challenges do they foresee in adapting the architecture to such tasks?
In conclusion, while the paper introduces an interesting hybrid architecture, the lack of strong novelty, limited empirical gains, and incomplete exploration of standard techniques make it unsuitable for acceptance in its current form. Addressing the above concerns could significantly strengthen the paper.