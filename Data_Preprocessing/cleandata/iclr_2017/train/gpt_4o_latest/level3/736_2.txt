Review of the Paper
Summary of Contributions
This paper introduces Adaptive Batch Normalization (AdaBN), a novel and simple approach for domain adaptation in deep neural networks. By replacing the source domain statistics in Batch Normalization (BN) layers with those of the target domain, the method achieves domain adaptation without requiring additional parameters or optimization steps. The authors claim that AdaBN is parameter-free, computationally efficient, and complementary to existing domain adaptation methods. The paper demonstrates AdaBN's effectiveness on standard benchmarks (Office and Caltech-Bing datasets) and a practical application in cloud detection for remote sensing images. The results show state-of-the-art performance in both single- and multi-source domain adaptation settings, with further improvements when combined with other methods like CORAL.
Decision: Reject
While the paper introduces an interesting and simple idea, there are several concerns that prevent its acceptance in the main conference track. The primary reasons for rejection are:
1. Insufficient Experimental Evaluation: The method heavily relies on pre-trained ImageNet models, and there is no evaluation of scenarios where models are trained from scratch. This limits the generalizability of the approach.
2. Unclear Fair Comparisons: The use of a stronger base CNN (Inception-BN) compared to other methods (e.g., AlexNet) may account for the reported improvements. The comparisons are not entirely fair, and the performance gains may not solely be attributed to AdaBN.
3. Obscured Simplicity: The core idea of the paper, while simple and elegant, is not clearly articulated in the abstract or introduction, making it harder for readers to grasp the novelty.
Supporting Arguments for Decision
1. Experimental Limitations: The paper does not evaluate AdaBN on toy datasets or in scenarios where models are trained from scratch. This is crucial to validate the robustness of the approach beyond pre-trained ImageNet models.
2. Baseline Comparisons: The use of Inception-BN as the base model provides a performance advantage over methods using AlexNet, which may inflate the perceived effectiveness of AdaBN. A more rigorous comparison using identical base models is necessary.
3. Clarity of Presentation: The simplicity of the method is a strength, but it is not effectively communicated. The abstract and introduction are dense with background information, which obscures the main contribution.
Suggestions for Improvement
1. Expand Experimental Evaluation: Evaluate AdaBN in scenarios where models are trained from scratch and on toy datasets. This would provide a more comprehensive understanding of the method's applicability.
2. Fair Comparisons: Use the same base CNN architecture (e.g., AlexNet or Inception-BN) across all methods to ensure fair comparisons. Additionally, report results with and without AdaBN to isolate its impact.
3. Clarify the Core Idea: Simplify the abstract and introduction to focus on the main contribution. Clearly articulate the novelty and simplicity of AdaBN upfront.
4. Ablation Studies: Include more detailed ablation studies to isolate the effects of AdaBN. For example, evaluate the impact of adapting individual BN layers versus all layers.
5. Theoretical Insights: Provide a deeper theoretical explanation of why replacing BN statistics works effectively for domain adaptation. This would strengthen the scientific rigor of the paper.
Questions for the Authors
1. How does AdaBN perform when models are trained from scratch rather than using pre-trained ImageNet models? Can the method generalize to such scenarios?
2. Can you provide results on toy datasets to validate the approach in controlled settings?
3. How much of the reported improvement is due to the stronger base CNN (Inception-BN) rather than the AdaBN technique itself?
4. Have you considered combining AdaBN with other domain adaptation methods (e.g., MMD-based approaches) beyond CORAL? If so, what are the results?
In conclusion, while the paper presents a promising idea, it requires additional experimental validation, clearer articulation of its contributions, and fairer comparisons to be considered for acceptance in the main conference track. The paper may be better suited for a workshop track, where it can benefit from further feedback and refinement.