Review
This paper introduces a novel recurrent neural network (RNN) architecture for action-conditional future prediction in high-dimensional environments, such as Atari games, 3D car racing, and 3D mazes. The proposed architecture integrates actions directly into the LSTM core, enabling more effective modeling of environment dynamics. The authors present a systematic evaluation of different architectures and training schemes, demonstrating that their 100%-Prediction scheme outperforms others for long-term predictions in high-dimensional video tasks. Additionally, the paper explores the utility of the model for improving exploration in 3D environments, a critical application in reinforcement learning.
Decision: Accept.  
Key reasons for this decision include the paper's strong empirical results, which demonstrate state-of-the-art performance in long-term prediction tasks, and its comprehensive analysis of training schemes and architectural variations. While the novelty is somewhat limited—primarily focusing on how actions are integrated into the LSTM—the systematic evaluation and practical contributions to high-dimensional video prediction make this work valuable to the research community.
Supporting Arguments:  
1. Empirical Insight: The paper provides robust empirical evidence that the proposed architecture and training scheme outperform prior methods, particularly in long-term predictions for high-dimensional video data. This is a significant contribution given the computational challenges in such domains.  
2. Comprehensive Results: The revised version includes extensive experimental results across diverse environments, such as Atari games and 3D worlds, which strengthen the paper's claims and provide valuable insights for future research.  
3. Practical Utility: The demonstration of the model's application to exploration in 3D environments highlights its potential impact on reinforcement learning tasks.  
4. Clarity and Rigor: The paper is well-written, with clear explanations of the methodology, experiments, and results. The experiments are scientifically rigorous and well-designed.
Additional Feedback:  
1. Limited Novelty: While the integration of actions into the LSTM is well-justified and impactful, the novelty is incremental compared to prior work. The authors could strengthen the paper by discussing broader implications or potential extensions of their approach.  
2. Evaluation of Robustness: The paper notes that the model is less robust to states not seen during training. Future work could explore methods to improve generalization, such as incorporating adversarial training or domain randomization.  
3. Comparison with Probabilistic Models: Since the proposed model is deterministic, it would be interesting to compare its performance with probabilistic models in noisy or stochastic environments.  
4. Memory and Compositionality: The authors mention the need for alternative memory structures to capture compositional dynamics better. Including preliminary experiments or a discussion of potential solutions would enhance the paper's impact.
Questions for the Authors:  
1. How does the proposed architecture handle stochastic environments where state transitions are inherently noisy?  
2. Can the model be extended to handle continuous action spaces, and if so, what modifications would be required?  
3. The paper mentions that the model struggles with compositional structures (e.g., independently moving objects). Could you elaborate on how this limitation might be addressed in future work?  
4. How sensitive is the model's performance to the choice of hyperparameters, such as the prediction length \( T \) or the number of prediction-dependent transitions?
In conclusion, despite its incremental novelty, the paper makes a strong empirical and practical contribution to high-dimensional video prediction and action-conditional dynamics modeling. Its systematic evaluation and state-of-the-art results justify acceptance.