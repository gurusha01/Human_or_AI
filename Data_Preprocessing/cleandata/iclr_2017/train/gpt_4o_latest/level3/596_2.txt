The paper proposes a novel method, Implicit ReasoNets (IRNs), for link prediction in knowledge bases, introducing two key innovations: iterative inference and a shared memory component. These innovations allow the model to perform multi-step inference implicitly, without directly manipulating observed triples in the knowledge base. The authors demonstrate that IRNs achieve state-of-the-art results on the FB15k and WN18 benchmarks, surpassing prior methods by significant margins. Additionally, the paper evaluates IRNs on a synthetic shortest path synthesis task, showcasing their ability to perform complex multi-step reasoning.
Decision: Weak Accept
The paper is well-written, and the proposed method demonstrates strong empirical performance, significantly outperforming existing approaches on two benchmarks. However, the decision to rate this as a weak accept stems from the following reasons: (1) The contributions of the iterative inference mechanism and shared memory component to the improved results are not sufficiently explained or disentangled. (2) The experimental analysis lacks exploration of critical hyperparameters, such as the shared memory size and Tmax, which could provide deeper insights into the model's behavior. (3) The benchmarks used (FB15k and WN18) are outdated, and the evaluation on more modern datasets would strengthen the paper's claims.
Supporting Arguments:
1. Strengths:  
   - The iterative inference mechanism and shared memory are novel and address the challenges of large-scale inference in knowledge bases.  
   - The empirical results are impressive, with IRNs achieving substantial improvements in hits@10 and mean rank on FB15k and WN18.  
   - The application of IRNs to the shortest path synthesis task demonstrates the model's versatility and reasoning capabilities.  
2. Weaknesses:  
   - The paper does not provide sufficient analysis of how the iterative inference and shared memory contribute to the observed performance gains. For example, what proportion of examples benefit from iterative inference, and how does the termination gate behave during inference?  
   - The effect of hyperparameters, such as shared memory size and Tmax, on performance is not explored in detail, leaving questions about the model's robustness and scalability.  
   - The use of a low temperature (λ = 10) in the attention mechanism is mentioned but not analyzed, leaving unclear its impact on attention distribution across relationships and entity types.  
   - The reliance on outdated benchmarks limits the generalizability of the results. Testing on larger, more modern datasets would provide a stronger validation of the method.
Additional Feedback and Questions for the Authors:
1. Clarifications Needed:  
   - Can the authors provide a more detailed analysis of the termination gate's behavior? For example, how often does the model terminate early, and what types of queries require more inference steps?  
   - How does the shared memory size impact performance, especially in terms of hits@10 and mean rank? Is there a trade-off between memory size and inference efficiency?  
   - Could the authors elaborate on the role of the low temperature (λ = 10) in the attention mechanism? How does it affect the model's ability to focus on relevant memory vectors?  
2. Suggestions for Improvement:  
   - Include experiments on larger, more modern datasets to validate the method's scalability and relevance to current knowledge base completion tasks.  
   - Provide ablation studies to isolate the contributions of the iterative inference mechanism and shared memory.  
   - Explore the impact of Tmax and shared memory size on performance to offer insights into optimal hyperparameter settings.  
   - Consider visualizing the attention weights or memory updates during inference to provide interpretability and insights into the model's reasoning process.
Overall, while the paper introduces a promising method with strong empirical results, addressing the outlined concerns would significantly strengthen its contributions and impact.