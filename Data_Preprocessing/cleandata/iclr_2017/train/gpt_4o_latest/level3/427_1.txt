Review of the Paper
Summary of Contributions
This paper introduces a novel, theoretically motivated method for visualizing the input feature map regions that contribute to the output decisions of deep neural networks (DNNs). The key insight is the use of conditional sampling to identify features that not only significantly impact the output but are also less predictable from other features, addressing a limitation in prior work that focused solely on output sensitivity. The proposed approach builds on the prediction difference analysis method by Robnik-Šikonja & Kononenko (2008) and incorporates improvements such as conditional sampling, multivariate analysis, and deep visualization of hidden layers. The authors demonstrate the utility of their method on both natural images (ImageNet) and medical images (MRI brain scans), showing that it identifies more salient and interpretable regions compared to marginal distribution-based methods. The paper also highlights the potential applications of this method in domains like healthcare, where interpretability is critical.
Decision: Accept
The paper makes a significant contribution to the field of interpretability in DNNs by addressing a key limitation in existing visualization methods. The proposed method is well-motivated, theoretically grounded, and empirically validated. The results demonstrate clear improvements over prior approaches, and the application to medical imaging showcases its broader impact.
Supporting Arguments
1. Novelty and Motivation: The paper addresses an important gap in the literature by considering the predictability of features in addition to their impact on the output. This is a meaningful advancement over prior methods, which often overlook feature redundancy.
2. Empirical Validation: The results convincingly show that the proposed conditional distribution-based method identifies more salient and interpretable regions than marginal sampling methods. The experiments on ImageNet and MRI datasets provide a strong demonstration of the method's utility across diverse domains.
3. Theoretical Rigor: The method builds on a well-established framework (Robnik-Šikonja & Kononenko, 2008) and extends it with theoretically sound improvements, such as conditional sampling and multivariate analysis.
Suggestions for Improvement
1. Comparison with Baselines: While the paper compares the proposed method with marginal sampling, it would benefit from a direct comparison with Zeiler et al.'s grey patch-based visualization approach. This would provide a more comprehensive evaluation of the method's performance relative to established baselines.
2. Justification of Sampling Strategy: The use of 10 samples for both marginal and conditional distributions is not well-justified. Given the differences in regularization effects, a more thorough analysis or justification of this choice is needed.
3. Additional Visualizations: The authors provide a link to additional visualizations, but including these in the appendix would make the paper more self-contained and accessible to readers.
4. Computational Efficiency: The method's computational cost is significant, with some analyses taking up to 70 minutes per image. While the authors acknowledge this limitation, discussing potential optimizations or trade-offs would strengthen the paper.
Questions for the Authors
1. How does the method perform when applied to other datasets or tasks beyond image classification, such as text or tabular data? Could the approach generalize to these domains?
2. Can the authors provide more details on the choice of the multivariate normal distribution for conditional sampling? How sensitive are the results to this choice?
3. Have the authors considered using more advanced generative models (e.g., diffusion models or VAEs) for conditional sampling, and if so, what challenges might arise?
In conclusion, this paper makes a valuable contribution to the interpretability of DNNs and is well-suited for acceptance at the conference. The suggestions provided aim to further enhance the clarity and impact of the work.