Review of the Paper
Summary of Contributions
This paper provides a comprehensive empirical study of the capacity and trainability of various recurrent neural network (RNN) architectures, including vanilla RNNs, gated architectures (GRU, LSTM), and two novel architectures (UGRNN and +RNN). The authors introduce a novel experimental framework to measure the bits of information stored per parameter in RNNs, finding that ungated RNNs have the highest per-parameter capacity but are harder to train. The proposed UGRNN architecture achieves a balance between capacity and trainability, while the +RNN demonstrates improved trainability for deeper architectures. The paper also highlights that the observed superiority of gated architectures is primarily due to their trainability rather than inherent capacity differences. While the experiments confirm intuitive results, they lack significant real-world validation.
Decision: Reject
The paper is well-executed and provides valuable insights into RNN capacity and trainability. However, the lack of significant novelty in the proposed architectures and limited real-world applicability of the experiments make it insufficient for acceptance. The primary contributions, while interesting, are incremental and do not provide groundbreaking insights or practical advancements for real-world tasks.
Supporting Arguments for the Decision
1. Novelty: While the paper introduces a novel experimental setup to measure bits per parameter, the proposed UGRNN architecture is conceptually similar to the Minimal Gated Unit by Zhou et al. (2016). The +RNN, while promising for deep architectures, does not demonstrate significant advantages over existing architectures like GRU or LSTM in real-world tasks. The novelty of the contributions is thus limited.
   
2. Significance: The experiments focus on synthetic tasks, such as random data modeling and parentheses counting, which do not directly translate to real-world applications. While the findings on capacity and trainability are valuable, they confirm existing intuitions rather than providing surprising or transformative insights. The proposed architectures fail to outperform GRU or LSTM on practical tasks like language modeling.
3. Clarity and Rigor: The paper is well-written, and the experiments are scientifically rigorous. However, the results primarily validate known ideas, such as the trade-off between trainability and capacity in gated architectures. The lack of surprising results diminishes the overall impact.
Suggestions for Improvement
1. Real-World Validation: The authors should evaluate the proposed architectures (UGRNN and +RNN) on more practical, real-world tasks, such as speech recognition or machine translation, to demonstrate their utility beyond synthetic benchmarks.
2. Motivation for Proposed Architectures: The motivation for UGRNN and +RNN should be clarified and strengthened. Why are these architectures necessary, and what specific gaps in existing architectures do they address? A more detailed comparison with related work, such as the Minimal Gated Unit, would also be beneficial.
3. Surprising Insights: The paper would benefit from deeper theoretical insights or unexpected empirical findings. For example, exploring why ungated RNNs have higher capacity but are harder to train could lead to novel training techniques or architectural innovations.
4. Efficiency Analysis: While the paper mentions computational trade-offs, a detailed analysis of training and inference efficiency for the proposed architectures compared to GRU and LSTM would add practical value.
Questions for the Authors
1. How do the proposed architectures (UGRNN and +RNN) perform on large-scale, real-world tasks such as speech recognition or machine translation?
2. Can the authors provide a more detailed comparison between UGRNN and the Minimal Gated Unit by Zhou et al. (2016)? What are the key differences and advantages of UGRNN?
3. Did the authors explore alternative training techniques to improve the trainability of ungated RNNs, given their higher capacity?
In summary, while the paper provides a solid empirical foundation for understanding RNN capacity and trainability, it lacks the novelty and practical impact required for acceptance. Addressing the above concerns could significantly strengthen the paper.