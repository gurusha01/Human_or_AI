The paper investigates a VAE architecture and training methodology designed to generate novel samples of a concept based on a set of exemplars provided to the model. The proposed architecture employs a recurrent neural network and an aggregation mechanism, akin to the approach used in Matching Networks, to process the exemplar set. The resulting "summary" representation is then utilized to condition a generative model (a VAE), enabling it to produce new samples that align with the characteristics of the given exemplars. The proposed aggregation and conditioning mechanism is shown to be more effective for handling sets of exemplars originating from multiple classes compared to simple averaging.
Interestingly, the model demonstrates the ability to generalize from generation conditioned on exemplars from 2 classes to generation conditioned on exemplars from 4 classes. 
The experiments, conducted on the OMNIGLOT dataset, are compelling. While an explicit comparison to prior works is absent, this omission is addressed in the appendices, and the authors provide a comparison to architectures resembling those used in earlier studies.