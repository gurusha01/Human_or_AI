The authors aim to compare deep neural networks (DNNs) with human visual perception through both quantitative and qualitative analyses.
Their first result involves conducting a psychophysical experiment on humans and a model, followed by a comparison of the outcomes. (It appears, however, that the psychophysical data were collected in a prior study and are merely utilized here.) The specific experiment determined, for approximately 1110 images, the level of additive noise required to produce a just-noticeable difference for humans in distinguishing the noiseless image from the noisy one. The authors then propose a metric for neural networks to measure what they hypothesize to be an analogous property in the networks. They correlate the noise-level patterns between humans and neural networks, finding that DNNs are significantly better predictors of human noise-level patterns than simpler image perturbation measures, such as RMS contrast.
The second result compares DNNs and humans in terms of error patterns across a series of controlled experiments using stimuli that highlight classic properties of human visual processing, such as segmentation, crowding, and shape understanding. The authors employ an information-theoretic single-neuron discriminability metric to evaluate whether DNNs exhibit similar error patterns. Their findings suggest that the top layers of DNNs can replicate human patterns of difficulty across these stimuli, albeit to a limited extent.
The third result examines the contrast sensitivity patterns of DNNs and humans using sine-grating images at varying frequencies. (This is a classic benchmark in vision research, making it a natural target for model comparison.) The authors define a DNN correlate for this property using the cross-neuron average of the L1-distance between responses to a blank image and responses to sinusoidal gratings of different contrasts and frequencies. They qualitatively compare the DNN results to established human data, observing that, like humans, DNNs exhibit a bandpass response for low-contrast gratings and a largely constant response at high contrast.
Pros:
- The overarching concept of rigorously comparing DNNs to psychophysical results in a detailed, quantitative manner is commendable.
- The authors introduce well-defined "linking functions"—metrics that translate specific behavioral results into neural network outputs (e.g., the L1 metrics in Results 1 and 3 and the information-theoretic measure in Result 2). This framework for linking functions is a promising direction for future research.
- The psychophysical data appear to have been handled with exceptional care and expertise, demonstrating the authors' strong command of psychophysical methodologies.
Cons:
- The primary limitation of this paper is that it does not offer insights beyond what is already known. Prior research has established that DNNs are reasonably good models of the human visual system in various respects, and this work adds more examples to that list. What would have elevated the contribution is:
  - (a) Demonstrating that their comparison metric is sensitive enough to differentiate between DNN models, identifying one as clearly superior.
  - (b) Highlighting a substantial gap between DNNs and humans that remains unresolved. While the authors touch on this in Result 1—where DNNs explain 60% of the variance compared to 84% inter-human consistency—the 24% gap is intriguing and warrants deeper exploration. For instance, they could have:
    - (i) Investigated which specific images contributed most to the gap and designed targeted experiments around those.
    - (ii) Attempted to close the gap by training a neural network to perfectly match the human pattern and evaluating whether this improved the network's performance on other tasks or metrics.
    
In essence, I would have preferred a more in-depth exploration of Result 1 over the inclusion of Results 2 and 3. While the authors' approach is promising, it feels underdeveloped in this work.
- Certain aspects of the paper's organization were confusing. For example, the quantitative results for Results 2 and 3 were not clearly presented. Why was Figure 8 relegated to the appendix? The quantification of model-human similarities for the data in Figure 8 is central to Result 2 and should have been more prominently displayed.
- Similarly, the quantification of model-human similarity for the data in Figure 3 is missing. Could the authors not derive a human contrast-sensitivity curve and compare it quantitatively to the models, rather than relying on qualitative observations? The absence of such an analysis is surprising and detracts from the rigor of the third result.