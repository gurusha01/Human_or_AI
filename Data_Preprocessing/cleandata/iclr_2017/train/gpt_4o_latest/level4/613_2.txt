The authors build upon their earlier work on causal discovery (Chalupka et al., 2016) by incorporating assumptions about sparsity through regularization. They test this extension on an intriguing private dataset from Sutter Health. While the direction is interesting, I found the presentation to be somewhat unclear, the methodological novelty to be less substantial compared to most ICLR contributions, and the central results (or possibly the data; see below) insufficient to convincingly address questions of causality.
First, the presentation lacks clarity in several areas. At times, the paper appears to focus entirely on healthcare data, while at other times it treats it as a motivating example or neglects it altogether. Additionally, Algorithm 1 is not referenced in the text, and its necessity is unclear. Figure 2 seems unnecessary for this audience. The primary methodological contribution, introduced in Section 2.1 (Causal regularizer), is presented amidst toy examples without clear terminology or a standard methodological framework. In Section 3.1 (bottom of the first paragraph), key data and results are relegated to the appendices, which detracts from the main narrative. Overall, the paper feels disorganized, and it seems to assume a deep familiarity with the Chalupka preprint, which is problematic. The paper should be self-contained.
Second, while the technical contributions are not the focal point of the paper's presentation, I am concerned about the limited methodological advancement. The primary contribution appears to be the addition of a regularization objective to the prior method. While this is not inherently a poor idea, I do not see a significant technical innovation that the community would find indispensable.
Third, the experiments do not convincingly address the core question of causality. While they demonstrate that regularization influences weights as expected, there is no substantial quantitative evidence to suggest that causality has been effectively learned. This issue is briefly touched upon (see "ground truth causality?" and the response below), and while I understand the challenges and potential impossibility of obtaining such a dataset, this limitation makes the work feel premature. Without a way to validate the results meaningfully, the claims about causality remain unsubstantiated.
In summary, while the effort is genuine, the paper falls short in several critical areas.