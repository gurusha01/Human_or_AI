This paper introduces a variational inference-based approach for learning nonlinear dynamical systems. In contrast to the deep Kalman filter, the proposed method explicitly learns a state space model, ensuring that the latent state encapsulates all information relevant to predictions, rather than relying on implicit information within the observations. Experimental results demonstrate that the proposed method is more effective in learning meaningful representations of sequence data.
The proposed DVBF is well-justified, and the overall presentation is clear. The experiments provide compelling results on illustrative toy datasets. I find the contribution both interesting and potentially impactful, and I would recommend acceptance.
The SVAE method introduced by Johnson et al. (2016) warrants more discussion than the brief mention it currently receives, as it appears to be closely related to the proposed approach. Similar to the DVBF, the SVAE enforces a Markovian structure and addresses comparable types of problems. From my understanding, the primary algorithmic distinction lies in the q network: the SVAE predicts potentials, whereas the DVBF predicts innovations. What are the trade-offs between these two approaches? Section 2.2 suggests that the latter choice is motivated by solving control-related tasks, but the reasoning behind this connection is unclear.
Do SVAEs fail to satisfy any of the desiderata outlined at the end of the Introduction? If so, it would be helpful to elaborate on this point.
Given that the SVAE code is publicly available, it would be valuable to include a direct comparison against it in the experiments.
I am also unclear about the treatment of uncertainty regarding v. In principle, one could estimate the transition parameters using maximum likelihood (i.e., fitting a point estimate of v), but this is not the approach taken here. Instead, v is marginalized as part of the marginal likelihood, which I interpret as enabling the flexibility to model varying dynamics across different sequences. However, if this is the case, shouldn't the q distribution for v depend on the observed data, rather than being data-independent as specified in Eqn. (9)?