This study explores a joint learning framework where tasks are organized hierarchically based on their complexity. To evaluate this approach, experiments are conducted on part-of-speech (POS) tagging, chunking, dependency parsing, semantic relatedness, and textual entailment. The proposed end-to-end model demonstrates improvements compared to models trained exclusively on individual target tasks.
While the hypothesis addressed in this work is significant, the experimental evaluation lacks sufficient rigor:
1. A straightforward multi-task learning baseline [1], without imposing a task hierarchy, should be implemented to verify the hypothesis that tasks must be ordered by complexity.
2. Since the chunking test set is included in the training data for dependency parsing, the chunking results obtained with JMT_all are not meaningful.
3. The model does not ensure well-formed dependency trees, which makes the results presented in Table 4 unfair.
Minor issue:
- Chunking is not inherently a word-level task, even though its annotation is word-level. It is a structured prediction task aimed at learning structured annotations over sequences [2].
[1]