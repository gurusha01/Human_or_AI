Paraphrased Review
Summary
Prior research has demonstrated that for several algorithms, the halting time adheres to a two-parameter distribution, a phenomenon referred to as the universal property, which the authors aim to investigate further. In this paper, the authors extend the scope of this investigation to include new algorithms, specifically spin-glass systems and gradient descent in deep learning.
An algorithm is said to exhibit the universality property if the centered and scaled fluctuations of its halting times (i.e., the empirical distribution of halting times) are influenced by the algorithm itself but remain independent of the target accuracy epsilon, an intrinsic dimension N, and the probability distribution or random ensemble. This is formalized in Eq. 1, where the left-hand side shows the empirical halting time distribution depending on epsilon, N, A, and E, while the right-hand side demonstrates that the approximation depends solely on the algorithm.
The authors empirically argue that the universal property is observed when the algorithms (spin-glass and deep learning) perform well, but it is absent when their performance deteriorates. To evaluate the presence of universality, the authors propose a moment-based indicator.
---
Review
This paper raises several concerns:
1. Page 2: "For sufficiently large N and eps = eps(N)"  
   The dependence of epsilon on N is problematic and warrants clarification.
2. Page 3: "Universality is a measure of stability in an algorithm [...] For example [...] halting time for the power method [...] has infinite expectation and hence this type of universality is not present. One could use this to conclude that the power method is naive. Therefore the presence of universality is a desirable feature of a numerical method."  
   This reasoning is flawed. An algorithm is considered naive if there exist better alternatives for solving the same problem. It cannot be concluded that an algorithm is naive solely based on an infinite expectation for halting time (e.g., an algorithm that solves a problem extremely quickly 99% of the time but loops indefinitely in 1% of cases). Furthermore, the universality property is more restrictive than merely having a finite expectation for halting time. While having a finite expectation may often be desirable, demonstrating that universality is desirable would require showing that its other, more restrictive aspects are also beneficial.  
   Additionally, this paragraph only discusses one algorithm. Why should the conclusions generalize to all numerical methods? Even if the universality property is desirable (assuming the paragraph's conclusion is correct), the argument provided does not substantiate this claim.
3. Comparison of Eq. 1 with Figures 2, 3, 4, and 5  
   According to Eq. 1, universality implies that the centered and scaled halting time fluctuations (which depend on A, epsilon, N, and E) can be approximated by a distribution that depends only on A (and not on epsilon, N, or E). However, in the experiments, only E varies (as shown in Figures 2, 3, 4, and 5). The validity of the approximation under variations in epsilon or N is not tested.
4. Definitions of Ensembles/Distributions (E) and Algorithms (A)  
   The paper does not clearly define the ensembles/distributions parameter E (on which halting fluctuations should not depend) or the algorithm A (on which halting fluctuations are allowed to depend). This lack of clarity is especially problematic given the standard usage of these terms. In the optimization setting, the authors state that the functional form of the landscape function is part of A (in response to a reviewer's question). However, it remains unclear what constitutes the functional form. What about cases where the landscape has no known functional form (e.g., black-box computations)?
5. Claims in the Conclusion Regarding the Five Questions  
   The paper claims to address five questions in a robust and quantitative manner, but this is not convincingly demonstrated:  
   - Question 1: "What are the conditions on the ensembles and the model that lead to such universality?"  
     The moment-based indicator is proposed as a quantitative tool, but the paper provides only one example of universality not being observed (conjugate gradient with M = N). This single example does not demonstrate the robustness of the method.  
   - Question 2: "What constitutes a good set of hyperparameters for a given algorithm?"  
     The authors suggest that universality can be used to identify good hyperparameters: if universality is observed, the hyperparameters are good; otherwise, they are bad. However, this correspondence is only demonstrated for one algorithm and one type of failure. Other algorithms may perform poorly in the universal regime or perform well outside it. The paper does not provide a robust method for answering this question.  
   - Question 3: "How can we go beyond inspection when tuning a system?"  
     This question is overly broad and general, and the paper does not provide a robust or quantitative method to address it.  
   - Question 4: "How can we infer if an algorithm is a good match to the system at hand?"  
     The paper does not convincingly demonstrate that universality is a reliable or robust criterion for evaluating the suitability of algorithms. The generalization of this approach to all systems and algorithms is highly speculative and unsupported.  
   - Question 5: "What is the connection between the universal regime and the structure of the landscape?"  
     As with the previous questions, this one is too vague to be addressed in a robust or quantitative manner. The lack of clarity regarding what constitutes A and E further complicates any attempt to answer this question.
6. Claims in the Conclusion  
   The conclusion asserts that the paper validates the claim that universality is present in all or nearly all sensible computations. However, this is not substantiated. The paper does not adequately test for the presence of universality (only one of the three parameters that should not vary is tested). Similarly, the paper does not sufficiently test whether universality is lost when computations are no longer sensible (only one failure case is examined). Finally, the experiments are limited to a small number of specific algorithms and cannot be generalized to all or nearly all computations.