The authors propose a recurrent deep neural network to predict human fixation locations in videos, modeling them as a mixture of Gaussians. The model is trained using maximum likelihood estimation with actual fixation data. In addition to assessing the model's performance in predicting fixations, the authors integrate the saliency predictions with C3D features for action recognition.
Quality: I find the evaluation of the fixation prediction performance insufficiently thorough. The center bias performance reported in Table 1 differs markedly from that in Table 2. Furthermore, all state-of-the-art models listed in Table 2 perform worse than the center bias performance reported in Table 1. Is it truly the case that no other model outperforms the center bias? Additionally, the paper lacks sufficient details on how central bias and human performance are modeled. Was human performance cross-validated?
You state that your "results are very close to human performance (the difference is only 3.2%)." However, this difference is actually larger than the difference between the central bias and your model as reported in Table 1. Moreover, comparing AUC performance differences can be problematic due to issues such as saturation, which makes such comparisons potentially misleading.
Clarity: The explanation provided for Table 3 is somewhat unclear. Additionally, it is not evident why the CONV5 and FC6 models differ in how the saliency map is applied. It would be helpful to evaluate the CONV5 model by multiplying the input with the saliency map, as this would clarify how much of the observed difference arises from the distinct methods of using the saliency map versus the different features employed.
Other Issues:  
You cite KÃ¼mmerer et al. (2015) as a model that "learns ... indirectly rather than from explicit information of where humans look." However, their model was trained on fixation data using maximum likelihood estimation, which contradicts this claim.
Despite these concerns, I believe the paper makes a valuable and interesting contribution to spatio-temporal fixation prediction. If the evaluation issues outlined above are addressed, I would be happy to revise my rating positively.