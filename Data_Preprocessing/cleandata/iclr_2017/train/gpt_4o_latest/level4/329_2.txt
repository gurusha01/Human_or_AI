This paper explores the use of denoising autoencoders (AEs) to enhance the performance of GANs. Specifically, the discriminator's feature representations of images generated by the generator are fed into a denoising AE, with the goal of accurately reconstructing these features. I find the idea of leveraging this "extra information"—the feature representations learned by the discriminator—quite intriguing. It aligns well with the innovative and exploratory spirit of ICLR. 
However, my primary concern lies in the nature of the reported improvements. While the method achieves higher inception scores compared to other approaches in certain scenarios, I find it challenging to interpret these scores meaningfully, which makes it difficult to fully appreciate the significance of the results. Moreover, the authors have not sufficiently demonstrated that the benefits of this approach justify the added complexity, both conceptually and in terms of implementation. On that note, will the authors be releasing the code? Additionally, I am curious about the practical challenges involved in getting this method to work reliably.
From my perspective, GANs are a means to an end. While I am not particularly enthusiastic about generating realistic images (especially at resolutions like 32x32), I am very excited about the broader potential of GAN-based systems. It would have been valuable to see whether the reported improvements in inception score translate into tangible benefits for a more practical downstream task. That said, this critique could likely apply to many GAN-related papers and may not be entirely fair to single out this work.
Overall, I find the idea of utilizing "extra information," such as discriminator features, compelling—both within the context of this paper and as a broader concept for future exploration.