This paper evaluates the sensitivity of multilayer neural networks to perturbations, comparing their performance to that of human vision. Across many of the tasks examined, multilayer neural networks demonstrate sensitivities that align closely with those observed in human vision.
Based on the tasks presented in this study, one could infer that multilayer neural networks encapsulate several properties of the human visual system. However, given the existence of well-documented adversarial examples—where small, imperceptible perturbations lead to significant categorization errors—it becomes challenging to interpret the broader implications of these findings. The observation that the two systems exhibit similar sensitivities in certain scenarios could be attributed to a variety of factors. A deeper analysis of why this alignment occurs in some cases but not in others would have been valuable. For instance, in the case of noise perturbations discussed in the first section, the correlation between conv2 and human sensitivity is already evident. Why not delve further into how the first-layer filters are integrated to produce this contextual effect? Such an investigation could yield meaningful insights into underlying neural mechanisms.
While I appreciate and support the direction the author has pursued, I feel the paper only begins to explore the relationship between perceptual correlates and multilayer neural networks, leaving significant room for deeper analysis.