The paper presents a novel network architecture designed to address inverse problems in computer vision. Examples of the inverse problems explored include image inpainting, intrinsic image decomposition, and foreground/background separation.
The proposed architecture consists of three main components:  
(i) a generator that produces the target (latent) output, such as foreground and background regions,  
(ii) a renderer that reconstructs the latent output back into an image, enabling comparison with the input image to compute reconstruction error, and  
(iii) an adversarial prior that enforces the latent output to adhere to specific image statistics.
---
Strengths:
- The architecture, particularly with its integration of a memory database, is innovative and demonstrates novelty.
Weaknesses:
- The experimental results are limited to proof-of-concept scenarios with toy datasets, which do not convincingly showcase the advantages of the proposed architecture.  
- The generalizability of the memory retrieval engine, which relies on L2 distance between pixel values, to more complex and realistic scenarios is uncertain.  
- The clarity of the paper could be improved, as some explanations and terminologies are ambiguous (see below for details).
---
Detailed Evaluation:
Originality:
- The primary novelty of this work lies in the adversarial prior (component iii), which introduces an adversarial loss between the generated latent output and a single image retrieved from a large, unlabelled database of target output examples (referred to as "memory"). Notably, the adversarial prior operates in a convolutional form, matching local image statistics rather than global image features. This combination of a memory-based, fully convolutional adversarial loss within the network architecture appears to be both novel and potentially impactful.
- Motivation for the Architecture:  
The weakest aspect of the proposed architecture is the "Memory retrieval engine" (Section 2.4), which retrieves images from the memory by computing L2 distance between pixel intensities. While this approach may suffice for the simple problems addressed in this paper, its ability to generalize to more complex datasets and tasks remains unclear. This limitation should be better discussed and justified, and ideally, results on more realistic datasets should be provided to strengthen the paper's claims.
---
Quality:
- Experiments:  
The experimental evaluation includes three tasks: inpainting of MNIST digits, intrinsic image decomposition on the MIT intrinsic image database, and figure/ground layer extraction on a synthetic dataset of 3D chairs rendered onto real photographic backgrounds.  
However, the experimental results are limited to simplified, toy setups, which weakens the validation of the proposed model. For instance:  
  - The MNIST digit inpainting task is far removed from the current state-of-the-art in image inpainting on real photographs (e.g., Pathak et al., 2016).  
  - Foreground/background separation is only demonstrated on synthetically generated data.  
  - For intrinsic image decomposition, the paper does not utilize larger, more challenging datasets such as the one introduced by Bell et al. (2014) (see citation below).  
While such proof-of-concept experiments may be acceptable for an ICLR submission, they diminish the significance of the work and raise questions about its applicability in real-world scenarios. To address this, the authors could focus on one specific problem and demonstrate the model's performance on a more challenging, state-of-the-art dataset. Additionally, it would be valuable to highlight the benefits of incorporating the memory database in these experiments.
Reference:  
S. Bell, K. Bala, and N. Snavely. Intrinsic images in the wild. ACM Transactions on Graphics, 33(4):159, 2014.
---
Clarity:
- The clarity of the paper can be improved. Some of the terminology, such as "imagination" and "memory," is ambiguous and may confuse readers.  
- For example, Figure 2 does not clearly explain how the "memories" for a given input image are obtained, which makes it difficult to understand this aspect of the architecture.  
- To enhance comprehension, the authors could include an illustration that visualizes the operations in the "feature space," similar in spirit to Figure 2 in [a relevant reference].