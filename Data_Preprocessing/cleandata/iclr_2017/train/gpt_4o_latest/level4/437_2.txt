This paper presents a variant of the A3C model, where agents operate on multiple CPU cores, while the computationally intensive model computations are offloaded to the GPU. The authors conduct various analyses to demonstrate the achieved speedup.
I appreciate the authors' efforts in addressing the raised questions and revising the paper to improve its clarity. The proposed modification to the original algorithm is intriguing, and Section 5 provides a thorough analysis of GPU utilization across different configurations.
The primary limitation of the paper lies in the lack of more extensive experiments across additional Atari domains and non-Atari domains, as well as the absence of multiple plots from repeated runs to examine instabilities. Stability is a critical concern in reinforcement learning, and the most robust algorithms should demonstrate strong performance across diverse domains. That said, I acknowledge the constraints of computational resources, particularly in an academic setting, assuming this work was conducted outside of Nvidia.