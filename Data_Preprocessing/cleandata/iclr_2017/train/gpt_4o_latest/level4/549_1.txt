The paper presents an efficient variant of sparse coding, leveraging it as a foundational component within CNNs for image classification tasks. The coding approach integrates both the input signal reconstruction objective and top-down information derived from class labels. The proposed module is compared against the recently introduced CReLU activation block.
Strengths:  
The method appears to be technically robust and offers a novel approach to training CNNs layer-wise by combining reconstruction and discriminative objectives.
Weaknesses:  
The improvement in classification accuracy over the prior state-of-the-art is not well-established. While the proposed method slightly outperforms the CReLU baseline on the CIFAR-10 dataset (by 0.5% on the test set), the performance gain is minimal.  
The paper would benefit from demonstrating the general applicability of the proposed method across diverse CNN architectures and datasets, with consistent and significant performance improvements over strong CNN baselines. Without such evidence, the practical impact of the work remains uncertain.