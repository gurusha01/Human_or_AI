This paper explores an alternative formulation of Kernel PCA by incorporating rank constraints as a regularization term in the objective function. However, the writing lacks clarity, with the focus shifting inconsistently between estimating "causal factors," nonlinear dimensionality reduction, Kernel PCA, and ill-posed inverse problems. The reformulation of Kernel PCA relies on relatively standard techniques, and the advantages of the proposed approach over existing methods remain unclear due to the absence of both theoretical analysis and empirical comparisons with state-of-the-art methods.
- The term "causal factors" is mentioned in the Abstract and the Problem Formulation section on page 3, but it is neither defined nor discussed, leaving its meaning ambiguous.
- In the context of KPCA, the purpose of step (iii) on page 2—finding a pre-image for each projection—is unclear.
- The authors highlight two main disadvantages of the existing KPCA approach. The first, concerning the exactness of the low-dimensional manifold assumption, has already been extensively addressed in the machine learning literature. It is common to assume that data lies near, rather than exactly on, a low-dimensional manifold. The second disadvantage, involving the task of finding "a data point (pre-image) corresponding to each projection in the input space," is not a standard step in KPCA and is somewhat unclear.
- On page 3, the notation $\mathcal{X} \times N$, $\mathcal{Y} \times N$, and $\mathcal{H} \times N$ is never explicitly defined. These cannot represent Cartesian products, so I assume the notation refers to N-tuples, but this should be clarified.
- On page 3, Section 2, $\mathcal{X}$ and $\mathcal{Y}$ are introduced as sets, but the meaning of $\mathcal{Y} \ll \mathcal{X}$ is not explained.
- On page 5, the notation $\mathcal{S}^n$ is used but never defined.
- Experiments: Standard algorithms for matrix completion, such as OptSpace or SVT, were not considered.
- Experiments: There is no comparison with alternative existing methods for Non-rigid Structure from Motion.
- Proof of Theorem 3.1: The transition from equation (16) to (17) using Hölder's inequality, as stated, would lead to a term involving the sum of the fourth powers of weights $w_{ij}$. It is unclear why these weights would sum to one under the orthonormal constraints. Providing additional details here would be helpful, as the argument is not immediately evident at this point.