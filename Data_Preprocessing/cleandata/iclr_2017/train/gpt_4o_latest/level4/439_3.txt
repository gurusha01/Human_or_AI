This paper introduces a novel approach for learning to generate programs. Rather than directly generating the program, the authors propose training a neural network to predict a fixed set of attributes, which subsequently guide a search procedure. This is an intriguing and logical approach, as constructing a generative model for programs is an inherently complex challenge.
The experimental results demonstrate faster computation times compared to baselines such as DFS, Enumeration, etc., in a setup where very small programs, with lengths of up to 5 instructions, need to be discovered. However, it is unclear how well the proposed method scales to larger programs, where potentially many attributes may be active. Would the approach still retain its advantage in such scenarios?
The authors evaluate their method using the time required to find a single program that produces the correct output for a given set of 5 input-output pairs. However, as noted in the paper, the goal is not merely to find any correct program but rather the best program or a ranked list of correct programs (e.g., top-k). Could the authors provide experiments in this more realistic setting? Would the proposed approach still be effective, and what challenges might arise in such a scenario?
In the second experiment, the authors present results where the program lengths at training and test time differ. However, the reported results are limited to cases where only 20% of the programs are successfully found. Could the authors provide results for cases where all programs are discovered?
The paper lacks a detailed analysis of the results. For instance, what types of programs are particularly challenging for the method? How frequently does the neural network make incorrect predictions, and how does this impact overall speed? What are the failure modes of the proposed approach?
The authors propose using a fixed-length representation for each input-output pair and then applying average pooling to obtain the final representation. However, it is unclear why average pooling is a suitable choice in this context. Would it not be more appropriate to combine the predictions at the decoder stage rather than at the encoder stage?
Learning from only 5 executions seems quite challenging. While this may be acceptable for very small programs, it appears less feasible for more complex and longer programs. How does the method generalize to such cases?
In summary, this is an interesting paper that addresses a challenging problem. However, as this topic lies outside my primary area of expertise, I may have overlooked some important aspects.