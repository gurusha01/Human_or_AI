The authors present a method for generating realistic images by first synthesizing the background and then conditioning on this background to generate one or more foreground objects. Additionally, they incorporate an image transformer layer, which facilitates the model's ability to handle variations in appearance more effectively.
I would appreciate some discussion on the decision to use a foreground+mask approach instead of directly predicting the foreground. For instance, in the case of MNIST, the foreground appears largely irrelevant. However, for datasets like CUB and CIFAR, the foreground contributes texture and color, while the mask ensures sharp boundaries. 
- Is the mask implemented as a binary mask or an alpha blending mask?
- It is intriguing that the model learns to decompose images so effectively and produces clean foreground masks with minimal extraneous elements (though some artifacts are present in CIFAR). This is a particularly fascinating aspect of the work.
The proposed evaluation metric is logical and appears reasonable. However, as far as I can tell, it is theoretically possible to achieve a high score even if the GAN generates images that are unrecognizable to humans but interpretable by the classifier network used to compute P_g. For example, the generator could encode the class in a subtle manner (though this is unlikely given the adversarial training setup).
Figure 3 effectively demonstrates that the decomposition is significantly improved when spatial transformers are employed. However, it also suggests that the foreground prediction and the foreground mask are largely redundant. For the final results, the quality of the decomposition seems to have limited relevance.
Additionally, the transformation layer appears to have only a minor impact, as evidenced by the transformed masked foreground objects, which are primarily scaled down.
- What do the 3rd and 6th columns in Figure 9 represent? It is unclear whether the final composed images are truly as poor as implied.
For the evaluation experiment using AMT, it is unclear why presenting users with L2-minimized nearest-neighbor matches is preferable to providing random pairs.
I assume that the Adversarial Divergence for real images reported in Table 1 was not actually evaluated. It would be interesting to see how close to zero this metric is across multiple differently initialized networks. Additionally, please clarify how the confidence intervals or standard deviations were computedâ€”specifically, whether they are based on different training sets, initializations, evaluation sets, or the number of runs conducted.