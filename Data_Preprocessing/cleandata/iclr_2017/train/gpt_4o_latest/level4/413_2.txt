The paper proposes a method to enhance the efficiency of CNNs that encode sequential inputs in a 'slow' manner, where the representations of adjacent steps in the sequence exhibit minimal variation. 
The authors provide theoretical performance improvements using toy video data (temporal MNIST) and natural movies, evaluated with a powerful Deep CNN (VGG). 
The extent of improvement is inherently constrained by the 'slowness' of the CNN representation, which is converted into a sigma-delta network. CNNs explicitly designed to produce 'slow' representations are expected to benefit the most. Additionally, the proposed method's efficiency gains are likely to be fully realized only with specialized hardware, making it difficult to comprehensively assess its full potential at this stage. 
Nevertheless, given the broad and general relevance of sequential data processing, it is plausible that this approach could inform the design and application of future CNNs. 
In summary, the paper introduces an intriguing concept that addresses an important problem. While the initial results are promising, the practical utility and significance of the method will depend on future developments.