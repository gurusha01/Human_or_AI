This paper introduces a novel approach for link prediction on Knowledge Bases, incorporating two key innovations: (1) an iterative inference process that enables the model to refine its predictions over multiple steps, and (2) a shared memory mechanism. These two components collectively allow the proposed model to achieve impressive performance on two benchmark datasets.
The paper is reasonably well-written, and the proposed model is both intriguing and effective, as evidenced by the strong experimental results. However, I recommend a weak accept for the following reasons:
* The primary concern with this work is the lack of detailed analysis explaining how and why the two proposed components contribute to the observed performance improvements. For example:
  - What is the model's performance without the shared memory component? Additionally, how does performance vary as the size of the shared memory is increased?
  - How does the model's performance change when Tmax is varied from 1 to 5 (which appears to be the chosen value for the experiments)? This would provide insights into the frequency and effectiveness of the termination gate.
  - It would also be valuable to report the proportion of examples where inference terminates before reaching Tmax.
  - What percentage of examples experience changes in predictions across multiple inference iterations?
* The choice of \lambda = 10 (Section 2) suggests a low temperature for the softmax function. Does this result in the attention mechanism focusing predominantly on a single cell? Additionally, how do the softmax activations vary based on the type of relationships or entity types?
* FB15k and WN18 are now considered outdated and overused benchmarks. It would strengthen the paper to evaluate the proposed method on larger and more challenging datasets.