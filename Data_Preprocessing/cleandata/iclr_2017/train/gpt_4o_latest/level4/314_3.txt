The paper introduces an on-policy approach for predicting future intrinsic measurements. All experiments are conducted within the Doom environment (specifically vizDoom). Instead of merely predicting win/loss outcomes or the number of frags (score), the authors train their model to predict a sequence of triplets comprising (health, ammunition, frags), weighted by a corresponding sequence of "goal" triplets provided as input. Adjusting the weights of the goal triplets serves as a mechanism to guide or influence exploration. During testing, the agent acts by optimizing for long-term goals exclusively.
The results are noteworthy, as this model secured victory in the 2016 vizDoom competition. The experimental section appears robust:
 - The paper includes comparisons of DFP against A3C, DQN, and an effort to benchmark it against DSR (a recent related method by Kulkarni et al., 2016). DFP demonstrates superior performance over other methods (or matches them when they plateau, as seen with A3C in scenario D1).
 - An ablation study is presented, which substantiates the claim that the additional complexities introduced by the model contribute meaningfully to its performance.
The concepts of predicting intrinsic motivation (Singh et al., 2004), auxiliary variables, and forward modeling are well-established in reinforcement learning. The version I reviewed (December 4th revision) appropriately cites prior work, though it may not be exhaustive.
Some minor comments on presentation:
 - Doom is described as a 3D environment, but it is more accurately a 2D environment (the height dimension is neither actionable nor discriminative) rendered in pseudo-3D.
 - The notation "P" in equation (2) (and subsequent equations) may lead to confusion, as it represents prediction rather than probability, which is the more common interpretation of "P."
 - The dual use of "j" (albeit in different fonts) in equation (6) could be misleading.
 - Results tables could benefit from repeating the units of measurement, particularly in Table 1, where the metrics are heterogeneous.
In my view, this paper is a clear accept. While one might argue for testing in additional environments or question the degree of novelty, I believe that papers that are both "correct" (methodologically sound, experimentally rigorous on Doom, with an appendix detailing reproducibility) and "milestone" (winning the vizDoom competition) merit publication.