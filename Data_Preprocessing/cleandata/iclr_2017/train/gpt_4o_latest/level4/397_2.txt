This paper proposes the concept of a "variational lossy autoencoder" (VLAE), where the powerful autoregressive conditional distribution of inputs \( x \) given the latent code \( z \) is deliberately constrained to ensure meaningful utilization of \( z \). The paper's primary contributions are as follows:
1. It provides a compelling information-theoretical explanation for why VAE-type models often fail to leverage their latent representation when the conditional distribution \( p(x|z) \) is sufficiently expressive.
2. It demonstrates that this insight can be leveraged to train VAEs with powerful autoregressive conditional distributions in a way that ensures effective use of the latent code.
3. It introduces a novel approach to parameterizing the prior using an autoregressive flow transformation, which is equivalent to applying an inverse autoregressive flow transformation to the approximate posterior.
The information-theoretical perspective on why VAEs underutilize their latent code when \( p(x|z) \) is highly expressive is, in itself, a significant contribution to our understanding of VAE-related methodologies.
However, the empirical evaluation of this intuition is somewhat lacking. The "crippling" mechanism employed appears to be manually designed and highly task-specific. Additionally, the qualitative evaluation of the "lossyness" of the learned representation is conducted on three datasets (MNIST, OMNIGLOT, and Caltech-101 Silhouettes) that consist of black-and-white images with minimal texture. While Figures 1a and 2a illustrate that reconstructions discard low-level details—evident in the subtle variations in strokes between the input and reconstruction—this analysis would have been more convincing if conducted on more complex image datasets. Have the authors considered applying VLAE to such datasets?
The Caltech-101 Silhouettes benchmark also warrants caution, as no comparisons are made with other competitive methods such as IAF VAE, PixelRNN, or Conv DRAW. Consequently, VLAE achieves state-of-the-art performance in only one of the four experimental settings presented.
A particularly pertinent question for this work is: "Does incorporating a latent representation on top of an autoregressive model improve density modeling performance?" While the paper briefly addresses this question, the discussion is limited. The sole comparison against recent autoregressive models shows that VLAE marginally outperforms PixelRNN in one setting.
The proposal to transform the latent code using an autoregressive flow—equivalent to parameterizing the approximate posterior with an inverse autoregressive flow transformation—is also intriguing. However, an important distinction must be noted: in the former approach, the prior over the latent code can be highly complex, whereas in the latter, the prior is restricted to a simple, factorized distribution.
It is unclear whether having a highly expressive prior is advantageous from a representation learning perspective. Often, the goal is to learn a representation of the data distribution that is disentangled and composed of approximately independent factors of variation. While the suitability of a simple spherical Gaussian prior for achieving this goal is debatable, striking a balance between the prior's capacity to fit the data and its utility as a high-level representation is an important consideration. I would be interested in the authors' perspective on this matter.
In summary, while the paper presents innovative ideas, the shortcomings in its empirical evaluation prevent me from fully endorsing its acceptance.
UPDATE: After reviewing the authors' response, I have revised my rating to a 7.