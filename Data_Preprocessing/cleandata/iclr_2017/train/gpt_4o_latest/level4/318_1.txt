The primary contribution of this paper appears to be the introduction of a set of differential graph transformations, enabling the learning of graph-to-graph classification tasks through gradient descent. This framework aligns naturally with the task of learning a cellular automaton represented as a sequence of graphs. In this context, the graph's nodes expand with each iteration, with edges connecting neighbors and special nodes (0/1) denoting specific values. The proposed architecture facilitates the learning of this sequence of graphs; however, in the experiments, this task (Rule 30) remains far from being fully addressed.
The proposed approach is further integrated with concepts from prior work (GGS-NN), allowing the model to generate textual outputs instead of graph outputs while utilizing graphs as intermediate representations. This integration enables the model to surpass the state-of-the-art performance on the BaBi tasks.