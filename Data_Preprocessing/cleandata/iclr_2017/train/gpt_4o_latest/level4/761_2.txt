The authors aim to investigate whether static analysis can be learned. As I suggested in my earlier question, I believe the toy language used in the study removes all of the meaningful complexity inherent to static analysis. The problem posed can be addressed with extraordinarily simple logic using a set, and it is unsurprising that an LSTM is able to learn this straightforward logic (especially when provided with a differentiable set object). This extreme level of simplicity does not inspire confidence that the approach would generalize to more realistic static analysis tasks.
LSTMs (and deep learning in general) have achieved remarkable success in tackling complex, real-world language problems. It is certainly plausible that LSTMs could be applied to static analysis, but adopting an overly cautious and simplistic approach is not the right way to explore this potential.