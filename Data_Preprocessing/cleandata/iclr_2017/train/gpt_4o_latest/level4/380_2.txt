The authors propose a novel method to modify the objective of generative adversarial networks (GANs) such that the discriminator can effectively recover density information about the underlying data distribution. In deriving this modified objective, they demonstrate that the standard GAN setup does not inherently guarantee discriminator stability, but this issue can be addressed by incorporating an additional entropy regularization term.
The paper is well-written and provides a clear theoretical derivation. The reasoning behind the additional regularization term appears sound and is explained thoroughly. The experiments also provide empirical evidence supporting the claim that the proposed modified objective leads to a "better" discriminator. However, there are a few areas where the paper could be improved:
- While the details in Sections 3.1 and 3.2 are relatively clear, the initial exposition fails to clearly articulate the distinction between the energy-based perspective on GAN training and the standard GAN framework. This lack of clarity made it challenging to understand why the results do not apply to standard GANs without multiple readings. To improve this, the authors could explicitly outline the connections in Section 3.1 (potentially without introducing the additional f-GAN perspective at this stage) and provide a more immediate explanation of how \( c() \) is implemented, either within this section or in the experiments. Alternatively, these details could be included in the Appendix (see also the related comment below).
- The proposed approach inherently improves the generator's performance but does not appear to enhance the stability of GAN training. While the authors do not explicitly claim improved stability, an uninformed reader might mistakenly infer this, especially given the mention of improved performance over Salimans et al. in the Inception score experiment. It would be helpful to clarify this point early in the paper to avoid potential misunderstandings.
- Although the experiments are well-designed, they primarily provide qualitative results, apart from the table in the Appendix for the toy datasets. While evaluating GANs quantitatively is inherently challenging, it would strengthen the paper to include additional quantitative experiments to assess the discriminator's performance. For instance, the authors could evaluate how effectively the final discriminator distinguishes real from fake examples or test its robustness to injected noise (e.g., by measuring classification accuracy on noisy training data). Additionally, it would be interesting to investigate whether the features learned by the discriminator's final layer under the modified objective are more effective for auxiliary tasks, such as object classification.
- A major concern is the lack of clarity regarding the architecture of the generator and discriminator used in the experiments. While the authors mention that code will be made available, a brief description of the energy function or model architecture should be included in the paper, perhaps in the Appendix.