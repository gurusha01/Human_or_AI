The paper presents a supervised deep learning approach that incorporates layer-wise reconstruction loss (in addition to the supervised loss) and class-conditional semantic additive noise to enhance representation learning. The layer-wise reconstruction loss is derived using the total correlation measure and additional insights from auto-encoders, which is then combined with the supervised loss. To complement this, a class-conditional additive noise model is proposed when integrating with the supervised loss, demonstrating consistent improvements over the baseline model. Extensive experiments are conducted on the MNIST and CIFAR-10 datasets, varying the number of training examples per class.
The derivation of Equation (3) from total correlation appears somewhat ad hoc. Furthermore, the assumed graphical model between X, Y, and Z requires a more rigorous derivation to accurately estimate H(X|Z) and H(Z|Y). The current approach, which involves encoding Z and Y from X and decoding from the encoded representation, lacks sufficient theoretical justification.
In Equation (8), is \(\sigma\) a trainable parameter or a hyperparameter? If it is trainable, how is it optimized? If it is not trainable, how are its values determined? Additionally, does \(j\) correspond to a specific class? The proposed feature augmentation seems akin to adding Gaussian noise to the pre-softmax neurons. As such, the method does not appear significantly different from Gaussian dropout (Wang and Manning, ICML 2013), albeit applied to different layers. Furthermore, the paper overlooks a relevant reference: "DisturbLabel: Regularizing CNN on the Loss Layer" (CVPR 2016), which also explores synthetic noise processes applied to the loss layer.
The experiments should be repeated multiple times with different random subsets, and the authors should report the mean and standard error. Overall, I find that the proposed method is not sufficiently well-justified and offers limited novelty.