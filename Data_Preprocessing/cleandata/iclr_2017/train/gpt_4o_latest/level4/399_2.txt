Paper Strengths:  
-- Sophisticated application of MoE to scale model capacity, facilitating the training of large models required to leverage extremely large datasets in a computationally efficient way.  
-- Significant increase in the effective batch size for training the MoE.  
-- Compelling experimental findings on the impact of scaling the number of MoEs, which aligns with expectations.  
Paper Weaknesses:  
-- While MoE is one approach to scaling model capacity for leveraging large datasets, there are several alternative methods. A discussion comparing MoE with these alternatives in terms of computational efficiency and other relevant factors would be highly valuable.