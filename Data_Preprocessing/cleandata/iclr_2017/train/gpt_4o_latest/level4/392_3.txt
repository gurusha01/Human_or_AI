The paper introduces a neural approach to learning an image compression-decompression scheme using an auto-encoder. While the concept is undoubtedly intriguing and well-justified, the practical results reveal that it achieves compression rates that are effectively on par with JPEG-2000.
As the authors point out, there is merit in the fact that this scheme is learned automatically rather than being manually engineered by experts. This implies potential advantages beyond compressing natural images, such as the ability to automatically learn compression schemes for signals where domain knowledge is limited. However, I believe the paper, in its current form, is not suitable for publication due to the following reasons:
1. First, the fact that the learned encoder is competitive with—but not demonstrably superior to—JPEG-2000 suggests that the paper should focus more on analyzing the similarities and differences between the two approaches. For instance, is the encoder learning filters similar to those in JPEG-2000, or are they fundamentally different? Additionally, for which types of textures does the proposed method perform better, and for which does it perform worse? The paper could include visualizations, such as the top 10 best and worst patches at various bit-rates, to provide deeper insights.
2. Second, it is essential for the paper to establish that the observed benefits stem from a superior coding scheme rather than merely a better decoder, as I raised in my initial pre-review question. For example, how would a decoder trained on JPEG-2000 codes—or potentially on encoded random projections—compare in performance? Demonstrating this distinction is critical to substantiate the claims of the proposed method.
3. Lastly, the fact that the proposed method performs only as well as or worse than JPEG-2000 weakens the argument for employing a 'deep' auto-encoder. JPEG-2000 relies on a wavelet transform, which prior research has shown can be approximated using straightforward sparse dictionary algorithms like K-SVD. Therefore, the method either needs to clearly outperform JPEG-2000 or provide comparisons to (or at least discuss) a carefully designed traditional or generative model-based baseline to justify its use.