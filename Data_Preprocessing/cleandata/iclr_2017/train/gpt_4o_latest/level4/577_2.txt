This paper introduces the use of a linear classifier as a probe to evaluate the informativeness of hidden activations across different layers of a neural network. Importantly, the training of the linear classifier is decoupled from the training of the neural network itself.
The study is well-motivated, aiming to assess the quality of representations at each layer by analyzing the amount of useful information they contain. The findings align with existing insights, such as: 1) (Fig. 5a) the detrimental effect of excessive random layers, 2) (Fig. 5b) the benefits of training, 3) (Fig. 7) the faster convergence of lower layers compared to higher layers, and 4) (Fig. 8) the challenges of training very deep networks, which can be mitigated by incorporating skip connections.
Nonetheless, the paper has the following shortcomings:
1. The justification for using a linear classifier as a probe is insufficient. It is not entirely clear why high linear classification accuracy necessarily indicates good intermediate features. Providing stronger theoretical analysis or clearer intuition would strengthen the argument.  
2. The paper offers limited guidance on how the observations can inform the design of better neural networks. Demonstrating how the findings can be applied to improve network architectures would also serve as a compelling validation of the proposed analysis.
In summary, while the paper addresses an interesting problem, the proposed technique (linear classifier as a probe) lacks novelty and requires stronger justification. Additionally, it is crucial to demonstrate how the insights gained can be leveraged to design improved neural networks.