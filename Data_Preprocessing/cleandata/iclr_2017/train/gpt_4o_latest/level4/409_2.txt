This paper presents the development of a corpus comprising freely-licensed classical music recordings paired with corresponding MIDI scores that are aligned to the audio. It also details experiments in polyphonic transcription using various deep learning methods, which demonstrate promising outcomes.
The paper, however, feels somewhat disorganized and occasionally contradictory. For instance, the opening sentence of Section 2 (MusicNet) might be better placed one paragraph later, allowing the section to begin with a survey of tools available to music researchers. Additionally, the description of Table 3 would be more appropriately located in the Methods section. Another example is the inconsistency between the abstract/introduction, which states that the goal is note prediction, and the fourth paragraph of the introduction, which claims the focus is on "learning low-level features of music...." This inconsistency is slightly confusing.
While prior works (e.g., Uehara et al., 2016) have explored collection platforms and corpora, this study stands out due to the scale of the corpus and the novel approach to feature generation. I am particularly interested in how the authors plan to expand the corpus offerings, both in terms of volume and diversity.