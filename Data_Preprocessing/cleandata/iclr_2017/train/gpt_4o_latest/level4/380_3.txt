The paper investigates various approaches to incorporate additional gradient information into the generator function during generative adversarial training. The authors begin by presenting a general framework for integrating this gradient information, referred to as \( K(p{\text{gen}}) \), into the GAN objective function (Equation 1). They then prove that the optimal discriminator's structure is influenced by the inclusion of this gradient information (Proposition 3.1), which is expected. Subsequently, the authors propose three specific methods to define \( K(p{\text{gen}}) \): the negative entropy of the generator distribution, the \( L_2 \) norm of the generator distribution, and a constant function (similar to the EBGAN objective introduced by Zhao et al., 2016).
The paper proceeds to experimentally evaluate the method, focusing on the case where \( K(p_{\text{gen}}) \) is set to approximate the generator distribution's entropy. At this stage, my interpretation is that the proposed objective function is essentially the standard GAN objective augmented with a regularization term that promotes diversity (i.e., high entropy) in the generator distribution. The authors aim for this regularization to encourage the discriminator to approximate the energy landscape of the data distribution.
The experimental results are presented in three parts: 1) contour plots of the generator distribution for a 2D toy problem, 2) an analysis of generation diversity for MNIST digits, and 3) sample generation results for CIFAR-10 and CelebA. The 2D problem results are compelling, as the discriminator scores clearly correspond to unnormalized density values. The MNIST experiments are also insightful, showing that more prototypical digits receive higher scores (unnormalized densities) from the discriminator, while less prototypical digits receive lower scores. However, the sample results in Section 5.3 are less persuasive, as no baseline model samples are provided for comparison.
To improve the paper, I suggest the authors address three key points. First, while entropy regularization appears to guide the discriminator toward estimating the data distribution's energy landscape, how does it reshape the generator function? It would be helpful to include the mean MNIST digit generated by the model and additional relevant statistics. Second, how do the generated samples compare visually to those from state-of-the-art methods? Third, what are the limitations of this approach compared to vanilla GANs? For instance, does it introduce significant computational overhead? Additionally, what are the qualitative and quantitative differences between the two entropy estimators proposed in the paper?
In summary, the paper is well-written and presents a clear contribution. I recommend acceptance.
As a broader question for the authors: What future advancements would enable the development of a GAN objective where the discriminator reliably estimates the data density function after training?