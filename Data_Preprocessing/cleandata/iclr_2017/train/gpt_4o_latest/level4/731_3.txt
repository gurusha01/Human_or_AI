This paper introduces a model capable of learning short binary codes using paragraph vectors, enabling fast document retrieval. Experimental results demonstrate that the proposed method outperforms semantic hashing. While the approach is straightforward, it lacks significant technical novelty. For a code size of 128, the performance loss relative to a continuous paragraph vector appears moderate.
The paper directs readers to the Salakhutdinov and Hinton work for baseline numbers, but including these within the paper itself would improve accessibility. To enhance clarity, the authors could present precision values at 12.5%, 25%, and 50% recall for both the proposed model and semantic hashing. Additionally, it seems the semantic hashing paper reports results on RCV2 rather than RCV1. Since RCV1 is twice the size of RCV2 and exclusively in English, the comparability of these results is questionable. It would be valuable to explore how many binary bits are necessary to achieve performance parity with the continuous representation. A comparison with the continuous PV-DBOW trained on bigrams would also provide a more balanced evaluation.
Figure 7 illustrates the performance loss associated with using the real-binary PV-DBOW. If a user requires high-quality ranking post-retrieval and has the resources for additional storage and computation, it would likely be more effective to employ a standard PV-DBOW to obtain the continuous representation at that stage.
Minor comments:
- First line after the introduction: "is sheer" → "is the sheer"
- Fourth line from the bottom of P1: "words embeddings" → "word embeddings"
- In Table 1: Clarify what "code size" refers to for PV-DBOW. Does this indicate the number of elements in the continuous vector?
- Fifth line from the bottom of P5: "W" → "We"
- Fifth line after Section 3.1: "covers wide" → "covers a wide"