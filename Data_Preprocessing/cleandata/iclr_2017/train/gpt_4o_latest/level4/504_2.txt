This paper introduces a novel approach for learning vision features as intermediate rewards to facilitate robot training in real-world scenarios. Given the limited availability of human demonstration sequences, the authors first segment these sequences into fragments to ensure that the features remain approximately invariant across corresponding fragments. They then cluster these fragments, identify the most discriminative features, and use these features as a reward function. The features themselves are derived from pre-trained deep models.
The proposed method is straightforward and appears to be effective in selecting appropriate reward functions. Figure 6 provides a compelling comparison (though it could be improved with the inclusion of error bars). However, some of the baselines used are not particularly robust, especially those related to vision. For instance, the random reward baseline ("simply outputs true or false") in Table 2 seems somewhat arbitrary and may not serve as a strong comparison point (though its performance is surprisingly not that poor). A more suitable baseline might involve employing random or simpler feature extraction methods on the images, such as binning features and selecting the most frequent ones, which, while potentially less discriminative, could serve as a meaningful comparison. This raises the question of whether a simpler vision-based approach could yield a reward function with comparable performance. If so, the necessity of the more intricate steps (e.g., segmentation) could be called into question.