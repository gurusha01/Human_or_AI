The authors propose novel prior and approximate posterior families for variational autoencoders (VAEs) that are compatible with the reparameterization trick and capable of capturing multiple modes. Additionally, they introduce a gating mechanism between the prior and posterior. The proposed methods demonstrate improvements in tasks such as bag-of-words document modeling and dialogue response generation. However, the original abstract makes overly strong claims regarding the inability of a unimodal latent prior \( p(z) \) to fit a multimodal marginal \( \int_z p(x|z)p(z)dz \) with a deep neural network (DNN) response model \( p(x|z) \), using phrases like "it cannot possibly capture more complex aspects of the data distribution" and "critical restriction."
While the assertion that a unimodal latent prior is inherently insufficient to model multimodal observations is incorrect, there are reasonable motivations for the proposed piecewise constant prior and posterior. For instance, viewing a VAE as a regularized autoencoder with latent codes constrained to "fill up" the prior latent space suggests that using a Gaussian prior with Gaussian posteriors may be suboptimal due to sphere-packing inefficiencies. Although the authors do not delve deeply into this perspective, a hypercube-based tiling of the latent space is a plausible and interesting idea.
The paper's treatment of "multi-modality" is somewhat imprecise. It conflates three distinct types of multimodality: (1) multimodality in the observed marginal distribution \( p(x) \), which any deep latent Gaussian model can capture; (2) multimodality in the prior \( p(z) \), which can be useful in certain contexts (e.g., modeling MNIST digits with 10 prior modes corresponding to digit classes); and (3) multimodality in the posterior \( q(z|x) \) for a given observation \( x \). The third type is harder to justify, except as a means of expressing flexible distributions without highly separated modes. While flexible posterior approximations are important for efficient tiling of latent space, they do not necessarily require multiple strong modes. It would be valuable to see experiments demonstrating the necessity of multimodal posteriors for real-world data.
The paper would benefit from a clearer distinction between these types of multimodality and a more explicit demonstration of which aspects of their analysis pertain to each. Additionally, the piecewise variable analysis is unsatisfactory in that it does not demonstrate different components of the multimodal prior corresponding to distinct words but rather shows a separation between Gaussian and piecewise variables.
As noted in my earlier questions, I find it surprising that the learned variance and mean for the Gaussian prior significantly improve G-NVDM likelihood, given that the powerful networks transforming to and from latent space should make the model scale-invariant. A breakdown of the contributions of the reimplemented base model, prior-posterior interpolation, and learned prior parameters would strengthen the experimental results. Overall, the strong improvements on the text modeling task over NVDM are difficult to interpret without an ablation analysis of the differences between the proposed model and the baseline.
The observation that adding more constant components improves document modeling is intriguing, and a more qualitative analysis of what the prior modes represent would be valuable. I would also be surprised if posterior modes were highly separated; if they are, it would be interesting to explore whether they correspond to phenomena such as ambiguous word senses.
The dialog modeling experiments yield mostly negative quantitative results. However, the finding that piecewise constant variables encode time-related words while Gaussian variables encode sentiment is compelling, particularly since this pattern emerges in both sets of experiments. Further analysis of why this occurs would be valuable. As with the document modeling task, it would be helpful to analyze the types of words encoded in different prior modes and whether they correspond to meaningful groupings, such as holidays or days.
In conclusion, while the piecewise constant variational family is an interesting idea, it is not well-motivated in the paper. The experimental results for document modeling are strong, but without ablation studies, it is unclear why such a small modification to G-NVDM yields such improvements. The superior performance of H-NVDM is noteworthy, but the paper should better justify the need for different types of multimodality and demonstrate that these are indeed captured by the model. As it stands, the paper introduces a promising variational family and shows its utility for certain tasks, but its motivation and analysis lack focus. To establish the broader applicability of the method, experiments on more standard datasets like MNIST would be valuable. Even without absolute log-likelihood improvements, demonstrating interpretable multimodal behavior would make this a significant contribution.