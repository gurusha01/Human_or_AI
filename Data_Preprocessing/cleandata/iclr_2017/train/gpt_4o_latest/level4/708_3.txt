The authors present a method for generating adversarial examples without requiring knowledge of the network architecture or gradients.
While the idea has some merit, as another reviewer noted, the topic has been extensively studied, including in black-box scenarios.
My primary concern lies with the first set of experiments, which permit images that fall outside the valid image space. The authors acknowledge this limitation in the first paragraph of page 7. In my view, this significantly undermines the value of these experiments, rendering them effectively meaningless. At the very least, the results are entirely unsurprising to me.
The issue is addressed to some extent by the greedy search procedure. However, the explanation of the proposed method is somewhat unclear. As far as I can tell, the process begins by generating a candidate set of pixels using PERT, after which the pixels are perturbed using CYCLIC. It remains unclear why this approach yields effective or minimal perturbations, given that the candidate pixels are selected using a large "p," which can lead to images outside the valid image space. The authors do not appear to provide a clear rationale for this choice.
In summary, while the authors conduct an interesting exploration and propose a method for generating adversarial examples in a black-box setting, the overall approach and conclusions appear relatively straightforward. Additionally, the paper is overly verbose, and I believe the findings could be presented in a much more concise manner.