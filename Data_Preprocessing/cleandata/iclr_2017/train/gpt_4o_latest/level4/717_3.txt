This paper seeks to explore and visualize the representations learned by deep networks as one progresses from lower to higher layers. Consistent with prior findings, the lower layers are shown to focus on local image features, while the higher layers capture more abstract properties, such as object identity. In the semantic space, higher-level nodes exhibit greater semantic selectivity, whereas lower-level nodes display more diffuse representations.
Overall, this is a commendable effort to disentangle the representations within deep networks. Perhaps the most notable finding is the significant role of color across all network layers, with performance on grayscale images being markedly reduced. The newly proposed NF measure is reasonable, though it remains tied to the specific images presented to the network. The more fundamental question is what functions these nodes are computingâ€”specifically, out of the space of all possible images, which ones most strongly activate a given unit? While this is undoubtedly a challenging problem, it would be valuable to see progress toward answering it. The color analysis presented here appears to make some headway in this direction. However, while the semantic analysis is well-executed, it is unclear what novel insights it contributes.