This paper investigates various strategies for instance-level image retrieval using deep convolutional neural networks (CNNs). The proposed method involves extracting features from a pre-trained image classification network (e.g., VGG) and applying post-processing techniques for image retrieval. Essentially, the network is used as an off-the-shelf feature extractor, and the post-processing steps are adapted from traditional retrieval pipelines based on hand-crafted features (e.g., SIFT with Fisher Vectors), which the authors refer to as "traditional wisdom."
In particular, the authors analyze several aspects, such as the optimal layer for feature extraction (i.e., neuron activations from convolutional layers), the most effective feature aggregation and normalization techniques, the impact of image resizing, the benefits of combining multiple scales, and other related factors.
While the experimental study is well-motivated and reasonable in its scope, it suffers from a significant limitation. Specifically, it overlooks two major recent works that directly contradict many of the claims made in the paper: [a] "End-to-end Learning of Deep Visual Representations for Image Retrieval" by Gordo et al. and [b] "CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard Examples" by RadenoviÄ‡ et al., both presented at ECCV 2016. These studies demonstrate that training CNNs specifically for retrieval tasks using siamese architectures achieves superior performance. Consequently, many of the claims and conclusions in the paper are outdated, questionable, or outright incorrect.
Some of the misleading claims include:
  - "Features aggregated from these feature maps have been exploited for image retrieval tasks and achieved state-of-the-art performances in recent years."  
    This statement is inaccurate. Until the publication of [a] (which is not cited), the state-of-the-art in image retrieval was still predominantly led by methods based on sparse invariant features. The final table in [a] clearly illustrates this.
  - "The proposed method [...] outperforms the state-of-the-art methods on four typical datasets."  
    This is incorrect for the same reasons mentioned above. The current state-of-the-art is now defined by [a] and [b], which are not acknowledged in the paper.
  - "Also in situations where a large number of training samples are not available, instance retrieval using unsupervised methods is still preferable and may be the only option."  
    This assertion is debatable. For instance, Gordo et al. in [a] demonstrate that their method achieves state-of-the-art performance on the UKB dataset (3.84 without QE or DBA), even though it was trained for landmark retrieval rather than object retrieval. This highlights that training, even with limited data, can still be feasible and advantageous.
  - Furthermore, most of the findings presented in the paper are neither novel nor surprising. For example, the concept of aggregating features across multiple regions and scales was already addressed by Tolias et al. and others. As a result, the overall contribution of the paper is limited.
Additionally, there are issues with the experimental setup. For example, the tuning experiments are conducted exclusively on the Oxford dataset using a single network (VGG-19). It is unclear whether these conditions are representative of other datasets and networks, especially given that the Oxford dataset is known to behave differently from others, such as the Holidays dataset. Moreover, the tuning process appears overly aggressive, raising concerns about potential overfitting to the test set (e.g., as evidenced in Table 3).
In conclusion, this paper is outdated by approximately one year in light of recent advancements in the state of the art.