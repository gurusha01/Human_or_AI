This paper introduces a model designed to generate a latent representation of input image(s) while optimizing a reconstruction loss combined with an adversarial loss (Eq (1)) over nearest neighbors retrieved from an image bank ("memory"). The proposed framework is applied to three tasks: (i) image in-painting, (ii) intrinsic image decomposition, and (iii) figure-ground layer extraction. Qualitative results are presented for all three tasks.
The proposed model demonstrates potential strengths. I particularly appreciate its approach of reasoning over image composites by matching against a bank of images, which bears some resemblance to the "Segmenting Scenes by Matching Image Composites" work from NIPS 2009. However, I am hesitant to fully endorse the paper due to areas where clarity and evaluation could be significantly improved.
Detailed comments:
The primary shortcoming of the paper is the absence of quantitative evaluation. At a minimum, the approach should be compared against prior work on intrinsic image decomposition, such as SIRFS, and ideally benchmarked on datasets like "Intrinsic Images in the Wild."
The writing throughout the paper is vague and often unclear. For example, the term "memory database" is ambiguous and ultimately appears to refer to a simple set of images. Similarly, the term "imagination" is not well-defined. On page 4, R(M,x) is described as taking both the database and the input image as arguments, but Fig. 2 does not depict the input image as an input to R. The contributions listed on page 3 should be refined for clarity (e.g., the phrase "Relevant memory retrieval for informative adversarial priors" is difficult to interpret). Additionally, Fig. 3 appears inconsistent with Fig. 2, as the "memory database" module is missing. More details should also be provided about the fully-convolutional discriminator, such as specifying a cost function.