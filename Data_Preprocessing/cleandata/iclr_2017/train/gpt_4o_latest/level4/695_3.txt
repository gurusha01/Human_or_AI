The paper introduces a method for pruning neural networks by eliminating neurons whose operations exhibit high correlation with other neurons. The concept is interesting and somewhat novel, as most pruning approaches focus on removing individual weights. However, I have not conducted an exhaustive review of related work in this area. That said, the method's experimental and theoretical justifications require significant improvement before the paper can be considered for publication:
1. Experiments: The authors do not provide sufficient evidence regarding accuracy degradation during pruning. While they briefly claim that the networks did not experience degradation, this assertion is not substantiated in the tables. Figure 5 offers some details, but it contradicts Table 2: in Table 2, the number of parameters ranges from 40k to 600k, whereas Figure 5 depicts a range of 12k to 24k. Without additional details, the claim that 50% of neurons can be removed without accuracy degradation is unconvincing.
2. Theory: The theoretical proofs presented do not align with the experimental conditions and rely on questionable assumptions. Specifically, the proofs demonstrate that, in the absence of biases, a network with a constant output will have two correlated neurons generating the output offset. However, this scenario is precisely why networks include biases, and the explanation does not clarify why noise injection is effective. According to the proofs, a deterministic auxiliary neuron should suffice, yet this does not align with the observed benefits of noise injection. My interpretation is that the noisy output introduces gradient noise (see, for example, the concurrent ICLR submission).