The results presented in the paper appear promising; however, the baselines used for comparison are suboptimal.
For example, in Table 2, which reports the "Misclassification rate for a 784-1024-1024-1024-10" architecture, the floating-point fully connected (FC) model achieves a misclassification rate of 1.33%. This is significantly higher than what can typically be achieved with this topology, which is closer to 0.8%. To strengthen the contribution, I would expect the authors to demonstrate "significant" compression levels on state-of-the-art results or to use stronger baselines. For reference, it is possible to achieve a misclassification rate of 0.6% with two fully connected hidden layers.
In the CIFAR-10 experiments, I find it puzzling that the "Sparsely-Connected 90% + Single-Precision Floating-Point" configuration performs worse than "Sparsely-Connected 90% + BinaryConnect." This suggests that binary precision outperforms floating-point precision, which is counterintuitive. 
I suspect that the experiments do not leverage all the techniques that can be applied to floating-point models but not to binary models, such as Gaussian noise or other forms of regularization. As a result, I believe the comparison between floating-point and binary precision is not entirely fair. This issue is not unique to this paper but is also a limitation of prior work on binary and ternary precision.
Notably, with the convolutional network used in this study, standard floating-point precision can achieve an error rate below 9%. This further highlights the inadequacy of the baselines used in the paper.
The authors' response to my initial concerns has not addressed these issues satisfactorily. I maintain that the proposed techniques should be evaluated on more challenging scenarios to better demonstrate their effectiveness.