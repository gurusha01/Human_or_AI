The authors aim to evaluate "feature importance," specifically identifying which pixels contribute most to a network's classification of an image. A straightforward (though not particularly effective) approach for this is to compute the gradients of the predicted class with respect to each pixel in an input image \( I \). This assigns a score to each pixel in \( I \), reflecting how much the output prediction would change if that pixel were altered. Building on this, the authors propose a method to compute feature importance by calculating gradients of the output with respect to scaled versions of the input image, \( \alpha \cdot I \), where \( \alpha \) is a scalar between 0 and 1. They then integrate these gradients across all values of \( \alpha \) to derive their feature importance score. Here, scaling is a simple linear transformation of pixel values (\( \alpha = 0 \) corresponds to a completely black image, while \( \alpha = 1 \) corresponds to the original image). The authors refer to these scaled images as "counterfactuals," though this term feels unnecessarily exaggerated for what is essentially a scaled image.
The authors present several visualizations suggesting that their proposed feature importance score provides more reasonable results than simply examining gradients with respect to the original image. They also provide limited quantitative evidence indicating that the highlighted pixels are more likely to correspond to objects rather than spurious regions in the image (e.g., see Figure 5). The method is further applied to other types of networks. However, the quantitative results are sparse, and much of the paper focuses on qualitative analyses.
While understanding deep networks is an important goal, it is unclear whether this paper significantly advances that understanding. The most notable observation is that scaling an image by a small \( \alpha \) (i.e., creating a faint version of the image) tends to emphasize pixels on the object relevant to the correct class prediction. Beyond this, the paper extends the idea slightly but does not provide deeper insights. The authors offer a speculative explanation for why small \( \alpha \) values might encourage the network to focus on the object, but the argument is unconvincing. A more thorough investigation into this phenomenon would have been interesting, though it may not be straightforward.
Ultimately, the utility of the proposed feature importance ranking remains unclear. The method is still quite noisy and does not provide a meaningful understanding of how a deep network processes a specific image. Computing a single gradient step on an image (or its scaled versions) barely scratches the surface of probing a network's internal mechanisms. Additionally, as the authors acknowledge, the approach assumes pixel independence, which is an unrealistic simplification.
Given the simplicity of the proposed idea, the paper is unnecessarily lengthy. The main text spans 14 pages, extending to 19 with references and the appendix. The writing is verbose and overly detailed, which detracts from the paper's clarity. Furthermore, the authors introduce unnecessary terminologyâ€”terms like "Gradients of Counterfactuals" sound sophisticated but are not closely tied to the core ideas of the paper. I recommend the authors streamline their writing, condense the figures, and reduce the overall length to improve readability. Additionally, the key ideas should be articulated more clearly and concisely early in the paper.