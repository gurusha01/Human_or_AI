This paper introduces a modification to the standard VAE framework by replacing the commonly used Gaussian prior with a group sparse prior. Additionally, the authors adapt the approximate posterior function to produce group sparse samples. The development of novel generative models and inference mechanisms in VAEs is a significant and active area of research. However, I find the motivation for the specific prior proposed in this work to be insufficiently justified. Furthermore, several of the conceptual claims appear to be incorrect, and the experimental results are unconvincing. I also suspect that the reported log likelihoods are being compared in bits for the proposed method but in nats for competing algorithms, which raises concerns about the validity of the comparisons.
Detailed Comments:
1. Log Likelihood Reporting (Table 1):  
   The log likelihoods reported for competing methods in Table 1 are all presented in nats. However, the reported log likelihood for cVAE using 10K samples is suspiciously highâ€”it exceeds not only the likelihood of true data samples but also the likelihood achievable by fitting a 10K-component k-means mixture model to the data (as discussed in "A note on the evaluation of generative models"). This result is highly implausible, as it should be nearly impossible to outperform a 10K-component k-means mixture on Parzen estimation. This raises skepticism about the eVAE results. However, if the eVAE log likelihood is actually reported in bits (and subsequently converted to nats by multiplying by log 2), the values become much more plausible. Since some Parzen window implementations report log likelihoods in bits, it is critical to clarify whether the eVAE results are in bits or nats. The table should explicitly label the units (e.g., bits or nats) to avoid confusion.
2. Variational Lower Bound:  
   It would be highly beneficial to report and compare the variational lower bound on the log likelihood. If concerns about the looseness of the bound exist, techniques such as Annealed Importance Sampling (AIS) could be used to obtain a more accurate estimate of the log likelihood. Even if the Parzen window results are correct, it is worth noting that Parzen estimates of log likelihood are notoriously unreliable. They inherit the limitations of log likelihood evaluation while introducing additional drawbacks.
3. MNIST Sample Quality:  
   The visual quality of the MNIST samples does not appear to be competitive. Additionally, it seems that the images shown represent the probability of activation for each pixel rather than actual samples from the model. Actual samples would provide a more accurate assessment of the model's performance. Regardless, the figure should clearly describe what is being depicted.
4. Dataset Scope:  
   The paper does not include experiments on non-toy datasets, which limits the generalizability of the proposed method.
Responses to Authors' Rebuttal:
1. Minibatch Construction (Alg. 1, ln. 4):  
   The authors' explanation regarding balanced minibatches with respect to epitome assignment is appreciated and addresses some concerns about the utilization of all epitomes.
2. Factorial Approximate Posterior:  
   The response does not adequately address why Cvae would trade off between data reconstruction and being factorial. The approximate posterior is factorial by design, and there is no mechanism in Cvae to make it more or less factorial.
3. KL Term Deactivation:  
   The claim that "C_vae requires all examples in the training set to deactivate a unit for the KL term to be zero" is incorrect. A standard VAE can achieve a KL term of zero for some training examples by setting the variance to 1 and the mean to 0, while maintaining non-zero KL for other examples.
4. Overfitting and Generative Model Likelihood:  
   The VAE loss optimizes a lower bound on the log likelihood, which includes a term resembling reconstruction error. Intuitively, overfitting should correspond to data samples becoming more likely under the generative model.
5/6. Parzen Window Concerns:  
   As noted earlier, Parzen estimates of log likelihood are highly unreliable. It is also unusual to train a binary model and then treat its probability of activation as a sample in a continuous space. Additionally, the claim that "we can only evaluate the model from its samples" is not accurate. The training process directly optimizes a lower bound on the log likelihood, which provides an alternative method for quantitative evaluation. Techniques like AIS could also be employed for exact log likelihood computation.
7. Parzen Window Evaluation:  
   I disagree with the assertion that Parzen window evaluation is a better measure of model quality than log likelihood, even in terms of sample generation.
Summary:  
While the paper explores an interesting direction by introducing a group sparse prior in VAEs, the motivation for this choice is not sufficiently supported, and several conceptual and experimental issues remain unresolved. The experimental results, particularly the log likelihood comparisons, are questionable and require clarification. Furthermore, the lack of experiments on more challenging datasets limits the broader applicability of the proposed method. Addressing these concerns would significantly strengthen the paper.