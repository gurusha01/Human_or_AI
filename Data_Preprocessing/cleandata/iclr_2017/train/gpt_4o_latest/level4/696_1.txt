The paper seeks to synthesize recent literature on straightforward "reading comprehension" tasks, where the goal is to match questions with answers located within a passage, and subsequently investigate the structural patterns learned by these models while proposing potential modifications. The datasets used for these tasks, such as CNN/Daily Mail, are relatively simple, as they typically do not require reasoning across multiple pieces of evidence, unlike more complex datasets like MCTest. Numerous models have been developed for this task, and the paper categorizes them into two groups: "aggregation readers" and "explicit reference readers." The authors demonstrate that aggregation readers organize their hidden states into a predicate structure, enabling them to emulate the behavior of explicit reference readers. They also experiment with incorporating linguistic features, including reference features, into existing models to enhance performance.
I commend the authors for re-naming and re-framing the paper to emphasize that aggregation readers specifically learn a predicate structure, as well as for including results related to the dimensionality of the symbol space. Additionally, the effort to classify and organize various reading comprehension models into broader categories is valuable, given the rapid proliferation of such models and the lack of clarity in the field.
However, there are some concerns with the paper. The predicate structure identified is relatively simple, and it is unclear whether it offers meaningful insights for developing improved models in the future, especially since "explicit reference readers" do not necessarily rely on it. Furthermore, the CNN/Daily Mail dataset has limited room for performance improvement, as shown by Chen et al. (2016), and the "dramatic improvements in performance" mentioned in the discussion section are unlikely to be achievable on these datasets. More complex datasets, which would require multi-hop inference, are not addressed in this paper. Additionally, the paper's message feels somewhat scattered and could benefit from greater focus and clarity.
While I believe that efforts to organize and analyze the growing array of neural network models for NLP tasks are important, this paper may be better suited for an NLP-focused conference or journal, such as TACL.