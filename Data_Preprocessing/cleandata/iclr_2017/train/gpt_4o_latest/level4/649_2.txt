This paper investigates the impact of various context types on the quality of word embeddings across a wide range of benchmarks.
I have mixed feelings about this work. On the one hand, it extends an important research direction by disentangling different factors in embedding algorithms, with a particular focus on context in this case. On the other hand, I am uncertain about the overarching takeaway from the experiments. The results do not seem to demonstrate a clear and consistent advantage for any specific context type. Why might this be the case? Are the benchmarks sufficiently sensitive to capture these differences, assuming they exist?
While I am open to the paper being accepted, I would prefer a more comprehensive version that addresses these deeper questions.
Additionally, there are several other context types that warrant discussion; for example, see "Open IE as an Intermediate Structure for Semantic Tasks" (Stanovsky et al., ACL 2015).