This paper introduces a method for jointly learning word vector representations for character sequences and acoustic spans. The writing is clear, and the proposed approach and experiments appear to be well-executed. However, the motivation and tasks seem somewhat artificial, as they rely on the assumption that acoustic spans for words have already been segmented from continuous speechâ€”a significant limitation. The evaluation tasks also feel somewhat contrived, particularly in the context of character-based comparisons, where phoneme-based comparisons should also be included.
The paper places considerable emphasis on character edit distance in relation to acoustic span similarity. It would be more natural and informative to incorporate phoneme string edit distance into both the discussion and the experiments. This is particularly relevant for the word similarity task. Instead of focusing solely on Levenshtein edit distance for characters, the evaluation should also consider the edit distance of phoneme strings relative to the acoustic embedding distances. Furthermore, the paper would be more compelling if it compared character embeddings with phoneme string embeddings. This could be achieved by simply replacing characters with phonemes as the symbol set, without altering the core function. Additionally, the discussion and experiments should address homophones, as it is unclear how the network would handle such cases.
The limited vocabulary size and the amount of training data reduce the problem to a toy setting. While many pairs are constructed, most of these pairs are likely to be easily distinguishable. The experiments and conclusions would be significantly strengthened by using a larger vocabulary and word segmentation dataset, with subsampling that prioritizes more challenging or similar pairs.
Finally, this approach seems ill-suited for tasks like keyword spotting in longer spoken utterances. If this is indeed the case, the paper should include a discussion explaining why the focus is on learning word embeddings given pre-segmented words. The motivating example of using this method for word retrieval appears flawed if a recognizer is required to segment words beforehand.