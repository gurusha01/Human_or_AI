This paper provides a theoretical analysis of transformation groups applied to convolutional neural networks (convnets) and includes empirical results demonstrating more efficient utilization of network parameters.
The core concept of steerability is highly compelling and appears to be a significant idea worth further exploration. However, it is not a new concept in image processing, as it can be traced back to the work of Simoncelli, Freeman, Adelson, Perona, Greenspan, and others from the early 1990s. This paper revisits the idea through the lens of group theory, offering a formal treatment. Ultimately, though, the underlying principle seems straightforward: the feature representation of a transformed image should correspond to the transformed feature representation of the original image. Since the authors restrict their analysis to discrete groups—such as rotations of 0, 90, 180, and 270 degrees—the use of group-theoretic formalism feels somewhat excessive. It is unclear what practical advantages this formalism provides. The real challenge seems to lie in handling continuous transformations, and if the theoretical framework could address that, it would be substantially more impactful.
Additionally, the experimental section is described in a way that lacks clarity. It would be challenging to reproduce the authors' implementation of capsules or transformation groups based on the information provided.