This paper introduces a novel perspective for understanding ResNet and Highway networks. The proposed perspective conceptualizes the blocks within networks featuring residual or skip connections as groups of consecutive layers with identical hidden sizes. These blocks are interpreted as iteratively refining estimates of the same feature rather than generating entirely new representations. Under this framework, certain contradictions arising from the traditional representation view of ResNet, Highway networks, and related works can be effectively explained.
Strengths of the paper:
1. The paper presents a fresh perspective on recent advancements in neural networks.
2. It includes quantitative experiments comparing ResNet and Highway networks, revealing results that contradict several claims from prior studies. The authors provide discussions and explanations for these contradictions, offering valuable insights into the strengths and weaknesses of these two types of networks.
Weaknesses of the paper:
The primary limitation of the paper lies in the insufficiency of its experimental validation. For instance, while the main contribution is the introduction of the "unrolled iterative estimation" perspective, stage 4 in Figure 3 appears to deviate from this assumption. The authors acknowledge this by stating: "We note that stage four (with three blocks) appears to be underestimating the representation values, indicating a probable weak link in the architecture." To strengthen the paper, additional experiments should be conducted to demonstrate conditions under which stage 4 aligns with the proposed assumption.
Furthermore, the paper would benefit from more experiments providing direct evidence for the "unrolled iterative estimation" framework, rather than focusing solely on comparisons between ResNet and Highway networks. The lack of experimental support for this central claim is my primary concern.