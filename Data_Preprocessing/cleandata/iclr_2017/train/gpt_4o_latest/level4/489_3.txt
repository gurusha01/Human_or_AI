This paper conducts a series of experiments to explore the types of information captured by common unsupervised methods for sentence representation learning. The findings are non-trivial and, in some cases, unexpected. For instance, the authors demonstrate that word order can be reconstructed from bag-of-words representations, and they show that LSTM sentence autoencoders encode interpretable features even when trained on randomly permuted, nonsensical sentences.
Unsupervised sentence representation learning is a critical and still largely unresolved challenge in NLP, and this study appears to provide a meaningful contribution toward addressing it. Moreover, the experimental framework introduced in this work seems broadly applicable to other representation learning systems. While some of the results are somewhat unusual, I do not identify any major technical flaws and find the findings to be insightful. I recommend acceptance.
One minor concern:
- The sharp decline in CBOW performance in Figures 1b and 4b is not explained and appears implausible enough to merit further investigation. Are you confident that these results would hold with a different codebase or random seed implementing the same model? However, this issue is largely tangential to the paper's primary conclusions.
Two writing suggestions:
- While the results involving word order and CBOW are indeed surprising, it may be slightly misleading to claim that CBOW is predictive of word order. CBOW does not encode word order directly, but it does contain sufficient information to probabilistically reconstruct word order.
- The statement that "LSTM auto-encoders are more effective at encoding word order than word content" is problematic, as these two aspects are not directly comparable.