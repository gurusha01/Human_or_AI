This paper explores computational creativity through the lens of machine learning. It defines creativity as a model's capacity to generate novel types of objects that were not encountered during training. The authors contend that likelihood-based training and evaluation are inherently unsuitable for generating out-of-class objects and propose a novel evaluation framework. This framework leverages held-out object classes to assess a model's ability to produce new and interesting object types.
I am not deeply acquainted with the computational creativity literature, so I am unable to assess how effectively this work is situated within the context of prior research. However, from a machine learning standpoint, I find the ideas presented in this paper to be innovative, intriguing, and intellectually stimulating.
As I understand it, the authors hypothesize that a model's ability to generate new and interesting types of objects we do not know about is correlated with its ability to generate new and interesting types of objects we do know about, with the latter serving as a reasonable proxy for the former. The validity of this hypothesis depends on the bias introduced during model selection. Similar to evaluating generalization performance, it is crucial to avoid reusing the same held-out classes for both model selection and evaluation.
That said, I appreciate the authors' effort to formalize the concept of computational creativity within a machine learning framework. I see this as an important foundational step in this area, and I believe the paper merits acceptance at ICLR, particularly given its clarity and accessibility for machine learning researchers.