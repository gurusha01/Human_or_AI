This paper introduces and evaluates two main ideas: (1) a network pruning method that identifies highly correlated neuron pairs, removes one neuron from each pair, and adjusts downstream weights to compensate for the removal (effective when the removed neurons are highly correlated); and (2) a technique called NoiseOut, which aims to increase neuron correlation by introducing auxiliary noise target outputs during training.
The first idea (1) is relatively straightforward, and it is unclear whether it has been previously explored. Nonetheless, it appears to be effective.
The second idea (2) has questionable utility and seems to this reviewer to primarily act as a regularization mechanism. Specific observations include:
- In Fig. 4 (right), the constant and Gaussian noise treatments appear to yield similar effects across both networks, while the Binomial noise treatment seems comparable to No_Noise. If this interpretation is correct, can it be inferred that the NoiseOut targets primarily serve to regularize the network by slightly reducing its capacity?
- To verify this hypothesis, comparisons with other capacity-reduction methods are necessary, such as reducing the number of neurons, applying L2 regularization at varying strengths, or using Dropout with different probabilities. While Fig. 7 attempts to address this, it omits critical comparison baselines, such as "Pruned without any regularization," "Pruned with only L2," and "Pruned with only DropOut." Have these experiments been conducted? If so, their results should be included and used to generate plots analogous to Fig. 5 and Fig. 7.
Without these comparisons, it is difficult to determine whether NoiseOut offers any unique benefits beyond providing regularization effects similar to DropOut or L2 regularization.
The combination of ideas (1) and (2) does achieve a significant reduction in parameters. However, the experiments and explanations lack sufficient depth to fully elucidate the underlying mechanisms. With additional effort, this work has the potential to be compelling, but in its current form, it is not ready for acceptance.
Additional comments:
- Section 4 states: "In all of these experiments, the only stop criteria is the accuracy decay of the model. We set the threshold for this criteria to match the original accuracy; therefore all the compressed network have the same accuracy as the original network." Is the accuracy being referred to here the training accuracy or the test accuracy? If it is training accuracy, the corresponding test accuracy should be reported (how much test performance is lost due to pruning?). If it is test accuracy, this approach could be considered "cheating," and the authors need to explicitly clarify and justify this choice.
- The use of lowercase rho to denote correlation is never explicitly defined, which may confuse readers. Please clarify this notation by stating that it represents correlation.
- How do the results compare to other pruning methods? No numerical comparisons are provided, which limits the ability to contextualize the proposed approach.