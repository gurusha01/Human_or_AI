* Summary:  
This paper introduces a neural machine translation model that performs end-to-end translation from characters to characters for both source and target texts. The model incorporates morphology learning in the encoder and employs a hierarchical decoder in the decoding process. The authors present compelling results across multiple bilingual corpora for various language pairs. The paper is well-written, and the results are competitive when compared to other baselines in the field.
* Review:  
   - The paper is well-written, and I appreciate the clarity and precision of the analysis presented.  
   - While the use of hierarchical decoders is interesting, similar ideas have been explored in prior work, such as [1]. Could you include citations to these papers?  
   - This work primarily applies existing techniques to character-level NMT tasks. While it is commendable that the authors have made their code publicly available, the contributions from a broader machine learning perspective remain somewhat limited.  
* Some Requests:  
   - Could you include the size of the models in Table 1?  
   - Could you provide examples of failure cases where the model struggled to translate correctly?  
* An Overview of the Review:  
Pros:  
   - The paper is well-written and clear.  
   - Provides extensive analysis of the model across various language pairs.  
   - Experimental results are convincing.  
Cons:  
   - The model is complex.  
   - Primarily an architecture engineering/application paper that combines well-known techniques, with limited novelty.  
   - The proposed model may be slower than traditional models, as it operates at the character level and involves multiple RNNs.  
[1] Serban IV, Sordoni A, Bengio Y, Courville A, Pineau J. Hierarchical neural network generative models for movie dialogues. arXiv preprint arXiv:1507.04808. 2015 Jul 17.