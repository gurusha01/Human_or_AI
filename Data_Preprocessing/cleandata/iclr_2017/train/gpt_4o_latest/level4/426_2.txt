The paper investigates bilingual word representation learning under the following framework:
1. Bilingual representations are learned in an offline manner, meaning that monolingual embeddings for both the source and target languages are pre-trained, and a shared mapping is subsequently learned between these two embeddings.
2. There are no direct word-to-word alignments available between the source and target languages.
This is a highly practical and relevant setting, and the authors have done commendable work in consolidating existing approaches to this problem while providing theoretical justifications. Although the authors do not introduce a novel method for offline bilingual representation learning, the paper makes the following noteworthy contributions:
1. Theoretical insights into offline bilingual representation learning.
2. The use of inverted softmax.
3. Incorporating cognate words for languages with similar scripts.
4. Demonstrating that the approach extends, to some extent, to sentence-level tasks.
The authors have adequately addressed all my pre-review questions, and I am satisfied with their responses. However, I have a few additional comments:
1. The header for Table 3, labeled "word frequency," is somewhat misleading. "Word frequency" could imply that rare words are listed in row-1, whereas I believe the authors intended to indicate that rare words are found in row-5.
2. I noticed that precision @5 and @10 metrics have been removed from Table 6. Was this due to space constraints, or do the results exhibit a different trend? I recommend including these metrics in the appendix for completeness.
3. In Table 6, what distinguishes row-3 from row-4? Is the sole difference the use of NN versus inverted softmax, or are there additional variations? Please clarify.
4. I suggest conducting an additional experiment that combines both the expert dictionary and the cognate dictionary. Comparing all three methods in this combined setting could provide deeper insights into the utility of the cognate dictionary.