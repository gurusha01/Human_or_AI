This paper introduces a novel approach that incorporates the previous error signal of the output layer as an additional input to the recurrent update function, aiming to improve the modeling capabilities of dynamic systems like RNNs.
- The paper is based on a flawed assumption: test label information is generally unavailable in most real-world scenarios, with only a few exceptions. Consequently, the language modeling task, which serves as the sole experimental evaluation in this paper, may not be an appropriate benchmark for this method. Furthermore, comparing this approach to models that do not utilize test error signals during inference is inherently unfair. Simply stating that test label information is accessible is insufficient, as this assumption is only valid in online prediction settings.
- The experimental evaluation is limited to a single dataset, where the paper claims state-of-the-art performance. However, this claim is inaccurate, as there are at least four other papers reporting superior results for this task, none of which are cited. While it is understandable that this work predates those papers, the manuscript should be revised to reflect these developments before a final decision is made.
- The paper does not provide information about the model size, which is a critical omission. Without this detail, it is difficult to accurately assess the contribution of the proposed method.