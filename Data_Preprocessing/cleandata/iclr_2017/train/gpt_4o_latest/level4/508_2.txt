The paper makes a contribution to the growing body of research on applying neural networks to graph-structured data. To the best of my understanding, the proposed method involves the following steps:
1. Construct a hierarchical organization of "objects" within the graph. Each object is composed of multiple "parts" derived from the objects at the preceding level. There appear to be different ways in which a part can belong to an object (referred to as \(\pi\) labels), which might be better described as "membership types." In the experiments, the lowest-level objects correspond to vertices. At the next level, objects are radius-0 (essentially a single vertex?) and radius-1 neighborhoods around each vertex, with membership types labeled as "root" or "element" (depending on whether a vertex is the center of the neighborhood or a neighbor). At the top level, there is a single object encompassing all these neighborhoods, with membership types designated as "radius-0 neighborhood" (is this still just a vertex?) or "radius-1 neighborhood."
2. Each object is assigned a representation. At the vertex level, representations are one-hot encodings of vertex degrees. To compute the representation of an object at the next level, the following process is applied:
   a. For each object, sum the representations of all its parts that share the same membership type.
   b. Concatenate the sums corresponding to different membership types.
   c. Pass the resulting vector through a multi-layer neural network.
I have provided this summary because the paper's description is somewhat difficult to follow, with key details scattered throughout the text. I would like to confirm whether my interpretation is accurate.
There are additional questions that remain unclear from the paper: How many layers and hidden units are used in the neural network? What are the dimensionalities of the representations at each level? How is the final classification task performed? What is the rationale behind using the "ego-graph" representation?
The proposed approach is both novel and interesting, with an effective compression technique and promising results. However, the paper suffers from poor clarity and structure. It took considerable effort to piece together the methodologyâ€”the initial description lacks illustrative examples, and understanding the role of the \(\pi\) labels required jumping between sections of the paper. Furthermore, critical details about the network architecture are missing, and there is little explanation or justification for many of the design choices. For instance, were alternative decomposition or object-part structures considered, given the flexibility of the shift-aggregate-extract framework? What motivated the choice of "ego-graphs"? Why were one-hot encodings of vertex degrees chosen as initial attributes?
In summary, the paper offers a technically valuable contribution, but significant improvements in presentation and organization are necessary before it can be recommended for acceptance.