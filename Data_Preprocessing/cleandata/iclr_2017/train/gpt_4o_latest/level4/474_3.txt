This paper introduces an intriguing framework, building upon the authors' prior work, to learn compositional rules for creating improved music. The system comprises two main components: a generative component (student) and a discriminative component (teacher). The generative component, modeled as a Probabilistic Graphical Model, generates music by adhering to learned rules. The teacher evaluates the generated music against the empirical distribution of exemplar compositions (e.g., Bach's chorales) and suggests new rules for the student to learn, facilitating iterative improvement.
Unlike GANs, the proposed framework is notable for the interpretability of both its generative and discriminative components. Based on the paper, the system appears capable of learning meaningful rules from composed music and applying them effectively in subsequent iterations, particularly when trained using a curriculum-based approach. However, the lack of comparisons with the authors' previous system or other straightforward baselines, such as an LSTM generative model, raises some concerns.
I found the paper somewhat challenging to follow, primarily due to (1) the extensive use of music-specific terminology (e.g., Table 1 is difficult to interpret) that complicates understanding of the system's performance, and (2) the presentation of overly complex mathematical symbols and concepts. For instance, on Page 4, terms like raw/high-level feature, Feature-Induced Partition, and Conceptual Hierarchy all refer to a non-overlapping hierarchical clustering in a 4-dimensional feature space. Additionally, the so-called Informational Hierarchy seems to be a list of rules rather than a true hierarchy. A clearer and more straightforward presentation would significantly enhance readability.
In summary, the paper presents a functional and potentially interesting system. However, I do not feel confident enough to draw strong conclusions about its contributions.