Review - Summary  
This paper builds upon and examines the gradient regularizer introduced by Hariharan and Girshick (2016). That work proposed a regularizer that penalizes gradient magnitudes, demonstrating its utility in improving low-shot learning performance. The current paper reveals that the earlier regularizer is mathematically equivalent to directly penalizing the magnitude of feature values, with the penalty weighted differently for each example.  
The analysis includes two illustrative cases where a feature penalty leads to improved representations. The first example tackles the XOR problem, showing how a feature penalty can encourage a representation that makes XOR linearly separable within a specific network. The second example considers a two-layer linear network, demonstrating that adding a feature penalty enhances the stability of a second-order optimizer. Additionally, the paper interprets the regularizer as a Gaussian prior on both features and weights, which can be seen as inducing a soft whitening effect. This interpretation links the feature regularizer to a soft version of Batch Normalization.  
Experimental results show modest gains on a synthetic XOR dataset. On the Omniglot dataset, feature regularization outperforms most baselines but falls short of the performance achieved by Matching Networks. Finally, an ImageNet experiment, similar to Hariharan and Girshick (2016), confirms the effectiveness of the proposed approach for low-shot learning.  
---
Strengths  
- The paper proposes a straightforward modification of the gradient regularizer introduced by Hariharan and Girshick (2016).  
- The concept of feature regularization is explored from multiple perspectives, both theoretically and empirically.  
- The connection between feature regularization and Batch Normalization has the potential for broader implications.  
---
Weaknesses  
- In Section 2, the gradient regularizer from Hariharan and Girshick (2016) is introduced, but the motivation behind it is questioned: "And it is not very clear why small gradients on every sample produces good generalization experimentally." This issue seems central, yet the paper, while providing related analysis, does not offer a definitive explanation.  
- The purpose and general applicability of Section 2.1 are unclear. The analysis presents a specific case (XOR with a non-standard architecture) where feature regularization intuitively aids representation learning. However, the intended takeaway is ambiguous.  
  One possible takeaway is that feature penalties, being effective in this case, might generalize to other cases. However, this argument is unconvincing due to the specific architecture used, which relies on an \(x^2\) non-linearity—a choice uncommon in modern neural network literature.  
  Alternatively, the section might aim to highlight differences between weight penalties and feature penalties, as the two encourage distinct values of \(b\) in this example. However, no direct comparison to a weight penalty on \(b\) is provided in Section 2.1.  
- Equation 3 appears to assume either an L2 or cross-entropy loss, but the paper does not specify a broader class of losses for which Equation 3 holds. This limitation should be clarified before presenting Equation 3.  
- The Omniglot and ImageNet experiments are conducted with Batch Normalization, despite the paper suggesting that feature regularization may have a similar effect. While the results demonstrate that the proposed regularizer provides additional benefits beyond Batch Normalization (as evidenced by improvements over the ResNet CNN baseline), experiments without Batch Normalization should be included to enable a direct comparison between the two methods.  
- The ImageNet experiment could more closely follow the methodology of Hariharan and Girshick (2016). Specifically, the same class split (provided in their appendix) should be used, and performance should be evaluated with \(n > 1\) novel examples per class (using k-nearest neighbors).  
---
Minor Points  
- While Section 3.2 briefly compares the proposed method to Matching Networks, the performance of Matching Networks should also be reported in Table 1 for completeness.  
- In the approach section, the statement "Intuitively when close to convergence, about half of the data-cases recommend to update a parameter to go left, while the other half recommend to go right" could be clarified. In high-dimensional spaces, there are many possible directions and ways to divide them into two groups, making the intuition unclear.  
- It would be helpful to clarify whether the SGM penalty from Hariharan and Girshick (2016) was re-implemented for this paper or if their original code was used. Either approach is acceptable, but this detail should be specified.  
- In Equation 13, should the first equal sign be replaced with a proportionality symbol instead?  
- The paper is dense, and its presentation could be improved. For instance, more detailed derivations could be included in an appendix, while some technical details (e.g., the derivation in Section 2.2.1) could be moved out of the main text to improve focus on the results.  
---
Overall Evaluation  
This paper offers an intriguing set of analyses, though their broader significance remains unclear. The central question—why a gradient or feature regularizer improves low-shot learning performance—lacks a definitive answer. Nonetheless, the experiments support the utility of the proposed regularizer, the analyses are interesting in their own right, and they may pave the way for a clearer understanding in the future.  
Overall, the work represents a somewhat novel extension and analysis of Hariharan and Girshick (2016), though certain aspects, as outlined above, require further clarification.