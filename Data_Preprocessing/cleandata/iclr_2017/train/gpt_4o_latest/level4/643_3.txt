I appreciate the authors' detailed response and clarifications.
This study introduces a novel training framework for online sparse dictionary learning, designed to handle a non-stationary stream of incoming data. The primary objective—and challenge—is to develop a model capable of adapting to new data in an online manner while retaining the ability to represent previously encountered data. The proposed approach addresses this challenge by incorporating a mechanism to dynamically add or remove atoms from the dictionary, drawing inspiration from the adult neurogenesis phenomenon observed in the dentate gyrus of the hippocampus.
The paper presents two key contributions over the baseline method (Mairal et al.): (i) "neuronal birth," an adaptive mechanism for expanding the dictionary by adding new atoms, and (ii) "neuronal death," which removes "redundant" or "useless" atoms from the dictionary.
Neuronal death is achieved by introducing a group-sparsity regularization term applied to the dictionary atoms (where each group corresponds to a dictionary column). This regularization encourages the removal of less useful atoms by shrinking them to zero, thereby controlling the growth of the dictionary size.
One of the paper's strongest aspects is its connection to the adult neurogenesis phenomenon, which I find to be a particularly appealing feature. Additionally, the manuscript is well-written and easy to follow.
However, the overall methodology lacks significant novelty. While not identical, similar ideas have been explored in prior work. Although neuronal death is implemented elegantly through a sparsity-promoting regularization term, neuronal birth relies on heuristic measures of how well the dictionary represents new incoming data. These heuristics may be challenging to tune, especially in scenarios with highly non-stationary data or the presence of outliers. Nevertheless, the concept of an adaptive dictionary size remains an intriguing contribution.
The authors may also consider citing additional references from the model selection literature. For example, the Minimum Description Length (MDL) principle has been employed for automatic dictionary size selection. While such methods may not directly address the online setting, they are still relevant and could enrich the discussion. A particularly relevant reference is:
Ramirez, Ignacio, and Guillermo Sapiro. "An MDL framework for sparse coding and dictionary learning." IEEE Transactions on Signal Processing 60.6 (2012): 2913-2927.