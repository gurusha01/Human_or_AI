The authors examine the neural GPU model originally proposed by Kaiser and Sutskever. In Section 3, they attribute its performance to the O(n^2) number of steps it can execute per example. Following this, they emphasize the significance of curriculum training and empirically demonstrate that larger models exhibit better generalization. In Section 5, they construct examples to expose failure modes. In the final section, they compare performance across different input formats.
The paper is well-written and includes a comprehensive set of experiments that shed light on the intricacies of training the neural GPU model. It advances the understanding of learnable algorithms. However, the paper lacks a unified central message and does not provide sufficient insight into the underlying reasons for the observed phenomena (e.g., why curriculum training is crucial or why specific failure modes arise).
The introduction contains several assertions that require clarification or further elaboration. To my knowledge, statistical learning theory does not guarantee that empirical risk minimization remains consistent when the number of parameters exceeds the number of examples; instead, generalization performance depends on the VC dimension of the function space. Additionally, the proposed connection between adversarial examples and learning algorithms is weak, and the claim that deep neural networks can match the performance of any parallel machine learning algorithm needs either supporting references or further justification.
The authors assert that the neural GPU performs O(n^2) "steps" per example, enabling it to learn algorithms with super-linear complexity, such as multiplication. However, this analysis appears to neglect the parallel nature of the neural GPU architecture: both addition and multiplication have O(log n) time complexity when parallelism is leveraged (e.g., using a carry-lookahead adder or a Wallace tree).
In Section 4, the authors show that larger models generalize better, which they argue is not immediately obvious. However, since both training and test errors decrease, it is likely that the smaller models are underfitting, making it unsurprising that larger models achieve better generalization.
The observation that progressively reducing the number of terms while increasing the radix of the number system serves as an effective learning curriculum is intriguing. Nonetheless, a stronger intuitive or theoretical explanation for the effectiveness of this approach would be beneficial.
The final section claims that neural GPUs function as cellular automata. Additional justification for this claim is necessary, as cellular automata are inherently discrete models, and the equivalence between the two frameworks is not immediately apparent. Furthermore, the connection between global operations and changes to the input format is somewhat convoluted.
In summary, while the paper offers valuable insights into the neural GPU model, it does not propose original extensions to the model or address fundamental limitations. Several claims require more robust substantiation.
Pros:
- Clear and well-written
- Comprehensive experimental evaluation
- Exploration of learning algorithms with decimal representation
- Source code availability
Cons:
- Lacks a cohesive central hypothesis or premise
- Contains a few bold claims without sufficient explanation or references
- Some ambiguity in experimental details
- Limited novelty and originality
Typos:
- Add a minus sign in "chance of carrying k digits is 10^k" (Section 5)
- Remove "are" from "the larger models with 512 filters are achieve" (Section 4)
- Add "a" in "such model doesn't generalize" (Section 4)