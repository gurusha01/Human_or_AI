This paper introduces the Layerwise Origin Target Synthesis (LOTS) method, which involves calculating a difference in representation at a specific layer of a neural network and then mapping that difference back to the input space using backpropagation. Two types of differences are examined: linear scalings of a single input's representation and difference vectors between representations of two inputs belonging to different classes.
In the first case, the LOTS method serves as a visualization tool for the representation of a specific input example, illustrating what it would mean, in input space, for the feature representation to be either suppressed or amplified. While this is an intriguing computation, the practical utility of these visualizations remains unclear.
In the second case, LOTS is employed to generate adversarial examples by moving an origin image incrementally toward a target image until the classification flips. As anticipated, the magnitude of the required changes decreases when LOTS targets higher layers in the network (approaching the last layer yields results similar to traditional adversarial image generation methods).
Overall, the paper presents an interesting foundational exploration and would likely make an excellent workshop contribution. However, the results do not appear sufficiently compelling to justify acceptance as a full ICLR paper.
A few recommendations for improvement:
- The paper frequently claims that LOTS could be used to mine diverse adversarial examples for training classifiers that are more robust to adversarial perturbations. However, the authors do not conduct the straightforward experiment of training on LOTS-generated examples. Demonstrating whether LOTS outperforms established methods like FGS would significantly strengthen the paper.
- The architecture details of the networks used in the experiments are not provided. For example, it is unclear how many layers the networks have or their internal structure. This omission left me wondering, for instance, whether the CONV21 layer in Fig. 2 directly follows the CONV11 layer or whether the FC8 layer is the network's final layer.
- Figures 1, 2, 3, and 4 present results of applying LOTS to various intermediate layers but omit its application to the input (data) layer and the output/classification (softmax) layer. Including these results would provide a more comprehensive view of the method's behavior (e.g., in Fig. 3, do even larger perturbations occur in pixel space compared to CONV1 space? Does operating in softmax space result in smaller perturbations than in IP2?).
- The PASS score is mentioned multiple times but is never explained. For instance, Fig. 1 uses the PASS score without clarifying whether higher or lower values correspond to more or less severe perturbations. A brief explanation would greatly aid understanding.
- Section 4.2 states: "In summary, the visualized internal feature representations of the origin suggest that lower convolutional layers of the VGG Face model have managed to learn and capture features that provide semantically meaningful and interpretable representations to human observers." This conclusion does not seem to follow from the presented results. If this claim is central to the paper, it should be substantiated with additional evidence or arguments.
1/19/17 UPDATE AFTER REBUTTAL:
Following the addition of new experiments in the revised version of the paper, I am raising my score from 5 to 6. I now believe the paper is just above the acceptance threshold.