Review - Summary:  
This paper explores the estimation of log-likelihoods for popular decoder-based generative models using annealed importance sampling (AIS) and Hamiltonian Monte Carlo (HMC). The authors validate their approach with bidirectional Monte Carlo on the MNIST dataset and compare the performance of GANs and VAEs.
Review:  
While this work appears to be a relatively straightforward application of AIS (please correct me if I have overlooked any key innovations that make this approach unique), I greatly value the paper's educational insights and empirical contributions. It has the potential to bring clarity to ongoing debates about the density estimation capabilities of GANs and could encourage broader adoption of AIS within the community.
If space allows, it might be beneficial to expand on the explanation of AIS. While the paper outlines the components of AIS and provides a basic description of the algorithm, it does not sufficiently explain why the algorithm works or the intuition behind its mechanics.
I initially found the large numerical differences in Figure 2 somewhat confusing. At first glance, I assumed that the figure was comparing GAN, GMMN, and IWAE models due to the labels at the bottom and the phrasing in the caption. It might help to explicitly state in the caption that panels (a) and (b) use continuous MNIST, while panel (c) uses discrete MNIST. Additionally, the label "GMMN-50" should likely be corrected to "GMMN-10."
Using reconstructions to evaluate models may be a necessary but insufficient criterion for assessing model quality. For instance, depending on the likelihood, a posterior sample could have very low density under the prior. It would be valuable if the authors could elaborate on and discuss the limitations of this evaluation approach in greater detail.
Minor Comments:  
- Consider adding a reference to MacKay's density networks (MacKay, 1995) as it is relevant to decoder-based generative models.  
- In Section 2.2, the authors state, "the prior over z can be drastically different than the true posterior p(z|x), especially in high dimension." The flow of the paper could be improved here, particularly for readers less familiar with importance sampling or AIS. At this point, the relevance of the posterior to importance sampling may not be entirely clear.  
- In Section 2.3, the authors argue that it is often more "meaningful" to estimate p(x) in log-space due to underflow issues. The term "meaningful" might not be the most appropriate choice here. It could be revised to state that estimating log p(x) is more practical due to underflow problems or that it is more meaningful in the context of its connections to compression, surprise, or entropy.