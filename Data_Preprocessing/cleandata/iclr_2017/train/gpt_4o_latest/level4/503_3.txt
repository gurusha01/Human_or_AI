This paper introduces the Gated Multimodal Unit (GMU) model for information fusion. The GMU employs multiplicative gates to determine how different modalities influence the unit's activation. The authors compiled a large genre dataset from IMDB and demonstrated that the GMU achieves strong performance.
The proposed approach is intriguing, and it is reasonable to expect that it could be applied to broader scenarios beyond movie genre prediction. However, the paper does not test the algorithm on other applications, which I consider its most significant limitation.
Another issue pertains to the evaluation of information fusion performance. The abstract states, "The model improves the macro f-score performance of single-modality models by 30% and 4% with respect to visual and textual information respectively." However, such improvements are not the central focus. When two modalities are complementary, fusion results are naturally expected to outperform single-modality models. The critical question is how much better the GMU performs compared to established baselines. Given the extensive range of existing fusion techniques, it is challenging to make a compelling case based on experiments with a single dataset. While the GMU performs well on the movie dataset, I would also anticipate that other techniques, such as fine-tuning, dropout, or distillation, could enhance performance. A comparison with these methods would strengthen the paper.
Additionally, I would like to see a more detailed discussion of the connection between the GMU and the mixture-of-experts (MoE) model. Both rely on nonlinear gated functions and may face challenges such as local minima during optimization on small datasets. A deeper exploration of their similarities and differences would be valuable.
To increase the impact of the GMU, I encourage the authors to open-source their code and evaluate the model on additional datasets.