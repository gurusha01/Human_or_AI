1) Summary
This paper introduces an end-to-end hybrid model designed to predict local linear trends in time series data. The approach involves a temporal convolutional network (convnet) applied to raw data for extracting short-term features, while long-term patterns are captured using an LSTM operating on piecewise linear approximations of the time series. These two representations are then merged through a multi-layer perceptron (MLP) with a single hidden layer (split into two parts, one for each stream). The entire model is trained end-to-end using the Adam optimizer to minimize the l2-regularized Euclidean loss with respect to the ground truth durations and slopes of local trends.
2) Contributions
+ The paper presents an innovative end-to-end architecture that separates short-term and long-term representation learning into two distinct streams in the initial stages of the model.
+ Provides comparisons against both deep and shallow baseline methods.
3) Suggestions for improvement
Incorporate an LRCN baseline and related discussion:  
To better evaluate the advantages of separating short-term and long-term representation learning, the authors should include a comparison with the widely-used "long-term recurrent convolutional network" (LRCN) proposed by Donahue et al.