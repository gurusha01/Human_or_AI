Hello Authors,
Congratulations on the acceptance of your paper.
Upon revisiting sections of the revised manuscript, I noticed a few points that you may want to address before the camera-ready submission deadline.
* While you now cite KLIEP after Eqn. (16), this procedure is more accurately described as least-squares importance estimation.
* Conversely, Eqn. (14) aligns more closely with KLIEP, with the key distinction being the use of the unnormalized form of the KL-divergence. It seems likely that the KLIEP reference was intended for this equation instead.
Additional thoughts on making Eqn. (14) practical:
In the KLIEP paper, the procedure is framed as a constrained optimization problem:
maximize  
$$
E{p^*} \log r\phi(x)
$$  
subject to the constraint  
$$
E{q\theta} r_\phi(x) = 1
$$  
By comparing this constrained optimization to your approach, the connection becomes evident: introducing a Lagrange multiplier to handle the constraint transforms the problem into the following unconstrained optimization task:
find stationary points of  
$$
\ell(\phi, \lambda) = E{p^*} \log r\phi(x) - \lambda E{q\theta} (r_\phi(x) - 1)
$$  
I believe solving this unconstrained optimization problem is feasible using stochastic gradient descent, and it avoids the problematic cross-entropy term in your formulation.
Am I overlooking something here?
Thanks,  
Rev1  
I realized I initially submitted my review as a pre-review question—apologies for that. Here's the full review, now with a few additional thoughts:
The authors provide a comprehensive and, as far as I can tell, accurate and transparent overview of the emerging theoretical framework surrounding GANs, particularly from the perspective of likelihood ratio estimation and divergence minimization. The paper is well-written, engaging, and serves as an excellent resource for those looking to delve into GANs.
However, my primary concern with this submission lies in identifying its precise novelty. Beyond articulating these perspectives more clearly than prior work, it is difficult to pinpoint a unique contribution. A sentence from the paper—"But it has left us unsatisfied since we have not gained the insight needed to choose between them."—captures my sentiment. While this is a commendable unifying review, it seems to lack a novel insight or a singular, groundbreaking idea that one typically expects from conference presentations.
In summary, my evaluation is mixed: I found the paper to be excellent and enjoyable to read, but I was left somewhat underwhelmed by the absence of a distinct novel contribution. This is why my confidence in recommending it for the conference is low (hence my score). That said, I remain open to being convinced otherwise.
Detailed comments:
1. The authors should consider discussing the connection between Eq. (13) and KLIEP: Kullback-Leibler Importance Estimation, as introduced by Sugiyama and colleagues.
2. The role of Eqns. (13) and (14) within the overall flow of the paper is unclear. By this stage, the authors have established that GANs revolve around estimating likelihood ratios to refine the generator. However, these sections seem to suggest an attempt to derive an alternative formulation, which ultimately appears impractical.
3. There is a typo in the spelling of "Csiszar divergence."
4. Equation (15) corresponds to Least Squares Importance Estimation, as described by Kanamori et al. (2009). A variant of this method employs the kernel trick to identify a function from an RKHS that best approximates the likelihood ratio between two distributions in a least-squares sense. It might be worthwhile to explore how this function relates to the witness function commonly used in MMD, and to compare their properties for simple distributions.
5. I am familiar with the work of Sugiyama and collaborators on direct density ratio estimation, and I have found their contributions to be highly insightful. While some of their work is cited in this paper, I feel the authors could do more to emphasize the significance of this group's contributions, even if their goals differ from those of this paper.
6. Regarding likelihood ratio estimation: some methods directly approximate the ratio (e.g., least-squares importance estimation), while others approximate its logarithm (e.g., logistic regression, denoising autoencoders). An unbiased estimate of the ratio yields a biased estimate of the logarithm, and vice versa. Estimating the logarithm directly seems more practical, and more generally, estimating the convex function of the ratio that defines the f-divergence appears to be a promising approach. Could the authors elaborate on this?
7. I feel the hypothesis testing perspective is overstated in the paper. Beyond using quantities from hypothesis testing as test statistics, the work does not seem to engage deeply with hypothesis testing concepts or leverage tools from that literature. This contrasts with Sutherland et al. (in review for ICLR), who explicitly draw on two-sample testing concepts to optimize divergence hyperparameters.