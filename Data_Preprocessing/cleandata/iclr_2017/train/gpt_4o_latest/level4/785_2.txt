This paper introduces a neural network architecture for predicting car states during driving, leveraging a competitive learning approach. The method involves creating multiple copies of a baseline neural architecture, with only the architecture yielding the minimum loss being updated during training. Experiments evaluate the competitive learning method against a single baseline architecture on a driving benchmark task. While the paper is generally clear, it would benefit from additional copy editing.
The competitive learning approach appears somewhat ad hoc, and the paper feels incomplete without a thorough discussion and comparison to ensembling techniques. Recent studies have demonstrated that duplicating and ensembling neural architectures can yield performance improvements. However, the paper does not convincingly explain why competitive learning is preferable to ensembling, and the approach seems less theoretically grounded in comparison.
A significant confound exists in the experiments, as the competitive learning architecture has substantially more free parameters than the baseline architecture. To validate the proposed approach, it is crucial to compare it to ensembling with an equivalent number of duplicated architectures and to a single baseline model with larger hidden layers, ensuring the total number of free parameters is comparable across methods.
The graphical model of the driving process in Figure 1 appears problematic. If "e" is observed, all other variables become deterministically known based on the depicted dependencies. Additionally, the notation is flawed, as it implies that the driving action "d" at time t influences the vehicle state "s" at the same time, whereas "st" should depend on "d(t-1)." Furthermore, the figure suggests that the driving decision "d" is independent of the observed vehicle state "x," which seems invalid.
There is an unnecessary paragraph break in the abstract.
The caption for Figure 1 should include a brief explanation of the variables depicted.