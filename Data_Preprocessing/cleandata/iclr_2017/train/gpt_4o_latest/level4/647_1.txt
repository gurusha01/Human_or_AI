This paper introduces RIMs, which unroll the variational inference procedure.
The authors assert that the key novelty lies in decoupling the model from the inference process, enabling MAP inference to be framed as an end-to-end approach. The effectiveness of this method is demonstrated through image restoration experiments.
Although unrolling inference is not a novel concept, the authors present an intriguing perspective on the `model-free' configuration, where the model and inference are not distinct and can be learned jointly.
However, I disagree with the authors' interpretation of [1] and [2]. While it is true that both [1] and [2] involve pre-defined MAP inference problems, this does not necessarily imply the need for a separate step. In fact, neither [1] nor [2] employs a pre-defined prior model or an explicit prior evaluation step, as depicted in Fig. 1(a). I believe that the implementation of both [1] and [2] aligns more closely with the proposed method, as illustrated in Fig. 1(c). In essence, the entire inference process becomes a learnable neural network, with the energy function implicitly defined through parameter learning.
Additionally, the use of the RNN block architecture (GRU) and the non-linearity (tanh) imposes constraints on flexibility, inherently shaping the family of variational energy functions and inference algorithms. This characteristic is also comparable to [1] and [2].
Given these observations, I share R1's sentiment that the novelty of the work is somewhat limited. Furthermore, additional discussions are warranted regarding the choice of architecture and non-linearity employed in the proposed method.