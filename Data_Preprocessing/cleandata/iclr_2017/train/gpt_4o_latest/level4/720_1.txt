A method for click prediction is proposed in this paper. The inputs consist of categorical variables, and the output is the click-through rate. The categorical input data is transformed into a feature vector using a discriminative approach designed to predict whether a given sample is fake or genuine. This embedding vector is then processed through a sequence of SUM/MULT gates, and the K-most significant interactions are identified using K-max pooling. This procedure is repeated across multiple layers, and the resulting feature is passed through a fully connected layer to predict the click-through rate.
The authors make the following claims:
(1) The use of gates and K-max pooling enables the modeling of interactions that achieve state-of-the-art results.
(2) Traditional methods like word2vec are not directly applicable for generating feature embeddings in this context, which is why the authors adopt the discriminative approach of distinguishing between fake and true samples for feature learning.
While convolutions theoretically function as "sum" gates between pairs of input dimensions, the authors explicitly impose this structure through the use of gates. The effectiveness of the proposed method could be validated by comparing it against a baseline network that excludes gatesâ€”specifically, a network comprising an embedding vector followed by a series of convolution and pooling layers. Unfortunately, this critical baseline comparison is missing from the paper.
Another concern is the unclear comparison of the number of parameters between the proposed model and baseline models. For example, how does the total number of parameters in the CCPM model compare to that of the proposed model?
Overall, the paper does not introduce a fundamentally new idea. However, this alone is not sufficient grounds for rejection, provided the proposed method demonstrates superior performance over established baselines. Currently, the comparison with baselines is weak, and I strongly encourage the authors to address this limitation.