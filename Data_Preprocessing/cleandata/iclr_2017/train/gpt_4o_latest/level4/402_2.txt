This paper presents an intriguing contribution. The algorithm is well-articulated, the problem is clearly identified, and the results are both compelling and credible.
Methods for hyperparameter optimization based on SMBO have historically struggled to effectively leverage convergence during training. This work offers a novel perspective by exploring a non-SMBO alternativeâ€”or so I initially thought, until another reviewer highlighted the significant overlap with the previously published successive halving algorithm (unfortunate!). Nonetheless, I remain eager to experiment with it. I am cautiously optimistic that this straightforward alternative to SMBO could represent the first meaningful advancement in model search for the skeptical practitioner since the argument for random search over grid search.