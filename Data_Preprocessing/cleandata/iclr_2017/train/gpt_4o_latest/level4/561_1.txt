The paper introduces a straightforward approach for constructing a visual hierarchy of ImageNet classes using a CNN trained to distinguish between these classes. It evaluates two metrics for assessing inter-class similarity: (1) softmax probability outputs, represented by the class confusion matrix, and (2) L2 distance between fc7 features. Additionally, it explores three methods for building the hierarchy from the distance matrix: (1) approximated central point, (2) minimal spanning tree, and (3) multidimensional scaling as described in Borg & Groenen (2005).
The paper claims two main contributions: (1) the construction of a biology-inspired evolutionary tree, and (2) insights into the representations learned by deep networks.
For (1), although the work is motivated by biological principles, the method relies solely on visual similarity. Consequently, the resulting trees are unlikely to represent true evolutionary hierarchies, and no quantitative experiments are provided to substantiate such claims.
For (2), the technical depth of the analysis falls short of the standards expected at ICLR. The conclusions drawn appear limited to the observation that CNNs can group categories based on visual similarity, with deeper networks performing this task better than shallower ones (as shown in Fig. 2).
In conclusion, this paper is not yet ready for publication.