The authors investigate the concept of applying deep learning to a static analysis task. They approach this using a toy programming language and a highly simplified problemâ€”determining whether all variables are initialized.
While the concept is intriguing and has the potential to evolve into a practical tool, the task addressed in this paper is overly simplistic for an ICLR submission. Identifying whether a variable is initialized in a string is a basic algorithmic problem, akin to those tackled in recent years by models such as the Neural Turing Machine, Stack RNNs, Neural GPU, or Differentiable Neural Computer. These architectures have demonstrated near-perfect performance on a variety of algorithmic tasks, suggesting they would likely excel at this one as well. Unfortunately, the authors only compare their approach to much simpler baselines, such as HMMs. Given that implementations of the aforementioned models are readily available online, the absence of these baselines makes the paper unfit for ICLR at this stage. Furthermore, there is a significant possibility that existing models already solve this problem effectively, which raises concerns about the clarity and novelty of the contribution.