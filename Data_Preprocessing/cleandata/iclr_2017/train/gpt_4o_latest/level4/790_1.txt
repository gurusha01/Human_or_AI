The submission introduces a slight modification to the standard GAN architecture by incorporating "encrypt" (Alice) and "decrypt" (Bob) modules, alongside a third module (Eve) tasked with attempting to decrypt the signal without access to the key. The adversarial training process aims to converge on a system where Alice and Bob can securely communicate (or at least ensure the security of a designated portion of the signal), while a sophisticated Eve is unable to break their encryption. The authors demonstrate this concept using toy data, stating:  
"As a proof-of-concept, we implemented Alice, Bob, and Eve networks that take N-bit random plain-text and key values, and produce N-entry floating-point ciphertexts, for N = 16, 32, and 64. Both plaintext and key values are uniformly distributed."
The concept presented here is intriguing. If the goal is for only part of the signal to remain secure, the proposed modules can learn to encrypt and decrypt that portion while simultaneously training an adversary to break the encryption. This setup ensures that some data can remain unencrypted, while the portion correlated with the encrypted signal must also be encrypted to prevent Eve from accurately predicting the secured part.
However, there are notable challenges that limit the practical applicability of this submission:  
1) GANs, as well as the specific objective described here, are known to be unstable during optimization, as evidenced by the convergence figures in the paper. The privacy guarantees rely on Eve converging to a highly capable adversary (potentially stronger than a dedicated attack over time). The paper does not provide any clear or reliable assurance of data transmission security under the proposed approach.  
2) Established public key encryption systems are already widely available, computationally efficient, and successfully deployed in real-world applications. The toy examples presented in the paper fail to demonstrate that the proposed method addresses any pressing real-world problem. While it is possible that a compelling use case may emerge in the future, the current work remains more of an interesting theoretical exercise than a practical solution.