1) Summary
This paper introduces a video captioning framework that utilizes a 3D convolutional neural network (C3D) as the encoder and an LSTM as the decoder. The authors explore the advantages of incorporating attention mechanisms that operate at both spatio-temporal and feature abstraction (layer) levels.
2) Contributions
+ The paper presents a well-justified and effectively implemented attention mechanism designed to address the varying shapes of C3D feature maps across spatial, temporal, and feature dimensions.  
+ The authors provide strong quantitative and qualitative results on three challenging datasets (Youtube2Text, M-VAD, MSR-VTT), clearly demonstrating the effectiveness of the proposed attention mechanisms.  
+ The comparison between soft and hard attention is insightful, with results indicating a slight performance edge for the simpler soft attention mechanism in this context.  
3) Suggestions for improvement
Hypercolumns comparison:  
As highlighted during the pre-review discussion, it would be valuable to include a comparison with hypercolumns to further contextualize the performance of the proposed approach.