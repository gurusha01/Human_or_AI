This paper presents an extensive series of experiments on vocabulary selection strategies aimed at reducing the computational cost of neural machine translation.
The authors explore a variety of techniques, ranging from straightforward methods like word co-occurrences to more sophisticated approaches involving SVMs.
The experiments are well-executed, thorough, and hold significant practical value. It is commendable that the best vocabulary selection method achieves a very high level of coverage compared to the full-vocabulary model (Fig. 3). However, I found the experiments in Section 4.3 (vocabulary selection during training) to be somewhat narrow in scope. Additional experiments in this area would have strengthened the paper.
My primary critique of this work is the lack of novelty. Most of the techniques employed are standard and relatively simple, with limited innovation beyond the work of Mi et al. (2016). While the study is robust, the absence of originality detracts from its overall contribution.
Minor comments: In Section 2.1, regarding the word co-occurrence measureâ€”was any smoothing applied to make the measure more robust to low-frequency counts?