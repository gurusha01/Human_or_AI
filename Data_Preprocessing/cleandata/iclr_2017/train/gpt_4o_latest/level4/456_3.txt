Variational auto-encoders, adversarial networks, and kernel scoring rules such as MMD have recently emerged as prominent techniques for learning directed generative models and for applications like domain adaptation. This paper introduces a novel method within the scoring rules framework, leveraging the matching of central moments to align two probability distributions. The proposed approach is simple and demonstrates strong effectiveness in the context of domain adaptation.
CMD appears to be an elegant and straightforward solution to the domain adaptation challenge. The method is computationally efficient to implement and exhibits notable stability with respect to tuning parameters, particularly when compared to MMD. Initially, I was skeptical, especially considering the use of only K=5 in the experiments, but the results presented are compelling. A natural follow-up question is how this method would perform in training generative models. While this is beyond the scope of the current paper, it represents a clear and promising direction for future work.
Below, I provide more detailed feedback.
One potential way to accelerate MMD is by employing a random Fourier basis, as demonstrated in "Fastmmd: Ensemble of circular discrepancy for efficient two-sample test" by Zhao and Meng, 2015. Additionally, linear time estimators, such as those proposed in "A Kernel Two-Sample Test" by Gretton et al., 2012, could be considered. While I do not think it is necessary to compare against these approaches since the paper benchmarks against the full MMD, these works should be cited for completeness.
The paper "Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy" by Sutherland et al., submitted to ICLR 2017, explores methods for optimizing the kernel used in MMD and should be cited in Section 3.
How restrictive is the assumption that the distribution has independent marginals?
The sample complexity of MMD is known to depend significantly on the dimensionality of the input space. Do you have any insights regarding the sample complexity of CMD? Based on the results in Figure 4, CMD seems relatively robust, but I would be surprised if this holds in scenarios involving 10,000 hidden units. This question is particularly relevant because, in generative models, the output space can often be high-dimensional.
I am also concerned about the numerical stability of central moments at higher orders during backpropagation. While this issue does not appear to affect the experimental results, it would be helpful if the authors could provide some commentary on this. Specifically, I am referring to the potential for ck(X) to become very large for k ≥ 3. While Proposition 1 alleviates concerns about the overall objective's stability, my question pertains to the stability of the individual terms.
Figure 3 is somewhat cluttered, and aside from the mouse class, the visualization does not clearly demonstrate the benefits of the CMD regularizer. It would be helpful to reduce the number of classes shown for the sake of clarity in visualization.
I would appreciate further clarification regarding the natural geometric interpretations of K=5. Are you suggesting that moments up to K=5 have been well-studied? If so, could you provide references to support this claim? Additionally, why do moments for K ≥ 6 lack a natural geometric interpretation?
Lastly, Figure 4 should include a legend for better readability.