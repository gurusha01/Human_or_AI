The objective of this paper is to examine the behavior of dialogue agents when tasked with answering factoid questions, requiring them to query an oracle for supplementary information. This scenario can be viewed as a form of interaction between the dialogue agent and a "teacher."
The research problem addressed is undeniably significant. The authors construct a synthetic environment to evaluate their agent. A key strength of the paper lies in its exploration of various combinations of environments, including scenarios where some knowledge is missing (necessitating the agent to query for it), instances of misspellings in the teacher's questions, and different strategies the agent employs to request additional information.
However, I have some reservations. Many of the tasks appear overly simplistic (e.g., the AQ question paraphrase), and the proposed environment is quite constrained and lacks the linguistic complexity characteristic of real human-chatbot interactions. I believe the paper would be better framed as an investigation into the basic reasoning and question-answering capabilities of agents rather than dialogue per se. That said, the "ground-up" approach, which begins with simplified environments, is a valuable direction for analysis, and this paper makes a meaningful contribution in that regard. Naturally, the inclusion of human experiments would significantly strengthen the paper's impact.
Additional comments:  
The simulation within the synthetic environment for the first type of learner error during dialogue—where "the learner struggles to understand the surface form of the dialogue partner's text, such as the phrasing of a question"—is notably limited. It only accounts for word misspellings, and the models employed do not operate at the character level. This represents just a small subset of the ways an agent might fail to comprehend context. I would be particularly interested in seeing a discussion on how the authors intend to scale this approach to more realistic and complex settings.
EDIT: I have revised my score to reflect the inclusion of the Mechanical Turk experiments.