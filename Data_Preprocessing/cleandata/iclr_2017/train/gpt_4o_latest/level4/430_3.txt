This paper introduces a novel approach to jointly learn word decomposition, or the mapping from words to sub-word sequences, alongside an attention-based sequence-to-sequence model. A key aspect of this method is that the decomposition is dynamic, conditioned on the acoustic input, and probabilistic, allowing a single word to map to multiple sub-word sequences. The authors posit that this dynamic decomposition framework better captures the variability in acoustic patterns. Notably, the motivation for this approach parallels the concept of learning a pronunciation mixture model in HMM-based speech recognition, where the probabilistic mapping from a word to its pronunciations is also conditioned on acoustic input. Relevant prior works in this domain include:
I. McGraw, I. Badr, and J. Glass, "Learning lexicons from speech using a pronunciation mixture model," IEEE Transactions on Audio, Speech, and Language Processing, 2013.
L. Lu, A. Ghoshal, S. Renals, "Acoustic data-driven pronunciation lexicon for large vocabulary speech recognition," Proc. ASRU.
R. Singh, B. Raj, and R. Stern, "Automatic generation of subword units for speech recognition systems," IEEE Transactions on Speech and Audio Processing, 2002.
It would be valuable to contextualize this work by drawing explicit connections to these earlier studies within the HMM framework.
In general, the paper is well-written and theoretically sound. However, the experimental evaluation could be more robust. For instance, including a word-level baseline would provide a clearer comparison, as the proposed method lies conceptually between character-level and word-level systems. Additionally, the vocabulary size of the WSJ si284 dataset, capped at 20K, is relatively small for the softmax layer and represents a closed vocabulary task. It seems plausible that a word-level system could achieve results competitive with those reported in this paper. Moreover, the computational efficiency of the proposed method warrants further clarification. Despite downsampling the data by a factor of 4 using an RNN, training still required approximately 5 days to converge, which seems computationally expensive, particularly given that only a single sample was used for gradient computation. Could the authors elaborate on the computational bottleneck?
Lastly, Table 2 could be more transparent. For example, the performance of CTC with a language model and the seq2seq model with a language model from Bahdanau et al. is much closer to the best results reported in Table 2, and incorporating a language model may yield only marginal improvements. Additionally, the phrasing "O(5) days to converge" is somewhat unconventional and could be revised for clarity.