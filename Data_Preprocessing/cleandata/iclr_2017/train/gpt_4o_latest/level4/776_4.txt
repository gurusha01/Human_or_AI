This paper introduces a method to iteratively refine a sentence produced by another MT system (specifically, a phrase-based system). The authors employ a neural network that takes as input the source sentence along with a window of (gold) words surrounding the current target word and predicts the current target word. During inference, the gold words are substituted with the generated ones. While the research direction is intriguing, I remain unconvinced by the proposed methodology, and the experimental validation appears insufficient.
Within the proposed framework, the model seems limited to performing basic word substitutions (e.g., it cannot transform "I went to the fridge even though I was not hungry" into "Although I was not hungry, I went to the fridge"). The observation that only 0.6 words are edited on average further underscores this limitation.
Specific comments:
- It would be valuable to evaluate the improvements when the baseline model is a neural system.
- I find it somewhat unusual that T^i and L(y^{-i|k}) consider only a 2k-word window. Does this imply that when deciding whether to modify the i-th word, the model lacks information about the context beyond this window?
- Similarly, the concept of modifying individual words based on local (word-level) scores seems unintuitive. Given access to the entire generated sentence, wouldn't it be more effective to use a global score? Sentence-level scoring could also enable non-greedy search strategies, potentially allowing for more substantial edits.
- How does the proposed method compare to a system that simply re-ranks the k-best outputs?
- Did you explore using an encoder-decoder model that takes x, yg as input and generates yref? During decoding, such a model could attend to both x and y_g instead of performing iterative edits.
Minor comments:
- The idea of iteratively refining generated text has also been studied in