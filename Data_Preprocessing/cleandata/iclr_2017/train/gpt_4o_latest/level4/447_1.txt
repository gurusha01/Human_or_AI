The paper presents a simulator and a suite of synthetic question-answering tasks where interaction with a "teacher" through question-asking is encouraged. The central idea is that an intelligent agent can enhance its performance by posing questions and receiving corresponding feedback from users. The study explores this problem in both offline supervised learning and online reinforcement learning frameworks. The results demonstrate that the models improve their performance by asking questions.
-- The concept is innovative and remains relatively underexplored within the research community. This work represents a solid foundational step in this area.  
-- The paper investigates three distinct types of tasks where user feedback can aid the agent's learning process.  
-- The manuscript is well-written, offering a clear and comprehensive explanation of the tasks, models, and experimental setups.
Additional comments/questions:  
-- What is the rationale for employing both vanilla-MemN2N and Cont-MemN2N? Does the inclusion of both lead to insights that significantly enhance the paper's contributions?  
-- In the Question Clarification setting, what is the distribution of misspelled words across question entities, answer entities, relation entities, or none of these categories? If the majority of misspellings occur in relation entities, the problem might be less challenging than it initially appears.  
-- The statement on Page 10, "The performance of TestModelAQ is worse than TestAQ but better than TestQA," does not hold true for Task 2 based on the data presented in Tables 2 and 4.  
-- How does the model's performance change if the conversational history is reduced or entirely absent?  
-- In Figure 5, Task 6, why does the accuracy of the good student decline when it stops asking questions? Since it already possesses the relevant facts, the absence of additional questions should not impact its performance.  
-- In Figure 5, Task 2, the poor student achieves nearly 70% accuracy on questions even without asking any. This seems unexpectedly highâ€”could you provide an explanation for this outcome?  
-- In Figure 1, Task 2 AQ, the last sentence should display a negative response "(-)" instead of the currently shown positive response.
Preliminary Evaluation:  
This work represents a promising initial step in the field of training dialogue agents through unstructured user interaction.