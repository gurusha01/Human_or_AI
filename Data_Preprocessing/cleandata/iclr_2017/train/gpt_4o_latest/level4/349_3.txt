This paper explores a set of tasks that extend the standard bAbI problems. Specifically, certain people and objects in the scenarios are substituted with unknown variables. To solve the questions, the agent must identify and query the values of some of these variables, as they are essential for deriving the correct answers. This setup allows for the evaluation of both the agent's accuracy in answering the questions and its efficiency in querying only the necessary unknown variables, avoiding irrelevant ones. This process of inferring unknown variables introduces a level of complexity that surpasses the requirements of the original bAbI tasks, which are now largely considered solved.
The paper is well-written, with its contributions clearly articulated. However, given the highly constrained vocabulary and structure of the bAbI problems, I believe these tasks (and their variants) are better categorized as basic reasoning exercises rather than natural language understanding. I am not fully persuaded by the paper's claim that these tasks effectively test the 'interaction' capabilities of agents. While the task is framed as a form of interaction, it seems more accurately described as the process of 'inferring critical unknown variables,' which, while significant, is more closely aligned with reasoning than interaction. The connection to 'interaction' feels somewhat superficial in this context.
That said, it is undeniable that conversational agents will require fundamental reasoning skills to engage meaningfully with humans. I appreciate the overarching goal of the bAbI tasks, which is to evaluate reasoning abilities in synthetic environments that are sufficiently complex to inspire the development of innovative models, without being overly complicated. I find the authors' proposed extension to these tasks to be compelling and believe it represents a valuable direction for future research. Therefore, I recommend the acceptance of this paper.