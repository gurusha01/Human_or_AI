The submitted paper introduces a "causal regularizer," which encourages predictive models to leverage causal dependencies (X → Y, where X represents a feature of the learning problem and Y is the target variable). Concurrently, the causal regularizer discourages reliance on non-causal dependencies, which may arise due to reverse causation (Y → X) or confounding (X ← Z → Y, where Z is an unobserved confounder).
+ In general, this work addresses one of the most critical challenges in machine learning: constructing causal models. The paper effectively tackles this issue, particularly when applied to a heart disease dataset. Through their experiments, the authors successfully identify several common causes of heart disease using their causal regularizer.
- However, the authors fail to discuss the robustness of their approach concerning the choice of hyperparameters (both for the neural network architecture and the generative model used to synthesize artificial causal data). This omission is particularly significant when working with medical data, where robustness is crucial.
- The conclusions drawn from the experimental evaluation require more thorough discussion. For instance, Figure 4.a indicates no discernible difference between L1 and causal regularization in terms of predictive performance, but the absence of error bars makes it difficult to determine whether this result is statistically significant. Additionally, Table 3 outlines qualitative differences between L1 and causal regularization, but the table is not easy to interpret. How were the 30 rows selected? What does the red highlighting signify? Are these red rows true causal features that were overlooked? If so, this relates to precision. What about recall? Did the causal regularizer incorrectly classify many non-causal features as causal?
- Regarding causal classifiers, the paper could significantly improve its review of prior work. For example, the paper "Towards a Learning Theory of Cause-Effect Inference" by Lopez-Paz et al. is notably absent from the references. This prior work explores several aspects that are presented as novel in the current submission. Specifically, Lopez-Paz et al. 1) introduce the concept of the Mother distribution (referred to as the Nature hyper-prior in this submission), which explicitly factorizes the distribution over causes and mechanisms, 2) avoid intractable likelihoods by synthesizing and training on causal data, 3) address the confounding scenario (compare Figure 1 in this submission with Appendix C of Lopez-Paz), and 4) seamlessly handle discrete data (e.g., the ChaLearn dataset discussed in Section 5.3 of Lopez-Paz).
On the positive side, the paper is well-written and tackles the important but often overlooked challenge of integrating causal reasoning into machine learning. On the negative side, the technical contributions offer limited novelty, and the qualitative evaluation of the results could be significantly expanded. Overall, I am slightly inclined toward acceptance. While the paper provides sufficient detail to enable reimplementation of the proposed methods, it does not mention whether the heart failure dataset will be made publicly available, which is critical for reproducibility.