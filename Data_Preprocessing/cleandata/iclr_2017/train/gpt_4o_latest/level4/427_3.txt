The authors present an intriguing method for visualizing the predictions of deep neural networks. The manuscript is well-written and provides valuable insights into the problem. I particularly appreciate the application to medical images, as focusing solely on ImageNet would not have been sufficiently compelling. However, I have several questions and comments.
1. As noted in Section 3.1, the authors correctly highlight that approximating the conditional probability of a feature \(xi\) using the marginal distribution \(p(xi)\) is unrealistic. They argue for translation invariance, suggesting that a pixel's position in the image should not influence its probability and that the pixel's appearance is determined by its local neighborhood. However, it is well established that global context significantly impacts pixel semantics. For example, in "Objects in Contexts," it is shown that the same local neighborhood of pixels can represent different semantic meanings depending on the global context of the image. Similarly, in the context of deep neural networks, works like "ParseNet" emphasize the importance of global context in determining spatial label distributions. While this limitation does not necessarily invalidate the proposed approach, it is a significant drawback. It would be beneficial if the authors could propose a modification to Equation (4) and empirically validate the impact of such a change.
2. Figure 7 illustrates the distribution of the top three predictions before and after applying the softmax function. It is expected that even relatively uniform distributions will shift toward delta-like distributions after softmax normalization. Is there any additional insight or takeaway that the authors intend to convey with this figure?
3. In Section 4.1, the authors mention that analyzing a single image with GooLeNet on a GPU takes 30 minutes. Why is this process so computationally intensive? Such high computational costs seem to render the algorithm impractical, particularly for analyzing datasets of statistically significant size. Could the authors clarify the reasons for this complexity or suggest potential optimizations to improve efficiency?