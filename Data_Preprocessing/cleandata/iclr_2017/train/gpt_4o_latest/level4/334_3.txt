This paper introduces a neural attention model with a learnable and differentiable sampling lattice. The work is well-motivated, as prior research has largely focused on fixed sampling lattices rather than learning them. The proposed approach bears similarities to Spatial Transformer Networks (Jaderberg 2015), but it distinguishes itself by enabling the model to learn the sampling lattice. Experimental results demonstrate that the model can learn a meaningful lattice for the visual search task, where the resulting sampling lattice resembles that of human perception.
The primary concern with this paper is the insufficiency of experiments. The results are limited to a modified clustered MNIST dataset. It would significantly enhance the paper if the authors evaluated the model on real-world datasets, such as the Toronto Face dataset, CUB bird dataset, or SVHN. For instance, on the Face dataset, it would be compelling to see the model attend to different facial regions for expression recognition, or on the CUB dataset, to focus on distinct parts of birds for fine-grained classification. Since the authors mentioned in their pre-review response that the model can learn meaningful lattices on the MSCOCO dataset, including those results in the paper would strengthen the work.
Another limitation of the paper is that it only compares the proposed model with its own variants. A broader comparison with existing methods, such as Spatial Transformer Networks and DRAW, on the same datasets, would better highlight the advantages of the learned sampling lattice.