The authors present two variational methods centered on posterior approximations that lack a tractable density. The first method builds on another ICLR submission on "amortized SVGD" (Wang and Liu, 2016), with the novelty here being the use of SGLD as the inference network. The second method is inspired by a NIPS paper (Ranganath et al., 2016) that minimizes the Stein divergence with a parametric approximating family, where the innovation lies in defining the test functions within an RKHS, enabling an analytic solution to the inner optimization problem.
The proposed methodology is incremental. Sections up to 3.2 primarily cover motivation, background, and related work. The concept of a "wild variational approximation" was already introduced in Ranganath et al. (2016) under the term "variational program." The authors should clarify if there are any distinctions between these notions.
Section 3.2 initially appears promising, as it provides an analytical solution to the maximization problem posed in Ranganath et al. (2016). However, this approach necessitates the use of a kernel, which is unlikely to scale effectively in high-dimensional settings. Consequently, this is practically equivalent to selecting a very simple test function family. Achieving scalability in high-dimensional spaces would require employing a more complex kernel and learning its parameters, which is no simpler than parameterizing the test function family as a neural network, as done in Ranganath et al. (2016).
In Section 4, the authors introduce a Langevin inference network, which effectively models the variational approximation as a sequence of evolving Markov transition operators, similar to Salimans et al. (2015). However, the explanation is unclear, particularly regarding the term "inference network." The approach does not involve amortization in the traditional sense, where parameters are outputs of a neural network. Instead, the authors define global parameters for the SGLD chain, which are applied across all latent variables. This seems suboptimal. (Why is this termed an "inference network"?) Is this approach not equivalent to the variational approximation in Salimans et al. (2015), but trained with a different objective?
The experiments are limited to a toy Gaussian mixture posterior and Bayesian logistic regression. These do not address key concerns such as scalability in high-dimensional or real-world datasets, the kernel's limitations, comparisons to Salimans et al. (2015) for the Langevin variational approximation, or runtime and training complexity.
Minor Comments
+ The authors' understanding of prior work on expressive variational families and inference networks appears unclear. For instance, they claim that Rezende & Mohamed (2015b), Tran et al. (2015), and Ranganath et al. (2015) require handcrafted inference networks. However, all three assume the use of neural networks for amortized inference, and none explicitly require an inference network. The authors may have intended to refer to handcrafted posterior approximations, which is partially accurate. However, the cited works are algorithmic in nature: in Rezende & Mohamed (2015), the key design choice is the flow length; in Tran et al. (2015), it is the size of the variational data; and in Ranganath et al. (2015), it is the flow length in the auxiliary variable space. Each approach is effective for different problems, which is also true for variational objectives that admit intractable q (as considered in the latter two works and Salimans et al. (2015)). The paper's motivation could be better articulated, and the authors should clarify their use of the term "inference network."
+ The authors are advised to avoid naming a variational inference method based solely on the class of approximating family. For example, while black-box variational inference in Ranganath et al. (2014) assumes a mean-field family, the term has been broadly used in the literature to describe any variational method that imposes minimal constraints on the model class.