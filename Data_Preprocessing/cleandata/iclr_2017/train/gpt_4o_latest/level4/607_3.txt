This paper explores video captioning using a TEM-HAM architecture, where the HAM module applies attention over the attended outputs of the TEM module during description generation. This introduces a form of two-level attention. The model is evaluated on the Charades and MSVD datasets.
1. Quality/Clarity: The paper is poorly written and difficult to follow. Based on my understanding, the TEM module described in Section 3.1 appears to be a straightforward attention-based frame encoder, similar to the approaches of Bahdanau et al. (2015) or Xu et al. (2015). The decoder in Section 3.3 is a standard LSTM with log-likelihood training. The HAM module in Section 3.2 is the novel component, but its description is unclear. It seems to function as an attention LSTM, where the attention is applied to the outputs of the TEM LSTM, with the attention weights conditioned on the decoder state. However, the explanation is riddled with issues, including notational inconsistencies, such as the use of \textbf in equations but not in the text. For instance, I spent considerable time trying to understand what f_m represents. The authors state:
"In order to let the network remember what has been attended before and the temporal structure of a video, we propose fm to memorize the previous attention and encoded version of an input video with language model. Using fm not only enables the network to memorize previous attention and frames, but also to learn multi-layer attention over an input video and corresponding language."
Here, one instance of fm is bolded while the other is not. Initially, I assumed fm was a novel technical contribution, but it is later clarified in Section 3.3 that f_m is simply an LSTM. This information is misplaced in Section 3.3, which primarily discusses the decoder. The paper contains other careless errors, such as inconsistent significant digits in Table 1 and the unexplained semantics of the horizontal line in Table 2.
2. Experimental Results: The ablation study presents mixed outcomes when incorporating TEM and HAM into the model. Focusing on METEOR, which the COCO paper identified as having the highest correlation with human judgment, adding TEM+HAM increases the score from 31.20 to 31.70. However, the significance of this improvement is unclear, especially given the small test set of only 670 videos. This raises doubts about the robustness of the results. Additionally, in Table 2, the METEOR score of Pan et al. (2016a) is higher [33.10 vs. 31.80], but this discrepancy is not addressed in the text. This is particularly surprising given the authors' explicit claim of achieving "state-of-the-art results."
3. Originality/Significance: The paper introduces an additional attention layer within a standard sequence-to-sequence framework, which is argued to reduce the memory burden on the LSTM. While this idea is moderately novel, the experimental results do not convincingly demonstrate its value. If the proposed approach simplified the standard model rather than adding complexity, I would be more inclined to view it favorably.
Minor: In response to the authors' comment, "not sure what causes to think of RBM. We don't model any part of our architecture using RBM. We'd be appreciated if you please elaborate more about your confusion about figure 1 so we can address it accordingly," I created a diagram to clarify this misunderstanding.