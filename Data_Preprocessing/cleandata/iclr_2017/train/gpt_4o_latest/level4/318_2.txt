This paper introduces an approach for learning on the fly to represent a dialog as a graph, which serves as the memory, and demonstrates this method on the bAbI tasks. In this work, graph learning is integrated into the inference process, while long-term representation learning is employed to optimize the graph transformation parameters and encode sentences as inputs to the graph. To the best of my knowledge, this is the first implementation of a differentiable memory represented as a graph. While it is significantly more complex than prior methods, such as memory networks, it does not achieve substantial performance improvements on the bAbI tasks. However, the work is still in its early stages, and the concept of representing memory as a graph appears to hold greater potential compared to simpler structures like stacks. 
One major concern is clarity, which remains an issue. That said, the authors have made significant improvements from an initial submission that was more suited for computational readability than human comprehension to a much more polished and accessible version. Overall, this paper is original, technically sound (to the extent I was able to understand), and intellectually stimulating, making it worthy of publication.
The preliminary results do not yet demonstrate whether the highly complex graph-based differentiable memory offers superior learning or generalization capabilities compared to other methods. While its performance on the bAbI tasks is on par with the best memory networks, it still lags behind more traditional rule induction approaches (see