The paper presents Edward, a probabilistic programming language built on TensorFlow and Python, which supports a wide array of popular contemporary methods in probabilistic machine learning.
Quality:
The Edward library offers an impressive suite of modern probabilistic inference techniques in a highly accessible format. The paper provides a concise overview of key methods, particularly from a representation learning perspective, and includes two experiments showcasing the implementation of advanced variational inference methods and GPU-accelerated Hamiltonian Monte Carlo (HMC).
The first experiment on variational inference would benefit from a clear link to complete code that allows readers to reproduce the reported results. Regarding the HMC experiment, while the results are acceptable, describing Stan as a "hand-optimized implementation" appears to be an unfair characterization, as the code is evidently not specifically hand-optimized for the model or hardware configuration in question. There is no reason to doubt the quality of the authors' implementation, so it would be better to avoid making unsubstantiated and dramatic claims. Instead, I suggest conducting a direct comparison with Stan on a single core and separately reporting the additional speedups achieved through parallelization and GPU acceleration. This approach would provide readers with a clearer understanding of the method's performance across different hardware setups.
Clarity:
The paper is generally well-written and easy to follow. The inclusion of numerous code examples is helpful, though at times challenging, as it is not always clear what components are missing. It would be highly beneficial if the authors could provide a machine-readable companion resource—such as a Jupyter notebook or even a plain text/HTML file—that contains complete, runnable code for all examples. This would make it easier for readers to replicate and experiment with the presented methods, as copying code directly from a PDF can be cumbersome.
Originality:
The Edward library is undoubtedly a unique and valuable collection of probabilistic inference methods. However, the novelty of the paper itself is somewhat undermined by prior publications from the same research group. The manuscript references Tran et al. (2016a), which appears to cover much of the same material, albeit from a different perspective. It is unclear whether the referenced paper has been published or submitted elsewhere, and additional clarification on this point would be helpful.
Significance:
Edward is poised to have a significant impact on the fields of Bayesian machine learning and deep learning, given its comprehensive and accessible implementation of probabilistic inference methods.
Other comments:
In Section 2, the authors draw a distinction between specialized languages (such as Stan) and Turing-complete languages like Edward. This distinction seems inaccurate, as Stan is also believed to be Turing complete. Furthermore, no formal proof is provided to substantiate the claim of Edward's Turing-completeness. Providing clarification or evidence on this point would strengthen the paper.