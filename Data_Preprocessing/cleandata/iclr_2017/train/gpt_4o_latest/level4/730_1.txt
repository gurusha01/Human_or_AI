The paper introduces and evaluates three techniques applied to traditional LSTMs: Monte Carlo test-time model averaging, average pooling, and residual connections. The results demonstrate that these methods improve the performance of traditional LSTMs on sentiment analysis tasks.
While the paper is well-written, the experimental section is undoubtedly its weakest aspect. First, although the proposed methods show some improvements over traditional LSTMs, the results fall short of achieving state-of-the-art performance. Second, if the goal is to establish these extensions as strong baselines for future research, the experimental setup is insufficient: the two datasets used are quite similar, even though they differ in specific statistical properties. I therefore recommend conducting additional experiments on a wider variety of tasks, such as those explored in "LSTM: A Search Space Odyssey."
Moreover, the proposed extensions lack significant novelty. The experiments are unconvincing because the two datasets are closely related (both focused on sentiment analysis). Have you considered evaluating your proposed methods on more diverse tasks, such as machine translation, question answering, or other domains?