The derivation of such a bound and its demonstration of satisfying a regret bound, supported by empirical evidence on CIFAR-10 for cross-entropy loss and an autoencoder for MSE loss, is an interesting contribution. Empirically, by comparing the observed training loss with the Taylor loss, it is observed that the better a particular optimizer performs (in terms of training loss, not validation or test performance), the smaller the discrepancy between these two metrics. Additionally, the paper demonstrates that the regret bound holds across different scales of the network, including by layer, neuron, and the entire network.
The Taylor approximation is leveraged to analyze the activation configurations of the network and is further linked to challenges in optimization at kinks in the loss surface. This is complemented by an empirical study of how optimizers like SGD, Adam, and RMSprop explore the activation surface, with findings suggesting that greater exploration correlates with improved training loss.
Although it does not directly affect the paper's main claims, the weaker performance of SGD might be attributed to its fixed learning rate. If the learning rate were annealed, which is expected to improve performance, it would be interesting to investigate whether this leads to increased exploration and a tighter alignment between the actual loss and the Taylor loss.
- Incorporating a cross-validation set for some of the empirical studies could be beneficial, as it would allow the authors to make stronger claims about the generalization of the resulting network.
- A clarification is needed regarding the change in the subscript on the Jacobian to \(a_l\).