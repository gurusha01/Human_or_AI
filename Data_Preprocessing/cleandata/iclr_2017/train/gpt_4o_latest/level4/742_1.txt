This paper explores a theoretical and empirical framework to analyze the expressivity of deep networks.
The authors examine random networks (deep networks with random Gaussian weights and hard tanh or ReLU activations) using various criteria: the number of neuron transitions, activation patterns, dichotomies, and trajectory length.
However, the paper lacks a robust justification for why the proposed measures of expressivity genuinely capture expressivity. For example, trajectory length appears to be a questionable metric. The only rationale provided is its proportionality with other expressivity measures in the specific context of random networks, which is insufficient to establish its validity.
The manuscript is overly lengthy and difficult to follow. While the work introduces some potentially interesting ideas, it fails to situate them adequately within the broader context of existing research.
Some of the findings appear to be trivial.
Detailed Comments
Page 2
- "Much of the work examining achievable functions relies on unrealistic architectural assumptions such as layers being exponentially wide"  
  This claim seems inaccurate. For instance, in "Deep Belief Networks are Compact Universal Approximators" by Leroux et al., it is proven that deep but narrow feed-forward neural networks with sigmoidal units can represent any Boolean function. Specifically, a network with \(2n-1 + 1\) layers of \(n\) units (where \(n\) is the number of input neurons) suffices.
- "Comparing architectures in such a fashion limits the generality of the conclusions"  
  Contrary to this statement, much of the prior work has focused on mathematical proofs that yield highly general conclusions about the representational power of deep networks. Leroux et al. is one such example. In contrast, the proposed approach, which relies on random networks, seems harder to generalize, as these networks are not commonly used in practice.
- "[we study] a family of networks arising in practice: the behaviour of networks after random initialization"  
  While such networks may appear during initialization, they are not used for actual computations. Consequently, their representational power is a priori irrelevant unless the authors provide a compelling justification for its relevance.
- "results on random networks provide natural baselines to compare trained networks with"  
  Random networks are not inherently "natural" for studying the expressivity of deep networks. It is unclear how the representational power of random networks relates to (i) the entire class of networks or (ii) networks after training. These are the two classes of networks that are most relevant, and the authors need to justify how studying random networks contributes to understanding either (i) or (ii).
Page 5
- "As FW is a random neural network [â€¦] it would suggest that points far enough away from each other would have independent signs, i.e. a direct proportionality between the length of \(z^{(n)}(t)\) and the number of times it crosses the decision boundary."  
  As noted, the proportionality between these two measures appears to depend on the network being random. This undermines the generalizability of the findings to non-random networks, where such proportionality cannot be assumed.
Page 6
- The discussion of expressivity with respect to remaining depth seems trivial and equivalent to expressivity with respect to depth. For instance, the observation in Figure 5 that the number of achievable dichotomies depends only on the number of layers above the layer being analyzed appears self-evident.
Page 7
- In Figure 6, the chosen network width of 100 for MNIST is far too small. This results in poor performance, making it difficult to extrapolate the findings to more realistic scenarios.