I sincerely apologize for the delay in providing this review!
The initial section of the paper places significant focus on the technical aspects. However, it would benefit from incorporating higher-level discussions about the overarching goals of the method and the specific limitations it seeks to address. If I have misunderstood the contribution (please feel free to correct me), my interpretation is that the primary novelty lies in proposing to learn the group parameterizations rather than pre-defining them. In this context, the approach appears to extend the idea of learning group parameterizations—previously applied to common spatial filters in De Brabandere et al.—to Steerable Frames.
The first contribution claims that "general frame bases are better suited to represent sensory input data than the commonly used pixel basis." However, the experiments on CIFAR-10+ suggest that this claim does not hold universally. Treating the basis as a hyperparameter necessitates an expensive search to identify that the Gauss-Frame performs better. This raises the question of whether the Gauss-Frame is inherently superior or if the evidence presented is too limited (based on a single network) to support such a conclusion. Perhaps the first contribution needs to be rephrased for clarity. Additionally, is the "Pixel" network representation adjusted to account for the larger number of parameters? From a practical perspective, as someone interested in applying this method, runtime considerations would also be valuable to discuss.
I strongly recommend improving Fig. 3. The figure uses the symbol "w" in multiple contexts with varying notations and representations, blending boxes, single symbols, and illustrative diagrams. This inconsistency makes the figure and its flow challenging to interpret and unnecessarily time-consuming to understand.
Summary: The paper is reasonably clear and technically sound in many areas, but its readability could be improved. For instance, the introduction of frames at the beginning lacks sufficient motivation and may be unclear to readers unfamiliar with the concept. The work falls into the broader category of methods that embed knowledge about filter transformations into network architectures. However, this approach has two aspects: the algorithmic and technical side (where there are multiple ways to achieve this) and the practical side (whether it is worth pursuing). While this paper presents a possible approach, I was left uncertain about what I had learned from it. The content did not inspire me to integrate or build upon this work. Specifically, I found a lack of insights into the transformational parameters that are meaningful for a given problem. For example, the Spatial Transformer Network paper, while less elegant technically, provided valuable insights into the feature transformations learned by the algorithm. In contrast, this paper falls short in that regard. From Table 2, I gather that one of four choices works better empirically, but the reasons behind this are unclear. What is lost or disrupted by the \(x^p y^p\) and Hermite frames that the ResNet cannot compensate for? It is possible to design network architectures that are supersets of both, which could prevent the observed inferior performance.
The algorithm is well-explained, but it bears similarities to the Dynamic Filter Networks paper. Unfortunately, I remain unconvinced of the practical utility of this particular formulation. A stronger paper would provide deeper insights into the transformations, more comprehensive comparisons to standard techniques, and clearer guidance on when and why this approach should be used.