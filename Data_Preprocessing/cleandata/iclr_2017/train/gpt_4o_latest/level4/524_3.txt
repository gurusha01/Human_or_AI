In this paper, the authors introduce a novel data augmentation strategy that, instead of augmenting the input data, focuses on augmenting intermediate feature representations. The approach leverages sequence auto-encoder derived features, and evaluates augmentation techniques such as random perturbation, feature interpolation, and extrapolation. Experiments on three sequence classification tasks, as well as MNIST and CIFAR-10 datasets, demonstrate that feature space augmentation—particularly extrapolation-based augmentation—yields notable accuracy improvements compared to the authors' baseline.
My primary questions and suggestions for further improving the paper are as follows:
a) The proposed data augmentation technique is applied to a learned auto-encoder-based feature space referred to as the "context vector" in the paper. These context vectors are augmented and subsequently used to train classification models. Have the authors explored the possibility of applying their feature space augmentation method directly within the classification model during training, potentially extending it to multiple layers of the model? Additionally, have the authors considered testing their approach on convolutional neural network (CNN) architectures? Since CNNs represent the state-of-the-art for many image and sequence classification tasks, evaluating the proposed method in the context of CNNs would significantly enhance the paper's impact.
b) When using interpolation or extrapolation-based augmentation, did the authors consider incorporating nearby samples from competing classes into the augmentation process? This could be particularly interesting for extrapolation-based augmentation, as it would be valuable to investigate whether the extrapolated features are closer to competing classes compared to the original features.
c) The consistent degradation in accuracy observed with random interpolation or nearest-neighbor interpolation-based augmentation is counter-intuitive. Do the authors have an explanation for why interpolation-based augmentation led to reduced accuracy?
d) The results on MNIST and CIFAR-10 are somewhat inconclusive. For example, the error rate on CIFAR-10 is currently well below 10%, making it challenging to draw meaningful conclusions from error rates exceeding 30%. Additionally, for MNIST, it is surprising to observe that data augmentation in the input space significantly degrades accuracy (1.093% → 1.477%). As noted earlier, extending the feature space augmentation approach to CNN-based models could address these issues and provide more robust insights.