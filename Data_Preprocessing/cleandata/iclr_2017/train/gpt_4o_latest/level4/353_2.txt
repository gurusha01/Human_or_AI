The paper integrates a hierarchical Variational Autoencoder (VAE) with PixelCNNs to model the distribution of natural images. The authors report promising (though not state-of-the-art) likelihoods on natural images and briefly investigate the information captured by the latent representations in the hierarchical VAE.
I consider the combination of PixelCNN with a VAE, as initially proposed in the PixelCNN paper, to be a significant and intriguing contribution. The encoding of high-, mid-, and low-level variations at different latent stages is interesting but not particularly surprising, given that the scale of the image regions modeled by the latent variables corresponds to these levels. Demonstrating that the PixelCNN enhances the latent representation of the VAE for a specific, meaningful task would provide a much stronger result. Additionally, while the paper asserts that integrating PixelCNN with the VAE reduces the reliance on computationally expensive autoregressive layers, it is unclear how much more efficient the proposed model is compared to a PixelCNN achieving similar likelihoods.
Overall, I find the clarity of the paper's presentation lacking. For instance, I concur with reviewer1 that the exact architecture of the proposed model is insufficiently detailed, making it challenging to reproduce the results.