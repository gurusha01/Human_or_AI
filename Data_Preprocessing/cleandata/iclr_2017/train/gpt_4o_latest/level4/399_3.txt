This paper introduces a method to significantly increase the size of network models (in terms of the number of stored parameters) within the framework of a recurrent neural network. The approach leverages a Mixture of Experts (MoE) mechanism applied between recurrent layers, which is shared across all time steps. By processing features from all time steps simultaneously, the effective batch size for the MoE is scaled by the number of steps in the model. Consequently, even with sparsely assigned experts, each expert operates on a sufficiently large sub-batch of inputs to maintain computational efficiency. Additionally, the paper proposes a second technique that redistributes elements within a distributed model, further enhancing the batch sizes per expert.
The authors conduct experiments on language modeling and machine translation tasks, demonstrating notable improvements by increasing the number of experts. These results are compared against both state-of-the-art methods and explicitly computationally-matched baseline systems, showcasing the effectiveness of the proposed approach.
One area that could be improved is the presentation of plots or statistics related to the actual computational load and system behavior. While two loss terms are used to balance expert utilization, their impact is not thoroughly explored in the experiments section. It would have been helpful to examine these effects in greater detail, along with the influence of increasing effective batch sizes. For instance, measurements of the losses during training could be compared against counts or histogram distributions of per-expert batch sizes.
Overall, this paper presents a well-articulated system that achieves strong results. The innovative placement of the MoE effectively addresses potential challenges associated with sparse computation.
Minor comment:  
I appreciate Fig. 3, but it's unclear whether the data points align between the left and right plots. For example, the H-H line has three points on the left but five on the right. Additionally, it would be helpful if the colors were consistent across corresponding lines in both plots.