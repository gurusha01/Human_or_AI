This paper offers two primary contributions:  
(1) Extending adversarial training to ImageNet, a significantly larger dataset than those explored in prior work, and  
(2) Conducting a comparative analysis of various adversarial training techniques, with a particular emphasis on the transferability of these methods. Additionally, the authors identify and provide an explanation for the label leaking effect, which represents a noteworthy contribution.  
The paper is well-structured, clearly written, and effectively evaluates and contrasts different adversarial training approaches while exploring their interrelations. The inclusion of an extensive set of empirical results provides valuable insights into the adversarial training process. Overall, this work makes a significant contribution to advancing the understanding of adversarial training, and I believe it is well-suited for presentation at ICLR.