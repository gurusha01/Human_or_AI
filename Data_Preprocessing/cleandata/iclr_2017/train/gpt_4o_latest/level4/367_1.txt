The paper introduces a novel perspective on binary auto-encoders by framing the objective function as a min-max reconstruction error over a training set, conditioned on the observed intermediate representations. The author demonstrates that this formulation results in a bi-convex problem, which can be addressed using alternating minimization techniques. This aspect is non-trivial and constitutes the primary contribution of the work. Proof-of-concept experiments are conducted, illustrating performance improvements for 1-hidden layer auto-encoders compared to a standard baseline approach.
However, the experimental section is relatively weak, as the auto-encoder literature is extensive, with numerous variants (e.g., denoising auto-encoders) shown to outperform basic methods without added complexity. Despite this limitation, the paper provides an insightful analysis that culminates in a novel learning algorithm for a well-established problem, making it a potentially valuable contribution to the field.