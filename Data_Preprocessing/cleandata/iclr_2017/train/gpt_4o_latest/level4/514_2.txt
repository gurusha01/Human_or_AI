This paper explores methods to enforce invariance in neural networks through weight sharing. The authors propose a formal framework for ensuring that feature functions remain invariant to a set of relations, with a particular focus on "set-invariant" functions. These functions are applied in two settings: anomaly detection and point cloud classification.
The concept of "invariance" is undoubtedly significant, as it allows us to avoid allocating parameters to model spurious ordering relationships, which can be inefficient. I appreciate the formalization of invariance introduced in this work. However, there are several weaknesses that, in my view, limit the strength of this submission. First, the exposition is overly abstract, and the paper would benefit greatly from a running, concrete example introduced early on to ground the discussion.
Second, while the paper defines "set invariance" through the authors' formal framework, it does not explicitly connect this definition to the intuitive notion of "set invariance" — for instance, invariance to permutations of input or output dimensions. Providing an alternative, explicit definition of set invariance and then relating it back to the proposed "structural invariance" framework could improve clarity. For example, it is not evident why Figure 1(b) represents the set data-structure, as this is never clearly explained.
I appreciate the discussion on the compositionality of structures, though I have a question: are the resulting compositional structures still valid as structures? That said, the paper overlooks another critical aspect of compositionality relevant to neural networks — specifically, the relationship between the proposed invariance and function composition. It seems important to address under what conditions compositions of invariant functions remain invariant. For instance, merely having one invariant layer in a network does not guarantee that the entire network is invariant. In the anomaly detection network presented later in the paper, is it clear that the final predictor is "set invariant" in any meaningful sense?
Regarding the experiments, no baselines are provided for the anomaly detection task, which is a significant omission. While baselines are included for the point cloud classification problem, the proposed model does not achieve the best results, and this issue should be addressed. (I should note that I am not familiar enough with the dataset to assess whether the comparisons are entirely fair.) Additionally, the paper does not adequately justify why set invariance is a desirable property in the context of point cloud classification. As a suggestion, the authors could experiment with a network that uses a fully connected layer at the end but employs data augmentation to enforce set invariance. Another avenue worth exploring is the use of classical set kernels.
Additional comments:
- Example 2.2: Shouldn't |S|=5 in the case of left-right and up-down symmetry?
- The phrase "parameters shared within a relation" is vague and lacks a clear definition.
- Why is the term "set convolution" used in the appendix? What aspect of it is convolutional?
- Is there any connection to symmetric function theory? This could be worth discussing.