This paper introduces a method to enhance the efficiency of deep networks processing sequences of correlated inputs by limiting computations to those necessary for capturing changes between consecutive inputs. The paper is well-written, the proposed approach is innovative, and it is intriguing to observe a practical algorithm inspired by the principles of spiking networks. However, the advantages of this method appear to be more theoretical than practical at present, as its implementation on current hardware seems unlikely to yield significant benefits. I strongly believe that training deep networks with a suitable sparse slowness penalty could result in a far greater reduction in computational demands.