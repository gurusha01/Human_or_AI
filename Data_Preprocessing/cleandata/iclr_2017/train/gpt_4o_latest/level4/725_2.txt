This paper establishes connections between deep neural networks (DNNs), simplified stochastic neural networks (SFNNs), and proposes leveraging DNNs as initialization models for simplified SFNNs. The authors demonstrate the effectiveness of their approach through evaluations on several small-scale tasks, yielding positive outcomes.
The relationships drawn between the different models are intriguing. While the connection between sigmoid-based DNNs and simplified SFNNs appears to align with the well-established mean-field approximation, the identified link between ReLU-based DNNs and simplified SFNNs is novel and noteworthy.
My primary concern lies in the practicality of the proposed method for real-world tasks involving large training datasets. For tasks with smaller training sets, I can see how stochastic units might enhance generalization performance.