The authors propose a method for training probabilistic models by optimizing an objective resembling a stochastic variational lower bound. The training process involves sampling followed by learning a transition-based inference mechanism to "walk back" samples to the data distribution. Due to its emphasis on transitions, the method can be employed to directly learn a raw transition operator rather than solely focusing on energy-based modeling. The proposed objective is conceptually appealing, as it draws parallels to earlier, successful yet less theoretically grounded training approaches for MRFs, such as Contrastive Divergence.
The algorithm's core idea is intriguing and has the potential to contribute meaningfully to the field. However, the current submission is not yet suitable for publication. The experiments are primarily qualitative, and the generated samples do not clearly demonstrate high model quality. Additionally, as noted elsewhere, the mathematical analysis does not establish the tightness of the variational bound when employing a learned transition operator. Further evaluation, such as using annealed importance sampling to estimate held-out likelihoods, is necessary. Assuming the analysis can be improved, the method's ability to directly parametrize a transition operator—a notable advantage—should be further investigated in additional experiments and compared against conventional energy-based modeling approaches.
Overall, this work presents a promising direction, and the technical issues raised in this and other reviews should help refine and strengthen the paper for future submission.