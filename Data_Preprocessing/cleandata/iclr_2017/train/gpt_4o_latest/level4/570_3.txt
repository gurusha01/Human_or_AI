This paper introduces a neural architecture designed for answering non-factoid questions. The proposed model demonstrates improvements over prior neural approaches for answer sentence selection. The experiments are conducted on a Japanese love advice corpus, and the most intriguing aspect for me was that the model was deployed to the public, where its answers were rated as twice as good as those provided by human contributors!
However, I found it challenging to assess the novelty of the contributions. The authors claim that their model "bridges the gap between answer selection and generation," yet the model itself does not perform any actual generation. Instead, it seems quite similar to the QA-LSTM model proposed by Tan et al., 2015, with the key difference being additional terms in the objective function to account for conclusion and supplementary sentences. The answer structure is constrained to a predefined template (e.g., conclusion â†’ supplementary), meaning the model does not truly learn how to order sentences. Another contribution discussed is the "word embedding with semantics" approach in Section 4.1, which is essentially a variation of the paragraph vector model, substituting "titles" and "categories" for paragraphs.
While the paper presents a model that has shown practical utility in real-world scenarios, the technical contributions do not appear sufficiently novel to warrant publication at ICLR.
Additional comments:
- A significant limitation of the model's reliance on a fixed template is that it cannot be evaluated on widely-used non-factoid QA datasets like InsuranceQA. If the template were learned dynamically by the model rather than predetermined, it might be possible to evaluate on diverse datasets.
- The examples in Table 4 do not convincingly demonstrate a clear advantage in answer quality for the proposed model; QA-LSTM also seems to select high-quality answers.
- Does the construction model benefit from an inherent advantage over the standard QA-LSTM due to its explicit knowledge of which sentences are conclusions and which are supplementary? Or does QA-LSTM also have access to this distinction?