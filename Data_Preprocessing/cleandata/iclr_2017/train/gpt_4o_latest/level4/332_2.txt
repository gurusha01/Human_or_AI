The idea of learning a deep feature representation that is supervised to group dissimilar views of the same object is intriguing. While the paper is not particularly groundbreaking from a technical standpoint, this does not detract from its value. It effectively explores a novel form of supervision using a new dataset. The fact that the dataset is synthetic does not concern me, but it would strengthen the work to include additional experiments with real-world data.
However, I feel the paper overreaches in drawing connections to human vision. The introduction, particularly the second to fourth paragraphs, leans heavily on cognitive science and neuroscience, which I find unnecessary. The contribution of the paper is more straightforward: "We often aim to learn deep feature representations that are invariant to viewpoint changes. This work supervises a deep network accordingly. Humans also exhibit some degree of viewpoint invariance, which has been extensively studied [citations]." I am skeptical of claims suggesting deeper connections beyond this.
In Section 3.1, I believe the analysis should rely on the full matrix of instance-to-instance similarity assessments rather than reducing it to tree-to-tree distance comparisons. The lossy conversion to trees seems unnecessary. Additionally, the use of "Remarkably" in the statement "Remarkably, we found that OPnets similarity judgement matches a set of data on human similarity judgement, significantly better than AlexNet" feels unwarranted.
While I am not an expert in human vision, my understanding from prior knowledge and online resources suggests that "object persistence" is often associated with the concept of occlusion, which is not addressed in this paper. This omission, along with the use of human vision terminology, may give rise to misleading or overstated claims.