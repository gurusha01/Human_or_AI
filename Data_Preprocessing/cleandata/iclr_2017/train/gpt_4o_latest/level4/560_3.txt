Vanishing and exploding gradients pose significant challenges to the optimization of RNNs. This issue is exacerbated in tasks with long-term dependencies, which require deeper RNNs. One proposed approach to address this challenge is to optimize in a manner that ensures the transfer matrix is nearly orthogonal. This paper explores the impact of orthogonality on optimization and learning, which is a crucial topic. The writing is clear, the arguments are well-structured, and the proposed optimization method is intriguing. However, the primary limitation of this paper lies in the experimental section, which I believe is critical and should be substantially improved. Below, I provide detailed comments on the experimental section:
1- The experiments presented are insufficient. At a minimum, results should be reported for the adding problem and the language modeling task on the Penn Treebank dataset.
2- While I understand that the copying task becomes challenging with non-linearity, removing non-linearity alters the optimization process significantly. As a result, it becomes difficult to draw meaningful conclusions from the copying task results.
3- I could not locate the number of hidden units used for RNNs across the different tasks. Please include this information.
4- The paper should report the running time of the proposed method for varying numbers of hidden units, compare it with SGD, and specify the neural network package used for implementation.
5- The results in Table 1 and Table 2 seem to suggest that orthogonality may not provide substantial benefits, as the performance without a margin is quite close to that with the optimal margin. Is this interpretation correct?
6- Figure 2 is presented without any accompanying discussion. What insights should we derive from this figure? Please elaborate.