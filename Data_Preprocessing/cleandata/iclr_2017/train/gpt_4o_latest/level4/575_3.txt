The authors present a method that integrates a CCA objective with a downstream loss. This is an elegant and intuitive concept. However, the current version of the paper falls short in terms of both execution and clarity of presentation.
The overall objective of the proposed method remains unclear. This issue was raised in a pre-review question, but the response did not fully resolve the ambiguity. Is the objective a simple sum of the CCA objective and the top-layer loss, including the CCA constraints? Or is there some form of interpolation between the two objectives?
When referring to the top-layer objective as "cosine distance" or "squared cosine distance," do you mean that the method minimizes this distance between matched pairs in the two views? If so, this approach would not work as intended without the intermediate CCA layer, as minimizing the distance could trivially collapse all projections to a single point. A more meaningful baseline would involve a contrastive loss, such as the one proposed by Hermann & Blunsom, which minimizes the distance for matched pairs while ensuring separation for mismatched pairs (e.g., through uniform sampling or a more sophisticated strategy). Alternatively, other discriminative top-layer objectives tailored to specific downstream tasks could be explored.
The paper also suffers from imprecise terminology. For instance, the terms "correlation" and "cross-correlation" are used to describe relationships between two vectors. However, "correlation" typically applies to scalar quantities, and its meaning in this context needs to be explicitly defined. Similarly, "cross-correlation" is commonly associated with time series data. In equation (2), the operation involves taking the maximum of a matrix, which could benefit from further clarification. Additionally, the claim that this approach is "fully differentiable" while standard CCA is not warrants revisiting, as the distinction is not immediately evident.
On a related note, the discussion about the relationship between cosine distance and correlation seems somewhat misleading. These concepts are indeed related when the dimensions of the vectors are interpreted as samples of a single random variable, where the cosine distance of mean-normalized vectors corresponds to the correlation between the respective random variables. However, in the context of CCA, each dimension of the vectors is treated as a distinct random variable. As such, the connection between cosine distance and correlation may not be as relevant as implied.
Finally, a couple of minor typographical errors were noted:
- "prosed" should be corrected to "proposed."
- "allong" should be corrected to "along."