(Paper Summary)  
The authors propose the concept of "sample importance," a metric designed to quantify the influence of individual training examples on the training process of a deep neural network. This metric is derived from the squared L2 norm of the gradient, aggregated either (i) over the parameters of a specific layer or (ii) across all parameters. By summing this metric over time, the authors define "overall importance," which is used to distinguish between easy and hard examples. Using this framework, the authors analyze the role of [easy, hard] examples during training and their influence on different network layers.
(Detailed Review)  
I have several concerns regarding this paper. My primary concern is the validity of "sample importance" as a meaningful metric. As noted earlier, gradient magnitudes vary significantly throughout the training process, and it is unclear what insights can be reliably drawn from comparing \(\sumt gi^t\) to \(\sumt gj^t\). For instance, gradients typically exhibit larger norms during the early stages of training compared to convergence, which raises questions about the appropriateness of treating all gradients equally across time. I attempted to illustrate this during the question period with a thought experiment: if the learning rate were excessively high, training might fail to converge, rendering sample importance ill-defined. A metric that depends on the learning rate is problematic, as is the reliance on the L2 norm. An alternative, such as the "input Fisher" norm, \(\mathbb{E} \frac{\partial \log p}{\partial x}\) (computed at a specific time step), might be more suitable since it directly measures the classifier's sensitivity to the input \(x\) and is less affected by variations in the mean gradient norm. However, even summing Fisher norms over time may not yield meaningful insights.
The experimental evaluation also raises issues. The authors assert in Fig. 2 that output layers are predominantly learned during the early stages of training. However, this claim does not hold for CIFAR-10 and is questionable for MNIST: sample importance remains high across all layers throughout training, with only a minor early spike in the output layer. Additionally, Fig. 2 (lower, middle) and Fig. 6 reveal a potential flaw in the SI metric: the SI is disproportionately influenced by the input layer, which has the largest number of parameters and thus exerts a greater effect on the gradient norm. Different model architectures might have led to different conclusions. If the authors had demonstrated that SI could be leveraged to design an improved curriculum, it would have significantly strengthened the metric's utility. Unfortunately, the results in this regard are negative.
PROS:  
+ Comprehensive experimental evaluation  
CONS:  
- Sample importance is a heuristic and lacks strong theoretical justification  
- SI provides limited insights into the training dynamics of neural networks  
- SI does not contribute to curriculum learning strategies