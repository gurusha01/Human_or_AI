This paper introduces an autoencoder-based method for lossy image compression by optimizing the weighted combination of reconstruction error and code length. The proposed architecture features a convolutional encoder paired with a sub-pixel convolutional decoder. The experimental evaluation includes comparisons of PSNR, SSIM, and MS-SSIM metrics against JPEG, JPEG-2000, and a recent RNN-based compression method. Additionally, a mean opinion score test was performed.
Pros:
+ The paper is well-organized and clearly written.
+ The decoder design leverages recent advancements in convolutional techniques for image super-resolution.
+ The proposed quantization and rate estimation strategies are logical and well-supported.
Cons:
- The set of experimental baselines appears to be somewhat incomplete.
The application of autoencoders for compression is a significant and impactful problem. While directly optimizing the rate-distortion tradeoff is not entirely novel, the paper introduces sufficient distinctions (e.g., the quantization method and sub-pixel convolutional decoder) to differentiate it from prior work. Although I am not an expert in image compression, the proposed approach and results appear both sound and compelling. The primary limitation is that the implementation of Toderici et al. 2016b seems incomplete, and there is no comparison with Balle et al. 2016. Nevertheless, the fact that this architecture achieves competitive performance with JPEG-2000 while paving the way for future research involving variations in encoder/decoder size and data domains suggests that this work will be of considerable interest to the community.
I have no additional specific comments at this time, as the pre-review questions adequately addressed my initial concerns.