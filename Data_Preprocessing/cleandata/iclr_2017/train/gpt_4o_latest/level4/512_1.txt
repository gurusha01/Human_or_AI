This paper introduces a principled framework for nonparametric learning of activation functions in deep neural networks. The authors provide a solid theoretical justification for their choice of nonparametric activation functions. While the theoretical results are sound, I am particularly impressed by the experimental setup, where the proposed methods are evaluated on image recognition datasets and demonstrate up to a 15% relative improvement in test performance over the baseline. The paper is well-written and presents novel theoretical contributions. The intuition behind the proof of Theorem 4.7 could be explained more clearly in the main text, although the Appendix provides sufficient clarification.