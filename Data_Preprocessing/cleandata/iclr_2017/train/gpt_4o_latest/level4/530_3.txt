This paper introduces a relation network (RN) designed to model relationships between input entities, such as objects. The proposed network operates in two stages. Initially, a lower-level structure processes pairs of input entities, with all possible pairs being passed through this structure. Subsequently, the outputs from the lower-level structure are aggregated across all input pairs using a simple summation operation. This aggregated result serves as the input to a higher-level structure. In its basic form, both the lower- and higher-level structures are implemented as multi-layer perceptrons (MLPs).
Overall, the approach is compelling and offers a clear, well-motivated framework for understanding relationships among entities. The central idea is rooted in the observation that pooling techniques, which introduce invariance, can be leveraged to learn relational patterns. This concept extends traditional pooling mechanisms (e.g., spatial or temporal average/max pooling) to focus specifically on pairwise relationships. While the current method emphasizes pairwise interactions, it could potentially be generalized to capture higher-order interactions, albeit with potential scaling challenges.
Experimental results on tasks involving scene descriptions and images demonstrate the effectiveness of relation networks. The MLP baselines used in the comparisons fail to capture the structured dependencies inherent in these tasks. It would be intriguing to explore whether pooling operators (e.g., across-object max pooling within an MLP) or data augmentation techniques, such as permutation, could enhance the performance of MLPs on these tasks. Nevertheless, the proposed model is both novel and effective in handling relational reasoning and shows significant potential for addressing more complex reasoning tasks in the future.