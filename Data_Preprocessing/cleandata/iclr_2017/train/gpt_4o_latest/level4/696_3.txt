The paper investigates several recently developed machine readers and observes that certain machine readers may benefit from the use of entity markers (assuming the same marker consistently refers to the same entity). While I generally appreciate analysis papers, I found the argument presented in this work to be somewhat unclear.
I found the experiments conducted on the Stanford reader particularly compelling, as they demonstrate that entity markers indeed improve the Stanford reader's performance on the WDW dataset. These results were quite intriguing.
That said, I found the paper's organization and overall message to be rather confusing. For instance, it seems that the authors aim to explain the observed behavior using a concept of "structures." However, I am uncertain about the success of this explanation. The definition of "structures" remains unclear to me, which made reading Section 4 somewhat frustrating.
Additionally, I am unsure about the key takeaway of the paper. Does it suggest that entity marking should be incorporated into machine reading models? Should models be designed to simultaneously handle entity references? What role do linguistic features play in this context? Should linguistic structures be leveraged to address the issue of entity reference?
In summary, while the analysis presented is interesting, I believe the paper would benefit from a more focused and coherent argument.