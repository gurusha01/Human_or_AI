Review - Overview:
This paper proposes a biasing term for stochastic gradient descent (SGD) that, based on theoretical analysis and a toy example, produces solutions with approximately equal or lower generalization error. This improvement comes at the computational expense of estimating the gradient of the biasing term in each iteration using stochastic gradient Langevin dynamics (SGLD), which approximates an MCMC sample of the log partition function of a modified Gibbs distribution. The computational cost is equivalent to introducing an inner loop within the standard SGD algorithm for each minibatch.
Pros:
- The paper synthesizes and builds upon numerous results and theorems from the past two decades, offering a promising direction for enhancing the generalizability of deep neural networks.
- The writing and presentation are generally clear and well-structured, with an engaging discussion on using the eigenvalues of the Hessian to characterize "flat" minima.
- The mathematical arguments are compelling and suggest that Entropy-SGD (E-SGD) has a generalization error that is provably no worse than SGD, providing motivation for further exploration of this approach.
Cons / Points Suggested for Rebuttal:
(1) One of the claims in the abstract states that "experiments on competitive baselines demonstrate that Entropy-SGD leads to improved generalization and has the potential to accelerate training." However, this claim does not seem to be substantiated by the current experimental results. As noted in the discussion section, "In our experiments, Entropy-SGD results in a comparable generalization error as SGD, but always has a lower cross-entropy loss." These two statements appear contradictory, and it is unclear how they can be reconciled.
(2) Similarly, the assertion that E-SGD accelerates training is not convincingly demonstrated in the current version of the paper. While vanilla SGD requires a single forward pass through all \( M \) minibatches during one epoch for a parameter update, E-SGD requires \( L \times M \) forward passes per epoch, where \( L \) is the number of Langevin updates, each requiring a minibatch sample. This implies that E-SGD may have worse computational complexity to achieve the same result. On page 9, the authors define an epoch as "the number of parameter updates required to run through the dataset once," but this does not address the additional factor of \( L \) computations introduced by the inner-loop SGLD iterations. The tradeoff introduced by SGLD could be computationally expensive and must be carefully managed by users of E-SGD.
(3) The paper would benefit from a more measured presentation of its claims. For instance, the introduction states, "Actively biasing towards wide valleys aids generalization, in fact, we can optimize solely the free energy term to obtain similar generalization error as SGD on the original loss function." However, based on the results reported on pages 9-10, only on MNIST does the generalization error from optimizing the free energy term (the log partition function of the modified Gibbs distribution) match that of SGD on the original loss function. This corresponds to setting \( \rho = 0 \) in Equation (6). On CIFAR-10, \( \rho = 0.01 \) is used, indicating that the claim does not hold universally.
(4) The paper's contribution to characterizing the optimization landscape using the eigenvalues of the Hessian and associating flat local minima with low generalization error is insightful and valuable. The plots provided are clear and informative. However, as another reviewer has noted, there are notable high-level similarities to the work "Flat Minima" by Hochreiter and Schmidhuber (1997). While the authors have added a paragraph addressing some differences with H&S 1997, it would be beneficial to explicitly identify and discuss the similarities as well. H&S 1997 includes detailed theoretical analysis that could inform future work in this area and appears to have independently proposed a similar approach to training generalizable networks.
(5) The assumptions about eigenvalues made in Section 4.4 and Appendix B raise questions about their applicability to real-world problems. For instance, what magnitude of \( c > 0 \) needs to be chosen? Does this correspond to a measurable property of the dataset? These aspects remain unclear in the current version of the paper and would benefit from further elaboration.