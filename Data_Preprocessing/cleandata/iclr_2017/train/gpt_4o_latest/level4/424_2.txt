This paper begins by introducing a general framework aimed at enhancing the optimization of a complex function through a sequence of approximations. The authors argue that if these approximations exhibit more favorable properties compared to the original function, optimization can, in principle, be accelerated. The framework is then applied to a specific formulation where a neural network is designed to act as a simpler network under high noise conditions, regaining its full capacity as noise diminishes during training.
The core idea and motivation of this work are compelling and well-founded. As noted in my pre-review question, I was curious about the connection to shaping methods in reinforcement learning (RL). While I agree with the authors that their approach differs from traditional shaping—which typically modifies the problem itself—by instead "shaping" the architecture, the underlying principle in both cases involves solving a sequence of optimization problems with increasing complexity. Therefore, I strongly recommend including a discussion that clarifies the distinctions between shaping, curriculum learning (which I also find conceptually similar to shaping), and the proposed method.
The presentation of the neural network methodology requires significant improvement for better clarity. Enhancing this aspect will make the paper more accessible to readers. Specifically:
- Algorithm 1 is not comprehensible at the point where it is first referenced.
- The steps leading to Eq. 25 need to be explained more thoroughly and explicitly connected to steps 1-6 in Algorithm 1.
- The function \( u(x) \) should be clearly defined before introducing \( u^*(x) \).
There are also several issues with the experimental evaluations that need to be addressed. Notably, the paper should discuss why the proposed method does not seem to perform well on more challenging network training tasks, such as training thin and deep networks. Specific concerns include:
- The MLPs used in the experiments (Parity and Pentomino) are not very deep. A more suitable evaluation would involve training thin networks with systematically increasing depth, as network depth is well-known to introduce significant optimization challenges. Instead, the paper claims—without supporting references—that "Learning the mapping from sequences of characters to the word-embeddings is a difficult problem."
- For cases where the observed benefit appears to stem primarily from regularization, the method should be compared against other weight noise regularization techniques.
- A comparison with highway networks is also recommended, given the thematic similarities with Eq. 22. Highway networks may inherently anneal their behavior from simple to complex during training, as they are typically initialized with a bias toward copying behavior.
- Regarding the CIFAR-10 experiment, does the mollified model incorporate residual connections? If so, what is the rationale? Regardless, why does the mollified network train more slowly than the residual and stochastic depth networks? This result seems inconsistent with the findings from the MLP experiments.
In summary, while the ideas and contributions of this paper are promising, further refinements are necessary before it can be considered a clear accept.