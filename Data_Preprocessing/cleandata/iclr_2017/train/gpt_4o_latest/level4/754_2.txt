This paper employs a pointer network over a sparse window of identifiers to enhance code suggestion for dynamically-typed languages. Code suggestion appears to be a domain where attention mechanisms and/or pointer networks demonstrate a clear advantage in capturing long-term dependencies.
The sparse pointer approach seems to outperform attention mechanisms for comparable window sizes. Specifically, when comparing a window size of 20 for both the attention and sparse pointer methods, the sparse pointer method consistently achieves superior results. A key strength of the pointer method lies in its ability to effectively handle larger window sizes due to the supervision it provides. However, it was disappointing (albeit understandable given potential memory constraints) that larger window sizes were not explored. Additionally, the use of different batch sizes for the sparse pointer and attention models complicates what would otherwise be a straightforward comparison between the two approaches.
The construction and filtering of the Python corpus appear promising, but as of now, the dataset remains inaccessible (marked as TODO in the paper). Considering that code suggestion represents an intriguing area for future research on long-term dependencies, this dataset could serve as a valuable resource for further exploration in this domain.
In summary, despite a few potential limitations, this paper and its associated dataset likely represent a meaningful contribution to the field.