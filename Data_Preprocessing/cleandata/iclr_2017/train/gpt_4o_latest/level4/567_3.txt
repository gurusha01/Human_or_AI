The authors propose a method for learning subspaces across multiple views such that the neighborhoods of data points are consistent across all views. This consistency is quantified by comparing the distributions of neighbors between pairs of views. The motivation for this approach is that it provides a natural criterion for information retrieval tasks.
I find the idea of preserving neighborhood relationships across views for retrieval tasks compelling. Additionally, it is a notable feature that the learned subspaces can differ in dimensionality across views. However, the empirical evaluation presented in the paper appears to be somewhat preliminary.
This paper is a revised version of the authors' ICLR 2016 submission, and the revisions are appreciated. However, I believe the paper still requires further development before it can be considered for publication. In its current state, it may be more suitable for the workshop track.
The experiments are conducted on very small datasets (e.g., 2000 examples in both the training and test sets for the MNIST task) and do not involve real-world tasks. While the authors note that their focus is not on efficiency and suggest that computational constraints may limit their ability to work with larger datasets, it remains unclear whether the conclusions drawn from these experiments would generalize to more realistic settings. Given the extensive body of work on multi-view subspace learning with applications to real-world tasks, it is difficult to view this paper as a significant contribution without demonstrating its applicability in such contexts.
On a related but minor point, the authors claim that no other approaches based on information retrieval exist, but this assertion seems somewhat overstated. For instance, the contrastive loss introduced by Hermann & Blunsom in "Multilingual models for compositional distributed semantics" (ACL 2014) is related to information retrieval and would be a natural baseline for comparison.
The presentation of the paper could also be improved, as it contains several vague or unclear points. Examples include:
- The term "dependency" is frequently used in a colloquial sense, which can be confusing in a technical context where the term has a specific definition.
- The phrase "an information retrieval task of the analyst" is vague and ungrammatical.
- The statement "the probability that an analyst who inspected item i will next pick j for inspection" is not well-defined.
- The discussion of KL divergence and its relationship to the "cost of misses" is difficult to follow. Clarifying this reasoning or omitting it (given that KL divergence is already well-motivated) could improve the clarity.
- It is unclear whether \( C_{\text{Penalty}} \) (Equation 7) is added to \( C \) (Equation 6) or replaces it. This section could benefit from clarification.
- The paper states that CCA "iteratively finds component pairs," but while CCA can be formulated as an iterative process, it is typically solved in a way that identifies all projections simultaneously.
- The description of PCA being performed "between \( Xi^1 \) and \( Xi^2 \)" is unclear.
- The phrase "We apply nonlinear dimensionality algorithm" is vague; the specific algorithm should be named.
- The tasks involving image patches and stock prices are not described clearly, making it difficult to understand their setup and objectives.
Additional minor comments, typos, and issues include:
- The fonts in the figures are too small to read comfortably.
- "difference measures" should be corrected to "different measures."
- The phrase "...since, hence any two..." is ungrammatical.
- The phrase "between feature-based views and views external neighborhoods" is unclear and needs rephrasing.