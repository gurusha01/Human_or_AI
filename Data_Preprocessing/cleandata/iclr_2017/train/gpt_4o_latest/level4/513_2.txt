Review - Summary
This paper develops models to predict whether block towers will collapse. It demonstrates that incorporating an additional model that predicts how blocks fall (via unsupervised learning of frame sequences) improves the generalization of the primary supervised task.
The authors create a synthetic dataset of block towers with 3 to 5 blocks placed in varying degrees of stability. The dataset includes labels (whether the tower falls) and video frame sequences depicting the tower's dynamics, simulated using a physics engine.
Three types of models are trained. The first (S) uses an image of the tower's initial state to predict whether it will fall. The other two models (CD and CLD) utilize both the tower's initial and final states to predict whether it has fallen, differing in how the final state is derived. The CD model (ConvDeconv) predicts the final frame from the initial frame, while the CLD model (ConvLSTMDeconv) predicts a sequence of intermediate frames leading to the final frame. Both CD and CLD models are trained in an unsupervised manner.
The models are trained on towers of a specific height and tested on towers of unseen heights. When the training and testing tower heights match, all models perform similarly (within a few percentage points). However, when the test towers are taller than the training towers, explicitly modeling the final state of the tower (as done by the CD and CLD models) significantly improves performance.
---
Pros
- The paper demonstrates substantial accuracy improvements by incorporating an unsupervised final frame predictor. The clear generalization challenge (training and testing on towers with different block counts) makes this a compelling toy example where unsupervised learning provides tangible benefits.
- The writing is concise and easy to follow.
---
Cons
The primary limitation of the paper is the lack of in-depth analysis. While the core result is well-established, the exploration of the idea does not meet the depth expected of an ICLR paper. Below are two potential directions for further analysis:
1. Limitations of the block tower rendering process:
   - The LSTM model might be constrained by the sub-sampling strategy. From the provided examples, the sampling rate appears too coarse. For instance, in Figure 2, the two falling towers collapse within just 1 or 2 time steps. How quickly do towers typically fall? What happens if the LSTM is trained on a higher frame rate? What is the LSTM's frame-by-frame video prediction accuracy, and is this metric meaningful? How does performance change if the LSTM is given ground truth for the first k frames?
2. Challenges in generalizing to different block heights:
   - Is the limitation due to model capacity or architectural design? What happens if the S-type models are made wider or deeper, while keeping the CD/CLD models' capacities fixed?
   - Could the limitation stem from the task specification? For example, what if models were trained on towers of multiple heights (an experiment the authors mention is in progress)? The paper does include one experiment in this direction, which is appreciated.
   - Could the training procedure be a bottleneck? What if the CD/CLD models were trained end-to-end? Alternatively, what if the double-frame fall predictor were trained using ground truth final frames instead of generated ones?
---
Minor Concerns
- While re-implementing Zhang et al. (2016) and PhysNet for the proposed dataset may be overly demanding, including baselines directly comparable to the proposed models would strengthen the paper. This is not a major concern, as the focus of the paper is on the role of unsupervised learning rather than achieving state-of-the-art performance in fall prediction.
- The auxiliary experiment is motivated by the idea that predicting the number of fallen blocks instead of a binary stability label might simplify the task. However, the intuition behind this claim is unclearâ€”further elaboration would be helpful.
- Will the dataset or the code to generate it be made publicly available?
---
Overall Evaluation
The paper's writing, presentation, and experiments are clear and meet the quality standards for ICLR. However, the experimental analysis is limited beyond the main result (as discussed above). While the novelty is moderate, as the work builds on unsupervised learning (video prediction) and prior research in intuitive physics (e.g., Lerer et al., 2016; Zhang et al., 2016), the results would still make a valuable contribution to the literature, particularly with additional analysis.