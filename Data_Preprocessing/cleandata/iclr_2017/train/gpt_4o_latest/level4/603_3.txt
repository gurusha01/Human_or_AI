This paper addresses the problem of source code completion using neural network models. It introduces several models, all of which are straightforward variations of LSTMs, tailored to accommodate the specific characteristics of the chosen data representation (where code is represented as a sequence of (nonterminal, terminal) pairs, with terminals optionally being EMPTY). Another minor modification is the inclusion of a "deny prediction" option, which is a reasonable addition in the context of code completion within an IDE, as it may be preferable for the model to abstain from making a prediction when it is highly uncertain about the next token.
Empirical results indicate that the proposed approach performs worse than prior work in predicting terminals but achieves better performance in predicting nonterminals. However, I find the distinction between terminals and nonterminals somewhat unusual, and the implications of this split are unclear. A more intuitive metric might be the overall accuracy of predicting the next token as it appears in the code. Why not compute and report a single performance metric to provide a clearer summary of the system's effectiveness?
In general, the paper is adequate but gives the impression of being a straightforward application of LSTMs to an existing dataset. The results are acceptable but not particularly compelling. Additionally, the writing could be improved in several places (see detailed comments below). Overall, I do not believe the contributions are substantial enough to justify publication at ICLR.
Detailed comments:
* The NT2NT model seems unusual, as it predicts the nonterminal and terminal independently, conditioned on the hidden state.
* The related work section requires revision. For instance, Bielik et al. does not generalize all the works mentioned at the start of Section 2, and the citation for Maddison (2016) is incorrect.