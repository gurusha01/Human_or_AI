The authors present an intriguing approach that establishes a connection between the energy-based model (descriptor) and the generator network, enabling mutual enhancement. Specifically, the generator's samples serve as the initialization for the descriptor's inference, while the refined samples from the descriptor are subsequently used to update the generator as the target image.
While the proposed idea is compelling, the primary limitation lies in the lack of convincing experimental evidence to substantiate the benefits of this architecture. For instance, readers would anticipate a quantitative analysis demonstrating how initializing with generator samples provides an advantage. Additionally, the sole quantitative experiment on reconstruction is compared against relatively outdated models. Given the resemblance of the proposed model to the work of Kim & Bengio (2016), a comparison with that model would also be expected by the audience.
 Minor Comments:
- I am curious about the validity of the convergence analysis, especially considering that the samples from SGLD are biased due to the use of a fixed step size.
- Could you provide further clarification on the derivation of Eqn 8, particularly regarding the dependency of p(x|y) on W_G?