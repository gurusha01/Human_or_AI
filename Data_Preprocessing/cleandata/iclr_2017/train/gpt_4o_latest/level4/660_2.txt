The paper introduces a semi-automatic learning rate schedule for the Adam optimizer, named Eve. While the originality is somewhat constrained, the proposed method seems to enhance neural network training. The manuscript is well-written, and the accompanying illustrations are suitable.
Pros:
- likely a more advanced scheduling approach compared to a basic decay mechanism  
- acceptable performance on the CIFAR dataset (albeit with a relatively small neural network)  
Cons:
- the impact of the momentum term warrants further investigation  
- the Adam citation refers only to the arXiv preprint rather than the conference publications  
- the comparison with Adam lacks full clarity