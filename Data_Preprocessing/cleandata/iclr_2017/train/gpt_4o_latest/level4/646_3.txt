This paper introduces an "interactive" version of the bAbI dataset by incorporating supporting questions and answers in scenarios where the original dataset lacks sufficient information to answer a given question. The concept of Interactive QA is undoubtedly an intriguing and well-motivated research direction as presented in the paper. However, the proposed extension of the bAbI dataset is not sufficiently detailed. For instance, the baseline DMN and MemN2N models for the IQA task operate by "taking both statements and the question as input and then estimating an answer." This approach inherently makes their task more challenging compared to CAN's, as they do not differentiate "feedback" from the original context. A potentially fairer comparison might involve treating all questions (both supporting and original) as distinct instances. Additionally, the process for generating the supporting questions and user feedback is unclear. How were these questions created? How many templates or words were used? The lack of detailed information on dataset creation is a significant omission. If space constraints are an issue, the paper could reduce or condense basic explanations of concepts like GRU or sentence encodings and instead reference the original works.
Another concern is the model's attempt to generate synthetic questions. If only a small number of templates are used, why not directly predict the values needed to populate these templates? For example, instead of generating a question like "Which bedroom, master one or guest one?" using an RNN decoder, it might suffice to predict just "which" or "which bedroom." Ultimately, these generated questions appear to function more as additional supporting facts rather than genuine user interaction. Furthermore, the fact that the experiments are conducted on only three out of the original twenty tasks raises doubts about the generalizability and reliability of the conclusions.
In summary, while the paper presents a compelling idea and motivation, the experimental results and methodology are not sufficiently robust to warrant acceptance at ICLR.