The paper introduces an approach to multimodal machine translation, specifically addressing the scenario where an image corresponding to both the source and target sentences is available.
The proposed method seems to rely on a latent variable model conditioned on the image. However, as evidenced by Equation 3 and Figure 3, the image is utilized solely during training for inference purposes. Consequently, the approach appears fundamentally flawed, as the image does not play a direct role in the actual translation process.
The experimental results are underwhelming. Assuming proper model selection using the validation set, the proposed model achieves only a marginal improvement of 0.6 METEOR and 0.2 BLEU over the baseline. Given the overall variance in the results, these gains cannot be deemed statistically significant.
The qualitative analysis presented in Subsection 4.4 is neither conclusive nor convincing.
In summary, the paper suffers from significant shortcomings in both its conceptual approach and its execution.