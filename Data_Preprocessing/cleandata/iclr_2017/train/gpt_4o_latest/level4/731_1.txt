The proposed method in this paper integrates a binary encoding layer into the PV-DBOW and PV-DM document embedding frameworks (Le & Mikolov, 2014). This binary encoding is implemented as a sigmoid function with trainable parameters, which is applied after the standard embedding training process.
To encode a document, a binary vector is generated by constraining the sigmoid to produce binary outputs for each component of the embedding vector. This binary representation facilitates compact storage and enables efficient document comparison.
Strengths:
- The binary representation achieves superior performance compared to the Semantic Hashing method introduced by Salakhutdinov & Hinton (2009).
- The experimental methodology is robust: the authors evaluate their method using the same experimental setup as Salakhutdinov & Hinton (2009). Additionally, they leverage advancements in document representations (Le & Mikolov, 2014) and combine these with an RBM to demonstrate the advantages of their binary PV-DBOW/PV-DM approach.
Weaknesses:
- The inclusion of the sigmoid layer to generate binary codes (as proposed by Lin et al., 2015) represents an incremental improvement.
- The explanation of the method is abstract and may be challenging for non-experts to follow (specific points are detailed below).
- The paper lacks a comparison with efficient indexing techniques commonly used in image retrieval. For large-scale indexing of embedding vectors, methods such as derivations of the Inverted Multi-Index are likely to be more effective than binary codes. See, for example, Babenko & Lempitsky, "Efficient Indexing of Billion-Scale Datasets of Deep Descriptors," CVPR 2016.
Detailed Comments:
- Section 1: The motivation for generating binary codes is not clearly articulated. Additionally, the experimental section would benefit from including timing and memory usage statistics to highlight the advantages of binary embeddings.
- Figures 1, 2, 3: There is sufficient space to provide more details about the model's representation, including parameters, training objectives, characteristic sizes, and dropout settings. For instance, in Figure 2, it is unclear why "embedding lookup" and "linear projection" cannot be combined into a single, smaller lookup table. Presumably, this is due to an intermediate training objective, but this should be clarified.
- Page 2: The statement, "This way, the length of binary codes is not tied to the dimensionality of word embeddings," requires further explanation. Why is this the case?
- Section 3: The experimental setup appears to replicate that of Salakhutdinov & Hinton (2009). This should be explicitly stated, along with any differences between the setups.
- "Similarity of the inferred codes": Clarify here that the codes are compared using Hamming distances.
- "Binary codes perform very well, despite their far lower capacity": Does this refer to the smaller size of binary codes compared to real-valued vectors? If so, rephrase for clarity.
- Figure 5: These plots could be omitted if space constraints arise.
- Section 3.1: The claim that "transferring" from Wikipedia to other datasets constitutes transfer learning is debatable, as Wikipedia is designed to encompass a broad range of topics and lexical domains.
- Section 3.2: Specify the metric used to compare the 300-dimensional real-valued vectors. Is it the L2 distance or the inner product?
- Figure 4: Include the raw performance of the large embedding vectors without pre-filtering using binary codes. Alternatively, report the performance for configurations such as (code-size, Hamming distance) = (28, 28), (24, 24), etc.