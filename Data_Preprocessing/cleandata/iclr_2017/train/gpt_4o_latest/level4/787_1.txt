The paper introduces a semantic embedding-based method for multilabel classification. Unlike prior approaches, SEM assumes that the underlying parameters governing the observed labels are low-rank, rather than assuming the observed label matrix itself is low-rank. However, the significance of the distinction between these two assumptions remains unclear.
SEM represents the labels for a given instance as samples from a multinomial distribution, which is parameterized by nonlinear functions of the instance features. In essence, this makes it a neural network. The proposed training procedure is marginally more complex than standard backpropagation. Nonetheless, the improvement in results over NNML, particularly on large datasets like Delicious and Eurlex, is not convincingly demonstrated.
The paper is well-written, and the core idea is clearly articulated. However, the experimental results lack sufficient impact to offset the limited conceptual innovation.