Thank you for providing an engaging and thought-provoking paper.
I found the work to be highly compelling. Given that (deterministic) approximate inference is inherently intertwined with the modeling process (unlike exact inference), it is crucial to provide users with the flexibility to choose inference methods that align with their specific needs and constraints. While I am not a PPL expert, this appears to be the first package I have encountered that emphasizes compositional inference to this extent. Additionally, the integration with TensorFlow is a significant advantage, as it facilitates the design of flexible computation graphs and enables parallel computation on GPUs.
My primary question pertains to the design of flexible objective functions for learning hyperparameters (or, as referred to in the paper, the variables associated with delta q distributions). It seems that hyperparameter learning is framed as inference, which is logical in the context of MAP. However, the authors also explore alternative objective functions, such as Renyi divergences. Does this imply that users would need to define an entirely new class of inference methods each time they wish to experiment with a different loss function?