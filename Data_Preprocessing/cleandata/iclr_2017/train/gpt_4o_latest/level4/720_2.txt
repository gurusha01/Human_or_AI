The paper introduces a method for learning continuous features from input data composed of multiple categorical variables. The approach involves embedding each category into a learnable low-dimensional continuous space, explicitly computing pairwise interactions between categories in a given input sample (via either component-wise dot product or component-wise addition), applying k-max pooling to retain the most informative interactions, and iteratively repeating this process to derive the final feature vector for the input. This final feature vector is then fed into a classifier or regressor to perform the target task. The category embeddings are learned in the standard manner. In the experimental section, the authors demonstrate on a synthetic dataset that their method can identify relevant interactions in the data. On a real-world dataset (iPinYou), the proposed model appears to outperform a few simple baselines.
My primary concern with this paper is the lack of novelty. The concept of embedding categorical data with mixed categories has been extensively explored in prior work, where a common approach involves learning separate lookup tables for each category type. The input is represented by concatenating the embeddings from these lookup tables, followed by applying a nonlinear function (e.g., a deep neural network) to extract features. The only minor contribution in this paper is the explicit modeling of category interactions as described in equations 2/3/4/5. Beyond this, the paper does not offer significant advancements.
Moreover, I believe that such interactions could (and arguably should) be learned automatically by employing a deep convolutional network on top of the input embeddings. This raises questions about the practical utility of the proposed contribution.
The experimental evaluation is also quite limited. The authors test their method on a single real-world dataset and compare it against a few relatively weak baselines. A more robust evaluation would involve comparisons against a broader range of models from the literature that address similar problems, such as wsabie.
While the authors argued in their response that wsabie is not applicable to their problem, I strongly disagree with this assertion. Although the original wsabie paper focused on image-based inputs, its training methodology can be readily adapted to other types of datasets, including those with categorical data. For example, I hypothesize that a model that embeds all categorical inputs, concatenates the embeddings, applies a deep convolutional network on top, and trains using a margin-based loss would perform as well as, if not better than, the manually designed interaction model proposed in this paper. While I could be mistaken, the lack of comparisons against such baselines makes the results less convincing.