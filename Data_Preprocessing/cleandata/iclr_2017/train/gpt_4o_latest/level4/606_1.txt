The paper introduces a method for training neural networks to replicate abstract data structures. The concept of training a network to adhere to an abstract interface is intriguing and holds promise, but the current empirical evidence is insufficient. The work would be greatly improved by demonstrating the method's utility in a practical application or by showing its superiority over standard RNN techniques in algorithmic learning tasks.
The assertions regarding mental representations lack adequate support. References to the mind and brain, along with the more philosophical discussions, should either be removed or reworked into a paper that focuses specifically on these aspects and provides robust evidence for the claims.