This paper explores multi-sense embeddings and introduces a method for learning them by leveraging aligned text across multiple languages. Additionally, it argues that incorporating more languages enhances word sense disambiguation, as certain ambiguities may persist across language pairs. While the core idea is not novel, the authors present a specific framework for learning multi-sense embeddings using multilingual data.
Overall, the concept is sound, but the paper has several significant shortcomings. First, the model description is unnecessarily complex for what is a straightforward idea that could be explained much more succinctly. More critically, the lack of comparison with existing work makes it difficult to objectively assess the effectiveness of the proposed model.
The paper would be considerably stronger if the learned embeddings were tested on downstream tasks and compared against other established methods. In its current form, the evaluation is limited, relying primarily on relative comparisons between model variants and t-SNE visualizations, which do little to substantiate the claims.