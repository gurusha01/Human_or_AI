The paper explores a novel approach to "learning" approximate data structures by training neural networks (specifically ConvNets) to emulate the behavior of an abstract data structure. This is achieved by applying an L2 loss (on the unrolled neural network) to ensure adherence to the axioms of the target data structure. For example, in the case of a stack, if the network is trained with operations like NN.push(8), NN.push(6), NN.push(4), the loss is computed based on the discrepancy between the sequence of NN.pop() operations and the expected output sequence of 4, 6, 8. This concept is illustrated in Figure 1 of the paper.
However, there are several significant issues with the work:
- For the stack example, the proposed approach appears indistinguishable from a seq-to-seq RNN trained to take an input sequence (e.g., 8, 6, 4) and predict the corresponding output sequence (e.g., 4, 6, 8).
- While some prior work is appropriately cited, the paper neglects a substantial body of relevant literature on learning data structures and axioms, including foundational works from the 1990s and more recent contributions. Notable omissions include [Das et al. 1992], [Wiles & Elman 1995], [Graves et al. 2014], [Joulin & Mikolov 2015], and [Kaiser & Sutskever 2016], among others. These should be cited and compared against the proposed approach.
- The use of MNIST digits as input unnecessarily complicates the problem, as a simpler categorical distribution over numbers would suffice.
- The most critical shortcoming lies in the experimental evaluation. While the figures provided are adequate, the experiments lack meaningful comparisons to alternative methods. Furthermore, there is no quantitative analysis or metric to assess the success of learning the data structures, such as performance relative to the number of training examples or the length of input sequences. As it stands, the experimental evidence presented in the current version of the paper (dated December 9th, 2016) is anecdotal at best and insufficient to substantiate the claims made.
While the paper explores an interesting research direction, the experimental validation is too weak to justify acceptance at ICLR.