This paper introduces a novel approach, termed interior gradients, for evaluating feature importance in deep neural networks. The interior gradient is defined as the gradient computed on a scaled version of the input, and the integrated gradient is obtained by integrating these interior gradients across all scaling factors. Visual comparisons between integrated gradients and standard gradients on real image inputs to the Inception CNN demonstrate that integrated gradients align well with an intuitive understanding of feature importance.
Although the motivation and qualitative examples are compelling, the paper falls short in providing both qualitative and quantitative comparisons with prior methods. The only baseline included for qualitative comparison is the standard gradient. However, the paper references several other approaches (e.g., DeepLift, layer-wise relevance propagation, guided backpropagation) that address the same problem of feature importance. The absence of comparisons with any of these methods represents a significant shortcoming. Without such comparisons, I do not consider the paper suitable for publication. Furthermore, my pre-review question highlighting this exact concern remains unaddressed.