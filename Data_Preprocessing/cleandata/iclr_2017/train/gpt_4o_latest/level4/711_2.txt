This paper introduces an architecture for the answer extraction task and evaluates its performance on the SQuAD dataset. The proposed model generates fixed-length representations for all spans within the answer document using a recurrent neural network. It achieves better performance than several baselines in terms of exact match and F1 scores on SQuAD.
Unfortunately, the results on the blind test set are not yet available due to copyright restrictions. Additionally, there are numerous other systems/submissions on the SQuAD leaderboard that could have been used for comparison.
In the absence of test set results, the use of grid search for hyperparameter tuning directly on the development set raises some concerns, despite the authors conducting cross-validation experiments.