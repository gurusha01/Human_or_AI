The authors present an extension to the "standard" attention mechanism by incorporating a distribution over latent structures (e.g., alignments, syntactic parse trees, etc.). These latent variables are represented as a graphical model, with potentials parameterized by a neural network.
The paper is well-written and easy to follow. The proposed methods are evaluated across multiple tasks, and in each case, the "structured attention" models outperform the baseline models (either those without attention or those using simple attention). For the two real-world applications, the performance gains achieved by the proposed approach over the "simple" attention models are relatively modest, but the techniques themselves remain intriguing.
Main comments:
1. In the Japanese-English Machine Translation task, the performance gap between the Sigmoid attention model and the Structured attention model appears to be relatively narrow. I wonder if the authors conducted an analysis of the attention alignments to assess whether the structured models produced better alignments. Specifically, if ground-truth alignments are available for the dataset, or if human annotations could be obtained for some test examples, it would be valuable to evaluate alignment quality in addition to the BLEU score.
2. In the final experiment on natural language inference, it was somewhat surprising that the use of pretrained syntactic attention layers did not enhance model performance and instead seemed to degrade it. Do the authors have any hypotheses to explain this outcome?
Minor comments:
1. Typographical error: Equation 1: "p(z | x, q" → "p(z | x, q)"
2. Section 3.3: "Past work has demonstrated that the techniques necessary for this approach, … " → "Past work has demonstrated the techniques necessary for this approach, … "