The application of machine learning (ML) to interactive theorem proving (ITP) represents a compelling research direction. In this work, the authors tackle the task of predicting whether a given statement will be useful in proving a conjecture, framing it as a binary classification problem. To this end, they propose a new dataset and introduce several deep learning-based baseline models.
As I am not an expert in ITP or theorem proving, my review primarily focuses on the ML aspects of the paper. One of the key objectives of this work should be to present the problem in a manner that is accessible to an ML audience. While the paper is generally well-written, certain sections, particularly Section 2, are difficult to follow:
- Terms such as LCF, OCaml-top level, and deBruijn indices are introduced without sufficient explanation or references. While these concepts may be standard in the ITP literature, they are not easily understood by readers outside this domain.  
- The description of how the dataset is split into training and test sets is unclear. Specifically, it is not evident whether the training and test examples can involve statements related to the same conjecture or if they are always derived from distinct conjectures.
Additionally, the application of the deep learning models is not fully explained. For instance, in the leftmost architecture depicted in Figure 1, each character is embedded into a 256-dimensional vector and processed up to the global max-pooling layer. However, it is unclear whether this layer computes the maximum value along each feature across all characters in the input.
Another concern is the lack of diversity in baseline methods. The authors only evaluate deep learning models, but it would be beneficial to include comparisons with traditional NLP techniques, such as a Bag-of-Words representation followed by an SVM classifier. While these approaches are likely to be outperformed by neural networks, their inclusion would provide a clearer sense of the difficulty of the proposed problem.
Furthermore, it is unclear whether the authors conducted an analysis of the algorithm's success and failure cases. Such an analysis could yield valuable insights into the limitations of the current models and guide the design of future approaches.
In summary, I find the exploration of ML for theorem proving to be an intriguing and promising research direction. However, the paper suffers from a lack of clarity, particularly regarding the dataset construction and the technical details of the baselines. For instance, the authors' claim that the models cannot perform logical reasoning is quite vague; providing concrete examples of errors would make this point more compelling. Additionally, as someone unfamiliar with ITP, I am unable to assess the value of the proposed dataset. Based on the references, it appears to be derived from a set of benchmark conjectures and proofs commonly used in the ITP community, suggesting that it may indeed be a valuable resource.
At present, my recommendation is a weak reject. However, if the authors address the concerns outlined above, I would be inclined to revise my rating to an accept.