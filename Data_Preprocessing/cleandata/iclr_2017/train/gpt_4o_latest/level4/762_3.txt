This paper is motivated by the human visual system's ability to recognize environmental content by extracting critical features and seeks to explore whether neural networks can replicate this capability. Specifically, the authors propose using an Auto-Encoder (AE) as the network to reconstruct low-fidelity visual input. Additionally, inspired by Mnih et al. (2014), the paper introduces a recurrent approach to emulate the sequential behavior of the human visual system.
Overall, I find the paper to be well-motivated. However, I have several concerns:  
1. The baselines used in the paper are too weak. Methods such as nearest neighbor, bilinear, bicubic, and cubic interpolations, which do not involve any learning process, are naturally expected to perform worse than AE-based models. The authors should compare their approach with state-of-the-art (SOTA) methods, such as...