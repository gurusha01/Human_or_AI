This work introduces a method to encode text documents and paragraphs into compact binary codes, facilitating efficient similarity search and retrieval through hashing techniques. It builds upon the real-valued paragraph vectors proposed by Le & Mikolov by incorporating a stochastic binary layer atop the neural network architecture. Two binarization strategies for the final activations are evaluated: (1) adding noise to sigmoid activations to promote discretization, and (2) employing straight-through estimation, where activations are binarized during the forward pass but remain real-valued in the backward pass. The proposed approach demonstrates promising results using straight-through estimation on the 20 Newsgroups and RCV1 datasets, achieving performance with 128-bit and 32-bit binary codes.
On the positive side, the application explored in this paper is both relevant and significant. The paper is well-written, with clear and concise exposition. However, the contribution from a machine learning perspective is somewhat incremental. The paper does not adequately discuss prior work on binary hashing beyond semantic hashing and Krizhevsky's binary autoencoders from 2011. Additionally, it omits an important baseline where real-valued paragraph vectors are first learned and then binarized using existing hashing techniques, such as random projection LSH (Charikar), BRE (Kulis & Darrell), ITQ (Gong & Lazebnik), or MLH (Norouzi & Fleet).
Given the limited novelty and the absence of this critical baseline, I cannot recommend this paper for publication in the ICLR conference proceedings in its current form. The work might be better suited for an NLP-focused conference, as its contributions are more application-oriented.
Additional comments:
- From a practical standpoint, it might be simpler to first learn real-valued paragraph vectors and then quantize them for indexing. However, the end-to-end approach proposed in this paper could potentially yield better performance. An empirical comparison between the proposed method and a simpler two-stage quantization approach would strengthen the paper.
- The authors should refer to "Estimating or Propagating Gradients Through Stochastic Neurons" by Bengio et al., which discusses straight-through estimation and alternative techniques.
- The claim that binary codes longer than 32 bits are unsuitable for document hashing is inaccurate. Multi-probe hashing methods, such as "Multi-Index Hashing" by Norouzi et al., allow the use of longer binary codes effectively.
- The authors should consult "Hashing for Similarity Search: A Survey" by Wang et al., which provides a comprehensive overview of binary hashing and quantization. The paper overlooks a substantial body of related work in this area.