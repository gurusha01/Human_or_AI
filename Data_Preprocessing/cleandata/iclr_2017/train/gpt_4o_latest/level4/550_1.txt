The paper introduces a modified DAE objective, wherein the mapped representation of the corrupted input is encouraged to align more closely with the representation of the uncorrupted input. This approach draws inspiration from both denoising autoencoders (DAE) for their stochasticity and contractive autoencoders (CAE) for their focus on representational closeness. However, the paper does not include a comparison to CAE, and the proposed method appears somewhat incremental. Similar to CAE, the method requires additional external constraints—such as tied weights, batch normalization, or other normalization techniques—to prevent the collapse of representations. While I appreciate that the authors addressed this concern by adding a paragraph discussing these constraints and their typical remedies in response to my earlier query, I believe this issue warrants a more rigorous formal analysis. Notably, these external constraints do not seem to follow naturally from the information-theoretic framework presented by the authors, which raises questions about the validity or completeness of their formal motivation. Furthermore, the role of such regularization from an information-theoretic perspective remains inadequately explained (e.g., how the strength of lambda should be interpreted).
On the experimental side, the empirical evidence supporting the proposed approach is quite limited, with only a few experiments conducted on synthetic and small-scale datasets. For MNIST, the modified DAE consistently exhibits higher test errors compared to the original DAE, except for one specific lambda setting, where the original DAE's performance still falls within the error bars of the modified DAE. Consequently, it remains unclear whether the observed improvement is statistically significant.