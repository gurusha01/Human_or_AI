The paper explores the use of various neural language models that leverage an attention mechanism to query contextual information from their recent history. The authors introduce a novel approach by separating the attended vectors into key, value, and prediction components. Their results indicate that this separation improves performance. Additionally, they observe that a simpler model, which concatenates recent activation vectors, achieves comparable performance to the more complex attention-based models.
Overall, the experimental methodology appears robust. However, I have concerns regarding the selection of vector dimensionalities within the attention mechanism. While it is commendable that the authors adjusted hidden layer sizes to maintain a consistent number of trainable parameters across models, this does not account for the possibility that higher-dimensional key/value/prediction vectors might inherently perform better, irrespective of their separation. Although this separation reduces the parameter count, it may also limit the model's ability to exploit overlaps in information, which could be beneficialâ€”e.g., vectors leading to similar predictions might also be relevant in similar contexts. Furthermore, some tasks may inherently demand more dimensions than others, and the explicit separation could constrain the model's capacity to adapt to such requirements.
While memory-augmented RNNs and attention-based RNNs are not novel concepts, some of the architectures explored in this work have not been previously applied to language modeling. Similarly, the idea of separating key and value functionalities has been proposed in other contexts but not specifically for natural language modeling. Regarding the proposed n-gram RNN, I am uncertain about its novelty, as similar architectures may exist. However, I recognize that the primary purpose of this model is not innovation but rather to serve as a baseline, demonstrating the limitations of more complex architectures. In this sense, it is a creative and valuable benchmark that could be utilized in future research to evaluate models claiming to capture long-term dependencies.
The computation of the representation \( h_t \) was initially unclear to me, as the terms "hidden" and "output" can sometimes be ambiguous. Nevertheless, the paper is generally well-written and clear.
The findings presented in this paper are significant, as they underscore that learning long-term dependencies remains an open challenge. The authors provide an excellent comparison to prior work, and the competitive performance of their n-gram RNN relative to more sophisticated models raises important questions about the extent to which these advanced methods truly capture contextual information. The success of the key/value/prediction separation in attention-based systems is also noteworthy, though further investigation with more controlled hyperparameter tuning is warranted.
---
Pros:
- Impressive and thought-provoking results.
- Strong comparison to prior work.
- The n-gram RNN serves as a compelling and inventive baseline.
Cons:
- The relationship between attention mechanism types and the number of hidden units somewhat undermines the claim that key/value/prediction separation drives performance improvements.
- Some model descriptions lack clarity.
- It would have been interesting to see the effects of applying attention to a much larger context size.