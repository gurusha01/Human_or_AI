The paper introduces a method for video sequence prediction, inspired by the work of Mathieu et al. The key contribution lies in dividing the predictor into two distinct networks, one for capturing motion and the other for content.
While the paper is engaging, its novelty is limited in comparison to the referenced work. As noted by AnonReviewer1, the approach bears resemblance to two-stream networks and a broader body of research stemming from that foundational concept. Additionally, the idea of separating motion and content has been explored in other domains, such as pose estimation.
Details:
The paper is comprehensible for readers familiar with foundational frameworks like GANs. However, its presentation lacks the clarity and accessibility needed for a wider audience.
For example, losses (7) to (9) are derived from the Mathieu et al. paper. To make the paper self-contained, these losses should be thoroughly explained, with an explicit mention that they are "additional" losses, while emphasizing that the GAN loss is the primary focus. The adversarial training aspect is not introduced in sufficient detail. Although adversarial training is now widely recognized in the community, it still warrants a proper introduction. This includes clarifying that \( L_{Disc} \) represents the loss for the discriminator network, along with an explanation of the roles of both networks.
Equation (1): The variable \( c \) is not defined (are these motion vectors?), and it is also overloaded with the feature dimension \( c' \).
Equation (3): The residual nature of the layer should be highlighted more explicitly.
The paper contains several typos and grammatical issues, such as missing articles and prepositions ("of," etc.). A thorough proofreading is necessary.
Lastly, you are training VGG-sized networks on relatively small datasets and appear to use the same architecture across all datasets. There is no mention of pre-training in the paper. Did you encounter any challenges with overfitting?