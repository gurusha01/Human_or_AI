The paper introduces a novel approach that leverages reinforcement learning (RL) to learn how to compose words in a sentence, specifically by inducing parse trees, which can be beneficial for downstream tasks. The authors adopt the shift-reduce framework and utilize RL to learn the policy governing the two primary actions: SHIFT and REDUCE. Experimental results on four datasets (SST, SICK, IMDB, and SNLI) demonstrate that the proposed method outperforms approaches relying on predefined tree structures (e.g., left-to-right, right-to-left).
The paper is well-written and has two notable strengths. First, the idea of employing RL to induce parse trees in the context of downstream tasks is both innovative and intriguing. The use of the shift-reduce framework is particularly clever, as it minimizes the action space to just two operations (shift and reduce). Second, the findings presented in the paper provide some evidence supporting the utility of parse trees, which is especially compelling given the ongoing debate about the relevance of syntax in modern NLP.
I have the following comments:
- It appears that the authors may not be aware of some recent work that also uses RL to learn structures for composition, such as Andreas et al. (2016).
- Since different composition functions (e.g., LSTM, GRU, or classical recursive neural networks) come with varying inductive biases, I am curious whether the tree structures discovered by the model are independent of the choice of composition function.
- Given that RNNs are theoretically equivalent to Turing machines, I wonder if constraining the model's expressiveness (e.g., by reducing the dimensionality) could help it focus on identifying more useful tree structures.
Reference:
Andreas et al. Learning to Compose Neural Networks for Question Answering. NAACL 2016.
Additionally, training the model was reported to be slow due to the need to construct a new computational graph for each sentence. I am curious whether this inefficiency stems from the implementation details (e.g., the use of TensorFlow or Python). Since Dynet is specifically designed for such dynamic computation graph scenarios, did the authors consider using it?