1029 tic-tac-toe boards are presented in various configurations. These boards represent all legal states where the next valid move could result in a game-ending play. The authors categorize these boards into 18 distinct classes: 9 corresponding to the possible locations of the next move, and 2 representing the color of the next player. The supervision provided to the model essentially conveys statements like, "If a black square is placed in the middle-right, black will win," or "If a white square is placed in the upper-left, white will win." A convolutional neural network (CNN) is trained to classify these 18 categories, achieving 100% accuracy.
The primary focus of the paper is the application of Zhou et al.'s Class Activation Mapping (CAM) to analyze the regions of the board the CNN attends to when making its predictions. As I understand it, CAM requires the class of interest as input. For instance, consider class 1 (black wins with a move to the bottom-right square, based on my interpretation of Figure 2â€”though the figure could benefit from clearer labeling of the classes). CAM is then used to identify the areas of the board the CNN focuses on to determine whether class 1 applies. Unsurprisingly, the attention is centered on the empty bottom-right square, as class 1 cannot manifest if that square is already occupied. Additionally, the CNN must condition its decision on other parts of the board to verify whether a winning line of three can be formed. However, it is unclear whether this conditioning is as strong as it could be.
While this analysis is somewhat interesting, I remain unconvinced by the broader claims the paper hints at regarding the discovery of game rules. Furthermore, the connection between this work and concepts like weakly supervised learning or multi-modal learning is not entirely clear to me.
Overall, the paper is reasonably well-written, albeit with some grammatical errors. However, I find the novelty of the work underwhelming and fail to see any particularly surprising insights. 
I am also concerned about the contrived nature of the experimental setup. The use of a large, expressive CNN for such a simple game domain, coupled with the application of a specific CNN visualization technique, feels somewhat artificial.
Finally, I should note that I am not an expert in reinforcement learning (which is not directly addressed in this paper but is relevant to related works on CNN-based game playing). It is possible that I am not fully appreciating the contributions of this work.