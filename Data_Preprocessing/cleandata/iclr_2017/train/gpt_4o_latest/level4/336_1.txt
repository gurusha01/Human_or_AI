Apologies for the delayed submission of this review, and thank you to the authors for addressing the earlier questions.
This paper introduces an enhanced implementation of the PixelCNN generative model. While most of the proposed improvements are relatively minor technical adjustments, such as the incorporation of dropout and skip connections, there are a few more notable changes, including the adoption of a different likelihood model and the use of multiscale analysis. The paper reports state-of-the-art likelihood results on CIFAR-10.
Summary of the main contribution:
Autoregressive models, such as PixelCNN, are an appealing class of generative models due to their ability to compute likelihoods in closed form. A key distinguishing factor for these models lies in how they represent the conditional likelihood of a pixel given its causal neighborhood:
- Earlier approaches, such as (Theis et al., 2012 MCGSM; Theis et al., 2015 Spatial LSTM), model the conditional distribution as a continuous density over real numbers. However, this has limitations: real-world pixel intensities are quantized into discrete integer values, so a discrete distribution could yield better likelihoods. Moreover, continuous distributions often assign probability mass outside the valid range of pixel intensities, which can negatively impact the likelihood.
- More recent work by van den Oord and colleagues models the conditional likelihood as an arbitrary discrete distribution over the 256 possible pixel intensity values. While this avoids the limitations of continuous likelihoods, it can be inefficient and less data-efficient.
The authors propose a middle-ground approach: they retain the discrete nature of the conditional likelihood but constrain the discrete distribution to those whose CDFs can be expressed as a linear combination of sigmoids. This method seems reasonable and somewhat novel, but it does not strike me as particularly groundbreaking or transformative.
The second moderately significant modification involves the use of downsampling and multiscale modeling (as opposed to dilated convolutions). The authors justify this choice as a way to reduce computational costs while preserving the multiscale flexibility of the model. They also introduce shortcut connections to mitigate potential information loss during downsampling. However, I find this modification to be relatively incremental as well. Multiscale image analysis with autoregressive generative models has been explored in prior work, such as (Theis et al., 2012), among others.
In conclusion, I feel that this paper lacks substantially novel contributions and reads more like a detailed account of a specific implementation of existing ideas.