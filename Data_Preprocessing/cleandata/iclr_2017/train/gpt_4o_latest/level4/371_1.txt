Review - Summary  
This paper introduces the Neural Physics Engine (NPE), a neural network architecture designed to simulate interactions between objects. Unlike approaches that rely on video frames, NPE explicitly represents objects but incorporates knowledge of physics primarily through training data. The method is evaluated in a simplified domain involving 2D bouncing balls.  
The proposed architecture processes each object in the scene individually. Object pairs are embedded into a shared space to capture their mutual effects. These pairwise embeddings are summed and combined with the state of the focus object to predict changes in its velocity. The paper also presents alternative baselines, which either replace the pairwise embedding with a single-object embedding or encode the focus object's neighbors sequentially using LSTM states.  
NPE significantly outperforms these baselines, highlighting the importance of the architectural design in learning object-based simulations. The model is rigorously evaluated in several ways: its ability to predict object trajectories over extended time horizons, its generalization to scenes with varying numbers of objects, its adaptability to slightly modified environments (e.g., walls of different shapes), and its performance in predicting object mass solely from interactions with other objects. In all cases, NPE demonstrates superior performance compared to the baselines.  
Comments  
- I have one clarification question regarding Figure 3 (b)/(c). Are the inputs to the blue box the concatenation of the summed embeddings and the state vector of object 3? Or is the input to the blue module constructed differently from these two vectors?  
- Section 2.1 begins with the statement: "First, because physics does not change across inertial frames, it suffices to separately predict the future state of each object conditioned on the past states of itself and the other objects in its neighborhood, similar to Fragkiadaki et al. (2015)."  
  I interpret this as an argument for using an object-centric representation instead of the visual representation employed in prior work. This distinction would be clearer if the authors explicitly contrasted their approach with visual representations.  
- While the paper acknowledges its novelty, it is worth noting that the concurrent work by Battaglia et al. (NIPS 2016), titled "Interaction Networks for Learning about Objects, Relations and Physics," shares the concept of using object-based representations to predict physical interactions. Although the architectures and experiments differ, and the presentation in Battaglia et al. is particularly strong, the overlap in the core idea should be acknowledged.  
Overall Evaluation  
This paper was a pleasure to read, offering a wealth of experiments that lead to clear and compelling conclusions. It presents a novel approach (albeit less so in light of the concurrent work by Battaglia et al., 2016) that marks a significant advancement in the study of intuitive physics.