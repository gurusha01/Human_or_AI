First, I would like to highlight that this paper is excessively lengthy, spanning 17 pages without any supplementary material. While ICLR does not impose a strict page limit, it would be considerate for authors to empathize with reviewers and avoid exploiting this flexibility. Adding 1 or 2 pages beyond the standard 8-page guideline is reasonable, but more than doubling the length feels unjustifiable.
Now, onto the review: This paper introduces a novel artificial dataset for sequence learning. I refer to it as artificial because it is synthetically derived from the original MNIST dataset, which consists of real images of handwritten digits. Alongside the dataset, the authors propose training recurrent networks using a sequence-length schedule, which they term "incremental learning." Their experiments demonstrate that the proposed schedule outperforms training without any schedule on this dataset. Additionally, they show that their schedule surpasses a few other intuitive scheduling strategies. The authors substantiate these claims through ablation studies conducted on their proposed dataset.
I have the following concerns about this paper:
-- The paper lacks novelty. The proposed incremental learning schedule is not a new concept and seems like a natural approach for sequence learning. Similar ideas have already been explored by several authors, including Bengio (2015) and Ranzato (2015). The only truly original contribution appears to be the ablation studies, which aim to isolate and confirm that the observed performance improvement stems from the curriculum used.
-- The authors evaluate their approach solely on the artificially generated dataset they propose. Why not test it on a real-world sequential dataset, such as one used for language modeling? Does the method fail to generalize in such scenarios? I strongly suspect that in tasks like language modeling, where the vocabulary size is substantial, the performance improvements would fall far short of the 74% reported in this paper.
-- I am not convinced of the value of introducing this artificial dataset. There are already numerous real-world sequential datasets available across domains like text, speech, and finance. The unique contribution of this dataset is unclear. While creating an additional dataset is not inherently problematic, it feels as though this dataset was specifically designed to showcase the proposed ideas. The paper would have been much stronger had the authors demonstrated results on other, more established datasets.
-- As mentioned earlier, the paper is excessively long. Much of this length is due to experiments that are tangential or unrelated to the core message of the paper. For example, the experiment in Section 6.2 does not align with the main narrative, and the transfer learning experiments in Section 6.4 similarly feel disconnected from the central theme.