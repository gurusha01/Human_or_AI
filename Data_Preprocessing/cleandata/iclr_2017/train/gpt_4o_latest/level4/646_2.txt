This paper presents:
1. A two-stage encoding mechanism for stories in bAbI-like setups, where a GRU encodes sentences word by word, conditioned on a sentence-level GRU that maintains a representation of the sentence-level encoding. Both components are utilized.
2. A modification of the bAbI tasks, making it necessary to ask a question to correctly solve the problem.
However, I remain unconvinced by the results presented in the paper:
1. The proposed architecture does not demonstrate a significant improvement over DMN+, and it appears to be conceptually similar to DMN+. What specific shortcomings of DMN+ does this architecture address?
2. There are already multiple papers addressing the second contribution, such as "Dialog-based Language Learning" by Weston and "Learning End-to-End Goal-Oriented Dialog" by Bordes and Weston, which, in my opinion, approach the problem more rigorously and compellingly. In this work, the correct answer to the question seems to be provided regardless of what the agent asks, giving an advantage to any model capable of outputting "unknown" and then incorporating the additional response. Essentially, most architectures designed for solving bAbI tasks can be adapted to perform this. In fact, the encoder-decoder accuracies reported in Appendix A suggest that this type of module can be appended to any existing model. Standard models can be trained to generate questions as a sequence of words. Moreover, I suspect that in the authors' setup, questions could simply be generated by enumerating all possible questions from the training data and applying a softmax over them, rather than generating them word by word.