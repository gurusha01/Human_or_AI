This paper seeks to deliver an insightful and analytical survey of recent literature on reading comprehension, with the specific aim of examining whether logical structure (or "predication," as the authors have rephrased in their response) emerges in many contemporary models. I greatly appreciate the intent of the paper and commend the authors for their efforts to organize the somewhat disordered recent literature into two cohesive themes: "aggregation readers" and "explicit reference models." The overall quality of the writing is excellent, and I found section 3 particularly engaging. Additionally, I am satisfied with the proposed rewording from "logical structure" to "predication," and the authors' detailed clarifications were both thoughtful and helpful.
That said, I remain somewhat ambivalent about the overall contribution of the work. First, I question whether the choice of dataset was optimal for achieving the paper's stated objectives. The CNN/DailyMail dataset (Chen et al., ACL'16) has been critiqued in prior work, and I am uncertain whether it is well-suited to support an investigation into the logical structure of meaningful kinds. It seems plausible that the dataset may inherently highlight the absence of logical structure rather than its presence.
Second, I would have liked to see the discussion on predication offer more actionable insights into dataset or model design to better address challenges in reading comprehension. In this regard, a more precise analysis of the different types of reading comprehension challenges, the specific logical structures missing in various existing models and datasets, and concrete recommendations for future research directions would have been particularly valuable for guiding the community's efforts.