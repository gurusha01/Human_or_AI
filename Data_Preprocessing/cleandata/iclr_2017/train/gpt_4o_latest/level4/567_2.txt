This paper introduces a multi-view learning algorithm that linearly projects inputs from different views such that the neighborhood relationships (transition probabilities) are consistent across views.
The paper is well-motivated, aiming to explore multi-view learning from an information retrieval perspective. However, there are some concerns:  
-- The algorithm, in its current form, has high time complexity (as noted in the last paragraph of page 4). This could explain why the experiments are limited to small datasets and employ linear projections.  
-- The proposed method offers some appealing features, such as not requiring projections to have the same dimensionality across views (a property I appreciate). While it models neighborhood relationships more directly than CCA-based approaches, it does not explicitly optimize retrieval-specific criteria, such as ranking-based objectives. In contrast, the contrastive loss approach in Hermann and Blunsom's "Multilingual Distributed Representations without Word Alignment" (ICLR 2014) is a relevant information retrieval method that should be discussed and compared with in this context.
My primary concern with this paper lies in the experimental evaluation. As noted in my earlier comments, there are limited scenarios where linear mappings are preferable to nonlinear mappings for dimensionality reduction. Although the authors argue that linear projections may offer better interpretability, this claim lacks empirical support in the paper. Furthermore, interpretability can also be achieved by visualizing the projections to examine how variations in the input are captured along specific dimensionsâ€”a common practice in nonlinear dimensionality reduction methods.
While the general approach proposed in this paper can be extended to nonlinear projections, the absence of experiments involving nonlinear projections and comparisons with nonlinear variants of CCA or other multi-view learning algorithms significantly limits the impact and significance of the current work.