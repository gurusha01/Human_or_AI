Considering the loss in the binarization step through a proximal Newton algorithm is an interesting approach. It represents at least one method to account for the missing loss during binarization, transitioning from the traditional two-step process of training and binarizing to a unified, simultaneous train-and-compress framework. The performance improvements demonstrated on a few small tasks highlight the potential benefits. However, it would be valuable to include results on larger networks and tasks that genuinely require compression for deployment on embedded systems (as mentioned in the introduction). Regarding the discussion of exploding/vanishing gradients, is it necessary in the context of RNN experiments conducted with LSTMs, where the cell error carousel inherently addresses these issues? While the connection to proposition 2 is noted, it is unclear whether the observed degradation in binary connect is directly related. Additionally, Adam is employed for LSTM optimizationâ€”was gradient clipping truly required, or could the degradation in binary connect be attributed to capacity limitations instead? For proposition 3.1, theorem 3.1, and proposition 3.2, please provide clear references to the proofs in the appendix.