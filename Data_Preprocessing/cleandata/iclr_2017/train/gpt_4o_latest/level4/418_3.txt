The paper presents a method for stabilizing the training process of Generative Adversarial Networks by unrolling the inner (discriminator) optimization within the GAN loss function for several steps and then optimizing the generator based on the final state of this unrolled optimization.  
The experimental results provide strong evidence supporting the effectiveness of this approach: the 2D example demonstrates a toy problem where the technique offers significant improvements, the LSTM MNIST generator example illustrates how the method aids in stabilizing the training of an unconventional generator architecture, and the image generation experiment, while not entirely conclusive, is highly persuasive.  
For future research, it would be valuable to explore whether a similar approach could be developed with reduced memory requirements.  
I highly recommend accepting this paper.