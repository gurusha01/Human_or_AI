The paper under review introduces a novel approach to learning sequence predictors. Following the principles of incremental learning and curriculum learning, the method initially trains on simpler samples and progressively increases complexity. The key distinction in this work lies in defining complexity based on the length of training sequences, with the underlying assumption being that longer sequences are more challenging to learn due to the need for more sophisticated internal representations.
The proposed method is applied to sequence prediction from primed prefixes, evaluated on a single dataset that the authors derive themselves from MNIST.
The concept presented in the paper is intriguing and merits attention. The evaluation section also includes several noteworthy aspects, particularly the ablation studies conducted by the authors to eliminate potential side effects in their tests. Additionally, the proposed learning strategy is compared against alternative strategies.
That said, the primary concern remains the evaluation. The method is tested on a single, non-standard dataset derived from MNIST. Given the broad claims made in the paper, it is essential to validate the proposed algorithm on other datasets, preferably publicly available ones, and in the context of different applications to substantiate its generalizability.
The paper is overly lengthy and would benefit from significant trimming.
The transfer learning component (from prediction to classification) appears tangential and lacks a clear connection to the paper's main contribution.
The presentation and organization of the paper require improvement. The writing is fairly sequential and, at times, resembles a student report, which detracts from its readability.
The loss function presented in the long, unnumbered equation on page 6 needs better clarification. Each term should be explained in detail, and the meanings of the various symbols should be explicitly defined. Since the learning process is supervised, it is important to clearly distinguish between the variables representing predictions and those corresponding to ground truth observations from the data.
Additionally, the names in Table 2 do not align with the descriptions provided in Section 4.
Regarding the statement "Best value for the average over 10 runs," further clarification is needed. What exactly was calculated here?