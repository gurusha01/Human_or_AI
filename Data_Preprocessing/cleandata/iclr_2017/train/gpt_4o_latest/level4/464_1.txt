I don't have much to add beyond my initial pre-review comments.  
This is a well-written paper presenting an intriguing idea. Combining reinforcement learning (RL) with natural language processing (NLP) is currently a very popular research direction. However, no one has yet managed to achieve truly groundbreaking or influential results that demonstrate superior performance on highly relevant or competitive NLP tasks.  
A major challenge lies in the fact that NLP typically requires highly efficient methods capable of handling very large datasets, while RL tends to be extremely slow. As a result, this research direction has yet to show significant promise, and it remains uncertain whether it ever will, given RL's inherent inefficiencies.  
That said, it is important to explore diverse approaches, as they may eventually lead to meaningful advancements.  
The paper's attempt to uncover the inherent grammatical structure of language is interesting, although the proposed trees still fall short of aligning with many of our linguistic intuitions.  
Overall, this is an intriguing exploration and deserves to be discussed at the conference.