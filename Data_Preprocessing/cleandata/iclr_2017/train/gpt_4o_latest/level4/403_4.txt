Paper Summary 
This paper formalizes the essential properties required for addressing (indexing) in memory-augmented neural networks and explores how these addressing mechanisms integrate with read/write operations. It further introduces a framework that allows any Lie group to serve as the addressing space. Experimental results on algorithmic tasks are presented.
 Review Summary 
This paper provides a unified and formal perspective on the requirements for memory addressing in differentiable memory systems. Its proposed framework offers a generalizable method for constructing addressing mechanisms. However, in comparison to key-value networks, the unbounded nature of memory cells and the absence of incentives for index reuse could pose practical challenges.
 Detailed Review 
The paper is well-written and demonstrates strong relevance to prior work in the field. Its unified treatment of memory-augmented networks is clear and contributes coherence to the area. The proposed method is presented effectively, showcasing its potential as a reusable tool for future research. However, the issue of unbounded memory growth is not adequately addressed. This limitation should be explicitly acknowledged, and a discussion on its implications for efficiency and scalability is necessary.