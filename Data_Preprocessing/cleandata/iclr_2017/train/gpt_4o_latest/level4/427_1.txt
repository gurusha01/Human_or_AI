The paper introduces a theoretically well-founded approach for visualizing which parts of the input feature map contribute most significantly to the output decision. The central idea is that features which both induce the largest changes in the output and are less predictable from other features are the most critical. In contrast, much of the prior work has focused solely on identifying features that maximally influence the output, without considering their predictability from other features. The authors extend the concepts introduced in the work of Robnik-Å ikonja & Kononenko (2008).
The results demonstrate that the proposed visualization mechanism, which leverages modeling of the conditional distribution, identifies more salient regions compared to a mechanism based on modeling the marginal distribution. I appreciate that the authors have provided visualization results for a single image across multiple networks and multiple classes. These results convincingly show that the proposed method captures class-discriminative features effectively. Additionally, the authors have shared a link to visualizations for a random sample of images in a comment, and I strongly encourage them to include this material in the appendix of the paper.
However, I have one concern with the paper. Zeiler et al. proposed a visualization technique that involves greying out small square regions of the image, which is conceptually similar to computing visualizations using the marginal distribution. In this work, the authors compute the marginal visualizations using 10 samples, but in the limit of infinite samples, the image region would effectively become gray. On the other hand, the conditional distribution is modeled using a normal distribution, which introduces some regularization. As a result, estimating both the conditional and marginal distributions using only 10 samples each may not be entirely justified. I would like to see a comparison of the proposed approach based on the conditional distribution against a visualization method that uses grey image patches, similar to Zeiler et al.'s approach.