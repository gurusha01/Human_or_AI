This paper extends a previously proposed approach for rate-distortion optimization to incorporate deep encoders and decoders, as well as transitioning from a basic entropy encoding scheme to an adaptive entropy coding framework. Additionally, the paper explores the connection between this approach and variational autoencoders.
While the approach to rate-distortion optimization has been published before, the novelty of this submission appears to be somewhat limited (please correct me if I have overlooked any new contributions). In certain respects, this work could be seen as a step backward, as prior research optimized for a perceptual metric, whereas this paper focuses on MSE. That said, the results demonstrate a clear improvement over JPEG 2000, and to my knowledge, no other learned encoding method has achieved this level of performance. Furthermore, the paper is exceptionally well written.
It seems that Equation 10 contains an error, as the partition function should likely depend on g_s(y; theta). If this is the case, the approach would not be equivalent to a VAE when applied to non-Euclidean metrics.
Why was MSE chosen as the optimization target instead of a perceptual metric, as in prior work? Given the authors' expertise, it is surprising that the evaluation was conducted solely in terms of PSNR.
What is the specific contribution of adaptive entropy coding compared to the impact of deeper encoders and decoders? This distinction seems critical, and it would be helpful to see performance results without adaptation, as in the earlier paper. Providing more details on the adaptive coder and its influence would strengthen the submission, and I would be inclined to assign a higher score if the authors address this.