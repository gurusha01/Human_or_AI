This paper presents a meticulous experimental investigation on the CIFAR-10 task, employing data augmentation and Bayesian hyperparameter optimization to train a substantial number of high-quality deep convolutional network classification models using hard (0-1) targets. An ensemble comprising the 16 top-performing models is subsequently utilized as a teacher model within the distillation framework, where student models are trained to replicate the averaged logits produced by the teacher ensemble. Data augmentation and Bayesian hyperparameter optimization are also applied during the training of the student models. Both non-convolutional (MLP) and convolutional student models with varying depths and parameter counts are explored. Additionally, convolutional models with identical architectures and parameter counts as some of the convolutional students are trained using hard targets and cross-entropy loss. The experimental findings reveal that convolutional students with only one or two convolutional layers fail to achieve the performance of students with more convolutional layers, under the constraint that all students maintain the same number of parameters.
Pros  
+ This study is exceptionally thorough and well-constructed, leveraging state-of-the-art tools to address the question of whether deep convolutional models require both depth and convolution.  
+ It builds effectively on the foundational results of Ba & Caruana, 2014.  
Cons  
- As the authors acknowledge, proving a negative is inherently challenging. Nevertheless, this study is as compelling as possible within the current theoretical and practical landscape of deep learning.  
Suggestions for Improvement  
- Section 2.2 should clarify that the logits are unnormalized log-probabilities (i.e., they exclude the log partition function).  
- The paper does not adhere to the ICLR citation style. Per the template: "When the authors or the publication are included in the sentence, the citation should not be in parenthesis (e.g., 'See Hinton et al. (2006) for more information.'). Otherwise, the citation should be in parenthesis (e.g., 'Deep learning shows promise to make progress towards AI (Bengio & LeCun, 2007).')."  
- Minor issues with English usage and typographical errors should be addressed in the final version of the manuscript.  
Specific Corrections  
- "necessary when training student models with more than 1 convolutional layers" → "necessary when training student models with more than 1 convolutional layer"  
- "remaining 10,000 images as validation set" → "remaining 10,000 images as the validation set"  
- "evaluate the ensemble's predictions (logits) on these samples, and save all data" → "evaluated the ensemble's predictions (logits) on these samples, and saved all data"  
- "more detail about hyperparamter optimization" → "more detail about hyperparameter optimization"  
- "We trained 129 deep CNN models with spearmint" → "We trained 129 deep CNN models with Spearmint"  
- "The best model obtained an accuracy of 92.78%, the fifth best achieved 92.67%." → "The best model obtained an accuracy of 92.78%; the fifth best achieved 92.67%."  
- "the sizes and architectures of three best models" → "the sizes and architectures of the three best models"  
- "clearly suggests that convolutional is critical" → "clearly suggests that convolution is critical"  
- "similarly from the hyperparameter-opimizer's point of view" → "similarly from the hyperparameter-optimizer's point of view"