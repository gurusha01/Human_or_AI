The paper presents an interesting framework that utilizes Tucker and Tensor Train low-rank tensor factorization to enable parameter sharing in multi-task learning.
The proposed framework is both innovative and compelling.
That said, multi-task learning (MTL) is a well-explored area, and the paper focuses on relatively simple classification tasks. It remains unclear whether "Deep Learning" is truly necessary for these straightforward datasets. A comparison with existing shallow MTL approaches is essential to demonstrate the advantages of the proposed methods (particularly the benefits of being deep) on the given datasets. The authors dismiss such comparisons based on speculation, leaving it uncertain whether the proposed framework genuinely outperforms simpler regularization techniques, such as the nuclear norm. Moreover, the concept of nuclear norm regularization could also be extended to deep learning, as gradient descent methods are widely applicable across various approaches.