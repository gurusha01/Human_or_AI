The authors propose a method for sampling from VAEs using a Markov chain defined as [zt ~ q(z|x=x{t-1}), xt ~ p(x|z=zt)]. While the idea has potential, the paper suffers from unclear notation, overstates its novelty, and overlooks some key prior work. Additionally, the qualitative distinction between standard sampling and the proposed Gibbs chain is not particularly compelling based on the provided figures. With improvements to the notation, a more thorough discussion of related work, and stronger experimental results (e.g., higher-quality or upscaled figures), this could be a strong workshop paper, or potentially more.
Comments:
- The Markov chain approach is already discussed in Rezende et al.'s (2014) original VAE paper, which the authors fail to acknowledge.
- The notation is unconventional and confusing. For instance, on page 1, the statement "p(x|z) which is approximated as q(x|z)" is unclear and requires clarification.
- The definition of q(z) is ambiguous. On page 2, q(z) is referred to as the learned distribution, but p(z) can also be a learned distribution in general, which is not addressed.
- The claim that it is impossible to sample from q(z) is incorrect. One can sample x ~ q(x) from the dataset and subsequently draw z ~ q(z|x).
- The paper does not specify whether the proposed analysis applies exclusively to continuous observed spaces or if it extends to discrete observed spaces as well.
- Figures 3 and 4 fail to convincingly demonstrate the advantages of the proposed method.