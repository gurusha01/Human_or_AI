Authors explore the use of pretrained CNNs for image retrieval and conduct a comprehensive evaluation of the impact of various parameters. For detailed feedback, please refer to my earlier questions. Below is a summary of my review:
The contributions of this paper appear limited, as it primarily consolidates existing practices and performs additional parameter tuning. Key findings, such as using the last convolutional layer, applying PCA with whitening, and processing images at their original sizes, are well-established in prior works. While the authors argue that Tolias et al. resized images, this was done due to practical constraints, and their approach similarly uses the largest feasible image sizes. Essentially, the paper combines known techniques and fine-tunes parameters to achieve state-of-the-art results, but some of this tuning is conducted on the test set, which raises concerns.
The claim of achieving state-of-the-art performance is somewhat misleading, as it is largely attributed to the use of the deeper VGG-19 network rather than novel methodological insights. 
Additionally, the paper's scope is limited to VGG-19, making it difficult to generalize the conclusions to other architectures such as ResNet or Inception. The authors do not address whether their findings hold for these networks, nor do they provide guidance on how to adapt their conclusions for them. Parameter tuning was conducted on the Oxford dataset, leaving open the question of how results might differ if tuning were performed on other datasets like UKB. A more accurate title for the paper would be "Optimal Parameter Settings for VGG-19 on Oxford/Paris Benchmarks," which underscores the limited novelty and relevance of the work for the broader community.
I agree with other reviewers regarding the lack of comparison with Gordo et al. and Radenovic et al., even though the authors justify this by stating they do not train their networks. However, this rationale is inconsistent, as comparisons with Arandjelovic et al., who also train networks, are included. These works should at least be cited and discussed. Furthermore, while the authors claim not to perform training, their extensive parameter grid search on the test set could be considered a form of implicit training.
In terms of insights, the paper offers little that is genuinely new. The use of the last convolutional layer, original image sizes, and PCA with whitening are all well-documented in prior works (e.g., Arandjelovic et al., Tolias et al., Gordo et al., Radenovic et al., Babenko and Lempitsky). The only relatively novel contributions are the exploration of multi-scale pooling and the comparison of max/sum pooling with l1/l2 normalization. However, even these experiments are not thoroughly analyzed; for instance, while sum-l1 pooling performs best in Table 1, the authors later favor max-l2 pooling for multi-scale settings without adequate justification. The most intriguing and genuinely novel aspect of the paper is Figure 3, which provides insights not previously documented.
The title's claim of presenting "best practices for CNNs" is an overreach, as the paper focuses exclusively on VGG-19. It remains unclear whether the conclusions would hold for other architectures like ResNet or Inception, which have different design principles (e.g., sum pooling during training). This work is better described as an in-depth analysis of VGG-19 rather than a general guide to best practices for CNNs in image retrieval.
On a broader level, this paper raises philosophical questions about the direction of research in this field. The conference focuses on learning representations, yet this work involves no learning. Instead, it treats CNNs as black boxes, tweaking inputs and outputs in a manner reminiscent of hand-engineered features like SIFT. While such studies can be useful, the field has seen numerous similar papers, and it is time to move beyond this approach. Future work should focus on:
a) Moving past treating CNNs as black boxes.
b) Incorporating training into the pipeline, such as end-to-end optimization of the entire system.
c) Designing architectures specifically tailored for image retrieval, which may differ from classification-focused CNNs.
d) Developing novel training methodologies for retrieval tasks, potentially addressing issues like the reliance on large-scale labeled datasets (as partially explored by Arandjelovic et al., Gordo et al., and Radenovic et al.).
Minor comments:
- I share Reviewer 3's skepticism regarding the "harder than category retrieval" statement. The two tasks are fundamentally different and not directly comparable.
- There are inconsistencies in the references (e.g., "Y. Lecun" vs. "Ross Girshick," "CVPR" vs. "Computer Vision and Pattern Recognition"). Please ensure uniformity in formatting.