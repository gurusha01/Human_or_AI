This paper introduces a novel memory module designed for large-scale life-long and one-shot learning. The proposed module is sufficiently general, allowing the authors to integrate it into multiple neural network architectures and demonstrate performance enhancements.
While the use of k-nearest neighbors for memory access is not entirely new, as it has been explored in works such as Rae et al., 2016 and Chandar et al., 2016, as well as in [R1] for one-shot learning, this paper contributes by providing experimental evidence that this approach can be effectively applied across diverse architectures.
The authors have satisfactorily addressed all of my pre-review questions, and I am satisfied with their responses.
Would the authors be open to releasing the source code to facilitate reproducibility of their results, particularly for the Omniglot experiments and synthetic task experiments?
References:
[R1] Charles Blundell, Benigno Uria, Alexander Pritzel, Yazhe Li, Avraham Ruderman, Joel Z. Leibo, Jack Rae, Daan Wierstra, Demis Hassabis: Model-Free Episodic Control. CoRR abs/1606.04460 (2016)