This paper introduces a novel generative model that leverages real-valued non-volume preserving (Real NVP) transformations to enable efficient and exact inference as well as sampling of data points. 
The authors employ the change-of-variable technique to derive a model distribution for the data, starting from a simple prior distribution defined on a latent variable. By meticulously designing the bijective function used in this technique, they ensure that the resulting Jacobian matrix is triangular, facilitating efficient computation.
Generative models with both tractable inference and efficient sampling remain an active area of research, and this work makes a meaningful contribution to the field.
Although the proposed method does not achieve state-of-the-art performance, it comes close. This does not detract from the fact that the approach is innovative and holds promise, as it aims to bridge the gap between auto-regressive models, variational autoencoders, and generative adversarial networks.
The authors explicitly highlight the differences and similarities between their method and other prominent generative models under active investigation. 
- Compared to autoregressive models, the proposed method provides faster sampling.
- Compared to generative adversarial networks, Real NVP enables tractable log-likelihood evaluation.
- Compared to variational autoencoders, the inference process is exact.
- Compared to deep Boltzmann machines, the learning process is tractable.  
It is evident that the goal of Real NVP is to serve as a unifying framework that bridges the strengths of existing generative models.
The paper includes a variety of compelling experiments that demonstrate the potential of the proposed technique. Making the implementation publicly available would further benefit the research community. Do the authors plan to release the code?
Typo: (Section 3.7) "use apply" should be corrected to either "use" or "apply" batch normalization.