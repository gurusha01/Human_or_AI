The authors explore a straightforward optimization approach that involves introducing gradient noise according to a predefined schedule. They evaluate their method on several recently proposed neural network architectures designed for simulating computer logic, including end-to-end memory networks, neural programmers, and neural random access machines.
In these architectures, the topic of optimization has not been as thoroughly investigated as it has been for more conventional networks. As such, a study tailored to this class of models is a valuable contribution. The results consistently demonstrate improved optimization performance when noise is incorporated into the training process.
However, one concern with the paper is that it remains unclear whether the proposed optimization method enables the learning of genuinely effective models or merely models that outperform those trained without noise. A comparison with results reported in the existing literature would strengthen the analysis.
For instance, in the MNIST experiments presented in Section 4.1, the optimization method achieves an average accuracy of approximately 92% in the most favorable scenario. This performance is still insufficient to indicate the learning of a meaningful problem representation, as a linear model would likely achieve similar accuracy. While I acknowledge that the architecture is intentionally designed to be challenging to optimize (20 layers with 50 hidden units each), it would have been more compelling to examine a scenario where increased depth provides a tangible advantage in solving the problem.