This paper introduces a novel approach for compressing CNN weights, specifically employing a new neural network quantization technique that reduces network weights to ternary values.  
The authors have recently published several papers on this topic, and this work appears to provide the least significant improvements among them, achieving only marginal gains (a fraction of a percentage) on ImageNet. Furthermore, results on AlexNet hold limited relevance at this point, especially since the group has already demonstrated that older architectures of this kind can be significantly compressed.  
Additionally, I would have appreciated the release of the compression code and a detailed report on the computational effort involved in the compression process, including metrics such as FLOPs, runtime, number of passes, and the need for the original dataset. Such information is crucial for assessing whether the proposed compression method justifies the required effort.