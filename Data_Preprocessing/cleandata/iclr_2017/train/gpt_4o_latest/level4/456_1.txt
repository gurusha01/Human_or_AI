The paper presents a novel regularization technique for training neural networks to learn domain-invariant representations. This regularization focuses on aligning the higher-order central moments of the hidden activations between the source and target domains. The authors benchmarked their proposed method against MMD and two state-of-the-art neural network-based domain adaptation approaches on the Amazon review and Office datasets, demonstrating comparable performance.
The proposed approach is simple and intuitive, and the empirical results indicate that it is quite effective. However, the primary limitation of the method lies in its assumption that the hidden activations are independently distributed. This assumption is clearly violated in scenarios such as convolutional layers, where neighboring activations exhibit dependencies. This likely explains why the authors begin adaptation at the dense layers for the image dataset. Do the authors have any insights into whether it would be advantageous to initiate adaptation at earlier layers? Additionally, do they have suggestions on how to relax this independence assumption? In such cases, does MMD hold an advantage since it does not rely on this assumption?
Figure 3 does not appear to strongly support the performance gains reported in Table 2. The only class where the proposed regularization seems to bring the source and target domains closer is the mouse class, as highlighted by the authors. Is the observed performance improvement primarily driven by this single class?