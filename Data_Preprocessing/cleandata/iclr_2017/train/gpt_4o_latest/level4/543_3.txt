This paper introduces a JavaScript framework incorporating WebCL components for training and deploying deep neural networks. The authors demonstrate that this approach can achieve competitive performance, even surpassing the speed of a compiled application using ViennaCL on AMD GPUs. Although it remains approximately three times slower than compiled high-performance software on NVIDIA GPUs, the framework provides compelling opportunities for easily deployable training and application scenarios in deep learning.
My primary criticisms are as follows:  
1. In Table 4, different batch sizes are employed. Even if this is due to technical limitations of the JavaScript library, it would be more equitable to use the smaller batch sizes for the other frameworks as well (likely favoring the presented framework on GPUs).  
2. In Figure 6, why not include additional information in the graphs? Specifically, as mentioned in the question, why are the node.js values omitted? While I understand the potential use case of one server with many "low-performance" clients, the scenario of having a few dedicated high-performance servers is also quite plausible. Even if this is not the primary focus, these values would provide a meaningful comparison. For consistency, please include Firefox, Chrome, and node.js in both subfigures.  
Aside from these points, the paper is well-written, clear, and conclusive.