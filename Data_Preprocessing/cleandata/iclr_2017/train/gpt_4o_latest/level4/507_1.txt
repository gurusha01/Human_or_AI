This paper presents a novel dataset designed to evaluate word representations. The task explored in the paper, referred to as outlier detection (also known as word intrusion), involves identifying the word that does not fit within a group of semantically related words. Originally proposed by Camacho-Collados & Navigli (2016) as a method for assessing word representations, this task serves as the foundation for the paper's primary contribution: the introduction of a new dataset spanning five languages. The dataset is automatically generated using the Wikidata hierarchy, where entities classified under the same category are grouped into clusters, and outliers are sampled at varying distances within the hierarchy. Additionally, several heuristics are employed to filter out uninformative clusters from the dataset.
Developing robust resources for evaluating word representations is a critical endeavor. The dataset introduced in this paper could potentially complement existing resources, though it is difficult to fully assess its value based solely on the paper. One concern is the limited discussion and comparison with existing evaluation methods (beyond word similarity datasets). Specifically, it would be valuable to elaborate on the advantages of this dataset compared to established benchmarks, such as word analogy tasks. Furthermore, the proposed evaluation appears closely related to entity typing, a connection that is not addressed in the paper.
In summary, while creating resources to evaluate word representations is undoubtedly important for the research community, I have mixed feelings about this submission. I am not entirely persuaded that the proposed dataset offers significant advantages over existing resources. Moreover, it seems that tasks like entity typing already capture similar aspects of word representations. Lastly, the paper might be better suited for submission to LREC rather than ICLR.