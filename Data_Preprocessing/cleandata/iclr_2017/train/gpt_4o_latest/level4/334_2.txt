The paper introduces an extension to the existing visual attention model by incorporating a deformable sampling lattice. In contrast to the fixed sampling lattice used in prior works, the proposed approach demonstrates that different sampling strategies can emerge depending on the specific visual classification tasks. The authors provide empirical evidence showing that the learned sampling lattice outperforms fixed strategies. Notably, when the attention mechanism is constrained to translation only, the proposed model learns a sampling lattice that closely resembles the structure of the primate retina.
Pros:
+ The paper is well-structured and clearly written.  
+ The qualitative analysis in the experimental section is thorough and detailed.
Cons:
- The paper would benefit significantly from additional experiments on diverse datasets.  
- The computational advantages of the proposed learned sampling lattice, compared to a fixed sampling strategy with zooming capabilities (e.g., the one used in the DRAW model), are not clearly demonstrated in the tables.
Overall, I find the paper compelling. However, the experimental section could be strengthened by including more experiments and conducting additional quantitative analyses with other baseline methods. Since the current version of the paper only evaluates the approach on a digit dataset with a black background, it is challenging to generalize the findings or validate certain claims, such as the linear relationship between eccentricity and sampling interval leading to the primate retina, based on results from a single dataset.