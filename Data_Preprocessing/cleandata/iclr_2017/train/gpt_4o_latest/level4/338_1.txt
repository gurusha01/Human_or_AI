Thank you for presenting an intriguing perspective on highway and residual networks. This paper explores a novel viewpoint on the nature and type of representations learned at each layer within these models. By incorporating residual information at periodic intervals, the layers are able to maintain feature identity, thereby avoiding the lesioning effect commonly observed in convolutional neural networks.
Pros  
- The iterative unrolling perspective was remarkably straightforward and intuitive, supported by theoretical insights and reasonable assumptions.  
- Figure 3 effectively illustrated the iterative unrolling concept with clarity.  
Cons  
- While the perspective is compelling, limited empirical evidence was provided to substantiate the claims. The primary experiments focused on image classification and language models trained on variations of character-aware neural language models.  
- Figures 4 and 5 could be merged and enlarged to better highlight the impact of batch normalization.