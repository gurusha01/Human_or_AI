The paper introduces QRAQ (Query, Reason, and Answer Questions), a novel synthetic domain designed to evaluate the reasoning and interaction capabilities of conversational agents in multi-turn settings. The authors present two key contributions: (1) the development of the QRAQ domain, which extends the complexity of reasoning tasks by requiring agents to deduce missing information, query relevant variables, and integrate responses into their reasoning process, and (2) the evaluation of two reinforcement learning (RL) architectures—baseRL and impRL—on QRAQ datasets, with impRL incorporating a soft-attention mechanism over memory hops for improved performance.
Decision: Accept  
The paper is well-motivated, presents a novel and challenging domain, and provides a thorough empirical evaluation of baseline and improved RL architectures. The primary reasons for acceptance are the novelty of the QRAQ domain, which pushes the boundaries of reasoning in task-oriented dialogue systems, and the clear demonstration of the potential for RL-based approaches to tackle such problems.
Supporting Arguments:  
1. Novelty and Contribution: The QRAQ domain represents a significant advancement over existing reasoning benchmarks like bAbI by introducing variables, multi-turn interactions, and the need for logical reasoning to handle incomplete or ambiguous information. This innovation is well-placed in the literature and addresses a critical gap in evaluating conversational agents' reasoning and interaction capabilities.  
2. Empirical Rigor: The paper provides a comprehensive evaluation of both RL and supervised learning (SL) approaches across multiple QRAQ datasets, varying in complexity. The inclusion of trajectory-completeness as a metric highlights the importance of solving problems holistically, not just answering correctly.  
3. Improved RL Architecture: The impRL agent demonstrates a meaningful improvement over baseRL, particularly in complex datasets, showcasing the value of the proposed soft-attention mechanism.  
Additional Feedback for Improvement:  
1. Clarity of Presentation: While the paper is detailed, some sections (e.g., the control loop and memory network architecture) are dense and may benefit from additional diagrams or simplified explanations to aid understanding, especially for readers less familiar with memory networks.  
2. Analysis of Failure Cases: The paper could provide a deeper analysis of why RL agents struggle with deeper problems compared to SL agents. Identifying specific bottlenecks (e.g., exploration challenges, reward sparsity) could guide future work.  
3. Practical Implications: While the synthetic QRAQ domain is valuable for benchmarking, discussing how the findings might generalize to real-world conversational systems would strengthen the paper's impact.  
4. Dataset Release: The authors mention plans to release the QRAQ datasets but do not specify a timeline. Ensuring timely availability would enhance reproducibility and encourage broader adoption of the domain.
Questions for the Authors:  
1. How does the QRAQ domain compare to real-world task-oriented dialogue systems in terms of complexity and applicability?  
2. Could the authors elaborate on the exploration strategies used in RL training and whether alternative strategies (e.g., curiosity-driven exploration) were considered?  
3. Are there plans to extend QRAQ to include more realistic language or noisy user inputs to better simulate real-world scenarios?  
In conclusion, this paper makes a strong contribution to the field of conversational AI by introducing a challenging new benchmark and demonstrating the potential of RL-based approaches. While there is room for further refinement and exploration, the work is a valuable step forward and merits acceptance.