Review of the Paper
Summary of Contributions
This paper presents an approach to learning low-dimensional state representations for robotic systems using unsupervised learning guided by robotic priors. The authors employ a deep convolutional neural network (CNN) trained via a siamese network architecture to enforce constraints derived from robotic priors, such as temporal coherence, proportionality, repeatability, and causality. The method is demonstrated in a simulated environment where a Baxter robot learns a one-dimensional representation of its head position from raw images. The results show a high correlation (97.7%) between the learned representation and the ground truth, with the proposed deep model outperforming a simpler one-layer model in robustness to noise and luminosity variations. Additionally, the learned feature detectors are suggested to be transferable to other tasks, showcasing potential for broader applicability.
Decision: Reject
While the paper demonstrates a novel application of robotic priors in a deep learning framework and achieves promising results, it fails to meet the standards of completeness and scientific rigor required for acceptance. The primary reasons for rejection are the limited scope of the experiments and insufficient evaluation of the method's generalizability and practical utility.
Supporting Arguments for Decision
1. Limited Experimental Scope: The experiments are conducted in a highly controlled simulation environment with low variability in input images. While the authors acknowledge this limitation, the lack of real-world experiments undermines the practical applicability of the proposed method. The claim that the approach should work with real images remains speculative.
   
2. Evaluation Metrics: The use of correlation with ground truth as the sole evaluation metric is insufficient, especially for higher-dimensional representations or scenarios without ground truth. The authors suggest reinforcement learning as an alternative evaluation method but do not implement it, leaving the robustness of the learned representations for task execution unverified.
3. Lack of Novelty in Architecture: While the use of robotic priors in a deep CNN is novel, the architectural choices (e.g., convolutional layers, batch normalization, ReLU) are standard and do not contribute significant innovation. The paper could benefit from a more detailed comparison with existing state representation learning methods, particularly in terms of performance and computational efficiency.
Suggestions for Improvement
1. Expand Experimental Validation: Conduct experiments in real-world environments with diverse and complex visual inputs to demonstrate the robustness and generalizability of the method. Additionally, include tasks beyond head position control to showcase versatility.
   
2. Alternative Evaluation Metrics: Implement reinforcement learning or other task-specific evaluations to validate the utility of the learned representations in practical applications. This would strengthen the claims about the method's effectiveness.
3. Acknowledge and Address Limitations: Provide a more detailed discussion of the limitations, particularly regarding scalability to higher-dimensional representations and the computational cost of the siamese network architecture.
4. Clarify Transfer Learning Potential: While the paper mentions the potential for transfer learning, no experiments are conducted to validate this claim. Including such experiments would significantly enhance the paper's impact.
Questions for the Authors
1. How does the method scale to higher-dimensional state representations, and what are the computational trade-offs?
2. Have you considered using reinforcement learning to validate the learned representations in real-world tasks? If not, what are the barriers to implementing this?
3. Can you provide quantitative evidence for the transferability of the learned feature detectors to other tasks or environments?
In conclusion, while the paper introduces an interesting approach to unsupervised state representation learning, it requires substantial improvements in experimental validation, evaluation metrics, and generalizability to meet the standards of the conference. I encourage the authors to address these shortcomings and resubmit in the future.