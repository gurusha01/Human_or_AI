The paper investigates the invariance and equivariance properties of Convolutional Neural Networks (CNNs) with respect to various input transformations, providing a comprehensive empirical study across 70 CNNs trained on two datasets (ILSVRC and RVL-CDIP). The authors measure how different transformations affect internal representations and propose a novel loss function to improve CNN equivariance. Key findings include that CNNs trained with data augmentation achieve invariance to all tested transformations, even beyond the training range, and that similar transformations yield more similar representations. Additionally, the proposed loss function enhances equivariance while maintaining or slightly improving classification performance.
Decision: Accept
The paper offers significant contributions to understanding CNN representations, particularly their robustness and structure under transformations. The empirical evaluation is thorough, and the proposed loss function for improving equivariance is novel and practically useful. However, some areas could benefit from clarification and additional experiments.
Supporting Arguments:
1. Novelty and Contribution: The paper extends prior work by systematically measuring invariance and equivariance across a wide range of transformations and datasets. The introduction of a loss function to improve equivariance is a meaningful contribution, especially for applications requiring robust representations.
2. Empirical Rigor: The study is well-executed, with experiments on two diverse datasets and a wide variety of transformations. The use of pairwise representation distances to group transformations is insightful and supports the claims.
3. Practical Usefulness: The findings are highly relevant for practitioners aiming to improve CNN robustness through data augmentation or loss function design. The results on generalization to unseen transformations are particularly valuable.
Additional Feedback:
1. Clarity: While the paper is dense with technical details, some sections, such as the mathematical definitions of invariance and equivariance, could be simplified for better accessibility. Including more intuitive explanations or visual aids would help readers unfamiliar with the concepts.
2. Limitations: The paper acknowledges some limitations, such as mixed results for the proposed loss function on ILSVRC. However, a deeper discussion of why certain transformations (e.g., Gaussian Blur) negatively impact performance would strengthen the analysis.
3. Cross-Dataset Generalization: The additional experiment on the ANDOC dataset is interesting but underexplored. Expanding this analysis could provide further insights into the generalization of invariance and equivariance properties across domains.
4. Equivariance Mapping: The choice of a linear mapping for equivariance measurement is justified, but exploring more complex mappings (e.g., multi-layer networks) could reveal additional insights.
Questions for Authors:
1. How does the proposed loss function compare to other methods for improving equivariance, such as group-equivariant CNNs?
2. Can the findings on representation distances be leveraged to design better data augmentation strategies or network architectures?
3. Were there any observed trade-offs between invariance and classification accuracy for specific transformations, and how might these be mitigated?
Overall, the paper is a strong contribution to the field and provides valuable insights into CNN robustness and representation learning. With minor clarifications and additional experiments, it could have even broader impact.