Review of the Paper
The paper presents a study on the factors affecting the discriminative ability of features extracted from convolutional neural networks (CNNs) for instance-level image retrieval. The authors conduct extensive evaluations of five key factors—feature aggregation and normalization, output layer selection, image resizing, multi-scale feature representation, and PCA/whitening—and propose a new multi-scale image representation method. The proposed method is shown to outperform state-of-the-art approaches on four benchmark datasets (Oxford5k, Paris6k, Oxford105k, and UKB). Additionally, the authors introduce a layer ensemble technique to further enhance retrieval performance.
Decision: Accept
Key reasons for this decision include:  
1. Thorough Evaluation and Novel Insights: The paper provides a comprehensive analysis of factors influencing CNN-based image retrieval, offering valuable insights into the design of effective feature representations.  
2. Strong Empirical Results: The proposed multi-scale representation and layer ensemble approach achieve significant performance improvements over existing methods, demonstrating the practical utility of the contributions.
Supporting Arguments  
1. The paper addresses a well-motivated problem in the field of image retrieval, providing a clear and systematic exploration of factors that impact feature effectiveness. The choice of datasets and evaluation metrics (e.g., mAP) is appropriate and aligns with standard practices in the field.  
2. The experimental results are robust and scientifically rigorous. The authors evaluate their method on multiple datasets and compare it against state-of-the-art approaches, showing consistent improvements. For instance, the proposed method achieves a 10.3% relative improvement on Oxford5k (cropped-query) and a 4.4% improvement on UKB.  
3. The novelty of the multi-scale representation and the layer ensemble approach is evident. The authors demonstrate that their method is both compact and effective, making it suitable for real-world applications.
Additional Feedback  
1. While the paper provides strong empirical evidence, the theoretical justification for some design choices (e.g., the superiority of max-pooling with l2 normalization) could be elaborated further. A deeper discussion on why certain combinations work better would strengthen the paper.  
2. The authors mention that PCA and whitening matrices should ideally be learned on datasets similar to the target dataset. It would be helpful to provide guidelines or heuristics for selecting such datasets in practical scenarios.  
3. The paper could benefit from a clearer explanation of the computational cost of the proposed method compared to existing approaches. While the authors claim comparable cost, quantitative evidence (e.g., runtime analysis) would make this claim more convincing.  
4. The overlap configurations in the multi-scale representation are described in the appendix. Including a brief summary in the main text would improve readability and accessibility.
Questions for the Authors  
1. How does the proposed method perform on datasets with significantly different characteristics (e.g., non-landmark images or highly diverse object categories)?  
2. Could the proposed multi-scale representation be extended to other tasks, such as object detection or semantic segmentation?  
3. Have the authors considered the impact of different CNN architectures (e.g., ResNet or Vision Transformers) on the proposed method's performance?
Overall, this paper makes a valuable contribution to the field of image retrieval and provides actionable insights for practitioners. With minor clarifications and additional theoretical discussions, it could have even greater impact.