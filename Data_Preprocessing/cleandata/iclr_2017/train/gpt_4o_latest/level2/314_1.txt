The paper proposes a novel approach to sensorimotor control in immersive environments by leveraging supervised learning techniques to predict future measurements from high-dimensional sensory streams and lower-dimensional measurement streams. The key contribution lies in replacing traditional reinforcement learning's sparse scalar rewards with dense, multidimensional feedback derived from the cotemporal structure of sensory and measurement streams. This enables the model to learn directly from raw sensory input without extraneous supervision, allowing for dynamic goal adaptation at test time. The approach is validated through extensive experiments in the Doom-based ViZDoom platform, demonstrating superior performance over state-of-the-art deep reinforcement learning methods across various challenging tasks. Notably, the model won the Full Deathmatch track of the Visual Doom AI Competition, showcasing its generalization capabilities in unseen environments.
Decision: Accept
Key Reasons for Decision:
1. Novelty and Impact: The paper introduces a significant departure from traditional reinforcement learning by framing sensorimotor control as a supervised learning problem. This innovation is well-motivated and addresses key challenges in reinforcement learning, such as sparse rewards and goal flexibility.
2. Strong Empirical Results: The approach outperforms established methods like DQN, A3C, and DSR in both performance and generalization, as evidenced by extensive experiments and the competition win.
Supporting Arguments:
- The paper provides a clear and thorough explanation of the proposed methodology, including the architecture, training regime, and experimental setup. The use of vectorial feedback instead of scalar rewards is well-justified and experimentally validated.
- The results are robust, with the model excelling in diverse scenarios of increasing complexity. The ablation study further highlights the importance of key components, such as multivariate feedback and multi-temporal predictions.
- The approach demonstrates practical utility, as evidenced by its ability to generalize across environments and dynamically adapt to new goals, which is critical for real-world applications.
Suggestions for Improvement:
1. Memory and Temporal Abstraction: The model is purely reactive and lacks memory or hierarchical skill organization. Future work could explore integrating recurrent architectures or temporal abstraction to enhance behavioral sophistication.
2. Continuous Action Spaces: Extending the approach to continuous action spaces would broaden its applicability, particularly in robotics and other real-world domains.
3. Clarity in Comparisons: While the paper compares its results to prior methods, additional details on hyperparameter tuning and computational efficiency for baselines would strengthen the claims of superiority.
4. Broader Evaluation: The experiments are limited to Doom-based environments. Testing the approach in other immersive environments or real-world tasks would further validate its generalizability.
Questions for Authors:
1. How does the approach handle scenarios where the sensory and measurement streams are noisy or incomplete? Is the model robust to such conditions?
2. Could the proposed method be adapted to tasks with continuous action spaces, and if so, what modifications would be required?
3. How scalable is the approach in terms of computational resources and training time compared to reinforcement learning methods?
Overall, the paper presents a compelling and innovative approach with strong empirical validation, making it a valuable contribution to the field of sensorimotor learning and AI.