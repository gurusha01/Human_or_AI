The paper investigates the potential of end-to-end dialog systems for goal-oriented tasks, specifically in the context of restaurant reservations. It introduces a novel testbed comprising five synthetic tasks and two real-world datasets to evaluate the capabilities of such systems. The authors demonstrate the performance of Memory Networks, a neural architecture, against traditional slot-filling baselines and other machine learning methods. The results highlight that while Memory Networks show promise in handling tasks like issuing and updating API calls, they struggle with more complex tasks such as interpreting API results and conducting full dialogs. The paper emphasizes the need for further advancements in end-to-end systems to match or surpass traditional methods in goal-oriented settings.
Decision: Accept
Key Reasons for Decision:
1. Novel Contribution: The paper provides a valuable resource for the community by introducing a systematic and reproducible testbed for evaluating goal-oriented dialog systems. This contribution is significant for advancing research in this area.
2. Rigorous Evaluation: The authors conduct a comprehensive evaluation of multiple methods, including rule-based systems, classical IR models, supervised embeddings, and Memory Networks, providing clear insights into the strengths and weaknesses of each approach.
Supporting Arguments:
- The proposed testbed is well-designed, breaking down goal-oriented dialog tasks into manageable subtasks that allow for targeted evaluation and error analysis. This structured approach is a notable improvement over existing datasets, which often lack reproducibility or granularity.
- The comparison with traditional slot-filling methods and real-world datasets (DSTC2 and Concierge) ensures that the findings are grounded in practical scenarios, not just synthetic tasks.
- The use of Memory Networks with match type features demonstrates the potential of end-to-end systems to handle out-of-vocabulary entities, a critical challenge in dialog systems.
Additional Feedback for Improvement:
1. Clarity on Limitations: While the paper acknowledges that Memory Networks struggle with tasks like displaying options and conducting full dialogs, it could benefit from a more detailed discussion on why these failures occur and how future work might address them.
2. Comparison with Other Architectures: The paper focuses on Memory Networks but does not explore how other state-of-the-art architectures, such as transformers, might perform on the proposed tasks. Including such comparisons would strengthen the evaluation.
3. Dataset Diversity: While the synthetic tasks are well-constructed, they may not fully capture the variability of real-world conversations. Expanding the testbed to include more diverse and noisy datasets could enhance its utility.
Questions for Authors:
1. How do you envision the proposed testbed being used to benchmark future dialog systems? Are there plans to extend it to other domains beyond restaurant reservations?
2. Did you explore any techniques to improve Memory Networks' performance on tasks like displaying options (Task 3) or conducting full dialogs (Task 5)? If so, what were the outcomes?
3. Could the inclusion of reinforcement learning or user simulators improve the performance of end-to-end systems on these tasks?
In conclusion, the paper makes a significant contribution to the field by addressing a critical gap in the evaluation of goal-oriented dialog systems. While there is room for improvement, the novelty and rigor of the work justify its acceptance.