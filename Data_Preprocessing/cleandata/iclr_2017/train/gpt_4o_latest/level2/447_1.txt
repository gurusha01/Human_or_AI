Review of the Paper
The paper presents a novel approach to improving dialogue agents by enabling them to ask questions and learn from interactions with users, rather than relying solely on fixed supervised signals. The main contributions include the design of a simulator and synthetic tasks in the movie domain to evaluate the benefits of question-asking, as well as experiments in both offline supervised and online reinforcement learning (RL) settings. The authors also validate their approach using real-world data collected via Amazon Mechanical Turk, demonstrating that bots capable of asking questions outperform those that cannot. This work represents a significant step toward developing interactive, end-to-end learned dialogue agents.
Decision: Accept
The decision to accept this paper is based on two key reasons: (1) the paper addresses an important and underexplored problem in dialogue systems—learning through interaction—and provides a well-motivated and rigorous framework for studying it; and (2) the experimental results, both in simulation and with real-world data, convincingly demonstrate the benefits of the proposed approach.
Supporting Arguments:
1. Novelty and Contribution: The paper introduces a novel framework for enabling dialogue agents to ask questions and learn interactively. This is a significant departure from traditional systems that rely solely on fixed training data. The tasks designed in the simulator are well-motivated and cover a range of realistic scenarios, such as question clarification, knowledge operation, and knowledge acquisition.
2. Experimental Rigor: The experiments are thorough and systematically explore various training and testing combinations, as well as different levels of student knowledge (good, medium, poor). The use of both offline supervised learning and online RL adds depth to the evaluation. The inclusion of real-world experiments with Mechanical Turk further strengthens the paper's claims.
3. Practical Usefulness: The ability for dialogue agents to ask questions and learn interactively has clear practical implications, especially for applications like customer support, education, and conversational AI. The results show that such agents can achieve better performance, making the approach highly relevant to the field.
4. Clarity and Reproducibility: The paper is well-written and provides sufficient details about the tasks, models, and experimental setups. The authors also make their code and data publicly available, which enhances reproducibility.
Suggestions for Improvement:
1. Limitations and Future Work: While the paper acknowledges some limitations (e.g., reliance on synthetic data and the cost of collecting real-world data), a more detailed discussion of these limitations and potential solutions would strengthen the paper. For example, how might the approach generalize to more complex, multi-turn dialogues or other domains beyond movies?
2. Human Evaluation: While the Mechanical Turk experiments are a step in the right direction, it would be valuable to include qualitative feedback from human evaluators on the bot's performance, particularly in terms of engagement and naturalness.
3. Scalability: The paper could discuss how the proposed approach scales to larger knowledge bases or more complex domains. Are there computational challenges associated with training and deploying such systems in real-world settings?
Questions for the Authors:
1. How does the proposed approach perform in multi-turn dialogues where the bot needs to ask multiple questions to resolve ambiguities or acquire knowledge incrementally?
2. Did the authors observe any patterns in the types of questions asked by the bot during the Mechanical Turk experiments? For example, were some question types more effective than others in improving performance?
3. How sensitive is the RL-based question-asking policy to the choice of cost parameters (e.g., costAQ)? Would the approach still work well if these parameters were not carefully tuned?
Overall, this paper makes a strong contribution to the field of dialogue systems and opens up exciting avenues for future research. The proposed framework is well-motivated, the experiments are rigorous, and the results are compelling. I recommend acceptance.