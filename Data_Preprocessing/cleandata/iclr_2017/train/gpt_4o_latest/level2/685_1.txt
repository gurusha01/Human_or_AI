The paper introduces an open-vocabulary neural language model (NLM) that generates word representations on-the-fly using character-level embeddings derived from convolutional networks. The authors propose two models: CWE, which combines word and character-level embeddings for input representations, and CWE-CWE, which extends this to the output layer, enabling predictions for unseen words. The models are evaluated in a machine translation (MT) reranking task from English to Czech, achieving a modest improvement of up to 0.7 BLEU points. The paper highlights the challenges of training such models, particularly instability and issues with character-level representations contaminating frequent word embeddings.
Decision: Reject
Key Reasons:
1. Limited Contribution: While the paper addresses an important problem—open-vocabulary modeling—the improvements in BLEU score are marginal, and the CWE-CWE model underperforms compared to CWE. This limits the practical impact of the proposed approach.
2. Insufficient Validation: The experimental results, while promising, are not robust enough to justify the claims. The paper lacks a comprehensive comparison with state-of-the-art methods, particularly recent advances in character-level modeling and open-vocabulary techniques.
Supporting Arguments:
- The use of convolutional networks for character-level embeddings is well-motivated, and the authors provide a clear explanation of the architecture and training process. However, the novelty of the approach is limited, as similar methods (e.g., Kim et al., 2015) have been explored in the literature.
- The paper acknowledges key challenges, such as instability during training and contamination of character n-gram representations, but the solutions (e.g., limited padding) are ad hoc and do not fully address the underlying issues.
- The experimental setup is well-documented, but the evaluation focuses narrowly on BLEU scores for a single MT task. Broader validation across tasks or languages would strengthen the paper's claims.
Additional Feedback:
1. Training Stability: The paper mentions instability during training, particularly for CWE-CWE models. Exploring alternative optimization techniques (e.g., gradient clipping or adaptive optimizers like Adam) or regularization methods could improve performance.
2. Noise Distribution in NCE: The authors note that the unigram distribution used for negative sampling biases updates toward frequent words. Investigating more sophisticated noise distributions or dynamic sampling strategies could mitigate this issue.
3. Broader Evaluation: Expanding the evaluation to other morphologically rich languages (e.g., German, Finnish) or tasks (e.g., POS tagging, text generation) would provide stronger evidence of the model's generalizability.
4. Analysis of Representations: The paper could benefit from a deeper analysis of the learned character-level representations, particularly their ability to generalize to unseen words or capture morphological patterns.
Questions for the Authors:
1. How does the proposed model compare to recent advancements in character-level modeling, such as those using LSTMs or transformers?
2. Have you considered alternative architectures (e.g., hybrid CNN-LSTM models) to address the limitations of convolutional networks for capturing long-range dependencies?
3. Could the BLEU score improvements be attributed to factors other than the proposed model, such as the diversity of the n-best lists or the baseline MT system's quality?
In summary, while the paper tackles an important problem and provides a thoughtful exploration of open-vocabulary NLMs, the limited improvements, lack of robust validation, and unresolved challenges make it unsuitable for acceptance in its current form. The authors are encouraged to refine their approach and address the outlined concerns for future submissions.