The paper presents a scalable extension of the scattering network for feature extraction, introducing higher-order nonlinearities and Fourier-based statistics to achieve time-invariant representations. By deriving the model entirely in the Fourier domain, the authors claim to achieve linear time complexity, leveraging the sparsity of wavelet representations. Validation is performed on a bird song classification task, achieving competitive results with state-of-the-art methods, while maintaining computational efficiency and scalability.
Decision: Accept with Minor Revisions
Key Reasons for Decision:
1. Novelty and Scalability: The paper introduces a novel approach by extending the scattering network with higher-order nonlinearities and invariant dispersion coefficients, while achieving linear complexity through Fourier domain computations. This is a significant improvement over existing methods.
2. Practical Validation: The framework is validated on a real-world task (bird song classification), demonstrating its utility and competitive performance compared to state-of-the-art techniques.
Supporting Arguments:
1. Claims and Support: The paper claims to improve computational efficiency and feature discriminability. These claims are supported by theoretical derivations and empirical results. The use of Fourier domain computations and sparse storage is well-motivated and demonstrated to reduce computational overhead.
2. Usefulness: The proposed framework is practically useful for applications requiring scalable feature extraction, such as audio and signal processing tasks. The reduction in memory and computational requirements makes it suitable for deployment on energy-efficient platforms.
3. Field Knowledge and Completeness: The paper demonstrates a strong understanding of the scattering network literature and builds upon it with well-cited references. The methodology is described in detail, ensuring reproducibility.
4. Validation: The bird song classification results are promising, especially given the lack of additional feature engineering or pre-processing. The framework's ability to achieve competitive performance with a simple classifier (random forests) highlights its robustness.
Suggestions for Improvement:
1. Clarity in Presentation: The paper is dense with technical details, which may hinder accessibility for a broader audience. Simplifying some sections or providing a high-level summary of the key steps in the methodology would improve readability.
2. Comparison with Baselines: While the results are promising, a more detailed comparison with other feature extraction methods (e.g., learned features from deep neural networks) would strengthen the evaluation.
3. Limitations: The paper does not explicitly discuss limitations, such as potential challenges in extending the framework to non-stationary signals or higher-dimensional data. Including this discussion would provide a more balanced perspective.
4. Classifier Choice: The use of random forests is justified for simplicity, but exploring more advanced classifiers (e.g., boosting or neural networks) could provide insights into the framework's compatibility with modern machine learning pipelines.
Questions for Authors:
1. How does the framework perform on larger datasets or other domains (e.g., image or speech processing)? Can the scalability claims be generalized beyond audio tasks?
2. Have you considered the impact of hyperparameter tuning (e.g., wavelet parameters, number of layers) on classification performance? Would cross-validation improve results?
3. Could the proposed framework be integrated with deep learning architectures, such as Fourier-based convolutional layers?
In summary, the paper makes a strong contribution to scalable feature extraction, with promising results and practical implications. Addressing the minor concerns raised above would further enhance its impact.