Review of "Surprisal-Driven Recurrent Networks for Temporal Data Prediction"
Summary of Contributions:
This paper introduces a novel feedback mechanism for recurrent neural networks (RNNs), termed "surprisal-driven recurrent networks," which incorporates prediction error (or surprisal) as an additional input signal during inference. The authors argue that this feedback mechanism, inspired by human cognitive processes, improves the generalization capabilities of RNNs by leveraging discrepancies between past predictions and actual observations. The proposed architecture is evaluated on the enwik8 character-level text modeling task, achieving state-of-the-art performance with 1.37 bits per character (BPC). The authors also position their work within the broader context of top-down feedback mechanisms, contrasting it with existing approaches like Gated-Feedback RNNs and Ladder Networks.
Decision: Reject
While the paper presents an interesting idea and achieves strong empirical results, it falls short in several key areas, including clarity of motivation, rigor in experimental evaluation, and completeness of the methodology.
Supporting Arguments for Decision:
1. Motivation and Placement in Literature:  
   The paper claims that the proposed feedback mechanism is inspired by human cognition, but this connection is not well substantiated. While the authors reference related work, the discussion lacks depth and fails to clearly articulate how their approach builds upon or diverges from prior methods. For example, the comparison to Gated-Feedback RNNs is superficial and does not adequately justify the novelty of using surprisal as a feedback signal.
2. Experimental Rigor:  
   The experimental results on the enwik8 dataset are promising, but the evaluation is limited to a single task. The authors do not provide ablation studies to isolate the contribution of the feedback mechanism from other architectural choices. Additionally, the absence of comparisons to more recent baselines or dynamic evaluation methods weakens the empirical claims.
3. Methodological Clarity and Reproducibility:  
   The mathematical formulation of the feedback mechanism is detailed but overly dense, making it difficult to follow. Key implementation details, such as the choice of hyperparameters and the role of the feedback matrix \( V \), are not sufficiently explained. This lack of clarity hinders reproducibility.
4. Acknowledgment of Limitations:  
   While the authors briefly mention the need for further exploration of feedback interactions and regularization, they do not adequately discuss the limitations of their approach, such as its scalability to larger datasets or its applicability to non-temporal tasks.
Suggestions for Improvement:
1. Provide a more thorough comparison to related work, including recent advancements in dynamic evaluation and other feedback-based RNN architectures.
2. Conduct additional experiments on diverse datasets and tasks to demonstrate the generality of the proposed approach. Include ablation studies to isolate the impact of the surprisal-driven feedback mechanism.
3. Clarify the connection between the proposed method and human cognitive processes, or remove this claim if it cannot be substantiated.
4. Improve the presentation of the methodology, focusing on simplifying the mathematical descriptions and providing more implementation details.
5. Discuss potential limitations more explicitly and propose concrete steps for addressing them in future work.
Questions for the Authors:
1. How does the proposed feedback mechanism compare to dynamic evaluation methods that adapt weights during inference? Could these approaches be combined?
2. Why was the enwik8 dataset chosen as the sole evaluation benchmark? Would the method generalize to other temporal tasks, such as time-series forecasting or speech recognition?
3. How sensitive is the performance to the choice of hyperparameters, such as the feedback matrix \( V \) or the learning rate?
In summary, while the paper introduces an intriguing idea with strong empirical results, it requires significant improvements in motivation, experimental rigor, and clarity to meet the standards of the conference. I encourage the authors to address these issues and resubmit.