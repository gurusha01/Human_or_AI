The paper introduces the Graph Convolutional Recurrent Network (GCRN), a novel deep learning model designed to predict structured sequences of data by combining graph convolutional networks (CNNs) and recurrent neural networks (RNNs). The authors propose two architectures for GCRN and evaluate their performance on two tasks: spatio-temporal sequence modeling using the Moving MNIST dataset and natural language modeling using the Penn Treebank dataset. The results demonstrate that GCRN can effectively leverage graph structures to improve prediction accuracy and learning speed, particularly in scenarios where spatial relationships are non-Euclidean.
Decision: Accept
The paper presents a significant and novel contribution to the field of graph-based deep learning by generalizing RNNs to graph-structured data. The proposed GCRN model is well-motivated, rigorously evaluated, and demonstrates promising results in diverse applications. The combination of graph CNNs with RNNs is innovative and addresses a gap in the literature, particularly for non-grid spatial structures.
Supporting Arguments:
1. Novelty and Contribution: The paper extends the application of RNNs to graph-structured data, a relatively underexplored area. The two proposed architectures (stacked CNN-RNN and graph-based convLSTM) are novel and provide a meaningful extension to existing models like convLSTM.
2. Experimental Validation: The experiments are comprehensive, comparing GCRN against established baselines. The results on Moving MNIST show that GCRN outperforms traditional CNNs in capturing spatio-temporal patterns, even on regular grids. Similarly, the Penn Treebank experiments highlight the potential of GCRN in accelerating learning and improving performance with dropout regularization.
3. Practical Usefulness: The model is applicable to a wide range of real-world problems, such as video prediction, natural language processing, and sensor networks, making it highly relevant to the target audience.
Suggestions for Improvement:
1. Clarity in Presentation: The paper is dense with technical details, which may be overwhelming for readers unfamiliar with graph CNNs or RNNs. A more intuitive explanation of the architectures and their differences (e.g., Model 1 vs. Model 2) would improve accessibility.
2. Limitations and Future Work: While the authors discuss some limitations, such as the dimensionality issue in Model 2, a deeper analysis of computational trade-offs (e.g., runtime, memory) would strengthen the paper. Additionally, the discussion on isotropic filters could benefit from further elaboration and empirical validation.
3. Broader Evaluation: The experiments focus on two datasets, which, while diverse, may not fully capture the generalizability of GCRN. Including additional datasets, particularly those with dynamic graph structures (e.g., social networks or fMRI data), would bolster the claims.
Questions for the Authors:
1. How does the computational complexity of GCRN compare to traditional RNNs or convLSTMs for large-scale graphs, particularly in terms of training time and memory usage?
2. Can the isotropic nature of the graph filters lead to performance degradation in tasks where directional information is critical (e.g., flow networks)?
3. What specific steps are planned to address the dimensionality issue in Model 2 for larger vocabularies or graphs?
Overall, the paper makes a strong case for the utility of GCRN in modeling structured sequences and provides a solid foundation for future research in this area. With minor revisions to improve clarity and broaden the evaluation, this work has the potential to make a significant impact in the field.