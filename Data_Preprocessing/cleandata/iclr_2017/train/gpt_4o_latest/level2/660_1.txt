The paper proposes a novel optimization algorithm, Eve, which builds upon the popular Adam algorithm by incorporating feedback from the objective function. The authors claim that Eve adaptively tunes the learning rate based on relative changes in the objective function, leading to improved training performance for deep learning models. The paper demonstrates the effectiveness of Eve through experiments on convolutional neural networks (CNNs) for image classification, recurrent neural networks (RNNs) for language modeling, and question-answering tasks. The results show that Eve outperforms state-of-the-art optimization methods, including Adam, RMSProp, and SGD variants, across multiple benchmarks.
Decision: Accept
Key reasons for this decision are:
1. Novelty and Practical Impact: The proposed feedback mechanism introduces a meaningful innovation to gradient-based optimization, addressing challenges like plateaus and saddle points in the loss surface. The method is simple, computationally efficient, and demonstrates clear improvements over existing approaches.
2. Strong Empirical Validation: The paper provides extensive experimental results across diverse tasks and models, consistently showing that Eve achieves lower training loss and better optimization performance compared to other methods.
Supporting Arguments:
1. Well-Motivated Approach: The paper identifies a key limitation in existing optimization methods—difficulty navigating plateaus and saddle points—and motivates the feedback mechanism as a solution. The theoretical underpinnings are sound, and the method is well-placed within the literature, with appropriate comparisons to related work.
2. Comprehensive Experiments: The authors evaluate Eve on a variety of tasks, including CIFAR-10/100 image classification, Penn Treebank language modeling, and bAbI question-answering. The results are compelling, with Eve consistently outperforming other methods. The analysis of the tuning coefficient \( d_t \) provides valuable insights into the algorithm's behavior during training.
3. Reproducibility: The paper includes sufficient details about the algorithm, hyperparameters, and experimental setup. The authors also commit to releasing their code, which enhances the reproducibility of their results.
Suggestions for Improvement:
1. Theoretical Analysis: While the empirical results are strong, the paper lacks a formal theoretical analysis of the feedback mechanism's convergence properties. Adding such analysis would strengthen the paper's contributions.
2. Scalability to Larger Datasets: The experiments focus on relatively small-scale datasets (e.g., CIFAR-10/100, Penn Treebank). Evaluating Eve on larger datasets like ImageNet or large-scale language models would further validate its practical utility.
3. Hyperparameter Sensitivity: The paper could include a more detailed analysis of Eve's sensitivity to its new hyperparameters (\( \beta_3, k, K \)). This would help practitioners better understand how to tune the algorithm for different tasks.
4. Comparison with Second-Order Methods: While the authors justify excluding second-order methods due to computational costs, a brief empirical comparison with at least one second-order method (e.g., saddle-free Newton) on a smaller-scale task could provide additional context.
Questions for the Authors:
1. How does Eve perform when the assumption of a known minimum objective value does not hold? Can the method be adapted to handle cases where this assumption is violated?
2. Did you observe any tasks or scenarios where Eve underperformed compared to Adam or other methods? If so, what were the possible reasons?
3. Could the feedback mechanism be generalized to other optimization algorithms beyond Adam, such as RMSProp or SGD with momentum?
In conclusion, the paper makes a valuable contribution to the field of optimization for deep learning, presenting a novel and effective method with strong empirical results. Addressing the suggested improvements would further enhance the impact and clarity of the work.