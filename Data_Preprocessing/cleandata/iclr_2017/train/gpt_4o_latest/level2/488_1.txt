The paper proposes an extension of adversarial and virtual adversarial training techniques to the text domain by applying perturbations to word embeddings in recurrent neural networks (RNNs) instead of directly perturbing the input. This innovation addresses the challenges posed by sparse, high-dimensional inputs like one-hot word representations, making adversarial training feasible for text classification tasks. The authors demonstrate state-of-the-art performance on multiple benchmark datasets for both supervised and semi-supervised learning, with qualitative analyses showing improved word embeddings and reduced overfitting. The method is computationally efficient, requiring optimization of only one additional hyperparameter, and is applicable to a wide range of text classification tasks.
Decision: Accept
Key Reasons for Decision:
1. Novelty and Contribution: The paper presents a significant and novel extension of adversarial training to the text domain, addressing a key limitation of prior methods. This is the first work to apply adversarial and virtual adversarial training to RNN-based text models, achieving state-of-the-art results.
2. Experimental Rigor: The claims are well-supported by extensive experiments on diverse datasets, including IMDB, RCV1, and DBpedia. The results consistently demonstrate the superiority of the proposed method over baselines and competing approaches.
Supporting Arguments:
- The paper is well-motivated, highlighting the limitations of existing adversarial training methods for text data and providing a clear rationale for perturbing word embeddings instead of discrete inputs.
- The experiments are thorough, covering both supervised and semi-supervised tasks, and the results are statistically significant. The inclusion of ablation studies (e.g., comparing adversarial perturbations with random noise) strengthens the validity of the claims.
- The method is practical and broadly applicable, requiring minimal additional computational overhead and hyperparameter tuning. The use of pretraining with a recurrent language model further enhances its utility.
- The authors provide qualitative analyses, such as visualizations of word embeddings, which offer valuable insights into the impact of adversarial training on model robustness and generalization.
Additional Feedback for Improvement:
1. Clarity of Presentation: While the technical details are comprehensive, the paper could benefit from a clearer explanation of the intuition behind adversarial and virtual adversarial training, especially for readers less familiar with these concepts.
2. Limitations: The paper briefly mentions that the method is not intended as a defense against adversarial attacks but does not fully explore the implications of this limitation. A more explicit discussion of scenarios where the method might underperform (e.g., very short labeled datasets like Rotten Tomatoes) would be helpful.
3. Reproducibility: Although the authors mention that code will be made available, providing more detailed hyperparameter settings and training configurations in the paper itself would enhance reproducibility.
Questions for the Authors:
1. How does the method scale to larger datasets or more complex models, such as transformers? Have you tested its applicability beyond LSTMs?
2. Could the proposed approach be adapted for tasks beyond text classification, such as machine translation or question answering? If so, what challenges might arise?
3. In cases where virtual adversarial training underperforms (e.g., Rotten Tomatoes dataset), could alternative strategies, such as weighting the supervised and unsupervised losses differently, mitigate the issue?
Overall, this paper makes a strong contribution to the field of adversarial training and text classification, and I recommend its acceptance. The proposed method is both innovative and impactful, with the potential to influence future research in semi-supervised learning and text-based applications.