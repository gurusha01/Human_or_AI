The paper introduces Classifier Two-Sample Tests (C2ST), a novel approach to two-sample testing that leverages binary classifiers to determine whether two samples are drawn from the same distribution. The authors claim that C2ST provides interpretable test statistics, learns data representations on the fly, and offers insights into where distributions differ. The paper presents theoretical analyses, empirical evaluations against state-of-the-art methods, and practical applications, including generative model evaluation and causal discovery.
Decision: Accept
Key reasons for acceptance:
1. Novelty and Practical Utility: The paper proposes a novel and intuitive approach to two-sample testing that bridges statistical testing and representation learning. Its practical applications, especially in evaluating generative models and causal discovery, are compelling and relevant to the AI community.
2. Strong Empirical Evidence: The authors provide extensive experimental results demonstrating that C2ST outperforms or matches state-of-the-art methods in various scenarios, including synthetic data, independence testing, and real-world datasets.
Supporting Arguments:
- The theoretical analysis of C2ST is robust, including its asymptotic properties, testing power, and interpretability. The authors derive a clear framework for understanding the statistical behavior of C2ST under null and alternative hypotheses.
- The empirical evaluations are comprehensive, covering both synthetic and real-world datasets. Notably, C2ST achieves competitive performance in distinguishing between distributions, evaluating GANs, and causal inference tasks.
- The interpretability of C2ST is a significant strength. By leveraging classifier predictions and learned features, the method provides actionable insights into how distributions differ, which is valuable for practical applications.
- The paper is well-structured, with clear explanations of the methodology, experiments, and results. The inclusion of implementation details and open-source code enhances reproducibility.
Additional Feedback:
1. Generative Model Evaluation: While the use of C2ST for GAN evaluation is promising, the reliance on pre-trained ResNet features raises questions about generalizability to non-image domains. The authors could discuss how C2ST might be adapted for other data modalities.
2. Causal Discovery: The application of C2ST to causal inference using CGANs is innovative but appears preliminary. The instability of GAN training and the need for ensembling are limitations that should be addressed in future work.
3. Computational Efficiency: The paper could provide more details on the computational cost of C2ST, particularly when using complex classifiers like neural networks. A comparison with kernel-based methods in terms of runtime would be helpful.
Questions for the Authors:
1. How does the choice of classifier (e.g., neural networks vs. simpler models like k-NN) affect the performance and interpretability of C2ST across different datasets?
2. Can C2ST handle high-dimensional data efficiently, especially when the sample size is small? How does it compare to kernel-based methods in such scenarios?
3. For causal discovery, how sensitive is the proposed method to the choice of CGAN architecture and hyperparameters?
Overall, the paper makes a significant contribution to the field of two-sample testing and its applications. The proposed method is innovative, well-supported by theory and experiments, and has the potential to impact various domains in AI and statistics.