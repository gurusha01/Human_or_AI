The paper investigates the computational similarities between human visual perception and deep neural networks (DNNs) trained on large-scale image recognition tasks. It claims that DNNs exhibit perceptual properties reminiscent of human vision, such as sensitivity to image changes, segmentation, crowding, and contrast constancy. By comparing psychophysical data with DNN computations, the authors argue that both systems may converge to similar solutions for general-purpose visual problems due to their shared optimization goals. The paper provides experimental evidence supporting these claims, including correlations between DNN metrics and human perceptual thresholds, as well as task-relevant information in DNN layers that mirrors human perceptual phenomena.
Decision: Reject
While the paper presents an intriguing exploration of the parallels between human perception and DNN computations, it falls short in several critical areas. The primary reasons for rejection are (1) insufficient novelty and (2) limited rigor in supporting the claims.
Supporting Arguments:
1. Novelty: The idea that DNNs trained on large-scale image datasets exhibit similarities to human perception is not new and has been explored in prior works (e.g., Yamins & DiCarlo, 2016; Kriegeskorte, 2015). The paper does not provide a significant advancement over existing literature, as many of its findings (e.g., mid-layer correlations with perceptual saliency) are already well-documented. The authors fail to articulate how their approach or results substantially extend the state of the art.
2. Rigor and Support for Claims: While the experiments are extensive, the paper relies heavily on anecdotal test cases and correlational analyses. The statistical rigor of the results is not always clear, and some claims (e.g., the universality of computational convergence) are speculative. For instance, the discussion of contrast constancy and shape formation lacks sufficient experimental depth to convincingly demonstrate the purported similarities.
Additional Feedback:
1. Clarity and Focus: The paper is dense and difficult to follow, with many tangential discussions that dilute the main contributions. A more focused narrative emphasizing the most novel findings would improve readability and impact.
2. Acknowledgment of Limitations: While the authors briefly discuss limitations, such as the absence of recurrent processing in DNNs, this section is underdeveloped. A more thorough exploration of the discrepancies between DNNs and biological vision (e.g., lack of 3D perception or symmetry detection) would strengthen the paper.
3. Reproducibility: The paper mentions that the MATLAB code will be made available, but it does not provide sufficient details about the experimental setup to ensure reproducibility. For example, the exact preprocessing steps for psychophysical data and the rationale for specific DNN architectures are not clearly described.
4. Suggestions for Improvement: The authors could enhance the paper by (1) introducing novel experimental paradigms that test unexplored aspects of perceptual similarity, (2) providing stronger theoretical grounding for their claims of computational convergence, and (3) including a more comprehensive comparison with alternative models, such as biologically plausible neural networks.
Questions for the Authors:
1. How do you address the possibility that the observed similarities between DNNs and human perception are coincidental rather than indicative of shared computational principles?
2. Why were certain perceptual phenomena (e.g., 3D perception, symmetry) excluded from the analysis, and how might their inclusion affect your conclusions?
3. Could you elaborate on the implications of your findings for the design of biologically inspired DNNs or for understanding human vision?
In summary, while the paper tackles a compelling topic, it does not meet the standards of novelty and rigor required for acceptance. However, with significant revisions and a more focused contribution, it has the potential to make a meaningful impact in the field.