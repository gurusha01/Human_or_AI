The paper proposes a novel approach to address the challenges posed by polysemous words in vector-space word representations when lexicons are used for learning. The authors introduce the concept of "fuzzy paraphrases," where each paraphrase is annotated with a degree of reliability based on bilingual similarity scores. By incorporating a dropout mechanism that probabilistically eliminates less reliable paraphrases during training, the method aims to reduce noise and improve the quality of word vectors. The key contributions include a practical, single-vector-per-word approach that avoids the need for word sense disambiguation, and experimental results demonstrating improvements over prior methods across multiple benchmarks.
Decision: Accept
The paper should be accepted due to its innovative approach to handling polysemy without requiring additional preprocessing, its strong empirical results, and its practical applicability in improving word vectors.
Supporting Arguments:
1. Novelty and Contribution: The proposed method introduces a fuzzy set-based approach to annotate paraphrases with reliability scores, which is a significant departure from prior works that rely on creating multiple vectors for polysemous words. This innovation is both theoretically interesting and practically useful, as it simplifies the use of word vectors in downstream tasks.
   
2. Empirical Validation: The experimental results are robust, with the proposed method outperforming prior works on benchmarks such as MEN, SimLex, and word analogical reasoning tasks. The authors also provide a detailed exploration of parameter effects, demonstrating the adaptability of the method to different tasks and corpus sizes.
3. Practical Utility: By maintaining a single vector per word, the approach avoids the overhead of word sense disambiguation or part-of-speech tagging, making it more accessible for real-world applications.
Additional Feedback:
1. Clarity of Presentation: While the methodology is sound, the paper could benefit from clearer explanations of some technical aspects, such as the dropout function and its role in controlling paraphrase reliability. Including more intuitive examples or visualizations would help readers unfamiliar with fuzzy sets or bilingual similarity scores.
2. Limitations: Although the authors mention that the method performs less effectively on tiny corpora (e.g., text8), this limitation could be discussed more explicitly. It would also be helpful to provide insights into how the method might generalize to other languages or domains with less comprehensive lexicons.
3. Future Work: The authors suggest extending the control function to consider full context, which is a promising direction. However, additional discussion on the computational trade-offs of such an extension would be valuable.
Questions for the Authors:
1. How sensitive is the method to the quality of the lexicon (e.g., PPDB2.0)? Would the approach still perform well with less reliable or smaller lexicons?
2. Can the proposed fuzzy paraphrase mechanism be adapted for multilingual embeddings or cross-lingual tasks?
3. How does the method handle cases where paraphrases are context-dependent but not explicitly annotated in the lexicon?
In conclusion, the paper presents a well-motivated and impactful contribution to the field of word representation learning. While there are areas for improvement in presentation and discussion of limitations, the strengths of the proposed method and its empirical results justify acceptance.