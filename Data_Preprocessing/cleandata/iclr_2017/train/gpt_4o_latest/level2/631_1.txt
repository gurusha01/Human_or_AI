The paper proposes a novel Layer-RNN (L-RNN) module that integrates within-layer recurrence into convolutional neural networks (CNNs) to capture multi-scale spatial contextual information adaptively. The authors claim three main contributions: (i) introducing a hybrid architecture that interleaves CNN layers with L-RNN modules to learn long-range dependencies, (ii) demonstrating that L-RNN modules can be seamlessly added to pre-trained CNNs and fine-tuned for improved performance, and (iii) achieving competitive results on CIFAR-10 classification and significant performance boosts in semantic segmentation on PASCAL VOC2012.
Decision: Accept
The paper makes a compelling case for acceptance due to its novel approach, strong empirical results, and practical applicability. The key reasons for this decision are:
1. Novelty and Innovation: The L-RNN module introduces a unique way of combining CNNs and RNNs, enabling adaptive learning of spatial dependencies within layers. This approach is distinct from prior work, such as ReNets and 2D-RNNs, and offers practical advantages like parallel processing on GPUs and reduced training time.
   
2. Empirical Validation: The paper provides robust experimental evidence, demonstrating that L-RNN modules improve performance on both CIFAR-10 classification and PASCAL VOC2012 segmentation tasks. Notably, the hybrid architecture achieves comparable results to state-of-the-art models like ResNet-164 with fewer parameters and boosts segmentation performance by 5% mean IOU when added to pre-trained FCNs.
Supporting Arguments:
- The paper is well-motivated and grounded in relevant literature, with clear comparisons to related works like ReNets, Inside-Outside Net, and CRF-RNN.
- The experiments are thorough, exploring various architectural configurations, pooling mechanisms, and recurrent units (e.g., GRU vs. vanilla RNN with layer normalization). The results consistently support the claims.
- The proposed method is practically useful, as it can be seamlessly integrated into existing architectures and fine-tuned for new tasks, reducing the need for training from scratch.
Suggestions for Improvement:
1. Clarity on Limitations: While the paper briefly mentions that L-RNNs may offer limited benefits in layers with large receptive fields (e.g., fully connected layers in FCN-32s), a more detailed discussion of scenarios where L-RNNs might underperform would strengthen the paper.
2. Broader Evaluation: Testing the L-RNN module on additional datasets (e.g., ImageNet) and tasks (e.g., object detection) would provide a more comprehensive assessment of its generalizability.
3. Ablation Studies: While the paper includes some architectural variations, more detailed ablation studies isolating the impact of specific design choices (e.g., bidirectional RNNs, fusion methods) would provide deeper insights.
Questions for the Authors:
1. How does the computational overhead introduced by L-RNN modules compare to other methods like dilated convolutions or CRFs in terms of training and inference time?
2. Could the L-RNN module be extended to tasks beyond vision, such as natural language processing or time-series analysis? If so, what modifications would be required?
3. Have you explored the impact of different initialization strategies for the recurrence matrix beyond the zero-initialization approach described?
Overall, the paper presents a significant contribution to the field, with a novel method that is both theoretically sound and empirically validated. With minor clarifications and additional experiments, it could have an even broader impact.