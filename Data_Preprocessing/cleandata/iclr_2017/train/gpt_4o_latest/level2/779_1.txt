The paper presents a comprehensive study on vocabulary selection techniques to improve the efficiency of Neural Machine Translation (NMT) systems, focusing on decoding and training speed-ups while maintaining translation accuracy. The authors extend prior work by exploring a variety of selection methods, including bilingual word co-occurrence counts, bilingual embeddings, word alignments, phrase pairs, and Support Vector Machines (SVMs). They evaluate these methods on WMT15 English-German and WMT16 English-Romanian datasets, achieving significant speed-ups—up to 90% in decoding time and 25% in training time—while maintaining comparable BLEU scores to full-vocabulary models.
Decision: Accept
The paper makes a strong case for acceptance due to its significant contributions to improving NMT efficiency, rigorous experimental evaluation, and practical applicability. The key reasons for this decision are:
1. Well-Motivated Problem and Novelty: The paper addresses the critical issue of computational inefficiency in NMT systems, particularly during decoding and training. By extending prior work with additional selection methods and providing a detailed analysis of speed-accuracy trade-offs, the paper demonstrates clear novelty and relevance to the field.
   
2. Strong Empirical Support: The experiments are thorough, with results validated across multiple datasets and test sets. The authors convincingly show that word alignment-based selection achieves a 10x speed-up in decoding with negligible accuracy loss, a significant improvement over prior work.
Supporting Arguments:
- The paper is well-situated in the literature, referencing key works and demonstrating an understanding of the field. The comparison to Mi et al. (2016) and the inclusion of novel methods like SVM-based selection highlight the paper's contributions.
- The results are scientifically rigorous, with clear metrics (BLEU scores, decoding speed, training time) and detailed analysis of trade-offs.
- The work is practically useful, as the proposed techniques can be directly applied to real-world NMT systems, especially for CPU-based decoding.
Additional Feedback:
1. Clarity of Presentation: While the paper is comprehensive, some sections (e.g., the detailed descriptions of selection methods) could benefit from more concise explanations. A summary table comparing the methods in terms of complexity, speed, and accuracy would enhance readability.
2. Limitations and Future Work: The paper could better acknowledge limitations, such as the reduced impact of vocabulary selection during training due to encoder bottlenecks. Additionally, exploring the integration of faster encoder architectures or alternative hardware setups could be a promising direction for future work.
3. Reproducibility: The authors mention releasing the code, which is commendable. However, providing more implementation details (e.g., hyperparameters for SVMs) in the appendix would further enhance reproducibility.
Questions for Authors:
1. How does the performance of vocabulary selection methods vary across different language pairs, particularly those with larger or more morphologically complex vocabularies?
2. Could the proposed methods be extended to subword-level vocabularies (e.g., byte pair encoding), and if so, how would this impact efficiency and accuracy?
3. Have you considered the potential impact of vocabulary selection on low-resource language pairs, where training data is limited?
In conclusion, the paper provides a valuable contribution to the field of NMT, addressing a critical bottleneck with innovative and well-supported solutions. With minor improvements in presentation and additional discussion of limitations, this work has the potential to make a significant impact.