The paper presents a novel approach to constructing a phylogenetic tree (Tree of Life) using deep representations from convolutional neural networks (CNNs) trained on ImageNet. The authors propose leveraging the hierarchical feature representations learned by CNNs to quantify visual similarity among species, providing a new perspective on deep learning applications in evolutionary biology and bioinformatics. The paper claims two main contributions: (1) offering a potential solution to constructing evolutionary trees using deep representations, and (2) providing insights into the representations produced by deep neural networks. The authors evaluate their method using three CNN architectures (AlexNet, VGG, and ResNet) and demonstrate its effectiveness in constructing fine-grained and coarse-grained trees for biological species and even non-biological objects like vehicles.
Decision: Reject
While the paper introduces an interesting and novel application of CNNs, it suffers from significant shortcomings in experimental rigor, theoretical grounding, and clarity of contributions. These issues outweigh the potential of the proposed method in its current form.
Supporting Arguments:
1. Insufficient Validation of Claims: The paper claims that the constructed trees are "highly competitive" with human-level performance, but the evaluation lacks quantitative metrics or statistical significance. The reliance on qualitative comparisons with WordNet hierarchies is insufficient to establish the robustness of the approach.
   
2. Limited Novelty in Methodology: While the application of CNNs to phylogenetic tree construction is novel, the methodology primarily repurposes existing CNN architectures and similarity measures (e.g., cosine similarity, softmax cross-activations). The paper does not introduce significant innovations in deep learning techniques or phylogenetic tree algorithms.
3. Weak Biological Relevance: The approach relies solely on visual similarity, which may not align with actual evolutionary relationships based on genetic or molecular data. This limitation is not adequately acknowledged or discussed, reducing the biological relevance of the results.
4. Incomplete Experimental Analysis: The experiments focus primarily on small subsets of species and lack diversity in datasets. The paper does not explore how the method generalizes to larger or more complex datasets, nor does it compare against modern phylogenetic tree construction methods based on genetic data.
5. Reproducibility Concerns: The paper provides insufficient implementation details for reproducibility, particularly regarding hyperparameters, dataset preprocessing, and the specifics of the tree construction algorithms.
Suggestions for Improvement:
1. Quantitative Evaluation: Include rigorous quantitative metrics (e.g., tree similarity scores, precision/recall) to validate the constructed trees against ground truth hierarchies.
2. Broader Dataset and Comparisons: Test the method on a wider range of datasets, including genetic data, and compare against state-of-the-art phylogenetic tree construction methods.
3. Biological Relevance: Address the limitations of using visual similarity as a proxy for evolutionary relationships and explore ways to incorporate genetic or molecular data.
4. Implementation Details: Provide more comprehensive details on the experimental setup to ensure reproducibility.
5. Limitations and Future Work: Explicitly discuss the limitations of the current approach and outline potential directions for improvement, such as integrating multimodal data (e.g., images and genetic sequences).
Questions for the Authors:
1. How does the proposed method compare quantitatively to traditional phylogenetic tree construction methods based on genetic data?
2. Can the approach be extended to incorporate non-visual features, such as genetic or molecular data, to improve biological relevance?
3. What specific metrics were used to evaluate the quality of the constructed trees, and how do they compare to human-constructed trees?
In conclusion, while the paper explores an intriguing application of deep learning, it requires significant improvements in experimental rigor, biological relevance, and methodological novelty to be suitable for acceptance.