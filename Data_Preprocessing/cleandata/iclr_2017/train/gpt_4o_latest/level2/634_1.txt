Review of the Paper: Layerwise Origin-Target Synthesis (LOTS)
Summary of Contributions
The paper introduces a novel algorithm, Layerwise Origin-Target Synthesis (LOTS), which serves three primary purposes: (1) visualizing the internal representations of inputs at any layer of a deep neural network (DNN), (2) assessing the stability of these internal representations with respect to input classes, and (3) generating diverse adversarial examples for adversarial training to improve model robustness. The authors demonstrate the utility of LOTS on two well-known DNNs: LeNet for handwritten digit recognition and VGG Face for face recognition. The paper claims that LOTS produces more diverse adversarial examples than existing methods, leading to improved adversarial robustness and performance when used for adversarial training. Additionally, the visualization capabilities of LOTS provide insights into the internal workings of DNNs, particularly the features learned at different layers.
Decision: Accept
The paper presents a novel and well-motivated approach that addresses important challenges in understanding and improving the robustness of DNNs. The key reasons for acceptance are: (1) the significant novelty of the LOTS algorithm, which extends existing adversarial generation methods to deeper layers and offers a unique visualization capability, and (2) the strong empirical evidence supporting the claims, including extensive experiments demonstrating the effectiveness of LOTS in adversarial training and visualization.
Supporting Arguments
1. Novelty and Motivation: The LOTS algorithm is a clear innovation over existing adversarial generation techniques, such as the hot/cold approach and fast gradient sign methods. By operating at multiple layers, LOTS provides a more comprehensive framework for both visualization and adversarial example generation. The paper is well-placed in the literature, with a thorough discussion of related work.
   
2. Empirical Support: The experiments are extensive and scientifically rigorous. The authors compare LOTS with several baseline adversarial generation methods and demonstrate its superior performance in terms of adversarial robustness and error rates. The use of multiple metrics (e.g., PASS, L2, Lâˆž norms) strengthens the validity of the results.
3. Practical Usefulness: LOTS has clear practical applications in both understanding DNNs and improving their robustness. The visualization capabilities are particularly valuable for researchers seeking to interpret DNN behavior, while the adversarial training results demonstrate real-world utility.
Suggestions for Improvement
1. Clarity in Visualization Results: While the visualization results are intriguing, the paper could benefit from more detailed qualitative analysis of the visualizations, particularly for complex datasets like VGG Face. For example, how do these visualizations compare to existing methods in terms of interpretability?
2. Computational Efficiency: The paper acknowledges that LOTS is computationally expensive, especially when generating adversarial examples. A more detailed discussion of the trade-offs between computational cost and performance would be helpful.
3. Broader Evaluation: The experiments focus on two specific networks (LeNet and VGG Face). It would strengthen the paper to evaluate LOTS on additional datasets or architectures, such as ResNet or transformers, to demonstrate its generalizability.
4. Limitations: While the paper briefly mentions limitations, such as the potential for higher computational costs, a more explicit discussion of the scenarios where LOTS might not be effective (e.g., very shallow networks or non-vision tasks) would provide a more balanced perspective.
Questions for the Authors
1. How does LOTS perform on state-of-the-art architectures like ResNet or transformers? Are there any challenges in extending the approach to these models?
2. Can the computational cost of LOTS be reduced without significantly compromising its performance? Have you explored approximations or optimizations for the backpropagation step?
3. How does the diversity of adversarial examples generated by LOTS quantitatively compare to other methods, beyond the metrics already presented?
Conclusion
Overall, the paper makes a significant contribution to the fields of adversarial robustness and DNN interpretability. The LOTS algorithm is both novel and practically useful, and the experimental results are compelling. With minor improvements in clarity and broader evaluation, this work has the potential to make a lasting impact. I recommend acceptance.