Review of the Paper: Hierarchical Compositional Network (HCN)
The paper introduces the Hierarchical Compositional Network (HCN), a directed generative model designed to discover and disentangle the building blocks of binary images without supervision. The authors claim that HCN addresses key limitations of existing generative models, such as poor feature interpretability and lack of compositionality, by leveraging max-product message passing (MPMP) for inference and learning. The paper also highlights the flexibility of HCN in tasks like classification, inpainting, and unsupervised denoising, while demonstrating its functional equivalence to convolutional neural networks (CNNs) in certain scenarios.
Decision: Accept
The decision to accept this paper is based on two key reasons: (1) the novelty and significance of the proposed model in addressing long-standing challenges in generative modeling, and (2) the rigorous experimental validation that demonstrates the effectiveness of HCN in both synthetic and real-world datasets. Below, I provide supporting arguments for this decision.
Supporting Arguments
1. Novelty and Contributions: The paper makes a strong case for the novelty of HCN by addressing the "explaining away" phenomenon in directed generative models using MPMP. Unlike prior works, HCN allows features to overlap and reuse components hierarchically, enabling richer and more interpretable representations. The binary nature of the weights and features is another unique aspect, which has practical implications for storage and computation.
2. Experimental Validation: The experiments convincingly demonstrate HCN's ability to discover interpretable features, even in challenging scenarios with noise and limited data. The comparison with state-of-the-art methods like NOCA and CNNs highlights HCN's superior performance in feature disentanglement, classification, and generalization to noisy data. The results on MNIST, despite using only a fraction of the training data, are particularly impressive.
3. Practical Utility: The model's flexibility in handling supervised, semi-supervised, and unsupervised tasks, along with its ability to generalize without retraining, makes it highly practical for real-world applications. The binary weights and efficient forward pass further enhance its utility.
Suggestions for Improvement
While the paper is strong overall, the following points could improve its clarity and impact:
1. Scalability: The memory requirements for storing messages during training (e.g., 150GB for MNIST) are a significant limitation. The paper briefly mentions an online learning extension, but a more detailed discussion or experiments demonstrating its scalability would strengthen the paper.
2. Comparison with Modern Generative Models: While the paper compares HCN with NOCA and CNNs, it would benefit from a more comprehensive comparison with modern generative models like VAEs and GANs. Even if direct comparisons are challenging due to differences in model structure, a qualitative discussion would be valuable.
3. Interpretability of Results: While the paper emphasizes the interpretability of HCN's features, more visualizations or examples of learned features (especially for real-world datasets like MNIST) would help illustrate this claim more effectively.
4. Runtime Analysis: The paper mentions that HCN's training time is longer than CNNs due to the complexity of MPMP. Providing a detailed runtime comparison and discussing potential optimizations would help address concerns about practical deployment.
Questions for the Authors
1. How does HCN perform on larger-scale datasets or more complex images (e.g., CIFAR-10 or ImageNet)? Are there any architectural modifications required to handle such datasets?
2. Can the online learning extension completely mitigate the memory bottleneck for larger datasets, and how does it affect the quality of the learned features?
3. Have you considered extending HCN to handle grayscale or real-valued images directly, rather than relying on preprocessing?
Conclusion
The paper presents a novel and well-supported contribution to the field of generative modeling, with clear advantages in feature interpretability, compositionality, and generalization. While there are areas for improvement, the strengths of the work outweigh its limitations, and it has the potential to inspire further research in hierarchical generative models. I recommend accepting the paper.