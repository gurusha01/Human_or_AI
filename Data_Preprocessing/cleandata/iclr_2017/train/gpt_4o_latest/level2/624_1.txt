The paper investigates the error surface of deep neural networks, particularly focusing on the susceptibility of finite-sized models and datasets to bad local minima. The authors challenge the widely held belief that deep networks optimized with gradient-based methods avoid poor local minima due to their high-dimensional error surfaces. Through theoretical constructions and empirical examples, the paper demonstrates counterexamples where neural networks encounter suboptimal learning dynamics, especially under specific initialization schemes and data structures. The work highlights the importance of initialization, data structure, and architectural choices in determining the success of gradient-based optimization.
Decision: Reject
Key Reasons for Rejection:
1. Limited Practical Impact: While the theoretical constructions are interesting, their practical relevance is unclear. The counterexamples appear contrived and do not convincingly address real-world scenarios where deep learning is applied.
2. Weak Empirical Validation: The empirical results, though illustrative, are limited in scope and fail to generalize the theoretical findings to broader, practical datasets or architectures.
Supporting Arguments:
- The paper provides a thorough review of existing literature on the error surface of deep networks and builds on prior work by presenting counterexamples. However, the examples rely heavily on artificial datasets and specific initialization schemes, which may not reflect realistic conditions in practical applications.
- While the theoretical proofs are rigorous, they focus on edge cases rather than providing actionable insights or guidelines for practitioners. For instance, the discussion on bad initialization is intriguing but lacks a clear connection to commonly used initialization methods in modern deep learning frameworks.
- The empirical experiments, particularly on MNIST and synthetic datasets, are limited in scope and fail to demonstrate the broader applicability of the findings. For example, the experiments do not explore how the proposed issues manifest in larger, more complex datasets or architectures.
Suggestions for Improvement:
1. Broader Empirical Validation: Extend the experiments to include more diverse datasets and architectures, such as convolutional neural networks or transformers, to assess the generalizability of the findings.
2. Practical Relevance: Provide concrete recommendations or strategies to mitigate the identified issues, such as improved initialization methods or architectural adjustments.
3. Clarify Assumptions: Clearly state the assumptions and limitations of the theoretical constructions and discuss their implications for real-world applications.
4. Explore Overparameterization: Investigate how overparameterization, a common characteristic of modern deep learning models, interacts with the identified issues.
Questions for the Authors:
1. How do the proposed counterexamples relate to the performance of state-of-the-art architectures on large-scale datasets?
2. Can the identified issues with initialization be mitigated by commonly used techniques such as batch normalization or adaptive optimizers like Adam?
3. Have you considered the impact of overparameterization, which is known to improve optimization landscapes in deep learning?
In summary, while the paper provides valuable theoretical insights, its limited practical relevance and weak empirical validation make it unsuitable for acceptance in its current form. Addressing the suggestions above could significantly strengthen the contribution.