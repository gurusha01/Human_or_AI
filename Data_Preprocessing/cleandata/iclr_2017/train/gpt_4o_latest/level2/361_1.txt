The paper presents a novel approach to hyperparameter optimization by leveraging Bayesian neural networks (BNNs) for learning curve prediction, introducing a specialized "learning curve layer" to improve performance. The authors claim five key contributions: (1) evaluating BNNs for learning curve fitting and uncertainty estimation, (2) developing a specialized neural network architecture for learning curve prediction, (3) comparing different Bayesian inference methods for BNNs, (4) demonstrating superior predictive performance over existing parametric models, and (5) extending Hyperband with their model to accelerate hyperparameter optimization. The paper is well-motivated, addressing the inefficiencies of traditional Bayesian optimization for computationally expensive tasks, and provides a thorough experimental evaluation.
Decision: Accept.  
The paper makes a significant contribution to the field of hyperparameter optimization by integrating Bayesian neural networks with learning curve prediction. The novelty of the specialized learning curve layer and its demonstrated improvements in predictive performance and optimization efficiency justify acceptance.
Supporting Arguments:  
1. Novelty and Relevance: The proposed learning curve layer is a meaningful innovation that builds on prior work (e.g., Domhan et al., 2015) while addressing its limitations. The integration of BNNs with Hyperband is a compelling extension that bridges the gap between theoretical advancements and practical utility.  
2. Experimental Rigor: The paper evaluates its approach across multiple datasets and baselines, including Gaussian processes, random forests, and other BNN methods. The results consistently show that the proposed method outperforms existing approaches in terms of both mean squared error and log-likelihood for learning curve prediction.  
3. Practical Impact: The extension of Hyperband with the proposed model demonstrates faster convergence to optimal configurations, highlighting its potential to significantly reduce computational costs in real-world applications.  
Additional Feedback:  
1. Clarity: While the paper is generally well-written, some sections (e.g., the mathematical derivations in Section 2.2) could benefit from clearer explanations for readers less familiar with Bayesian neural networks. Adding more intuitive descriptions alongside equations would improve accessibility.  
2. Limitations: The paper does not explicitly discuss the computational overhead introduced by the BNN-based approach compared to simpler methods like random forests or Gaussian processes. A detailed analysis of this trade-off would strengthen the paper.  
3. Generality: While the experiments are comprehensive, they are limited to specific datasets (e.g., CNNs, FCNet, etc.). It would be valuable to evaluate the method on more diverse tasks or larger-scale datasets to assess its generalizability.  
Questions for Authors:  
1. How does the computational overhead of training the proposed BNN model compare to the baseline methods, particularly for large-scale datasets?  
2. Could the proposed learning curve layer be adapted for other model architectures, such as recurrent neural networks, as mentioned in the conclusion? If so, what challenges might arise?  
3. How sensitive is the performance of the proposed method to the choice of hyperparameters for the Bayesian neural network itself?  
Overall, the paper presents a strong contribution to the field, with a well-motivated problem, innovative methodology, and thorough experimental validation. Addressing the feedback and questions above would further enhance its impact and clarity.