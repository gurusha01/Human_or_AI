Review of "Deep Variational Information Bottleneck"
The paper introduces a novel method called Deep Variational Information Bottleneck (Deep VIB), which extends the information bottleneck (IB) principle to deep neural networks by leveraging variational inference and the reparameterization trick. The authors claim that this approach allows for efficient training of stochastic neural networks, yielding models that outperform traditional regularization techniques in terms of generalization and robustness to adversarial attacks. They support their claims with theoretical derivations and experimental results on MNIST and ImageNet datasets, demonstrating improved performance and adversarial robustness.
Decision: Accept
The primary reasons for acceptance are the paper's significant contributions to the field of representation learning and its rigorous experimental validation. The proposed method addresses a key limitation of the original IB framework—its computational intractability—by introducing a variational approximation that is scalable to high-dimensional data. Furthermore, the demonstrated improvements in adversarial robustness are timely and relevant, given the growing concerns about the vulnerability of deep learning models.
Supporting Arguments:
1. Novelty and Contribution: The paper makes a substantial contribution by bridging the gap between the IB principle and deep learning through a variational framework. This is a meaningful advancement over prior work, which was limited to discrete or Gaussian settings.
   
2. Experimental Validation: The experiments are thorough and well-designed. The authors compare Deep VIB against baseline methods (e.g., deterministic models, dropout, and other regularization techniques) and show consistent improvements in both classification accuracy and robustness to adversarial attacks. The visualization of embeddings and adversarial perturbations provides additional insights into the method's behavior.
3. Theoretical Rigor: The derivation of the variational lower bound and its connection to mutual information is clearly presented. The use of the reparameterization trick for efficient gradient estimation is a sound choice, aligning with best practices in variational inference.
Additional Feedback:
1. Clarity of Presentation: While the theoretical derivations are detailed, they may be challenging for readers unfamiliar with variational inference. Including a high-level summary or diagram to explain the intuition behind the method would improve accessibility.
2. Limitations and Future Work: The paper could benefit from a more explicit discussion of its limitations. For instance, the authors briefly mention that the method's performance depends on the choice of the β parameter, but they do not provide a systematic way to select it. Additionally, the experiments are limited to MNIST and ImageNet features; testing on more diverse datasets would strengthen the generalizability of the claims.
3. Comparison with State-of-the-Art: While the authors acknowledge that their results are not state-of-the-art, it would be helpful to contextualize their findings by comparing Deep VIB to the latest adversarial training methods or other robust representation learning techniques.
Questions for the Authors:
1. How sensitive is the method to the choice of the variational prior \( r(z) \)? Have you explored alternatives to the isotropic Gaussian prior?
2. Can the proposed method be extended to unsupervised or semi-supervised learning tasks? If so, how would the objective need to be modified?
3. Have you considered the computational overhead introduced by the stochastic encoder and multiple posterior samples during inference? How does this compare to deterministic baselines?
In conclusion, the paper presents a compelling method with strong theoretical foundations and promising empirical results. Addressing the feedback above would further enhance its impact and clarity.