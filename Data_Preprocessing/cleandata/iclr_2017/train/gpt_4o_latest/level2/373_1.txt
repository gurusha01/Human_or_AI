Review
The paper addresses the problem of transfer learning for neural sequence tagging, focusing on improving performance on low-resource tasks by leveraging knowledge from related high-resource tasks. The authors propose a transfer learning framework based on hierarchical recurrent neural networks (RNNs) and explore three architectures (T-A, T-B, T-C) for cross-domain, cross-application, and cross-lingual transfer. The paper claims two main contributions: (1) a novel study of layer-wise transferability in hierarchical RNNs, and (2) a unified framework for handling diverse transfer settings. Experimental results demonstrate significant improvements in low-resource scenarios and state-of-the-art performance on several benchmarks.
Decision: Accept
The paper is well-motivated, presents a novel and unified approach to transfer learning for sequence tagging, and provides strong empirical evidence to support its claims. The key reasons for acceptance are the methodological novelty and the thorough experimental evaluation, which convincingly demonstrate the utility of the proposed approach.
Supporting Arguments:
1. Novelty and Contribution: The paper's focus on layer-wise transferability in hierarchical RNNs is novel and provides valuable insights into parameter sharing for transfer learning. The unified framework for cross-domain, cross-application, and cross-lingual transfer is a significant improvement over existing methods, which often focus on a single transfer setting.
2. Experimental Rigor: The authors conduct extensive experiments across multiple datasets and transfer settings, including low-resource conditions. The results consistently show substantial performance gains, particularly in low-label scenarios, and achieve state-of-the-art results on several benchmarks. The comparison of architectures (T-A, T-B, T-C) further highlights the trade-offs in parameter sharing.
3. Practical Usefulness: The proposed approach is practically useful, as it addresses real-world challenges in NLP, such as low-resource languages and domains. The framework is generalizable and could be applied to other sequence tagging tasks beyond those studied in the paper.
4. Placement in Literature: The paper demonstrates a solid understanding of prior work, situating its contributions within the context of resource-based and model-based transfer learning. The references are relevant and comprehensive.
Suggestions for Improvement:
1. Clarity on Limitations: While the paper acknowledges that transfer learning performance diminishes with less related source and target tasks, it could provide more detailed analysis or discussion of these limitations. For example, what specific characteristics of tasks make them more or less transferable?
2. Resource-Based Transfer: The authors mention the potential for combining model-based and resource-based transfer but do not explore this in detail. Including preliminary experiments or a discussion on how this integration could be achieved would strengthen the paper.
3. Reproducibility: While the authors provide a link to the code, additional details on hyperparameter tuning, training time, and computational resources would enhance reproducibility.
4. Cross-Lingual Transfer: The cross-lingual experiments are limited to languages with similar alphabets (e.g., English and Spanish). It would be helpful to discuss how the approach could be extended to languages with disparate alphabets, even if only theoretically.
Questions for the Authors:
1. How does the performance of the proposed architectures (T-A, T-B, T-C) vary with respect to the size of the source task dataset? Are there diminishing returns when the source task has abundant labels?
2. Can the proposed framework handle scenarios where the target task has no labeled data at all (i.e., zero-shot transfer learning)? If not, what modifications would be required?
3. How sensitive is the framework to the choice of hyperparameters, particularly the binomial probability for task sampling during training?
In conclusion, the paper makes a significant contribution to the field of transfer learning for sequence tagging and is a strong candidate for acceptance. Addressing the suggestions above would further enhance its impact and clarity.