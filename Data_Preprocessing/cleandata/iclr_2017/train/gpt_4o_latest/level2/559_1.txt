The paper proposes Prototypical Networks, a novel approach to few-shot and zero-shot learning that simplifies and improves upon existing methods like Matching Networks. The key contribution is the idea of representing each class by a single prototype, computed as the mean of its support set in an embedding space learned by a neural network. Classification is then performed using Euclidean distances between query points and these prototypes. The authors demonstrate that this approach is computationally efficient, scalable, and achieves competitive or state-of-the-art results on benchmark datasets such as Omniglot, miniImageNet, and CUB-200 for zero-shot learning.
Decision: Accept.  
The paper makes a significant contribution to the field of few-shot and zero-shot learning by introducing a simpler and more scalable method that achieves competitive performance. The approach is well-motivated, grounded in the literature, and supported by rigorous empirical results.
Supporting Arguments:  
1. Novelty and Simplicity: The paper introduces a novel inductive bias—class prototypes as mean embeddings—while simplifying the computational complexity compared to Matching Networks. This innovation is both conceptually elegant and practical.  
2. Empirical Validation: The results on Omniglot and miniImageNet demonstrate competitive performance, while the state-of-the-art results on CUB-200 for zero-shot learning highlight the generalizability of the method. The experiments are thorough, with appropriate baselines and ablation studies (e.g., prototype normalization).  
3. Theoretical Insight: The equivalence of Prototypical Networks to a linear classifier with learned weights provides a strong theoretical foundation, enhancing the paper's credibility.  
Additional Feedback:  
1. Clarity of Presentation: While the paper is generally well-written, the explanation of prototype normalization and its benefits could be expanded for clarity. For instance, more details on how normalization impacts training stability and regularization would be helpful.  
2. Limitations: The paper does not explicitly discuss potential limitations. For example, the reliance on Euclidean distance may not be optimal for all datasets, and the method's performance on highly imbalanced support sets is unclear. Acknowledging and addressing these concerns would strengthen the paper.  
3. Comparison with Other Methods: While the paper compares Prototypical Networks to Matching Networks and a few others, additional comparisons with more recent methods (e.g., memory-augmented networks) would provide a more comprehensive evaluation.  
Questions for Authors:  
1. How does the method handle scenarios with highly imbalanced support sets (e.g., one class having significantly more examples than others)?  
2. Have you explored alternative distance metrics (e.g., cosine similarity) in place of Euclidean distance, and if so, how do they affect performance?  
3. Could the approach be extended to handle multi-modal prototypes (e.g., using clustering within each class)?  
Overall, the paper is a strong contribution to the field, offering a simple yet effective solution to few-shot and zero-shot learning. With minor clarifications and additional comparisons, it would be an excellent addition to the conference.