The paper introduces a novel framework for adaptive, imagination-based optimization in reinforcement learning (RL) using a metacontroller architecture. The metacontroller dynamically decides the number of computational steps and selects among multiple predictive models ("experts") to balance task performance and computational cost. The authors demonstrate the approach on a challenging decision-making task involving non-linear dynamics, where the metacontroller outperforms traditional fixed-policy methods by adapting its computation to task difficulty. This work is inspired by cognitive science and builds on prior research in meta-reasoning and model-based RL, offering a flexible and resource-efficient method for decision-making.
Decision: Accept
Key reasons: (1) The paper presents a significant methodological innovation in RL by introducing a metacontroller that optimizes computational resources adaptively. (2) The experimental results convincingly demonstrate the framework's effectiveness and efficiency compared to baseline methods.
Supporting Arguments:
1. Novelty and Contribution: The metacontroller framework is a significant advancement over traditional RL approaches, which often rely on fixed computational policies. By integrating model-free and model-based elements, the framework introduces a hybrid system capable of dynamically adapting computation. This is a meaningful contribution to the field of RL and adaptive computation.
   
2. Experimental Validation: The experiments on the physics-based spaceship task are well-designed and demonstrate the metacontroller's ability to adapt computation to task difficulty. The results show that the metacontroller achieves lower overall costs (task loss + computational cost) compared to iterative and reactive agents. The ability to outperform even when computational costs are negligible highlights the robustness of the approach.
3. Usefulness and Practicality: The framework has clear practical applications in resource-constrained environments, such as robotics or real-time decision-making systems. The ability to balance performance and computational cost is a critical feature for deploying RL systems in real-world scenarios.
Additional Feedback:
1. Clarity of Presentation: While the paper is dense, the core ideas are well-articulated. However, the technical details, particularly in the appendices, could be streamlined for better readability. For example, the mathematical formulations in Sections 2.2 and 2.3 could benefit from additional explanatory text or visual aids.
2. Limitations and Future Work: While the paper acknowledges some limitations, such as the reliance on differentiable experts and the challenges in training with multiple experts, these points could be expanded. For example, the authors could discuss how the framework might generalize to non-differentiable experts or tasks with more complex dynamics.
3. Comparison to Related Work: The paper provides a solid discussion of related work, but a more detailed comparison with recent advances in adaptive computation time (e.g., Graves, 2016) and conditional computation (e.g., Bengio, 2013) would strengthen the positioning of the contribution.
4. Scalability: While the experiments focus on a single task, it would be helpful to discuss the scalability of the approach to more complex, multi-step decision-making tasks or larger action spaces.
Questions for the Authors:
1. How does the metacontroller handle scenarios where the experts provide conflicting evaluations? Is there a mechanism to assess or improve expert reliability dynamically?
2. Could the framework be extended to handle tasks with sequential decision-making (e.g., multi-step planning) rather than one-shot decisions?
3. How sensitive is the performance to the choice of hyperparameters, such as the entropy regularization term for the manager?
In conclusion, the paper presents a compelling and innovative approach to adaptive computation in RL. While there are areas for improvement, the contributions are significant, and the results are promising. I recommend acceptance with minor revisions to address clarity and scalability concerns.