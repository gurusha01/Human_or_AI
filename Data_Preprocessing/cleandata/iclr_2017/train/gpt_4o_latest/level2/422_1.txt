The paper introduces Deep Variational Bayes Filters (DVBF), a novel method for unsupervised learning of latent Markovian state-space models from raw non-Markovian sequential data. The authors leverage Stochastic Gradient Variational Bayes (SGVB) to overcome intractable inference distributions, enabling DVBF to handle complex nonlinear data such as image sequences without requiring domain knowledge. The key contributions include enforcing state-space model assumptions for reliable system identification, enabling long-term prediction, and providing a scalable inference mechanism trainable on raw data. The experimental results demonstrate DVBF's ability to recover latent states with full information and achieve stable long-term predictions, outperforming existing methods like Deep Kalman Filters (DKF).
Decision: Accept
The paper is well-motivated, presents significant novelty, and provides robust experimental evidence supporting its claims. The key reasons for acceptance are:
1. Novelty and Innovation: DVBF introduces a reparametrization of transitions that enforces state-space assumptions and prioritizes latent dynamics over reconstruction, addressing a critical limitation in prior methods.
2. Empirical Validation: The experiments, particularly on the pendulum and bouncing ball tasks, convincingly demonstrate DVBF's superiority over DKF in recovering latent states and achieving long-term generative predictions.
Supporting Arguments:
1. Claims and Support: The paper claims that DVBF enforces state-space assumptions, enables realistic long-term prediction, and scales to large datasets. These claims are substantiated through rigorous experiments, including comparisons with DKF. For instance, DVBF outperforms DKF in capturing angular velocity in the pendulum task (RÂ² = 0.916 vs. 0.035) and demonstrates stable predictions beyond training sequence lengths.
2. Usefulness: The method is practically useful for applications requiring latent system identification and long-term prediction, such as control and reinforcement learning. The ability to train directly on raw data without preprocessing is a significant advantage.
3. Field Knowledge and Completeness: The paper demonstrates a strong understanding of the literature, citing relevant works (e.g., VAEs, DKF, E2C) and clearly positioning DVBF within this context. The technical details provided, including equations and implementation specifics, ensure reproducibility.
Suggestions for Improvement:
1. Clarity on Limitations: While the paper acknowledges the limitations of competing methods, it does not explicitly discuss potential limitations of DVBF, such as computational overhead or sensitivity to hyperparameters. Including this discussion would strengthen the paper.
2. Broader Evaluation: The experiments focus on simulated environments with known ground truth. Testing DVBF on real-world datasets would enhance its practical relevance.
3. Comparison with Additional Baselines: While DKF is a suitable baseline, including results from other state-of-the-art methods (e.g., E2C, Johnson et al. (2016)) would provide a more comprehensive evaluation.
Questions for the Authors:
1. How does DVBF perform on real-world datasets with noisy or incomplete observations? Are there any challenges in scaling the method to such scenarios?
2. Can the authors provide more details on the computational cost of DVBF compared to DKF, particularly in terms of training time and memory requirements?
3. How sensitive is DVBF to the choice of priors and hyperparameters, such as the annealing schedule or latent space dimensionality?
In conclusion, the paper makes a strong contribution to the field of unsupervised learning for dynamical systems, and its innovative approach is well-supported by theoretical and empirical evidence. Addressing the suggested improvements would further enhance its impact.