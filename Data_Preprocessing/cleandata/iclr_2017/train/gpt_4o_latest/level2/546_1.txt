The paper proposes a novel neural network architecture, the Equation Learner (EQL), designed to learn interpretable analytical expressions for regression tasks and to generalize beyond the training domain (extrapolation). The authors claim two main contributions: (1) introducing the EQL network, which incorporates sparsity regularization to produce concise and interpretable expressions, and (2) a model selection strategy tailored for extrapolation tasks. The paper demonstrates the effectiveness of EQL through experiments on synthetic and real-world datasets, including physical systems like pendulums, robotic arms, and atomic x-ray transition energies.
Decision: Accept  
The paper presents a significant and novel contribution to the field of machine learning by addressing the underexplored problem of extrapolation in regression tasks with a focus on interpretability. The proposed EQL network is well-motivated, and the experimental results convincingly support the claims of improved extrapolation performance and interpretability compared to baseline methods like MLPs and SVRs. However, there are areas where the paper could be improved, as detailed below.
Supporting Arguments:  
1. Novelty and Motivation: The paper addresses a critical gap in machine learningâ€”learning interpretable models that can extrapolate to unseen domains. The use of sparsity regularization and the inclusion of domain-relevant nonlinearities (e.g., sine, cosine, and multiplication units) are innovative and well-justified for physical systems.  
2. Experimental Validation: The experiments on synthetic and real-world datasets demonstrate the EQL's ability to recover true functional forms and outperform baselines in extrapolation tasks. The results are robust across various settings, including noise levels and data sparsity.  
3. Practical Usefulness: The EQL's ability to produce interpretable models is particularly valuable for applications in the natural sciences and engineering, where understanding the underlying mechanisms is crucial.  
Additional Feedback for Improvement:  
1. Reproducibility: While the paper mentions that the code will be made public upon acceptance, providing a link to a repository or including pseudocode would enhance reproducibility.  
2. Limitations: The paper acknowledges that the EQL struggles when the true function lies outside its hypothesis class (e.g., division operations). However, a more detailed discussion of these limitations and potential solutions (e.g., incorporating additional base functions) would strengthen the paper.  
3. Comparison to Symbolic Regression: While the paper briefly mentions symbolic regression, a more detailed comparison, including computational complexity and scalability, would provide additional context for the EQL's advantages.  
4. Clarity of Model Selection: The ranking-based sparsity and validation error trade-off is novel but could benefit from a more detailed explanation or visual examples in the main text, rather than relegating this to the appendix.
Questions for the Authors:  
1. How does the EQL handle cases where the true function involves operations (e.g., division, logarithms) not included in the current architecture? Are there plans to extend the hypothesis class?  
2. Could the authors provide more details on the computational efficiency of EQL compared to symbolic regression methods, especially for high-dimensional datasets?  
3. How sensitive is the EQL to hyperparameter choices (e.g., regularization strength, number of layers)? Are there guidelines for selecting these parameters in practice?
In conclusion, the paper makes a strong contribution to the field by introducing a novel approach to interpretable function learning with extrapolation capabilities. While some areas could be clarified or expanded, the work is well-executed and highly relevant to both theoretical and applied machine learning communities.