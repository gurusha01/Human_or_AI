Summary:
In this paper, the authors introduce NoiseOut, a way to reduce parameters by pruning neurons from a network. 
They do this by identifying pairs of neurons produce the most correlated outputs, and replacing the pair by one neuron, and then appropriately adjusting weights.
This technique relies on neurons having high correlations however, so they introduce an additional output neuron -- a noise output, which results in the network trying to predict the mean of the noise distribution.
As this is a constant, it increases correlation between neurons.
Experiments test this out on MNIST and SVHN
Comments:
This is an interesting suggestion on how to prune neurons, but more experiments (on larger datasets) are probably need to be convincing that this is an approach that is guaranteed to work well. 
Equation (5) seems to be very straightforwards?
It seems like that for larger datasets, more noise outputs might have to be added to ensure higher correlations? Is there a downside to this in terms of the overall accuracy?
The paper is presented clearly, and was definitely interesting to read, so I encourage the authors to continue this line of work.