The concept of data augmentation in the embedding space is very interesting. The method is well presented and also justified on different tasks such as spoken digits and image recognition etc.
One comments of the comparison is the use of a simple 2-layer MLP as the baseline model throughout all the tasks. It's not clear whether the gains maintain when a more complex baseline model is used. 
Another comment is that the augmented context vectors are used for classification, just wondering how does it compare to using the reconstructed inputs. And furthermore, as in Table 4, both input and feature space extrapolation improves the performance, whether these two are complementary or not?