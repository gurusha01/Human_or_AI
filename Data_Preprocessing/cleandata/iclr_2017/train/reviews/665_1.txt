Paper Summary: 
This paper presents a new large scale machine reading comprehension dataset called MS MARCO. It is different from existing datasets in that the questions are real user queries, the context passages are real web documents, and free form answers are generated by humans instead of spans in the context. The paper also includes some analysis of the dataset and performance of QA models on the dataset.
Paper Strengths: 
-- The questions in the dataset are real queries from users instead of humans writing questions given some context.
-- Context passages are extracted from real web documents which are used by search engines to find answers to the given query.
-- Answers are generated by humans instead of being spans in context.
-- It is large scale dataset, with an aim of 1 million queries. Current release includes 100,000 queries.
Paper Weaknesses: 
-- The authors say, "We have found that the distribution of actual questions users ask intelligent agents can be very different from those conceived from crowdsourcing them from the text.", but the statement is not backed up with any study.
-- The paper doesn't clearly present what additional information can today's QA models learn from MS MARCO which they can't from existing datasets. 
-- The paper should talk about what challenges are involved in obtaining a good performance on this dataset.
-- What are the human performances as compared to the models presented in the paper?
-- In section 4.1, what are the train/test splits? The results are for the subset of MS MARCO where every query has multiple answers. How big is that subset?
-- What is DSSM mentioned in row 2, Table 5?
-- The authors should include in the paper how experiments in section 4.2 prove that MS MARCO is a better dataset.
-- In Table 6, the performance of Memory Networks is already close to Best Passage. Does that mean there is not enough room for improvement there?
-- The paper seems to be written in hurry, with partial analysis, evaluation and various mistakes in the text.
Preliminary Evaluation: 
The proposed dataset MS MARCO is unique from existing datasets as it is a good representative of the QA task encountered by search engines. I think it can be a very useful dataset for the community to benefit from. Given the huge potential in the dataset, this paper lacks the analysis and evaluation needed to present the dataset's worth. I think it can benefit a lot with a more comprehensive analysis of the dataset.