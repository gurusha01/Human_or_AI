The paper presents an application of a tensor factorization to linear models, which allows to consider higher-order interactions between variables in classification (and regression) problems, and that maintains computational feasibility, being linear in the dimension. The factorization employed is based on the TT format, first proposed by Oseledests (2011). The authors also propose the adoption of a Riemannian optimization scheme to explicit consider the geometry of the tensor manifold, and thus speed up convergence.
The paper in general is well written, it presents an interesting application of the TT tensor format for linear models (together with an application of Riemannian optimization), which in my opinion is quite interesting since it has a wide range of possible applications in different algorithms in machine learning.
On the other side, I have some concerns are about the experimental part, which I consider not at the level of the rest of the paper, for instance in terms of number of experiments on real datasets, role of dropout in real datasets, comparison with other algorithms on real datasets. Moreover the authors do not take into account explicitly the problem of the choice of the rank to be used in the experiments. In general the experimental section seems a collection of preliminary experiments where different aspects have been tested by not in a organic way.
I think the paper is close to a weak acceptance / weak rejection, I don't rate it as a full acceptance paper, mainly due to the non-satisfactory experiment setting. In case of extra experiments confirming the goodness of the approach, I believe the paper could have much better scores.
Some minor comments:
-formula 2: Obvious comment: learning the parameters of the model in (1) can be done as in (2), but also in other ways, depending on the approach you are using.
-the fact that the rank is bounded by 2r, before formula 9, is explained in Lubich et al., 2015?
-after formula 10: why the N projections in total they cost O(dr^2(r+N)), it should be O(Ndr^2(r+1)), no? since each of the elements of the summation has rank 1, and the cost for each of them is O(dr^2(r+TT_rank(Z)^2)), where TT-rank(Z)=1. Am I wrong?
-section 6.2: can you explain why the random initialization freezes the convergence? This seems interesting but not motivated. Any guess?
-section 6.3: you adopt dropout: can you comment in particular on the advantages it gives in the context of the exponential machines? did you use it on real datasets?
-how do you choose r_0 in you experiments? with a validation set?
-in section 7: why you don't have x1 x2 among the variables?
-section 8: there is a typo in "experiments"
-section 8.1: "We simplicity, we binarized" I think there's a problem with the English language in this sentence
-section 8.3: "we report that dropout helps".. this is quite general statement, only tested on a synthetic dataset
-section 8.5: can you provide more results for this dataset, for instance in terms of training and inference time? or test wrt other algorithms?