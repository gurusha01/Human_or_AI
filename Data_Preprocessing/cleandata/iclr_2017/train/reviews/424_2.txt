This paper first discusses a general framework for improving optimization of a complicated function using a series of approximations. If the series of approximations are well-behaved compared to the original function, the optimization can in principle be sped up. This is then connected to a particular formulation in which a neural network can behave as a simpler network at high noise levels but regain full capacity as training proceeds and noise lowers.
The idea and motivation of this paper are interesting and sound. As mentioned in my pre-review question, I was wondering about the relationship with shaping methods in RL. I agree with the authors that this paper differs from how shaping typically works (by modifying the problem itself) because in their implementation the architecture is what is "shaped". Nevertheless, the central idea in both cases is to solve a series of optimization problems of increasing difficulty. Therefore, I strongly suggest including a discussion of the differences between shaping, curriculum learning (I'm also not sure how this is different from shaping), and the present approach.
The presentation of the method for neural networks lacks clarity in presentation. Improving this presentation will make this paper much easier to digest. In particular:
- Alg. 1 can not be understood at the point that it is referenced. 
- Please explain the steps to Eq. 25 more clearly and connect to steps 1-6 in Alg. 1.
- Define u(x) clearly before defining u*(x)
There are several concerns with the experimental evaluations. There should be a discussion about why doesn't the method work for solving much more challenging network training problems, such as thin and deep networks. Some specific concerns:
- The MLPs trained (Parity and Pentomino) are not very deep at all. An experiment of training thin networks with systematically increasing depth would be a better fit to test this method. Network depth is well known to pose optimization challenges. Instead, it is stated without reference that "Learning the mapping from sequences of characters to the word-embeddings is a difficult problem."
- For cases where the gain is primarily due to the regularization effect, this method should be compared to other weight noise regularization methods.
- I also suggest comparing to highway networks, since there are thematic similarities in Eq. 22, and it is possible that they can automatically anneal their behavior from simple to complex nets during training, considering that they are typically initialized with a bias towards copying behavior.
- For CIFAR-10 experiment, does the mollified model also use Residual connections? If so, why? In either case, why does the mollified net actually train slower than the residual and stochastic depth networks? This is inconsistent with the MLP results.
Overall, the ideas and developments in this paper are promising, but it needs more work to be a clear accept for me.