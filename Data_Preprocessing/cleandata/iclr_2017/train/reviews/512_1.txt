This paper provides a principled framework for nonparametrically learning activation
functions in deep neural networks. A theoretical justification for authors' choice of 
nonparametric activation functions is given. 
Theoretical results are satisfactory but I particularly like the experimental setup
where their methods are tested on image
recognition datasets and achieve up to a 15% relative increase in test performance
compared to the baseline.
Well-written paper and novel theoretical techniques. 
The intuition behind the proof of Theorem 4.7 can be given in a little bit more clear way in the main body of the paper, but the
Appendix clarifies everything.