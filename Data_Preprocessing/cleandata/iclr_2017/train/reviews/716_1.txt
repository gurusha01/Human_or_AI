Paper summary: this work presents ENet, a new convnet architecture for semantic labeling which obtains comparable performance to the previously existing SegNet while being ~10x faster and using ~10x less memory. 
Review summary: Albeit the results seem interesting, the paper lacks detailed experimental results, and is of limited interest for the ICLR audience.
Pros:
* 10x faster
* 10x smaller
* Design rationale described in detail
Cons:
* The quality of the reference baseline is low. For instance, cityscapes results are 58.3 IoU while state of the art is ~80 IoU. Thus the results are of limited interest.
* The results that support the design rationale are not provided. It is important to provide the experimental evidence to support each claim.
Quality: the work is interesting but feels incomplete. If your model is 10x faster and smaller, why not try build a model 10x longer to obtain improved results ? The paper focuses only on  nimbleness at the cost of quality (using a weak baseline). This limits the interest for the ICLR audience.
Clarity: the overall text is somewhat clear, but the model description (section 3) could be more clear. 
Originality: the work is a compendium of "practitioners wisdom" applied to a specific task. It has thus limited originality.
Significance: I find the work that establishes a new "best practices all in one" quite interesting, but however these must shine in all aspects. Being fast at the cost of quality, will limit the impact of this work.
Minor comments:
* Overall the text is proper english but the sentences constructions is often unsound, specific examples below. 
* To improve the chances of acceptance, I invite the authors to also explore bigger models and show that the same "collected wisdom" can be used both to reach high speed and high quality (with the proper trade-off curve being shown). Aiming for only one end of the quality versus speed curve limits too much the paper.
* Section 1: "mobile or battery powered … require rates > 10 fps". 10 fps with which energy budget ? Should not this be  > 10 fps && < X Watt.
* "Rules and ideas" -> rules seem too strong of a word, "guidelines" ?
* "Is of utmost importance" -> "is of importance" (important is already important)
* "Presents a trainable network … therefore we compare to … the large majority of inference the same way"; the sentence makes no sense to me, I do not see the logical link between before and after "therefore"
* Scen-parsing -> scene-parsing
* It is arguable if encoder and decoder can be called "separate"
* "Unlike in Noh" why is that relevant ? Make explicit or remove
* "Real-time" is vague, you mean X fps @ Y W ?
* Other existing architectures -> Other architectures
* Section 3, does not the BN layer include a bias term ? Can you get good results without any bias term ?
* Table 1: why is the initial layer a downsampling one, since the results has half the size of the input ?
* Section 4, non linear operations. What do you mean by "settle to recurring pattern" ?
* Section 4, dimensionality changes. "Computationally expensive", relative to what ?
* Section 4, dimensionality changes. "This technique ... speeds-up ten times", but does not provide the same results. Without an experimental validation changing an apple for an orange does not make the orange better than the apple.
* Section 4, dimensionality changes. "Found one problem", problem would imply something conceptually wrong. This is more an "issue" or an "miss-match" when using ResNet for semantic labelling.
* Section 4, factorizing filters. I am unsure of why you call nx1 filter asymmetric. A filter could be 1xn yet be symmetric (e.g. -2 -1 0 1 2). Why not simply call them rectangular filters ?
* Section 4, factorizing filters. Why would this change increase the variety ? I would have expected the opposite.
* Section 4, regularization. Define "much better".
* Section 5.1; "640x360 is adequate for practical applications"; for some applications.
* Section 5.2, "very quickly" is vague and depends on the reader expectations, please be quantitative.
* Section 5.2, Haver -> have
* Section 5.2, in this work -> In this work
* Section 5.2, unclear what you use the class weighting for. Is this for class balancing ?
* Section 5.2, Cityscapes was -> Cityscapes is
* Section 5.2, weighted by the average -> is each instance weighted relative the average object size.
* Section 5.2, fastest model in the Cityscapes -> fastest model in the public Cityscapes