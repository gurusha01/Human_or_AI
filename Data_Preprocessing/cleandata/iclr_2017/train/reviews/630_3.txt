This work explores the neural models for sentence summarisation by using a read-again attention model and a copy mechanism which grants the ability of direct copying word representations from the source sentences. The experiments demonstrate the model achieved better results on DUC dataset. Overall, this paper is not well-written. There are confusing points, some of the claims are lack of evidence and the experimental results are incomplete. 
Detailed comments:
 
-Read-again attention. How does it work better than a vanilla attention? What would happen if you read the same sentences multiple times? Have you compared it with staked LSTM (with same number of parameters)? There is no model ablation in the experiment section. 
-Why do you need reading two sentences? The Gigaword dataset is a source-to-compression dataset which does not need multiple input sentences. How do you compare your model with single sent input and two sent input?
-Copy mechanism. What if there are multiple same words appeared in the source sentences to be copied? According to equation (5), you only copy one vector to the decoder. However, there is no this kind of issue for a hard copy mechanism. Besides, there is no comparison between the hard copy mechanism and this vector copy mechanism in the experiment section
-Vocabulary size. This part is a bit off the main track of this paper. If there is no evidence showing this is the special property of vector copy mechanism, it would be trivial in this paper. 
-Experiments. On the DUC dataset, it compares the model with other up-to-date models, while on the Gigaword dataset paper only compares the model with the ABS Rush et al. (2015) and the GRU (?), which are quite weak baseline models. It is irresponsible to claim this model achieved the state-of-the-art performance in the context of summarization.
Typos: (1) Tab. 1. -> Table 1. (2) Fig. 3.1.2.?