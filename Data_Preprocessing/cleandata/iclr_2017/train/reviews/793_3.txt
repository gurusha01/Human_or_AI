This paper proposes to leverage "surprisal" as top-down signal in RNN. More specifically author uses the error corresponding to the previous prediction as an extra input at the current timestep in a LSTM.
The general idea of suprising-driven feedback is interesting for online prediction task. It is a simple enough idea that seems to bring some significant improvements. However, the paper in its current form has some important flaws.
- Overall, the paper writing could be improved. In particular, section 2.4 and 2.5 is composed mostly by the equations of the forward and backward propagation of feedback RNN and feedback LSTM. However, author provides no analysis along with those equations. It is therefore not clear what insight the author tries to express in those sections. In addition, feedback RNN is not evaluated in the experimental section, so it is not clear why feedback RNN is described.
- The experimental evaluation is limited. Only one dataset enwik8 is explored. I think it is necessary to try the idea on different datasets to see if feedback LSTM sees some consistent improvements.
Also, author claims state-of-art on enwik8, but hypernetwork, already cited in the paper, achieves better results (1.34 BPC, table 4 in the hypernetworks paper).
- Author only compares to methods that do not use last prediction error as extra signal. I would argue that a comparison with dynamic evaluation would be more fair. 
 Feedback LSTM uses prediction error as extra input in the forward prop, while dynamic evaluation  backprop it through the network and change the weight accordingly. Also they don't propagate the prediction error in the same way, they both leverage "extra" supervised information through the prediction errors.
In summary:
Pros: 
- Interesting idea
- Seems to improve performances
Cons:
- Paper writing
- Weak evaluation (only one dataset)
- Compare only with approaches that does not use the last-timestep error signal