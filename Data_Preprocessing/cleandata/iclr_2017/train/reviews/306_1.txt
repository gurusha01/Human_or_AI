This work presents an LSTM based meta-learning framework to learn the optimization algorithm of a another learning algorithm (here a NN).
The paper is globally well written and the presentation of the main material is clear. The crux of the paper: drawing the parallel between Robbins Monroe update rule and the LSTM update rule and exploit it to satisfy the two main desiderata of few shot learning (1- quick acquisition of new knowledge, 2- slower extraction of general transferable knowledge) is intriguing. 
Several tricks re-used from (Andrychowicz et al. 2016)  such as parameter sharing and normalization, and novel design choices (specific implementation of batch normalization) are well  motivated. 
The experiments are convincing. This is a strong paper. My only concerns/questions are the following:
1. Can it be redundant to use the loss, gradient and parameters as input to the meta-learner? Did you do ablative studies to make sure simpler combinations are not enough.
2. It would be great if other architectural components of the network can be learned in a similar fashion (number of neurons, type of units, etc.). Do you have an opinion about this?
3. The related work section (mainly focused on meta learning) is a bit shallow. Meta-learning is a rather old topic and similar approaches have been tried to solve the same problem even if they were not using LSTMs:
     - Samy Bengio PhD thesis (1989) is all about this ;-)
     - Use of genetic programming for the search of a new learning rule for neural networks (S. Bengio, Y. Bengio, and J. Cloutier. 1994)
     - I am convince Schmidhuber has done something, make sure you find it and update related work section.  
Overall, I like the paper. I believe the discussed material is relevant to a wide audience at ICLR.