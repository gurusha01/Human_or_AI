The present submission discusses a "causal regularizer", which promotes the use of causal dependencies (X -> Y, where X is a feature of the learning problem, and Y is the target variable) in predictive models. Similarly, such causal regularizer penalizes the use of non-causal dependencies, which can arise due to reverse causation (Y -> X) or confounding (X <- Z -> Y, where Z is a hidden confounder).
+ Overall, this submission tackles one of the most important problems in machine learning, which is to build causal models. The paper discusses and addresses this issue effectively when applied to a dataset in heart disease. In their experiments, the authors correctly identify some of the common causes of heart disease by virtue of their causal regularizer.
- The authors do not discuss the robustness of their approach with respect to choice of hyper-parameters (both describing the neural network architecture and the generative model that synthesizes artificial causal data). This seems like a crucial issue, in particular when dealing with medical data.
- The conclusions of the experimental evaluation should be discussed in greater length. On the one hand, Figure 4.a shows that there are no differences between L1 and causal regularization in terms of predictive performance, but it is difficult to conclude if this result is statistically significant without access to error-bars. On the other hand, Table 3 describes the qualitative differences between L1 and causal regularization. However, this table is hard to read: How were the 30 rows selected? What does the red highlighting mean? Are these red rows some true causal features that were missed? If so, this is related to precision. What about recall? Did the causal regularization pick up many non-causal features as causal?
- Regarding causal classifiers, this paper should do a much better job at reviewing previous work. For instance, the paper "Towards a Learning Theory of Cause-Effect Inference" from Lopez-Paz et al. is missing from the references. However, this prior work studies many of the aspects that are hinted as novel in this submission. In particular, the prior work of Lopez-Paz 1) introduces the concept of Mother distribution (referred as Nature hyper-prior in this submission) which explicitly factorizes the distribution over causes and mechanisms, 2) circumvented intractable likelihoods by synthesizing and training on causal data, 3) tackled the confounding case (compare Figure 1 of this submission and Appendix C of Lopez-Paz), and 4) dealt with discrete data seamlessly (such as the ChaLearn data from Section 5.3 in Lopez-Paz).
On a positive note, this is a well-written paper that addresses the important, under-appreciated problem of incorporating causal reasoning into machine learning. On a negative note, the novelty of the technical contributions is modest and the qualitative evaluation of the results could be greatly extended. In short, I am leaning slightly towards acceptance.
While the paper provides enough detail to re-implement the proposed methods, there is no discussion as to whether the heart failure dataset will be released. This would be key for reproducibility.