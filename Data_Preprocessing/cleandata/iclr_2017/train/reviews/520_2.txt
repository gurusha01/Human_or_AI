This work focuses on conditional image synthesis in the autoregressive framework.  Based on PixelCNN, it trains models that condition on text as well as segmentation masks or keypoints.  Experiments show results for keypoint conditional synthesis on the CUB (birds) and MHP (human pose) dataset, and segmentation conditional synthesis on MS-COCO (objects).  This extension to keypoint/segment conditioning is the primary contribution over existing PixelCNN work.  Qualitative comparison is made to GAN approaches for synthesis.
Pros:
(1) The paper demonstrates additional capabilities for image generation in the autoregressive framework, suggesting that it can keep pace with the latest capabilities of GANs.
(2) Qualitative comparison in Figure 9 suggests that PixelCNN and GAN-based methods may make different kinds of mistakes, with PixelCNN being more robust against introducing artifacts.
(3) Some effort is put forth to establish quantitative evaluation in terms of log-likelihoods (Table 1).
Cons:
(1) Comparison to other work is difficult and limited to qualitative results.  The qualitative results can still be somewhat difficult to interpret.  I believe supplementary material or an appendix with many additional examples could partially alleviate this problem.
(2) The extension of PixelCNN to conditioning on additional data is fairly straightforward.  This is a solid engineering contribution, but not a surprising new concept.