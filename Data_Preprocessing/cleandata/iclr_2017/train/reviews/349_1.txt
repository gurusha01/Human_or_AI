This paper proposed an integration of memory network with reinforcement learning. The experimental data is simple, but the model is very interesting and relatively novel. There are some questions about the model:
1. how does the model extend to the case with multiple variables in a single sentence?
2. If the answer is out of vocabulary, how would the model handle it?
3. I hope the authors can provide more analysis about the curriculum learning part, since it is very important for the RL model training.
4. In the training, in each iteration, how the data samples were selected, by random or from simple one depth to multiple depth?