(paper summary) The authors introduce the notion of "sample importance", meant to measure the influence of a particular training example on the training of a deep neural network. This quantity is closely related to the squared L2 norm of the gradient, where the summation is performed over (i) parameters of a given layer or (ii) across all parameters. Summing this quantity across time gives the "overall importance", used to tease apart easy from hard examples. From this quantity, the authors illustrate the impact of [easy,hard] example during training, and their impact on layer depth.
(detailed review)
I have several objections to this paper. First and foremost, I am not convinced of the "sample importance" as a meaningful metric. As previously mentioned, the magnitude of gradients will change significantly during learning, and I am not sure what conclusions one can draw from \sumt gi^t vs \sumt gj^t. For example, gradients tend to have higher norms early in training than at convergence, in which case weighting each gradient equally seems problematic. I tried illustrating the above with a small thought experiment during the question period: "if" the learning rate were too high, training may not even converge in which case sample importance would be ill-defined.  Having a measure which depends on the learning rate seems problematic to me, as does the use of the L2 norm. The "input Fisher" norm, \mathbb{E} \frac{\partial \log p} {\partial x} (for a given time-step) may be better suited, as it speaks directly to the sensitivity of the classifier to the input x (and is insensitive to changes in the mean gradient norm). But again summing Fisher norms across time may not be meaningful.
The experimental analysis also seems problematic. The authors claim from Fig. 2 that output layers are primarily learnt in the early stage of training. However, this is definitely not the case for CIFAR-10 and is debatable for MNIST: sample importance remains high for all layers during training, despite a small spike early on the output layer. Fig 2. (lower, middle) and Fig. 6 also seems to highlight an issue with the SI measure: the SI is dominated by the input layer which has the most parameters, and can thus more readily impact the gradient norm. Different model architectures may have yielded different conclusions. Had the authors managed to use the SI to craft a better curriculum, this would have given significant weight to the measure. Unfortunately, these results are negative.
PROS:
+ extensive experiments
CONS:
- sample importance is a heuristic, not entirely well justified
- SI yields limited insight into training of neural nets
- SI does not inform curriculum learning