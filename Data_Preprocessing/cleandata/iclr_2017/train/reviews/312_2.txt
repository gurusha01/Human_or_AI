This paper presents search for optimal neural-net architectures based on actor-critic framework. The method treats DNN as a variable length sequence, and uses RL to find the target architecture, which acts as an actor. The node selection is an action in the RL context, and evaluation error of the outcome architecture corresponds to reward. A auto-regressive two-layer LSTM is used as a controller and critic. The method is evaluated on two different problems, and each compared with number of other human-created architectures.
This is very exciting paper! Hand selecting architectures is difficult, and it is hard to know how far from optimal results the hand-designed networks are. The presented method is  novel. The authors do an excellent job of describing it in detail, with all the improvements that needed to be done. The tested data represents well the capability of the method. It is very interesting to see the differences between the generated architectures and human generated ones. The paper is written very clearly, and is very accessible. The coverage and contrast with the related literature is done well.
It would be interesting to see the data about the time needed for training, and correlation between time/resources needed to train and the quality of the model. It would also be interesting to see how human bootstrapped models perform and involve.
Overall, an excellent and interesting paper.