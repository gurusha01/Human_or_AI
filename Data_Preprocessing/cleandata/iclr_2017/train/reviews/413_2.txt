The paper presents a method to improve the efficiency of CNNs that encode sequential inputs in a 'slow' fashion such that there is only a small change between the representation of adjacent steps in the sequence.
It demonstrates theoretical performance improvements for toy video data (temporal mnist) and natural movies with a powerful Deep CNN (VGG). 
The improvement is naturally limited by the 'slowness' of the CNN representation that is transformed into a sigma-delta network: CNNs that are specifically designed to have 'slow' representations will benefit most. Also, it is likely that only specialised hardware can fully harness the improved efficiency achieved by the proposed method. Thus as of now, the full potential of the method cannot be thoroughly evaluated.
However, since the processing of sequential data seems to be a broad and general area of application, it is conceivable that this work will be useful in the design and application of future CNNs.
All in all, this paper introduces an interesting idea to address an important topic. It shows promising initial results, but the demonstration of the actual usefulness and relevance of the presented method relies on future work.