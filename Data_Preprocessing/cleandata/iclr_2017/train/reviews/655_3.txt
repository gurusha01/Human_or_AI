This paper proposed to use the BPA criterion for classifier ensembles.
My major concern with the paper is that it attempts to mix quite a few concepts together, and as a result, some of the simple notions becomes a bit hard to understand. For example:
(1) "Distributed" in this paper basically means classifier ensembles, and has nothing to do with the distributed training or distributed computation mechanism. Granted, one can train these individual classifiers in a distributed fashion but this is not the point of the paper.
(2) The paper uses "Transfer learning" in its narrow sense: it basically means fine-tuning the last layer of a pre-trained classifier.
Aside from the concept mixture of the paper, other comments I have about the paper are:
(1) I am not sure how BPA address class inbalance better than simple re-weighting. Essentially, the BPA criteria is putting equal weights on different classes, regardless of the number of training data points each class has. This is a very easy thing to address in conventional training: adding a class-specific weight term to each data point with the value being the inverse of the number of data points will do.
(2) Algorithm 2 is not presented correctly as it implies that test data is used during training, which is not correct: only training and validation dataset should be used. I find the paper's use of "train/validation" and "test" quite confusing: why "train/validation" is always presented together? How to properly distinguish between them?
(3) If I understand correctly, the paper is proposing to compute the BPA in a batch fashion, i.e. BPA can only be computed when running the model over the full train/validation dataset. This contradicts with the stochastic gradient descent that are usually used in deep net training - how does BPA deal with that? I believe that an experimental report on the computation cost and timing is missing.
In general, I find the paper not presented in its clearest form and a number of key definitions ambiguous.