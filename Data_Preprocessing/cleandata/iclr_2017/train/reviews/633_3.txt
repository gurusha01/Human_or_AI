This paper proposed a new joint training scheme for two probabilistic models of signals (e.g. images) which are both deep neural network based and are termed generator and descriptor networks.  In the new scheme, termed cooperative training, the two networks train together and assist each other: the generator network provides samples that work as initial samples for the descriptor network, and the descriptor network updates those samples to help guide training of the generator network.
This is an interesting approach for coupling the training of these two models.  The paper however is quite weak on the empirical studies.  In particular:
- The training datasets are tiny, from sets of 1 image to 5-6.  What is the reason for not using larger sets?  I think the small datasets are leading to over training and are really masking the true value of the proposed cooperative training approach.
- For most of the experiments presented in the paper it is hard to assess the specific value brought by the proposed cooperative training approach because baseline results are missing.  There are comparisons provided for face completion experiments - but even there comparisons with descriptor or generator network trained separately or with other deep auto-encoders are missing.  Thus it is hard to conclude if and how much gain is obtained by cooperative training over say individually training the descriptor and generator networks.
Another comment is that in the "related work" section, I think relation with variational auto encoders (Kingma and Welling 2013) should be included.
Despite limitations mentioned above, I think the ideas presented in the paper are intuitively appealing and worth discussing at ICLR.  Paper would be considerably strengthened by adding more relevant baselines and addressing the training data size issues.