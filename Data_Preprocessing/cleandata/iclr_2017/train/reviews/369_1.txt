The paper shows a different approach to a ternary quantization of weights.
Strengths:
1. The paper shows performance improvements over existing solutions
2. The idea of learning the quantization instead of using pre-defined human-made algorithm is nice and very much in the spirit of modern machine learning.
Weaknesses:
1. The paper is very incremental.
2. The paper is addressed to a very narrow audience. The paper very clearly assumes that the reader is familiar with the previous work on the ternary quantization. It is "what is new in the topic" update, not really a standalone paper. The description of the main algorithm is very concise, to say the least, and is probably clear to those who read some of the previous work on this narrow subject, but is unsuitable for a broader deep learning audience.
3. There is no convincing motivation for the work. What is presented is an engineering gimmick, that would be cool and valuable if it really is used in production, but is that really needed for anything? Are there any practical applications that require this refinement? I do not find the motivation "it is related to mobile, therefore it is cool" sufficient.
This paper is a small step further in a niche research, as long as the authors do not provide a sufficient practical motivation for pursuing this particular topic with the next step on a long list of small refinements, I do not think it belongs in ICLR with a broad and diversified audience.
Also - the code was not released is my understanding.