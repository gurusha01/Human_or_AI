The authors did not bother responding or fixing any of the pre-review comments. Hence I repeat here:
Please do not make incredibly unscientific statements like this one:
"The working procedure of this model is just like how we human beings read a text and then answer a related question. "
Really, "humans beings" have an LSTM like model to read a text? Can you cite an actual neuroscience paper for such a claim? The answer is no, so please delete such statements from future drafts.
Generally, your experiments are about simple classification and the methods you're competing against are simple models like NB-SVM. So I would change the title, abstract ad introduction accordingly and not attempt hyperbole like "Learning to Understand" in the title.
Lastly, your attention level approach seems similar to dynamic memory networks by Kumar et al. they also have experiments for sentiment and it would be interesting to understand the differences to your model and compare to them.
Other reviewers included further missing related work and fitting this paper into the context of current literature.
Given that no efforts were made to fix the pre-review questions and feedback, I doubt this will become ready in time for publication.