Summary
===
This paper proposes the Neural Physics Engine (NPE), a network architecture
which simulates object interactions. While NPE decides to explicitly represent
objects (rather than video frames), it incorporates knowledge of physics
almost exclusively through training data. It is tested in a toy domain with
bouncing 2d balls.
The proposed architecture processes each object in a scene one at a time.
Pairs of objects are embedded in a common space where the effect of the
objects on each other can be represented. These embeddings are summed
and combined with the focus object's state to predict the focus object's
change in velocity. Alternative baselines are presented which either
forego the pairwise embedding for a single object embedding or
encode a focus object's neighbors in a sequence of LSTM states.
NPE outperforms the baselines dramatically, showing the importance of
architecture choices in learning to do this object based simulation.
The model is tested in multiple ways. Ability to predict object trajectory
over long time spans is measured. Generalization to different numbers of objects
is measured. Generalization to slightly altered environments (difference
shaped walls) is measured. Finally, the NPE is also trained to predict
object mass using only interactions with other objects, where it also
outperforms baselines.
Comments
===
* I have one more clarifying question. Are the inputs to the blue box in
figure 3 (b)/(c) the concatenation of the summed embeddings and state vector
of object 3? Or is the input to the blue module some other combination of the
two vectors?
* Section 2.1 begins with "First, because physics does not
change across inertial frames, it suffices to separately predict the future state of each object conditioned
on the past states of itself and the other objects in its neighborhood, similar to Fragkiadaki
et al. (2015)."
I think this is an argument to forego the visual representation used by previous
work in favor of an object only representation. This would be more clear if there
were contrast with a visual representation.
* As addressed in the paper, this approach is novel, though less so after taking
into consideration the concurrent work of Battaglia et. al. in NIPS 2016 titled
"Interaction Networks for Learning about Objects, Relations and Physics."
This work offers a different network architecture and set of experiments, as
well as great presentation, but the use of an object based representation
for learning to predict physical behavior is shared.
Overall Evaluation
===
This paper was a pleasure to read and provided many experiments that offered
clear and interesting conclusions. It offers a novel approach (though
less so compared to the concurrent work of Battaglia et. al. 2016) which
represents a significant step forward in the current investigation of
intuitive physics.