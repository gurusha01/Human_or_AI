The paper presents an action-conditional recurrent network that can predict frames in video games hundreds of steps in the future. The paper claims three main contributions: 
1. modification to model architecture (used in Oh et al.) by using action at time t-1 to directly predict hidden state at t
2. exploring the idea of jumpy predictions (predictions multiple frames in future without using intermediate frames)
3. exploring different training schemes (trade-off between observation and prediction frames for training LSTM)
1. modification to model architecture
+ The motivation seems good that in past work (Oh et al.) the action at t-1 influences xt, but not the state ht of the LSTM. This could be fixed by making the LSTM state ht dependent on a{t-1}
- However, this is of minor technical novelty. Also, as pointed in reviewer questions, a similar effect could be achieved by adding at-1 as an input to the LSTM at time t. This could be done without modifying the LSTM architecture as stated in the paper. While the authors claim that combining at-1 with ht-1 and st-1 performs worse than the current method which combines at-1 only with ht-1, I would have liked to see the empirical difference in combining at-1 only with st-1 or only with h_t-1. Also, a stronger motivation is required to support the current formulation.
- Further, the benefits of this change in architecture is not well analyzed in experiments. Fig. 5(a) provides the difference between Oh et al. (with traditional LSTM) and current method. However, the performance difference is composed of 2 components (difference in training scheme and architecture). This contribution of the architecture to the performance is not clear from this experiment. The authors did claim in the pre-review phase that Fig. 12 (a) shows the difference in performance only due to architecture for "Seaquest". However, from this plot it appears that the gain at 100-steps (~15)  is only a small fraction of the overall gain in Fig. 5 (a) (~90). It is difficult to judge the significance of the architecture modification from this result for one game.
2. Exploring the idea of jumpy predictions:
+ As stated by the authors, omitting the intermediate frames while predicting future frames could significantly sppedup simulations.
+ The results in Fig. 5(b) present some interesting observations that omitting intermediate frames does not lead to significant error-increase for at least a few games.
- However, it is again not clear whether the modification in the current model leads to this effect or it could be achieved by previous models like Oh et al.
- While, the observations themselves are interesting, it would have been better to provide a more detailed analysis for more games. Also, the novelty in dropping intermediate frames for speedup is marginal.
3. Exploring different training schemes
+ This is perhaps the most interesting observation presented in the paper. The authors present the difference in performance for different training schemes in Fig. 2(a). The training schemes are varied based on the fraction of training phase which only uses observation frames and the fraction that uses only prediction frames.
+ The results show that this change in training can significantly affect prediction results and is the biggest contributor to performance improvement compared to Oh et al.
- While this observation is interesting, this effect has been previously explored in detail in other works like schedule sampling (Bengio et al.) and to some extent in Oh et al.
Clarity of presentation:
- The exact experimental setup is not clearly stated for some of the results. For instance, the paper does not say that Fig. 2(a) uses the same architecture as Oh et al. However, this is stated in the response to reviewer questions.
- Fig. 4 is difficult to interpret. The qualitative difference between Oh et al. and current method could be highlighted explicitly. 
- Minor: The qualitative analysis section requires the reader to navigate to various video-links in order to understand the section. This leads to a discontinuity in reading and is particularly difficult while reading a printed-copy.
Overall, the paper presents some interesting experimental observations. However, the technical novelty and contribution of the proposed architecture and training scheme is not clear.