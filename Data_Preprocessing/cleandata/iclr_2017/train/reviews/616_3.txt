The paper describes a network architecture for inverse problems in computer vision. Example inverse problems considered are image inpainting, computing intrinsic image decomposition and foreground/background separation.
The architecture is composed of (i) a generator that produces target (latent) output (such as foreground / background regions), 
(ii) renderer that composes that latent output back to the image that can be compared with the input to measure reconstruction error, 
and (iii) adversarial prior that ensures the target output (latent) image respects a certain image statistics.
Strong  points.
- The proposed architecture with memory database is interesting and appears to be novel. 
Weak points:
- Experimental results are only proof-of-concept in toy set-ups and do not clearly demonstrate benefits of the proposed architecture.
- It is unclear whether the memory retrieval engine that retrieves images based on L2 distance on pixel values is going generalize to other more realistic scenarios. 
- Clarity. The clarity of explanation can be also improved (see below).
Detailed evaluation.
Originality:
- The novelty of this work lies in the (iii) adversarial prior that places an adversarial loss between the generated latent output and a single image retrieved from a large unlabelled database of target output examples (called memory). The adversarial prior has a convolutional form matching local image statistics, rather than the entire image.  The particular form of network architecture with the memory-based fully convolutional adversarial loss appears to be novel and potentially interesting.
- Motivation for the Architecture. The weakest point of the proposed architecture is the "Memory retrieval engine" R (section 2.4),
where images are retrieved from the memory by measuring L2 distance on pixel intensities. While this maybe ok for simple problems considered in this work, it is unclear how this can generalize to other more complicated datasets and problems.  
This should be better discussed, better justified and ideally results in some more realistic set-up shown (see below).
Quality:
- Experiments. Results are shown for inpainting of MNIST digits, intrinsic image decomposition on the MIT intrinsic image database, and figure/ground layer extraction on the synthesized dataset of 3D chairs rendered onto background from real photographs.  
 The experimental validation of the model is not very strong and proof-of-concept only. All the experiments are performed in simplified toy set-ups. The MNIST digit inpainting is far from current state-of-the-art on image inpainting in real photographs (see e.g. Pathak et al., 2016). The foreground background separation is done on  only synthetically generated test data. Even for intrinsic image demposition problem there is now relatively large-scale dataset of (Bell et al., 2014), see the citation below.  
While this is probably ok for the ICLR paper, it diminishes the significance of the work. Is this model going to be useful in a real settings? One possibility to address this would be to focus on one of the problems and show results on a challenging state-of-the-art data. It would be great to see the benefits of the memory database. 
S. Bell, K. Bala, and N. Snavely. Intrinsic images in the wild.
ACM Transactions on Graphics, 33(4):159, 2014.
Clarity:
- The clarity of the writing can be improved. I found some of the terminology of the paper, specially the "imagination" and "memory" confusing. From figure 2, it is not clear how the "memories" for the given input image are obtained, which also took me some time to understand.
- To help understand the proposed architecture, it would be useful to draw an illustration of what is happening in the "feature space", similar in spirit e.g. to figure 2 in