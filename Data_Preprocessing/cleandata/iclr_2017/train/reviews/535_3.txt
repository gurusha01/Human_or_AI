1) Summary
This paper proposes a video captioning model based on a 3D (space+time) convnet (C3D) encoder and a LSTM decoder. The authors investigate the benefits of using attention mechanisms operating both at the spatio-temporal and layer (feature abstraction) levels.
2) Contributions
+ Well motivated and implemented attention mechanism to handle the different shapes of C3D feature maps (along space, time, and feature dimensions).
+ Convincing quantitative and qualitative experiments on three challenging datasets (Youtube2Text, M-VAD, MSR-VTT) showing clearly the benefit of the proposed attention mechanisms.
+ Interesting comparison of soft vs hard attention showing a slight performance advantage for the (simpler) soft attention mechanism in this case.
3) Suggestions for improvement
Hypercolumns comparison:
As mentioned during pre-review questions, it would be interesting to compare to the hypercolumns of