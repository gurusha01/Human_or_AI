This paper introduces CoopNets, an algorithm which trains a Deep-Energy Model (DEM, the "descriptor") with the help of an auxiliary directed bayes net, e.g. "the generator". The descriptor is trained via standard maximum likelihood, with Langevin MCMC for sampling. The generator is trained to generate likely samples under the DEM in a single, feed-forward ancestral sampling step. It can thus be used to shortcut expensive MCMC sampling, hence the reference to "cooperative training".
The above idea is interesting and novel, but unfortunately is not sufficiently validated by the experimental results. First and foremost, two out of the three experiments do not feature a train /test split, and ignore standard training and evaluation protocols for texture generation (see [R1]). Datasets are also much too small. As such these experiments only seem to confirm the ability of the model to overfit. On the third in-painting tasks, baselines are almost non-existent: no VAEs, RBMs, DEM, etc which makes it difficult to evaluate the benefits of the proposed approach.
In a future revision, I would also encourage the authors to answer the following questions experimentally. What is the impact of the missing rejection step in Langevin MCMC (train with, without ?). What is the impact of the generator on the burn-in process of the Markov chain (show sample auto-correlation). How bad is approximation of training the generator from ({\tilde{Y}, \hat{X}) instead of ({\tilde{Y}, \tilde{X}) ? Run comparative experiments.
The paper would also greatly benefit from a rewrite focusing on clarity, instead of hyperbole ("pioneering work" in reference to closely related, but non-peer reviewed work) and prose ("tale of two nets"). For example, the authors fail to specify the exact form of the energy function: this seems like a glaring omission.
PROS:
+ Interesting and novel idea
CONS:
- Improper experimental protocols
- Missing baselines
- Missing diagnostic experiments
[R1] Heess, N., Williams, C. K. I., and Hinton, G. E. (2009). Learning generative texture models with extended fields of-experts.