This paper evaluates how different context types affect the quality of word embeddings on a plethora of benchmarks.
I am ambivalent about this paper. On one hand, it continues an important line of work in decoupling various parameters from the embedding algorithms (this time focusing on context); on the other hand, I am not sure I understand what the conclusion from these experiments is. There does not appear to be a significant and consistent advantage to any one context type. Why is this? Are the benchmarks sensitive enough to detect these differences, if they exist?
While I am OK with this paper being accepted, I would rather see a more elaborate version of it, which tries to answer these more fundamental questions.
There are many other types of contexts which should be discussed; see "Open IE as an Intermediate Structure for Semantic Tasks" (Stanovsky et al., ACL 2015).