It is interesting to derive such a bound and show it satisfies a regret bound along with empirical evidence on the CIFAR-10 for cross entropy loss and auto encoder for MSE loss. At least empirically, by comparing the observed training loss and taylor loss, the better a particular optimizer performs (training loss statement, not a validation or observed test statement) the smaller the difference between these two. Also shown is the regret loss is satisfied at different scales of the network, by layer, neuron and whole network. 
The Taylor approximation can be used to investigate activation configurations of the network, and used to connect this to difficulty in optimizing  at kinks in the loss surface, along with an empirical study of exploration of activation surface of the SGD/Adam/RMSprop optimizers, the more exploration the better the resulting training loss.
Not that it impacts the paper but the weaker performance of the SGD could be related to the fixed learning rate, if we anneal this learning rate, which should improve performance, does this translate to more exploration and tightening between the actual loss and the Taylor loss? 
- It might be useful to use a cross validation set for some of the empirical studies, in the end we would like to say something about generalization of the resulting network
- Is there a reason the subscript on the Jacobian changes to a_l in the