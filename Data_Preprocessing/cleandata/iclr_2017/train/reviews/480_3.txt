This paper proposes a recurrent architecture for simultaneously predicting motion and action states of agents.
The paper is well written, clear in its presentation and backed up by good experiments.
They demonstrate that by forcing the network to predict motion has beneficial consequences on the classification of actions states,
allowing more accurate classification with less training data.
They also show how the information learned by the network is interpretable and organised in a hierarchy.
Weaknesses:
- a critical discussion on the interplay between motion an behaviour that is needed to experience the benefits of their proposed model is missing from the paper.
- moreover, a discussion on how this approach could scale to more challenging scenarios "involving animals" and visual input for instance and more general "behaviours" is also missing;
The criticism here is pointed at the fact that the title/abstract claim general behaviour modelling, whilst the experiments are focused on two very specific and relatively simple scenarios,
making the original claim a little bit far fetched unless its backed up by additional evidence.
Using "Insects", or "fruit flies" would be more appropriate than "animals".