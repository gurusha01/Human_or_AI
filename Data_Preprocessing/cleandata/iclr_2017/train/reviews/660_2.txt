The paper demonstrates a semi-automatic learning rate schedule for the Adam optimizer, called Eve. Originality is somehow limited but the method appears to have a positive effect on neural network training. The paper is well written and illustrations are appropriate.
Pros:
- probably a more sophisticated scheduling technique than a simple decay term
- reasonable results on the CIFAR dataset (although with comparably small neural network)
Cons:
- effect of momentum term would be of interest
- the Adam reference doesn't point to the conference publications but only to arxiv
- comparison to Adam not entirely conclusive