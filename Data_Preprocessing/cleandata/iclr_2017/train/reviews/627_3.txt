I have problems understanding the motivation of this paper. The authors claimed to have captured a latent representation of text and image during training and can translate better without images at test time, but didn't demonstrate convincingly that images help (not to mention the setup is a bit strange when there are no images at test time). What I see are only speculative comments: "we observed some gains, so these should come from our image models". The qualitative analysis doesn't convince me that the models have learned latent representations; I am guessing the gains are due to less overfitting because of the participation of images during training. 
The dataset is too small to experiment with NMT. I'm not sure if it's fair to compare their models with NMT and VNMT given the following description in Section 4.1 "VNMT is fine-tuned by NMT and our models are fine-tuned with VNMT". There should be more explanation on this.
Besides, I have problems with the presentation of this paper.
(a) There are many symbols being used unnecessary. For example: f & g are used for x (source) and y (target) in Section 3.1. 
(b) The ' symbol is not being used in a consistent manner, making it sometimes hard to follow the paper. For example, in section 3.1.2, there are references about h'\pi obtained from Eq. (3) which is about h\pi (yes, I understand what the authors mean, but there can be better ways to present that).
(c) I'm not sure if it's correct in Section 3.2.2 h'_z is computed from \mu and \sigma. So how \mu' and \sigma' are being used ?
(d) G+O-AVG should be something like G+O_{AVG}. The minus sign makes it looks like there's an ablation test there. Similarly for other symbols.
Other things: no explanations for Figure 2 & 3. There's a missing \pi symbol in Appendix A before the KL derivation.