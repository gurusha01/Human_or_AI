Pros:
The authors are presenting an RNN-based alternative to wavenet, for generating audio a sample at a time.
RNNs are a natural candidate for this task so this is an interesting alternative. Furthermore the authors claim to make significant improvement in the quality of the produces samples.
Another novelty here is that they use a quantitative likelihood-based measure to assess them model, in addition to the AB human comparisons used in the wavenet work.
Cons:
The paper is lacking equations that detail the model. This can be remedied in the camera-ready version.
The paper is lacking detailed explanations of the modeling choices:
- It's not clear why an MLP is used in the bottom layer instead of (another) RNN.
- It's not clear why r linear projections are used for up-sampling, instead of feeding the same state to all r samples, or use a more powerful type of transformation. 
As the authors admit, their wavenet implementation is probably not as good as the original one, which makes the comparisons questionable. 
Despite the cons and given that more modeling details are provided, I think this paper will be a valuable contribution.