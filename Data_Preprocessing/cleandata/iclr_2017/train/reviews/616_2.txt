This paper proposes a model that generates a latent representation of input image(s) and optimizes a reconstruction loss with an adversarial loss (Eq (1)) over nearest neighbors from a bank of images ("memory").   The framework is adapted to three tasks: (i) image in-painting, (ii) intrinsic image decomposition, (iii) figure-ground layer extraction.  Qualitative results are shown for all three tasks.
I think the proposed model has potential merits.  I particularly like the fact that it seems to be reasoning over image composites via matching against a bank of images (somewhat similar to "Segmenting Scenes by Matching Image Composites" work in NIPS 2009).  However, I won't champion the paper as the overall clarity and evaluation could be improved.
More detailed comments:
I believe the fatal flaw of the paper is there is no quantitative evaluation of the approach.  At the very least, there should be a comparison against prior work on intrinsic image decomposition (e.g., SIRFS, maybe benchmark on "intrinsic images in the wild" dataset).
I found the writing vague and confusing throughout.  For instance, "memory database" could mean a number of things, and in the end it seems that it's simply a set of images.  "Imagination" is also vague.  On page 4, R(M,x) has the database and input image as arguments, but Fig 2 doesn't show the input image as an input to R.  The contributions listed on page 3 should be tightened (e.g., it's not clear what "Relevant memory retrieval for informative adversarial priors" means).  Fig 3 seems inconsistent with Fig 2 as the module for "memory database" is not present.  The fully-convolutional discriminator could use more details; one possibility is to provide a cost function.