Summary of the paper
The paper studies the invertiblity of convolutional neural network in the random model. A reconstruction algorithm similar to IHT is proposed for layer-wise inversion of the network.
 
Clarity:
- The paper is confusing wrt to standard notations in deep learning.
Comments:
The paper makes two simplifications in the analysis of a CNN, that makes it map to a model based compressive sensing framework:
1-  The non linearity (RELU) is dropped. This is a big simplification, for random gaussian weights for instance we know by JL that we can preserve L_2 distance, when RELU is applied the metric changes (see for instance the kernel for n=1 in