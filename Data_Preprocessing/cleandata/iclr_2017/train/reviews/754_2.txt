This paper uses a pointer network over a sparse window of identifiers to improve code suggestion for dynamically-typed languages. Code suggestion seems an area where attention and/or pointers truly show an advantage in capturing long term dependencies.
The sparse pointer method does seem to provide better results than attention for similar window sizes - specifically, comparing a window size of 20 for the attention and sparse pointer method shows the sparse pointer winning fairly definitively across the board. Given a major advantage of the pointer method is being able to use a large window size well thanks to the supervision the pointer provides, it was unfortunate (though understandable due to potential memory issues) not to see larger window sizes. Having a different batch size for the sparse pointer and attention models is unfortunate given it complicates an otherwise straight comparison between the two models.
The construction and filtering of the Python corpus sounds promising but as of now it is still inaccessible (listed in the paper as TODO). Given that code suggestion seems an interesting area for future long term dependency work, it may be promising as an avenue for future task exploration.
Overall this paper and the dataset are likely an interesting contribution even though there are a few potential issues.