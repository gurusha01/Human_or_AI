This work proposes to iteratively improve a sentence that has been generated from another MT system (in this case, a phrase-based system). The authors use a neural net that takes in the source sentence and a window of (gold) words around the current target word, and predicts the current target word. During testing, the gold words are replaced with the generated words. While this is an interesting area of research, I am not convinced by the proposed approach, and experimental evidence is lacking.
Under the current framework, it is all but impossible for the model to do anything more than a rudimentary word replacement (e.g. it cannot change "I went to the fridge even though I was not hungry" to "Although I was not hungry, I went to the fridge"). The fact that only 0.6 words are edited on average supports this. 
Specific comments:
- It would be interesting to see what the improvements are if the baseline model is a neural system.
- It seems strange (to me at least) that T^i and L(y^{-i|k}) only look at a window of 2k words. It means that when making the decision to change the i-th word, the model does not know what was generated outside of the window? 
- Relatedly, the idea of changing individual words based on local (i.e. word-level) scores seems counterintuitive. Given that we have the full generated sentence, don't we want a global score? Scoring at the sentence-level could also make room for non-greedy search strategies, which could potentially facilitate richer edits.
- How does the approach compare to a model that simply re-ranks the k-best output?
- Instead of editing, did you consider learning an encoder-decoder that takes in x, yg, and generates yref? When decoding you can attend to both x and y_g.
Minor comments:
- Iteratively improving a generated text was also explored in