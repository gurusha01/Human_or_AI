The authors propose two variational methods based on the theme of posterior approximations which may not have a tractable density. The first is from another ICLR submission on "amortized SVGD" (Wang and Liu, 2016), where here the innovation is in using SGLD as the inference network. The second is from a NIPS paper (Ranganath et al., 2016) on minimizing the Stein divergence with a parametric approximating family, where here the innovation is in defining their test functions to be an RKHS, obtaining an analytic solution to the inner optimization problem.
The methodology is incremental. Everything up to Section 3.2 is essentially motivation, background, or related work. The notion of a "wild variational approximation" was already defined in Ranganath et al. (2016), termed a "variational program". It would be useful for the authors to comment on the difference, if any.
Section 3.2 is at first interesting because it analytically solves the maximum problem that is faced in Ranganath et al. (2016). However, this requires use of a kernel which will certainly not scale in high dimensions, so it is then equivalent in practice to having chosen a very simple test function family. To properly scale to high dimensions would require a deeper kernel and also learning its parameters; this is not any easier than parameterizing the test function family as a neural network to begin with, which Ranganath et al. (2016) do.
Section 4 introduces a Langevin inference network, which essentially chooses the variational approximation as an evolving sequence of Markov transition operators as in Salimans et al. (2015). I had trouble understanding this for a while because I could not understand what they mean by inference network. None of it is amortized in the usual inference network sense, which is that the parameters are given by the output of a neural network. Here, the authors simple define global parameters of the SGLD chain which are used across all the latent variables (which is strictly worse?). (What then makes it an "inference network"?) Is this not the variational approximation used in Salimans et al. (2015), but using a different objective to train it?
The experiments are limited, on a toy mixture of Gaussians posterior and Bayesian logistic regression. None of this addresses the problems one might suspect on high-dimensional and real data, such as the lack of scalability for the kernel, the comparison to Salimans et al. (2015) for the Langevin variational approximation, and any note of runtime or difficulty of training.
Minor comments
+ It's not clear if the authors understood previous work on expressive variational families or inference networks. For example, they argue Rezende & Mohamed, 2015b; Tran et al., 2015; Ranganath et al., 2015 require handcrafted inference networks. However, all of them assume use of any neural network for amortized inference. None of them even require an inference network. Perhaps the authors mean handcrafted posterior approximations, which to some extent is true; however, the three mentioned are all algorithmic in nature: in Rezende & Mohamed (2015), the main decision choice is the flow length; Tran et al. (2015), the size of the variational data; Ranganath et al. (2015), the flow length on the auxiliary variable space. Each works well on different problems, but this is also true of variational objectives which admit intractable q (as the latter two consider, as does Salimans et al. (2015)). The paper's motivation could be better explained, and perhaps the authors could be clearer on what they mean by inference network.
+ I also recommend the authors not term a variational inference method based on the class of approximating family. While black box variational inference in Ranganath et al. (2014) assumes a mean-field family, the term itself has been used in the literature to mean any variational method that imposes few constraints on the model class.