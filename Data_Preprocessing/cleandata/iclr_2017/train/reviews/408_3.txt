this proposes a multi-view learning approach for learning representations for acoustic sequences. they investigate the use of bidirectional LSTM with contrastive losses. experiments show improvement over the previous work.
although I have no expertise in speech processing, I am in favor of accepting this paper because of following contributions:
- investigating the use of fairly known architecture on a new domain.
- providing novel objectives specific to the domain
- setting up new benchmarks designed for evaluating multi-view models
I hope authors open-source their implementation so that people can replicate results, compare their work, and improve on this work.