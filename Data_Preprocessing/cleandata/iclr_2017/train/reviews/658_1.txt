This paper tries to solve the problem of interpretable representations with focus on Sum Product Networks.  The authors argue that SPNs are a powerful linear models that are able to learn parts and their combinations, however, their representations havent been fully exploited by generating embeddings.
Pros:
-The idea is interesting and interpretable models/representations is an important topic.
-Generating embeddings to interpret SPNs is a novel idea.
-The experiments are interesting but could be extended.
Cons:
-The author's contribution isn't fully clear and there are multiple claims that need support. For example, SPNs are indeed interpretable as is, since the bottom-up propagation of information from the visible inputs could be visualized at every stage, and the top-down parse could be also visualized as it has been done before (Amer & Todorovic, 2015). Another example, Proposition one claims that MPNs are perfect encoder decoders since the max nodes always have one max value, however, what if it was uniformally distributed node, or there are two equal values? Did the authors run into such cases? Did they address all edge cases? 
-A good comparison could have been against Generative Adversarial Networks (GANs), Generative Stochastic Networks (GSNs) and Variational Autoencoders too since they are the state-of-the-art generative models, rather than comparing with RBMs and Nade.
I would suggest that the authors take sometime to evaluate their approach against the suggested methods, and make sure to clarify their contributions and eliminate over claiming statements. I agree with the other comments raised by Anon-Reviewer1.