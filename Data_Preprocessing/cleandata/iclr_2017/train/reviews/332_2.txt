I think learning a deep feature representation that is supervised to group dissimilar views of the same object is interesting. The paper isn't technically especially novel but that doesn't bother me at all. It does a good job exploring a new form of supervision with a new dataset. I'm also not bothered that the dataset is synthetic, but it would be good to have more experiments with real data, as well. 
I think the paper goes too far in linking itself to human vision. I would prefer the intro not have as much cognitive science or neuroscience. The second to fourth paragraphs of the intro in particular feels like it over-stating the contribution of this paper as somehow revealing some truth about human vision. Really, the narrative is much simpler -- "we often want deep feature representations that are viewpoint invariant. We supervise a deep network accordingly. Humans also have some capability to be viewpoint invariant which has been widely studied [citations]". I am skeptical of any claimed connections bigger than that.
I think 3.1 should not be based on tree-to-tree distance comparisons but instead based on the entire matrix of instance-to-instance similarity assessments. Why do the lossy conversion to trees first? I don't think "Remarkably" is justified in the statement "Remarkably, we found that OPnets similarity judgement matches a set of data on human similarity judgement, significantly better than AlexNet"
I'm not an expert on human vision, but from browsing online and from what I've learned before it seems that "object persistence" frequently relates to the concept of occlusion. Occlusion is never mentioned in this paper. I feel like the use of human vision terms might be misleading or overclaiming.