I very much like the underlying idea for this paper. I wasn't convinced by the execution in its current state. My primary concern is the one I expressed in my pre-review question below, which I don't think the authors addressed. Specifically, I think the choice of q(s | s') = p(s | s') will make the forward and reverse trajectories almost pathologically mismatched to each other, and will thus make the variational bound extremely loose and high variance. 
The claim about the tightness of the bound in Appendix D relies on the assumption that the transition distribution obeys detailed balance. The learned transition distribution in the paper does not obey detailed balance, and therefore the tightness claim in Appendix D does not hold. (In Section 2.1 you briefly discuss the idea of learning an energy function, rather than directly learning a transition distribution. I think this would be excellent, and in that case you could choose an MCMC transition operator that does obey detailed balance for that energy function.) I did not go through Appendix D beyond this step.
The experimental results were not visually impressive. I suspect this is primarily driven by the mismatch between generative and inference trajectories. See my concern above and in the pre-review question below.
Also, see note below for sec. 5. I suspect some terms are being dropped from the training gradient.
The paper is optimizing a variational bound on log likelihood. You should really, really, really report and compare log likelihoods against competing methods!
Detailed comments below. Some of these were written based on a previous version of the paper.
sec 1.2 - first paragraph is very difficult to follow
"these modes these spurious modes" -> "these spurious modes"
sec 2.1 - "s = (v,h)" -> "s = {v,h}"
sec 2.2 - "with an MCMC" -> "with an MCMC chain"
"(ideally an MCMC)" -> "(e.g. via MCMC)" MCMC is not ideal ... it's just often the best we can do.
sec 3, last bullet - could make the temperature infinite for the last step, in which case the last step will sample directly from the prior, and the posterior and the prior will be exactly the same.
sec. 4 -- Using an energy function would be great!! Especially, because many MCMC transition operators obey detailed balance, you would be far less prone to suffer from the forward/backward transition mismatch that is my primary concern about this technique.
eq. 12,13 -- What is alpha? How does it depend on the temperature. It's never specified.
sec. 5, last paragraph in GSN section -- Note that q also depends on theta, so by not backpropagating through the full q chain you are dropping terms from the gradient.
sec. 5, non-equilibrium thermodynamics -- Note that the noneq. paper also increases the noise variance as the distance from the data increases.
Fig. 1 -- right/left mislabeled
Fig. 2 -- label panes
Fig. 3 -- After how many walkback steps?