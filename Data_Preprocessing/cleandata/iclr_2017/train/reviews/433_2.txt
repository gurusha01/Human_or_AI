This paper proposes a new generative model that uses real-valued non-volume preserving transformations in order to achieve efficient and exact inference and sampling of data points.
The authors use the change-of-variable technique to obtain a model distribution of the data from a simple prior distribution on a latent variable. By carefully designing the bijective function used in the change-of-variable technique, they obtain a Jacobian that is triangular and allows for efficient computation.
Generative models with tractable inference and efficient sampling are an active research area and this paper definitely contributes to this field.
While not achieving state-of-the-art, they are not far behind. This doesn't change the fact that the proposed method is innovative and worth exploring as it tries to bridge the gap between auto-regressive models, variational autoencoders and generative adversarial networks.
The authors clearly mention the difference and similarities with other types of generative models that are being actively researched.
Compared to autoregressive models, the proposed approach offers fast sampling.
Compared to generative adversarial networks, Real NVP offers a tractable log-likelihood evaluation.
Compared to variational autoencoders, the inference is exact.
Compared to deep Boltzmann machines, the learning of the proposed method is tractable.
It is clear that Real NVP goal is to bridge the gap between existing and popular generative models.
The paper presents a lot of interesting experiments showing the capabilities of the proposed technique. Making the code available online will certainly contribute to the field. Is there any intention of releasing the code?
Typo: (Section 3.7) We also "use apply" batch normalization