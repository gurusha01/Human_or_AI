Thie paper proposed an iterative memory updating model for cloze-style question-answering task. The approach is interesting, and result is good. For the paper, I have some comments:
1. Actually the model in the paper is not single model, it proposed two models. One consists of "reading", "writing", "adaptive computation" and " Answer module 2", the other one is "reading", "composing", "writing", "gate querying" and "Answer module 1". Based on the method section and the experiment, it seems the "adaptive computation" model is simpler and performs better. And without two time memory update in single iteration and composing module, the model is similar to neural turing machine.
2. What is the MLP setting in the composing module? 
3. This paper tested different size of hidden state:[256, 368, 436, 512], I do not find any relation between those numbers, how could you find 436? Is there any tricks helping you find those numbers?
4. It needs more ablation study about using different T such as T=1,2..
5. According to my understanding, for the adaptive computation,  it would stop when the P_T <0. So what is the distribution of T in the testing data?