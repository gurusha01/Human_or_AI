The authors proposes an interesting idea of connecting the energy-based model (descriptor) and 
the generator network to help each other. The samples from the generator are used as the initialization 
of the descriptor inference. And the revised samples from the descriptor is in turn used to update
the generator as the target image. 
The proposed idea is interesting. However, I think the main flaw is that the advantages of having that 
architecture are not convincingly demonstrated in the experiments. For example, readers will expect 
quantative analysis on how initializing with the samples from the generator helps? Also, the only 
quantative experiment on the reconstruction is also compared to quite old models. Considering that 
the model is quite close to the model of Kim & Bengio 2016, readers would also expect a comparison 
to that model. 
 Minor
- I'm wondering if the analysis on the convergence is sound when considering the fact that samples 
from SGLD are biased samples (with fixed step size). 
- Can you explain a bit more on how you get Eqn 8? when p(x|y) is also dependent on W_G?