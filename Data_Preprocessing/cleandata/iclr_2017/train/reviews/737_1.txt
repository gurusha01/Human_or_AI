Strengths
-- An interesting proposal for a smaller CNN architecture designed for embedded CNN applications. 
-- Balanced exploration of CNN macroarchitecture and microarchitecture with fire modules.
-- x50 less memory usage than AlexNet, keeping similar accuracy 
-- strong experimental results
Weaknesses
--Would be nice to test Sqeezenet on multiple tasks
--lack of insights and rigorous analysis into what factors are responsible for the success of SqueezeNet. For example, how are ResNet and GoogleNet connected to the current architecture? Another old paper (Analysis of correlation structure for a neural predictive model with application to speech recognition, Neural Networks, 1994) also showed that the "by-pass" architecture by mixing linear and nonlinear prediction terms improves long term dependency in NN based on rigorous perturbation analysis. Can the current work be placed more rigorously on theoretical analysis?