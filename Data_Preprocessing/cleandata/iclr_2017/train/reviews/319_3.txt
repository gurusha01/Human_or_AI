This paper proposes to investigate attention transfers between a teacher and a student network. 
Attention transfer is performed by minimising the l2 distance between the teacher/student attention maps at different layers, in addition to minimising the classification loss and optionally a knowledge distillation term.
Authors define several activation based attentions (sum of absolute feature values raise at the power p or max of values raised at the power p). They also propose a gradient based attention (derivative of the Loss w.r.t. inputs). 
They evaluate their approaches on several datasets (CIFAR, Cub/Scene, Imagenet) showing that attention transfers  does help improving the student network test performance.  However, the student networks performs worst than the teacher, even with attention.
Few remarks/questions:
- in section 3 authors  claim that networks with higher accuracy have a higher spatial correlation between the object and the attention map. While Figure 4 is compelling, it would be nice to have quantitative results showing that as well.
- how did you choose the hyperparameter values, it would be nice to see what is the impact of $\beta$.
- it would be nice to report teacher train and validation loss in Figure 7 b)
- from the experiments, it is not clear what at the pros/cons of the different attention maps
- AT does not lead to better result than the teacher. However, the student networks have less parameters. It would be interesting to characterise the corresponding speed-up. If you keep the same architecture between the student and the teacher, is there any benefit to the attention transfer?
In summary:
Pros:
- Clearly written and well motivated.
- Consistent improvement of the student with attention compared to the student alone.
Cons:
- Students have worst performances than the teacher models.
- It is not clear which attention to use in which case?
- Somewhat incremental novelty relatively to Fitnet