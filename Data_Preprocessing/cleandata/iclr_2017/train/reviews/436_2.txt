This paper proposes a weakly supervised, end-to-end neural network model for solving a challenging natural language understanding task. 
As an extension of the Neural Programmer, this work aims at overcoming the ambiguities imposed by natural language. 
By predefining a set of operations, the model is able to learn the interface between the language reasoning and answer composition using backpropagation. 
On the WikiTableQuestions dataset, it is able to achieve a slightly better performance than the traditional semantic parser methods. 
Overall, this is a very interesting and promising work as it involves a lot of real-world challenges about natural language understanding. 
The intuitions and design of the model are very clear, but the complication makes the paper a bit difficult to read, which means the model is also difficult to be reimplemented. I would expect to see more details about model ablation and it would help us figure out the prominent parts of the model design.