This paper proposed to use Generalized Advantage Estimation (GAE) to optimize DNNs for information seeking tasks. The task is posed as a reinforcement learning problem and the proposed method explicitly promotes information gain to encourage exploration.
Both GAE and DNN have been used for RL before. The novelty in this paper seems to be the explicit modeling of information gain. However, there is insufficient empirical evidence to demonstrate the benefit and generality of the proposed method. An apple to apple comparison to previous RL framework that doesn't model information gain is missing. For example, the cluttered MNIST experiment tried to compare against Mnih et al. (2014) (which is a little out dated) with two settings. But in both setting the input to the two methods are different. Thus it is unclear what contributed to the performance difference.
The experiment section is cluttered and hard to read. A table that summarizes the numbers would be much better.