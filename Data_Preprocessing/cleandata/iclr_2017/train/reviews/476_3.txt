This paper describes a careful experimental study on the CIFAR-10 task that uses data augmentation and Bayesian hyperparameter optimization to train a large number of high-quality, deep convolutional network classification models from hard (0-1) targets.  An ensemble of the 16 best models is then used as a teacher model in the distillation framework, where student models are trained to match the averaged logits from the teacher ensemble.  Data augmentation and Bayesian hyperparameter optimization is also applied in the training of the student models.  Both non-convolutional (MLP) and convolutional student models of varying depths and parameter counts are trained.  Convolutional models with the same architecture and parameter count as some of the convolutional students are also trained using hard targets and cross-entropy loss.  The experimental results show that convolutional students with only one or two convolutional layers are unable to match the results of students having more convolutional layers under the constraint that the number of parameters in all students is kept constant.
Pros
+ This is a very thorough and well designed study that make use of the best existing tools to try to answer the question of whether or not deep convolutional models need both depth and convolution.
+ It builds nicely on the preliminary results in Ba & Caruana, 2014.
Cons
- It is difficult to prove a negative, as the authors admit.  That said, this study is as convincing as possible given current theory and practice in deep learning.
Section 2.2 should state that the logits are unnormalized log-probabilities (they don't include the log partition function).
The paper does not follow the ICLR citation style.  Quoting from the template:  "When the authors or the publication are included in the sentence, the citation should not be in parenthesis (as in "See Hinton et al. (2006) for more information."). Otherwise, the citation should be in parenthesis (as in "Deep learning shows promise to make progress towards AI (Bengio & LeCun, 2007).")."
There are a few minor issues with English usage and typos that should be cleaned up in the final manuscript.
necessary when training student models with more than 1 convolutional layers → necessary when training student models with more than 1 convolutional layer
remaining 10,000 images as validation set → remaining 10,000 images as the validation set
evaluate the ensemble's predictions (logits) on these samples, and save all data → evaluated the ensemble's predictions (logits) on these samples, and saved all data
more detail about hyperparamter optimization → more detail about hyperparameter optimization
We trained 129 deep CNN models with spearmint → We trained 129 deep CNN models with Spearmint
The best model obtained an accuracy of 92.78%, the fifth best achieved 92.67%. → The best model obtained an accuracy of 92.78%; the fifth best achieved 92.67%.
the sizes and architectures of three best models → the sizes and architectures of the three best models
clearly suggests that convolutional is critical →  clearly suggests that convolution is critical
similarly from the hyperparameter-opimizer's point of view → similarly from the hyperparameter-optimizer's point of view