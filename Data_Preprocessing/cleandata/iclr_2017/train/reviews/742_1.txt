This paper presents a theoretical and empirical approach to the problem of understanding the expressivity of deep networks.
Random networks (deep networks with random Gaussian weights, hard tanh or ReLU activation) are studied according to several criterions: number of neutron transitions, activation patterns, dichotomies and trajectory length.
There doesn't seem to be a solid justification for why the newly introduced measures of expressivity really measure expressivity.
For instance the trajectory length seems a very discutable measure of expressivity. The only justification given for why it should be a good measure of expressivity is proportionality with other measures of expressivity in the specific case of random networks.
The paper is too obscure and too long. The work may have some interesting ideas but it does not seem to be properly replaced in context.
Some findings seem trivial.
detailed comments
p2 
"Much of the work examining achievable functions relies on unrealistic architectural assumptions such as layers being exponentially wide"
I don't think so. In "Deep Belief Networks are Compact Universal Approximators" by Leroux et al., proof is given that deep but narrow feed-forward neural networks with sigmoidal units can represent any Boolean expression i.e. A neural network with 2n−1 + 1 layers of n units (with n the number of input neutron).
"Comparing architectures in such a fashion limits the generality of the conclusions"
To my knowledge much of the previous work has focused on mathematical proof, and has led to very general conclusions on the representative power of deep networks (one example being Leroux et al again).
It is much harder to generalise the approach you propose, based on random networks which are not used in practice.
"[we study] a family of networks arising in practice: the behaviour of networks after random initialisation"
These networks arise in practice as an intermediate step that is not used to perform computations; this means that the representative power of such intermediate networks is a priori irrelevant. You would need to justify why it is not.
"results on random networks provide natural baselines to compare trained networks with"
random networks are not "natural" for the study of expressivity of deep networks. It is not clear how the representative power of random networks (what kind of random networks seems an important question here) is linked to the representative power of (i) of the whole class of networks or (ii) the class of networks after training. Those two classes of networks are the ones we would a priori care about and you would need to justify why the study of random networks helps in understanding either (i) or (ii).
p5
"As FW is a random neural network […] it would suggest that points far enough away from each other would have independent signs, i.e. a direct proportionality between the length of z(n)(t) and the number of times it crosses the decision boundary."
As you say, it seems that proportionality of the two measures depends on the network being random. This seems to invalidate generalisation to other networks, i.e. if the networks are not random, one would assume that path lengths are not proportional.
p6
the expressivity w.r.t. remaining depth seems a trivial concerns, completely equivalent to the expressivity w.r.t. depth. This makes the remark in figure 5 that the number of achievable dichotomies only depends only on the number of layers above the layer swept seem trivial
p7
in figure 6 a network width of 100 for MNIST seems much too small. Accordingly performance is very poor and it is difficult to generalise the results to relevant situations.