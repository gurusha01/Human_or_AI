Summary
===
This paper trains models to predict whether block towers will fall down
or not. It shows that an additional model of how blocks fall down
(predicting a sequence of frames via unsupervised learning) helps the original
supervised task to generalize better.
This work constructs a synthetic dataset of block towers containing
3 to 5 blocks places in more or less precarious positions. It includes both
labels (the tower falls or not) and video frame sequences of the tower's
evolution according to a physics engine.
Three kinds of models are trained. The first (S) simply takes an image of a
tower's starting state and predicts whether it will fall or not. The
other two types (CD and CLD) take both the start state and the final state of the
tower (after it has or has not fallen) and predict whether it has fallen or not,
they only differ in how the final state is provided. One model (ConvDeconv, CD)
predicts the final frame using only the start frame and the other
(ConvLSTMDeconv) predicts a series of intermediate frames before coming
to the final frame. Both CD and CLD are unsupervised.
Each model is trained on towers of a particular heigh and tested on
towers with an unseen height. When the height of the train towers
is the same as the test tower height, all models perform roughly the same
(with in a few percentage points). However, when the test height is
greater than the train height it is extremely helpful to explicitly
model the final state of the block tower before deciding whether it has
fallen or not (via CD and CLD models).
Pros
===
* There are very clear (large) gains in accuracy from adding an unsupervised
final frame predictor. Because the generalization problem is also particularly
clear (train and test with different numbers of blocks), this makes for
a very nice toy example where unsupervised learning provides a clear benefit.
* The writing is clear.
Cons
===
My one major concern is a lack of more detailed analysis. The paper
establishes a base result, but does not explore the idea to the extent
to which I think an ICLR paper should. Two general directions for potential
analysis follow:
* Is this a limitation of the particular way the block towers are rendered?
The LSTM model could be limited by the sub-sampling strategy. It looks
like the sampling may be too coarse from the provided examples. For the
two towers in figure 2 that fall, they have fallen after only 1 or 2
time steps. How quickly do most towers fall? What happens if the LSTM
is trained at a higher frame rate? What is the frame-by-frame video
prediction accuracy of the LSTM? (Is that quantity meaningful?)
How much does performance improve if the LSTM is provided ground truth
for only the first k frames?
* Why is generalization to different block heights limited?
Is it limited by model capacity or architecture design?
What would happen if the S-type models were made wider/deeper with the CD/CLD
fall predictor capacity fixed?
Is it limited by the precise task specification?
What would happen if networks were trained with towers of multiple heights
(apparently this experiment is in the works)?
I appreciate that one experiment in this direction was provided.
Is it limited by training procedure? What if the CD/CLD models were trained
in an end-to-end manner? What if the double frame fall predictor were trained
with ground truth final frames instead of generated final frames?
Minor concerns:
* It may be asking too much to re-implement Zhang et. al. 2016 and PhysNet
for the newly proposed dataset, but it would help the paper to have baselines
which are directly comparable to the proposed results. I do not think this
is a major concern because the point of the paper is about the role of
unsupervised learning rather than creating the best fall prediction network.
* The auxiliary experiment provided is motivated as follows: 
"One solution could be to train these models to predict how many blocks have
fallen instead of a binary stability label."
Is there a clear intuition for why this might make the task easier?
* Will the dataset, or code to generate it, be released?
Overall Evaluation
===
The writing, presentation, and experiments are clear and of high enough
quality for ICLR. However the experiments provide limited analysis past
the main result (see comments above). The idea is a clear extension of ideas behind unsupervised
learning (video prediction) and recent results in intuitive physics from
Lerer et. al. 2016 and Zhang et. al. 2016, so there is only moderate novelty.
However, these results would provide a valuable addition to the literation,
especially if more analysis was provided.