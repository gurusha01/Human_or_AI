The goal of this paper is to learn vector representation of boolean and polynomial expressions, such that equivalent expressions have similar representations.
The model proposed in the paper is based on recursive neural network, as introduced by Socher et al. (2012). Given the syntactic parse tree of a formula (either boolean or polynomial), the representation for a node is obtained by applying a MLP on the representation of the children. This process is applied recursively to obtain the representation of the full expression. Contrary to Socher et al. (2012), this paper proposes to use more than one layer (this is especially important to capture XOR operation, which is not surprising at all). The paper also introduces a reconstruction error (called SubexpForce), so that the expression of children can be recovered from the expression of the parent (if I understood correctly). The model is trained using a classification loss, where the label of a given expression corresponds to its equivalence class. The method is then evaluated on randomly generated data, and compared to baselines such as tf-idf, GRU RNN or standard recursive neural network.
While I do agree with the authors that learning good representation for symbolic expressions (and to capture compositionality) is an important task, I am not entirely convinced by the experimental setting proposed in this paper. Indeed, as stated in the paper, the task of deciding if two boolean expressions are equivalent is NP-hard, and I do not understand if the model can do better than implicitly computing the truth table of expressions. While sometimes a bit hard to follow, the paper is technically sound. In particular, the proposed model is well adapted to the problem and outperforms the baselines.
pros:
 - the model is relatively simple and sound.
 - using a classification loss over equivalence classes (should be compared with using similarity).
cons:
 - not convinced by the setting: I do not believe that you can really do better than the truth table for boolean expr (or computing the value of the polynomial expression for randomly chosen points in [0, 1]^n).
 - some part of the paper are a bit hard to follow (e.g. justification of the SubexpForce, discussion of why softmax does not work, etc...).
 - comparison between classification loss and similarity loss is missing.