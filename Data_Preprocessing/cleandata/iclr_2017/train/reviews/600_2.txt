This paper proposed the group sparse auto-encoder for feature extraction. The author then stack the group sparse auto-encoders on top of CNNs to extract better question sentence representation for QA tasks. 
Pros: 
- group-sparse auto-encoder seems new to me.
- extensive experiments on QA tasks. 
Cons:
- The idea is somewhat incremental.
- Writing need to be improved. 
- Lack of ablation studies to show the effectiveness of the proposed approach. 
Moreover, I am not convinced by the author's answer regarding the baseline. A separate training stages of CNN+SGL for comparison is fine. The purpose is to validate and analyze why the proposed SGA is preferred rather than group lasso, e.g. joint training could improve, or the proposed group-sparse regularization outperforms l_21 norm, etc. However, we can't see it from the current experiments.