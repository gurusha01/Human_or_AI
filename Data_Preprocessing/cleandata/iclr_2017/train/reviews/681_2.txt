This work proposes 3 improvements to scattering networks: (1) a non-linearity that allows Fourier-domain computation, (2) compact-supported (in the Fourier domain) representations, and (3) computing additional variance features.
The technical contributions seem worthwhile, since 1 and 2 may result in better speed, while 3 may improve accuracy. Unfortunately, they are poorly described and evaluated. If the writing was clear and the evaluation more broad, I would have recommended acceptance since the ideas have merit.
One of the biggest faults of the presentation is that many sentences are overly long and full of unnecessary obfuscating language, e.g. the last paragraph of Section 1 (though unfortunately this permeates the whole paper).
Likewise, most equations are made unnecessarily complicated. For example, Eq. 5 does not need 4 lines and so many indexes, but just 2:
X_0 = x
Xl = |X{l-1} * Psi_l|
with the |.| operator being element-wise. Most of the hyperparameter dependencies and indexes are not necessary, as well as the repetition of iterations. The same reasoning can be applied to most Equations 5 to 13.
The argument of cardinality (Eq. 14) does not really help prove that variance is more informative. In fact, we could just as easily write that the cardinality of S concatenated with any (!) other quantity is >= the cardinality of S. Another argument from machine learning theory would be better.
The authors should strive to make the arguments in the paper less hyperbolic and better substantiated. The claims about finding invariants of any input (Abstract) and fundamental structures (last paragraph of Section 1.2.1) are not really backed up by any math. How can we have any guarantees about singling out, for example, semantically relevant representations? The learning procedures in machine learning give at least some guarantees, while here the feature building seems a bit more heuristic. This does not take away from the main idea, but this part needs to be better researched.