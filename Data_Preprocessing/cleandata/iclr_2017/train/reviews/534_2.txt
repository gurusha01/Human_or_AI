The paper provides an exposition of multiple ways of learning in implicit generative models, of which generative adversarial networks are an example. The paper is very clear, the exposition is insightful, and the presented material is clearly important.
It is hard to assess "novelty" of this work, as the individual pieces are not novel, and yet the exposition of all of them in the same space with clear outline of the connections between them is novel.
I believe this work is significant - it provides a bridge for language and methods used in multiple parts of statistics and machine learning. This has the potential to accelerate progress.
I recommend publishing this paper at ICLR, even though it is not the "typical" paper that get published at this conference (in that it doesn't offer empirical validation, nor makes a particular claim about relative merits of different methods).