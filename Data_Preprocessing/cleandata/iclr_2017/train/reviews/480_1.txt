While my above review title is too verbose, it would be a more accurate title for the paper than the current one (an overall better title would probably be somewhere in between). 
The overall approach is interesting: all three of the key techniques (aux. tasks, skip/diagonal connections, and the use of internal labels for the kind of data available) make a lot of sense.
I found some of the results hard to understand/interpret. Some of the explanation in the discussion below has been helpful (e.g. see my earlier questions about Fig 4 and 5); the paper would benefit from including more such explanations. 
It may be worthwhile very briefly mentioning the relationship of "diagonal" connections to other emerging terms for similar ideas (e.g. skip connections, etc). "Skip" seems to me to be accurate regardless of how you draw the network, whereas "diagonal" only makes sense for certain visual layouts.
In response to comment in the discussion below: "leading to less over-segmentation of action bouts" (and corresponding discussion in section 5.1 of the paper): I would be like to have a bit more about this in the paper. I have assumed that "per-bout" refers to "per-action event", but now I am not certain that I have understood this correctly (i.e. can a "bout" last for a few minutes?): given the readership, I think it would not be inappropriate to define some of these things explicitly.
In response to comment about fly behaviours that last minutes vs milliseconds: This is interesting, and I would be curious to know how classification accuracy relates to the time-scale of the behaviour (e.g. are most of the mistakes on long-term behaviours? i realize that this would only tell part of the story, e.g. if you have a behaviour that has both a long-term duration, but that also has very different short-term characteristics than many other behaviours, it should be easy to classify accuractely despite being "long-term"). If easy to investigate this, I would add a comment about it; if this is hard to investigate, it's probably not worth it at this point, although it's something you might want to look at in future.
In response to comment about scaling to human behavior: I agree that in principle, adding conv layers directly above the sensory input would be the right thing to try, but seriously: there is usually a pretty big gap between what "should" work and what actually works, as I am sure the authors are aware. (Indeed, I am sure the authors have a much more experiential and detailed understanding of the limitations of their work than I do). What I see presented is a nice system that has been demonstrated to handle spatiotemporal trajectories. The claims made should correspond to this. 
I would consider adjusting my rating to a 7 depending on future revisions.
In Figure 4b, BESNet and BENet have very comparable performance. In particular, BENet is better both with and without filter in the per-bout score. Do you happen to have any intuition or thoughts on why that is the case? Would that be related to the fact that in Fig 5b, there is almost no difference between the LL's associated with RNN and BESNet?