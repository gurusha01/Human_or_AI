This paper proposed a variant of the semi-supervised VAE model which leads to a unified objective for supervised and unsupervised VAE.  This variant gives software implementation of these VAE models more flexibility in specifying which variables are supervised and which are not.
This development introduces a few extra terms compared to the original semi-supervised VAE formulation proposed by Kingma et al., 2014.  From the experiment results it seems that these terms do not do much as the new formulation and the performance difference between the proposed method and Kingma et al. 2014 are not very significant (Figure 5).  Therefore the benefit of the new formulation is likely to be just software engineering flexibility and convenience.
This flexibility and convenience is nice to have, but it is better to demonstrate a few situations where the proposed method can be applied while for other previous methods it is non-trivial to do.
The paper's title and the way it is written make me expect a lot more than what is currently in the paper.  I was expecting to see, for example, structured hidden variable model for the posterior (page 4, top), or really "structured interpretation" of the generative model (title), but I didn't see any of these.  The main contribution of this paper (a variant of the semi-supervised VAE model) is quite far from these.
Aside from these, the plug-in estimation for discrete variables only works when the function h(x,y) is a continuous function of y.  If however, h(x, y) is not continuous in y, for example h takes one form when y=1 and another form when y=2, then the approach of using Expectation[y] to replace y will not work.  Therefore the "plug-in" estimation has its limitations.