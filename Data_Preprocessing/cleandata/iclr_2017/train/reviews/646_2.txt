This work describes 
1: a two stage encoding of stories in bAbI like setups, where a GRU is used to encode a sentence, word by word, conditioned on a sentence level GRU, and the sentence level GRU keeps track of a sentence level encoding.  Each is used
2: modifying the bAbI tasks so it is necessary to ask a question to correctly solve the problem
I am not convinced by the papers results:
1:   The new architecture does not do significantly better than DMN+, and in my view, is similar to DMN+.   What problem with DMN+ does your architecture solve?   
2:  There are now several papers doing the second thing, for example "Dialog-based Language Learning" by Weston and  "Learning End-to-End Goal-Oriented Dialog" by Bordes and Weston, and I think doing it more carefully and in more compelling ways.   In the current work, the correct answer to the question seems given independent of the what the agent asks, so any model that can output "unknown" and then input the extra response has an advantage.  Essentially all of the architectures that are used to solve bAbI can be modified to do this...  Indeed, the enc-dec* accuracies in appendix A show that this sort of module can be appended to any other model.  All of the standard models can be trained to output questions as a sequence of words.    Furthermore, I suspect you could generate the questions  in the authors' setting just by enumerating all the questions that occur in training, and taking a softmax over them, instead of generating word-by-word.