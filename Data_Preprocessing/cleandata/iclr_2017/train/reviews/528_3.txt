This paper presents design decisions of TerpreT [1] and experiments about learning simple loop programs and list manipulation tasks. The TerpreT line of work (is one of those which) bridges the gap between the programming languages (PL) and machine learning (ML) communities. Contrasted to the recent interest of the ML community for program induction, the focus here is on using the design of the programming language to reduce the search space. Namely, here, they used the structure of the control flow (if-then-else, foreach, zipWithi, and foldli "templates"), immutable data (no reuse of a "neural" memory), and types (they tried penalizing ill-typedness, and restricting the search only to well-typed programs, which works better). My bird eye view would be that this stands in between "make everything continuous and perform gradient descent" (ML) and "discretize all the things and perform structured and heuristics-guided combinatorial search" (PL).
I liked that they have a relevant baseline (\lambda^2), but I wished that they also included a fully neural network program synthesis baseline. Admittedly, it would not succeed except on the simplest tasks, but I think some of their experimental tasks are simple enough for "non-generating code " NNs to succeed on.
I wished that TerpreT was available, and the code to reproduce these experiments too.
I wonder if/how the (otherwise very interesting!) recommendations for the design of programming languages to perform gradient descent based-inductive programming would hold/perform on harder task than these loops. Even though these tasks are already interesting and challenging, I wonder how much of these tasks biased the search for good subset of constraints (e.g. those for structuring the control flow).
Overall, I think that the paper is good enough to appear at ICLR, but I am no expert in program induction / synthesis.
Writing:
 - The paper is at times hard to follow. For instance, the naming scheme of the model variants could be summarized in a table (with boolean information about the features it embeds).
 - Introduction: "basis modern computing" -> of
 - Page 3, training objective: "minimize the cross-entropy between the distribution in the output register rR^{(T)} and a point distribution with all probability mass on the correct output value" -> if you want to cater to the ML community at large, I think that it is better to say that you treat the output of rR^{(T)} as a classification problem with the correct output value (you can give details and say exactly which type of criterion/loss, cross-entropy, you use).
[1] "TerpreT: A Probabilistic Programming Language for Program Induction", Gaunt et al. 2016