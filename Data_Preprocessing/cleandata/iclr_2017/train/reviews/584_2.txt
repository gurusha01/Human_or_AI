this work investigates a joint learning setup where tasks are stacked based on their complexity. to this end, experimental evaluation is done on pos tagging, chunking, dependency parsing, semantic relatedness, and textual entailment. the end-to-end model improves over models trained solely on target tasks.
although the hypothesis of this work is an important one, the experimental evaluation lacks thoroughness:
first, a very simple multi-task learning baseline [1] should be implemented where there is no hierarchy of tasks to test the hypothesis of the tasks should be ordered in terms of complexity.
second, since the test set of chunking is included in training data of dependency parsing, the results related to chunking with JMT_all are not informative. 
third, since the model does not guarantee well-formed dependency trees, thus, results in table 4 are not fair. 
minor issue:
- chunking is not a word-level task although the annotation is word-level. chunking is a structured prediction task where we would like to learn a structured annotation over a sequence [2].
[1]