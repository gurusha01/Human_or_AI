The paper proposes a set of recommendations for the design of differentiable programming languages, based on what made gradient descent more successful in experiments.
I must say i'm no expert in program induction. While i understand there is value in exploring what the paper set out to explore -- making program learning easier -- i did not find the paper too engaging. First everything is built on top of Terpret, which isn't yet publicly available. Also most of the discussion is very detailed on the programming language side and less so on the learning side. It is conceivable that it would be best received on a programming language conference. A comparison with alternatives not generating code would be valuable in my opinion, to motivate for the overall setup.
Pros: 
Useful, well executed, novel study.
Cons:
Low on learning-specific contributions, more into domain-related constraints. Not sure a great fit to ICLR.