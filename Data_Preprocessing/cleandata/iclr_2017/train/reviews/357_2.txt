The paper presents a method for predicting video sequences in the lines of Mathieu et al. The contribution is the separation of the predictor into two different networks, picking up motion and content, respectively.
The paper is very interesting, but the novelty is low compared to the referenced work. As also pointed out by AnonReviewer1, there is a similarity with two-stream networks (and also a whole body of work building on this seminal paper). Separating motion and content has also been proposed for other applications, e.g. pose estimation.
Details :
The paper can be clearly understood if the basic frameworks (like GANs) are known, but the presentation is not general and good enough for a broad public.
Example : Losses (7) to (9) are well known from the Matthieu et al. paper. However, to make the paper self-contained, they should be properly explained, and it should be mentioned that they are "additional" losses. The main target is the GAN loss. The adversarial part of the paper is not properly enough introduced. I do agree, that adversarial training is now well enough known in the community, but it should still be properly introduced. This also involves the explanation that L_Disc is the loss for a second network, the discriminator and explaining the role of both etc.
Equation (1) : c is not explained (are these motion vectors)? c is also overloaded with the feature dimension c'.
The residual nature of the layer should be made more apparent in equation (3).
There are several typos, absence of articles and prepositions ("of" etc.). The paper should be reread carefully.
You are training VGG size networks on quite small datasets, and you seem to use the same architecture for all datasets. I didn't find any information on pre-training. Didn't you have any issues with overfitting?