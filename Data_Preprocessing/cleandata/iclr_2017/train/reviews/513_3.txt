Paper Summary 
The paper proposes to learn a predictive model (aka predict the next video frames given an input image) and uses the prediction from this model to improve a supervised classifier. The effectiveness of the approach is illustrated on a tower stability dataset.
 Review Summary 
This work seems rather preliminary in terms of experimentation and using forward modeling as pretraining has already been proposed and applied to video and text classification tasks. Discussion on related work is insufficient. The end task choice (will there be motion?) might not be the best to advocate for unsupervised training.
 Detailed Review 
This work seems rather preliminary. There is no comparison with alternative semi-supervised strategies. Any approach that consider the next frames as latent variables (or privileged information) can be considered. Also I am not sure if the supervised stability prediction model is actually needed once the next frame is predicted. Basically the task can be reduced to predict whether there will be motion in the video following the current frame or not (for instance comparing the first frame and last prediction or the density of gray in the top part of the video might work just as well). Also training a model to predict the presence of motion from the unsupervised data only would probably do very well. I would suggest to stir away from task where the label can be inferred trivially from the unsupervised data, meaning that unlabeled videos can be considered labeled frames in that case.
The related work section misses a discussion on previous work on learning unsupervised features from video (through predictive models, dimensionality reduction...) for helping classification of still images or videos [Fathi et al 2008; Mabahi et al 2009; Srivastava et al 2015]. More recently, Wang and Gupta (2015) have obtained excellent ImageNet results from features pre trained on unlabeled videos. Vondrick et al (2016) have shown that generative models of video can help initialize models for video classification tasks. Also in the field of text classification, pre training of classifier with a language model is a form predictive modeling, e.g. Dai & Le 2015.
I would also suggest to report test results on the dataset from Lerrer et al 2016 (I understand that you need your own videos to pre train the predictive model) but stability prediction only require still images.
Overall, I feel the experimental section is too preliminary. It would be better to focus on a task where solving the unsupervised task does not necessarily imply that the supervised task is trivially solved (or conversely that a simple rule can turn the unlabeled data into label data).
 Reference 
Fathi, Alireza, and Greg Mori. "Action recognition by learning mid-level motion features." Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on. IEEE, 2008.
Mobahi, Hossein, Ronan Collobert, and Jason Weston. "Deep learning from temporal coherence in video." Proceedings of the 26th Annual International Conference on Machine Learning. ACM, 2009.
Srivastava, Nitish, Elman Mansimov, and Ruslan Salakhutdinov. "Unsupervised learning of video representations using lstms." CoRR, abs/1502.04681 2 (2015).
A. Dai, Q.V. Le, Semi-supervised Sequence Learning, NIPS, 2015
Unsupervised learning of visual representations using videos, X Wang, A Gupta, ICCV 2015 
Generating videos with scene dynamics, C Vondrick, H Pirsiavash, A Torralba, NIPS 16