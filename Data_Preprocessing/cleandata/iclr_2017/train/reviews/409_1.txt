This paper introduces MusicNet, a new dataset. Application of ML techniques to music have been limited due to scarcity of exactly the kind of data that is provided here: meticulously annotated, carefully verified and organized, containing enough "hours" of music, and where genre has been well constrained in order to allow for sufficient homogeneity in the data to help ensure usefulness. This is great for the community.
The description of the validation of the dataset is interesting, and indicates a careful process was followed.
The authors provide just enough basic experiments to show that this dataset is big enough that good low-level features (i.e. expected sinusoidal variations) can indeed be learned in an end-to-end context.
One might argue that in terms of learning representations, the work presented here contributes more in the dataset than in the experiments or techniques used. However, given the challenges of acquiring good datasets, and given the essential role such datasets play for the community in moving research forward and providing baseline reference points, I feel that this contribution carries substantial weight in terms of expected future rewards. (If research groups were making great new datasets available on a regular basis, that would place this in a different context. But so far, that is not the case.) In otherwords, while the experiments/techniques are not necessarily in the top 50% of accepted papers (per the review criteria), I am guessing that the dataset is in the top 15% or better.