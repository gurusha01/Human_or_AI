This paper proposes a new gating mechanism to combine word and character representations. The proposed model sets a new state-of-the-art on the CBT dataset; the new gating mechanism also improves over scalar gates without linguistic features on SQuAD and a twitter classification task. 
Intuitively, the vector-based gate working better than the scalar gate is unsurprising, as it is more similar to LSTM and GRU gates. The real contribution of the paper for me is that using features such as POS tags and NER help learn better gates. The visualization in Figure 3 and examples in Table 4 effectively confirm the utility of these features, very nice! 
In sum, while the proposed gate is nothing technically groundbreaking, the paper presents a very focused contribution that I think will be useful to the NLP community. Thus, I hope it is accepted.