The authors propose to extend the "standard" attention mechanism, by extending it to consider a distribution over latent structures (e.g., alignments, syntactic parse trees, etc.). These latent variables are modeled as a graphical model with potentials derived from a neural network.
The paper is well-written and clear to understand. The proposed methods are evaluated on various problems, and in each case the "structured attention" models outperform baseline models (either one without attention, or using simple attention). For the two real-world tasks, the improvements obtained from the proposed approach are relatively small compared to the "simple" attention models, but the techniques are nonetheless interesting.
Main comments:
1. In the Japanese-English Machine Translation example, the relative difference in performance between the Sigmoid attention model, and the Structured attention model appears to be relatively small. In this case, I'm curious if the authors analyzed the attention alignments to determine whether the structured models resulted in better alignments. In other words, if ground-truth alignments are available for the dataset, or if they can be human-annotated for some test examples, it would be interesting to measure the quality of the alignments in addition to the BLEU metric.
2. In the final experiment on natural language inference, I thought it was a bit surprising that using pretrained syntactic attention layers did not appear to improve model performance, but instead appear to degrade performance. I was curious if the authors have any hypotheses for why this is the case?
Minor comments:
1. Typographical error: Equation 1: "p(z | x, q" → "p(z | x, q)"
2. Section 3.3: "Past work has demonstrated that the techniques necessary for this approach, … " →  "Past work has demonstrated the techniques necessary for this approach, … "