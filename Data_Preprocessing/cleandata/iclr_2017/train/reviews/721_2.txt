This paper proposes an approach to unsupervised learning based on a modification to sparse coding that allows for explicit modeling of transformations (such as shift, rotation, etc.), as opposed to simple pooling as is typically done in convnets.  Results are shown for training on natural images, demonstrating that the algorithm learns about features and their transformations in the data.  A comparison to traditional sparse coding shows that it represents images with fewer degrees of freedom.
This seems like a good and interesting approach, but the work seems like its still in its early formative stages rather than a complete work with a compelling punch line.  For example one of the motivations is that you'd like to represent pose along with the identity of an object.  While this work seems well on its way to that goal, it doesn't quite get there - it leaves a lot of dots still to be connected.  
Also there are a number of things that aren't clear in the paper:
o The central idea of the paper it seems is the use of a transformational sparse coding tree to make tractable the inference of the Lie group parameters x_k.  But how exactly this is done is not at all clear.  For example, the sentence: "The main idea is to gradually marginalize over an increasing range of transformations," is suggestive but not clear.  This needs to be much better defined.  What do you mean by marginalization in this context?  
 o The connection between the Lie group operator and the tree leaves and weights w_b is not at all clear.   The learning rule spells out the gradient for the Lie group operator, but how this is used to learn the leaves of the tree is not clear.  A lot is left to the imagination here.  This is especially confusing because although the Lie group operator is introduced earlier, it is then stated that its not tractable for inference because there are too many local minima, and this motivates the tree approach instead.  So its not clear why you are learning the Lie group operator.
 o It is stated that "Averaging over many data points, smoothens the surface of the error function."  I don't understand why you would average over many data points.  It seems each would have its own transformation, no?
 o What data do you train on?  How is it generated?  Do you generate patches with known transformations and then show that you can recover them?  Please explain.
The results shown in Figure 4 look very interesting, but given the lack of clarity in the above, difficult to interpret and understand what this means, and its significance.
I would encourage the authors to rewrite the paper more clearly and also to put more work into further developing these ideas, which seem very promising.