This paper proposes an extension of neural network language (NLM) models to better handle large vocabularies. The main idea is to obtain word embeddings by combining character-level embeddings with a convolutional network.
The authors compare word embeddings (WE),character embeddings (CE) as well a combined character and word embeddings (CWE). It's quite obvious how CE or CWE embeddings can be used at the input of an NLM, but this is more tricky at the output layer. The authors propose to use NCE to handle this problem.  NCE allows to speed-up training, but has no impact on inference during testing: the full softmax output layer must be calculated and normalized (which can be very costly).
It was not clear to me how the network is used during TESTING with an open-vocabulary. Since the NLM is only used during reranking, the unnormalized probability of the requested word could be obtained at the output. However, when reranking n-best lists with the NLM feature, different sentences are compared and I wonder whether this does work well without proper normalization.
In addition, the authors provide perplexities in Table 2 and Figures 2 and 3.  This needs normalization, but it is not clear to me how this was performed.  The authors mention a 250k output vocabulary. I doubt that the softmax was calculated over 250k values. Please explain.
The model is evaluated by reranking n-best lists of an SMT systems for the IWSLT 2016 EN/CZ task.  In the abstract, the authors mention a gain of 0.7 BLEU. I do not agree with this claim. A vanilla word-based NLM, i.e. a well-known model, achieves already a gain of 0.6 BLEU. Therefore, the new model proposed in this paper brings only an additional improvement of 0.1 BLEU. This is not statistically significant. I conjecture that a similar variation could be obtained by just training several models with different initializations, etc.
Unfortunately, the NLM models which use a character representation at the output do not work well. There are already several works which use some form of character-level representations at the input.
Could you please discuss the computational complexity during training and inference.
Minor comments
 - Figure 2 and 3 have the caption "Figure 4". This is misleading.
 - the format of the citations is unusual, eg.
   "While the use of subword units Botha & Blunsom (2014)"
   -> "While the use of subword units (Botha & Blunsom, 2014)"