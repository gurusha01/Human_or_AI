The proposed method of modeling multimodal datasets is a VAE with an inference network for every combination of missing and present modalities. The method is evaluated on modeling MNIST and CelebA datasets.
MNIST is hardly a multimodal dataset. The authors propose to use the labels as a separate modality that gets modeled with a variational autoencoder. The reviewer finds this choice perplexing.
Even then the modalities are never actually missing, so the applicability of the suggested method is questionable.
In addition the differences in log-likelihoods between different models are tiny, and likely to be due to noise.
The other experiment reports log-likelihood of models that were not trained to maximize log-likelihood. It is not clear what conclusions can be drawn from such comparison.