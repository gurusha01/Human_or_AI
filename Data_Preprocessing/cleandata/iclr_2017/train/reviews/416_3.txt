The authors propose a new approach for estimating maximum entropy distributions
subject to expectation constraints. Their approach is based on using
normalizing flow networks to non-linearly transform samples from a tractable
density function using invertible transformations. This allows access to the
density of the resulting distribution. The parameters of the normalizing flow
network are learned by maximizing a stochastic estimate of the entropy
obtained by sampling and evaluating the log-density on the obtained samples.
This stochastic optimization problem includes constraints on expectations with
respect to samples from the normalizing flow network. These constraints are
approximated in practice by sampling and are therefore stochastic. The
optimization problem is solved by using the augmented Lagrangian method. The
proposed method is validated on a toy problem with a Dirichlet distribution and
on a financial problem involving the estimation of price changes from option
price data.
Quality:
The paper seems to be technically sound. My only concern would the the approach
followed to apply the augmented Lagrangian method when the objective and the
constraints are stochastic. The authors propose their own solution to this
problem, based on a hypothesis test, but I think it is likely that this has
already been addressed before in the literature. It would be good if the
authors could comment on this.
The experiments performed show that the proposed approach can outperform Gibbs
sampling from the exact optimal distribution or at least be equivalent, with
the advantage of having a closed form solution for the density.
I am concern about the difficulty of he problems considered.
The Dirichlet distributions are relatively smooth and the distribution in the
financial problem is one-dimensional (in this case you can use numerical
methods to compute the normalization constant and plot the exact density).
They seem to be very easy and do not show how the method would perform in more
challenging settings: high-dimensions, more complicated non-linear constraints,
etc...
Clarity:
The paper is clearly written and easy to follow.
Originality:
The proposed method is not very original since it is based on applying an
existing technique (normalizing flow networks) to a specific problem: that of
finding a maximum entropy distribution. The methodological contributions are
almost non-existing. One could only mention the combination of the normalizing
flow networks with the augmented Lagrangian method. 
Significance:
The results seem to be significant in the sense that the authors are able to
find densities of maximum entropy distributions, something which did not seem
to be possible before. However, it is not clearly how useful this can be in
practice. The problem that they address with real-world data (financial data)
could have been solved as well by using 1-dimensional quadrature. The authors
should consider more challenging problems which have a clear practical
interest.
Minor comments:
More details should be given about how the plot in the bottom right of Figure 2 has been obtained.
"a Dirichlet whose KL to the true pâˆ— is small": what do you mean by this? Can you give more details on how you choose that Dirichlet?
I changed updated my review score after having a look at the last version of the paper submitted by the authors, which includes new experiments.