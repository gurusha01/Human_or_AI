This paper presents a model for semi-supervised learning by encouraging feature invariance to stochastic perturbations of the network and/or inputs.  Two models are described:  One where an invariance term is applied between different instantiations of the model/input a single training step, and a second where invariance is applied to features for the same input point across training steps via a cumulative exponential averaging of the features.  These models evaluated using CIFAR-10 and SVHN, finding decent gains of similar amounts in each case.  An additional application is also explored at the end, showing some tolerance to corrupted labels as well.
The authors also discuss recent work by Sajjadi &al that is very similar in spirit, which I think helps corroborate the findings here.
My largest critique is it would have been nice to see applications on larger datasets as well.  CIFAR and SVHN are fairly small test cases, though adequate for demonstration of the idea.  For cases of unlabelled data especially, it would be good to see tests with on the order of 1M+ data samples, with 1K-10K labeled, as this is a common case when labels are missing.
On a similar note, data augmentations are restricted to only translations and (for CIFAR) horizontal flips.  While "standard," as the paper notes, more augmentations would have been interesting to see --- particularly since the model is designed explicitly to take advantage of random sampling.  Some more details might also pop up, such as the one the paper mentions about handling horizontal flips in different ways between the two model variants.  Rather than restrict the system to a particular set of augmentations, I think it would be interesting to push it further, and see how its performance behaves over a larger array of augmentations and (even fewer) numbers of labels.
Overall, this seems like a simple approach that is getting decent results, though I would have liked to see more and larger experiments to get a better sense for its performance characteristics.
Smaller comment: the paper mentions "dark knowledge" a couple times in explaining results, e.g. bottom of p.6.  This is OK for a motivation, but in analyzing the results I think it may be possible to have something more concrete.  For instance, the consistency term encourages feature invariance to the stochastic sampling more strongly than would a classification loss alone.