This paper proposes an elegant solution to a very important problem in VAEs, namely that the model over-regularizes itself by killing off latent dimensions. People have used annealing of the KL term and "free bits" to hack around this issue but a better solution is needed.
The offered solution is to introduce sparsity for the latent representation: for every input only a few latent distributions will be activated but across the dataset many latents can still be learned. 
What I didn't understand is why the authors need the topology in this latent representation. Why not place a prior over arbitrary subsets of latents? That seems to increase the representational power a lot without compromising the solution to the problem you are trying to solve. Now the number of ways the latents can combine is no longer exponentially large, which seems a pity. 
The first paragraph on p.7 is a mystery to me: "An effect of this â€¦samples". How can under-utilization of model capacity lead to overfitting?
The experiments are modest but sufficient. 
This paper has an interesting idea that may resolve a fundamental issue of VAEs and thus deserves a place in this conference.