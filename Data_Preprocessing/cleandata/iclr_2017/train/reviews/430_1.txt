This paper proposes to learn decomposition of sequences (such as words) for speech recognition. It addresses an important issue and I forsee it being useful for other applications such as machine translation. While the approach is novel and well-motivated, I would very much like to see a comparison against byte pair encoding (BPE). BPE is a very natural (and important) baseline (i.e. dynamic vs fixed decomposition). The BPE performance should be obtained for various BPE vocab sizes. 
Minor points
- Did the learned decompositions correspond to phonetically meaningful units? From the example in the appendix it's hard to tell if the model is learning phonemes or just most frequent character n-grams.
- Any thoughts on applications outside of speech recognition? If this is shown to be effective in other domains it would be a really strong contribution (but this is probably outside the scope for now).