This paper presents a novel approach for visualizing the importance of specific inputs in determining the output of a Long Short Term Memory (LSTM) network. The authors propose a method for decomposing the output of an LSTM into a product of factors, where each term can be interpreted as the contribution of a particular word to the predicted probability of a class. They then use these importance scores to extract phrases from a trained LSTM, which are validated by using them as input to a simple, rules-based classifier.
The main claims of the paper are that the proposed approach can effectively extract meaningful phrases from an LSTM, and that these phrases can be used to approximate the output of the LSTM. The authors support these claims through experiments on sentiment analysis and question answering datasets, where they demonstrate that their approach can achieve reasonable performance and provide insightful visualizations.
I decide to accept this paper, with the main reason being that it presents a novel and well-motivated approach to visualizing the importance of inputs in LSTMs. The paper is well-written, and the authors provide a clear and concise explanation of their method and its applications.
The approach is well-supported by experiments, which demonstrate the effectiveness of the proposed method in extracting meaningful phrases and approximating the output of an LSTM. The authors also provide a thorough analysis of the results, including a comparison with prior work and an examination of the limitations of their approach.
One potential limitation of the paper is that the approach is limited to LSTMs, and it is not clear how it can be extended to other types of neural networks. Additionally, the authors could provide more analysis on the interpretability of the extracted phrases, and how they can be used in practice.
To improve the paper, I suggest that the authors provide more details on the implementation of their approach, including the hyperparameters used in the experiments and the computational resources required. They could also provide more examples of the extracted phrases, and analyze their quality and relevance to the task at hand.
Some questions I would like the authors to answer are: How do the importance scores change when using different types of LSTMs, such as bidirectional or multi-layer LSTMs? Can the approach be extended to other types of neural networks, such as convolutional neural networks or transformers? How can the extracted phrases be used in practice, for example, in improving the performance of an LSTM or in providing insights into the decision-making process of the model?