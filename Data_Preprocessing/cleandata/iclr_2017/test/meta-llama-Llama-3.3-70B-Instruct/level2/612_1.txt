This paper proposes a novel approach to next frame prediction in video sequences by predicting transformations between frames instead of directly predicting pixel values. The authors claim that this approach leads to sharper results and is more efficient in terms of parameters and computational cost. They also propose a new evaluation protocol that uses a classifier trained on ground truth sequences to assess the quality of generated frames.
I decide to accept this paper with the following key reasons: 
1. The approach is well-motivated and placed in the literature, addressing a significant problem in video sequence prediction.
2. The paper supports its claims with thorough experiments on the UCF-101 dataset, demonstrating the effectiveness of the proposed approach.
The paper provides a clear and concise introduction to the problem of next frame prediction, and the proposed approach is well-explained and easy to follow. The experiments are thorough and demonstrate the effectiveness of the proposed approach, including comparisons to state-of-the-art methods. The evaluation protocol proposed in the paper is also a significant contribution, as it provides a more meaningful way to assess the quality of generated frames.
To further improve the paper, I suggest the authors consider the following points:
- Provide more analysis on the limitations of the proposed approach, such as the underestimation of transformations due to the use of MSE as a criterion.
- Consider adding more visualizations or examples to illustrate the effectiveness of the proposed approach.
- Discuss potential applications of the proposed approach, such as video compression or video generation.
Some questions I would like the authors to answer to clarify my understanding of the paper are:
- Can the authors provide more details on how the affine transform extractor is implemented, and how the parameters are chosen?
- How does the proposed approach handle cases where the motion is complex or non-linear, such as in cases of occlusion or fast motion?
- Can the authors provide more information on the computational cost of the proposed approach, and how it compares to other state-of-the-art methods?