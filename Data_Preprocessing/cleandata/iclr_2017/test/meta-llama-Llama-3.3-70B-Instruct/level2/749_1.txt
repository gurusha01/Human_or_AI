This paper proposes a set of design patterns for convolutional neural networks (CNNs) by analyzing recent architectures and identifying common principles. The authors extract 14 design patterns, including "Architectural Structure follows the Application", "Proliferate Paths", and "Strive for Simplicity", which can be used to guide the design of new CNN architectures. The paper also introduces several novel architectures, including Fractal of FractalNet, Stagewise Boosting Networks, and Taylor Series Networks, which are shown to achieve competitive performance on CIFAR-10 and CIFAR-100 datasets.
I decide to accept this paper, with the main reason being that it provides a comprehensive and well-motivated analysis of recent CNN architectures, and the proposed design patterns are well-supported by empirical evidence. The paper is well-written, and the authors provide a clear and concise explanation of their methodology and results.
The supporting arguments for my decision are as follows: (1) the paper tackles a specific and relevant problem in the field of deep learning, namely the lack of guidance on designing CNN architectures; (2) the approach is well-motivated, and the authors provide a thorough analysis of recent architectures to identify common principles; and (3) the results are promising, with the proposed architectures achieving competitive performance on benchmark datasets.
To further improve the paper, I suggest that the authors provide more detailed analysis of the trade-offs between different design patterns, and explore the applicability of their approach to other domains, such as recurrent neural networks or deep reinforcement learning. Additionally, it would be helpful to include more visualizations of the proposed architectures and their performance on different datasets.
Some questions I would like the authors to answer to clarify my understanding of the paper are: (1) How do the proposed design patterns relate to existing architectural design principles, such as those proposed by Szegedy et al. (2015b)? (2) Can the authors provide more insight into the choice of hyperparameters for the proposed architectures, such as the number of paths and the learning rate schedule? (3) How do the authors plan to extend their approach to more complex tasks, such as image segmentation or object detection?