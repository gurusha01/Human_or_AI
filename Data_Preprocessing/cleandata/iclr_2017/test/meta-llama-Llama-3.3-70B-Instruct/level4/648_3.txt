After rebuttal:
I appreciate the inclusion of AlexNet results in the rebuttal. Although the results are not impressive, it is not necessarily a drawback, and as the authors acknowledge, investigating the reason behind this outcome would be intriguing. However, the omission of these results from the original paper and their continued absence is concerning. Furthermore, some claims in the paper appear to be inaccurate in light of these results, such as:
- "This suggests that our gains stem from the CC-GAN method rather than the use of a better architecture."
- "Since discrimination of real/fake in-paintings is more closely related to the target task of object classification than extracting a feature representation suitable for in-filling, it is not surprising that we are able to exceed the performance of Pathak et al. (2016) on PASCAL classification."
These statements, as well as potentially other parts of the paper, require revision. In its current form, I do not believe the paper is suitable for publication. Perhaps a revised version could be considered.
--------
Initial review:
The paper presents an application of generative adversarial networks (GANs) to unsupervised feature learning, demonstrating that the representation learned by the discriminator of a conditional GAN trained for image inpainting performs well on image classification, while also producing convincing inpaintings as a byproduct.
The proposed method combines two existing concepts: utilizing the discriminator of a GAN as a feature learner [Radford et al. 2015] and performing unsupervised feature learning with image inpainting [Pathak et al. 2016]. As a result, the paper's conceptual novelty is limited. On the positive side, the authors effectively implement their idea and achieve state-of-the-art results on STL-10 and respectable results on Pascal VOC (although the Pascal experiments are incomplete, as discussed below). Overall, I am inclined to assign a borderline score, and I would be willing to increase it if the authors address my concerns regarding the experiments.
1) The experimental evaluation on Pascal VOC is not entirely satisfactory. The comparison with prior work is unfair because the network architecture used by the authors (VGG) differs from the architecture used by existing methods (AlexNet). Although the authors acknowledge this discrepancy, I do not understand why they are unwilling to simply run their method with the AlexNet architecture, despite requests from two commenters. Conducting such an experiment would strongly support the authors' claims. The current justification that "we thought it reasonable to use more current models while making the difference clear" is unconvincing. While better architectures do lead to better results, it is essential to properly compare with prior work. Relatedly, Doersch et al. also used the VGG architecture; would it be possible to compare with their results? Additionally, why not compare with [Noroozi&Favaro, ECCV 2016]? I would also like the authors to address the comment by Richard Zhang.
2) The qualitative inpainting results are incomplete: a comparison with previous methods (e.g., [Pathak et al 2016]) is missing, and it is impossible to compare different versions of the proposed method because different images are used for each variant. I recognize that space constraints in the main paper may limit the number of results that can be shown, but many more results should be included in the supplementary material. Quantitative results are also missing, rendering the inpainting results merely interesting to look at, rather than providing substantial contributions to the paper.