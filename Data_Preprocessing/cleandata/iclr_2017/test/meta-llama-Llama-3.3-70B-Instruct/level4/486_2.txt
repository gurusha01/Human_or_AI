This paper presents a semi-supervised learning approach for graphs, leveraging the spectral structure of the graph within a convolutional neural network (CNN) framework. The proposed method exhibits low complexity and demonstrates scalability on large datasets. Comparative analyses with baseline methods across various datasets reveal a significant performance improvement with the proposed approach.
From a technical standpoint, the paper is well-structured and clear, with the algorithm showing good scalability and favorable results compared to baselines on different datasets. The simplicity of the algorithm and ease of training are notable advantages. However, in terms of originality, the proposed method can be seen as an adaptation of graph convolutional networks (as referenced in Defferrard 2016) to a semi-supervised transductive setting. While this is acknowledged in the paper, a more detailed discussion on the novelty and differences compared to this reference would be beneficial. Additionally, the absence of a comparison with iterative classifiers, which often outperform regularization-based approaches in terms of both performance and training time (especially in inductive settings), is noteworthy. Relevant references for this family of methods include works by Qing Lu and Lise Getoor (2003), Gideon S Mann and Andrew McCallum (2010), David Jensen et al. (2004), Joseph J Pfeiffer III et al. (2015), and Stephane Peters et al. (2010).
The authors suggest that more complex filters could be learned by stacking layers but opt for a single hidden layer in their architecture. It would be insightful for them to comment on the potential benefits of utilizing multiple layers for graph classification. Overall, the paper provides a solid foundation, but addressing these points could enhance its contribution to the field.