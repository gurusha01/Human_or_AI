This paper presents a set of guidelines for designing convolutional neural network (CNN) architectures for image processing and computer vision tasks, effectively serving as a review of contemporary CNN architectures. Additionally, it introduces several novel architectural concepts inspired by these guidelines, which are evaluated experimentally on the CIFAR-10 and CIFAR-100 datasets. However, the performance achieved by these new architectures appears to be relatively subpar, as evidenced by the results in Table 1, leaving their usefulness uncertain.
The question arises as to whether the compilation of these rules, largely derived from existing research, merits publication as an original research paper. While summarizing key observations in the field of CNNs, now a staple in computer vision, could be beneficial, especially for newcomers, a significant portion of the content seems to rely on intuitive principles (e.g., points 1, 3, 7, 11). The remainder might be more appropriately suited for educational materials or blog posts aimed at introducing CNN training principles. Furthermore, the paper's focus seems skewed towards recent, incremental works, such as the numerous variants of ResNet.
A statement in the paper claims universality in CNNs regarding the downsampling of activations and the increase in channel numbers from input to final layer, which is inaccurate. This inaccuracy was previously discussed, particularly in relation to design pattern 5, and the response provided ("the nature of design patterns is that they only apply some of the time") does not justify such broad assertions. This claim should likely be retracted.
The explanation provided for normalization's role in enhancing the effectiveness of backpropagation by placing all input samples on an equal footing (section 3.2, second paragraph) is vague and open to multiple interpretations. It would benefit from clarification and should be supported by experimental evidence rather than personal opinion, as indicated by the phrase "we feel." Similar instances of vague claims without empirical backing are found throughout the paper.
The proposed connection between Taylor series and the so-called Taylor Series Networks appears weak, and the naming seems inappropriate. The resulting function, being a sum of different functions raised to various powers, does not constitute a polynomial and represents a generic nonlinear function of x, lacking particular interest or novelty.
In summary, the paper comes across as a disjointed collection of ideas and thoughts without clear delineation, and the experimental outcomes fail to convince. The compilation of existing knowledge and the introduction of new concepts lack the depth and rigor expected in a research publication, suggesting that the work might not be ready for publication in its current form.