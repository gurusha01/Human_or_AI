This paper explores the energy-based model interpretation of Generative Adversarial Networks (GANs), where the discriminator serves as an unnormalized model for the likelihood of a generative model p(x|θ) and the generator acts as a directed model approximating this distribution. The generator is utilized to draw approximate negative phase samples, which are then employed in stochastic maximum likelihood/contrastive divergence learning of the Energy-Based Model (EBM)/discriminator.
The core concept presented in the paper involves fitting the generator by following the Stein variational gradient, which, in practice, comprises the standard gradient provided by the discriminator along with an additional term. This extra term introduces a repulsive force between the sampled data points, aiming to enhance sample diversity.
Although the idea of using a kernel to push apart sampled points is intriguing and may be effective in low-dimensional spaces, its applicability to high-dimensional data, such as full-scale images, is questionable. For high-dimensional samples x, the proposed kernel may not yield a useful distance measure between points. Unfortunately, the paper lacks convincing experiments to counter this concern. Specifically:
- A comparative experiment between standard GAN and GAN with repulsion, using the same architecture, is missing. (This point should be addressed in the rebuttal.)
- If the Stein variational concept is applied strictly, the generator should be fully optimized at each step, followed by a single optimization step on the discriminator. However, the current implementation updates each component alternately, with adjusted learning rates to maintain balance between the two.
- The kernel used for fitting the generator is defined within the auto-encoder space of the discriminator, making it dependent on the discriminator's parameters. Consequently, the objective function for the generator changes at every step, and the procedure can no longer be interpreted as stochastic gradient descent with respect to a single, well-defined objective.
The authors report achieving good results, with generated images appearing superior to those produced by DCGAN. Nevertheless, their approach incorporates several changes compared to DCGAN, making it unclear what specifically contributes to the improvement. Moreover, DCGAN is no longer a strong baseline, as various alternative techniques have been proposed since its introduction.
It is also worth noting that the dual use of φ for both the "particle gradient direction" and the energy function is confusing and may benefit from clarification.