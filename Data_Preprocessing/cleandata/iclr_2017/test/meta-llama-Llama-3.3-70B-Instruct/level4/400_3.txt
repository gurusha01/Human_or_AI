The authors have provided a satisfactory response to my inquiries, and I appreciate their effort. My evaluation remains unchanged.
This manuscript presents a novel neural approach for generating tree structures from scratch, which is achieved by 1) decoupling the recurrence between depths and siblings, and 2) separating topology and label generation. The proposed model outperforms existing methods on the IFTTT benchmark dataset. Notably, it eliminates the need for manual annotation of subtrees with special tokens, making it a viable alternative for such tasks. The authors conduct thorough experiments on a synthetic dataset and demonstrate superior performance compared to alternative methods on the real-world IFTTT dataset.
Several intriguing results in the paper warrant further exploration. For instance, the precision decline with increasing node count in the synthetic dataset raises questions. Is this due to the sequential encoder's inability to capture sufficient information from long sequences, hindering the tree decoder's performance? Or is the tree decoder inherently intolerant to large tree structures? Clarifying this issue is essential for developing improved models. Potential solutions, such as incorporating attention layers to preserve input sequence information, could be explored.
Additionally, investigating the relationships between precision and various tree characteristics, including 1) depth, 2) width, and 3) symmetry, could provide valuable insights. The use of greedy search in decoding also prompts the question of whether beam search could enhance tree decoding performance.
Regarding the IFTTT dataset, providing more detailed statistics, such as tree depth and vocabulary sizes for both language and program aspects, would facilitate a better understanding of the task's complexity.
The paper is well-written, with only minor typos noted in my initial review. Overall, I consider this a solid contribution, with opportunities for further exploration. Therefore, I am inclined to accept the paper.