The work of Gatys et al. has shown that the correlation statistics, specifically empirical Gram matrices, of deep feature responses effectively capture the characteristics of visual textures. This paper delves into the specifics of which deep or shallow networks are well-suited for this framework, yielding the notable finding that very shallow networks, comprising a single filter bank with random weights, perform surprisingly well. In fact, for simple and regular textures, these shallow nets can produce visually superior results compared to more complex data-adapted filters, such as those found in networks like VGG-19. The paper also presents an engaging and informative discussion on the strengths and limitations of these methods for texture synthesis.
Figure 4 illustrates that optimizing images with respect to shallow filter banks can result in texture images with a lower VGG-19 loss than directly optimizing the VGG-19 objective. This is attributed to the challenges of optimizing the highly non-linear VGG-19 cost function, a reasonable explanation. The new supplementary material demonstrates that better optimization results can be achieved by initializing VGG-19-based optimization with the shallow network optimization results, providing a useful complement to the original experiments.
A primary limitation of the paper is the lack of a systematic comparison of different methods against a quantifiable objective. While it is straightforward to define image statistics that can generate an exact copy of any reference texture with good visual quality, the goal is to capture a texture distribution. Measuring how well a method meets this challenge remains an open problem. Although the empirical results suggest that simple statistics are sufficient for texture synthesis in terms of quality and diversity when compared to more complex statistics, it is challenging to conclusively confirm this.
The authors propose measuring diversity in terms of entropy, a reasonable approach, but acknowledge the practical difficulties. Moreover, this would not account for visual quality, another crucial aspect of the problem. They suggest performing a psychophysical assessment, potentially the only practical way to address this issue, but consider it material for future work.
Given the challenges of evaluating image generation, I believe the paper has sufficient strengths to warrant publication in ICLR. However, incorporating some form of psychophysical assessment would be beneficial in confirming the intuitions that currently rely on visual inspection of the figures in the paper and supplementary material.