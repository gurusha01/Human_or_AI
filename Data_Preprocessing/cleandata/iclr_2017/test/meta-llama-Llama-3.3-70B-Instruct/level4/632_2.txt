This manuscript proposes an extension of prior research on utilizing embeddings for Knowledge Base modeling and question answering, with a focus on employing multivariate Gaussian likelihood over inner products for attention scoring, allowing for greater control over attention spread.
The paper is densely packed and complex, spanning 16 pages including supplementary material, which may benefit from being divided into two separate submissions: one focused on Knowledge Base completion and the other on question answering.
The concept of regulating attention spread is intriguing and logical. However, the manuscript falls short of convincingly justifying the use of this approach over traditional inner products due to several concerns. 
Notably, the absence of comprehensive ablation experiments hinders the understanding of the individual components' contributions to the model. Although Table 8 in Appendix B provides some insight, more detailed analyses are necessary. A comparative study between Gaussian interaction and inner product would be particularly insightful.
Furthermore, evaluating the model on established benchmarks for Knowledge Base completion and question answering would strengthen the results. While proposing a new benchmark (WorldCup2014) is commendable, it should supplement, rather than replace, experiments on existing datasets.
The comparison between TransE and TransGaussian on WordNet in Table 11 of Appendix C addresses some of these concerns but raises additional questions. The underperformance of TransGaussian relative to the simpler TransE, coupled with the disappointing results of TransGaussian (SINGLE) in Table 2, suggests that training TransGaussian may be challenging, thereby casting doubt on the architecture's validity.