The concept presented in this paper is sound, proposing a gradual transition from original weights to compressed weights by compressing a portion of them and fine-tuning the remainder. Overall, the paper appears to be in good order, with satisfactory results and adequately addressed questions.
To enhance the paper:
1) Incorporating some of the provided answers directly into the paper would be beneficial, particularly the results combining pruning with the proposed method, as this would enable a fair comparison with Han et al. and demonstrate its superior performance.
2) A more detailed explanation of the encoding method is necessary, as the current description is unclear (which led to an error in my subsequent question regarding the computation of n2). Specifically, the mention of "5 bits" is misleading, as the method actually employs variable-length encoding, which averages around 5 bits. This encoding scheme represents:
- The value 0 with 1 bit (e.g., 0)
- Other values with 5 bits, where the first bit distinguishes them from 0, and the remaining 4 bits represent 16 different values corresponding to powers of 2.