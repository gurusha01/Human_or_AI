This paper presents a novel approach to tackling combinatorial optimization problems by leveraging Recurrent Neural Networks (RNNs) and reinforcement learning. Notably, the incorporation of a pointer network allows for generalization to inputs of varying sizes. Additionally, the proposed method employs "fine-tuning" on test examples through active search, resulting in enhanced performance.
From a theoretical standpoint, the proposed method is intriguing, as it demonstrates the potential of combining RNNs and reinforcement learning to solve combinatorial optimization problems, yielding performance comparable to that of traditional heuristic-based algorithms.
However, a significant limitation of the study is the absence of a thorough complexity comparison with baseline methods, which renders it challenging to assess the practical viability of the proposed approach. This issue is further complicated by the fact that the proposed method utilizes a GPU, whereas the baseline methods rely on a CPU, making it difficult to establish a meaningful unit of complexity. One possible solution could be to consider the financial costs associated with hardware and electricity consumption per instance.
Moreover, the performance comparisons should be interpreted with caution, as traditional heuristic-based algorithms can often achieve superior performance when granted additional computational resources, which is not consistently controlled across algorithms.