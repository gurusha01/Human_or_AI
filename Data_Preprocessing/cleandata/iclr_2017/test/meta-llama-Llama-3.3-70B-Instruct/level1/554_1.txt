Summary
The paper explores the use of eligibility traces in combination with recurrent networks in the Atari domain, specifically in the context of deep reinforcement learning. The authors investigate the benefits of both recurrent nets and eligibility traces in some Atari games and highlight the importance of the optimization used in the training. They demonstrate that eligibility traces can improve and stabilize learning, and using Adam as the optimizer can strongly accelerate learning.
Decision
I decide to Accept this paper, with the main reason being that the approach is well-motivated and well-placed in the literature. The authors provide a clear and thorough explanation of the background and notation, and the experimental results are convincing in demonstrating the benefits of using eligibility traces and Adam as the optimizer.
Supporting Arguments
The paper tackles a specific question/problem in the field of reinforcement learning, namely the use of eligibility traces in combination with recurrent networks. The approach is well-motivated, as the authors provide a clear explanation of the benefits of using eligibility traces and how they can improve learning in environments with sparse rewards. The experimental results are also well-supported, with the authors providing a thorough analysis of the results and discussing the implications of the findings.
Additional Feedback
To further improve the paper, I would suggest that the authors consider providing more details on the hyperparameter tuning process, as well as a more in-depth analysis of the results. Additionally, it would be interesting to see more experiments on different Atari games to further demonstrate the generalizability of the approach. I would also like to see more discussion on the potential limitations of the approach and how it can be applied to more complex environments.
Questions for the Authors
I would like to ask the authors to clarify the following points:
* How did the authors choose the value of Î» = 0.8 for the eligibility traces, and what is the sensitivity of the results to this parameter?
* Can the authors provide more details on the implementation of the Adam optimizer, and how it was tuned for the experiments?
* How do the authors plan to address the potential issue of the frozen network's update frequency, and what are the implications of this for the approach?