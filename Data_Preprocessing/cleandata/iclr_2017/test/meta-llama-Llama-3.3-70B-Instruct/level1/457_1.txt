This paper presents a novel method called Incremental Network Quantization (INQ) that efficiently converts any pre-trained full-precision convolutional neural network (CNN) model into a low-precision version. The authors claim that their method can achieve lossless low-precision quantization, which is a significant improvement over existing methods that often suffer from noticeable accuracy loss.
The paper tackles the specific question of how to efficiently convert a pre-trained full-precision CNN model into a low-precision version without losing accuracy. The approach is well-motivated, as it addresses a critical issue in deep learning, which is the need to deploy CNN models on devices with limited computational resources and memory. The authors provide a thorough review of existing methods and highlight the limitations of these methods, which motivates the need for a new approach.
The paper supports its claims through extensive experiments on the ImageNet large-scale classification task using various deep CNN architectures, including AlexNet, VGG-16, GoogleNet, and ResNets. The results show that the proposed INQ method can achieve improved accuracy compared to the full-precision baselines, even with low-precision weights (e.g., 5-bit, 4-bit, 3-bit, and 2-bit ternary weights). The authors also demonstrate that their method can be combined with network pruning to achieve significant compression ratios while maintaining accuracy.
Based on the results and the thorough evaluation, I decide to Accept this paper. The key reasons for this decision are:
1. The paper tackles a significant problem in deep learning and provides a novel solution that addresses the limitations of existing methods.
2. The approach is well-motivated, and the authors provide a thorough review of existing methods and their limitations.
3. The paper provides extensive experimental results that support the claims made by the authors, demonstrating the effectiveness of the proposed INQ method.
To further improve the paper, I would like to see:
* More analysis on the computational complexity and memory requirements of the proposed INQ method, as this is critical for deploying CNN models on devices with limited resources.
* A more detailed comparison with other state-of-the-art methods, including a discussion of the advantages and disadvantages of each approach.
* An investigation into the applicability of the INQ method to other computer vision tasks, such as object detection and segmentation.
Some questions I would like the authors to answer to clarify my understanding of the paper are:
* Can the authors provide more insight into the choice of the variable-length encoding scheme and how it affects the performance of the INQ method?
* How does the INQ method handle the case where the pre-trained full-precision CNN model has a large number of parameters, and how does this affect the computational complexity and memory requirements of the method?
* Are there any plans to extend the INQ method to other types of neural networks, such as recurrent neural networks (RNNs) and long short-term memory (LSTM) networks?