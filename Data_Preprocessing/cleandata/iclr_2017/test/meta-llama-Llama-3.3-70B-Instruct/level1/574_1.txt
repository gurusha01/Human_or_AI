Summary
The paper proposes a large-scale visual search system for finding similar product images given a fashion item. The system defines over 90 fashion-related attributes and uses a combination of these attributes to represent thousands of unique fashion styles. The authors introduce a recurrent neural network (RNN) to recognize multiple fashion attributes in an end-to-end manner and build an inverted indexing scheme to scale the system. The paper also extracts color and appearance features in a region-of-interest (ROI) of a fashion item for visual similarity.
Decision
I decide to Accept this paper with two key reasons: (1) the approach is well-motivated and placed in the literature, and (2) the paper supports its claims with empirical results.
Supporting Arguments
The paper tackles a specific question of defining similarity among arbitrary fashion products, which is a challenging problem. The authors provide a clear motivation for their approach, discussing the limitations of existing methods and the need for a specialized model that mimics human perception of fashion product similarity. The paper is well-placed in the literature, citing relevant works in computer vision, language modeling, and multi-label classification. The empirical results demonstrate the effectiveness of the proposed system, with competitive performance on benchmarks such as Holidays and UKB.
Additional Feedback
To improve the paper, I suggest the authors provide more details on the dataset collection process, including how the fashion attributes were defined and annotated. Additionally, the authors could discuss potential applications of their system beyond e-commerce, such as fashion recommendation or style transfer. It would also be helpful to include more visual examples of the system's output, such as retrieved images for different queries.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. How did you ensure the quality and consistency of the fashion attribute annotations in the dataset?
2. Can you provide more details on the ResCeption network architecture and how it differs from the original inception-v3 architecture?
3. How do you plan to handle out-of-vocabulary fashion attributes or new fashion styles that are not represented in the training data?