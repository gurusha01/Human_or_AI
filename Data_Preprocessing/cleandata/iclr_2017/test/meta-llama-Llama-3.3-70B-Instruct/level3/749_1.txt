Summary of the Paper's Contributions
The paper proposes a novel method for visualizing the importance of specific inputs in determining the output of a Long Short Term Memory (LSTM) network. By decomposing the output of an LSTM into a product of factors, the authors are able to assign importance scores to individual words, which can then be used to extract representative phrases that capture the underlying patterns learned by the LSTM. The authors demonstrate the effectiveness of their approach on several sentiment analysis and question answering datasets, including Yelp, Stanford Sentiment Treebank, and WikiMovies.
Decision and Key Reasons
Based on the provided guidelines, I decide to Reject this paper. The two key reasons for this decision are:
1. Lack of clarity and rigor in the presentation: The paper's language is often vague, and the authors' claims are not always supported by clear and convincing evidence. For example, the authors claim that their approach provides "superior predictive ability and cleaner visualizations" compared to prior work, but the results presented in the paper do not always bear this out.
2. Methodological limitations and lack of comparison to state-of-the-art methods: The authors' approach is not always compared to state-of-the-art methods, and the results presented in the paper are not always convincing. For example, the authors report that their approach achieves "reasonable performance" on the WikiMovies dataset, but the results are not always competitive with other state-of-the-art methods.
Supporting Arguments
The paper's approach to visualizing the importance of individual words in an LSTM is novel and interesting, but the presentation is often unclear and lacking in rigor. The authors' use of mathematical notation is sometimes confusing, and the paper could benefit from more detailed explanations of the authors' methods and results. Additionally, the paper's results are not always convincing, and the authors could benefit from more thorough comparisons to state-of-the-art methods.
Additional Feedback and Questions
To improve the paper, the authors could benefit from more detailed explanations of their methods and results, as well as more thorough comparisons to state-of-the-art methods. Some specific questions that the authors could address in a revised version of the paper include:
* How do the authors' importance scores compare to other methods for visualizing the importance of individual words in an LSTM, such as attention mechanisms or gradient-based methods?
* How do the authors' results on the WikiMovies dataset compare to other state-of-the-art methods, such as key-value memory networks or graph-based methods?
* Can the authors provide more detailed explanations of their mathematical notation and methods, including the derivation of the importance scores and the phrase extraction algorithm?