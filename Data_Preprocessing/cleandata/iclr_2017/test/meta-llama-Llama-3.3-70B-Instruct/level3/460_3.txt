Summary of the Paper's Contributions
The paper proposes a novel neural network architecture, called Doubly Recurrent Neural Networks (DRNNs), specifically designed for generating tree-structured objects from encoded representations. The architecture models the information flow in a tree with two separate recurrent modules: one carrying ancestral information and the other carrying fraternal information. The topology of the tree is modeled explicitly and separately from the label prediction. The paper demonstrates the effectiveness of DRNNs in recovering latent tree structure in sequences and mapping sentences to simple functional programs.
Decision and Reasons
Based on the review, I decide to Accept the paper. The two key reasons for this choice are:
1. The paper proposes a novel and well-motivated architecture that addresses a significant problem in natural language processing, namely generating tree-structured objects from encoded representations.
2. The experimental results demonstrate the effectiveness of DRNNs in various tasks, including recovering latent tree structure in sequences and mapping sentences to simple functional programs.
Supporting Arguments
The paper provides a clear and well-structured introduction to the problem of generating tree-structured objects, and the proposed architecture is well-motivated and based on sound methods. The experimental results are reasonably complete and demonstrate the effectiveness of DRNNs in various tasks. The paper also provides a good coverage of related literature, particularly in drawing attention to recursive neural networks and their limitations.
Additional Feedback
To improve the paper, I suggest providing more detailed analysis of the results, including confidence intervals and a clearer breakdown of the impact of each innovation. Additionally, it would be helpful to provide more examples of generated trees and to discuss the potential applications of DRNNs in other domains.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on the training process, including the optimization algorithm used and the hyperparameter settings?
2. How do you plan to address the exposure bias issue in the DRNN architecture, and what are the potential consequences of using teacher forcing during training?
3. Can you provide more examples of generated trees and discuss the potential applications of DRNNs in other domains, such as computer vision or robotics?