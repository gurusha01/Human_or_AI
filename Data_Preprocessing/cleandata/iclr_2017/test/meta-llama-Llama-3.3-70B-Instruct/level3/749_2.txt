Summary of the Paper's Contributions
The paper presents a novel approach for visualizing the importance of specific inputs in determining the output of a Long Short Term Memory (LSTM) network. The authors propose a method for decomposing the output of an LSTM into a product of factors, where each term can be interpreted as the contribution of a particular word to the predicted probability of a class. They also introduce a technique for extracting phrases from a trained LSTM by searching for phrases that consistently provide large contributions to the prediction of a particular class. The extracted phrases are then used to construct a simple, rules-based classifier that approximates the output of the original LSTM.
Decision and Key Reasons
Based on the review, I decide to Accept the paper. The key reasons for this decision are:
1. The paper tackles a specific and important problem in the field of natural language processing, namely, understanding the mechanisms by which LSTM networks make predictions.
2. The approach proposed by the authors is well-motivated and grounded in the literature, and they provide a clear and concise explanation of their method.
Supporting Arguments
The paper provides a thorough analysis of the problem and a clear explanation of the proposed approach. The authors also provide a comprehensive evaluation of their method, including experiments on several datasets and a comparison with prior work. The results show that the proposed approach is able to extract sensible phrases and achieve reasonable performance on a simple, rules-based classifier.
Additional Feedback
To improve the paper, I suggest that the authors provide more details on the implementation of their method, including the specific hyperparameters used and the computational resources required. Additionally, it would be helpful to include more examples of the extracted phrases and their corresponding importance scores to provide a better understanding of the method's output.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on the specific datasets used in the experiments and how they were preprocessed?
2. How did you select the hyperparameters for the LSTM and the rules-based classifier, and what was the effect of varying these hyperparameters on the results?
3. Can you provide more examples of the extracted phrases and their corresponding importance scores to illustrate the output of the method?