Summary
The paper proposes a novel approach to train stochastic neural networks for probabilistic inference, specifically for drawing samples from given target distributions. The method, called SteinGAN, is based on iteratively adjusting the neural network parameters to minimize the KL divergence with the target distribution using a Stein variational gradient descent (SVGD) algorithm. The authors demonstrate the effectiveness of their approach on several datasets, including MNIST, CIFAR-10, CelebA, and LSUN, and show that their method can generate realistic-looking images competitive with state-of-the-art generative adversarial networks (GANs).
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the idea presented is nice but not complete, lacking a significant reduction in model size as seen in reference Song 2016. Secondly, the model size reduction in the paper is compared to Song 2016, where a 49X reduction in VGG model size was achieved with pruning and 5-bit quantization, without loss of accuracy.
Supporting Arguments
The paper proposes a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. However, the approach does not demonstrate a significant reduction in model size, which is a critical aspect of efficient inference techniques. In contrast, Song 2016 achieved a 49X reduction in VGG model size with pruning and 5-bit quantization, without loss of accuracy. The inclusion of pruning in the paper could lead to similar or better reductions in model size, but this is not currently demonstrated.
Additional Feedback
To improve the paper, the authors could consider incorporating pruning techniques to reduce the model size and demonstrate the effectiveness of their approach in achieving significant reductions in model size. Additionally, the authors could provide more detailed comparisons with other state-of-the-art methods, including GANs and variational inference methods, to demonstrate the advantages of their approach.
Questions for the Authors
I would like to ask the authors to clarify the following points:
1. How do the authors plan to address the issue of model size reduction, and what techniques do they propose to use to achieve significant reductions in model size?
2. Can the authors provide more detailed comparisons with other state-of-the-art methods, including GANs and variational inference methods, to demonstrate the advantages of their approach?
3. How do the authors plan to extend their approach to more complex datasets and tasks, and what are the potential limitations of their method?