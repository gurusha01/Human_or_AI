Summary
The paper proposes an amortized version of the Stein variational gradient descent (SVGD) method, which is applied to generative adversarial training with a neural network mimicking SVGD dynamics. The authors claim that their method, called SteinGAN, can generate realistic-looking images competitive with state-of-the-art results. The paper also discusses the theoretical background of SVGD and its application to maximum likelihood estimation.
Decision
I decide to reject this paper. The two main reasons for this decision are: (1) the presentation spends too much time setting up the method and not enough time evaluating its wide applicability, resulting in insufficient empirical results; and (2) the empirical results are insufficient to justify the proposed approach, with SteinGAN samples not looking significantly better than DCGAN samples except for the CelebA dataset.
Supporting Arguments
The paper provides a thorough introduction to the theoretical background of SVGD and its application to maximum likelihood estimation. However, the empirical results are limited to four datasets (MNIST, CIFAR-10, CelebA, and LSUN), and the comparison with DCGAN is not comprehensive. The paper also lacks a detailed analysis of the hyperparameters and their impact on the performance of SteinGAN. Furthermore, the use of "testing accuracy" as an evaluation metric is questionable, as it may not accurately reflect the quality of the generated images.
Additional Feedback
To improve the paper, the authors should provide more comprehensive empirical results, including a detailed comparison with other state-of-the-art methods. They should also conduct a thorough analysis of the hyperparameters and their impact on the performance of SteinGAN. Additionally, the authors should consider using more robust evaluation metrics, such as the Frechet inception distance (FID) or the inception score, to assess the quality of the generated images.
Questions for the Authors
I would like the authors to answer the following questions to clarify my understanding of the paper:
1. How did the authors choose the hyperparameters for SteinGAN, and what is the impact of these hyperparameters on the performance of the method?
2. Can the authors provide more detailed comparisons with other state-of-the-art methods, including a quantitative evaluation of the quality of the generated images?
3. How does the authors' method handle mode collapse, which is a common issue in generative adversarial training?
4. Can the authors provide more insights into the theoretical advantages of using SVGD over other variational inference methods?