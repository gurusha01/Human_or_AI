Summary
The paper proposes a method for multi-task state representation learning in reinforcement learning, called MT-LRP. This approach learns multiple low-dimensional state representations from raw observations in an unsupervised fashion, without any knowledge of which task is executed or the number of tasks involved. The method is based on a gated neural network architecture, trained with an extension of the learning with robotic priors objective. The authors demonstrate the effectiveness of MT-LRP in a multi-task slot-car racing scenario, where the agent must learn to control different cars with varying visual cues.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper proposes a method that is not entirely novel, as similar methods have been proposed in previous works. Secondly, the proposed model does not handle multimodality, which limits its contribution to the field.
Supporting Arguments
The paper's approach is based on a gated neural network architecture, which is similar to previous works on mixtures of experts. While the authors extend the learning with robotic priors objective to handle multiple tasks, the core idea is not new. Furthermore, the model's inability to handle multimodality is a significant limitation, as it restricts the model's ability to learn complex tasks with multiple modes.
Additional Feedback
To improve the paper, I suggest that the authors provide a more detailed comparison to previous works, highlighting the key differences and advantages of their approach. Additionally, the authors should consider addressing the limitation of multimodality, either by proposing a new method or by demonstrating the effectiveness of their approach in tasks where multimodality is not a significant issue. The authors may also want to consider testing their method using 2 RGB frames as input and predicting the transformation as output, as suggested by other researchers, to provide a more comprehensive evaluation of their approach.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. How does the proposed method differ from previous works on mixtures of experts, and what are the key advantages of the MT-LRP approach?
2. Can the authors provide more insight into why the model struggles with multimodality, and how they plan to address this limitation in future work?
3. How do the authors plan to extend their approach to handle more complex tasks with multiple modes, and what are the potential applications of their method in real-world scenarios?