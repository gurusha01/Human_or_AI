Summary
The paper proposes a novel approach to learning unsupervised state representations using multi-task reinforcement learning with gated neural networks and robotics priors. The approach, called MT-LRP, learns multiple low-dimensional state representations from raw observations in an unsupervised fashion, without any knowledge of which task is executed, nor of the number of tasks involved. The method is evaluated on two simulated datasets, showing promising results.
Decision
I decide to accept this paper, with the main reason being that the approach is well-motivated, clearly written, and theoretically sound. The use of gating for joint representation, extension of multi-task learning, and combination of multiple losses for strong representation are all positives of the paper.
Supporting Arguments
The paper tackles a specific question of learning state representations in multi-task reinforcement learning, which is a challenging problem in the field. The approach is well-motivated, as it combines the strengths of robotic priors and gated neural networks to learn task-specific state representations. The evaluation on two simulated datasets shows promising results, demonstrating the effectiveness of the approach.
Additional Feedback
To improve the paper, I suggest standardizing model parameter selection and evaluating on high-dimensional datasets for improved comparison and results. Additionally, the authors could provide more analysis on the contribution of each loss term and the effect of hyperparameter tuning on the results.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. How do the authors plan to extend the approach to more complex tasks and higher-dimensional state spaces?
2. Can the authors provide more insight into the choice of hyperparameters, such as the number of gate units and the weights for the loss terms?
3. How do the authors plan to address the issue of limited multi-task learning, where the number of tasks is large and the number of experiences per task is limited?