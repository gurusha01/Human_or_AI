Summary
The paper introduces a new reinforcement learning environment called "The Retro Learning Environment" that interfaces with the LibRetro API to access various emulators and games, starting with the SNES platform. The environment offers more complex games than Atari 2600, with 5 games initially supported, and allows for easy addition of new consoles and games. The authors evaluate several DQN variants and propose a new benchmarking technique.
Decision
I decide to reject this paper. The main reasons for this decision are that the paper does not bring enough value to be presented at a major conference, and the contribution of the proposed benchmarking technique is exaggerated and not particularly new.
Supporting Arguments
While the environment has potential, the paper lacks significant contributions to the field of reinforcement learning. The evaluation of DQN variants is not comprehensive, and the proposed benchmarking technique is not substantially different from existing methods. Additionally, the paper raises concerns about the legality of using emulated game ROMs, which is not adequately addressed. The environment's complexity and the number of supported games are not sufficient to justify the introduction of a new environment, especially considering the recent release of OpenAI Universe and DeepMind Lab.
Additional Feedback
To improve the paper, the authors should provide a more comprehensive evaluation of the environment, including comparisons with existing environments and a more detailed analysis of the proposed benchmarking technique. They should also address the legal concerns surrounding the use of emulated game ROMs and provide a clearer motivation for the introduction of a new environment. Furthermore, the paper contains numerous typos, inaccuracies, and unclear points, such as the difference between RLE and ALE, missing results, and incomplete references, which need to be corrected.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence for my assessment, I would like the authors to answer the following questions:
1. How do the authors plan to address the legal concerns surrounding the use of emulated game ROMs?
2. Can the authors provide a more detailed comparison of the proposed environment with existing environments, such as OpenAI Universe and DeepMind Lab?
3. How do the authors justify the introduction of a new environment, given the recent release of other environments?
4. Can the authors provide more comprehensive results for the evaluation of DQN variants and the proposed benchmarking technique?