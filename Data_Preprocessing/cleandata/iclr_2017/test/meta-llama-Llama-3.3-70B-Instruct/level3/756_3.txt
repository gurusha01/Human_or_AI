Summary of the Paper's Contributions
The paper proposes a novel neural network architecture, called Doubly Recurrent Neural Networks (DRNNs), specifically designed for generating tree-structured objects from encoded representations. The architecture models the information flow in a tree with two separate recurrent modules: one carrying ancestral information and the other carrying fraternal information. The topology of the tree is modeled explicitly and separately from the label prediction. The authors evaluate the proposed method on several tasks, including synthetic tree recovery, mapping sentences to functional programs, and machine translation, and demonstrate its effectiveness in recovering latent tree structures and generating coherent trees.
Decision and Reasons
Based on the evaluation of the paper, I decide to Reject the paper. The main reasons for this decision are:
1. Lack of novelty: The architecture and approach of the model are not entirely novel, being similar to existing neural network architectures trained with SGD on similarity signals.
2. Unconvincing evaluation: The evaluation of the method is unconvincing due to the use of small corpora for training embeddings, which may not reflect real-world performance. The experiments on analogy tasks and named entity recognition (NER) are limited and may not persist when trained on larger corpora.
Supporting Arguments
The paper's contributions, while interesting, are not sufficient to warrant acceptance. The use of a doubly recurrent neural network architecture is not entirely new, and the evaluation of the method is limited by the small size of the corpora used for training. Additionally, the experiments on machine translation, while promising, are not comprehensive enough to demonstrate the effectiveness of the proposed method in a real-world setting.
Additional Feedback
To improve the paper, the authors could consider the following:
* Provide a more comprehensive evaluation of the proposed method on larger corpora and more diverse tasks.
* Compare the performance of the proposed method with existing state-of-the-art methods on the same tasks.
* Provide more details on the training procedure, including the hyperparameters used and the optimization algorithm employed.
* Consider using more robust evaluation metrics, such as precision, recall, and F1-score, to assess the performance of the proposed method.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
* Can you provide more details on the generative process used to create the synthetic tree dataset?
* How did you select the hyperparameters for the proposed method, and what was the effect of varying these hyperparameters on the performance of the method?
* Can you provide more examples of the generated trees, including those that demonstrate the ability of the proposed method to capture complex tree structures?