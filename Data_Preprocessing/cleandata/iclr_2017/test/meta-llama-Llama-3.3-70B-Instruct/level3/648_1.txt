Summary
The paper proposes a semi-supervised learning approach for images based on in-painting using an adversarial loss. The approach, called Context-Conditional Generative Adversarial Networks (CC-GANs), uses a generator to fill in missing patches in an image and a discriminator to distinguish between real and generated images. The authors demonstrate the effectiveness of their approach on two classification benchmarks, STL-10 and PASCAL VOC 2007, achieving comparable or better performance than state-of-the-art methods.
Decision
I decide to Accept this paper, with the main reason being that the approach is well-motivated and effectively addresses the problem of semi-supervised learning for image classification. The use of adversarial loss for in-painting is a novel and interesting idea, and the experimental results demonstrate the potential of the approach.
Supporting Arguments
The paper is well-written and clearly explains the proposed approach, including the architecture of the generator and discriminator networks. The authors provide a thorough review of related work and demonstrate a good understanding of the literature. The experimental results are convincing, and the comparison to other state-of-the-art methods is fair and thorough. The code and models are also made available, which is a plus.
Additional Feedback
To further improve the paper, I would suggest providing more analysis on the role of the low-resolution input to the generator and its effect on the performance of the model. Additionally, it would be interesting to see more examples of in-painted images and a more detailed discussion on the limitations of the approach. The authors may also consider exploring other applications of the CC-GAN approach, such as image generation or image-to-image translation.
Questions for the Authors
I would like to ask the authors to clarify the following points:
* How did they choose the size of the missing patch and the location of the hole in the image?
* Can they provide more insight into the effect of the low-resolution input on the performance of the model?
* Have they explored other architectures for the generator and discriminator networks, and if so, what were the results?
* Are there any plans to extend the approach to other domains, such as video or 3D data?