Summary
The paper proposes a Chaos-Free Network (CFN), a simple gated recurrent neural network that achieves performance comparable to well-known gated architectures, such as LSTMs and GRUs, on the word-level language modeling task. The CFN has a differentiable gating mechanism and a task coherence prior, which enables it to learn state representations for multiple tasks. The approach is orthogonal to multi-task learning and jointly learns a task classifier and a state representation learner, resulting in improved performance over standard non-multitask approaches.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper lacks thorough evaluation on a wider range of setups to demonstrate the generality and scalability of the approach to more complex tasks. Secondly, the paper does not provide a comprehensive discussion and references to other relevant works, such as policy distillation and actor-mimic, which are important for understanding the context and contributions of the proposed approach.
Supporting Arguments
The paper's evaluation is limited to two toy experimental scenarios, and the second scenario is incomplete as it only shows the learned state representation and not the resulting control policy. Additionally, the paper does not provide a clear comparison with other state-of-the-art methods, making it difficult to assess the significance of the proposed approach. Furthermore, the paper's lack of discussion and references to other relevant works makes it challenging to understand the context and contributions of the proposed approach.
Additional Feedback
To improve the paper, I suggest that the authors provide a more comprehensive evaluation of the proposed approach on a wider range of tasks and datasets. Additionally, the authors should provide a clear discussion and references to other relevant works, such as policy distillation and actor-mimic, to contextualize the proposed approach. The authors may also consider combining the proposed approach with other state representation learning methods to demonstrate its effectiveness in more complex scenarios.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
1. Can you provide more details on the experimental setup and hyperparameter tuning process used to achieve the reported results?
2. How does the proposed approach handle tasks with longer-term dependencies, and what are the limitations of the current implementation?
3. Can you provide a more comprehensive comparison with other state-of-the-art methods, including policy distillation and actor-mimic, to demonstrate the significance of the proposed approach?