Summary of the Paper's Contributions
The paper proposes a novel approach for visualizing the importance of specific inputs in determining the output of a Long Short Term Memory (LSTM) network. By decomposing the output of an LSTM into a product of factors, the authors are able to assign importance scores to words according to their contribution to the LSTM's prediction. The paper then demonstrates how these importance scores can be used to extract phrases from a trained LSTM, which can be used to construct a simple, rules-based classifier that approximates the output of the original LSTM.
Decision and Key Reasons
Based on the provided guidelines, I decide to Accept this paper. The two key reasons for this decision are:
1. The paper tackles a specific and well-motivated question, namely, understanding the mechanism by which LSTMs come to their conclusions. The approach is well-placed in the literature, building on existing work on visualizing LSTMs and extracting important features from neural networks.
2. The paper provides extensive experimental results, including comparisons to published baselines, which demonstrate the effectiveness of the proposed approach. The results are scientifically rigorous, and the authors provide a clear and detailed explanation of their methods and findings.
Supporting Arguments
The paper's approach is well-motivated, and the authors provide a clear and detailed explanation of their methods and findings. The experimental results are extensive and demonstrate the effectiveness of the proposed approach. The paper also provides a thorough comparison to existing work, which helps to establish the novelty and significance of the contributions.
Additional Feedback
To improve the paper, I suggest that the authors consider the following:
* Provide more details on the preprocessing and attention steps, and consider including results without these steps for comparison.
* Enhance the quality of Figure 2, which is difficult to read, especially in printed hard copy format.
* Consider including more examples of extracted phrases and their corresponding importance scores to provide further insight into the effectiveness of the approach.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence for my assessment, I would like the authors to answer the following questions:
* Can you provide more details on the computational resources required to train and evaluate the LSTM models, and how this might impact the scalability of the approach?
* How do you plan to extend the approach to more complex models, such as those with multiple layers or attention mechanisms?
* Can you provide more insight into the types of phrases that are extracted by the approach, and how these might be used in practice to improve the interpretability of LSTMs?