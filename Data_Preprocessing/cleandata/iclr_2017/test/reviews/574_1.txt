The paper presents a large-scale visual search system for finding product images given a fashion item. The exploration is interesting and the paper does a nice job of discussing the challenges of operating in this domain. The proposed approach addresses several of the challenges. 
However, there are several concerns.
1) The main concern is that there are no comparisons or even mentions of the work done by Tamara Berg's group on fashion recognition and fashion attributes, e.g., 
-  "Automatic Attribute Discovery and Characterization from Noisy Web Data" ECCV 2010 
- "Where to Buy It: Matching Street Clothing Photos in Online Shops" ICCV 2015,
- "Retrieving Similar Styles to Parse Clothing, TPAMI 2014,
etc
It is difficult to show the contribution and novelty of this work without discussing and comparing with this extensive prior art.
2) There are not enough details about the attribute dataset and the collection process. What is the source of the images? Are these clean product images or real-world images? How is the annotation done? What instructions are the annotators given? What annotations are being collected? I understand data statistics for example may be proprietary, but these kinds of qualitative details are important to understand the contributions of the paper. How can others compare to this work?
3) There are some missing baselines. How do the results in Table 2 compare to simpler methods, e.g., the BM or CM methods described in the text?
While the paper presents an interesting exploration, all these concerns would need to be addressed before the paper can be ready for publication.