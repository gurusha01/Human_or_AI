The paper proposes a method for future frame prediction based on transformation of previous frame rather than direct pixel prediction.
Many previous works have proposed similar methods. The authors in their responses state that previous work is deterministic, yet the proposed model also does not handle multimodality.
Further, i asked if they could test their method using 2 RGB frames as input and predicting the transformation as output, to be able to quantify the importance of using transformations both as input and output, since this is the first work that uses transformations as input also. The authors dismissed the suggestion by saying "if we were to use RGB frames as input and ask the model to output future frames it would produce very blurry results", that is, misunderstanding what the suggestion was. So, currently, it does not seem to be a valid novel contribution in this work compared to previous works.