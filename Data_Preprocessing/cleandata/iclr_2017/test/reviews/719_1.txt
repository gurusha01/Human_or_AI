The paper presents an alternative way of supervising the training of neural network without explicitly using labels when only link/not-link information is available between pairs of examples. A pair of network is trained each of which is used to supervise the other one.
The presentation of the paper is not very clear, the writing can be improved.
Some design choice are not explained: Why is the power function used in the E-step for approximating the distribution (section 2.1)? Why do the authors only consider a uniform distribution? I understand that using a different prior breaks the assumption that nothing is known about the classes. However I do not see a practical situations where the proposed setting/work would be useful.  
Also, there exist a large body of work in semi-supervised learning with co-training based on a similar idea. 
Overall, I think this work should be clarified and improved to be a good fit for this venue.