The authors take on the task of figuring out a set of design patterns for current deep architectures - namely themes that are recurring in the literature.  If one may say so, a distributed representation of deep architectures. 
There are two aspects of the paper that I particularly valued: firstly, the excellent review of recent works, which made me realize how many things I have been missing myself.  Secondly, the "community service" aspect of helping someone who starts figure out the "coordinate system" for deep architectures - this could potentially be more important than introducing yet-another trick of the trade, as most other submissions may do.
However I think this work is still half-done, and even though working on this project is a great idea, the authors do not yet do it properly. 
Firstly, I am not too sure how the choice of these 14 patterns was made. Maxout for instance (pattern 14) is one of the many nonlinearities (PreLU, ReLU, ...) and I do not see how it stands on the same grounds as something as general as "3 Strive for simplicity".
Similarly some of the patterns are as vague as "Increase symmetry" and are backed up by statements such as "we noted a special degree of elegance in the FractalNet". I do not see how this leads to a design pattern that can be applied to a new architecture - or if it applies to anything other than the FractalNet. 
Some other patterns are phrased with weird names "7 Cover the problem space" - which I guess stands for dataset augmentation; or "6 over-train" which is not backed up by a single reference. Unless the authors relate it to regularization (text preceding "overtrain"), which then has no connection to the description of "over-train" provided by the authors ("training a network on a harder problem to improve generalization"). If "harder problem" means one where one adds an additional term (i.e. the regularizer), the authors are doing harm to the unexperienced reader, confusing "regularization" with something that sounds like "overfitting" (i.e. the exact opposite).
Furthermore, the extensions proposed in Section 4 seem a bit off tune - in particular I could not figure out 
-how the Taylor Series networks stem from any of the design patterns proposed in the rest of the paper. 
-whether the text between 4.1 and 4.1.1 is another of the architecture innovations (and if yes, why it is not in the 4.1.2, or 4.1.0) 
-and, most importantly, how these design patterns would be deployed in practice to think of a new network. 
To be more concrete, the authors mention that they propose the "freeze-drop-path" variant from "symmetry considerations" to "drop-path". 
Is this an application of the "increase symmetry" pattern? How would "freeze-drop-path" be more symmetric that "drop-path"?
 Can this be expressed concretely, or is it some intuitive guess? If the second, it is not really part of applying a pattern, in my understanding. If the first, this is missing. 
What I would have appreciated more (and would like to see in a revised version) would have been a table of "design patterns" on one axis, "Deep network" on another, and a breakdown of which network applies which design pattern. 
A big part of the previous work is also covered in cryptic language - some minimal explanation of what is taking place in the alternative works would be useful.