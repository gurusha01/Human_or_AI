The paper proposes a minimal yet robust baseline for parametric texture synthesis using single-layer convolutional neural networks with random filters, challenging the prevailing notion that deep hierarchical representations and pre-trained feature maps are essential for high-quality texture generation. The authors demonstrate that their approach often rivals state-of-the-art VGG-based models in perceptual quality, particularly for textures with regular structures. They also highlight the computational inefficiency of their method due to large filter sizes, raising the question of whether hierarchical models could achieve similar results more efficiently. Despite its strengths, the paper acknowledges that both the proposed and VGG-based models produce imperfect samples inferior to non-parametric methods, and the VGG-based model outperforms in inpainting tasks.
Decision: Reject
While the paper presents an intriguing and well-executed exploration of minimal models for texture synthesis, it falls short in several key areas. The primary reasons for rejection are: (1) the lack of significant improvement over existing methods, as the proposed baseline only occasionally rivals VGG-based models and remains computationally inefficient, and (2) insufficient empirical evidence to support broader claims about the dispensability of hierarchical representations in texture synthesis.
Supporting Arguments:
1. Novelty and Contribution: The paper introduces a simple baseline that challenges assumptions about the necessity of hierarchical depth and learned features. However, the proposed model does not consistently outperform existing methods, and its computational inefficiency undermines its practical applicability. While the findings are thought-provoking, they do not represent a substantial advancement in the field.
   
2. Empirical Rigor: The experiments are thorough, comparing various filter types and scales. However, the evaluation relies heavily on perceptual similarity metrics derived from VGG-based losses, which may not fully capture the quality or variability of synthesized textures. The claim that hierarchical models are unnecessary is not convincingly supported, as the authors themselves acknowledge that hierarchical architectures improve efficiency without degrading quality.
3. Broader Impact: The discussion raises important questions about the trade-offs between perceptual similarity and variability in texture synthesis. However, the paper does not provide actionable insights or methodologies to address these trade-offs, limiting its utility for advancing the field.
Suggestions for Improvement:
1. Strengthen Empirical Evidence: Provide more quantitative comparisons beyond VGG-based loss, such as human perceptual studies or alternative metrics like Structural Similarity Index (SSIM). Additionally, explore whether hierarchical models can achieve similar results with reduced computational cost.
   
2. Address Variability: The paper focuses on perceptual similarity but neglects the variability of generated textures. Future work could include experiments to quantify variability and balance it against perceptual quality.
3. Clarify Claims: The claim that hierarchical representations are unnecessary should be tempered or better substantiated. For example, include experiments that systematically compare hierarchical and single-layer models in terms of both quality and efficiency.
4. Expand Discussion: The discussion on the MaxEnt framework and perceptual metrics is insightful but could be more concise and directly tied to the experimental findings. Additionally, consider exploring practical applications where the proposed model might excel despite its inefficiencies.
Questions for the Authors:
1. Can you provide more evidence to support the claim that hierarchical models are unnecessary, particularly for textures with complex or irregular structures?
2. How does the proposed model perform in tasks beyond texture synthesis, such as style transfer or inpainting, compared to VGG-based models?
3. Could you explore alternative optimization techniques or architectures to address the computational inefficiency of the proposed approach?
In summary, while the paper offers a compelling exploration of minimal models for texture synthesis, it requires stronger empirical support and clearer practical implications to warrant acceptance.