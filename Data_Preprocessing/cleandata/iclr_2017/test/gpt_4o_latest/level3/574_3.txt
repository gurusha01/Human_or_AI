Review
Summary of Contributions
The paper presents a large-scale visual search system designed to retrieve similar fashion-product images based on a query image. The authors propose a novel approach to define fashion similarity using over 90 fashion-related attributes, which are modeled as a multi-label classification problem. They employ a recurrent neural network (RNN) with Long Short-Term Memory (LSTM) to capture attribute dependencies and introduce a custom vision encoder network, ResCeption, based on Inception-v3 with residual connections. The system integrates semantic and visual similarity through an inverted indexing scheme and region-of-interest (ROI) detection, enabling scalable and efficient search. The authors claim competitive results in attribute recognition, ROI detection, and retrieval benchmarks, and they highlight the practical application of their system in an e-commerce platform.
Decision: Reject  
Key Reasons:  
1. Clarity and Organization Issues: The manuscript is scattered and difficult to follow, with unclear connections between sections. The extensive use of footnotes and vague statements (e.g., "That is a competitive result") detracts from readability and scientific rigor.  
2. Unclear Contributions and Comparisons: While the technical depth is evident, the paper fails to clearly articulate the shortcomings it addresses or how it outperforms state-of-the-art baselines. For example, the relationship between ResCeption and existing models like Inception-v3 is inadequately explained.  
3. Writing Quality: The paper contains numerous grammatical errors and awkward phrasing, which hinders comprehension and reflects poorly on the overall quality.  
Supporting Arguments
1. Clarity of Problem and Motivation: The problem of defining and retrieving similar fashion items is well-motivated, especially in the context of e-commerce. However, the paper does not clearly position its contributions within the broader literature. For example, while the use of RNNs for multi-label classification is novel in this domain, the authors do not adequately compare their approach to other multi-label methods or justify why RNNs are preferable.  
2. Experimental Results: The experiments in Section 3.1 are interesting, particularly the use of ResCeption and its application to attribute recognition and retrieval. However, the lack of clear baselines and detailed comparisons to state-of-the-art methods makes it difficult to assess the significance of the results. Statements like "That is a competitive result" are insufficient without quantitative benchmarks or statistical analysis.  
3. Writing and Presentation: The extensive use of footnotes, vague claims, and grammatical errors significantly detracts from the paper's readability and professionalism. For example, the explanation of ResCeption's architecture is overly technical without sufficient context or clarity, making it inaccessible to a broader audience.
Suggestions for Improvement
1. Improve Clarity and Structure: Reorganize the manuscript to ensure a logical flow. Clearly state the problem, contributions, and how the proposed methods address specific shortcomings in the literature. Avoid excessive footnotes and vague statements.  
2. Baseline Comparisons: Provide detailed comparisons to state-of-the-art methods in multi-label classification, ROI detection, and image retrieval. Clearly articulate the advantages of ResCeption and the RNN-based approach over existing techniques.  
3. Writing Quality: Revise the manuscript for grammatical correctness and clarity. Simplify overly technical explanations and ensure that key ideas are accessible to a broader audience.  
4. Experimental Clarity: Clearly explain the experimental setup, including datasets, evaluation metrics, and baselines. For example, clarify how ResCeption's performance compares to Inception-v3 and other vision encoders. Provide statistical significance testing for empirical results.  
5. Clarify Practical Impact: While the application to e-commerce is interesting, the paper should better articulate the practical benefits of the proposed system compared to existing solutions.
Questions for the Authors
1. How does ResCeption compare quantitatively to Inception-v3 and other state-of-the-art vision encoders in terms of accuracy, training time, and computational efficiency?  
2. Can you provide more details on how the RNN implicitly learns attribute dependencies? How does this compare to explicit modeling of dependencies using tree structures?  
3. What specific challenges in e-commerce applications does your system address that existing methods cannot?  
4. Can you clarify the statement "That is a competitive result" in Section 3.1? What are the specific benchmarks or baselines being compared?  
5. How does the system handle cases where the query image contains multiple fashion items or ambiguous attributes?  
In conclusion, while the paper addresses an important problem and demonstrates technical depth, significant improvements in clarity, experimental rigor, and writing quality are necessary for it to be considered for acceptance.