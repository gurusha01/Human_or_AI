Review of the Paper
Summary of Contributions
The paper proposes the use of Rectified Factor Networks (RFNs) for biclustering, aiming to address the limitations of the widely-used FABIA model. The authors argue that RFNs overcome FABIA's shortcomings, such as computational inefficiency, insufficient decorrelation of code units, and challenges in determining sample memberships. RFNs leverage rectified Gaussian posteriors, dropout, and sparse priors to achieve efficient and interpretable biclustering. Empirical results demonstrate that RFNs outperform 14 biclustering methods, including FABIA, on synthetic datasets, gene expression datasets, and the 1000 Genomes Project. The authors claim that RFNs are particularly well-suited for large datasets and sparse coding, making them a potential state-of-the-art biclustering method.
Decision: Reject  
Key reasons: (1) The methodological novelty of the proposed approach is insufficient, and the authors' responses to concerns about novelty were unconvincing. (2) The paper is difficult to follow due to unclear descriptions of key components, such as the definitions of $w$ and the estimation of $h$, which hinders reproducibility and understanding.
Supporting Arguments
1. Empirical Performance: The paper presents strong empirical results, showing that RFNs outperform 14 competing methods across various datasets. This is a notable strength and highlights the practical utility of the approach. However, empirical performance alone is not sufficient to justify publication without clear methodological contributions.
   
2. Limited Novelty: While the paper claims to extend FABIA by incorporating rectification and dropout from deep learning, these techniques are well-established in the literature. The application of these methods to biclustering does not appear to introduce significant theoretical or methodological innovation. The authors' responses to novelty concerns did not provide compelling arguments to address this issue.
3. Clarity and Accessibility: The paper suffers from unclear explanations of key concepts and methods. For instance, the lack of a clear definition for $w$ and the ambiguous description of $h$ estimation make it challenging to understand the technical details. This lack of clarity undermines the paper's reproducibility and accessibility for the broader research community.
Additional Feedback for Improvement
1. Clarify Methodology: The authors should provide precise definitions and detailed explanations of key components, such as $w$, $h$, and the optimization procedure. Including pseudocode or a step-by-step algorithmic description would greatly enhance clarity.
2. Positioning in the Literature: The paper should better contextualize its contributions within the existing literature. For example, a more detailed comparison of RFNs with FABIA and other methods in terms of theoretical underpinnings would strengthen the case for novelty.
3. Address Novelty Concerns: The authors should explicitly highlight what is fundamentally new about their approach beyond the application of rectification and dropout. A theoretical analysis or proof of why RFNs are particularly well-suited for biclustering would add depth.
4. Improve Writing and Organization: The paper would benefit from clearer organization and more concise writing. For example, the introduction could be streamlined to focus on the key contributions, and technical sections should avoid unnecessary jargon.
Questions for the Authors
1. Can you provide a formal definition of $w$ and a clearer explanation of how $h$ is estimated in the RFN model?
2. How does the use of rectification and dropout in RFNs differ fundamentally from their use in existing deep learning models? What specific advantages do these techniques offer in the context of biclustering?
3. Did you conduct any ablation studies to isolate the contributions of individual components (e.g., rectification, dropout) to the performance of RFNs?
While the paper demonstrates strong empirical results, the lack of methodological novelty and unclear explanations make it unsuitable for publication in its current form. Addressing these issues could significantly improve the paper's quality and impact.