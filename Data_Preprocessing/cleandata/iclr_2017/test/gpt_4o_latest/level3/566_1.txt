Review
Summary of Contributions
This paper introduces a novel active learning framework for deep neural networks, particularly convolutional neural networks (CNNs), leveraging a variational approximation of Bayesian inference. The authors propose a batch active learning strategy that selects mini-batches of data based on a criterion derived from the variational free energy. The criterion incorporates both a training factor and a generalization factor, approximated using Fisher information matrices with Kronecker factored approximations (KFAC). The method is computationally efficient, avoiding backpropagation for each query, and demonstrates scalability for large datasets. Experimental results on MNIST and USPS datasets show that the proposed approach achieves competitive test accuracy using only 30% of the labeled data, outperforming random sampling and other baselines. The paper highlights the potential of combining variational inference and active learning for deep networks.
Decision: Reject  
While the paper proposes an interesting and theoretically grounded approach, several critical issues hinder its acceptance. The key reasons for this decision are:  
1. Clarity and Accessibility: The paper's poor English and overly dense theoretical exposition make it difficult to follow. The explanation of the proposed method, particularly the approximations and their practical implications, lacks clarity and structure.  
2. Evaluation Limitations: The experiments are restricted to two grayscale digit datasets (MNIST and USPS), which are relatively simple and do not adequately demonstrate the generalizability of the method to more complex, real-world datasets.  
Supporting Arguments
1. Clarity Issues: The theoretical framework, while intriguing, is challenging to parse due to convoluted language and insufficiently explained approximations. For instance, the derivation of the variational free energy criterion and its connection to active learning is presented in a highly technical manner without sufficient intuition or illustrative examples. This makes the paper inaccessible to a broader audience, including practitioners.  
2. Limited Dataset Evaluation: MNIST and USPS are well-studied benchmarks but do not reflect the diversity or complexity of modern machine learning tasks. The lack of experiments on more challenging datasets (e.g., CIFAR-10, ImageNet) raises questions about the method's scalability and robustness in practical scenarios.  
3. Alternative Strategies Overemphasized: The paper dedicates excessive space to detailing alternative active learning strategies, which detracts from the focus on the proposed method. This space could have been better utilized to provide a more structured explanation of the proposed approach.  
Suggestions for Improvement
1. Language and Presentation: The paper should undergo significant language editing to improve readability. Additionally, the theoretical framework should be accompanied by visual aids, diagrams, or simplified explanations to make the concepts more accessible.  
2. Broader Evaluation: Adding experiments on more diverse datasets, including those with higher complexity or noise, would strengthen the empirical validation of the method.  
3. Comparison with State-of-the-Art: The paper should include comparisons with more recent active learning methods for deep networks to contextualize its contributions better.  
4. Structured Explanation: The approximations and their computational implications should be explained more systematically, with clear connections to the overall active learning framework.  
Questions for the Authors
1. How does the proposed method perform on more complex datasets, such as CIFAR-10 or ImageNet?  
2. Can you provide more intuition or illustrative examples for the variational free energy criterion and its role in active learning?  
3. How sensitive is the method to the choice of hyperparameters, such as the size of the query batch or the scaling factor Î³?  
4. Could the proposed approach be extended to other types of neural networks, such as transformers or recurrent networks?  
In summary, while the paper presents a promising direction for active learning in deep networks, significant improvements in clarity, evaluation, and presentation are required for it to make a meaningful impact.