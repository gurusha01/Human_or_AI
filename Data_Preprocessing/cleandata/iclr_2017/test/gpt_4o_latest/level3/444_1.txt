The paper proposes a novel method to interpret Long Short-Term Memory (LSTM) models by decomposing predictions into word-level importance scores, specifically for question-answering (QA) tasks. By identifying consistently important patterns, the authors distill LSTM predictions into interpretable phrases and validate these patterns by constructing a rule-based classifier. This classifier achieves competitive accuracy on the WikiMovies dataset, demonstrating the utility of the extracted patterns. The work is particularly noteworthy for its strong motivation to interpret LSTMs and the surprising efficacy of simple pattern matching in approximating LSTM performance.
Decision: Weak Accept
The decision to recommend weak acceptance is based on the paper's strong motivation and its contribution to interpretability in NLP, which is a critical area of research. The proposed method is innovative and demonstrates competitive performance, but the paper suffers from clarity issues in the pattern extraction process and the specificity of the evaluation task. Addressing these issues could significantly enhance the paper's impact.
Supporting Arguments:
1. Strong Motivation and Contribution: The paper addresses an important problemâ€”interpreting LSTMs, which are often treated as black boxes. The ability to extract interpretable patterns from LSTMs and use them in a simple classifier is a valuable contribution to the NLP community.
2. Competitive Results: The rule-based classifier, despite its simplicity, achieves competitive accuracy on the WikiMovies dataset, underscoring the utility of the extracted patterns. The method also provides qualitative insights into LSTM behavior, as evidenced by the extracted patterns and heatmaps.
3. Clarity Issues: The paper lacks clarity in key areas, such as the specifics of the pattern extraction process, the role of softmax predictions, and the definitions of P and Q vectors. These omissions make it difficult to fully understand and evaluate the proposed method.
Suggestions for Improvement:
1. Task Introduction: Provide a clearer introduction to the QA task and its challenges, especially for readers unfamiliar with WikiMovies.
2. Clarification of Methodology: Explain the softmax predictions and the roles of P and Q vectors in greater detail. Additionally, analyze the impact of the cutoff constant (e.g., c = 1.1) on pattern extraction.
3. Handling Non-Entity Answers: Address how the method handles non-entity answers in QA tasks, as this is a limitation of the current approach.
4. Extension Beyond Word-Level Predictions: Discuss how the method could be extended to phrase-level or sentence-level predictions, which may improve interpretability and applicability.
Questions for the Authors:
1. How does the choice of the cutoff constant (c = 1.1) affect the quality and interpretability of the extracted patterns? Have alternative values been explored?
2. How does the method handle cases where the correct answer is not an entity or is indirectly implied in the text?
3. Can the proposed approach be generalized to other NLP tasks beyond QA, such as machine translation or summarization?
4. What are the computational costs of the pattern extraction process, and how do they compare to the original LSTM model?
In conclusion, while the paper makes a valuable contribution to LSTM interpretability, addressing the clarity and methodological issues would significantly enhance its impact and utility for NLP researchers.