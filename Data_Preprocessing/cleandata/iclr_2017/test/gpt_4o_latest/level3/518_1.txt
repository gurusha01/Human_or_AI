Review of "Amortized Stein Variational Gradient Descent and SteinGAN"
Summary of Contributions
The paper introduces an amortized version of Stein Variational Gradient Descent (SVGD) that employs a neural network to mimic SVGD dynamics. This approach is designed to adaptively train neural samplers for probabilistic inference, particularly in scenarios requiring repeated inference across similar tasks. The proposed method is applied to generative adversarial training, resulting in a novel framework termed SteinGAN. Here, the discriminator is interpreted as an energy-based probabilistic model, and the generator is trained to approximate the likelihood function. The authors claim that SteinGAN produces realistic-looking images competitive with state-of-the-art GANs while offering a principled approach to enforcing sample diversity through SVGD. 
Decision: Reject
The paper is not ready for publication due to insufficient empirical validation, limited scope of evaluation, and outdated benchmarks.
Supporting Arguments
1. Empirical Evaluation: The empirical results are narrow in scope and fail to substantiate the claimed wide applicability of the proposed method. The experiments are limited to standard datasets (e.g., MNIST, CIFAR-10, CelebA, LSUN), and the use of DCGAN as a baseline is problematic since it is considered outdated. Modern GAN architectures like StyleGAN or BigGAN should have been included for a more rigorous comparison.
   
2. Qualitative and Quantitative Results: While the paper claims that SteinGAN produces competitive or superior results, the qualitative improvements over DCGAN are marginal, except for CelebA. Even here, questions arise about the source of DCGAN samples used for comparison. Quantitatively, the Inception Scores for ImageNet and CIFAR-10 show only marginal differences between SteinGAN and DCGAN, which undermines the claim of significant advancements.
3. Unconvincing Metrics: The "testing accuracy" metric used to evaluate the generated images is unconvincing. It measures task-specific information (e.g., classification accuracy) rather than the general modeling capabilities of the generative model. This metric does not align with the broader goals of generative modeling, such as capturing the underlying data distribution or producing diverse, high-quality samples.
4. Positioning in Literature: While the paper builds on SVGD and amortized inference, it does not sufficiently contextualize its contributions within the broader landscape of generative modeling. The novelty of SteinGAN is somewhat diminished by its reliance on outdated benchmarks and insufficient exploration of its advantages over existing methods.
Suggestions for Improvement
1. Broader Empirical Validation: Extend the evaluation to include more diverse datasets and state-of-the-art GAN baselines. This would provide a clearer understanding of the method's strengths and weaknesses.
   
2. Modern Benchmarks: Replace DCGAN with more recent GAN architectures like StyleGAN or BigGAN for comparisons. This would better reflect the current state of the field.
3. Improved Metrics: Incorporate widely accepted metrics for generative modeling, such as Fr√©chet Inception Distance (FID), to provide a more robust evaluation of sample quality and diversity.
4. Clarify Contributions: Clearly articulate the unique advantages of SteinGAN over existing methods, both theoretically and empirically. For example, emphasize how the use of SVGD provides principled diversity enforcement compared to heuristic regularizers in other GANs.
5. Address Scalability: Discuss the scalability of the proposed method to high-dimensional data and more complex tasks, as this is critical for practical applications.
Questions for the Authors
1. How does SteinGAN compare to more recent GAN architectures in terms of sample quality and diversity?
2. Can you provide additional evidence to support the claim that SteinGAN captures more information from the training set than DCGAN?
3. What is the computational overhead of amortized SVGD compared to traditional GAN training methods?
4. How does the choice of kernel in SVGD affect the performance of SteinGAN, and how robust is the method to this choice?
In conclusion, while the paper introduces an interesting adaptation of SVGD for generative modeling, it requires significant improvements in empirical validation, positioning within the literature, and clarity of contributions to meet the standards of a top-tier conference.