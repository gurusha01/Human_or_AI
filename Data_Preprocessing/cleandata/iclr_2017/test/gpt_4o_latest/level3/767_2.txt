Review of the Paper
Summary of Contributions
This paper proposes a novel approach to automatically learn learning rates for supervised learning using an actor-critic reinforcement learning (RL) framework. The actor network determines the learning rate at each training step, while the critic network evaluates the long-term impact of these decisions. The method is validated on MNIST and CIFAR-10 datasets, demonstrating superior performance compared to standard optimizers such as SGD, Adam, and RMSprop. Notably, the proposed method achieves better generalization performance and can mitigate overfitting. The authors also highlight the importance of feeding different examples to the actor and critic networks to improve robustness. The paper positions itself as a step toward automating hyperparameter tuning, a critical challenge in machine learning.
Decision: Reject
While the paper introduces an interesting idea and shows promising results, it falls short in several critical areas. The lack of comparison with recent, relevant methods and concerns about the experimental rigor undermine the validity of the claims. These issues must be addressed before the paper can be considered for acceptance.
Supporting Arguments
1. Lack of Comparisons with Relevant Work:  
   The paper does not adequately compare its approach to similar recent methods, such as those by Daniel et al. (2016) and Andrychowicz et al. (2016). The work by Daniel et al., which also uses RL for learning rate adaptation, is particularly relevant. However, the paper does not convincingly argue why its approach is superior or addresses the limitations of Daniel et al.'s method. For instance, the claim that prior knowledge in Daniel et al.'s approach is a disadvantage is not substantiated with evidence or analysis.
2. Experimental Concerns:  
   The experimental results for baseline methods like RMSprop appear unusually poor, raising questions about whether these baselines were properly tuned. Additionally, the experiments are limited to relatively simple datasets (MNIST and CIFAR-10) and architectures. Comparisons on more complex and widely used architectures, such as ResNet or Network in Network, are necessary to validate the generalizability of the proposed method.
3. Insufficient Theoretical Analysis:  
   While the paper demonstrates empirical improvements, it lacks a theoretical analysis of why the proposed actor-critic framework is effective for learning rate adaptation. This omission weakens the scientific rigor of the work.
Suggestions for Improvement
1. Expand Comparisons:  
   Include detailed comparisons with recent methods, particularly Daniel et al. and Andrychowicz et al. Discuss the advantages and limitations of each approach and provide quantitative results to support the claims.
2. Improve Experimental Rigor:  
   Ensure that all baseline methods are properly tuned and report hyperparameter settings for reproducibility. Extend experiments to include more challenging datasets and architectures to demonstrate the scalability and robustness of the proposed method.
3. Theoretical Justification:  
   Provide a theoretical analysis or intuition to explain why the actor-critic framework is well-suited for learning rate adaptation. This could include a discussion of the relationship between long-term rewards and model convergence.
4. Ablation Studies:  
   Conduct ablation studies to isolate the contributions of different components of the method, such as the use of separate examples for the actor and critic networks.
Questions for the Authors
1. Why were the works of Daniel et al. and Andrychowicz et al. not included in the experimental comparisons? How does your method address the limitations of these approaches?
2. Can you provide more details on the tuning process for baseline methods like RMSprop? Were the results consistent with those reported in prior literature?
3. Have you tested the proposed method on more complex architectures or tasks? If not, how do you anticipate the method will perform in such scenarios?
4. How sensitive is the performance of your method to the choice of hyperparameters for the actor and critic networks?
By addressing these concerns and questions, the paper could make a stronger case for its contributions and improve its overall impact.