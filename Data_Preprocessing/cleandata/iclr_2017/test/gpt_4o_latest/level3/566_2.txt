Review
Summary of Contributions
This paper introduces a novel framework for integrating active learning into deep learning, specifically targeting scalability challenges in Convolutional Neural Networks (CNNs). The authors propose a batch active learning scheme based on a variational approximation of Bayesian inference, leveraging the Fisher Information matrix to define a two-term active learning criterion. The framework avoids computationally expensive backpropagation during active selection by approximating the posterior and prior distributions of weights using Maximum Likelihood Estimation (MLE). The method is evaluated on MNIST and USPS datasets, achieving competitive test accuracy using only 30% of the labeled training data. The proposed approach demonstrates scalability and efficiency, offering a promising direction for combining active learning with deep learning.
Decision: Reject  
While the paper explores an interesting and significant direction, it suffers from critical issues in clarity, presentation, and scientific rigor that hinder its overall impact. The lack of clarity in the motivation, methodology, and experimental details, combined with grammatical and typographical errors, makes the paper difficult to follow and evaluate.
Supporting Arguments for Decision
1. Clarity and Presentation:  
   The paper lacks coherence in its structure and explanations. The motivations for the proposed framework are not clearly articulated, and there are inconsistencies between the introduction and Section 3. The related work section, while detailed, feels disconnected from the rest of the paper and does not effectively position the proposed approach within the broader literature. Additionally, the derivations and approximations in Section 3 are dense and difficult to parse, which may alienate readers unfamiliar with the technical details of variational inference or Fisher Information.
2. Scientific Rigor:  
   While the paper claims to approximate the Fisher Information matrix and use it for active learning, the approximations and assumptions made are not sufficiently justified or validated. For example, the reliance on asymptotic properties of MLE may be unstable for small datasets, as acknowledged by the authors, but no concrete solutions or empirical validations are provided to address this limitation. Furthermore, the experimental results, while promising, lack sufficient analysis to demonstrate the robustness of the approach across diverse datasets or tasks.
3. Language and Typographical Errors:  
   The paper contains numerous grammatical and typographical errors, which detract from its readability and professionalism. For example, phrases like "Such a solution is immediate in the process but fails to model the correlations between samples" are awkwardly worded, and there are several instances of inconsistent terminology.
Suggestions for Improvement
1. Clarity in Motivation and Methodology:  
   Clearly articulate the motivation for combining active learning with deep learning and how the proposed framework addresses existing challenges. Ensure consistency between the introduction, methodology, and experimental sections. Simplify the mathematical derivations and provide intuitive explanations for key concepts to make the paper accessible to a broader audience.
2. Experimental Validation:  
   Expand the experimental evaluation to include more datasets and tasks, demonstrating the generalizability of the approach. Provide detailed comparisons with state-of-the-art active learning methods and analyze the impact of key hyperparameters, such as batch size and the choice of approximations.
3. Language and Presentation:  
   Proofread the paper thoroughly to eliminate grammatical and typographical errors. Use clear and concise language, and include diagrams or visualizations to aid in understanding complex concepts like the Fisher Information matrix approximations.
Questions for the Authors
1. How does the proposed framework handle noisy or imbalanced datasets, as seen in real-world scenarios?  
2. Can the authors provide more empirical evidence to validate the stability of the MLE-based approximations for small datasets?  
3. How does the choice of hyperparameter Î³ affect the balance between the training and generalization factors in the active learning criterion?  
In conclusion, while the paper presents a novel and promising approach, significant revisions are required to improve its clarity, rigor, and overall presentation.