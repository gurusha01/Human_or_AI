The paper presents a novel approach to natural texture synthesis, challenging the prevailing assumption that deep, hierarchical, and pre-trained convolutional neural networks (CNNs) are essential for high-quality texture generation. The authors propose a minimalistic model using single-layer CNNs with random filters and demonstrate that this approach can rival state-of-the-art methods, such as Gatys et al. (2015a), in generating perceptually high-quality textures. The paper also introduces a quantitative evaluation metric based on VGG-loss, replacing traditional human inspection, and provides extensive comparisons across various filter types and architectures. The authors further explore the importance of multi-scale filters and non-linearities in achieving high-quality synthesis.
Decision: Accept
Key reasons for acceptance include:  
1. Novelty and Insight: The paper provides a surprising and impactful finding that challenges established assumptions in the field, showing that depth and pre-training are not indispensable for texture synthesis.  
2. Scientific Rigor: The methodology is thorough, with extensive experiments and comparisons across multiple architectures, filter types, and evaluation metrics, supporting the claims convincingly.  
Supporting Arguments:  
The paper is well-motivated, addressing a fundamental question about the necessity of deep hierarchical representations for texture synthesis. It is firmly grounded in the literature, contrasting its findings with prior work (e.g., Gatys et al., 2015a). The experimental results are robust, demonstrating that single-layer random-filter models can achieve competitive perceptual quality, particularly when multi-scale filters are used. The use of VGG-loss as a quantitative evaluation metric is a significant contribution, offering a more objective alternative to human inspection. The discussion on the balance between perceptual similarity and variability, as well as the connection to maximum entropy models, adds depth to the analysis.
Suggestions for Improvement:  
1. Computational Efficiency: The paper acknowledges the inefficiency of large-scale filters in single-layer models. Exploring strategies to mitigate this, such as hierarchical approximations or optimized implementations, would strengthen the practical applicability of the approach.  
2. Variability Assessment: While the paper focuses on perceptual similarity, a more detailed exploration of variability in the synthesized textures would provide a more comprehensive evaluation of the model's performance.  
3. Human Perception Studies: Incorporating psychophysical experiments to validate the perceptual quality of the textures would bolster the claims and provide additional evidence for the proposed evaluation metrics.  
Questions for the Authors:  
1. How does the proposed model perform on textures with highly irregular or non-repetitive structures? Are there limitations in such cases?  
2. Could the multi-scale approach be extended to include adaptive filter sizes based on the texture's characteristics?  
3. How sensitive is the model's performance to the choice of random filters? Would different random initializations lead to significant variations in texture quality?  
Overall, the paper makes a compelling case for rethinking the role of depth and pre-training in texture synthesis, offering a simpler yet effective alternative. The findings have the potential to inspire new directions in generative modeling and challenge existing paradigms in the field.