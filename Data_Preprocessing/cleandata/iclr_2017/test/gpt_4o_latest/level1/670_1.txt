Review of "MT-LRP: Multi-Task State Representation Learning with Robotic Priors"
Summary of Contributions
This paper introduces MT-LRP, a novel approach for learning state representations in multi-task reinforcement learning (RL) using robotic priors. The method is unsupervised, requiring no prior knowledge of the number or nature of tasks, and employs a gated neural network architecture to learn task-specific state representations and a task detector simultaneously. The authors extend the learning with robotic priors (LRP) framework by introducing a task-coherence prior, which enforces consistency and separation of tasks during training. The paper demonstrates the efficacy of MT-LRP through simulated experiments in a multi-task slot-car racing scenario, showing that it outperforms baseline methods in learning task-specific representations and policies, particularly in scenarios with high task ambiguity. The work is well-motivated, builds on prior literature in state representation learning and reinforcement learning, and provides insights into when and why the proposed method succeeds.
Decision: Accept
The paper makes a significant contribution to multi-task RL by addressing the challenge of learning task-specific state representations in an unsupervised manner. The method is novel, well-motivated, and rigorously evaluated. The key reasons for acceptance are:
1. Novelty and Contribution: MT-LRP extends existing state representation learning methods by combining robotic priors with task discovery, filling a gap in the literature.
2. Empirical Validation: The experiments convincingly demonstrate the superiority of MT-LRP over baselines, particularly in scenarios with task ambiguity, and provide insightful analyses of the learned representations.
Supporting Arguments
1. Problem and Motivation: The paper tackles the important problem of learning state representations for multiple tasks without task labels, which is critical for scaling RL to real-world scenarios. The motivation is clear, and the method is well-placed in the literature, building on prior work in robotic priors, gated networks, and task discovery.
2. Methodological Rigor: The proposed gated neural network architecture and task-coherence prior are innovative and well-justified. The inclusion of both task consistency and task separation terms in the loss function is a thoughtful design choice that enhances task-specific representation learning.
3. Experimental Evaluation: The experiments are thorough, with comparisons to strong baselines and ablation studies to isolate the contributions of different components. The results are compelling, showing that MT-LRP achieves near-optimal performance in most scenarios and significantly outperforms baselines in challenging settings.
Suggestions for Improvement
1. Clarity of Presentation: While the paper is technically sound, the presentation could be improved. For example, the mathematical notation in Section 4.1 is dense and could benefit from additional explanatory text or diagrams to aid understanding.
2. Task-Separation Loss: The experiments suggest that the task-separation term may not always be necessary. The authors could elaborate on scenarios where this term is beneficial and discuss its potential drawbacks, such as over-separation of tasks.
3. Generalization to Real-World Tasks: While the slot-car racing scenario is a useful testbed, it is relatively simple. Future work could evaluate MT-LRP on more complex, real-world tasks to demonstrate its scalability and robustness.
Questions for the Authors
1. How does the performance of MT-LRP scale with the number of tasks? Does the method remain effective when the number of tasks is significantly larger than the number of gate units?
2. Could the task-coherence prior be adapted for non-episodic settings where task boundaries are less well-defined?
3. How sensitive is MT-LRP to hyperparameter choices, such as the weights of the loss terms (e.g., ωτ)?
In conclusion, this paper presents a well-motivated and rigorously evaluated method that advances the state of the art in multi-task RL. While there are areas for improvement, the contributions are significant and warrant acceptance.