This paper presents a method for generating vector representations of documents using a skip-gram style learning approach, augmented with a regularizer in the form of a global context vector and various dropout mechanisms. While the individual components introduced in this work are not novel, I believe their combination in this particular manner is innovative. Additionally, I found the detailed analysis of the model's behavior in Section 3 to be insightful and well-executed.
The primary limitation of this submission lies in its relatively weak empirical evaluation. There are arguably more compelling tasks than sentiment analysis and k-way classification to demonstrate the method's utility. Similarly, dedicating 2/3 of a page to t-SNE projections feels like a missed opportunity to provide deeper analysis or evaluation.
Despite my reservations about the limited evaluation and my agreement with other reviewers regarding the use of soft baselines, I believe this paper warrants acceptance. The proposed algorithm is both interesting and efficient, and it is reasonable to expect that other researchers may find value in the ideas presented here.