The paper proposes a novel pruning technique for neural networks based on the second-order Taylor expansion and evaluates its performance against a first-order method and brute-force pruning. The authors conduct experiments on several toy examples, including a two-layer network trained on MNIST, and demonstrate that the second-order method performs significantly worse than the brute-force baseline. Furthermore, the authors interpret the success of brute-force pruning as evidence supporting the hypothesis of Mozer et al., which posits that neurons either contribute positively to network performance or cancel out the effects of other neurons.
The authors have made a commendable effort to present the details of their work in a clear and accessible manner, ensuring that even readers unfamiliar with pruning methods can follow the content. Moreover, they have been highly responsive and thorough in addressing all questions raised during the pre-review process.
However, my primary concern is that the paper lacks focus, does not offer a clear conclusion, and fails to articulate its contributions to the existing literature. To illustrate this, I summarize the key points of the conclusion section as follows:
- Paragraph 1: The paper does not benchmark against state-of-the-art methods; pruning methods perform poorly compared to brute-force; some evidence supports Mozer & Smolensky's hypothesis, but further investigation is needed.
- Paragraph 2: The second-order Taylor method is introduced but underperforms relative to the baseline.
- Paragraph 3: Re-training might improve results but is deemed unfair.
- Paragraph 4: Brute-force pruning achieves 40-70% reduction in shallow networks.
- Paragraph 5: Brute-force pruning is less effective in deeper networks.
- Paragraph 6: Not all neurons equally contribute to network performance.
The title and the authors' responses to pre-review questions suggest that the paper aims to explore learned representations rather than focus on the new second-order method or benchmark pruning algorithms. However, only two or three sentences in the conclusion—and none in the abstract's results section—address neural representations. For instance, the authors state in their pre-review response:
> Furthermore, we do not have to accept the conclusion that re-training is a necessary part of pruning because a brute force search reveals that neurons can in fact be  
> pruned from trained networks in a piecemeal fashion with no retraining and minimal adverse effect on the overall performance of the network. This would be  
> impossible if neurons did not belong to the distinct classes we describe.
Yet, this conclusion could already be drawn from the second-order method, which shares similar characteristics with other second-order approaches (not detailed here). This raises the question: what is the motivation for introducing a new second-order method?
Additionally, some minor conclusions about representations—such as the cancellation effect—may stem from artifacts of the greedy, serial pruning method. Ideally, one would need to evaluate all possible pruning combinations (a computationally infeasible task due to exponential scaling with the number of neurons). The authors acknowledge this limitation for conventional pruning methods in their conclusion: "Third, we assumed that pruning could be done in a serial fashion [...]. We found that all of these assumptions are deeply flawed in the sense that the true relevance of a neuron can only be partially approximated [...] at certain stages of the pruning process." However, the brute-force pruning process is also serial—why is this not considered a limitation?
Overall, it remains unclear what the paper contributes: it provides limited insights into learned representations and insufficient benchmarking against state-of-the-art pruning methods. I recommend the following steps to improve focus and impact:
1. Either benchmark against a state-of-the-art pruning method from the literature (that does not require re-training) or restrict the analysis to brute-force pruning alone, depending on whether the goal is to compare pruning methods or to investigate learned representations.
2. Minimize discussion of the second-order method to avoid confusing readers about the paper's purpose, and significantly shorten the manuscript.
3. Focus the experiments on a two-layer MNIST network and a deeper CIFAR-10 network for clarity and relevance.
4. Clearly articulate the paper's contributions in an itemized list and streamline the content to align with these contributions.
These revisions could significantly enhance the paper's impact but will require substantial reworking.
PS: The confusion begins with the following sentence in the abstract: "In this work we set out to test several long-held hypotheses about neural network learning representations and numerical approaches to pruning." These two aspects are largely orthogonal but are conflated throughout the paper.