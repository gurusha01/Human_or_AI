The paper introduces a method for learning low-dimensional state representations from raw observations in a multi-task setting. Unlike traditional multi-task learning approaches, which typically learn a joint representation by leveraging transferable information across tasks, this method focuses on identifying and solving individual tasks independently. To achieve this, the authors extend the "learning with robotic priors" framework by incorporating an additional term in the loss function to enforce task coherence, ensuring that task representations only change between training episodes. The method is evaluated on two tasks: multi-task slot-car racing and mobile navigation, demonstrating its potential effectiveness.
However, there are several unclear issues:
1. The first concern is whether the method is only suited for specific scenarios like slot-car racing or if it can be generalized to broader multi-task learning settings. While the authors argue in the related work section that their approach is orthogonal to multi-task learning, they acknowledge that both approaches explore shared knowledge across tasks. What are the advantages and disadvantages of the proposed method in general multi-task settings, particularly in comparison to multi-task joint learning? The authors' response to this question was not entirely satisfactory. Their argument did not justify the absence of a comparison with multi-task joint learning, and they do not appear to plan to include such a comparison. This omission is critical, as the lack of comparison undermines the fundamental motivation for the work. Without such an analysis, the method appears to be merely an alternative to multi-task joint learning, offering little (if any) practical advantage.
2. Building on the previous concern, the results for the mobile navigation task require clarification. It is unclear how the plot on the right supports the claim that MT-LRP identifies all tasks, as the evidence appears weak. Compared to the multi-task slot-car racing experiment, the results for mobile navigation are sparse, with almost no comparisons to alternative methods or baseline approaches. Is this indeed the case for the problem? While the authors provided additional details and explicit information in their response, the results remain insufficient to make a strong argument.
3. Regarding the proposed gated neural network architecture, it appears to employ a soft gating mechanism (please correct me if this interpretation is incorrect). A potential baseline for comparison would be a hard-gated structure. How might this alternative affect the conclusions? This question is particularly relevant given the constraint that the representation should remain consistent during training. The authors reiterated their modeling approach without addressing the comparison to hard gating, though this issue is less critical than the concerns raised in Question 1.
In summary, while there are still significant concerns regarding the lack of comparisons, there is a slight inclination toward accepting the submission.