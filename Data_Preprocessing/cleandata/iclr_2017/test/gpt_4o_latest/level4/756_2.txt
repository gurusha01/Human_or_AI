This paper introduces the use of feed-forward neural networks to learn similarity-preserving embeddings and extends the proposed approach to represent out-of-vocabulary words based on their contextual surroundings.
Firstly, in light of the related work [1,2], the proposed method offers limited novelty. Specifically, the concept of Context Encoders appears to be only a minor enhancement over word2vec.
The experimental setup would benefit from more robust evidence beyond visualizations and the use of a non-standard benchmark for evaluating word vectors in the context of NER [3].