This study examines the effectiveness of transfer learning from resource-rich environments (BookTest, CNN/Daily Mail corpora) to low-resource settings (bAbI, SQuAD benchmarks). The experimental results indicate minimal gains in zero-shot learning scenarios. However, some improvements are observed when the model is exposed to a few training examples.
The claims presented in this paper require a more thorough analysis. I question the use of bAbI as a representation of a low-resource real-world scenario. bAbI is specifically designed as a unit test and does not adequately capture the complexity of many natural language phenomena. Consequently, the conclusions drawn from bAbI provide only weak evidence for evaluating transfer learning from high-resource to low-resource settings in real-world applications. I strongly suggest incorporating recently proposed real-world benchmarks [1,2].
Additionally, the study does not sufficiently explain the mechanisms behind the observed improvements in transfer learning. While the authors briefly hypothesize that the transfer knowledge resides not only in embeddings but also in the model itself, this explanation is superficial. Given the context of related work [3], these claims offer limited novelty. A deeper exploration of the "how and why" behind the observed effects should be a central focus of this paper.  
[1]