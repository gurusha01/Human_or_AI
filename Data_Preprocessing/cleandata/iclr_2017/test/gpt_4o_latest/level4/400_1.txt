This paper introduces a variant of a recurrent neural network featuring two orthogonal temporal dimensions, designed to function as a decoder for generating tree structures (including their topology) within an encoder-decoder framework. The proposed architecture is well-justified, and I can envision several additional applications (beyond those discussed in the paper) that require generating tree structures from unstructured data.
One notable limitation of the paper lies in the scope of its experiments. While the IFTTT dataset is an intriguing and suitable application, and a synthetic dataset is also included, it would have been more compelling to explore additional natural language applications involving syntactic tree structures. Nonetheless, I find the experiments adequate as an initial demonstration of the novel architecture.
A key strength of the paper is the authors' exploration of various design choices for the topology predictor components of the architecture, particularly regarding when and how to decide termination, rather than relying on a single arbitrary approach.
Overall, I anticipate future applications of this architecture and believe it opens up promising directions for further research. Therefore, I recommend its acceptance as a contribution to the conference.