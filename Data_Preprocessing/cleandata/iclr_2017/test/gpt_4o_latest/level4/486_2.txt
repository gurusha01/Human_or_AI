The paper presents a method for semi-supervised learning on graphs that leverages the spectral properties of the graph within a convolutional neural network framework. The proposed approach is computationally efficient and demonstrates strong scalability on large datasets. Comparisons with baseline methods across multiple datasets reveal a significant improvement in performance using the proposed technique.
The paper is technically sound and well-written. The algorithm appears to scale effectively, and the results across datasets show clear advantages over the baselines. The method is straightforward, and the training process seems uncomplicated. Regarding originality, the proposed algorithm is essentially a straightforward adaptation of graph convolutional networks (as introduced in Defferrard et al., 2016) to a semi-supervised transductive learning setting. While this is explicitly acknowledged in the paper, the authors could better emphasize the distinctions and novel contributions relative to this prior work. Additionally, the paper does not include comparisons with iterative classification methods, which are known to perform well in terms of both accuracy and training efficiency, particularly in inductive settings. The authors should consider addressing this gap. Below, I provide some references for iterative classification methods that could be relevant for comparison.
The authors note that more complex filters could be learned by stacking additional layers but restrict their architecture to a single hidden layer. They should discuss the potential benefits and trade-offs of using deeper architectures for graph classification tasks.
References on iterative classification:  
- Qing Lu and Lise Getoor. 2003. Link-based classification. In ICML, Vol. 3. 496–503.  
- Gideon S Mann and Andrew McCallum. 2010. Generalized expectation criteria for semi-supervised learning with weakly labeled data. The Journal of Machine Learning Research 11 (2010), 955–984.  
- David Jensen, Jennifer Neville, and Brian Gallagher. 2004. Why collective inference improves relational classification. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 593–598.  
- Joseph J Pfeiffer III, Jennifer Neville, and Paul N Bennett. 2015. Overcoming Relational Learning Biases to Accurately Predict Preferences in Large Scale Networks. In Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 853–863.  
- Stephane Peters, Ludovic Denoyer, and Patrick Gallinari. 2010. Iterative annotation of multi-relational social networks. In Advances in Social Networks Analysis and Mining (ASONAM), 2010 International Conference on. IEEE, 96–103.