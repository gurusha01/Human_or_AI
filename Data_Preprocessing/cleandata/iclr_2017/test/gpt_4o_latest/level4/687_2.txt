I appreciated reading parts of the introduction and background, particularly the section that revisits influential papers from the late 1980s and early 1990s. The core idea of the proposal is straightforward: prune neurons based on the estimated change in the loss function derived from backpropagation, using either first-order or second-order approximations. The results align with expectations, showing that the first-order method performs worse than the second-order method, which, in turn, is outperformed by the brute-force approach.
That said, I believe this work is not suitable for ICLR for several reasons. First, the paper overlooks the now well-established understanding of weight decay algorithms and their connection to Bayesian priors, which I would consider essential to address in any work within this domain. Additionally, several claims in the text are not necessarily accurate, especially when viewed in the context of deep networks with modern regularization techniques. For instance, the authors assert that the brute-force method is the most accurate, but this assumes the independence of neuron effects, which may not hold true. Consequently, the sequential order of neuron removal may not represent the optimal approach.
Moreover, I find the paper unnecessarily lengthy, as the core idea and results could have been conveyed in a more concise manner. Lastly, while the inclusion of a Q&A section is noted, I believe these points should be integrated into the main body of the paper rather than presented separately.