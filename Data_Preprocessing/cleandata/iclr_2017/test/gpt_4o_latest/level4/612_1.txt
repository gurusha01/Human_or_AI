The paper introduces a method for future frame prediction that relies on transforming the previous frame rather than directly predicting pixels.
Several prior studies have proposed similar approaches. In their responses, the authors argue that earlier works are deterministic; however, the proposed model also fails to address multimodality.
Additionally, I suggested testing the method using two RGB frames as input and predicting the transformation as output. This would help evaluate the significance of employing transformations both as input and output, given that this is the first work to use transformations as input as well. The authors dismissed this suggestion, stating that "if we were to use RGB frames as input and ask the model to output future frames it would produce very blurry results," which indicates a misunderstanding of the suggestion. As it stands, the work does not appear to offer a meaningful novel contribution compared to prior research.