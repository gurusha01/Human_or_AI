After Rebuttal:
Thank you for providing the AlexNet results. While the results are not particularly strong, this in itself is not a major issue, as it raises interesting questions about why this might be the case, as the authors also point out. However, the omission of these results from the original submission (and their continued absence in the revised version) is concerning. Furthermore, some of the claims made in the paper appear to be inconsistent with these results. For example:
- "This suggests that our gains stem from the CC-GAN method rather than the use of a better architecture."
- "Since discrimination of real/fake in-paintings is more closely related to the target task of object classification than extracting a feature representation suitable for in-filling, it is not surprising that we are able to exceed the performance of Pathak et al. (2016) on PASCAL classification."
These statements, along with potentially other parts of the paper, need to be revised to reflect the new findings. In its current state, I do not believe the paper is ready for publication. A thorough revision would be necessary to address these issues.
---
Initial Review:
This paper explores the use of generative adversarial networks (GANs) for unsupervised feature learning. The authors demonstrate that the discriminator of a conditional GAN trained for image inpainting learns a representation that performs well on image classification tasks. Additionally, the method produces reasonably convincing inpainting results as a byproduct.
The proposed approach integrates two existing ideas: leveraging the discriminator of a GAN for feature learning [Radford et al. 2015] and using image inpainting for unsupervised feature learning [Pathak et al. 2016]. As such, the conceptual novelty of the paper is somewhat limited. On the positive side, the authors execute their approach effectively and achieve state-of-the-art results on STL-10, as well as promising results on Pascal VOC (though the Pascal experiments are incomplete, as discussed below). Overall, I am on the borderline regarding this paper but would be willing to increase my score if the authors address the experimental concerns outlined below.
1) The experimental evaluation on Pascal VOC is insufficient. The comparison with prior work is not entirely fair, as the authors use the VGG architecture, whereas existing methods predominantly use AlexNet. While the authors are transparent about this in the paper, I do not understand why they have not conducted experiments using AlexNet, especially since two reviewers specifically requested this. Such an experiment would significantly bolster the authors' claims. The justification provided—"we thought it reasonable to use more current models while making the difference clear"—is not compelling. While it is true that better architectures yield better results, it is equally important to ensure proper comparisons with prior work. On a related note, Doersch et al. have also experimented with the VGG architecture; could the authors compare their results to that work? Additionally, why is there no comparison to [Noroozi & Favaro, ECCV 2016]? Finally, I would like the authors to address the comment raised by Richard Zhang.
2) The qualitative inpainting results are incomplete. There is no comparison with prior methods (e.g., [Pathak et al. 2016]), and it is difficult to compare different variants of the proposed method because different images are used for each variant. While space constraints in the main paper are understandable, the supplementary material should include more comprehensive results. Quantitative evaluations of inpainting are also missing. As it stands, the inpainting results are visually interesting but do not contribute as much to the paper as they could.