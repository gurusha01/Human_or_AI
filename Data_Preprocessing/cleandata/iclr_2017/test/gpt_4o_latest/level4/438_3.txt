This innovative study introduces an approach to enhance existing RL models by incorporating self-supervised tasks aimed at fostering improved internal representations.  
The proposed auxiliary tasks include depth prediction and loop closure detection. While these tasks rely on the assumption of a 3D environment and some positional information, such priors are highly applicable to a wide range of navigation and robotics tasks.  
Comprehensive experiments demonstrate that integrating these auxiliary tasks not only boosts performance but also significantly accelerates learning. Further analysis of value functions and internal representations indicates that the model uncovers some underlying structure that would likely remain undiscovered without the inclusion of these auxiliary tasks.  
Although tailored to 3D-environment tasks, this work offers compelling evidence that leveraging input data alongside sparse external reward signals enhances both learning speed and the quality of internal representations. The study is original, well-articulated, and backed by robust empirical results.  
One minor limitation of the experimental methodology (or perhaps just the results presented) lies in the reliance on top-5 runs, which makes it challenging to discern whether the model's performance stems from its suitability to the chosen hyperparameter range or its robustness to hyperparameter variations. An analysis of performance across different hyperparameter settings could help validate the model's superiority over the baselines. My intuition is that incorporating auxiliary tasks likely improves robustness to suboptimal hyperparameters.  
Another shortcoming is the authors' dismissal of navigation literature as "not RL." While I understand the constraints on the scope of a single paper, some experimental comparisons with this body of work could have been valuable, even if only to evaluate the quality of the learned representations.