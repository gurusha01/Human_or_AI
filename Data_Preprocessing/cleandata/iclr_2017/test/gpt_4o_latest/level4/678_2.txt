This paper explores transfer learning within the context of question answering (QA) from stories. The proposed system is tasked with answering questions based on a given short story. The study investigates whether a system trained on one dataset can effectively answer questions from a different dataset. The findings, however, are predominantly negative: transfer learning appears to be almost nonexistent in this context.
The paper primarily focuses on presenting negative results. Specifically, the core hypothesis—that transfer learning between QA datasets using the attention sum reader is feasible—proves to be unachievable. The study demonstrates that achieving meaningful performance requires access to a small amount of labeled data from the target dataset.
While presenting negative results is acceptable if accompanied by a thorough analysis of failure modes and underlying reasons, this paper falls short in that regard. A detailed analysis could have provided valuable insights and suggested potential research directions, but such depth is largely absent here.
The responses to the pre-review questions begin to offer some interesting observations—for example, the apparent transfer of typing information. However, the paper does not delve into other potentially significant factors, such as the impact of syntax differences (e.g., between bAbI, Gutenberg books, and CNN news articles) or the overlap in word/entity/ngram distributions across the three datasets.
In its current form, the paper offers little in terms of actionable insights or takeaways.