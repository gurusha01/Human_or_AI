This paper addresses the problem of learning unsupervised state representations through multi-task reinforcement learning. The authors introduce a novel method that integrates gated neural networks with multitask learning, leveraging robotics priors. Their approach is evaluated on two simulated datasets, demonstrating promising results. The paper is well-written and grounded in solid theoretical principles.
Strengths:
+ Utilization of gating mechanisms to facilitate the learning of a joint representation.
+ Extension of multi-task learning beyond single-task approaches explored in prior work.
+ Effective combination of multiple loss functions (Coherence, Proportionality, Causality, Repeatability, Consistency, and Separation) to develop a robust representation.
Weaknesses:
- Arbitrary selection of parameters (e.g., the "w" parameters).
- Restricting multi-task learning to differentiate between tasks rather than enabling knowledge sharing and transfer across tasks.
- Experiments were not conducted using a standardized simulation framework, such as OpenAI Gym, which would enhance comparability.
I recommend that the authors adopt a more systematic approach for selecting model parameters and evaluate their method on standardized, high-dimensional datasets to strengthen the work further.