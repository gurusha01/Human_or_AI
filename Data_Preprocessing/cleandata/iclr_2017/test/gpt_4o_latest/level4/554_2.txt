The paper introduces a deep reinforcement learning approach incorporating eligibility traces. The authors integrate DRQN with eligibility traces to enhance training efficiency. The proposed algorithm is tested on two problems using a single set of hyperparameters and is compared against DQN.
The topic is highly engaging. While incorporating eligibility traces into reinforcement learning updates is not a new concept, this class of algorithms has not been thoroughly investigated in the context of deep reinforcement learning. The paper is well-written, with a comprehensive review of related work. However, additional experiments would significantly strengthen this promising contribution. Given that this is an exploratory, experimental study, it is essential to include a broader range of tasks, varied hyperparameter configurations, and comparisons with vanilla DRQN, DeepMind's DQN implementation, and other state-of-the-art methods.