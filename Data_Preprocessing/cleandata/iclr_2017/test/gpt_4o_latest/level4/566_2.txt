Review - Quality:  
The paper introduces a framework to integrate active learning into the deep learning paradigm, primarily addressing challenges such as scalability associated with training deep neural networks.  
That said, the paper appears to lack polish, as it contains numerous grammatical and typographical errors.
Clarity:  
Significant improvements are needed to enhance the clarity of the paper. The motivations presented in the introduction—specifically, the challenges of implementing active learning in deep architectures—could be articulated more effectively and connected more cohesively to the explanations in Section 3. For instance, while the authors highlight the importance of (mini)batch label queries in the introduction, this concept is not revisited in Section 3, where the main methodology is described.  
The related work section, although seemingly systematic and comprehensive, feels somewhat disconnected from the core content of the paper. Rather than serving as a survey of the literature, the related work section should help situate the current work within the existing research landscape, emphasizing its strengths and limitations. In this regard, the authors might consider shortening discussions of less relevant prior work and instead focusing on comparisons with closely related studies, such as Graves '11.
Originality & Significance:  
The authors propose an active learning framework for training, which conceptualizes the network parameter optimization problem as a Bayesian inference problem (a concept previously introduced by Graves) and formulates the active learning task as selecting the most informative data points. Here, informativeness is defined using the variational free energy, which depends on the Fisher information. To address the computational challenges of inverting the Fisher Information matrix, the authors introduce approximation techniques, which appear to be novel.  
This paper explores an intriguing direction—adapting deep learning to label-intensive problems through active learning. However, the presentation requires significant refinement to improve its overall quality.