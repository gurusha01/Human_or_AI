The paper proposes an alternative approach to supervising the training of neural networks without explicitly relying on labels, utilizing only link/not-link information between pairs of examples. A pair of networks is trained, where each network supervises the other.
The clarity of the paper's presentation is lacking, and the writing could be improved.  
Certain design choices are insufficiently justified: Why is the power function employed in the E-step to approximate the distribution (Section 2.1)? Why do the authors restrict themselves to a uniform distribution? While I understand that adopting a different prior would violate the assumption of no prior knowledge about the classes, I struggle to envision practical scenarios where the proposed framework would be applicable.
Additionally, there is a substantial body of work in semi-supervised learning that employs co-training, which is based on a similar concept.
In summary, I believe this work requires further clarification and refinement to align better with the standards of this venue.