This paper presents a similarity encoder built using a standard feed-forward neural network, designed to produce similarity-preserving embeddings. The proposed method extends the CBOW word2vec model by modifying the learned embeddings with their average context vectors. The authors evaluate their approach on tasks such as analogy reasoning and named entity recognition (NER).
While the paper provides some intuitive reasoning for why a feed-forward neural network can create effective similarity-preserving embeddings, the proposed architecture and methodology lack novelty. The model appears to be a straightforward feed-forward neural network trained with stochastic gradient descent (SGD) on similarity signals, without introducing significant innovation.
The idea of leveraging context embeddings to enhance the expressive power of word representations is somewhat more original. However, incorporating explicit contextual information is not a novel concept, particularly in tasks like word sense disambiguation. For instance, the paper by Neelakantan et al., "Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space," explores related ideas and should be cited. That said, the specific implementation of context embeddings in this work appears to be unique, to the best of my knowledge.
The experimental evaluation is unconvincing. The embeddings were trained on relatively small corpora, which are not representative of the scale typically used for unsupervised or semi-supervised embedding learning. The results on the analogy task provide limited insight into the method's potential performance on larger datasets. Furthermore, as the authors themselves acknowledge, the observed gains may diminish with larger corpora, where word2vec could capture similar global context statistics through extended training.
The authors argue (and I agree) that extrinsic evaluations hold greater relevance for practical applications, so the inclusion of NER experiments is a positive aspect. However, the embeddings used for these experiments were also trained on a small corpus, which raises doubts about whether the reported improvements would generalize to larger-scale training scenarios.
In summary, this paper demonstrates limited novelty and provides weak experimental evidence to substantiate its claims. I am unable to recommend it for acceptance.