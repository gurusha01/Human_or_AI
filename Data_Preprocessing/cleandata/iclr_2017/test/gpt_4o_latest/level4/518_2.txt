The authors introduce amortized SVGD, an extension of the Stein Variational Gradient Descent (SVGD) framework, which is a particle-based variational method designed to minimize the KL divergence at each update step. In this work, "amortized SVGD" is achieved by training a neural network to approximate the dynamics of SVGD. The authors then apply this approach to train energy-based models, which are characterized by their tractable unnormalized densities.
A key distinction of SVGD compared to standard MAP estimation lies in the inclusion of a "repulsive force," which mitigates particle degeneracy by encouraging the distribution of probability mass beyond the mode. However, it is unclear how this mechanism retains sufficient entropy-like behavior in high-dimensional spaces. In the authors' earlier work, this issue was less apparent as the experiments were limited to toy datasets and UCI benchmarks.
In the current experiments, the authors employ a kernel defined on the hidden representations of an autoencoder, which appears to be a critical component of their method. This is reminiscent of Li et al. (2015), where the kernel-based approach for MMD was similarly dependent on the choice of representation. However, unlike Li et al. (2015), the autoencoder in this work is integrated into the model and is not fixed. This undermines much of the authors' stated motivation and critiques of prior methods, as the reliance on a learned low-dimensional representation (which evolves during training) shifts the focus to the autoencoder itself, making it a central and dynamic part of the process.
Additionally, the proposed amortized SVGD approach appears to be less efficient than non-amortized methods. This inefficiency arises because the method requires updating the particles (xi) first, followed by regressing to update the neural network parameters (eta). In contrast, prior approaches typically update inference network parameters directly, without the need for intermediate local updates. This two-step process introduces significant computational overhead during training.
I recommend rejecting the paper and suggest that the authors provide more thorough experimental analysis in future iterations. Specifically, they should investigate the role of the autoencoder, compare incremental updates with full updates, and evaluate the training time of amortized versus non-amortized approaches. While the results presented are promising, it remains unclear what drives the observed performance given the numerous hyperparameters and design choices involved.
References
Li, Y., Swersky, K., & Zemel, R. (2015). Generative Moment Matching Networks. Presented at the International Conference on Machine Learning.