I appreciate the demonstration provided in the paper, showing that incorporating the learning of auxiliary tasks does not hinder the performance of RL tasks and, in fact, enhances it. This outcome, however, is not entirely unexpected when working with deep networks. The deep architecture of the model enables it to first develop a robust representation of the environment, which can then be leveraged to solve specific objectives. While early representations are naturally influenced by task performance, it is evident that there are shared initial stages in sensory processing, such as the necessity for edge detection. Consequently, training with auxiliary tasks effectively increases the overall training data. That said, it remains unclear how to account for this in order to ensure a fair comparison. The paper could have provided additional insights, such as an analysis of how the learned representations differ with and without auxiliary training.
However, I strongly disagree with the implied characterization of supervised and self-supervised learning in the paper. Unsupervised learning is traditionally defined as learning without the use of external labels, regardless of whether those labels are provided by a human or an expensive machine used to train the network for subsequent independent task performance. For instance, I would classify EM as a self-supervised method, where the model generates its own labels to iteratively refine its parameters. In this case, the method relies on externally supplied labels, which unequivocally makes it a supervised learning task!