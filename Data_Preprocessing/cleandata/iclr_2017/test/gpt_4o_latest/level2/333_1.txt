The paper presents a novel approach to natural texture synthesis, challenging the prevailing assumption that deep hierarchical architectures and supervised training are essential for high-quality texture generation. The authors propose a minimal baseline model using single-layer convolutional neural networks (CNNs) with random filters, demonstrating that such networks can rival state-of-the-art methods in perceptual quality. Key contributions include a systematic comparison of various single-layer architectures, the introduction of a quantitative evaluation metric based on VGG-based synthesis loss, and a discussion on the importance of multi-scale filters and non-linearities in texture synthesis.
Decision: Accept
The paper makes a compelling case for rethinking the necessity of deep architectures and supervised training in texture synthesis. Its findings are both novel and significant, offering a strong baseline for future research. The experimental results are thorough, and the proposed approach is well-motivated and scientifically rigorous. However, there are areas where the paper could be improved to enhance clarity and address potential limitations.
Supporting Arguments:
1. Novelty and Contribution: The paper challenges established paradigms by showing that single-layer CNNs with random filters can achieve competitive results. This is a significant departure from prior work, which heavily relies on deep, pre-trained networks. The introduction of a quantitative evaluation metric further strengthens the paper's contributions.
2. Experimental Rigor: The authors conduct extensive experiments, comparing different filter types (e.g., random, hand-crafted, unsupervised) and architectures. The results convincingly demonstrate that multi-scale random filters outperform single-scale models and that non-linearities are crucial for high-quality synthesis.
3. Practical Implications: The proposed approach simplifies the computational complexity of texture synthesis by eliminating the need for deep networks and supervised training. This has potential applications in scenarios where computational resources are limited.
Additional Feedback:
1. Clarity of Presentation: While the paper is thorough, some sections, particularly the mathematical formulations, could benefit from clearer explanations. For instance, the derivation of the Gram matrix and its role in texture synthesis might be challenging for readers unfamiliar with the field.
2. Limitations: The paper acknowledges the computational inefficiency of large filter sizes but does not explore potential optimizations in depth. A discussion on how to balance computational efficiency with synthesis quality would be valuable.
3. Variability vs. Perceptual Similarity: The authors focus on maximizing perceptual similarity but note the trade-off with variability. Future work could explore methods to better balance these two aspects, potentially using psychophysical assessments as suggested.
4. Generalization: While the results are promising for texture synthesis, it would be interesting to see if the findings extend to other image generation tasks, such as artistic style transfer or inpainting.
Questions for the Authors:
1. How does the proposed approach perform on textures with highly irregular or non-repetitive patterns? Are there specific limitations in such cases?
2. Could the computational inefficiency of large filters be mitigated by using approximations or alternative architectures, such as dilated convolutions?
3. How sensitive is the performance of the model to the choice of random filters? Would different random initializations lead to significant variations in synthesis quality?
Overall, the paper presents a strong case for its claims and offers valuable insights into the role of shallow architectures in texture synthesis. With minor improvements in clarity and a deeper exploration of limitations, this work has the potential to make a lasting impact on the field.