This paper proposes a novel approach to providing strong privacy guarantees for training data in machine learning applications, called Private Aggregation of Teacher Ensembles (PATE). The authors demonstrate that PATE can be used to train models with high utility and meaningful privacy guarantees, even when combined with semi-supervised learning. The approach is based on training an ensemble of teacher models on disjoint subsets of the sensitive data and then using a student model to learn from the aggregate output of the ensemble. The student model is trained on non-sensitive and unlabeled data, and the privacy guarantees are established using differential privacy.
The paper makes several key contributions, including: (1) demonstrating a general machine learning strategy that provides differential privacy for training data in a "black-box" manner, (2) improving upon previous work on learning machine models that protect training data privacy, (3) exploring different approaches for reducing the student's dependence on its teachers, and (4) presenting a new application of the moments accountant technique for improving the differential-privacy analysis of knowledge transfer.
The authors evaluate their framework on MNIST and SVHN, achieving state-of-the-art privacy/utility trade-offs. They also demonstrate the applicability of PATE to other model structures and datasets with different characteristics.
I decide to accept this paper because it presents a well-motivated and well-placed approach to providing strong privacy guarantees for training data in machine learning applications. The paper is well-written, and the authors provide a clear and concise explanation of their approach and its contributions. The evaluation results are impressive, and the authors demonstrate the applicability of PATE to different datasets and model structures.
However, I do have some suggestions for improvement. Firstly, the paper could benefit from a more detailed discussion of the limitations of the approach and potential avenues for future work. Secondly, the authors could provide more insight into the choice of hyperparameters and the sensitivity of the results to these choices. Finally, the paper could benefit from a more detailed comparison with other related work in the area of differential privacy and machine learning.
Some questions I would like the authors to answer to clarify my understanding of the paper include: (1) How do the authors choose the number of teachers and the noise scale parameter Î³? (2) Can the authors provide more insight into the trade-off between the accuracy and privacy of labels predicted by the ensemble? (3) How do the authors plan to extend their approach to other machine learning applications and datasets? 
Additional feedback to help improve the paper includes: (1) providing more details on the implementation of the moments accountant technique and its application to the PATE approach, (2) discussing the potential applications of PATE to other areas of machine learning, such as natural language processing and computer vision, and (3) providing more insight into the potential limitations and challenges of implementing PATE in practice.