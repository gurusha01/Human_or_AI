This paper explores the suitability of deep versus shallow networks for various functions, with a focus on the role of pooling operations in combining correlated information. The authors present theoretical results for convolutional arithmetic circuits, utilizing the concept of separability to measure the complexity of functions relative to a particular geometry of pooling operations.
The paper tackles the specific question of whether deep or shallow networks are more effective in representing complex functions, and whether the use of pooling operations can improve the performance of shallow networks. The approach is well-motivated, as it addresses a fundamental problem in machine learning and provides a novel perspective on the role of depth and pooling in neural networks.
However, the comparison between deep and shallow networks is somewhat misleading, as shallow networks lack a hierarchical pooling structure, making it more of an analysis of the effect of pooling versus no pooling. Additionally, the paper's theoretical results may be limited by their dependence on product pooling, and extension to max pooling could provide more insight, potentially through simple illustrative examples.
The relationship between network depth and separability of representable functions is not explicitly discussed, leaving questions about why very deep networks are often more effective than shallower ones. Nevertheless, the paper addresses an important problem in an interesting way, and its limitations, such as the focus on arithmetic circuits and comparison to shallow networks without localized pooling, reduce its convincingness in explaining the importance of depth.
I decide to reject this paper, with the main reason being that the comparison between deep and shallow networks is not entirely fair, and the paper's theoretical results are limited by their dependence on product pooling. Additionally, the paper lacks a clear discussion of the relationship between network depth and separability of representable functions.
To improve the paper, I would suggest that the authors provide more insight into the relationship between network depth and separability, and explore the use of max pooling in addition to product pooling. Furthermore, the authors could consider comparing deep and shallow networks with similar architectures, such as shallow networks with hierarchical pooling structures, to provide a more fair comparison.
Some questions I would like the authors to answer to clarify my understanding of the paper include: How do the authors plan to extend their theoretical results to max pooling, and what insights do they expect to gain from this extension? How do the authors think their results relate to the performance of deep and shallow networks in practice, and what implications do their results have for the design of neural network architectures? What are the potential applications of the authors' work, and how do they plan to explore these applications in future research?