Summary of the Paper's Contributions
The paper proposes a novel method for domain transfer, which involves learning a generative function to map samples from a source domain to a target domain while preserving the representation of a given function. The authors introduce a compound loss function that combines a multiclass GAN loss, an f-preserving component, and a regularizing component to encourage the generator to map samples from the target domain to themselves. The method is evaluated on two application domains: digits and face images, demonstrating its ability to generate convincing novel images of previously unseen entities while preserving their identity.
Decision and Key Reasons
I decide to accept this paper with two key reasons: (1) the paper tackles a novel and well-motivated problem of domain transfer, and (2) the proposed method is well-supported by experimental results, demonstrating its effectiveness in generating high-quality images that preserve the representation of the given function.
Supporting Arguments
The paper provides a clear and well-structured introduction to the problem of domain transfer, highlighting its relevance to various applications. The proposed method is well-motivated, and the authors provide a thorough analysis of the compound loss function and its components. The experimental results are impressive, demonstrating the ability of the method to generate high-quality images that preserve the representation of the given function. The authors also provide a detailed comparison with existing methods, such as style transfer, and demonstrate the advantages of their approach.
Additional Feedback and Questions
To further improve the paper, I suggest the authors consider providing more analysis on the role of the regularizing component and its impact on the generator's performance. Additionally, it would be interesting to see more experiments on the robustness of the method to different types of noise and perturbations. I also have a few questions for the authors: (1) How do the authors plan to extend the method to more complex domains, such as videos or 3D models? (2) Can the method be used for other types of transfer learning tasks, such as transferring knowledge from one task to another? (3) How does the method handle cases where the representation of the given function is not well-defined or is ambiguous?