This paper proposes a novel framework for modeling the co-evolution of user and item latent features in recommender systems, leveraging recurrent neural networks (RNNs) and temporal point processes. The approach, dubbed DEEPCOEVOLVE, captures the nonlinear and dynamic relationships between users and items, allowing for accurate predictions of both item interactions and time of interactions.
The specific question tackled by the paper is how to effectively model the co-evolution of user and item features in recommender systems, where users and items influence each other over time. The approach is well-motivated, building upon existing work in temporal point processes and RNNs, and addressing the limitations of traditional methods that rely on static or epoch-based representations.
The paper supports its claims through extensive experiments on three real-world datasets, demonstrating significant improvements in both item prediction and time prediction tasks compared to state-of-the-art baselines. The results are scientifically rigorous, with careful consideration of dataset sparsity and robustness of the algorithm.
I decide to accept this paper, with two key reasons: (1) the proposed approach is novel and well-motivated, addressing a significant challenge in recommender systems; and (2) the experimental results demonstrate significant improvements over existing methods, with careful evaluation of dataset sparsity and algorithm robustness.
To further improve the paper, I suggest providing additional analysis on the latent variables, including component collapsing, and exploring the impact of different learning-rate and momentum scheduling approaches on training speed. Additionally, it would be helpful to clarify the relationship between the proposed approach and existing work in temporal point processes and RNNs.
Questions I would like answered by the authors include: (1) How do the authors plan to extend the approach to other social applications, such as group dynamics in message services? (2) Can the authors provide more insight into the computational efficiency of the proposed algorithm, particularly in terms of scalability to large datasets? (3) How do the authors plan to address potential issues with overfitting or underfitting in the RNN model, particularly in cases where the dataset is highly sparse?