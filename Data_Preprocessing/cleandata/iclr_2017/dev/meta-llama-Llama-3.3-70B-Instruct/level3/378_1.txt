Summary
The paper proposes a novel end-to-end speech recognition system that combines a convolutional neural network (CNN) with a graph decoding approach, trained using an automatic segmentation criterion called AutoSegCriterion (ASG). The system is designed to output letters directly from the speech signal, without the need for force alignment of phonemes. The authors claim that their approach is simpler and faster than traditional methods, and achieves competitive results on the LibriSpeech corpus.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the main motivation of the paper is unclear, and the authors should benchmark their algorithm with standard reinforcement learning tasks to clarify their goal. Secondly, the paper's comparison with REINFORCE is limited, as it uses a simple version of REINFORCE on a non-standard task, and stronger baselines should be considered.
Supporting Arguments
The paper proposes a novel approach to speech recognition, but it is not clear how this approach relates to the broader field of reinforcement learning. The authors should provide more context and motivation for their work, and benchmark their algorithm against standard reinforcement learning tasks. Additionally, the comparison with REINFORCE is limited, and the authors should consider stronger baselines to demonstrate the effectiveness of their approach.
Additional Feedback
To improve the paper, the authors should provide more details on the architecture of their CNN and the graph decoding approach. They should also consider using more advanced techniques, such as attention mechanisms or transfer learning, to improve the performance of their system. Furthermore, the authors should provide more analysis on the results, including error analysis and comparison with other state-of-the-art systems.
Questions for the Authors
I would like to ask the authors to clarify the following points:
* How does the proposed approach relate to the broader field of reinforcement learning?
* Why was the AutoSegCriterion (ASG) chosen over other sequence criteria, such as CTC?
* How does the performance of the system vary with different types of input features, such as MFCCs, power spectrum, and raw waveform?
* What are the potential applications of this approach, and how does it compare to other state-of-the-art speech recognition systems?