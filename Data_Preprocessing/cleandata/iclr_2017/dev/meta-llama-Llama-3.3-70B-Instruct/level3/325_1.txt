Summary of the Paper's Claims and Contributions
The paper proposes a novel approach to providing strong privacy guarantees for training data in machine learning applications, called Private Aggregation of Teacher Ensembles (PATE). The approach combines multiple models trained on disjoint datasets, using a noisy voting mechanism to aggregate their predictions. The paper demonstrates that PATE can provide excellent utility while maintaining meaningful worst-case guarantees, outperforming existing differentially private machine learning methods. The authors also introduce a new application of the moments accountant technique to improve the differential-privacy analysis of knowledge transfer.
Decision and Key Reasons
I decide to Accept this paper, with two key reasons:
1. Novel and effective approach: The paper proposes a novel and effective approach to providing strong privacy guarantees for training data, which is a critical problem in machine learning. The approach is well-motivated, and the authors demonstrate its effectiveness through experiments on several datasets.
2. State-of-the-art results: The paper achieves state-of-the-art results in terms of privacy/utility trade-offs on several benchmark datasets, including MNIST and SVHN. The authors also provide a thorough analysis of the approach's privacy guarantees, using the moments accountant technique.
Supporting Arguments
The paper provides a clear and well-structured presentation of the PATE approach, including its motivation, technical details, and experimental evaluation. The authors demonstrate the approach's effectiveness in providing strong privacy guarantees while maintaining good utility, and they provide a thorough analysis of the approach's privacy guarantees. The paper also discusses the limitations of the approach and potential avenues for future work.
Additional Feedback and Questions
To further improve the paper, I would like to see more discussion on the following topics:
* How does the number of teachers affect the privacy cost, and what is the optimal number of teachers for a given dataset and task?
* Can the PATE approach be applied to other machine learning tasks, such as natural language processing or reinforcement learning?
* How does the approach compare to other differentially private machine learning methods, such as those based on gradient descent or Bayesian inference?
I would also like the authors to clarify the following points:
* How is the privacy parameter Î³ chosen, and what is its impact on the approach's privacy guarantees?
* Can the approach be used with other types of noise, such as Gaussian noise, instead of Laplacian noise?
* How does the approach handle cases where the data is not naturally partitioned, such as in the case of online learning or streaming data?