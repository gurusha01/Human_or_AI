Summary
The paper proposes a generative model, Generative Paragraph Vector (GPV), which is a probabilistic extension of the Distributed Bag of Words version of Paragraph Vector (PV-DBOW). GPV introduces a complete generative process for a corpus, allowing it to infer distributed representations for unseen texts. The authors also propose a supervised version, Supervised Generative Paragraph Vector (SGPV), which incorporates text labels into the model to guide representation learning. The experiments demonstrate that both GPV and SGPV outperform state-of-the-art baselines on several text classification tasks.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper lacks clear explanations of the model architecture and its relation to the class of joint distributions, leaving some aspects of the approach somewhat heuristic. Secondly, the experiments are limited to simple, synthetic examples of missing data and would be more convincing with real-world problem applications.
Supporting Arguments
The paper proposes an elegant approach to controlling the generality of represented distributions using tensors to represent joint distributions of mixture components. However, the choice of model architecture and its relation to the class of joint distributions is not clearly explained, which raises questions about the expected performance of the model in challenging scenarios. Additionally, the experiments are limited to simple, synthetic examples of missing data, and the handling of missing data in the experiments is unclear, particularly when only a subset of a region is missing. The computational runtime of the proposed method is also not discussed, which is an important consideration for real-world applications.
Additional Feedback
To improve the paper, the authors should provide a clearer explanation of the model architecture and its relation to the class of joint distributions. They should also conduct more extensive experiments on real-world problem applications, such as the Netflix challenge, to demonstrate the effectiveness of the proposed method. Furthermore, the authors should discuss the computational runtime of the proposed method and provide more details on the handling of missing data in the experiments. The paper could also benefit from careful proofreading to eliminate minor errors in grammar and terminology.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence, I would like the authors to answer the following questions:
1. Can you provide a more detailed explanation of the model architecture and its relation to the class of joint distributions?
2. How do you handle missing data in the experiments, particularly when only a subset of a region is missing?
3. What is the computational runtime of the proposed method, and how does it compare to other state-of-the-art methods?
4. Can you provide more extensive experiments on real-world problem applications to demonstrate the effectiveness of the proposed method?