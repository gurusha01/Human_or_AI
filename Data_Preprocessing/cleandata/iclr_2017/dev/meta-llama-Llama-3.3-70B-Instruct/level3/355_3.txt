Summary
The paper introduces an Input Switched Affine Network (ISAN) model, a recurrent neural network architecture designed with intelligibility in mind. The authors demonstrate that ISAN achieves comparable performance to traditional RNN architectures, such as GRUs and LSTMs, on a character-level language modeling task. The simplicity of the latent dynamics in ISAN allows for easier interpretation and understanding of the trained model. The paper provides various analyses, including decomposition of current predictions based on previous time steps, change of basis, and comparison with n-gram models.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper lacks a thorough discussion of related work, particularly in the areas of reward shaping, incremental task setups, and complementary work on other FPS games. Secondly, I have two unanswered concerns that were mentioned in a previous review by AnonReviewer2, which the authors have not addressed.
Supporting Arguments
The paper's contribution to the field of neural networks is significant, as it provides a new perspective on designing intelligible models. However, the lack of references to relevant literature on reward shaping, incremental task setups, and complementary work on other FPS games limits the paper's impact. Furthermore, the authors' failure to address the concerns raised by AnonReviewer2 undermines the paper's credibility.
Additional Feedback
To improve the paper, I suggest that the authors provide a more comprehensive discussion of related work, including references to relevant literature on reward shaping, incremental task setups, and complementary work on other FPS games. Additionally, the authors should address the concerns raised by AnonReviewer2 and provide clear explanations for their design decisions. The authors may also consider providing more experimental results to demonstrate the effectiveness of their approach.
Questions for the Authors
To clarify my understanding of the paper and provide additional evidence for my assessment, I would like the authors to answer the following questions:
1. How do the authors plan to address the concerns raised by AnonReviewer2, and what changes will they make to the paper to address these concerns?
2. Can the authors provide more references to relevant literature on reward shaping, incremental task setups, and complementary work on other FPS games, and discuss how their work relates to these areas?
3. How do the authors plan to scale their approach to larger input sets, such as word-level language models with enormous vocabularies, and what additional logic will they use to achieve this?