This paper presents a novel approach to program synthesis, called Neuro-Symbolic Program Synthesis (NSPS), which uses a probabilistic generative model called Recursive-Reverse-Recursive Neural Network (R3NN) to synthesize string manipulation programs based on input-output pairs. The approach is interesting and promising, but the model appears too complicated and unclear at several places, requiring further clarification.
The experimental results are weak, with the model obtaining an accuracy of 38% on the FlashFill benchmark with 5 input-output examples, which degrades to 29% with 10 examples. This raises questions about the model's applicability to long programs and its evaluation methodology. Additionally, the paper lacks baseline results on the FlashFill benchmark, making it difficult to assess the model's performance.
I have several technical questions about the model, including how the probability distribution is normalized, the impact of using only 1 input-output pair, and the input-output representation. The paper exceeds the recommended page limit and needs to be shortened to improve clarity and readability.
Based on these concerns, I recommend a weak reject, encouraging the authors to address the comments and resubmit the paper. The paper's general idea is promising, but it requires significant revisions to improve its clarity, readability, and experimental results.
To improve the paper, I suggest the authors provide more details on the model's architecture, experimental setup, and evaluation methodology. They should also consider adding more baseline results and comparing their model's performance to existing approaches. Additionally, the authors should clarify the technical aspects of the model, such as the normalization of the probability distribution and the impact of using only 1 input-output pair.
Some specific questions I would like the authors to answer include:
* How does the model handle long programs, and what are the limitations of the current approach?
* Can the authors provide more details on the input-output representation and how it is used in the model?
* How does the model's performance change when using different numbers of input-output examples, and what are the implications of this for the model's applicability?
* Can the authors provide more baseline results and comparisons to existing approaches to better assess the model's performance?