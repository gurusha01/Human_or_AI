Summary of the Paper's Contributions
The paper presents a novel approach to the problem of domain transfer, where the goal is to learn a mapping between two related domains, S and T, such that the output of a given representation function f remains unchanged. The authors propose a Domain Transfer Network (DTN) that employs a compound loss function, including a multiclass GAN loss, an f-preserving component, and a regularizing component. The DTN is evaluated on two application domains: digits and face images, demonstrating its ability to generate convincing novel images of previously unseen entities while preserving their identity.
Decision and Key Reasons
Based on the evaluation of the paper, I decide to Accept the paper with some minor revisions. The two key reasons for this decision are:
1. The paper tackles a novel and significant problem in the field of domain transfer, and the proposed approach shows promising results on two different application domains.
2. The paper is well-written, and the authors provide a clear and concise explanation of the methodology, experiments, and results.
Supporting Arguments
The paper's significance and originality lie in its systematic evaluation of various parameterizations, and the results demonstrate the effectiveness of the proposed DTN approach. The authors also provide a thorough analysis of the contributions of each component of the loss function, which helps to understand the importance of each term. Additionally, the paper includes a comprehensive review of related work, which helps to contextualize the proposed approach within the broader field of domain transfer and generative models.
Additional Feedback and Questions
To further improve the paper, I suggest that the authors provide more analysis on the sensitivity of the results to the choice of hyperparameters and the robustness of the approach to different types of noise or perturbations. Additionally, it would be interesting to see more examples of the generated images and a more detailed comparison with other state-of-the-art methods.
Some questions I would like the authors to answer to clarify my understanding of the paper are:
* Can the authors provide more insight into the choice of the specific architecture of the DTN and the selection of the hyperparameters?
* How does the proposed approach handle cases where the domains S and T have different distributions or densities?
* Are there any plans to extend the approach to more complex domains or tasks, such as video or 3D data?