Summary of the Paper's Contributions
The paper proposes a novel approach to providing strong privacy guarantees for training data in machine learning applications. The authors introduce the Private Aggregation of Teacher Ensembles (PATE) framework, which combines multiple models trained on disjoint datasets to produce a student model that learns to predict an output chosen by noisy voting among all the teachers. The PATE approach provides a general and applicable method for protecting the privacy of training data, independent of the learning algorithm used to train the teachers or the student. The authors demonstrate the effectiveness of their approach on several benchmark datasets, including MNIST and SVHN, and show that it achieves state-of-the-art privacy/utility trade-offs.
Decision and Reasons
I decide to accept this paper, with the primary reason being its unique and creditable effort to combine differential geometry of curves with convolutional neural networks. The approach used by the authors, including a Siamese configuration and adaptation of deep convnet frameworks to 1D signals, is reasonable and makes sense if the problem is worth pursuing. Although I have concerns about the narrow audience for this type of shape representation at the ICLR conference, I believe that the paper's contributions and results are significant enough to warrant acceptance.
Supporting Arguments
The paper tackles a specific and important problem in machine learning, namely protecting the privacy of training data. The authors' approach is well-motivated and well-placed in the literature, building on previous work on differential privacy and knowledge transfer. The paper provides a clear and detailed explanation of the PATE framework and its components, including the noisy aggregation mechanism and the semi-supervised training of the student model. The authors also provide a thorough analysis of the privacy guarantees of their approach, using the moments accountant technique to bound the privacy cost.
Additional Feedback and Questions
To improve the paper, I suggest that the authors provide more details on the implementation of the PATE framework, including the specific architectures used for the teacher and student models. I would also like to see more experiments on different datasets and tasks, to demonstrate the general applicability of the approach. Additionally, I have some questions about the sensitivity of the approach to hyperparameters, such as the number of teachers and the noise scale, and how these parameters affect the trade-off between privacy and utility.
Specifically, I would like the authors to answer the following questions:
* How do the authors choose the number of teachers and the noise scale in the PATE framework, and what is the effect of these parameters on the privacy/utility trade-off?
* Can the authors provide more details on the semi-supervised training of the student model, including the specific loss functions and optimization algorithms used?
* How do the authors plan to extend the PATE framework to other machine learning tasks and datasets, and what are the potential challenges and limitations of their approach?