The paper investigates the ability of convolutional networks to model correlations among regions of their input, with a focus on convolutional arithmetic circuits. The authors analyze the separation rank of functions realized by these circuits, which measures how far a function is from being separable with respect to a given partition of the input. They show that a deep network can support exponentially high separation ranks for certain input partitions, while being limited to polynomial or linear separation ranks for others. The network's pooling geometry effectively determines which input partitions are favored in terms of separation rank.
The authors also establish a connection between the separation rank and the L2 distance from separable functions, providing an upper bound on the L2 distance in terms of the separation rank. They demonstrate that the specific lower bound on separation ranks of deep convolutional arithmetic circuits can be translated into a lower bound on the L2 distance from separable functions.
The paper concludes with empirical validation of the authors' conclusions, using both convolutional arithmetic circuits and convolutional rectifier networks. The experiments demonstrate how different pooling geometries lead to superior performance in different tasks, such as measuring shape continuity and symmetry.
Overall, the paper provides a theoretical understanding of the inductive bias of convolutional networks and how it relates to their ability to model correlations among input regions. The results have implications for the design of convolutional networks and the choice of pooling geometry, and suggest that the analysis can be extended to other types of neural networks.
To answer the three key questions:
1. The specific question/problem tackled by the paper is the analysis of the inductive bias of convolutional networks and how it relates to their ability to model correlations among input regions.
2. The approach is well-motivated, as it provides a theoretical understanding of the inductive bias of convolutional networks and has implications for their design and application.
3. The paper supports its claims through a combination of theoretical analysis and empirical validation, providing a rigorous and well-supported argument.
Based on the analysis, I would accept the paper, as it provides a significant contribution to the understanding of convolutional networks and their inductive bias. The paper is well-written, and the arguments are clear and well-supported. The empirical validation provides additional evidence for the authors' claims, and the results have implications for the design and application of convolutional networks.
However, I would suggest some minor revisions to improve the clarity and readability of the paper. Specifically, some of the mathematical notation and terminology could be explained in more detail, and some of the figures and tables could be improved for better visualization. Additionally, the authors could provide more discussion on the implications of their results and how they can be applied in practice. 
Some questions I would like the authors to answer to clarify my understanding of the paper are:
* Can the authors provide more intuition on why the separation rank is a good measure of the correlation between input regions?
* How do the authors choose the pooling geometry, and what are the implications of different pooling geometries on the inductive bias of the network?
* Can the authors provide more details on the empirical validation, such as the specific datasets and tasks used, and how the results were evaluated?
* How do the authors think their results can be applied in practice, and what are the potential implications for the design and application of convolutional networks?