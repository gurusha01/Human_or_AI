Summary
The paper presents a novel approach to modeling sensory neurons using multitask recurrent neural networks (RNNs). The authors demonstrate that RNNs can outperform traditional generalized linear models (GLMs) in predicting the spiking responses of primate retinal ganglion cells to natural images. The paper also introduces a GLM-RNN hybrid model, which provides insights into the aspects of retinal processing better captured by RNNs.
Decision
I decide to reject this paper, with the main reason being the lack of proper experimental justification. The paper only reports validation loss, and there is no testing result or common evaluation criteria provided. This makes it difficult to assess the generalizability and robustness of the proposed approach.
Supporting Arguments
The application of sparsity in backward gradients for training LSTMs is an interesting finding, and the paper provides a good overview of the current state-of-the-art models in neuroscience. However, the experimental results are not comprehensive, and the paper lacks actual justification of gains in speed and efficiency. The authors claim that the multitask framework improves predictive performance, but more rigorous evaluation is needed to support this claim.
Additional Feedback
To improve the paper, I suggest including testing results and common evaluation criteria, such as accuracy, precision, and recall. The authors should also provide more details on the experimental setup, including the dataset used, the training and testing protocols, and the hyperparameter tuning process. Additionally, the paper could benefit from a more thorough analysis of the GLM-RNN hybrid model, including its strengths and limitations.
Questions for the Authors
1. Can you provide more details on the testing protocol and the evaluation metrics used to assess the performance of the proposed approach?
2. How did you tune the hyperparameters of the RNNs, and what was the effect of different hyperparameter settings on the performance of the model?
3. Can you provide more insights into the interpretability of the RNNs, and how they can be used to guide the development of simpler, more mechanistic models of neural processing?