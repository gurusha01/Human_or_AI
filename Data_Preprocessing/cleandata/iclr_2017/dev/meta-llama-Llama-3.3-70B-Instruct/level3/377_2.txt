Summary of the Paper's Contributions
The paper proposes a novel approach to modeling long-term dependency in sequential data using higher-order recurrent neural networks (HORNNs). The authors extend the standard RNN structure by incorporating multiple memory units to capture more preceding states, which are fed back to the hidden layer through different weighted paths. This approach is shown to improve the model's ability to capture long-term dependency and outperform regular RNNs and LSTMs on language modeling tasks.
Decision and Key Reasons
I decide to reject this paper, with two key reasons for this choice. Firstly, the paper lacks a clear connection to the concept of gathering information through direct interaction with the environment, which is the main theme of the conference. Secondly, the paper's MDP formulation is not fully defined, with unclear state and action spaces, which makes it difficult to evaluate the effectiveness of the proposed approach.
Supporting Arguments
The paper's focus on language modeling tasks, while interesting, does not align with the conference's theme of active learning and exploration-exploitation in RL. Additionally, the paper's empirical results, although promising, do not provide a clear understanding of how the proposed approach would work in a more general setting. The lack of a formal grounding in an existing framework and the unclear MDP formulation make it challenging to assess the paper's contributions and potential impact.
Additional Feedback and Questions
To improve the paper, I suggest that the authors provide a clearer connection to the conference theme and a more detailed explanation of the MDP formulation. I would also like to see more analysis on the effectiveness of the proposed approach in different scenarios and a comparison with other state-of-the-art methods. Some questions I would like the authors to answer include: How does the proposed approach relate to other methods for modeling long-term dependency in sequential data? How do the authors plan to extend the approach to other sequential modeling tasks, such as speech recognition and sequence-to-sequence modeling? What are the potential limitations and challenges of the proposed approach, and how do the authors plan to address them?