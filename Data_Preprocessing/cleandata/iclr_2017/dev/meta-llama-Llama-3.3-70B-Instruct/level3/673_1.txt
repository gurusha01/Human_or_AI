Summary of the Paper
The paper proposes a novel technique called Neuro-Symbolic Program Synthesis (NSPS) that learns to generate programs incrementally based on given input-output examples. The approach uses two novel neural modules: the cross correlation I/O network and the Recursive-Reverse-Recursive Neural Network (R3NN). The R3NN model encodes partial program trees and expands them into full program trees, conditioned on input-output examples. The paper demonstrates the effectiveness of NSPS on the domain of regular expression-based string transformations.
Decision
I decide to reject this paper, with two key reasons for this choice. Firstly, the model's hierarchical memory is fixed rather than learned, which may limit its ability to generalize to new tasks. Secondly, the comparison of different mips values is unclear, and it is not evident whether using the lowest value of 1-mips is the best approach.
Supporting Arguments
The paper's approach to program synthesis is novel and well-motivated, and the use of neural networks to condition the search space of programs is an interesting idea. However, the fixed hierarchical memory may not be sufficient to capture the complexities of program synthesis, and the lack of learning in this component may limit the model's ability to generalize. Additionally, the comparison of different mips values is not well-explained, and it is unclear whether the chosen approach is optimal.
Additional Feedback
To improve the paper, the authors could consider learning the hierarchical memory structure instead of fixing it. This could involve using a separate neural network to predict the memory structure based on the input-output examples. Additionally, the authors could provide more explanation and justification for the comparison of different mips values, and consider alternative approaches to evaluating the model's performance.
Questions for the Authors
I would like the authors to clarify the following points:
* How do the authors plan to address the limitation of the fixed hierarchical memory, and what alternative approaches have they considered?
* Can the authors provide more explanation and justification for the comparison of different mips values, and how they chose the optimal value?
* How do the authors plan to evaluate the model's performance on more complex tasks, and what metrics will they use to measure success?