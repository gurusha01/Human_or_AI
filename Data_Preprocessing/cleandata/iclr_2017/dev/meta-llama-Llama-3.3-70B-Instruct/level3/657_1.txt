Summary of the Paper's Claims and Contributions
The paper presents a novel end-to-end speech recognition system that combines a convolutional neural network (CNN) with a graph decoding approach, trained using a simple sequence criterion called AutoSegCriterion (ASG). The system is designed to output letters directly from the speech signal, without the need for phonetic transcription or force alignment. The authors claim that their approach is competitive with state-of-the-art systems on the LibriSpeech corpus, with a word error rate (WER) of 7.2% using MFCC features, and promising results using power spectrum and raw speech features.
Decision and Key Reasons
I decide to Reject this paper, with two key reasons:
1. Lack of novelty: The paper's main contribution, the AutoSegCriterion, is not significantly novel, as it is similar to existing sequence criteria such as Connectionist Temporal Classification (CTC). The authors' claim that their approach is faster and more accurate than CTC is not convincingly demonstrated.
2. Insufficient evaluation: The paper's evaluation is limited to a single dataset (LibriSpeech) and does not provide a thorough comparison with other state-of-the-art systems. The authors' claim that their approach is competitive with other systems is not supported by sufficient evidence.
Supporting Arguments
While the paper presents a well-written and clear description of the proposed system, the lack of novelty and insufficient evaluation are significant concerns. The authors' claim that their approach is faster and more accurate than CTC is based on a limited comparison, and it is not clear whether the results would generalize to other datasets or scenarios. Additionally, the paper does not provide a thorough analysis of the system's performance on different types of speech or noise conditions.
Additional Feedback and Questions
To improve the paper, I would suggest that the authors:
* Provide a more thorough comparison with other state-of-the-art systems, including a detailed analysis of the strengths and weaknesses of each approach.
* Evaluate the system on multiple datasets and scenarios, including noisy speech and different languages.
* Provide more details on the implementation of the AutoSegCriterion and the graph decoding approach, including any optimization techniques used.
* Consider adding more ablation studies to demonstrate the effectiveness of each component of the system.
Some questions I would like the authors to answer include:
* How does the AutoSegCriterion differ from other sequence criteria, such as CTC, and what are the advantages and disadvantages of each approach?
* How does the system perform on speech with different types of noise or degradation, such as background noise or reverberation?
* Can the authors provide more details on the computational resources required to train and deploy the system, and how it compares to other state-of-the-art systems?