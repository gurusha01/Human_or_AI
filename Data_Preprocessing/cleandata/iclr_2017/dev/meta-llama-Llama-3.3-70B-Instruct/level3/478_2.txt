Summary of the Paper's Contributions
The authors propose a framework called Private Aggregation of Teacher Ensembles (PATE) that provides strong privacy guarantees for training data in a "black-box" manner, independent of the learning algorithm. The approach combines multiple models trained with disjoint datasets, using them as "teachers" for a "student" model that learns to predict an output chosen by noisy voting among all the teachers. The paper demonstrates the effectiveness of PATE on MNIST and SVHN datasets, achieving state-of-the-art privacy/utility trade-offs. The authors also provide a data-dependent privacy analysis using the moments accountant technique, which allows for more precise bounds on the privacy cost.
Decision and Key Reasons
I decide to Reject this paper, with two key reasons:
1. Lack of thorough quantitative analysis: The experimental evaluation relies on specific examples rather than measuring robust statistics over multiple curves, which raises concerns about the generality of the results.
2. Limited novelty: The paper's novelty is limited, as Siamese networks have been used for years, and this work only applies them to a different task, which may not be sufficient for the ICLR conference.
Supporting Arguments
The paper's approach, while well-motivated, has some limitations. The selection of negative samples may lead to inferior performance, and the experimental evaluation lacks a thorough quantitative analysis. Additionally, the paper's novelty is limited, as Siamese networks have been used in various applications before. While the authors demonstrate the effectiveness of PATE on MNIST and SVHN datasets, the results may not generalize to other datasets or tasks.
Additional Feedback and Questions
To improve the paper, I suggest that the authors:
* Provide a more thorough quantitative analysis of the results, including robust statistics over multiple curves.
* Discuss the limitations of the approach and potential avenues for future work.
* Clarify the novelty of the paper and how it contributes to the existing literature on Siamese networks and privacy-preserving machine learning.
I would like the authors to answer the following questions:
* How do the authors plan to address the limitations of the approach, particularly with regards to the selection of negative samples?
* Can the authors provide more details on the experimental setup and the hyperparameters used in the experiments?
* How do the authors envision the PATE approach being applied to other datasets and tasks, and what are the potential challenges and limitations?