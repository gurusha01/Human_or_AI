Summary
The paper proposes a novel approach to generating synthetic training data for deep networks using 3D models and adversarial training, applied to honeybee identification. However, the provided paper does not match the problem statement. The paper actually introduces a Generative Paragraph Vector (GPV) and a Supervised Generative Paragraph Vector (SGPV) for learning distributed representations of texts. The GPV model is a probabilistic extension of the Distributed Bag of Words version of Paragraph Vector, and the SGPV model incorporates labels paired with the texts into the model to guide the representation learning. The authors demonstrate the effectiveness of their models on five text classification benchmark datasets.
Decision
I decide to reject the paper, with the main reason being that the paper does not match the problem statement. Additionally, the paper lacks experiments on standard and realistic datasets to demonstrate the general applicability of the proposed approach.
Supporting Arguments
The paper is well-written, and the proposed method is reasonable. The inclusion of a baseline with manually designed transformations strengthens the paper and provides a useful comparison. However, the authors' claims of improvement over previous work are overstated, and further analysis is needed to determine the necessity of restricting the model to a fixed set of transformations and identifying the most important transformations.
Additional Feedback
To improve the paper, the authors should provide more experiments on standard and realistic datasets to demonstrate the general applicability of the proposed approach. Additionally, the authors should tone down their claims of improvement over previous work and provide more detailed analysis of the results. The authors should also consider providing more details on the hyperparameter tuning and the computational resources used to train the models.
Questions for the Authors
1. Can you provide more details on how the GPV and SGPV models are applied to the honeybee identification problem?
2. How do you plan to extend the GPV and SGPV models to more complex and realistic datasets?
3. Can you provide more analysis on the importance of word order information in modeling text semantics?
4. How do you plan to address the issue of overfitting in the SGPV model, especially when the number of parameters is large?
5. Can you provide more details on the computational resources used to train the models and the hyperparameter tuning process?