Summary
The paper proposes a Generative Paragraph Vector (GPV) model, a probabilistic extension of the Distributed Bag of Words version of Paragraph Vector, with a complete generative process for a corpus. This allows for the inference of distributed representations for unseen texts. The authors also introduce a supervised version, Supervised Generative Paragraph Vector (SGPV), which incorporates text labels into the model. The experiments demonstrate the effectiveness of GPV and SGPV in text classification tasks, outperforming state-of-the-art baselines.
Decision
I decide to reject this paper, with two key reasons: (1) the paper has technical flaws, including undefined product of vectors and incorrect equation dimensions, which raise concerns about the correctness of the model; and (2) the interpretation of the CP decomposition or HT decomposition on the prior density tensor in the joint density over all samples modeled as a tensorial mixture generative model is unclear.
Supporting Arguments
The technical flaws in the paper, such as undefined product of vectors and incorrect equation dimensions, indicate a lack of rigor in the mathematical formulation of the model. This raises concerns about the correctness of the model and its ability to produce reliable results. Furthermore, the unclear interpretation of the CP decomposition or HT decomposition on the prior density tensor makes it difficult to understand the underlying assumptions and limitations of the model.
Additional Feedback
To improve the paper, the authors should address the technical flaws and provide a clear interpretation of the CP decomposition or HT decomposition. Additionally, the authors should comment on the sample complexity of the method given the complexity of the model. The use of convolution operators to compute an inner product may lose the invariance structure, which is the advantage of CNN compared to feed-forward neural networks. The authors should also clarify the special case for diagonal Gaussian Mixture Models and the claim that TMM reduces to product of mixture model.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions: (1) Can you provide a clear interpretation of the CP decomposition or HT decomposition on the prior density tensor? (2) How do you address the technical flaws in the paper, such as undefined product of vectors and incorrect equation dimensions? (3) Can you provide more details on the sample complexity of the method and its relationship to the complexity of the model?