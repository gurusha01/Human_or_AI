Summary
The paper introduces a novel recurrent neural network architecture called Input Switched Affine Network (ISAN), which achieves state-of-the-art performance on a language modeling task while being more interpretable and computationally efficient than traditional RNNs. The ISAN model uses affine transformations without nonlinearity, allowing for linear analysis and decomposition of the network's predictions. The authors demonstrate the effectiveness of the ISAN model on the Text8 dataset and provide various analyses to understand how the network makes predictions.
Decision
I decide to Accept this paper with two key reasons: (1) the paper tackles a specific and important problem in the field of neural networks, namely, the lack of interpretability in traditional RNNs, and (2) the approach is well-motivated and supported by thorough analyses and experiments.
Supporting Arguments
The paper provides a clear and well-structured introduction to the problem and the proposed solution. The authors motivate the need for interpretable neural networks and explain how the ISAN model addresses this need. The experimental results demonstrate that the ISAN model achieves comparable performance to traditional RNNs on the language modeling task, while being more efficient and interpretable. The analyses provided in the paper, such as the decomposition of current predictions based on previous time steps and the change of basis, offer valuable insights into how the network makes predictions.
Additional Feedback
To further improve the paper, I suggest that the authors provide more comparisons with other interpretable neural network architectures and discuss the potential limitations and challenges of the ISAN model. Additionally, it would be helpful to include more visualizations and examples to illustrate the interpretability of the ISAN model. Some questions I would like the authors to answer include: (1) How does the ISAN model handle out-of-vocabulary words or characters? (2) Can the ISAN model be applied to other tasks beyond language modeling? (3) How does the computational efficiency of the ISAN model compare to traditional RNNs in practice?