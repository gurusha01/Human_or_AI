Summary
This paper proposes a novel approach to learning geometric invariants of planar curves using a convolutional neural network (CNN) framework. The authors leverage the representational power of CNNs to compute invariant geometric quantities, such as curvature, and demonstrate that their approach outperforms traditional axiomatic constructions in terms of numerical robustness and stability. The paper also introduces a multi-scale representation paradigm, which allows for a hierarchical analysis of curves at varying levels of abstraction.
Decision
I decide to Accept this paper, with the main reason being that the approach is well-motivated and effectively tackles the problem of learning geometric invariants. The paper provides a clear and concise introduction to the problem, a thorough review of related work, and a well-structured presentation of the proposed method.
Supporting Arguments
The paper supports its claims through a series of experiments, which demonstrate the robustness and effectiveness of the proposed approach. The authors show that their method can handle noise, sampling variations, and occlusions, and that it outperforms traditional methods in terms of numerical stability. The paper also provides a clear and intuitive explanation of the multi-scale representation paradigm, which is a novel contribution to the field.
Additional Feedback
To further improve the paper, I suggest that the authors provide more details on the implementation of the CNN architecture, including the specific hyperparameters used and the training procedure. Additionally, it would be helpful to include more visualizations of the learned invariant signatures and their applications in shape analysis and retrieval tasks. Finally, the authors may want to consider discussing the limitations of their approach and potential avenues for future research.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on the construction of the negative examples used in the training dataset?
2. How do you ensure that the learned invariant signatures are indeed invariant to the desired transformations (e.g., rotations, translations, and reflections)?
3. Can you discuss the potential applications of the proposed approach in other fields, such as computer vision, robotics, or medical imaging?