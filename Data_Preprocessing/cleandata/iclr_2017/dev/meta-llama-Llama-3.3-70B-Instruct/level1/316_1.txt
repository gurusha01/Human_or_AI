Summary
The paper proposes a novel approach to providing strong privacy guarantees for training data in machine learning applications, called Private Aggregation of Teacher Ensembles (PATE). The approach combines multiple models trained on disjoint datasets, using them as "teachers" to train a "student" model that learns to predict an output chosen by noisy voting among all the teachers. The student model's privacy properties can be understood both intuitively and formally, in terms of differential privacy. The paper demonstrates the effectiveness of PATE on MNIST and SVHN datasets, achieving state-of-the-art privacy/utility trade-offs.
Decision
I decide to accept this paper, with two key reasons for this choice. Firstly, the paper tackles a specific and important problem in machine learning, namely protecting the privacy of sensitive training data. Secondly, the approach proposed by the authors is well-motivated, well-placed in the literature, and supported by thorough experimental evaluations.
Supporting Arguments
The paper provides a clear and concise introduction to the problem of protecting sensitive training data, and motivates the need for a new approach. The authors demonstrate a good understanding of the existing literature on differential privacy and machine learning, and propose a novel solution that builds upon previous work. The experimental evaluations are thorough and well-designed, demonstrating the effectiveness of PATE on multiple datasets. The paper also provides a detailed analysis of the privacy guarantees provided by PATE, using the moments accountant technique.
Additional Feedback
To further improve the paper, I suggest that the authors consider providing more detailed explanations of the theoretical results, particularly in Section 3. Additionally, it would be helpful to include more comparisons with other related work, such as the recent advances in federated learning and distributed differential privacy. Finally, the authors may want to consider exploring the applicability of PATE to other machine learning tasks, such as natural language processing and reinforcement learning.
Questions for the Authors
I would like to ask the authors to clarify the following points:
1. How do the authors plan to extend PATE to more complex machine learning tasks, such as those involving multiple modalities or sequential data?
2. Can the authors provide more insights into the trade-offs between the number of teachers, the noise scale, and the privacy guarantees in PATE?
3. How do the authors plan to address the potential limitations of PATE, such as the requirement for a large number of teachers and the potential impact on model accuracy?