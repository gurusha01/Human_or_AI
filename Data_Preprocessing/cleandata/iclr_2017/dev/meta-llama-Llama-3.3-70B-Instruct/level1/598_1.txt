Summary
This paper presents a novel end-to-end speech recognition system that combines a convolutional neural network (CNN) with a graph decoding approach, trained using a simple sequence criterion called AutoSegCriterion (ASG). The system is designed to output letters directly from the speech signal, without the need for force alignment of phonemes. The authors demonstrate competitive results on the LibriSpeech corpus, with word error rates (WERs) of 7.2% using Mel-Frequency Cepstral Coefficients (MFCCs) and 9.4% and 10.1% using power spectrum and raw waveform features, respectively.
Decision
I decide to Accept this paper, with two key reasons: (1) the approach is well-motivated and placed in the literature, addressing a significant problem in speech recognition, and (2) the paper supports its claims with rigorous experiments and results, demonstrating the effectiveness of the proposed ASG criterion and the overall system.
Supporting Arguments
The paper provides a clear and concise introduction to the problem of speech recognition and the limitations of traditional approaches. The authors motivate their approach by highlighting the need for a simpler and more efficient system that can learn from raw speech data without requiring force alignment or phonetic transcription. The experimental results demonstrate the competitiveness of the proposed system, with WERs comparable to state-of-the-art systems. Additionally, the authors provide a thorough analysis of the ASG criterion, showing its advantages over the Connectionist Temporal Classification (CTC) criterion.
Additional Feedback
To further improve the paper, I suggest the authors provide more details on the implementation of the ASG criterion, including the optimization algorithm used and the hyperparameter tuning process. Additionally, it would be interesting to see more experiments on the robustness of the system to different types of noise and speaking styles. Finally, the authors may want to consider providing more insights into the computational efficiency of the system, including the memory requirements and the processing time for larger datasets.
Questions for the Authors
To clarify my understanding of the paper, I would like the authors to answer the following questions:
1. Can you provide more details on the optimization algorithm used to train the CNN and the ASG criterion?
2. How did you tune the hyperparameters for the ASG criterion, and what was the impact of different hyperparameter settings on the results?
3. Have you considered applying the proposed system to other speech recognition tasks, such as speech-to-text or voice command recognition?