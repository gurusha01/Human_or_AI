Summary of the Paper's Claims and Contributions
This paper proposes a novel approach to modeling sensory neurons using multitask recurrent neural networks (RNNs). The authors claim that their framework provides a more accurate and flexible way to capture complex computations of neurons, outperforming traditional generalized linear models (GLMs) in predicting the spiking responses of primate retinal ganglion cells to natural images. The paper also introduces a GLM-RNN hybrid model, which provides insights into the aspects of retinal processing better captured by the recurrent neural networks.
Decision and Key Reasons
Based on the review, I decide to Accept this paper. The two key reasons for this choice are: (1) the paper tackles a specific and important problem in neuroscience, namely, developing accurate predictive models of sensory neurons, and (2) the approach is well-motivated and supported by rigorous empirical results, demonstrating the effectiveness of the proposed multitask RNN framework in capturing complex neural computations.
Supporting Arguments
The paper provides a clear and well-structured presentation of the problem, approach, and results. The authors motivate their approach by highlighting the limitations of traditional GLMs and the potential benefits of using deep neural networks to model neural spiking responses. The empirical results demonstrate the superiority of the proposed multitask RNN framework over traditional GLMs and individual RNNs, both in terms of predictive performance and robustness to limited training data. The introduction of the GLM-RNN hybrid model provides additional insights into the aspects of retinal processing that are better captured by the recurrent neural networks.
Additional Feedback and Questions
To further improve the paper, I suggest that the authors provide more detailed analysis of the learned features and dynamics captured by the recurrent neural networks. Specifically, I would like to see more visualizations and interpretations of the learned filters and weights, as well as a more thorough discussion of the implications of the results for our understanding of sensory processing and brain computations. Some questions I would like the authors to address include: (1) How do the learned features and dynamics captured by the RNNs relate to known properties of retinal ganglion cells? (2) Can the proposed framework be extended to model other types of sensory neurons or brain areas? (3) How do the results of this study inform the development of retinal prosthetics or other neural interfaces?