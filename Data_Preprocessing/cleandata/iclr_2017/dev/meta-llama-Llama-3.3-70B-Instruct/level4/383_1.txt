This manuscript presents a reinforcement learning-based framework for the automated design of neural network architectures, wherein an agent selects a new layer type and its associated parameters at each time step. To mitigate the complexity of the state-action space, the authors employ a restricted set of design options.
The key strengths of this work include:
- The introduction of a pioneering approach to automatic neural network architecture design, leveraging reinforcement learning.
- The demonstration of promising performance on multiple benchmark datasets, including MNIST and CIFAR-10.
However, several weaknesses are noted:
- The architecture design choices are constrained by numerous pre-defined assumptions, such as a limited range of convolutional filter numbers, a maximum of two fully-connected layers, and fixed dropout rates.
- While the method is showcased in a tabular Q-learning context, its efficacy in larger state-action spaces remains uncertain.
In conclusion, this work proposes an innovative and intriguing approach to neural network architecture design, meriting publication despite some limitations.