This manuscript introduces a novel, theoretically-grounded approach to sentence vector representation. The experimental results demonstrate that the generated vectors achieve strong performance on similarity and entailment benchmarks, outperforming certain RNN-based methods.
In general, this is a noteworthy empirical finding, particularly given that the model appears to be order-invariant. To further enhance the paper, it would be beneficial to include a more in-depth analysis explaining why this relatively simple model surpasses LSTM-based methods in capturing similarity and entailment. It is also worth exploring whether this outcome is a consequence of the specific characteristics of the benchmarks used.