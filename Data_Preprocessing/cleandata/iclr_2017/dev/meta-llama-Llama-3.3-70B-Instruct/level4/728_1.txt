The paper commences by highlighting the necessity for methods that can perform both state and temporal representation learning in reinforcement learning (RL), while also providing insight into the learning process, potentially enabling human intervention when required. This objective is of significant practical importance, and it is commendable to see research efforts directed towards this goal. As such, I strongly encourage the authors to continue pursuing this line of inquiry. Nevertheless, I have reservations regarding the current formulation of this work, with concerns stemming from both presentation and potential conceptual limitations.
To achieve "interpretability," the authors employ specific abstraction methods, such as initializing and terminating skills in single states, and utilizing clustering for forming higher-level states. These constraints appear overly restrictive, and it is unclear why such limitations are necessary beyond convenience. Similarly, the approach to ensuring temporal coherence seems restrictive. The authors reference supplementary material that supposedly justifies these choices, but this was not accessible in the posted version of the paper. It is essential for the authors to either provide clear explanations for these specific choices or consider relaxing these constraints while maintaining interpretability.
From a presentation perspective, the paper would benefit significantly from the inclusion of formal definitions for AMDP and SAMDP, as well as detailed mathematical descriptions of the algorithms used in constructing these representations, such as Bellman equations and update rules. While the paper offers intuitive explanations, the mathematical formulations are not precisely stated. Additionally, the computational overhead of constructing an SAMDP, including time and space complexity, should be clarified.
The experimental section is well-executed, with a commendable inclusion of both gridworld experiments, which facilitate easy visualization and understanding, and Atari games. The results are positive, but due to the complex nature of the proposed approach, which relies on several specific choices, the significance and general applicability of the method remain uncertain at this point. Access to the complete supplementary material might have provided further insight in this regard.
On a minor note, there are typographical errors in the notation and an incorrect sign in the equation following Eq 2.