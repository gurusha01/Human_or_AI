This paper proposes a novel approach to building generative models using tensors, where the input is divided into regions represented by mixture models, and the joint distribution of the mixture components is captured by a tensor. By leveraging efficient tensor decomposition, the authors train convolutional arithmetic circuits to generate the probability of the input and class label, resulting in a generative model of the input and labels.
The proposed framework appears to be elegant and provides a nice way to control the generality of the represented distributions. However, the choice of specific architecture and its relation to the class of joint distributions that can be represented is not entirely clear. While the overall framework is promising, it is unclear how the authors' choices are made, and whether they are heuristic or based on a more systematic approach.
The experimental evaluation is limited to simple, synthetic examples of missing data, which restricts the paper's convincingness. It would be more persuasive to include experiments on real-world problems with missing data, such as the Netflix challenge. Moreover, the requirement to know which input elements are missing limits the applicability of the approach. The experiments do provide reasonable comparisons to prior work, but the lack of real-world examples is a notable limitation.
The handling of missing data in the experiments is somewhat confusing. Initially, it seemed that the generative model was built over region patches in the image, suggesting marginalization over missing regions. However, when dealing with IID randomly missing pixels, it is unclear why marginalization is appropriate, especially since every region may be missing some information. The summation in the equation following Equation 6 could also be computationally expensive, and its runtime is not discussed.
The paper's scope and applicability beyond images are unclear. While the motivation for the probabilistic model is mostly image-based, the authors claim that their method is not limited to images. However, the experiments only involve image-based comparisons, and it would be more convincing to include experiments outside the image domain.
Furthermore, it is unclear whether the proposed network utilizes translation invariance, a key property of CNNs that contributes to their success. The authors do not explicitly address whether their network encodes translation invariance through weight sharing or other means, which raises questions about its expected performance in challenging image domains.
On a minor note, the paper requires careful proofreading, as evidenced by several errors in the first few pages, such as "significantly lesser" instead of "significantly less", "the the", and "provenly" instead of "provably".