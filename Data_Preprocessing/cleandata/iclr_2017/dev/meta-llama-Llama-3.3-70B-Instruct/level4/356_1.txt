This paper proposes a methodology for synthesizing string manipulation programs from input-output pairs, focusing on a specific class of programs defined by a simple context-free grammar. The approach utilizes a probabilistic generative model, known as the Recursive-Reverse-Recursive Neural Network (R3NN), which assigns probabilities to program parse trees through a combination of bottom-up and top-down passes. The results are evaluated on both a synthetic dataset and the FlashFill benchmark from Microsoft Excel.
The problem of program synthesis is of significant interest, particularly within the deep learning community, and the approach presented, leveraging parse trees and recursive neural networks, appears intriguing and holds promise. However, the complexity and clarity of the model are concerns, with several aspects requiring further elucidation. Moreover, the experimental section is notably weak, leading to the conclusion that the paper is not yet ready for publication based on the current state of its experimental results.
Initially, the paper's concept was viewed favorably, but upon closer examination, it was found that the method achieves an accuracy of 38% on the FlashFill benchmark with 5 input-output examples, yet this performance drops to 29% when the number of examples is increased to 10. This unexpected degradation raises significant concerns, potentially indicating either a flaw in the implementation or a fundamental limitation of the model. For program synthesis to be effective, it must be capable of handling multiple input-output examples, as complex programs often require numerous examples to accurately define their behavior.
Given the shortcomings in the experimental section, it is challenging to support the paper's publication in its current form. Therefore, a weak reject recommendation is made. The authors are encouraged to address the detailed comments provided and resubmit, as the underlying idea shows potential.
Additional comments and questions include:
- Clarification on how the probability distribution is normalized, particularly in the context of bottom-up and top-down evaluation of potentials, and whether this involves enumerating different program completions and comparing their exponentiated potentials. If so, this could limit the model's applicability to longer programs due to the prohibitive cost of enumerating completions.
- Inquiry into the model's performance when using only 1 input-output pair per program, and whether this yields improved results.
- Request for elaboration on Section 5.1.2, potentially through the inclusion of examples, to clarify the input-output representation and its assumptions regarding the number of input-output examples across different tasks.
- Suggestions for the experimental section include presenting baseline results on the FlashFill benchmark for comparison, clarifying the method's applicability to programs of varying lengths, defining the criteria for a program to be considered correct (e.g., exact match to a test program or success on held-out input-output pairs), and specifying whether the reported accuracy is for the best program out of multiple samples or after filtering based on training data.
- Lastly, the paper exceeds the recommended page limit, and consideration should be given to condensing the content to improve readability and adherence to guidelines.