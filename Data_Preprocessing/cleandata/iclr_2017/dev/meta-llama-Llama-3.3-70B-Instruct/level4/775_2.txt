This paper examines the application of deep reinforcement learning to control high-dimensional characters, with a focus on comparing the impact of different control parameterizations on reinforcement learning and optimized control policies. The study evaluates various planar gait cycle trajectories under different parameterizations, including torques, muscle activations, and PD control with target joint positions and velocities. The results suggest that more abstract parameterizations yield more robust and higher-quality policies.
> Significance & Originality:
While the parameterizations explored in this study are fairly standard in humanoid control, the systematic evaluation of these parameterizations is a notable contribution. This type of investigation is valuable and provides meaningful insights, although the findings may be specific to the particular problem and tested architecture. The transferability of these results to other networks and control problems is uncertain, which may limit the paper's appeal to the ICLR community, potentially making it more suitable for the robotics or graphics community.
> Clarity:
The paper is well-structured and accessible to readers with a background in constrained multi-body simulation and control, making it relatively easy to follow.
> Experiments:
In my view, the experimental validation could be more comprehensive. Given the paper's emphasis on experimental results, I would have expected a more detailed analysis of parameter sensitivity and performance variance across multiple policy optimizations.