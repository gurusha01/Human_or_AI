The paper presents a well-founded concept with promising results. However, the computational requirements of the proposed method raise significant concerns, as it demands 8-10 days on 10 GPUs for relatively small datasets, which is impractically expensive for most real-world applications.
A crucial aspect to investigate is the scalability of this approach to larger images and its performance on unconventional or limited datasets. Conducting an experiment on the Caltech-101 dataset, for instance, would be highly insightful in determining the method's viability in low-data regimes and scenarios where suitable architecture designs are not immediately apparent. In contrast to well-studied datasets like Cifar-10/100, MNIST, and SVHN, where reasonable model initializations are well-established, demonstrating the ability to discover competitive architectures for more challenging datasets would be a significant contribution.
If the authors can provide evidence of their method's effectiveness in discovering a competitive architecture for a dataset like Caltech-101, it would substantially strengthen the paper's case for publication.
Minor suggestions include adding a reference to ResNets in the table for completeness.