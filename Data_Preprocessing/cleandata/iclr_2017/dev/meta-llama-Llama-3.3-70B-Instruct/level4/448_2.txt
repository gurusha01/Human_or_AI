This manuscript presents an extension of a recent mean-field approximation for deep random neural networks, focusing on the analysis of depth-dependent information propagation, its phase transitions, and the effects of dropout. The manuscript is exceptionally well-structured and clearly written, with rigorous mathematical derivations and supporting numerical simulations that validate the theoretical findings. Notably, this work distinguishes itself as one of the limited studies that provide an in-depth examination of both the training dynamics and performance of deep neural networks.