This paper is overall of high quality, presenting an engaging and well-structured narrative that effectively advances the field of differentially-private deep learning. The authors' writing style is clear and thorough, making the content accessible to readers.
However, one notable limitation is the lack of theoretical guarantees regarding the learning performance of the proposed approach. Typically, research in privacy-preserving machine learning analyzes both the privacy aspect, often in the context of differential privacy (DP), and the learning performance under various assumptions. Since the learning performance may be influenced by the choice of architecture, it is recommended that the authors conduct additional experiments using the same datasets but with different architectures to validate their findings. Alternatively, they should provide a justification for the chosen architecture and clarify what aspects of the observed learning performance can be generalized.
Another concern is that the reported epsilon values are not privately releasable, as the authors' technique for doing so would alter the resulting epsilon. This issue needs to be addressed to enable a meaningful comparison with the epsilon-delta values reported in related studies.
Furthermore, the authors acknowledge that their approach may not be applicable to other natural data types. Therefore, it is strongly suggested that they conduct experiments on additional datasets to demonstrate the broader applicability of their method. Additionally, they should cite the datasets used in their research.
In terms of related work, the authors provide a thorough discussion of certain topics, but it would be beneficial to include a survey or discussion of research on differentially-private semi-supervised learning. For instance, a relevant study (G. Jagannathan, C. Monteleoni, and K. Pillaipakkamnatt, 2013) proposed a differentially-private semi-supervised learning approach via a teacher-learner framework, which is not explicitly mentioned as such. This study used private labeled data only for learning the primary ensemble and then learned a secondary ensemble from unlabeled data using pseudo-labels generated by the primary ensemble.
The comparison of approaches in Section C is commendable, but it is essential to ensure that the quantitative results constitute a fair comparison with the GAN results.
The paper is generally well-written, but some sections require clarification. For example, the last paragraph of Section 3.1 should be rephrased to clarify that the training data is the same with respect to the same teacher on the neighboring database, not with respect to all teachers. In Section 4.1, the authors mention a trade-off between the classification task's complexity and the available data, but this trade-off is not formalized, making the statement imprecise. Additionally, the discussion of Figure 3 is unclear and should be revised for better understanding. The text and caption seem to imply contradictory statements regarding the gap, which is likely not the intended meaning.