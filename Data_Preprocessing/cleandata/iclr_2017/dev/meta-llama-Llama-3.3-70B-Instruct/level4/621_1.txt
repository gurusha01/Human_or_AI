This paper addresses the task of music generation utilizing an orderless NADE model for the "fill in the notes" task. The model is trained on a sequence of T timesteps of pitches, where some pitches are randomly masked, and the goal is to predict the missing notes, following the standard training procedure for orderless NADE models. Typically, ancestral sampling is employed during the sampling process, which involves defining an ordering over outputs and iteratively running the model on the current input, sampling one output, and adding it to the next input until all outputs are sampled. However, the authors argue that this sampling strategy is suboptimal and instead propose adopting the blocked Gibbs sampling approach introduced by Yao et al. in 2014. This method involves randomly masking N inputs, sampling them, and repeating the process, which helps ensure the sampling chain mixes well, particularly for large N. Nevertheless, using a large N results in incoherent samples due to their independence. To address this, the authors implement an annealed schedule for N, gradually decreasing it over time, ultimately reducing to ancestral sampling and providing global structure to the sample. The paper presents various experiments, including both standard metrics and human evaluations, demonstrating the superiority of blocked Gibbs sampling over other sampling procedures.
The paper is well-written, and the authors have done an excellent job in presenting their work. However, my primary concern is that, having read Uria and Yao, I am unsure about the significance of the contributions made by this paper in the context of an ICLR submission. If this paper were submitted to a computational music or art conference, it would likely be accepted. Nevertheless, for ICLR, I do not see sufficient novelty compared to the previous works it builds upon, as orderless NADE is an established model, and the blocked Gibbs sampling and annealing scheme are essentially identical to those used in Yao. The primary novelty of this paper lies in its application to the music domain and the finding that Yao's method is more effective for sampling music. While this is a valuable contribution, it is more relevant to those working in the music domain. If the authors were to demonstrate that these results also apply to other domains, such as images (e.g., CIFAR or tiny ImageNet) or text (e.g., document generation), I would reconsider my evaluation and recommend accepting this paper for ICLR. Even experimenting with musical domains beyond Bach chorales would be beneficial. Nevertheless, as it stands, the experiments are not convincing enough to warrant acceptance.