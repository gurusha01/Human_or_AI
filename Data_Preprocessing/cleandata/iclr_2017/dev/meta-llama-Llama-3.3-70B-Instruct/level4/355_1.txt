This paper presents an investigation into training learning agents for the 3D game Doom, introducing several performance-enhancing approaches (including curriculum learning, attention-focused frames, reward shaping, game variables, and post-training rules) that leverage domain-specific knowledge.
The collective implementation of these enhancements yields a notable improvement, as evidenced by the competition results. Figure 4 illustrates the benefits of curriculum learning in navigating increasingly challenging environments, with a notable absence of overfitting to more difficult classes, likely due to the health and speed-based curriculum. Although the authors argue that the adaptive curriculum outperforms pure A3C based on Figure 5, this conclusion seems somewhat speculative given the graph's limitations. Furthermore, the claim that pure A3C fails to learn in more demanding maps is not substantiated by empirical results or visual evidence. Table 5, however, clearly demonstrates the advantages of post-training rules.
In the context of solving complex problems like 3D shooters, this paper makes a substantial contribution by identifying practical techniques for enhancing performance in such tasks. Nevertheless, the heavy reliance on domain knowledge detracts from its relevance to pure reinforcement learning, resulting in relatively predictable outcomes. The novelty of these findings may be specific to this problem domain, though.
The current form of Figure 6 does not allow for definitive conclusions, and I suggest that the authors enhance the resolution or apply quantitative metrics to assess the clarity of each image, providing a more concrete analysis than the existing low-resolution visuals.
--- Added after rebuttal:
Although high-resolution images for Figure 6 or a link to them are still not provided, I trust that the authors will include them if the paper is accepted.