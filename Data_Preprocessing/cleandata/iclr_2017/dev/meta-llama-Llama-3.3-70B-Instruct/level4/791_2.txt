The authors propose a self-supervised loss function based on a Siamese architecture, which aims to bring patches from the same image closer together in feature space compared to a contrasting patch from a different, randomly selected image. This approach bears a strong resemblance to the losses introduced by Doersch et al. at ICCV 2015 and Isola et al. at the ICLR 2016 workshop. Upon closer inspection, it appears that the proposed loss can be viewed as a simplified variant of Doersch et al.'s ICCV 2015 work, as it does not leverage spatial offset, a readily available self-supervised signal present in natural images. Intuitively, this suggests that the self-supervised problem formulated by this method may be less complex and consequently less effective than the aforementioned approach. A more in-depth comparison between these two methods would be beneficial. Nonetheless, the proposed method demonstrates efficacy in achieving favorable empirical results using this straightforward loss. To further strengthen the work, additional implementation details should be provided, including the impact of patch size, overlap between sampled patches, and any measures taken to prevent trivial solutions, to facilitate a more comprehensive understanding of the approach.