This paper presents a novel way to do unsupervised pretraining in a deep convolutional network setting (though likely applicable to fully-connected nets as well). The method is that of 'spatial constrasting', i.e. of building triplets from patches of input images and learning a presentation that assigns a high score for patches coming from the same image and a low score for patches from diferent images. The method is simple enough that I am surprised that no-one has tried this before (at least according to the previous work in the submission). Here are some comments:
The usage of P(fi^1 | fi^2) in Section 4.1 is a bit odd. May be worth defining mathematically what kind of probability the authors are talking about, or just taking that part out ("probability" can be replaced with another word).
I would like to know more about how the method is using the "batch statistics" (end of Section 4.2) by sampling from it, unless the authors simply mean that the just sample from all the possible triples in their batch.
Shouldn't the number of patches sampled in Algorithm 1 be a hyper-parameter rather than just be 1? Have the authors tried any other value?
I think there are some missing details in the paper, like the patch size or whether the authors have played with it at all (I think this is an important hyper-parameter).
The STL results are quite impressive, but CIFAR-10 maybe not so much. For CIFAR I'd expect that one can try to pre-train on, say, Imagenet + CIFAR to build a better representation. Have the authors considered this?
All in all, this is an interesting piece of work with some obvious applications, and it seems relatively straightforward to implemenent and try. I think I would've liked more understanding of what the spatial contrasting actually learns, more empirical studies on the effects of various parameter choices (e.g., patch size) and more attempts at beating the state of the art (e.g. CIFAR).