The framework of semi-Markov decision processes (SDMPs) has been long used to model skill learning and temporal abstraction in reinforcement learning. This paper proposes a variant of such a model called a semi-aggregated MDP model. 
The formalism of SAMDP is not defined clearly enough to merit serious attention. The approach is quasi heuristic and explained through examples rather than clear definition. The work also lacks sufficient theoretical rigor. 
Simple experiments are proposed using 2D grid worlds to demonstrate skills. Grid worlds have served their purpose long enough in reinforcement learning, and it is time to retire them. More realistic domains are now routinely used and should be used in this paper as well.