The paper proposes an approach to generating synthetic training data for deep networks, based on rendering 3D models and learning additional transformations with adversarial training. The approach is applied to generating barcode-like markers used for honeybee identification. The authors demonstrate that a classifier trained on synthetic data generated with the proposed approach outperforms both training on (limited) real data and training on data with hand-designed augmentations. 
The topic of the paper — using machine learning (in particular, adversarial training) for generating realistic synthetic training data — is very interesting and important. The proposed method looks reasonable, and the paper is written well. The downside is that experiments are limited to a fairly simple and not-widely-known domain of honeybee marker classification. While I am sure this is an important task by itself, in order to demonstrate general applicability of the method and to allow comparison with existing techniques, experiments on some standard and/or realistic datasets would be very helpful. Overall, I recommend acceptance, but encourage the authors to perform experiments on more datasets.
I appreciate that the authors added a baseline with manually designed transformations. This strengthens the paper.
As Reviewer3 points out, it would be interesting to analyze if restricting GAN to a fixed set of transformations is necessary here, and which transformations are most important. Perhaps this would provide some guidelines for designing sets of transformations for more complicated scenarios.
The authors should tone down their claims such as "Our method is an improvement over previous work  <...> Whereas previous work relied on real data for training using pre-trained models or mixing real and generated data, we were able to train a DCNN from scratch with generated data that performed well when tested on real data. ". This is not a fair comparison: the domain studied by authors in this work is much simpler than what was studied in these previous works, so this comparison is not appropriate.