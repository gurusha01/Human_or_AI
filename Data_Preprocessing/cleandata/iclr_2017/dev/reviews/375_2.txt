This paper proposes a simple way to reweight the word embedding in the simple composition function for sentence representation. This paper also shows the connection between this new weighting scheme and some previous work.
Here are some comments on technical details:
- The word "discourse" is confusing. I am not sure whether the words "discourse" in "discourse vector c_s" and the one in "most frequent discourse" have the same meaning.
- Is there any justification about $c_0$ related to syntac?
- Not sure what thie line means: "In fact the new model was discovered by our detecting the common component c0 in existing embeddings." in section "Computing the sentence embedding"
- Is there any explanation about the results on sentiment in Table 2?