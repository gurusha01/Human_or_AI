Review
Summary of Contributions
This paper proposes a novel metric learning framework that connects the differential geometry of planar curves with convolutional neural networks (CNNs). The authors aim to construct invariant geometric functions of planar curves under Euclidean and Similarity transformations using a Siamese network configuration. The paper demonstrates that the learned invariants are numerically robust to noise, sampling variations, and occlusions, outperforming traditional axiomatic methods. Additionally, the authors introduce a multi-scale representation paradigm within a similarity metric learning framework, which is both theoretically motivated and practically significant. This interdisciplinary effort bridges classical numerical differential geometry with modern deep learning, offering a fresh perspective on invariant-based methods.
Decision: Accept (with reservations)  
The paper presents a novel and interdisciplinary approach that is well-motivated and scientifically rigorous. However, the use of the outdated MPEG-7 dataset raises concerns about the relevance of the experimental setup in a modern machine learning context. While the paper's niche focus may limit its audience at ICLR, its unconventional nature and potential to inspire future research justify its acceptance.
Supporting Arguments
1. Novelty and Interdisciplinary Contribution: The paper's attempt to connect differential geometry with CNN-based metric learning is innovative and addresses a non-trivial problem. Revisiting invariant-based methods using deep learning is a sensible and timely approach, given the historical reliance of such methods on smoothed representations and nonlinearities.
   
2. Technical Soundness: The use of a Siamese network for learning geometric invariants is well-aligned with the problem requirements. The contrastive loss function is appropriate for the task, and the multi-scale representation is a meaningful extension that adds depth to the work.
3. Experimental Validation: The results demonstrate that the learned invariants are robust to noise and sampling variations, outperforming traditional differential and integral invariants. The experiments are well-designed to highlight the strengths of the proposed approach.
4. Relevance to ML Community: While the focus on planar curves and geometric invariants may seem niche, the methodology has broader implications for applying deep learning to problems in numerical geometry and beyond.
Suggestions for Improvement
1. Dataset Relevance: The reliance on the MPEG-7 dataset is a significant limitation. This dataset is outdated and does not reflect the complexity of modern benchmarks. The authors should consider evaluating their method on more contemporary datasets or justify why MPEG-7 remains relevant for this task.
2. Broader Impact: While the paper focuses on planar curves, it would benefit from a discussion on how the proposed framework could generalize to other geometric problems or domains, such as 3D shape analysis or medical imaging.
3. Clarity in Presentation: The paper is dense with mathematical details, which may hinder accessibility for a broader audience. Simplifying some of the explanations, especially in the introduction and methodology sections, could make the work more approachable.
4. Comparison with Modern Methods: The paper lacks a comparison with recent deep learning-based approaches for invariant representation learning. Including such comparisons would strengthen the empirical validation.
Questions for the Authors
1. Why was the MPEG-7 dataset chosen for this study, given its age and limited relevance to modern machine learning benchmarks? Could you provide justification or plans to test on more contemporary datasets?
   
2. How does the proposed method generalize to higher-dimensional geometric problems, such as 3D surfaces or volumetric data?
3. Can the multi-scale representation framework be extended to handle transformations beyond Euclidean and Similarity groups, such as affine or projective transformations?
4. How sensitive is the proposed framework to hyperparameter choices, such as the margin in the contrastive loss function or the number of convolutional layers?
---
In conclusion, this paper represents a bold and unconventional effort to merge deep learning with classical geometry. While there are areas for improvement, the novelty and rigor of the work make it a valuable contribution to the field.