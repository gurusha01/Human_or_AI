Review of the Paper
Summary of Contributions
The paper proposes a novel approach to generative modeling by introducing a Restricted Boltzmann Machine (RBM) with leaky rectified linear units (Leaky ReLU), termed as "leaky RBM." The authors systematically analyze the joint and marginal distributions of leaky RBM, demonstrating its interpretation as a union of truncated Gaussian distributions. They propose a new meta-sampling algorithm that anneals the leakiness during Gibbs sampling, which improves the efficiency and accuracy of partition function estimation compared to conventional annealed importance sampling (AIS). The paper also highlights the advantages of leaky RBM over Bernoulli-Gaussian RBM in terms of log-likelihood performance on benchmark datasets. The authors further show that annealing leakiness enhances mixing properties during training.
Decision: Reject
The paper introduces an interesting idea of leaky RBM and provides a detailed theoretical analysis, but it falls short in several critical areas. The lack of baseline comparisons, limited experimental validation, and insufficient demonstration of the model's superiority over existing methods make it difficult to justify acceptance.
Supporting Arguments for the Decision
1. Baseline Comparisons: The paper does not compare the proposed leaky RBM to other advanced models like stepped sigmoid units or spike-and-slab RBMs. This omission makes it challenging to assess whether the proposed method offers significant improvements over existing approaches.
2. Experimental Validation: While the paper demonstrates the effectiveness of leaky RBM on log-likelihood benchmarks, it does not test the model on binary visible RBMs or compare its performance to binary MNIST modeling benchmarks. Such experiments would have strengthened the claims.
3. Computational Complexity: The focus on conditionals and the necessity of projection steps introduce computational overhead. The paper does not adequately address how this complexity compares to other state-of-the-art methods.
4. Novelty: Although deriving the energy function from specified conditionals is an interesting approach, it is not unique to this work. The paper does not sufficiently differentiate itself from prior work in this area.
Suggestions for Improvement
1. Baseline Comparisons: Include comparisons with stepped sigmoid units, spike-and-slab RBMs, and other advanced RBM variants to establish the superiority of leaky RBM.
2. Additional Experiments: Test the proposed model on binary visible RBMs and compare its performance to binary MNIST modeling benchmarks. This would provide a more comprehensive evaluation of its applicability.
3. Efficiency Analysis: Provide a detailed analysis of the computational cost of the proposed sampling algorithm and projection steps, comparing it to other sampling methods like AIS and contrastive divergence.
4. Broader Evaluation Metrics: Beyond log-likelihood, consider evaluating the model on other metrics such as reconstruction error, classification accuracy, or sample quality to provide a holistic view of its performance.
Questions for the Authors
1. How does the computational complexity of the proposed sampling algorithm compare to other methods like AIS or contrastive divergence in practice?
2. Why were stepped sigmoid units and spike-and-slab RBMs excluded from the baseline comparisons?
3. Can the proposed meta-sampling algorithm be extended to other activation functions, such as softplus, and if so, how would it perform?
4. Have you considered testing the leaky RBM on binary visible RBMs or binary MNIST benchmarks? If not, why?
In conclusion, while the paper provides a solid theoretical foundation and introduces a novel sampling algorithm, the lack of comprehensive experimental validation and baseline comparisons limits its impact. Addressing these shortcomings would significantly strengthen the work.