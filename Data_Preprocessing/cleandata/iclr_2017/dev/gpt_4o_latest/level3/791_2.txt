Review
Summary of the Paper
This paper introduces a novel self-supervised learning method called Spatial Contrasting (SC) for training convolutional neural networks (ConvNets) on unlabeled data. The method leverages a Siamese architecture to compare spatial features from patches within the same image and across different images. The proposed loss function encourages patches from the same image to be closer in feature space while pushing patches from different images apart. Unlike prior works such as Doersch et al. (2015), which rely on spatial offsets as a self-supervised signal, this approach simplifies the problem by focusing solely on feature similarity and dissimilarity. Despite its simplicity, the method achieves competitive results on datasets like STL10, CIFAR10, and MNIST, demonstrating its potential as a pretraining method for supervised tasks. The authors also highlight the computational efficiency of their approach, as it requires no architectural modifications and integrates seamlessly with standard training pipelines.
Decision: Reject
While the paper presents an interesting and simple approach to self-supervised learning, it falls short in several key areas. The primary reasons for rejection are:  
1. Lack of sufficient novelty: The proposed method is conceptually similar to prior works, such as Doersch et al. (2015) and Isola et al. (2016), and does not introduce a fundamentally new idea.  
2. Insufficient experimental rigor: The empirical results, while promising, lack comprehensive comparisons with other state-of-the-art self-supervised methods.  
Supporting Arguments
1. Novelty and Motivation:  
   The paper builds on existing ideas in self-supervised learning, particularly the use of Siamese networks and contrastive losses. While the simplification of Doersch et al.'s approach is noteworthy, the authors do not sufficiently justify why removing spatial offset information is advantageous. The proposed method appears to be a less powerful variant of prior methods, and the paper does not provide a compelling theoretical or empirical argument for its superiority.  
2. Experimental Results:  
   The results on STL10 and CIFAR10 are competitive, but the evaluation lacks depth. For instance, there is no direct comparison with other prominent self-supervised methods like SimCLR, BYOL, or MoCo. Additionally, the paper does not explore the impact of key hyperparameters, such as patch size, overlap, or batch size, which are likely to influence the performance of the SC loss.  
3. Implementation Details:  
   The paper omits critical implementation details, such as how trivial solutions (e.g., collapsing all features to a single point) are avoided. Without this information, it is difficult to assess the robustness of the method.  
Suggestions for Improvement
1. Provide more comparisons: Include a broader set of baselines, including recent self-supervised methods, to contextualize the performance of SC.  
2. Clarify implementation details: Explain how patch size, overlap, and other design choices affect the results. Additionally, describe any measures taken to prevent trivial solutions.  
3. Theoretical justification: Offer a stronger theoretical motivation for why SC is expected to work better (or as well) as more complex methods that leverage spatial offsets or other signals.  
4. Ablation studies: Conduct ablation studies to isolate the contribution of different components of the SC loss. For example, how does performance change if only intra-image comparisons are used?  
Questions for the Authors
1. How does the choice of patch size and overlap affect the performance of the SC loss?  
2. What measures are in place to prevent the network from collapsing to trivial solutions?  
3. Why was the spatial offset signal removed, and how does this simplification affect the expressiveness of the learned features?  
4. Can SC be combined with other self-supervised signals (e.g., temporal or spatial offsets) to improve performance further?  
In conclusion, while the paper proposes an interesting simplification of self-supervised learning methods, it lacks sufficient novelty and experimental rigor to warrant acceptance in its current form. Addressing the above concerns could significantly strengthen the paper.