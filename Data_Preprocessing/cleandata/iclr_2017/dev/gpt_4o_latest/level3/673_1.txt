Review of the Paper: "Hierarchical Memory Networks with Maximum Inner Product Search for Large-Scale Factoid Question Answering"
Summary of Contributions
This paper introduces a Hierarchical Memory Network (HMN) designed to address scalability challenges in memory networks for large-scale factoid question answering tasks. The authors propose using Maximum Inner Product Search (MIPS) as a hybrid between soft and hard attention mechanisms to efficiently retrieve relevant memory subsets. They explore both exact and approximate K-MIPS techniques, demonstrating their scalability and computational advantages over traditional soft attention. The paper reports empirical results on the SimpleQuestions dataset, showing that exact K-MIPS improves accuracy compared to soft attention, while approximate K-MIPS offers speedups with some trade-offs in performance. The authors also propose strategies to mitigate the approximation bias of clustering-based K-MIPS.
Decision: Reject
While the paper addresses an important problem and proposes a novel approach, it falls short in several critical areas. The key reasons for rejection are:  
1. Lack of Hierarchical Evidence: Despite the claim of a hierarchical memory structure, the experiments do not convincingly demonstrate the benefits of hierarchy. The memory structure appears fixed and not learned, which undermines the core motivation of the paper.  
2. Unclear Reasoning for Optimality: The results suggest that 1-MIPS might be optimal, but the reasoning behind this observation is not well-articulated or supported by theoretical insights.  
3. Robustness Concerns: Approximate K-MIPS performs worse than the original method, raising doubts about the robustness and practical utility of the proposed approach.
Supporting Arguments
1. Hierarchical Memory: The paper claims to use a hierarchical memory structure, but the hierarchy is not explicitly leveraged or analyzed in the experiments. The clustering-based approach is more of an approximation technique than a true hierarchical design. This weakens the novelty and contribution of the proposed HMN.  
2. Empirical Results: While exact K-MIPS shows improved accuracy, the approximate K-MIPS results are underwhelming. The clustering-based approach, which is central to the scalability claim, performs significantly worse than full softmax, undermining the practical relevance of the method.  
3. Theoretical Justification: The paper lacks a rigorous theoretical analysis to explain why 1-MIPS or smaller K values outperform larger K values. This leaves the reader questioning the generalizability of the findings.
Suggestions for Improvement
1. Demonstrate Hierarchy: Provide experiments or ablation studies that explicitly validate the benefits of the hierarchical memory structure. For example, compare flat memory networks with hierarchical ones to show the impact of hierarchy.  
2. Theoretical Insights: Include a theoretical analysis to explain why smaller K values (e.g., 1-MIPS) yield better performance. This could involve analyzing the gradient flow or the nature of the SimpleQuestions dataset.  
3. Robustness of Approximate K-MIPS: Investigate why approximate K-MIPS underperforms and propose strategies to improve its robustness. For instance, explore dynamic memory updates or hybrid approaches that combine exact and approximate methods.  
4. Broader Evaluation: Test the proposed method on additional datasets or tasks to demonstrate its generalizability and practical utility.  
Questions for the Authors
1. How does the fixed memory structure impact the performance of HMNs? Would a learned memory hierarchy improve results?  
2. Can you provide more detailed reasoning or theoretical justification for why 1-MIPS performs better than larger K values?  
3. Have you considered hybrid approaches that combine exact and approximate K-MIPS to balance accuracy and scalability?  
4. How does the method compare to other state-of-the-art scalable memory access techniques beyond the SimpleQuestions dataset?  
In conclusion, while the paper tackles an important problem and introduces an interesting approach, the lack of demonstrated hierarchy, unclear reasoning for key results, and robustness concerns limit its impact and readiness for acceptance. Addressing these issues could significantly strengthen the work.