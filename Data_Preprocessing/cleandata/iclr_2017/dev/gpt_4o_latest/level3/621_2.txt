Review of the Paper
Summary of Contributions
This paper introduces COCONET, a convolutional neural network (CNN) model for polyphonic music generation, specifically targeting the distribution of four-part Bach chorales. The authors propose using blocked Gibbs sampling as an analogy to the nonlinear, iterative process of human music composition. The paper claims that blocked Gibbs sampling improves sample quality compared to ancestral sampling, even when using approximate methods. The authors demonstrate the model's ability to inpaint corrupted Bach chorales and generate unconditioned polyphonic music. This work is intriguing as it bridges the gap between machine learning-based music generation and the iterative nature of human composition, producing non-trivial musical outputs.
Decision: Reject
While the paper presents an exciting idea and a novel approach to music generation, it falls short in critical areas such as evaluation rigor and generalizability. Specifically, the lack of comparable likelihoods with prior work and insufficient data for direct model comparisons significantly weaken the empirical support for the claims. Additionally, the human evaluation methodology is suboptimal, and the transferability of the approach to other musical domains remains unclear.
Supporting Arguments for the Decision
1. Evaluation Issues: The paper does not provide a clear comparison of likelihoods with prior work, making it difficult to assess the model's performance relative to existing methods. Furthermore, the dataset and metrics used for evaluation are insufficient for a comprehensive comparison.
   
2. Human Evaluation Design: The human evaluation asks participants to judge "musicality," which is subjective and ambiguous. A stronger question, such as "Which piece of music do you prefer?" would yield more actionable insights and better reflect user preferences.
3. Generalizability: While the model performs well on Bach chorales, the paper does not address whether the method can generalize to other types of music with different data distributions. This limits the broader applicability of the approach.
Suggestions for Improvement
1. Evaluation Metrics: Provide likelihood comparisons with prior work and use a more diverse dataset to enable direct comparisons. Include quantitative metrics such as perplexity or other measures of musical coherence.
   
2. Human Evaluation Design: Redesign the human evaluation to include questions that assess user preference and perceived quality more robustly. For example, pairwise comparisons of generated pieces could provide clearer insights.
3. Generalizability: Explore the model's performance on other musical genres or datasets to demonstrate its versatility. Discuss potential limitations when applied to music with different structures or distributions.
4. Theoretical Justification: Elaborate on why blocked Gibbs sampling improves sample quality compared to ancestral sampling, particularly in the context of poorly modeled conditional distributions.
Questions for the Authors
1. How does the model's performance compare quantitatively to prior work on Bach chorales? Can you provide likelihood or perplexity scores for direct comparison?
2. Can you elaborate on the choice of "musicality" as the evaluation criterion? Why not use preference-based questions or other metrics like harmonic complexity?
3. Have you tested COCONET on other musical datasets? If so, how does it perform compared to Bach chorales?
Overall, while the paper introduces a compelling model and task, the lack of rigorous evaluation and generalizability limits its impact. Addressing these issues could significantly strengthen the paper.