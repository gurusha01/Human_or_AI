Review of the Paper
Summary
The paper introduces Tensorial Mixture Models (TMMs), a novel generative framework leveraging tensor decomposition techniques, specifically CP and Hierarchical Tucker (HT) decompositions, to model dependencies between local structures in data. The authors propose that TMMs can be efficiently implemented as Convolutional Arithmetic Circuits (ConvACs), enabling tractable inference and marginalization. The paper highlights the advantages of TMMs in handling missing data, demonstrating their theoretical and practical utility in classification tasks. The authors claim that TMMs outperform existing methods in robustness to missing data and provide state-of-the-art results on MNIST and NORB datasets.
Decision: Reject
While the paper presents an interesting and theoretically grounded model, it fails to meet the standards required for acceptance due to several critical shortcomings. The primary reasons for rejection are the lack of sufficient theoretical justification for key claims and the limited empirical evaluation.
---
Supporting Arguments for Rejection
1. Theoretical Limitations:
   - The paper's reliance on tensor decomposition assumes that these decompositions are universally applicable without addressing their limitations, such as subspace restrictions or approximation errors. This omission weakens the theoretical foundation of the proposed model.
   - The authors dismiss the need for rigorous theoretical analysis, claiming that it is less relevant in the deep learning era. This is an unjustified assertion, especially given the incomplete theoretical guarantees of the proposed method.
2. Empirical Limitations:
   - The experiments are conducted on simple datasets (MNIST, NORB) and synthetic missing data scenarios. These datasets are insufficient to demonstrate the generalizability or scalability of the model to more complex, real-world tasks.
   - Despite claims of applicability beyond image-based tasks, no experiments are provided to substantiate this assertion.
3. Unjustified Claims:
   - The paper claims that TMMs are universally applicable and optimal for missing data scenarios but does not provide sufficient evidence or comparative analysis to support this. For example, the paper does not compare TMMs to state-of-the-art generative models on diverse datasets or tasks.
4. Missing Extensions:
   - The authors claim that TMMs can be applied to domains beyond images, such as text or audio. However, no experiments or examples are provided to validate this claim. This omission is particularly concerning given that the paper's theoretical framework is heavily image-centric.
---
Suggestions for Improvement
1. Theoretical Justification:
   - Address the limitations of tensor decomposition explicitly, including its applicability and potential approximation errors.
   - Provide a rigorous theoretical analysis of the model's expressiveness and limitations, particularly in comparison to other generative models.
2. Experimental Evaluation:
   - Extend the empirical evaluation to include more diverse datasets and tasks, such as text, audio, or real-world missing data scenarios.
   - Compare TMMs against a broader range of baseline methods, including state-of-the-art generative models like VAEs and GANs.
3. Clarity of Claims:
   - Avoid dismissing the importance of theoretical analysis without justification. If theoretical analysis is not the focus, clearly state this and provide empirical evidence to compensate.
4. Demonstration of Generalizability:
   - Provide experiments or case studies demonstrating the applicability of TMMs to non-image domains, as claimed in the paper.
---
Questions for the Authors
1. How does the model handle approximation errors or subspace restrictions inherent in tensor decomposition? Are there specific scenarios where the decomposition might fail?
2. Why were MNIST and NORB chosen as the primary datasets? How do you justify the generalizability of your results to more complex datasets?
3. Can you provide empirical evidence to support the claim that TMMs are applicable beyond image-based tasks? Have you tested TMMs on text or audio datasets?
4. What is the computational complexity of TMMs compared to other generative models, especially in high-dimensional settings?
---
In conclusion, while the paper introduces an intriguing generative framework, it lacks the theoretical rigor and empirical breadth necessary to justify its claims. Addressing these issues in a future revision could significantly strengthen the paper.