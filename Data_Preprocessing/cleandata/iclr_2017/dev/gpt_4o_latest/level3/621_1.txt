Review
The paper explores the use of blocked Gibbs sampling for music generation tasks, specifically in the context of "fill in the notes" problems. The authors introduce COCONET, a convolutional neural network in the NADE family, and demonstrate that blocked Gibbs sampling significantly improves sample quality over ancestral sampling. The paper attributes this improvement to the poor modeling of some conditional distributions in ancestral sampling. An annealed schedule for the block size (N) is proposed to mitigate the risk of incoherent samples for large N. The authors provide empirical evidence, including human evaluations, to show that their approach outperforms existing sampling methods. While the primary focus is on polyphonic music generation, the paper positions its approach as a more human-like, nonlinear method of composition.
Decision: Reject
While the paper is well-written and the experimental results are compelling, the lack of novelty and limited scope of the contributions make it unsuitable for acceptance at a high-impact conference like ICLR. The work primarily applies existing methods (orderless NADE and Yao's blocked Gibbs sampling) to a new domain (music generation) without introducing significant methodological innovations. Additionally, the paper does not explore the broader applicability of the proposed approach to other domains, which limits its potential impact.
Supporting Arguments
1. Lack of Novelty: The paper builds on well-established methods (orderless NADE and Yao et al.'s blocked Gibbs sampling) without introducing substantial new techniques. While the application to music generation is interesting, it does not constitute a significant methodological advancement.
   
2. Limited Scope: The experiments focus exclusively on Bach chorales, which restricts the generalizability of the findings. The authors do not explore other musical styles or datasets, nor do they test the approach on non-music domains like images or text, which could have strengthened the paper's impact.
3. Strong Empirical Results: The empirical results, including human evaluations, convincingly demonstrate the superiority of blocked Gibbs sampling over ancestral sampling. However, this strength is overshadowed by the limited novelty and scope.
Additional Feedback
1. Broader Applicability: To enhance the impact of the paper, the authors could test their method on other datasets, such as images or text, to demonstrate its versatility. Exploring different musical styles beyond Bach chorales would also strengthen the paper's claims.
2. Theoretical Insights: The paper could benefit from a deeper theoretical analysis of why blocked Gibbs sampling improves sample quality in the context of music generation. This would provide more insight into the underlying mechanisms and make the contribution more robust.
3. Comparison with Other Models: The authors could compare their approach with other state-of-the-art music generation models to provide a more comprehensive evaluation.
Questions for the Authors
1. Have you considered applying your method to other domains, such as image inpainting or text generation? If so, what were the results?
2. Why did you choose to focus exclusively on Bach chorales? Could your method generalize to other musical styles or genres?
3. Can you provide more theoretical justification for why blocked Gibbs sampling improves sample quality in your model?
In summary, while the paper presents interesting results and is well-executed, the lack of novelty and limited scope make it unsuitable for acceptance at ICLR in its current form. Expanding the experiments and exploring broader applications could significantly strengthen the paper.