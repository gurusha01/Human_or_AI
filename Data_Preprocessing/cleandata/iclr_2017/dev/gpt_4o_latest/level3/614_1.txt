Review of the Paper
Summary of Contributions
This paper introduces a novel time-dependent recommender system that models the co-evolution of user and item latent features using recurrent neural networks (RNNs) and multi-dimensional temporal point processes. The proposed framework, termed "DEEPCOEVOLVE," captures the nonlinear dynamics of user-item interactions, addressing limitations in prior work that relied on static or epoch-based methods. Key contributions include: (1) a parameterized point process model for recommendations, (2) an efficient stochastic gradient optimization algorithm to handle the co-evolutionary nature of user-item interactions, and (3) empirical validation on real-world datasets, demonstrating significant improvements in both item and time prediction tasks. The work is technically sound and offers a promising approach to modeling temporal dynamics in recommender systems.
Decision: Reject
While the paper presents a technically sound model with interesting ideas, it ultimately falls short in terms of novelty, clarity, and evaluation rigor. The primary reasons for rejection are: (1) insufficient justification for the choice of specific modeling components (e.g., the point process and sigmoid non-linearity), and (2) lack of clarity and rigor in the evaluation methodology, particularly in comparison to prior work.
Supporting Arguments
1. Novelty and Clarity: The paper builds on the authors' prior work (NIPS 2016) but does not sufficiently differentiate itself. While the use of a different point process and latent factor dynamics is noted, the paper does not clearly articulate how these changes drive performance improvements. This lack of clarity undermines the claimed novelty of the approach.
2. Evaluation Methodology: The evaluation lacks rigor in several key areas:
   - The choice of metrics, particularly the relevance of time prediction, is not well justified. It is unclear how this metric aligns with practical recommendation tasks.
   - There is no comparison of computational complexity or scalability with other methods, leaving questions about the feasibility of applying the model to large-scale datasets.
   - Inconsistencies between the results in this paper and the authors' previous work are not adequately addressed.
3. Justification of Model Choices: The paper does not provide sufficient theoretical or empirical justification for the choice of the specific point process (Rayleigh) or the sigmoid non-linearity. Exploring alternative forms could strengthen the claims of generality and robustness.
Suggestions for Improvement
1. Clarify Novelty: Explicitly highlight the differences from prior work and provide a detailed analysis of how these changes contribute to performance improvements. For example, a direct ablation study comparing the proposed model to the NIPS 2016 model would be valuable.
2. Evaluation Rigor: 
   - Justify the choice of evaluation metrics and their relevance to real-world recommendation tasks.
   - Include a comparison of computational complexity and runtime with baseline methods to demonstrate scalability.
   - Address inconsistencies with prior results and provide explanations for observed differences.
3. Model Justification: Provide a rationale for the choice of the Rayleigh process and sigmoid non-linearity. Additionally, explore alternative forms (e.g., Hawkes processes or other activation functions) to demonstrate robustness and generality.
4. Clarity in Presentation: Simplify the technical exposition in some sections to improve accessibility for a broader audience. For example, the derivation of gradients and the optimization procedure could be summarized more concisely.
Questions for the Authors
1. What specific insights or theoretical motivations led to the choice of the Rayleigh process and sigmoid non-linearity? Have alternative forms been explored?
2. Can you provide a detailed comparison of the proposed model with your NIPS 2016 work, including an ablation study to isolate the impact of new components?
3. How does the model scale with increasing numbers of users and items? Can you provide empirical evidence of scalability on larger datasets?
4. Why is time prediction considered a meaningful metric for recommender systems? How does it translate to practical improvements in user experience?
In conclusion, while the paper presents an interesting approach to modeling temporal dynamics in recommender systems, it requires significant improvements in clarity, justification, and evaluation rigor to meet the standards of the conference.