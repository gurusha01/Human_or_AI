The paper presents a novel unsupervised algorithm for domain transfer, constrained by a fixed perceptual function \( f \). The proposed Domain Transfer Network (DTN) employs a compound loss function combining a multiclass GAN loss, an \( f \)-preserving term, and a regularization term to achieve cross-domain mappings while maintaining perceptual consistency. The paper showcases the method's effectiveness in generating visually appealing results across multiple datasets, including SVHN-to-MNIST digit transfer and photo-to-emoji face transformation. Additionally, the approach demonstrates improved domain adaptation performance on the SVHN-to-MNIST task, achieving state-of-the-art results.
Decision: Accept.  
The decision to accept is based on the paper's interesting and well-executed idea of leveraging a fixed perceptual function \( f \) for cross-domain sample comparison, as well as its strong empirical results. Despite some limitations in novelty and generalization, the paper's contributions are significant and relevant to the field.
Supporting Arguments:  
1. Strengths:  
   - The idea of using a fixed perceptual function \( f \) to enforce cross-domain consistency is both innovative and practical. This approach ensures that the generated samples preserve key semantic features across domains.  
   - The method produces visually compelling results on diverse datasets, including challenging tasks like photo-to-emoji generation. The qualitative results are impressive and demonstrate the model's ability to capture domain-specific characteristics while maintaining identity.  
   - The quantitative results on the SVHN-to-MNIST domain adaptation task are strong, surpassing prior state-of-the-art methods. This highlights the potential of DTN for unsupervised domain adaptation.  
   - The paper is well-written, with clear explanations of the methodology, experiments, and results, making it accessible to a broad audience.
2. Weaknesses:  
   - The primary contribution lies in the \( f \)-constancy term, which limits the novelty of the work. The reliance on a fixed \( f \) trained on the source domain may hinder performance for highly dissimilar domains.  
   - The paper evaluates domain adaptation on only one task (SVHN-to-MNIST), which raises concerns about the universality of the approach. Additional experiments on other domain pairs would strengthen the claims.  
   - The visual quality of the generated samples could be misrepresented due to the placement of original model outputs in the appendix. Including these results in the main paper would provide a more transparent evaluation.
Suggestions for Improvement:  
1. Move the original model outputs from the appendix to the main paper to provide a more accurate representation of the visual quality.  
2. Extend the experimental evaluation to include additional domain adaptation tasks and more diverse domain pairs to demonstrate the generalizability of the approach.  
3. Discuss potential limitations of the \( f \)-constancy constraint in greater detail, particularly in scenarios where \( f \) is less effective on the target domain.  
Questions for the Authors:  
1. How sensitive is the approach to the choice of the perceptual function \( f \)? Would a different \( f \) (e.g., trained on a different dataset or task) significantly impact the results?  
2. Have you considered incorporating adaptive techniques to improve \( f \)'s performance on the target domain? If so, how would this affect the overall framework?  
3. Could the method be extended to handle more complex or multimodal domain transfer tasks, such as text-to-image or audio-to-video mappings?  
Overall, the paper makes a meaningful contribution to unsupervised domain transfer and demonstrates promising results. Addressing the outlined weaknesses and suggestions could further enhance its impact.