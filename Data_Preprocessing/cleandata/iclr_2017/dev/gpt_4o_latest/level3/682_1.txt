Review of the Paper
Summary of Contributions
This paper introduces a novel approach to Restricted Boltzmann Machines (RBMs) by replacing binary units with leaky ReLU units, referred to as "leaky RBM." The authors propose a new sampling method that anneals the leakiness during Gibbs sampling, which they claim improves mixing and efficiency. They also provide a theoretical analysis of the leaky RBM as a union of truncated Gaussian distributions, addressing constraints that ensure valid training. The paper demonstrates the effectiveness of the proposed sampling algorithm in estimating the partition function and compares the performance of leaky RBM against Bernoulli-Gaussian RBM on CIFAR-10 and SVHN datasets, reporting higher log-likelihoods for the former. The authors also suggest that their method has better mixing properties compared to traditional contrastive divergence (CD) methods.
Decision: Reject
While the paper presents an interesting idea and makes a valuable attempt to improve RBMs, it falls short in several critical areas. The primary reasons for rejection are the lack of clarity and rigor in explaining the proposed sampling algorithm (Algorithm 2) and the subpar empirical results, which suggest improper training of the Gaussian RBM baseline.
Supporting Arguments for the Decision
1. Insufficient Explanation of Algorithm 2: The proposed sampling method, which anneals the leakiness during Gibbs sampling, is not adequately explained. The computational cost of the algorithm is also not rigorously analyzed, leaving readers uncertain about its practical feasibility. For example, the paper mentions that the algorithm requires Cholesky decomposition of the covariance matrix, which can be computationally expensive, but does not provide a detailed discussion on how this impacts scalability.
2. Subpar Gaussian RBM Baseline Results: The reported results for Gaussian RBM on CIFAR-10 and SVHN are significantly lower than expected, raising concerns about whether the baseline was properly trained. This undermines the validity of the comparison and the claims of superiority for leaky RBM.
3. Limited Scope of Experiments: The experiments focus primarily on log-likelihood comparisons, but the utility of leaky RBM in other tasks, such as classification with fewer labels or texture synthesis, is not explored. This limits the paper's impact and leaves its broader applicability untested.
Suggestions for Improvement
1. Clarify Algorithm 2: Provide a more detailed explanation of the proposed sampling method, including its computational complexity and practical implementation details. Discuss how the algorithm scales with larger datasets and higher-dimensional models.
2. Improve Baseline Comparisons: Ensure that the Gaussian RBM baseline is properly trained and optimized. Consider using advanced training techniques, such as persistent contrastive divergence (PCD), to provide a fairer comparison.
3. Expand Experimental Scope: Conduct additional experiments to evaluate the utility of leaky RBM in tasks beyond log-likelihood estimation, such as semi-supervised classification or texture synthesis. This would strengthen the paper's claims about the versatility of the proposed model.
4. Theoretical Rigor: Include a more thorough theoretical analysis of the proposed sampling algorithm, particularly its convergence properties and guarantees. This would help address concerns about its correctness and reliability.
Questions for the Authors
1. Can you provide a detailed explanation of the computational cost of Algorithm 2, particularly the Cholesky decomposition step, and how it scales with the number of visible and hidden units?
2. How was the Gaussian RBM baseline trained, and what steps were taken to ensure it was properly optimized? Could the poor performance be due to insufficient tuning of hyperparameters or training instability?
3. Have you considered evaluating the proposed model on tasks like semi-supervised learning or texture synthesis? If not, what are the potential challenges in applying leaky RBM to these tasks?
In conclusion, while the paper introduces an interesting idea, it requires significant improvements in clarity, rigor, and experimental validation to meet the standards of the conference.