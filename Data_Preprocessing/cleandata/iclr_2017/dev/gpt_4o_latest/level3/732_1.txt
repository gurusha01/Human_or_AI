Review of the Paper
Summary
This paper introduces the Generative Paragraph Vector (GPV) and its supervised extension, Supervised Generative Paragraph Vector (SGPV), as probabilistic enhancements to the Distributed Bag of Words version of Paragraph Vector (PV-DBOW). The authors aim to address the limitation of PV-DBOW in inferring representations for unseen texts by incorporating a complete generative process. The supervised extension (SGPV) integrates text labels into the model, enabling direct use in prediction tasks. The paper claims that these models outperform state-of-the-art baselines in text classification tasks across five benchmark datasets, while maintaining simplicity and efficiency.
Decision: Reject
The paper is rejected due to flawed motivation, lack of novelty in the approach, and insufficient scientific rigor in supporting its claims. Below, I outline the key reasons for this decision and provide constructive feedback to improve the work.
Supporting Arguments
1. Flawed Motivation: The paper's central motivation is based on the assumption that PV-DBOW cannot generalize to unseen data, which is inaccurate. PV-DBOW can infer representations for unseen texts through optimization techniques like gradient descent. This undermines the primary justification for introducing GPV and SGPV, making the contribution less compelling.
2. Lack of Novelty: The proposed models closely resemble existing probabilistic models like Latent Dirichlet Allocation (LDA) with directed extensions. The generative process described for GPV and SGPV does not introduce significant methodological innovation beyond standard directed LDA-like bag-of-words/bigram models. The incremental nature of the contribution weakens its impact.
3. Insufficient Scientific Rigor: While the paper claims superior performance over state-of-the-art methods, the experimental results lack thorough statistical analysis. For example, no confidence intervals or significance tests are provided to validate the claimed improvements. Additionally, the paper does not adequately compare against baselines that can also infer unseen text representations, such as PV with fine-tuning.
4. Formatting and Citation Errors: The submission contains basic formatting issues and BibTeX citation errors, which reflect a lack of attention to detail. These issues detract from the overall professionalism of the work.
Additional Feedback
- Clarify Assumptions: The authors should revisit their assumption about PV-DBOW's inability to handle unseen data and clearly articulate how their approach differs fundamentally from existing methods.
- Expand Related Work: The related work section should include a more comprehensive discussion of existing techniques for inferring representations for unseen texts, such as fine-tuning in PV or transfer learning approaches.
- Improve Experimental Rigor: Include statistical significance tests (e.g., t-tests) to validate performance improvements. Additionally, provide ablation studies to isolate the contributions of different components (e.g., the generative process, supervised labels, and bigrams).
- Address Formatting Issues: Ensure the paper adheres to the conference's formatting guidelines and correct all BibTeX citation errors.
Questions for the Authors
1. How does GPV compare to PV with fine-tuning for unseen text representations? Have you conducted experiments to evaluate this?
2. Can you provide more details on the computational efficiency of GPV and SGPV compared to deep learning baselines, especially for large-scale datasets?
3. What specific probabilistic distributions or extensions could be explored in future work to improve the model?
By addressing these issues, the authors could strengthen the paper's contribution and make it more competitive for future submissions.