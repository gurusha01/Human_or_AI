Review of the Paper
Summary of Contributions
This paper tackles the problem of multi-modal classification for e-commerce product categorization, leveraging both text and image inputs. The authors propose a decision-level fusion approach, combining state-of-the-art text and image classification models with a novel policy network that learns to select between the two. The paper introduces a new large-scale dataset of 1.2 million products from Walmart.com, which is a valuable contribution to the field. The authors demonstrate mild performance improvements in top-1 accuracy over single-modal models, highlighting the potential of multi-modal architectures in real-world, large-scale classification tasks.
Decision: Reject
While the paper introduces an interesting dataset and application, the methodological and experimental shortcomings outweigh the contributions. The key reasons for rejection are: (1) the limited performance improvement achieved by the proposed approach, and (2) the lack of comparisons to standard datasets and prior works, which makes it difficult to assess the generalizability and novelty of the proposed method.
Supporting Arguments
1. Limited Performance Improvement: The proposed decision-level fusion approach achieves only a mild improvement over the single-modal models, despite the demonstrated potential for multi-modality. The results fall short of the oracle improvement identified in the error analysis, suggesting that the proposed method does not fully exploit the complementary nature of the modalities.
   
2. Lack of Comparisons to Prior Work: The paper does not evaluate the proposed method on standard datasets or benchmark it against existing multi-modal fusion techniques. This omission makes it difficult to contextualize the results within the broader literature and assess the novelty of the contributions.
3. Incomplete Exploration of Architectures: The authors focus on decision-level fusion but do not adequately explore feature-level fusion or report results for such architectures. This limits the scope of the study and leaves open questions about whether alternative fusion strategies might perform better.
4. Clarity Issues: The policy network's decision-making process is not well-explained. Specifically, it is unclear how the network learns to outperform simple aggregation methods like max or mean of input class probabilities. This lack of clarity undermines confidence in the proposed approach.
Suggestions for Improvement
1. Broader Evaluation: Evaluate the proposed method on standard multi-modal datasets and compare it to prior works in the field. This will help establish the generalizability and novelty of the approach.
2. Feature-Level Fusion: Include experiments with feature-level fusion architectures and report their results. This would provide a more comprehensive exploration of multi-modal fusion strategies.
3. Policy Network Explanation: Provide a clearer explanation of the policy network's learning mechanism and its ability to outperform baseline aggregation methods. Visualizations or ablation studies could help clarify its role.
4. Error Analysis and Potential Realization: The paper identifies a significant potential for improvement through multi-modality but does not fully realize it. Investigating deeper policy networks, better confidence measures, or ensemble methods could help bridge this gap.
Questions for the Authors
1. Why were standard datasets not used for evaluation? How does the proposed method generalize to other domains?
2. Can you provide more details on the training process and hyperparameter tuning for the policy network? How sensitive is the network to these choices?
3. Why were feature-level fusion results omitted? Were there specific challenges in training these architectures?
While the paper introduces an interesting dataset and application, addressing the above concerns would significantly strengthen its contributions and impact.