Review
Summary of Contributions
This paper proposes a novel end-to-end speech recognition system that combines a convolutional neural network (ConvNet) acoustic model with a graph-based decoder. The main contribution is the introduction of the AutoSegCriterion (ASG), a variant of the Connectionist Temporal Classification (CTC) criterion. ASG eliminates the need for blank labels, introduces letter repetition symbols, and uses unnormalized scores with global normalization. The approach is evaluated on the LibriSpeech dataset, achieving competitive word error rates (WERs) with MFCC features and promising results with raw waveform inputs. The system is computationally efficient, avoiding the need for HMM/GMM pre-training or the computational overhead of RNN-based models. The authors also provide a detailed comparison of ASG and CTC in terms of accuracy and speed, demonstrating that ASG is faster for longer sequences while maintaining comparable accuracy.
Decision: Reject  
While the paper introduces an interesting variant of CTC and demonstrates competitive results, it falls short in several key areas, particularly in its evaluation and positioning within the literature. The lack of direct comparisons to state-of-the-art word-level models, insufficient justification of design choices, and incomplete analysis of the proposed approach's limitations prevent the paper from meeting the standards of acceptance.
Supporting Arguments for Decision
1. Evaluation Gaps: The paper claims competitive performance but does not provide a direct comparison to word-level hybrid DNN/HMM models, such as those from Panayotov et al. (2015). Additionally, the results are not contextualized against Baidu's Deep Speech models, which use significantly larger training datasets. This omission makes it difficult to assess the true competitiveness of the proposed approach.
   
2. Unjustified Design Choices: The use of a large analysis window (~2 seconds) is not adequately justified, and the observed advantages are not explained. Similarly, the decision to replace blank symbols with letter repetition symbols in ASG is not rigorously analyzed in terms of its impact on beam pruning and language model integration.
3. Incomplete Technical Details: The paper lacks sufficient discussion on critical aspects such as the handling of non-normalized scores, beam pruning strategies, and the role of transition scalars. These details are essential for reproducibility and understanding the approach's limitations.
4. Clarity and Presentation Issues: Inconsistent notation (e.g., variable 't' for different time scales) and missing units in Table 1 reduce readability. Furthermore, Figure 4 does not specify the corpus used, and prior related work (e.g., the NIPS end-to-end workshop paper) is not clearly referenced.
Suggestions for Improvement
1. Comparative Evaluation: Include direct comparisons to word-level hybrid DNN/HMM models and clarify how the results compare to Baidu's Deep Speech models, accounting for differences in training data size.
   
2. Justification of Design Choices: Provide a detailed explanation of the advantages of the large analysis window and the use of letter repetition symbols. Analyze the impact of dropping normalization on beam pruning and language model scores.
3. Technical Details: Expand on the handling of non-normalized scores, beam pruning, and transition scalars. Clarify how digits are used to label character repetitions and how numbers are processed.
4. Presentation: Fix inconsistent notation, include units in all tables, and specify the corpus used in figures. Clearly reference prior related work to better position the paper in the literature.
Questions for the Authors
1. How does the proposed ASG criterion perform when compared to word-level models, particularly hybrid DNN/HMM systems?
2. What specific advantages does the large analysis window provide, and how does it affect computational efficiency and accuracy?
3. Can you provide more details on the impact of dropping normalization on beam pruning and language model integration?
4. How are digits used to label character repetitions, and how are numbers handled during training and decoding?
While the paper presents an interesting approach, addressing the above issues would significantly strengthen its contributions and make it more suitable for acceptance in a future submission.