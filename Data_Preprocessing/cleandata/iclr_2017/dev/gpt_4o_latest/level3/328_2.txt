Review of the Paper
Summary of Contributions
This paper presents a novel application of recurrent neural networks (RNNs) to model the spiking responses of parasol ganglion cells in the primate retina to natural images. The authors demonstrate that RNNs outperform traditional generalized linear models (GLMs) in predictive performance, even with limited training data. The multitask framework, which shares parameters across neurons, is shown to improve predictive stability and accuracy. Additionally, the paper introduces a hybrid GLM-RNN model that provides insights into the temporal and spatial nonlinearities captured by RNNs. While the work does not yet yield new biological insights, it represents a significant methodological advancement by introducing deep learning to a field that has traditionally relied on simpler models. This proof-of-concept study lays the groundwork for future research that could explore more complex neural computations and shorter timescales.
Decision: Accept (with minor revisions)  
The paper should be accepted because it introduces a promising and underexplored approach to modeling neural responses, demonstrates its feasibility, and provides a solid foundation for follow-up research. The modest performance gains and lack of immediate biological insights are limitations, but the methodological contribution and potential for future impact outweigh these concerns.
Supporting Arguments
1. Novelty and Contribution: The application of RNNs to model retinal neuron firing rates is a novel contribution to the field. The multitask framework and hybrid GLM-RNN model are particularly valuable additions, demonstrating the potential of deep learning to address complex neural computations.
   
2. Scientific Rigor: The experiments are well-designed, with appropriate baselines (GLMs and LNs) and metrics (fraction of explainable variance). The results convincingly support the claim that RNNs outperform traditional models in predictive accuracy.
3. Potential for Future Impact: While the current work primarily validates the feasibility of the approach, it opens the door to significant future research opportunities. Applying this framework to other neural systems, shorter timescales, or local field potentials (LFPs) could yield impactful biological insights.
4. Clarity and Accessibility: The paper is well-written and provides sufficient methodological detail to allow replication. The authors also acknowledge the limitations of their work, which adds credibility.
Suggestions for Improvement
1. Clarifications: The role of the 0.833 ms bins should be explicitly explained, as this detail is currently unclear. Additionally, the term "epoch" should be used consistently throughout the paper to avoid confusion.
2. Figure Adjustments: Figure 4's x-axis should be adjusted to a log scale, as this would better illustrate the relationship between training data size and model performance.
3. Biological Interpretability: While the authors acknowledge the "black-box" nature of RNNs, future work could benefit from a deeper exploration of how the learned features relate to known biological mechanisms. This would help bridge the gap between predictive performance and biological insight.
4. Discussion of Limitations: The paper could more explicitly discuss the modest performance gains and the lack of immediate biological insights, framing these as areas for future exploration.
Questions for the Authors
1. Could you clarify the specific role of the 0.833 ms bins in the modeling process? How do they influence the temporal resolution of the predictions?
2. How robust is the multitask framework to variations in the number of neurons included in the training set? Would it generalize well to datasets with fewer neurons?
3. Have you considered applying this framework to other types of neurons or brain regions? If so, what challenges do you anticipate?
In conclusion, this paper represents a valuable methodological contribution to the field of computational neuroscience. While the immediate biological insights are limited, the introduction of RNNs and multitask learning to this domain has significant potential for future impact. With minor revisions, this work will be a strong addition to the conference.