The paper introduces COCONET, a neural autoregressive model with convolution, designed for music composition. It proposes the use of blocked Gibbs sampling as an alternative to the conventional ancestral sampling method, aiming to improve the quality of generated music. The authors argue that blocked Gibbs sampling better aligns with the nonlinear, iterative process of human composition. Experimental results demonstrate that COCONET outperforms baseline models in terms of negative log-likelihood (NLL) and generates music that is compelling based on human evaluation. The paper positions its contributions as incremental, building on prior work by Yao et al. (2014) and Boulanger-Lewandowski et al. (2012).
Decision: Accept
The paper should be accepted due to its strong empirical results, clear motivation, and practical contributions to music generation. While the novelty is somewhat limited, the work provides a meaningful improvement over existing methods and demonstrates scientific rigor.
Supporting Arguments:
1. Clear Problem Definition and Motivation: The paper addresses a well-defined problemâ€”improving music generation by mimicking the nonlinear composition process of human composers. The use of blocked Gibbs sampling is well-motivated and provides a fresh perspective on sampling strategies in generative models.
   
2. Empirical Rigor: The results convincingly support the claims. COCONET demonstrates superior performance in both quantitative (NLL) and qualitative (human evaluation) metrics compared to baselines. The inclusion of visualizations (e.g., inpainting of corrupted Bach chorales) further strengthens the empirical evidence.
3. Positioning in Literature: The paper acknowledges prior work and builds on it in a meaningful way. While the approach is incremental, the use of blocked Gibbs sampling in this context is a novel application that advances the field.
Suggestions for Improvement:
1. Clarify the Novelty: While the paper builds on prior work, the novelty could be better emphasized. For example, the authors could explicitly compare their blocked Gibbs sampling approach to Yao et al. (2014) and highlight the specific advancements made.
   
2. Ablation Studies: It would be helpful to include ablation studies to isolate the impact of blocked Gibbs sampling versus other architectural choices in COCONET.
3. Broader Applications: The paper focuses on unconditioned polyphonic music generation. Discussing potential extensions to other music generation tasks (e.g., conditioned generation or style transfer) could broaden the impact of the work.
Questions for the Authors:
1. How does the computational cost of blocked Gibbs sampling compare to ancestral sampling? Is the improvement in sample quality worth the trade-off in efficiency?
2. Can the authors provide more details on the human evaluation process? How were evaluators selected, and what criteria were used to assess the quality of the generated music?
3. Have the authors considered applying COCONET to other domains (e.g., text or image generation) to test the generalizability of the blocked Gibbs sampling approach?
In conclusion, while the novelty of the paper is incremental, the strong empirical results and practical contributions make it a valuable addition to the field of generative music models.