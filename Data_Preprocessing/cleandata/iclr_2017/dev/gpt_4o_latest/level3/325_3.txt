The paper introduces a heuristic training approach for deep directed generative models, focusing on learning a Markov chain transition operator that progressively denoises unstructured noise into samples matching the target data distribution. The proposed "infusion training" method biases the training chain with information from target examples, enabling the model to generate high-quality samples in fewer steps compared to prior methods like Sohl-Dickstein et al.'s diffusion-based approach. The authors provide empirical results on datasets such as MNIST, CIFAR-10, and CelebA, demonstrating competitive sample quality and effective inpainting capabilities. The paper also includes proper log-likelihood estimates for future comparisons and highlights the efficiency of the method.
Decision: Reject.  
While the paper presents an interesting heuristic approach, it lacks sufficient empirical evaluation and theoretical grounding to justify its acceptance. The absence of comparisons with state-of-the-art methods, particularly for inpainting tasks, and the limited exploration of robustness and applicability diminish its potential impact.
Supporting Arguments:  
1. Novelty and Efficiency: The infusion training procedure is a creative alternative to variational optimization, offering a simpler and computationally efficient method for training generative models. The approach avoids the complexities of adversarial training (GANs) and variational inference (VAEs), which is a notable strength.  
2. Empirical Limitations: The empirical evaluation is insufficient to establish the method's robustness and generalizability. While the paper demonstrates competitive results on standard datasets, it does not provide a thorough comparison with other generative models, particularly for inpainting tasks. Missing comparisons with methods like VAEs or GANs in the context of inpainting weaken the practical relevance of the work.  
3. Theoretical Concerns: The heuristic nature of the proposed method raises questions about its theoretical soundness. While the authors acknowledge this limitation, the paper does not provide sufficient analysis or justification for the proposed surrogate loss function.  
Additional Feedback:  
1. Comparative Analysis: Including comparisons with state-of-the-art methods for inpainting and sample quality (e.g., GANs, VAEs) would significantly strengthen the paper. Metrics such as FID (Fr√©chet Inception Distance) or precision-recall curves for generative models could provide more rigorous evaluations.  
2. Clarity on Limitations: The authors should explicitly discuss the limitations of their approach, particularly in comparison to VAEs and other probabilistic models. For instance, how does the heuristic posterior approximation impact model performance in scenarios requiring precise latent variable inference?  
3. Citations and Formatting: The paper lacks citations for "ordered visible dimension sampling" and contains typos in citation formatting. Addressing these issues would improve the paper's presentation and scholarly rigor.  
4. Broader Applicability: Exploring the applicability of the method to more diverse datasets and tasks (e.g., text or speech generation) would enhance its generalizability and impact.  
Questions for the Authors:  
1. How does the proposed method compare quantitatively with state-of-the-art generative models on inpainting tasks?  
2. Can the infusion training procedure be extended to conditional generative tasks, and if so, how would it perform compared to conditional GANs or VAEs?  
3. What are the trade-offs between using the heuristic posterior approximation versus a variational or MCMC-based approach?  
In summary, while the paper introduces an intriguing and efficient method, it requires stronger empirical validation, theoretical grounding, and comparative analysis to warrant acceptance.