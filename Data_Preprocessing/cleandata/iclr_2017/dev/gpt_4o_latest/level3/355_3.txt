Review of the Paper
Summary of Contributions
This paper presents a novel framework for training AI agents in First-Person Shooter (FPS) games, specifically Doom, using the Asynchronous Advantage Actor-Critic (A3C) model enhanced with curriculum learning. The authors demonstrate the effectiveness of their approach by achieving first place in Track 1 of the 2016 ViZDoom AI Competition, outperforming competitors by a significant margin. The framework is notable for its simplicity, relying solely on game states from the AI's perspective without leveraging opponent-specific information. The paper also introduces adaptive curriculum training, which dynamically adjusts task difficulty based on the agent's performance, and post-training rules to further refine the agent's behavior. The authors provide ablation studies and visualizations to analyze the agent's learning process and tactics, showcasing its ability to develop human-like strategies.
Decision: Reject
While the paper demonstrates strong empirical results and practical contributions, it falls short in several key areas that are critical for acceptance in a scientific conference. The primary reasons for rejection are the lack of sufficient contextualization within existing literature and the failure to address concerns raised by another reviewer.
Supporting Arguments for Decision
1. Literature Contextualization: The paper's citation list is sparse and does not adequately reference the rich body of work on reward shaping and incremental task setups. While the authors employ curriculum learning and reward shaping effectively, they fail to position their work within the broader landscape of reinforcement learning research. For example, foundational or complementary studies on reward shaping and curriculum design are either missing or insufficiently discussed. This omission weakens the scientific rigor and broader relevance of the paper.
2. Unaddressed Reviewer Concerns: The authors have not responded to two concerns raised by another reviewer. While these concerns are not explicitly detailed in the review process, their neglect raises questions about the robustness of the work and the authors' engagement with peer feedback.
3. Scientific Justification of Design Choices: Although the authors attempt to justify their design decisions, the explanations are not always grounded in rigorous scientific analysis. For instance, the choice of specific reward shaping parameters and the effectiveness of post-training rules are not thoroughly validated beyond empirical results. A more systematic exploration of these design choices would strengthen the paper.
Additional Feedback for Improvement
1. Expand Literature Review: The authors should incorporate and discuss relevant work on reward shaping, curriculum learning, and reinforcement learning in partially observable environments. This would better situate their contributions within the field and highlight the novelty of their approach.
2. Address Reviewer Concerns: The authors should explicitly address the two concerns raised by another reviewer. This would demonstrate a commitment to scientific rigor and improve the paper's credibility.
3. Contextualize FPS Research: The paper would benefit from a deeper discussion of how its contributions relate to other research on AI in FPS games. For example, comparing the proposed approach to other methods in terms of generalizability to different FPS games or scenarios would enhance its impact.
4. Theoretical Insights: While the empirical results are impressive, the paper could benefit from more theoretical insights into why the proposed enhancements (e.g., adaptive curriculum learning) work. For example, an analysis of how the adaptive curriculum impacts the exploration-exploitation trade-off would add depth.
Questions for the Authors
1. How does the proposed reward shaping framework compare to other established reward shaping techniques in terms of convergence speed and final performance?
2. Could the adaptive curriculum learning approach generalize to other FPS games or different genres of games? If so, how would the parameters need to be adjusted?
3. What were the specific concerns raised by the other reviewer, and why were they not addressed in this version of the paper?
In conclusion, while the paper demonstrates clear practical achievements, its scientific contributions are undermined by insufficient contextualization, unaddressed feedback, and a lack of theoretical depth. Addressing these issues in a future revision could make the paper a strong candidate for acceptance.