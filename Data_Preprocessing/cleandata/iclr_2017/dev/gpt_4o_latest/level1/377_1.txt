Review of the Paper
Summary of Contributions
This paper introduces a novel approach to studying how artificial agents can infer hidden physical properties of objects (e.g., mass, cohesion) through active interaction in simulated environments. The authors propose two interactive tasks—"Which is Heavier" and "Towers"—to evaluate agents' ability to experiment and learn representations of object properties using deep reinforcement learning. The paper demonstrates that agents can learn effective experimentation strategies that balance the cost of information gathering with the risk of incorrect predictions. The authors also show that their agents outperform randomized baselines in terms of accuracy and efficiency. While the paper does not propose a new algorithm, it contributes to the field by emphasizing the importance of active experimentation for physical reasoning and by providing a framework to evaluate such capabilities.
Decision: Accept
The paper addresses an important and underexplored problem in AI—how agents can actively interact with their environment to infer hidden physical properties. My decision to accept is based on two key reasons:
1. Novelty of the Problem and Framework: The paper tackles an important gap in AI research by focusing on active experimentation, a capability that current AI systems lack but is fundamental to human learning. The proposed tasks and environments are well-designed to probe this capability.
2. Empirical Rigor: The experiments are thorough, with clear evidence that the agents learn meaningful strategies for experimentation. The comparison with randomized baselines strengthens the claims.
Supporting Arguments
1. Motivation and Placement in Literature: The paper is well-motivated and grounded in prior work from both AI and developmental psychology. The connection to infant learning and the analogy to scientific experimentation provide a compelling narrative. The authors also position their work effectively within the context of related research, such as learning from dynamics and active sensing.
2. Scientific Rigor: The experiments are carefully designed to test the hypotheses. The use of multiple difficulty levels, different actuation strategies, and comparison with baselines demonstrates robustness. The results are consistent with the claims, showing that agents adapt their strategies based on task difficulty and outperform random policies.
3. Broader Impact: The work has implications for advancing AI systems that can reason about the physical world, which is critical for applications in robotics, autonomous systems, and embodied AI.
Suggestions for Improvement
While the paper is strong overall, there are areas where it could be improved:
1. Clarity on Generalization: The paper does not address how well the learned policies generalize to unseen environments or tasks. Future work could explore whether the agents can transfer their learned experimentation strategies to new settings.
2. Comparison with Alternative Approaches: While the paper compares learned policies to randomized baselines, it would be valuable to compare them to other structured approaches, such as model-based reinforcement learning or physics-informed priors.
3. Data Efficiency: The paper acknowledges that it does not optimize for data efficiency. Including a discussion or preliminary results on how the approach could be made more sample-efficient would strengthen the contribution.
4. Theory Building and Transfer: The authors mention the potential for agents to build theories or transfer knowledge but do not explore this. Adding even a small experiment or discussion on this topic would enhance the paper's impact.
Questions for the Authors
1. How well do the learned policies generalize to environments with different physical dynamics or unseen object configurations?
2. Could the proposed framework be extended to tasks requiring more complex reasoning, such as tool use or multi-object interactions?
3. How sensitive are the results to the choice of hyperparameters, especially the discount factor and the architecture of the agent?
In conclusion, this paper makes a meaningful contribution to the field by addressing a critical gap in AI research and providing a framework for studying active experimentation. While there are areas for improvement, the paper's strengths outweigh its limitations, and I recommend its acceptance.