Review of "Hierarchical Multiscale Recurrent Neural Networks"
Summary
This paper introduces the Hierarchical Multiscale Recurrent Neural Network (HM-RNN), a novel approach to learning latent hierarchical structures in temporal data without explicit boundary information. The authors propose a mechanism involving three operations—COPY, UPDATE, and FLUSH—guided by binary boundary detectors, enabling the model to adaptively determine timescales for different abstraction levels. The paper demonstrates the efficacy of the HM-RNN on two tasks: character-level language modeling and handwriting sequence generation. The model achieves state-of-the-art results on the Text8 dataset and competitive performance on the Penn Treebank and Hutter Prize Wikipedia datasets. Additionally, it outperforms standard RNNs on handwriting sequence generation. The paper also introduces the slope annealing trick to improve training stability for models with discrete variables.
Decision: Accept
The paper is well-motivated, addresses a longstanding challenge in RNNs, and provides empirical evidence supporting its claims. The proposed HM-RNN demonstrates both theoretical novelty and practical utility, achieving strong results across multiple tasks. The contributions are significant and well-placed in the literature, making this work a valuable addition to the field.
Supporting Arguments
1. Problem Relevance and Novelty: The paper tackles the important problem of learning hierarchical and temporal representations in RNNs, a challenge that has persisted despite prior work on multiscale RNNs. The proposed HM-RNN introduces a novel mechanism for adaptive timescale learning, which is a meaningful advancement over fixed or soft timescale approaches in prior models.
   
2. Empirical Rigor: The results are robust and scientifically rigorous. The HM-RNN achieves state-of-the-art performance on the Text8 dataset and competitive results on other benchmarks. The handwriting sequence generation task further validates the model's ability to generalize to real-valued temporal data. The visualization of learned hierarchical structures adds interpretability and supports the claim that the model discovers latent structures.
3. Placement in Literature: The paper provides a thorough review of related work and clearly differentiates the HM-RNN from prior models, such as hierarchical RNNs, LSTMs, and clockwork RNNs. The authors highlight the limitations of fixed timescales and demonstrate how their approach overcomes these challenges.
Suggestions for Improvement
1. Clarity of Visualizations: While the boundary visualizations are insightful, their interpretation could be further clarified. For example, providing more detailed explanations of how the detected boundaries align with semantic or syntactic structures in the data would strengthen the analysis.
2. Ablation Studies: The paper would benefit from additional ablation studies to isolate the contributions of individual components, such as the boundary detector, the slope annealing trick, and the specific operations (COPY, UPDATE, FLUSH).
3. Computational Efficiency: While the authors claim computational efficiency due to sparse updates, quantitative comparisons of training and inference times with baseline models would provide stronger evidence for this claim.
4. Generalization to Other Tasks: The paper focuses on two tasks (language modeling and handwriting generation). Exploring the applicability of HM-RNNs to other domains, such as speech or video data, would further demonstrate the model's generality.
Questions for the Authors
1. How sensitive is the model to the choice of hyperparameters, such as the slope annealing schedule or the number of layers?
2. Can the proposed boundary detection mechanism handle data with highly irregular or noisy hierarchical structures?
3. Have you considered extending the HM-RNN to bidirectional architectures for tasks that allow access to future context?
In conclusion, the HM-RNN is a well-executed and impactful contribution to the field of sequence modeling. Addressing the above suggestions would further strengthen the paper, but they do not detract from its overall merit.