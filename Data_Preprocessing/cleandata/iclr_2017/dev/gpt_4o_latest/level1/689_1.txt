Review of the Paper: "Tensorial Mixture Models (TMMs)"
Summary of Contributions:
This paper introduces Tensorial Mixture Models (TMMs), a novel family of generative models designed to address key limitations of existing generative approaches. The authors propose a framework where local structures (e.g., patches in an image) are modeled using mixtures of simple component distributions, with dependencies between these structures represented by a "priors tensor." To overcome the intractability of the priors tensor, the authors leverage tensor decompositions, resulting in a Convolutional Arithmetic Circuit (ConvAC) representation. This framework enables both tractable inference and tractable marginalization, making TMMs particularly suited for tasks like classification with missing data. The authors demonstrate the theoretical properties of TMMs, including universality and expressive capacity, and provide empirical evidence of their effectiveness on image classification tasks, particularly under missing data scenarios. The paper also highlights the advantages of TMMs over discriminative models and other generative approaches, such as Sum-Product Networks (SPNs).
Decision: Accept
Key Reasons for Acceptance:
1. Novelty and Significance: The paper introduces a well-motivated and theoretically grounded generative model that addresses a critical gap in the literatureâ€”classification with missing data. The use of tensor decompositions to achieve tractable inference and marginalization is a significant contribution.
2. Empirical Validation: The experimental results convincingly demonstrate the superiority of TMMs over existing methods, particularly in handling missing data. The performance gains are substantial, with TMMs achieving up to 50 percentage points higher accuracy in some cases.
3. Theoretical Rigor: The paper provides strong theoretical foundations for TMMs, including proofs of universality and depth efficiency, which are critical for understanding the model's expressive power.
Supporting Arguments:
- The paper is well-placed in the literature, addressing the limitations of both discriminative models (e.g., inability to handle missing data) and existing generative models (e.g., intractable inference or marginalization).
- The authors provide a clear and comprehensive explanation of the TMM framework, including its relationship to ConvACs and tensor decompositions.
- The experiments are thorough and include comparisons to a wide range of baselines, including discriminative models, data imputation methods, and generative classifiers like MP-DBMs.
- The theoretical analysis, particularly the proofs of depth efficiency and universality, adds significant weight to the claims made in the paper.
Suggestions for Improvement:
1. Clarity in Presentation: While the paper is dense with theoretical and empirical content, some sections (e.g., the mathematical formulation of TMMs) could benefit from additional simplification or visual aids to improve accessibility for a broader audience.
2. Scalability Discussion: The paper could include a more detailed discussion of the computational complexity of TMMs, particularly in comparison to other generative models, and provide insights into their scalability to larger datasets.
3. Ablation Studies: While the experiments are comprehensive, ablation studies on the impact of key hyperparameters (e.g., the number of channels, pooling window sizes) would provide deeper insights into the model's behavior.
4. Broader Applications: The paper focuses primarily on image classification. Exploring applications in other domains (e.g., text or audio) would strengthen the generalizability of the proposed approach.
Questions for the Authors:
1. How does the computational cost of training and inference for TMMs compare to state-of-the-art discriminative models like ConvNets or other generative models like SPNs?
2. Can the proposed framework be extended to semi-supervised learning or other tasks beyond classification with missing data?
3. How sensitive are TMMs to the choice of tensor decomposition (e.g., CP vs. HT)? Are there scenarios where one decomposition is clearly preferable?
Conclusion:
This paper makes a strong contribution to the field of generative modeling and classification under missing data. The combination of theoretical rigor, practical applicability, and empirical validation makes it a valuable addition to the conference. With minor improvements in presentation and additional experiments, the work has the potential to make a significant impact on the community. I recommend acceptance.