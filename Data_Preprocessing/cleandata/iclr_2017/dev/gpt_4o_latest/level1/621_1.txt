The paper introduces COCONET, a convolutional neural network in the NADE family of generative models, and explores its application to polyphonic music generation using a blocked Gibbs sampling approach. The authors argue that this method better mimics the nonlinear, iterative process of human music composition compared to traditional chronological sampling methods. They claim that blocked Gibbs sampling significantly improves sample quality over ancestral sampling, even when using an approximate procedure. The paper provides evidence that this improvement stems from certain conditional distributions being poorly modeled in ancestral sampling. The authors demonstrate the effectiveness of their approach through experiments on unconditioned polyphonic music generation, including the inpainting of corrupted Bach chorales.
Decision: Accept
The key reasons for this decision are: (1) the paper addresses an important and underexplored problem in music generation by proposing a novel approach inspired by human compositional processes, and (2) the experimental results convincingly demonstrate the superiority of the proposed blocked Gibbs sampling method over traditional approaches.
Supporting Arguments:
1. Problem and Motivation: The paper tackles a well-defined and meaningful problem in music generationâ€”how to better emulate the nonlinear, iterative nature of human composition. The use of blocked Gibbs sampling as an analogue to human creativity is well-motivated and supported by references to prior work in generative modeling (e.g., NADE and Yao et al., 2014).
2. Scientific Rigor: The experimental results are compelling and scientifically rigorous. The authors provide qualitative and quantitative evidence, such as the inpainting of corrupted Bach chorales, to demonstrate the effectiveness of their method. The visualizations and heatmaps are particularly helpful in illustrating the iterative refinement process.
3. Novelty and Contribution: The paper makes a clear contribution by combining blocked Gibbs sampling with convolutional neural networks in the NADE family, offering a new perspective on music generation. The versatility of the method is also demonstrated, adding to its practical relevance.
Suggestions for Improvement:
1. Clarity of Presentation: While the paper is generally well-written, the explanation of how blocked Gibbs sampling is implemented could be more detailed. For instance, a step-by-step breakdown of the algorithm would help readers unfamiliar with the technique.
2. Comparison with Other Methods: The paper primarily compares blocked Gibbs sampling to ancestral sampling. Including comparisons with other state-of-the-art music generation models would strengthen the claims of superiority.
3. Ablation Studies: It would be helpful to see ablation studies that isolate the contributions of different components of the model (e.g., the convolutional architecture vs. the sampling procedure).
Questions for the Authors:
1. How does the model perform on other datasets or genres of music beyond Bach chorales? Is the method generalizable to broader musical contexts?
2. Could you provide more details on the computational efficiency of the blocked Gibbs sampling approach compared to ancestral sampling?
3. How sensitive is the model to hyperparameter choices, particularly in the blocked Gibbs sampling procedure?
In summary, this paper makes a meaningful contribution to the field of music generation and is well-aligned with the conference's goals. With minor clarifications and additional comparisons, it could have even greater impact.