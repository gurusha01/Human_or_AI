This paper introduces a novel approach to defending against adversarial examples by training a complementary classifier to detect them. The experimental results demonstrate that adversarial examples can indeed be detected with relative ease. Furthermore, the proposed detector exhibits strong generalization to other similar or weaker adversarial examples. The core idea of the paper is straightforward yet non-trivial. While the paper does not present a complete framework for leveraging this idea to construct defensive systems, it opens up a promising new direction for further exploration. Given its originality, I recommend acceptance.
My primary concern with this paper lies in its lack of completeness. The paper does not propose an effective method to counter dynamic adversaries. While addressing this challenge may be inherently difficult, the paper appears to make limited efforts to explore this aspect. Understanding how challenging it is to defend against dynamic adversaries is a critical and intriguing question that naturally arises from the paper's conclusions. Investigating this issue could significantly enhance our understanding of adversarial examples.
Nonetheless, the paper's contribution in terms of novelty remains substantial.
Minor comment:  
The paper could benefit from improved clarity. Certain key details are omitted, such as a more thorough explanation of dynamic adversaries and the training methodology for handling them.