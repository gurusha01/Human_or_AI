The paper introduces an end-to-end machine learning model named Dynamic Reader, designed for the machine reading comprehension task. Unlike earlier systems, this model demonstrates the ability to extract and rank a set of answer candidates from a given document.
Recent advancements in question answering systems have largely focused on extracting phrases from articles. This work appears to contribute two distinctive aspects:
1.	The application of a convolutional model, and  
2.	The introduction of dynamic chunking.
While convolutional networks are typically employed for modeling character-based word embeddings, their effectiveness in representing phrases remains unclear. I would appreciate more detailed analysis in this regard, as the authors have not compared the convolutional framework to alternative approaches like LSTM. Such comparisons are crucial, especially since the model incorporates uni-gram, bi-gram, and tri-gram information through the convolutional network. It is not evident whether tri-gram information would still be necessary if LSTM models were utilized.
Dynamic chunking is an interesting concept, and a similar idea has been explored in recent works such as [Kenton et al., 16], which also address the same dataset. However, further analysis of dynamic chunking is needed. Why is this method particularly effective for representing answer chunks? Since the chunk representation is derived from the first and last word representations generated by the convolutional network, I question whether this approach adequately captures long answer phrases.
Additionally, the authors have opted not to use character-based embeddings, instead relying on pre-trained NLP models. It would be valuable to see a discussion of the advantages and disadvantages of using linguistic features compared to character embeddings.
In summary, while the paper presents several promising ideas, the lack of thorough analysis makes it challenging to assess the significance of the proposed techniques.