The paper appears robust, and the proposed idea is intuitive. The results are also quite encouraging.
However, my primary concern lies with the computational cost of the method. Requiring 8-10 days on 10 GPUs for relatively small datasets makes the approach impractical for many real-world applications. A key question is how well this method scales to larger image datasets and whether it remains effective when applied to more unconventional or smaller datasets. For example, could you conduct an experiment on Caltech-101? It would be interesting to see if your method performs well in low-data scenarios and in cases where the optimal architecture is not immediately obvious. For datasets like CIFAR-10/100, MNIST, and SVHN, the community already has a strong understanding of reasonable model initializations.
If you can demonstrate that your approach can discover a competitive architecture for a dataset like Caltech-101, I would be inclined to recommend this paper for publication.
Minor comments:
- ResNets should be included in the table.