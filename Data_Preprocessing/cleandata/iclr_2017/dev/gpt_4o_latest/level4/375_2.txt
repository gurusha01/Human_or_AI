This paper introduces a straightforward method to reweight word embeddings within a simple composition function for sentence representation. Additionally, it establishes a connection between this novel weighting scheme and prior research.
Below are some comments regarding technical aspects:
- The term "discourse" is somewhat unclear. It is not evident whether the term "discourse" in "discourse vector c_s" carries the same meaning as in "most frequent discourse."
- Is there any justification for $c_0$ in relation to syntax?
- The following statement in the section "Computing the sentence embedding" is unclear: "In fact the new model was discovered by our detecting the common component c0 in existing embeddings."
- Could you provide an explanation for the sentiment results presented in Table 2?