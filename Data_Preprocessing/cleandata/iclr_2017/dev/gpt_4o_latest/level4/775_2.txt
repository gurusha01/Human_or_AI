Review: The paper investigates the application of the deep reinforcement learning paradigm for controlling high-dimensional characters. The experiments analyze how different control parameterizations—such as torques, muscle activations, PD control with target joint positions, and target joint velocities—affect the performance of reinforcement learning and the resulting optimized control policies. The evaluation focuses on various planar gait cycle trajectories. The results demonstrate that more abstract parameterizations tend to yield more robust and higher-quality policies.
> Significance & Originality:  
The parameterizations explored in this work are fairly standard in humanoid control. The primary contribution lies in the systematic evaluation of these parameterizations. I believe this type of study is both valuable and insightful. However, the findings are highly specific to the problem setting and the particular architecture tested. It remains unclear whether these results would generalize to other network architectures or control problems/domains. Consequently, for the ICLR community, the work may have limited general appeal, though it might resonate more strongly with the robotics or graphics communities.
> Clarity:  
The paper is well-written and relatively easy to follow for readers with a background in constrained multi-body simulation and control.
> Experiments:  
In my view, the experimental validation is somewhat lacking. Since this is fundamentally an experimental study, I would have appreciated a more thorough analysis of sensitivity to various parameters, as well as an investigation of performance variance when the policy is re-optimized multiple times.