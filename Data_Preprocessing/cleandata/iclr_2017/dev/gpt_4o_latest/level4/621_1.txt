The paper addresses the problem of music generation using an orderless NADE model for the "fill in the notes" task. Specifically, given a roll of T timesteps of pitches, the authors randomly mask certain pitches and train the model to predict the missing notes. This approach aligns with the training methodology of the orderless NADE model. For sampling, the standard approach involves ancestral sampling, where an ordering is defined over the outputs. The model processes the current input, samples one output based on the defined order, incorporates this output into the next input, and iterates until all outputs are sampled. The paper's central argument is that this sampling strategy is suboptimal. Instead, they propose adopting the blocked Gibbs sampling strategy from Yao et al. 2014. In this method, N inputs are randomly and independently masked, sampled, and the process is repeated. The goal of this strategy is to ensure better mixing of the sampling chain, which is achieved with a large N. However, large N can lead to incoherent samples due to the independence of the samples. To address this, the authors employ an annealed schedule for N, gradually reducing it over time. This eventually transitions to ancestral sampling, thereby preserving the global structure of the sample. The paper includes extensive experiments using both standard metrics and human evaluations, demonstrating that the blocked Gibbs sampling approach outperforms other sampling methods.
Overall, this is a well-written paperâ€”great work.
My primary concern is that, having read the works of Uria and Yao, I am uncertain about the extent of new insights this paper provides, particularly in the context of an ICLR submission. If this paper were submitted to a computational music or art-focused conference, it would be a clear accept. However, for ICLR, the novelty compared to prior work seems limited. The orderless NADE model is well-established, and both the blocked Gibbs sampling strategy and the annealing schedule closely follow the method proposed by Yao. Consequently, the primary contribution of this paper lies in its application to the music domain and the finding that Yao's method performs better for sampling music. While this is a valuable contribution, it seems more relevant to researchers in the music domain. If the authors were to demonstrate that these results generalize to other domains, such as images (e.g., CIFAR or tiny Imagenet) or text (e.g., document generation), I would be inclined to accept this paper for ICLR. Even exploring additional musical domains beyond Bach chorales would strengthen the contribution. As it stands, however, the experimental results are not sufficiently compelling.