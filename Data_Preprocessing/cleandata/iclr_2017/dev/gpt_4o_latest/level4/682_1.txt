The authors proposed replacing binary units with leaky rectified linear units in Gaussian RBMs and introduced a sampling method for training the leaky-ReLU RBM. In the experimental section, AIS-estimated likelihoods on CIFAR-10 and SVHN datasets were reported.
Exploring alternative nonlinear hidden units for RBMs is an interesting direction. However, there are several concerns regarding the current work:  
1. The authors did not provide a clear explanation of why the proposed sampling method (Algorithm 2) is theoretically valid. Additionally, the extra computational cost introduced by the inner loop and the projection step should be discussed in detail.  
2. The reported results, including both the likelihood estimates and the generative samples, are significantly worse than what is typically observed for Gaussian RBMs. This raises concerns that the Gaussian RBM may not have been trained effectively.  
3. Representations learned from high-quality generative models often improve performance in classification tasks, especially in low-label scenarios. Furthermore, Gaussian RBMs are known to perform well in texture synthesis tasks where mixing is a critical factor. The authors are encouraged to conduct additional experiments in these two directions to strengthen their work.