The semi-Markov decision process (SMDP) framework has been extensively utilized for modeling skill acquisition and temporal abstraction in reinforcement learning. This paper introduces a variation of this framework, referred to as the semi-aggregated MDP (SAMDP) model.
However, the formalism of SAMDP is insufficiently defined to warrant significant consideration. The proposed approach is largely heuristic and relies on illustrative examples rather than providing a clear and precise definition. Furthermore, the work lacks the necessary theoretical depth and rigor.
The paper presents simple experiments conducted in 2D grid worlds to showcase skills. While grid worlds have historically been useful in reinforcement learning research, their utility has diminished, and they should now be replaced with more realistic and contemporary domains, which are increasingly standard in the field.