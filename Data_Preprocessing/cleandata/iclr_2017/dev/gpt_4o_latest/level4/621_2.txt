The paper introduces a method for modeling the distribution of four-part Bach chorales using Convolutional Neural Networks. Additionally, it tackles the challenge of artificial music generation by employing blocked Gibbs sampling to sample from the model, presenting intriguing results.
The CNN-based approach for modeling the distribution appears highly suitable for the dataset in question. Moreover, the exploration of the proposed sampling strategies, along with the analogy drawn between Gibbs sampling and human music composition, is particularly compelling.
However, I have some reservations regarding the evaluation. Since the reported likelihoods are not directly comparable to prior work, it is challenging to assess the quality of the quantitative results. For the human evaluation, I would appreciate access to the data for direct comparisons between the models. For instance, how did NADE perform relative to Bach? Additionally, I believe the question "Which piece of music do you prefer?" would serve as a more robust test than "Which piece is more musical to you?" as the term "musical" may be ambiguous to the AMT workers.
Lastly, while I agree that Bach Chorales are fascinating musical pieces worthy of analysis, I find it difficult to determine how effectively this modeling approach would generalize to other types of music with potentially very different data distributions.
In summary, despite these concerns, I find this to be an innovative model addressing an interesting problem, and it demonstrates the ability to generate non-trivial musical data.