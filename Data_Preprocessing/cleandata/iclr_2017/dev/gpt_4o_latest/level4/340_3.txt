Update: After reviewing the rebuttal comments and the revised submission, I have decided to maintain my initial rating.
This paper introduces an unsupervised algorithm designed to transfer samples between one domain and another (related) domain, with the constraint that a predefined function f produces the same output for both the input and the transformed result.
Strengths:
1. The paper introduces an intriguing concept of comparing samples across domains using a fixed perceptual function f.
2. The proposed approach generates visually compelling results across multiple datasets.
3. The authors demonstrate the utility of their method for domain adaptation, achieving improved performance on the SVHN-to-MNIST task.
4. The paper is well-structured and clearly written, making it accessible to readers.
Weaknesses:
1. The novelty of the method is somewhat limited, as the primary contribution appears to be the introduction of the f-constancy term.
2. The proposed method seems likely to fail when applied to more dissimilar domains. The approach depends on a fixed f trained on the source domain, which could potentially lose information critical for achieving 1) higher-quality reconstructions in the target domain and 2) stronger alignment between x and g(f(x)). I recommend that the authors explore training all components of the model end-to-end or incorporating target domain samples into the training process for f.
3. The inclusion of only a single domain adaptation experiment is insufficient to establish the proposed method as a general alternative to existing domain adaptation techniques.
Additionally, I would like to highlight that presenting super-resolved outputs instead of the actual model outputs may create a misleading impression of the visual quality of the transferred samples. I suggest moving the original outputs from the appendix to the main text for greater transparency.