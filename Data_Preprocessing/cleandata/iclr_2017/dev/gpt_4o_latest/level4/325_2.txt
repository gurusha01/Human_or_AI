The paper introduces a novel method for training a generative model through an iterative denoising process. This process begins with a random sample from a rough approximation of the data distribution and refines it into a high-quality sample via multiple denoising steps. The training involves constructing a Markov chain that gradually blends samples from the current denoising model with real data examples. The denoising model is then updated to reproduce the improved samples generated through this blending process.
This is a well-written paper that explores an intriguing approach to training generative models. I found the simplicity of the proposed method appealing and enjoyed reading the paper. The method is innovative, though it shares conceptual similarities with recent work on using denoising models for sampling, such as the work by Sohl-Dickstein and research on employing denoising autoencoders (DAEs) as generative models.
I believe this line of research is significant. The proposed approach draws inspiration from generating samples by minimizing an energy function via transitions along a Markov chain. If successful, it could potentially address several challenges faced by current methods for training directed generative models, including:
- Convergence and mode collapse issues in generative adversarial networks (GANs)
- Difficulties in modeling multi-modal distributions when pairing a powerful generative model with a restrictive approximate inference model
That said, another promising method that bears some superficial resemblance to the proposed work is the combination of Hamiltonian Monte Carlo (HMC) inference with variational inference, as described in [1]. I am not entirely convinced that the proposed method will outperform the approach in [1], though it may be simpler to train. Similarly, while the authors argue that using a Markov chain Monte Carlo (MCMC) chain for sampling via a Monte Carlo Expectation-Maximization (MC-EM) procedure is computationally expensive, I am not convinced that such a procedure would fail to perform reasonably well on a simple dataset like MNIST. A more direct comparison of different inference methods using MCMC-based procedures would be valuable, though I understand this may fall outside the scope of the paper. However, I would have expected a direct comparison to Sohl-Dickstein's method in terms of sampling steps and generation quality, given the close relationship between the two approaches.
Major Points (Strengths and Weaknesses):
- While the method is generally well-explained, some training details are missing. For instance, the paper does not specify how the parameters alpha or omega are set (I assume omega is 0.01 based on the experimental setup). It is also unclear how alpha influences the generator's performance. While it seems reasonable to use a small alpha over many steps to ensure gradual blending of distributions, the paper does not clarify how critical this choice is or at what point the procedure might fail (e.g., if alpha = 1, would the generator be able to denoise a sample from the relatively uninformative p0?). The authors mention in a figure caption that the denoising model fails to produce good samples in 1-2 steps, but this might be an artifact of training the model with a small alpha. Additional experiments on this would be helpful.
- The paper does not include infusion chains or generating chains for more complex data distributions, which would have been interesting to examine.
- The evaluation of the model across multiple metrics is commendable, and the bound on the log-likelihood is a valuable addition.
- The proposed approach lacks theoretical guarantees. It remains unclear under what conditions (e.g., specific choices of alpha) the procedure will succeed or whether there is a deeper connection to MCMC sampling or energy-based models. While this does not detract significantly from the paper's value, it might be worth briefly addressing in the conclusion.
Minor Points:
- The second reference appears to be broken.
- Figure 3 begins at 100 epochs, which limits its informativeness. It might be more useful to display the entire training process and use a log-scale for the x-axis.
- The explanation of the convolutional networks is unclear. The authors state that they use the same architecture as the "Improved GANs" paper, which generates samples from a fixed-length random input. However, the proposed model likely does not use a generator with one fully connected layer followed by up-convolutions. Instead, it seems to involve several convolutional stages, a fully connected layer, and then up-convolutions. This should be clarified.
- The choice to parametrize the variance using a sigmoid output unit is unconventional. Was there a specific motivation for this decision?
- Footnote 1 contains grammatical errors: "This allow to" → "This allows to," "few informations" → "little information," "This force the network" → "This forces the network."
- Page 1: Typographical error ("etc...").
- Page 4: Typographical error ("operator should to learn").
[1] Markov Chain Monte Carlo and Variational Inference: Bridging the Gap, Tim Salimans and Diederik P. Kingma and Max Welling, ICML 2015.
---
Update:
Based on the authors' response, I believe all open issues have been adequately addressed. I strongly support the acceptance of this paper to the conference. The only remaining concern is that, as the authors acknowledge, the generator's architecture is likely suboptimal and may limit the method's performance during evaluation. However, this does not detract from the paper's main contributions.
I am maintaining my score as a clear accept. I would like to emphasize my belief that this paper should be published, even if the review process imposes a high cut-off threshold due to inflated review scores.