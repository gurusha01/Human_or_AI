This paper introduces COCONET, a neural autoregressive model incorporating convolution, designed for the task of music composition. It further proposes the use of blocked Gibbs sampling as an alternative to the ancestral sampling employed in the original NADE model, aiming to generate higher-quality musical pieces. Experimental results demonstrate that COCONET achieves a lower NLL compared to other baseline models, and a human evaluation conducted via Amazon's Mechanical Turk indicates that the model is capable of producing compelling music.
Overall, I find the paper to be solid. The application of a NADE-based model with convolutional operations to music generation, combined with the use of blocked Gibbs sampling, introduces a degree of novelty. However, the contribution is somewhat incremental, as blocked Gibbs sampling for NADE models was previously proposed by Yao et al. (2014), and the use of NADE-based models for music modeling was earlier explored by Boulanger-Lewandowski et al. (2012).