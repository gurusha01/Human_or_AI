This paper presents a reinforcement learning framework aimed at automating the design of neural network architectures. At each time step, the agent selects a new layer type along with its associated parameters (e.g., number of filters). To manage the complexity of the state-action space, the authors employ a limited set of design options.
Strengths:
- Proposes an innovative approach for the automatic design of neural network architectures.
- Demonstrates promising performance across multiple datasets (MNIST, CIFAR-10).
Weaknesses:
- The architecture design space is constrained by several prior assumptions (e.g., predefined sets for the number of convolution filters, a maximum of 2 fully connected layers, fixed maximum depth, hard-coded dropout, etc.).
- The method is tested within a tabular Q-learning framework, leaving uncertainty about its scalability to larger state-action spaces.
In summary, this work offers a compelling and original method for designing neural network architectures, and despite some limitations, it appears to merit publication.