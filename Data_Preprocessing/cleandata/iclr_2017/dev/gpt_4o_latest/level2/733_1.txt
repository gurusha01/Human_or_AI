The paper proposes a novel approach to designing anomaly-based host intrusion detection systems (HIDS) by leveraging a system-call language modeling technique using LSTM-based neural networks and an innovative ensemble method to reduce false alarm rates. The authors claim two main contributions: (1) introducing a system-call language model that captures both semantic meaning and interactions of system calls, and (2) developing an ensemble method that integrates multiple thresholding classifiers to minimize false alarms. The paper demonstrates the effectiveness of the proposed method through experiments on benchmark datasets, highlighting its robustness, portability, and efficiency.
Decision: Accept
Key reasons for this decision are the novelty of the proposed system-call language modeling approach and the significant reduction in false alarm rates achieved by the ensemble method. The paper provides a well-motivated solution to a critical problem in computer security, and the experimental results convincingly support the claims.
Supporting Arguments:
1. Novelty and Contribution: The application of LSTM-based language modeling to system-call sequences is a fresh perspective in the domain of intrusion detection. The ensemble method, which focuses on accumulating "highly normal" sequences, is innovative and addresses a key limitation of anomaly-based IDSâ€”high false alarm rates.
2. Experimental Rigor: The authors validate their approach using multiple datasets (ADFA-LD, KDD98, UNM) and compare their results against state-of-the-art methods. The reported AUC values and false alarm rates demonstrate the superiority of the proposed method.
3. Practical Usefulness: The portability of the system-call language model across different datasets and systems is a significant advantage, reducing the training overhead and enabling broader applicability.
4. Relevance to Literature: The paper provides a thorough review of related work and situates its contributions within the context of existing methods, such as Markov models, feature-based classifiers, and deep learning approaches.
Additional Feedback:
1. Clarity of Presentation: While the technical details are comprehensive, the paper could benefit from a clearer explanation of the ensemble method, particularly the role of the leaky ReLU function and its impact on performance.
2. Limitations and Future Work: The authors acknowledge the challenges of detecting sophisticated attacks like mimicry attacks but could elaborate on how their method might be extended to address these scenarios. Additionally, the scalability of the approach in real-world, high-throughput environments could be discussed further.
3. Visualization of Results: The t-SNE visualizations of system-call embeddings are insightful, but similar visualizations for attack patterns (even if limited) could strengthen the narrative around the model's ability to differentiate between normal and abnormal sequences.
Questions for Authors:
1. How sensitive is the proposed method to the choice of hyperparameters in the LSTM model? Could this affect its portability across different systems?
2. Have you considered incorporating domain-specific prior knowledge into the system-call language model to further enhance its performance?
3. Could the ensemble method be extended to include classifiers trained on different datasets to improve generalization further?
In summary, the paper presents a compelling and well-supported contribution to the field of intrusion detection systems. With minor improvements in clarity and additional discussion of its limitations, this work has the potential to make a significant impact.