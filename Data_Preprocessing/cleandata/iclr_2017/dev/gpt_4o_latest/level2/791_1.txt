Review of the Paper
Summary of Contributions
This paper introduces Spatial Contrasting (SC), a novel unsupervised learning criterion for training convolutional networks (ConvNets) on unlabeled data. The key idea is to leverage the spatial similarity of features within an image and the dissimilarity between features from different images to learn useful representations. The SC loss is differentiable and integrates seamlessly into standard ConvNet training pipelines using stochastic gradient descent (SGD) and backpropagation. The authors demonstrate that SC can serve as an effective pretraining method, improving performance on supervised tasks across datasets like STL10, CIFAR10, and MNIST. Notably, SC achieves state-of-the-art results on STL10 and competitive performance on CIFAR10, showcasing its potential to leverage unlabeled data effectively.
Decision: Accept
The paper presents a significant and well-motivated contribution to unsupervised learning for ConvNets, addressing a critical challenge in the field. The proposed SC criterion is innovative, practical, and empirically validated with strong results. My decision to accept is based on the novelty of the approach, its demonstrated effectiveness, and its potential for broader applicability in semi-supervised and unsupervised learning.
Supporting Arguments
1. Novelty and Innovation: The SC criterion is a unique approach that contrasts spatial features within and across images, moving beyond traditional reconstruction-based unsupervised methods. This innovation addresses key limitations of existing techniques, such as their reliance on pixel-level reconstruction or extensive architectural modifications.
   
2. Empirical Validation: The experiments are thorough and demonstrate clear improvements over baseline models. For example, the SC-initialized model achieves a 7% improvement in test accuracy on STL10 compared to the previous best model, and a 6.8% improvement on CIFAR10 over non-initialized models. These results strongly support the claim that SC effectively leverages unlabeled data.
3. Practicality: The SC loss integrates seamlessly into existing ConvNet architectures and training pipelines without requiring significant computational overhead or architectural changes. This makes it a practical and accessible method for the community.
Suggestions for Improvement
1. Clarity of Presentation: While the technical details are well-explained, the paper could benefit from a more concise and structured presentation of the SC loss formulation and training procedure. For example, the explanation of Equation (4) could be streamlined for better readability.
   
2. Comparison with Semi-Supervised Methods: Although the paper focuses on unsupervised pretraining, it would be valuable to compare SC with semi-supervised methods like Ladder Networks to highlight its potential in hybrid settings.
3. Ablation Studies: The paper would benefit from additional ablation studies to isolate the contributions of different components of the SC loss (e.g., patch size, number of contrasting samples) and their impact on performance.
4. Broader Applicability: The authors briefly mention the potential for temporal contrasting in sequence data. Including preliminary experiments or a discussion of how SC could be adapted for non-visual domains would strengthen the paper's broader impact.
Questions for the Authors
1. How sensitive is the SC loss to hyperparameters such as patch size, batch size, and the choice of contrasting samples? Did you observe any trade-offs between computational cost and performance?
2. Have you explored the use of SC in semi-supervised settings where both labeled and unlabeled data are available? If so, how does it compare to existing semi-supervised methods?
3. Could SC be extended to other modalities, such as audio or text? If so, what modifications would be required?
Conclusion
This paper makes a significant contribution to unsupervised learning for ConvNets by introducing the SC criterion, which is both innovative and practical. The strong empirical results and the potential for broader applicability make this work a valuable addition to the field. While there are areas for improvement, particularly in presentation and additional comparisons, these do not detract from the overall quality and impact of the work. I recommend acceptance.