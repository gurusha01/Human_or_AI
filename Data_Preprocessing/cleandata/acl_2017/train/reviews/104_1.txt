- Strengths:
* Outperforms ALIGN in supervised entity linking task which suggests that the
proposed framework improves representations of text and knowledge that are
learned jointly.
* Direct comparison with closely related approach using very similar input
data.
* Analysis of the smoothing parameter provides useful analysis since impact of
popularity is a persistent issue in entity linking.
- Weaknesses:
* Comparison with ALIGN could be better. ALIGN used content window size 10 vs
this paper's 5, vector dimension of 500 vs this paper's 200. Also its not clear
to me whether N(ej) includes only entities that link to ej. The graph is
directed and consists of wikipedia outlinks, but is adjacency defined as it
would be for an undirected graph? For ALIGN, the context of an entity is the
set of entities that link to that entity. If N(e_j) is different, we cannot
tell how much impact this change has on the learned vectors, and this could
contribute to the difference in scores on the entity similarity task. 
* It is sometimes difficult to follow whether "mention" means a string type, or
a particular mention in a particular document. The phrase "mention embedding"
is used, but it appears that embeddings are only learned for mention senses.
* It is difficult to determine the impact of sense disambiguation order without
comparison to other unsupervised entity linking methods. 
- General Discussion: