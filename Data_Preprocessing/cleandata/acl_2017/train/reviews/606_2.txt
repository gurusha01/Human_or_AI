This paper introduces Neural Symbolic Machines (NSMs) --- a deep neural model
equipped with discrete memory to facilitate symbolic execution. An NSM includes
three components: (1) a manager that provides weak supervision for learning,
(2) a differentiable programmer based on neural sequence to sequence model,
which encodes input instructions and predicts simplified Lisp programs using
partial execution results stored in external discrete memories. (3) a symbolic
computer that executes programs and provide code assistance to the programmer
to prune search space. The authors conduct experiments on a semantic parsing
task (WebQuestionsSP), and show that (1) NSM is able to model language
compositionality by saving and reusing intermediate execution results, (2)
Augmented REINFORCE is superior than vanilla REINFROCE for sequence prediction
problems, and (3) NSM trained end-to-end with weak supervision is able to
outperform existing sate-of-the-art method (STAGG).
- Strengths
* The idea of using discrete, symbolic memories for neural execution models is
novel.                    Although in implementation it may simply reduce to copying
previously
executed variable tokens from an extra buffer, this approach is still
impressive since it works well for a large-scale semantic parsing task.
* The proposed revised REINFORCE training schema using imperfect hypotheses
derived from maximum likelihood training is interesting and effective, and
could inspire future exploration in mixing ML/RL training for neural
sequence-to-sequence models.
* The scale of experiments is larger than any previous works in modeling neural
execution and program induction. The results are impressive.
* The paper is generally clear and well-written, although there are some points
which might require further clarification (e.g., how do the keys ($v_i$'s in
Fig. 2) of variable tokens involved in computing action probabilities?
Conflicting notations: $v$ is used to refer to variables in Tab. 1 and memory
keys in Fig 1.).
Overall, I like this paper and would like to see it in the conference.
* Weaknesses
* [Choice of Dataset] The authors use WebQuestionsSP as the testbed. Why not
using the most popular WebQuestions (Berant et al., 2013) benchmark set? Since
NSM only requires weak supervision, using WebQuestions would be more intuitive
and straightforward, plus it could facilitate direct comparison with
main-stream QA research.
* [Analysis of Compositionality] One of the contribution of this work is the
usage of symbolic intermediate execution results to facilitate modeling
language compositionality. One interesting question is how well questions with
various compositional depth are handled. Simple one-hop questions are the
easiest to solve, while complex multi-hop ones that require filtering and
superlative operations (argmax/min) would be highly non-trivial. The authors
should present detailed analysis regarding the performance on question sets
with different compositional depth.
* [Missing References] I find some relevant papers in this field missing. For
example, the authors should cite previous RL-based methods for knowledge-based
semantic parsing (e.g., Berant and Liang., 2015), the sequence level REINFORCE
training method of (Ranzato et al., 2016) which is closely related to augmented
REINFORCE, and the neural enquirer work (Yin et al., 2016) which uses
continuous differentiable memories for modeling neural execution.
* Misc.
* Why is the REINFORCE algorithm randomly initialized (Algo. 1) instead of
using parameters pre-trained with iterative ML?
* What is KG server in Figure 5?