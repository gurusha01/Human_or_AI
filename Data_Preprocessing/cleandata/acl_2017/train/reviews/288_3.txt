- Strengths:
*The paper is very well written
*It shows how stylometric analysis can help in reasoning-like text
classification
*The results have important implications for design on NLP datasets
*The results may have important implications for many text classification tasks
- Weaknesses:
*I see few weaknesses in this paper. The only true one is the absence of a
definition of style, which is a key concept in the paper
- General Discussion:
This paper describes two experiments that explore the relationship between
writing task and writing style. In particular, controlling for vocabulary and
topic, the authors show that features used in authorship attribution/style
analysis can go a long way towards distinguishing between 1) a natural ending
of a story 2) an ending added by a different author and 3) a purposefully
incoherent ending added by a different author.
This is a great and fun paper to read and it definitely merits being accepted.
The paper is lucidly written and clearly explains what was done and why. The
authors use well-known simple features and a simple classifier to prove a
non-obvious hypothesis. Intuitively, it is obvious that a writing task greatly
constraints style. However, proven in such a clear manner, in such a controlled
setting, the findings are impressive.
I particularly like Section 8 and the discussion about the implications on
design of NLP tasks. I think this will be an influential and very well cited
paper. Great work.  
The paper is a very good one as is. One minor suggestion I have is defining
what the authors mean by "style" early on. The authors seem to mean "a
set of low-level easily computable lexical and syntactic features".  As is,
the usage is somewhat misleading for anyone outside of computational
stylometrics. 
The set of chosen stylistic features makes sense. However, were there no other
options? Were other features tried and they did not work? I think a short
discussion of the choice of features would be informative.