- Strengths: The authors address a very challenging, nuanced problem in
political discourse reporting a relatively high degree of success.
The task of political framing detection may be of interest to the ACL
community.
The paper is very well written.
- Weaknesses: Quantitative results are given only for the author's PSL model
and not compared against any traditional baseline classification algorithms,
making it unclear to what degree their model is necessary. Poor comparison with
alternative approaches makes it difficult to know what to take away from the
paper.
The qualitative investigation is interesting, but the chosen visualizations are
difficult to make sense of and add little to the discussion. Perhaps it would
make sense to collapse across individual politicians to create a clearer
visual.
- General Discussion: The submission is well written and covers a topic which
may be of interest to the ACL community. At the same time, it lacks proper
quantitative baselines for comparison. 
Minor comments:
- line 82: A year should be provided for the Boydstun et al. citation
- It's unclear to me why similar behavior (time of tweeting) should
necessarily be indicative of similar framing and no citation was given to
support this assumption in the model.
- The related work goes over quite a number of areas, but glosses over the work
most clearly related (e.g. PSL models and political discourse work) while
spending too much time mentioning work that is only tangential (e.g.
unsupervised models using Twitter data).
- Section 4.2 it is unclear whether Word2Vec was trained on their dataset or if
they used pre-trained embeddings.
- The authors give no intuition behind why unigrams are used to predict frames,
while bigrams/trigrams are used to predict party.
- The authors note that temporal similarity worked best with one hour chunks,
but make no mention of how important this assumption is to their results. If
the authors are unable to provide full results for this work, it would still be
worthwhile to give the reader a sense of what performance would look like if
the time window were widened.
- Table 4: Caption should make it clear these are F1 scores as well as
clarifying how the F1 score is weighted (e.g. micro/macro). This should also be
made clear in the "evaluation metrics" section on page 6.