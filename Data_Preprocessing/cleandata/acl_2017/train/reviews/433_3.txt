The authors construct a new dataset of 1200 Singaporean English (Singlish)
sentences annotated with Universal Dependencies. They show that they can
improve the performance of a POS tagger and a dependency parser on the Singlish
corpus by integrating English syntactic knowledge via a neural stacking model.
- Strengths:
Singlish is a low-resource language. The NLP community needs more data for low
resource languages, and the dataset accompanying this paper is a useful
contribution. There is also relatively little NLP research on creoles, and the
potential of using transfer-learning to analyze creoles, and this paper makes a
nice contribution in that area.
The experimental setup used by the authors is clear. They provide convincing
evidence that incorporating knowledge from an English-trained parser into a
Singlish parser outperforms both an English-only parser and a Singlish-only
parser on the Singlish data. They also provide a good overview of the relevant
differences between English and Singlish for the purposes of syntactic parser
and a useful analysis of how different parsing models handle these
Singlish-specific constructions.
- Weaknesses:
There are three main issues I see with this paper:
*  There is insufficient comparison to the UD annotation of non-English
languages. Many of the constructions they bring up as specific to Singlish are
also present in other UD languages, and the annotations should ideally be
consistent between Singlish and these languages.
*  I'd like to see an analysis on the impact of training data size. A central
claim of this paper is that using English data can improve performance on a
low-resource language like Singlish. How much more Singlish data would be
needed before the English data became unnecessary?
*  What happens if you train a single POS/dep parsing model on the concatenated
UD Web and Singlish datasets? This is much simpler than incorporating neural
stacking. The case for neural stacking is stronger if it can outperform this
baseline.
- General Discussion:
Line 073: "POS taggers and dependency parsers perform poorly on such Singlish
texts based on our observations" - be more clear that you will quantify this
later. As such, it seems a bit hand-wavy.
Line 169: Comparison to neural network models for multi-lingual parsing. As far
as I can tell, you don't directly try the approach of mapping Singlish and
English word embeddings into the same embedding space.
Line 212: Introduction of UD Eng. At this point, it is appropriate to point out
that the Singlish data is also web data, so the domain matches UD Eng.
Line 245: "All borrowed words are annotated according to their original
meanings". Does this mean they have the same POS as in  the language from
which they were borrowed? Or the POS of their usage in Singlish?
Figure 2: Standard English glosses would be very useful in understanding the
constructions and checking the correctness of the UD relations used.
Line 280: Topic prominence: You should compare with the "dislocated" label
in UD. From the UD paper: "The dislocated relation captures preposed (topics)
and postposed elements". The syntax you are describing sounds similar to a
topic-comment-style syntax; if it is different, then you should make it clear
how.
Line 294: "Second, noun phrases used to modify the predicate with the
presence of a preposition is regarded as a "nsubj" (nominal subject)."
Here, I need a gloss to determine if this analysis makes sense. If the phrase
is really being used to modify the predicate, then this should not be nsubj. UD
makes a distinction between core arguments (nsubj, dobj, etc) and modifiers. If
this is a case of modification, then you should use one of the modification
relations, not a core argument relation. Should clarify the language here.
Line 308: "In UD-Eng standards, predicative "be" is the only verb used as
a copula, which often depends on its complement to avoid copular head." This
is an explicit decision made in UD, to increase parallelism with non-copular
languages (e.g., Singlish). You should call this out. I think the rest of the
discussion of copula handling is not necessary.
Line 322: "NP deletion: Noun-phrase (NP) deletion often results in null
subjects or objects." This is common in other languages (zero-anaphora in
e.g. Spanish, Italian, Russian, Japaneseâ€¦ )Would be good to point this out,
and also point to how this is dealt with in UD in those languages (I believe
the same way you handle it).
Ling 330: Subj/verb inversion is common in interrogatives in other languages
("Fue Marta al supermercado/Did Marta go to the supermarket?"). Tag
questions are present in English (though perhaps are not as frequent). You
should make sure that your analysis is consistent with these languages.
Sec 3.3 Data Selection and Annotation:
The way you chose the Singlish sentences, of course an English parser will do
poorly (they are chosen to be disimilar to sentences an English parser has seen
before). But do you have a sense of how a standard English parser does overall
on Singlish, if it is not filtered this way? How common are sentences with
out-of-vocabulary terms or the constructions you discussed in 3.2?
A language will not necessarily capture unusual sentence structure,
particularly around long-distance dependencies. Did you investigate whether
this method did a good job of capturing sentences with the grammatical
differences to English you discussed in Section 3.2?
Line 415: "the inter-annotator agreement has an unlabeled attachment score
(UAS) of 85.30% and a labeled attachment score (LAS) of 75.72%."
*  What's the agreement on POS tags? Is this integrated with LAS?
*  Note that in Silveira et al 2014, which produced UD-Eng, they measured 94%
inter-annotator agreement on a per-token basis. Why the discrepancy?
POS tagging and dep parsing sections:
For both POS-tagging and dep parsing, I'd like to see some analysis on the
effect of training set size. E.g., how much more Singlish data would be needed
to train a POS tagger/dep parser entirely on Singlish and get the same accuracy
as the stacked model?
What happens if you just concatenate the datasets? E.g., train a model on a
hybrid dataset of EN and Singlish, and see what the result is?
Line 681: typo: "pre-rained" should be "pre-trained"
742 "The neural stacking model leads to the biggest improvement over nearly
all categories except for a slightly lower yet competitive performance on "NP
Deletion" cases" --- seems that the English data strongly biases the parser
to expect an explicit subj/obj. you could try deleting subj/obj from some
English sentences to improve performance on this construction.