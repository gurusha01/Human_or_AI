- Strengths:
This paper introduced a novel method to improve zero pronoun resolution
performance.. The main contributions of this papers are: 1) proposed a simple
method to automatically generate a large training set for zero pronoun
resolution task; 2) adapted a two step learning process to transfer knowledge
from large data set to the specific domain data; 3) differentiate unknown words
using different tags. In general, the paper is well written. Experiments are
thoroughly designed. 
- Weaknesses:
But I have a few questions regarding finding the antecedent of a zero pronoun:
1. How will an antecedent be identified, when the prediction is a pronoun? The
authors proposed a method by matching the head of noun phrases. It's not
clear how to handle the situation when the head word is not a pronoun.
2. What if the prediction is a noun that could not be found in the previous
contents?
3. The system achieves great results on standard data set. I'm curious is it
possible to evaluate the system in two steps? The first step is to evaluate the
performance of the model prediction, i.e. to recover the dropped zero pronoun
into a word; the second step is to evaluate how well the systems works on
finding an antecedent.
I'm also curious why the authors decided to use attention-based neural
network. A few sentences to provide the reasons would be helpful for other
researchers.
A minor comment:
In figure 2, should it be s1, s2 … instead of d1, d2 ….? 
- General Discussion:
Overall it is a great paper with innovative ideas and solid experiment setup.