This paper presents an interesting model for reading comprehension, by
depicting the multiplicative interactions between the query and local
information around a word in a document, and the authors proposed a new
gated-attention strategy to characterize the relationship. The work is quite
solid, with almost state of art result on the whole four cloze-style datasets
achieved. Some of the further improvement can be helpful for the similar tasks.
Nevertheless, I have some concerns on the following aspect:
1. The authors have referred many papers from arXiv, but I think some really
related works are not included. Such as the works from Caiming Xiong, et al.
https://openreview.net/pdf?id=rJeKjwvclx and the work form Shuohang Wang, et
al. https://openreview.net/pdf?id=B1-q5Pqxl . Both of them concentrated on
enhancing the attention operation to modeling the interaction between documents
and queries. Although these works are not evaluated on the cloze-style corpus
but the SQuAD, an experimental or fundamental comparison may be necessary.
2. There have been some studies that adopts attention mechanism or its variants
specially designed for the Reading Comprehension tasks, and the work actually
share the similar ideas with this paper. My suggestion is to conduct some
comparisons with such work to enhance the experiments of this paper.