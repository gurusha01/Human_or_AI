The paper presents a self-learning framework for learning of bilingual word
embeddings. The method uses two embeddings (in source and target languages) and
a seed lexicon. On each step of the mapping learning a new bilingual lexicon is
induced. Then the learning step is repeated using the new lexicon for learning
of new mapping. The process stops when a convergence criterion is met.
One of the strengths is that the seed lexicon is directly encoded in the
learning process as a binary matrix. Then the self-learning framework solves a
global optimization problem in which the seed lexicon is not explicitly
involved. Its role is to establish the initial mapping between the two
embeddings. This guarantees the convergence. The initial seed lexicon could be
quite small (25 correspondences).
The small size of the seed lexicon is appealing for mappings between languages
for which there are not large bilingual lexicons.
It will be good to evaluate the framework with respect to the quality of the
two word embeddings. If we have languages (or at least one of the languages)
with scarce language resources then the word embeddings for both languages
could differ in their structure and coverage. I think it could be simulated on
the basis of the available data via training the corresponding word embeddings
on different subcorpora for each language.