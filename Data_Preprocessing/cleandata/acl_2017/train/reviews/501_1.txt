The paper proposes a task of selecting the most appropriate textual description
for a given scene/image from a list of similar options. It also proposes couple
of baseline models, an evaluation metrics and human evaluation score. 
- Strengths:
The paper is well-written and well-structured. 
It is clear with its contributions and well supports them by empirical
evidence. So the paper is very easy to read. 
The paper is well motivated. A method of selecting the most appropriate caption
given a list of misleading candidates will benefit other
image-caption/understanding models, by acting as a post-generation re-ranking
method. 
- Weaknesses:
I am not sure if the proposed algorithm for decoys generation is effective,
which as a consequence puts the paper on questions.
For each target caption, the algorithm basically picks out those with similar
representation and surface form but do not belong to the same image. But a
fundamentally issue with this approach is: not belonging to the image-A does
not mean not appropriate to describe image-A, especially when the
representation and surface form are close. So the ground-truth labels might not
be valid. As we can see in Figure-1, the generated decoys are either too far
from the target to be a good decoy (giraffe vs elephant), or fair
substitutes for the target (small boy playing kites vs boy flies a kite).
Thus, I am afraid that the dataset generated with this algorithm can not train
a model to really go beyond key word recognition, which was claimed as
contribution in this paper. As shown in Figure-1, most
decoys can be filtered by key word mismatch---giraffe vs elephant, *pan vs
bread, frisbee vs kite, etc. And when they can not be separated by key word
match*, they look very tempting to be a correct option.
Furthermore, it is interesting that humans only do correctly on 82.8% on a
sampled test set. Does it mean that those examples are really too hard even for
human to correctly classify? Or are some of the decoys in fact good enough to
be the target's substitute (or even better) so that human choose them over
ground-truth targets?
- General Discussion:
I think this is a well-written paper with clear motivation and substantial
experiments. 
The major issue is that the data-generating algorithm and the generated dataset
do not seem helpful for the motivation. This in turn makes the experimental
conclusions less convincing. So I tend to reject this paper unless my concerns
can be fully addressed in rebuttal.