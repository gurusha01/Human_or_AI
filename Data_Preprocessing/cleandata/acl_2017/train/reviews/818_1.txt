Thank you for the author response. It addresses some my concerns, though much
of it are promises ("we will...") -- necessarily so, given space constraints,
but then, this is precisely the problem: I would like to see the revision to
the paper to be able to check that the drawbacks have been fixed. The changes
needed are quite substantial, and the new experimental results that they
promise to include will not have undergone review if the paper is accepted at
this stage. I'm still not sure that we can simply leave it to the authors to
make the necessary changes without a further reviewing round. I upgrade my
score to a 3 to express this ambivalence (I do like the research in the paper,
but it's extremely messy in its presentation).
--------------
- Strengths:
The topic of the paper is very creative and the purpose of the research really
worthwhile: the paper aims at extracting common knowledge from text, overcoming
the well-known problem of reporting bias (the fact that people will not state
the obvious, such as the fact that a person is usually bigger than a ball), by
doing joint inference on information that is possible to extract from text.
- Weaknesses:
1) Many aspects of the approach need to be clarified (see detailed comments
below). What worries me the most is that I did not understand how the approach
makes knowledge about objects interact with knowledge about verbs such that it
allows us to overcome reporting bias. The paper gets very quickly into highly
technical details, without clearly explaining the overall approach and why it
is a good idea.
2) The experiments and the discussion need to be finished. In particular, there
is no discussion of the results of one of the two tasks tackled (lower half of
Table 2), and there is one obvious experiment missing: Variant B of the
authors' model gives much better results on the first task than Variant A, but
for the second task only Variant A is tested -- and indeed it doesn't improve
over the baseline. 
- General Discussion:
The paper needs quite a bit of work before it is ready for publication. 
- Detailed comments:
026 five dimensions, not six
Figure 1, caption: "implies physical relations": how do you know which physical
relations it implies?
Figure 1 and 113-114: what you are trying to do, it looks to me, is essentially
to extract lexical entailments (as defined in formal semantics; see e.g. Dowty
1991) for verbs. Could you please explicit link to that literature?
Dowty, David. "Thematic proto-roles and argument selection." Language (1991):
547-619.
135 around here you should explain the key insight of your approach: why and
how does doing joint inference over these two pieces of information help
overcome reporting bias?
141 "values" ==> "value"?
143 please also consider work on multimodal distributional semantics, here
and/or in the related work section. The
following two papers are particularly related to your goals:
Bruni, Elia, et al. "Distributional semantics in technicolor." Proceedings of
the 50th Annual Meeting of the Association for Computational Linguistics: Long
Papers-Volume 1. Association for Computational Linguistics, 2012.
Silberer, Carina, Vittorio Ferrari, and Mirella Lapata. "Models of Semantic
Representation with Visual Attributes." ACL (1). 2013.
146 please clarify that your contribution is the specific task and approach --
commonsense knowledge extraction from language is long-standing task.
152 it is not clear what "grounded" means at this point
Section 2.1: why these dimensions, and how did you choose them?
177 explain terms "pre-condition" and "post-condition", and how they are
relevant here
197-198 an example of the full distribution for an item (obtained by the model,
or crowd-sourced, or "ideal") would help.
Figure 2. I don't really see the "x is slower than y" part: it seems to me like
this is related to the distinction, in formal semantics, between stage-level
vs. individual-level
predicates: when a person throws a ball, the ball is faster than the person
(stage-level) but
it's not true in general that balls are faster than people (individual-level).
I guess this is related to the
pre-condition vs. post-condition issue. Please spell out the type of
information that you want to extract.
248 "Above definition": determiner missing
Section 3
"Action verbs": Which 50 classes do you pick, and you do you choose them? Are
the verbs that you pick all explicitly tagged as action verbs by Levin? 
306ff What are "action frames"? How do you pick them?
326 How do you know whether the frame is under- or over-generating?
Table 1: are the partitions made by frame, by verb, or how? That is, do you
reuse verbs or frames across partitions? Also, proportions are given for 2
cases (2/3 and 3/3 agreement), whereas counts are only given for one case;
which?
336 "with... PMI": something missing (threshold?)
371 did you do this partitions randomly?
376 "rate the general relationship"
378 "knowledge dimension we choose": ? (how do you choose which dimensions you
will annotate for each frame?)
Section 4
What is a factor graph? Please give enough background on factor graphs for a CL
audience to be able to follow your approach. What are substrates, and what is
the role of factors? How is the factor graph different from a standard graph?
More generally, at the beginning of section 4 you should give a higher level
description of how your model works and why it is a good idea.
420 "both classes of knowledge": antecedent missing.
421 "object first type"
445 so far you have been only talking about object pairs and verbs, and
suddenly selectional preference factors pop in. They seem to be a crucial part
of your model -- introduce earlier? In any case, I didn't understand their
role.
461 "also"?
471 where do you get verb-level similarities from?
Figure 3: I find the figure totally unintelligible. Maybe if the text was
clearer it would be interpretable, but maybe you can think whether you can find
a way to convey your model a bit more intuitively. Also, make sure that it is
readable in black-and-white, as per ACL submission instructions.
598 define term "message" and its role in the factor graph.
621 why do you need a "soft 1" instead of a hard 1?
647ff you need to provide more details about the EMB-MAXENT classifier (how did
you train it, what was the input data, how was it encoded), and also explain
why it is an appropriate baseline.
654 "more skimp seed knowledge": ?
659 here and in 681, problem with table reference (should be Table 2). 
664ff I like the thought but I'm not sure the example is the right one: in what
sense is the entity larger than the revolution? Also, "larger" is not the same
as "stronger".
681 as mentioned above, you should discuss the results for the task of
inferring knowledge on objects, and also include results for model (B)
(incidentally, it would be better if you used the same terminology for the
model in Tables 1 and 2)
778 "latent in verbs": why don't you mention objects here?
781 "both tasks": antecedent missing
The references should be checked for format, e.g. Grice, Sorower et al
for capitalization, the verbnet reference for bibliographic details.