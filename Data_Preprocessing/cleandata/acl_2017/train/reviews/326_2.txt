The paper proposes a method to train models for Chinese word segmentation (CWS)
on datasets having multiple segmentation criteria.
- Strengths:
1. Multi-criteria learning is interesting and promising.
2. The proposed model is also interesting and achieves a large improvement from
baselines.
- Weaknesses:
1. The proposed method is not compared with other CWS models. The baseline
model (Bi-LSTM) is proposed in [1] and [2]. However, these model is proposed
not for CWS but for POS tagging and NE tagging. The description "In this paper,
we employ the state-of-the-art architecture ..." (in Section 2) is misleading.
2. The purpose of experiments in Section 6.4 is unclear. In Sec. 6.4, the
purpose is that investigating "datasets in traditional Chinese and simplified
Chinese could help each other." However, in the experimental setting, the model
is separately trained on simplified Chinese and traditional Chinese, and the
shared parameters are fixed after training on simplified Chinese. What is
expected to fixed shared parameters?
- General Discussion:
The paper should be more interesting if there are more detailed discussion
about the datasets that adversarial multi-criteria learning does not boost the
performance.
[1] Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional lstm-crf models for
sequence tagging. arXiv preprint arXiv:1508.01991.
[2] Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via
bi-directional lstm-cnns-crf. arXiv preprint arXiv:1603.01354 .