- Strengths:
The approach proposed in the paper seems reasonable, and the experimental
results make the approach seem promising. There are two features of the 
approach. One feature is that the approach is for general-purpose programming
languages. It might be applicable to Java, C++, etc. However, proof 
is still needed. Another feature is its data-driven syntactic neural model,
which is described in Section 3 (together with Section 4 I think). 
By the neural model, it brings around 10% improvement over another same-purpose
approach LPN in accuracy (according to the experimental data). 
Overall, this is nice work with clear motivation, methodology, data analysis,
and well-organized presentation.
- Weaknesses:
1. At Line 110, the authors mentioned hypothesis space. I did not know what it
means until I read the supplementary materials. Because such materials 
will not be included in the full paper, in my opinion it is better to give some
explanation on hypothesis space. 
2. Section 3 introduces the grammar model and Section 4 describes Action
probability estimation. My understanding is that the latter is a part of the
former. The two section titles do not reflect this relation. At least Section 3
does not explain all about the grammar model. 
3. About the experimental data, I'm wondering how the authors train their model
before doing the experiments. How many datasets are used. Is it true that 
more the model get trained, more accuracy can be obtained?  How about the
efficiency of the two approaches, the one in the paper and LPN?   
4. Are there differences between the neural network-based approaches that are
used for code generation of general-purpose language and those of domain
specific ones? 
5. The authors claim that their approach scale up to generation of complex
programs. I did not find any argument in the paper to backup this conclusion. 
Minor comments:
Line 117: The underlying syntax => the syntax of which language? (NL or PL?)
Line 148: Are there any constraints on x? 
Line 327: The decoder uses a RNN => The decoder uses an RNN?
Reference:  format is inconsistent
- General Discussion:
This paper proposes a data-driven syntax-based neural network model for code
generation in general-purpose programming langauge, i.e., Python. 
The main idea of the approach is first to generate a best-possible AST using a
probabilistic grammar model for a given statement in natural language, and
then ecode AST into surce code using deterministic generation tools. Generating
code from an AST is relatively easy. The key point is the first step. 
Experimental results provided in the paper show the proposed approach
outperform some other state-of-the-art approaches.