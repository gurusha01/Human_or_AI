- Strengths:
i. Motivation is well described.
ii. Provides detailed comparisons with various models across diverse languages
- Weaknesses:
i.          The conclusion is biased by the selected languages. 
ii.           The experiments do not cover the claim of this paper completely.
- General Discussion:
This paper issues a simple but fundamental question about word representation:
what subunit of a word is suitable to represent morphologies and how to compose
the units. To answer this question, this paper applied word representations
with various subunits (characters, character-trigram, and morphs) and
composition functions (LSTM, CNN, and a simple addition) to the language
modeling task to find the best combination. In addition, this paper evaluated
the task for more than 10 languages. This is because languages are
typologically diverse and the results can be different according to the word
representation and composition function. From their experimental results, this
paper concluded that character-level representations are more effective, but
they are still imperfective in comparing them with a model with explicit
knowledge of morphology. Another conclusion is that character-trigrams show
reliable perplexity in the majority of the languages. 
However, this paper leaves some issues behind.
-         First of all, there could be some selection bias of the experimental
languages. This paper chose ten languages in four categories (up to three
languages per a category). But, one basic question with the languages is "how
can it be claimed that the languages are representatives of each category?"
All the languages in the same category have the same tendency of word
representation and composition function? How can it be proved? For instance,
even in this paper, two languages belonging to the same typology
(agglutinative) show different results. Therefore, at least to me, it seems to
be better to focus on the languages tested in this paper instead of drawing a
general conclusions about all languages. 
-         There is some gap between the claim and the experiments. Is the
language modeling the best task to prove the claim of this paper? Isn't there
any chance that the claim of this paper breaks in other tasks? Further
explanation on this issue is needed.
-         In Section 5.2, this paper evaluated the proposed method only for
Arabic. Is there any reason why the experiment is performed only for Arabic?
There are plenty of languages with automatic morphological analyzers such as
Japanese and Turkish.
-         This paper considers only character-trigram among various n-grams. Is
there any good reason to choose only character-trigram? Is it always better
than character-bigram or character-fourgram? In general, language modeling with
n-grams is affected by corpus size and some other factors. 
Minor typos: 
- There is a missing reference in Introduction. (88 line in Page 1)
- root-and-patter -> root-and-pattern (524 line in Page 6)