- Strengths:
This paper has high originality, proposing a fundamentally different way of
predicting words from a vocabulary that is more efficient than a softmax layer
and has comparable performance on NMT. If successful, the approach could be
impactful because it speeds up prediction.
This paper is nice to read with great diagrams. it's very clearly presented --
I like cross-referencing the models with the diagrams in Table 2. Including
loss curves is appreciated.
- Weaknesses:
Though it may not be possible in the time remaining, it would be good to see a
comparison (i.e. BLEU scores) with previous related work like hierarchical
softmax and differentiated softmax.
The paper is lacking a linguistic perspective on the proposed method. Compared
to a softmax layer and hierarchical/differentiated softmax, is binary code
prediction a natural way to predict words? Is it more or less similar to how a
human might retrieve words from memory? Is there a theoretical reason to
believe that binary code based approaches should be more or less suited to the
task than softmax layers?
Though the paper promises faster training speeds in the introduction, Table 3
shows only modest (less than x2) speedups for training. Presumably this is
because much of the training iteration time is consumed by other parts of the
network. It would be useful to see the time needed for the output layer
computation only.
- General Discussion:
It would be nice if the survey of prior work in 2.2 explicitly related those
methods to the desiderata in the introduction (i.e. specify which they
satisfy).
Some kind of analysis of the qualitative strengths and weaknesses of the binary
code prediction would be welcome -- what kind of mistakes does the system make,
and how does this compare to standard softmax and/or hierarchical and
differentiated softmax?
LOW LEVEL COMMENTS
Equation 5: what's the difference between id(w) = id(w') and w = w' ?
335: consider defining GPGPU
Table 3: Highlight the best BLEU scores in bold
Equation 15: remind the reader that q is defined in equation 6 and b is a
function of w. I was confused by this at first because w and h appear on the
LHS but don't appear on the right, and I didn't know what b and q were.