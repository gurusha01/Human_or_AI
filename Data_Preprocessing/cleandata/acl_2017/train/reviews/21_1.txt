The paper is clearly written, and the claims are well-supported.  The Related
Work in particular is very thorough, and clearly establishes where the proposed
work fits in the field.
I had two main questions about the method: (1) phrases are mentioned in section
3.1, but only word representations are discussed.  How are phrase
representations derived?
(2) There is no explicit connection between M^+ and M^- in the model, but they
are indirectly connected through the tanh scoring function.  How do the learned
matrices compare to one another (e.g., is M^- like -1*M^+?)?  Furthermore, what
would be the benefits/drawbacks of linking the two together directly, by
enforcing some measure of dissimilarity?
Additionally, statistical significance of the observed improvements would be
valuable.
Typographical comments:
- Line 220: "word/phase pair" should be "word/phrase pair"
- Line 245: I propose an alternate wording: instead of "entities are translated
to," say "entities are mapped to".  At first, I read that as a translation
operation in the vector space, which I think isn't exactly what's being
described.
- Line 587: "slightly improvement in F-measure" should be "slight improvement
in F-measure"
- Line 636: extraneous commas in citation
- Line 646: "The most case" should be "The most likely case" (I'm guessing)
- Line 727: extraneous period and comma in citation