This paper details a method of achieving translation from morphologically
impoverished languages (e.g. Chinese) to morphologically rich ones (e.g.
Spanish) in a two-step process. First, a system translates into a simplified
version of the target language. Second, a system chooses morphological features
for each generated target word, and inflects the words based on those features.
While I wish the authors would apply the work to more than one language pair, I
believe the issue addressed by this work is one of the most important and
under-addressed problems with current MT systems. The approach taken by the
authors is very different than many modern approaches based on BPE and
character-level models, and instead harkens back to approaches such as
"Factored Translation Models" (Koehn and Hoang, 2007) and "Translating into
Morphologically Rich Languages with Synthetic Phrases" (Chahuneau et a. 2013),
both of which are unfortunately uncited.
I am also rather suspicious of the fact that the authors present only METEOR
results and no BLEU or qualitative improvements. If BLEU scores do not rise,
perhaps the authors could argue why they believe their approach is still a net
plus, and back the claim up with METEOR and example sentences.
Furthermore, the authors repeatedly talk about gender and number as the two
linguistic features they seek to correctly handle, but seem to completely
overlook person. Perhaps this is because first and second person pronouns and
verbs rarely occur in news, but certainly this point at least merits brief
discussion. I would also like to see some discussion of why rescoring hurts
with gender. If the accuracy is very good, shouldn the reranker learn to just
keep the 1-best?
Finally, while the content of this paper is good overall, it has a huge amount
of spelling, grammar, word choice, and style errors that render it unfit for
publication in its current form. Below is dump of some errors that I found.
Overall, I would like to this work in a future conference, hopefully with more
than one language pair, more evaluation metrics, and after further
proofreading.
General error dump:
Line 062: Zhand --> Zhang
Line 122: CFR --> CRF
Whole related work section: consistent use of \cite when \newcite is
appropriate
It feels like there's a lot of filler: "it is important to mention that", "it
is worth mentioning that", etc
Line 182, 184: "The popular phrase-based MT system" = moses? or PBMT systems in
general?
Line 191: "a software"
Line 196: "academic and commercial level" -- this should definitely be
pluralized, but are these even levels?
Line 210: "a morphology-based simplified target" makes it sound like this
simplified target uses morphology. Perhaps the authors mean "a morphologically
simplified target"?
Line 217: "decide on the morphological simplifications"?
Table 1: extra space in "cuestión" on the first line and "titulado" in the
last line.
Table 1: Perhaps highlight differences between lines in this table somehow?
How is the simplification carried out? Is this simplifier hand written by the
authors, or does it use an existing tool?
Line 290: i.e. --> e.g.
Line 294: "train on" or "train for"
Line 320: "our architecture is inspired by" or "Collobert's proposal inspires
our architecture"
Line 324: drop this comma
Line 338: This equation makes it look like all words share the same word vector
W
Line 422: This could also be "casas blancas", right? How does the system choose
between the sg. and pl. forms? Remind the reader of the source side
conditioning here.
Line 445: This graph is just a lattice, or perhaps more specifically a "sausage
lattice"
Line 499: Insert "e.g." or similiar: (e.g. producirse)
Line 500: misspelled "syllable"
Line 500/503: I'd like some examples or further clarity on what palabras llanas
and palabras estrújulas are and how you handle all three of these special
cases.
Line 570: "and sentences longer than 50 words"
Line 571: "by means of zh-seg" (no determiner) or "by means of the zh-seg tool"
Line 574: are you sure this is an "and" and not an "or"?
Line 596: "trained for" instead of "trained on"
Line 597: corpus --> copora
Line 604: size is --> sizes are
Line 613: would bigger embedding sizes help? 1h and 12h are hardly unreasonable
training times.
Line 615: "seven and five being the best values"
Line 617: Why 70? Increased from what to 70?
Table 3: These are hyperparameters and not just ordinary parameters of the
model
Line 650: "coverage exceeds 99%"?
Line 653: "descending"
Line 666: "quadratic"
Line 668: space before \cites
Line 676: "by far" or "by a large margin" instead of "by large"
Line 716: below
Line 729: "The standard phrase-based ..."
zh-seg citation lists the year as 2016, but the tool actually was released in
2009