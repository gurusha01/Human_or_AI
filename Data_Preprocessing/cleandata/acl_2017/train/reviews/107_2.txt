This paper describes a model for cross-lingual named entity recognition (NER).
The authors employ conditional random fields, maximum entropy Markov, and
neural network-based NER methods. In addition, authors propose two methods to
combine the output of those methods (probability-based and ranking-based), and
a method to select the best training instances from cross-lingual comparable
corpora. The cross-lingual projection is done using a variant of Mikolov's
proposal. In general, the paper is easy to follow, well-structured, and the
English quality is also correct. The results of the combined annotations are
interesting.
Detailed comments:
I was wondering which is the motivation behind proposing a Continuous
Bag-of-word (CBOW) model variation. You don't give much details about this
(or the parameters employed). Was the original model (or the Continuous
Skip-gram model) offering low results? I suggest to include also the results
with the CBOW model, so readers can analyse the improvements of your approach.
Since you use a decay factor for the surrounding embeddings, I suggest to take
a look to the exponential decay used in [1].
Similarly to the previous comment, I would like to look at the differences
between the original Mikolov's cross-lingual projections and your frequency
weighted projections. These contributions are more valuable if readers can see
that your method is really superior.
"the proposed data selection scheme is very effective in selecting
good-quality projection-labeled data and the improvement is significant" ‚Üê
Have you conducted a test of statistical significance? I would like to know if
the differences between result in this work are significant. 
I suggest to integrate the text of Section 4.4 at the beginning of Section 4.2.
It would look cleaner. I also recommend to move the evaluation of Table 2 to
the evaluation section.
I miss a related work section. Your introduction includes part of that
information. I suggest to divide the introduction in two sections.
The evaluation is quite short (1.5 pages with conclusion section there). You
obtain state-of-the-art results, and I would appreciate more discussion and
analysis of the results.
Suggested references:
[1] Iacobacci, I., Pilehvar, M. T., & Navigli, R. (2016). Embeddings for word
sense disambiguation: An evaluation study. In Proceedings of the 54th Annual
Meeting of the Association for Computational Linguistics (Vol. 1, pp. 897-907).