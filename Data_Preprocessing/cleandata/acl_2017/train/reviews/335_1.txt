This work describes a gated attention-based recurrent neural network method for
reading comprehension and question answering. This method employs a
self-matching attention technique to counterbalance the limited context
knowledge of gated attention-based recurrent neural networks when processing
passages. Finally, authors use pointer networks  with signals from the question
attention-based vector to predict the beginning and ending of the answer.
Experimental results with the SQuAD dataset offer state-of-the-art performance
compared with several recent approaches. 
The paper is well-written, structured and explained. As far as I know, the
mathematics look also good. In my opinion, this is a very interesting work
which may be useful for the question answering community.
I was wondering if the authors have plans to release the code of this approach.
From that perspective, I miss a bit of information about the technology used
for the implementation (theano, CUDA, CuDNN...), which may be useful for
readers.
I would appreciate if authors could perform a test of statistical significance
of the results. That would highlight even more the quality of your results.
Finally, I know that the space may be a constraint, but an evaluation including
some additional dataset would validate more your work.