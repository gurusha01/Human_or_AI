Comments after author response
- Thank you for clarifying that the unclear "two-step framework" reference was
not about the two facets. I still do not find this use of a pipeline to be a
particularly interesting contribution.
- You state that "5. de Marneffe (2012) used additional annotated features in
their system. For fair comparison, we re-implement their system with annotated
information in FactBank." But the de Marneffe et al. feature cited in the
paper, "Predicate Classes" requires only a dependency parser and vocabulary
lists from Roser Saurí's PhD thesis; "general classes of event" might be
referring to FactML event classes, and while I admit it is not particularly
clear in their work, I am sure they could clarify.
- I continue to find the use of "combined properly" to be obscure. I agree that
using LSTM and CNN where respectively appropriate is valuable, but you seem to
imply that some prior work has been improper, and that it is their combination
which must be proper.
- Thank you for reporting on separate LSTMs for each of the paths. I am curious
as to why this combination may less effective. In any case, experiments with
this kind of alternative structure deserve to be reported.
---
This paper introduces deep neural net technologies to the task of factuality
classification as defined by FactBank, with performance exceeding alternative
neural net models and baselines reimplemented from the literature.
- Strengths:
This paper is very clear in its presentation of a sophisticated model for
factuality classification and of its evaluation.  It shows that the use of
attentional features and BiLSTM clearly provide benefit over alternative
pooling strategies, and that the model also exceeds the performance of a more
traditional feature-based log-linear model.  Given the small amount of training
data in FactBank, this kind of highly-engineered model seems appropriate. It is
interesting to see that the BiLSTM/CNN model is able to provide benefit despite
little training data.
- Weaknesses:
My main concerns with this work regard its (a) apparent departure from the
evaluation procedure in the prior literature; (b) failure to present prior work
as a strong baseline; and (c) novelty.
While I feel that the work is original in engineering deep neural nets for the
factuality classification task, and that such work is valuable, its approach is
not particularly novel, and "the proposal of a two-step supervised framework"
(line 087) is not particularly interesting given that FactBank was always
described in terms of two facets (assuming I am correct to interpret "two-step"
as referring to these facets, which I may not be).
The work cites Saurí and Pustejovsky (2012), but presents their much earlier
(2008) and weaker system as a baseline; nor does it consider Qian et al.'s
(IALP 2015) work which compares to the former.              Both these works are
developed
on the TimeBank portion of FactBank and evaluated on a held-out ACQUAINT
TimeBank section, while the present work does not report results on a held-out
set.
de Marneffe et al.'s (2012) system is also chosen as a baseline, but not all
their features are implemented, nor is the present system evaluated on their
PragBank corpus (or other alternative representations of factuality proposed in
Prabhakaran et al. (*SEM 2015) and Lee et al. (EMNLP 2015)).  The evaluation is
therefore somewhat lacking in comparability to prior work.
There were also important questions left unanswered in evaluation, such as the
effect of using gold standard events or SIPs.
Given the famed success of BiLSTMs with little feature engineering, it is
somewhat disappointing that this work does not attempt to consider a more
minimal system employing deep neural nets on this task with, for instance, only
the dependency path from a candidate event to its SIP plus a bag of modifiers
to that path. The inclusion of heterogeneous information in one BiLSTM was an
interesting feature, which deserved more experimentation: what if the order of
inputs were permuted? what if delimiters were used in concatenating the
dependency paths in RS instead of the strange second "nsubj" in the RS chain of
line 456? What if each of SIPpath, RSpath, Cue_path were input to a separate
LSTM and combined? The attentional features were evaluated together for the CNN
and BiLSTM components, but it might be worth reporting whether it was
beneficial for each of these components. Could you benefit from providing path
information for the aux words? Could you benefit from character-level
embeddings to account for morphology's impact on factuality via tense/aspect?
Proposed future work is lacking in specificity seeing as there are many
questions raised by this model and a number of related tasks to consider
applying it to.
- General Discussion:
194: Into what classes are you classifying events?
280: Please state which are parameters of the model.
321: What do you mean by "properly"? You use the same term in 092 and it's not
clear which work you consider improper nor why.
353: Is "the chain form" defined anywhere? Citation? The repetition of nsubj in
the example of line 456 seems an unusual feature for the LSTM to learn.
356: It may be worth footnoting here that each cue is classified separately.
359: "distance" -> "surface distance"
514: How many SIPs? Cues? Perhaps add to Table 3.
Table 2. Would be good if augmented by the counts for embedded and author
events. Percentages can be removed if necessary.
532: Why 5-fold? Given the small amount of training data, surely 10-fold would
be more useful and not substantially increase training costs.
594: It's not clear that this benefit comes from PSen, nor that the increase is
significant or substantial.  Does it affect overall results substantially?
674: Is this significance across all metrics?
683: Is the drop of F1 due to precision, recall or both?
686: Not clear what this sentence is trying to say.
Table 4: From the corpus sizes, it seems you should only report 2 significant
figures for most columns (except CT+, Uu and Micro-A).
711: It seems unsurprising that RS_path is insufficient given that the task is
with respect to a SIP and other inputs do not encode that information. It would
be more interesting to see performance of SIP_path alone.
761: This claim is not precise, to my understanding. de Marneffe et al (2012)
evaluates on PragBank, not FactBank.
Minor issues in English usage:
112: "non-application" -> "not applicable"
145: I think you mean "relevant" -> "relative"
154: "can be displayed by a simple source" is unclear
166: Not sure what you mean by "basline". Do you mean "pipeline"?