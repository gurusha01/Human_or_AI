- Strengths:
The idea of hard monotonic attention is new and substantially different from
others.
- Weaknesses:
The experiment results on morphological inflection generation is somewhat
mixed. The proposed model is effective if the amount of training data is small
(such as CELEX). It is also effective if the alignment is mostly monotonic and
less context sensitive (such as Russian, German and Spanish).
- General Discussion:
The authors proposed a novel neural model for morphological inflection
generation which uses "hard attention", character alignments separately
obtained by using a Bayesian method for transliteration. It is substantially
different from the previous state of the art neural model for the task which
uses "soft attention", where character alignment and conversion are solved
jointly in the probabilistic model.
The idea is novel and sound. The paper is clearly written. The experiment is
comprehensive. The only concern is that the proposed method is not necessarily
the state of the art in all conditions. It is suitable for the task with mostly
monotonic alignment and with less context sensitive phenomena. The paper would
be more convincing if it describe the practical merits of the proposed method,
such as the ease of implementation and computational cost.