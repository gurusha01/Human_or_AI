- Strengths:
  * Knowledge lean, language-independent approach
- Weaknesses:
  * Peculiar task/setting
  * Marginal improvement over W_Emb (Fu et al, 2014)
  * Waste of space
  * Language not always that clear
- General Discussion:
It seems to me that this paper is quite similar to (Fu et al, 2014) and only
adds marginal improvements. It contains quite a lot of redundancy (e.g. related
work in  sec 1 and sec 2), uninformative figures (e.g. Figure 1 vs Figure 2),
not so useful descriptions of MLP and RNN, etc. A short paper might have been a
better fit.
The task looks somewhat idiosyncratic to me. It is only useful if you already
have a method that gives you all and only the hypernyms of a given word. This
seems to presuppose (Fu et al., 2013). 
Figure 4: why are the first two stars connected by conjunction and the last two
starts by disjunction?              Why is the output "1" (dark star) if the the
three
inputs are "0" (white stars)?
Sec 4.2, lines 587-589 appears to suggest that thresholds were tuned on the
test data (?) 
W_Emb is poorly explained (lines 650-652).
Some parts of the text are puzzling. I can't make sense of the section titled
"Combined with Manually-Built Hierarchies". Same for sec 4.4. What do the red
and dashed lines mean?