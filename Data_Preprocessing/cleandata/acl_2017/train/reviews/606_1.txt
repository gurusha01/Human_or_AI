This paper introduces a new approach to semantic parsing in which the model is
equipped with a neural sequence to sequence (seq2seq) model (referred to as the
"programmer") which encodes a natural language question and produces a
program. The programmer is also equipped with a 'key variable' memory
component which stores (a) entities in the questions (b) values of intermediate
variables formed during execution of intermediate programs. These variables are
referred to further build the program.                    The model is also equipped
with
certain
discrete operations (such as argmax or 'hop to next edges in a KB'). A separate
component ("interpreter/computer") executes these operations and stores
intermediate values (as explained before). Since the 'programmer' is
inherently a seq2seq model, the "interpreter/computer" also acts as a
syntax/type checker only allowing the decoder to generate valid tokens. For
example, the second argument to the "hop" operation has to be a KB
predicate. Finally the model is trained with weak supervision and directly
optimizes the metric which is used to evaluate the performance (F score).
Because of the discrete operations and the non differentiable reward functions,
the model is trained with policy gradients (REINFORCE). Since gradients
obtained through REINFORCE have high variance, it is common to first pretrain
the model with a max-likelihood objective or find some good sequences of
actions trained through some auxiliary objective. This paper takes a latter
approach in which it finds good sequences via an iterative maximum likelihood
approach. The results and discussion sections are presented in a very nice way
and the model achieves SOTA results on the WebQuestions dataset when compared
to other weakly supervised model.
The paper is written clearly and is very easy to follow.
This paper presents a new and exciting direction and there is scope for a lot
of future research in this direction. I would definitely love to see this
presented in the conference.
Questions for the authors (important ones first)
1. Another alternative way of training the model would be to bootstrap the
parameters (\theta) from the iterative ML method instead of adding pseudo gold
programs in the beam (Line 510 would be deleted). Did you try that and if so
why do you think it didn't work?
2. What was the baseline model in REINFORCE. Did you have a separate network
which predicts the value function. This must be discussed in the paper in
detail.
3. Were there programs which required multiple hop operations? Or were they
limited to single hops. If there were, can you provide an example? (I will
understand if you are bound by word limit of the response)
4. Can you give an example where the filter operation would be used?
5. I did not follow the motivation behind replacing the entities in the
question with special ENT symbol
Minor comments:
Line 161 describe -> describing
Line 318 decoder reads ')' -> decoder generates ')'