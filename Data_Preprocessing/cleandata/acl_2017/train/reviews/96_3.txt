This paper focuses on interpreting sarcasm written in Twitter identifying
sentiment words and then using a machine translation engine to find an
equivalent not sarcastic tweet. 
EDIT: Thank you for your answers, I appreaciate it. I added one line commenting
about it.
- Strengths:
Among the positive aspects of your work, I would like to mention the parallel
corpus you presented. I think it will be very useful for other researchers in
the area for identifying and interpreting sarcasm in social media. An important
contribution is also the attempt to evaluate the parallel corpora using
existing measures such as the ones used in MT tasks. But also because you used
human judgements to evaluate the corpora in 3 aspects: fluency, adequacy and
equivalent sentiment.
- Room for improvement:
Tackling the problem of interpretation as a monolingual machine translations
task is interesting, while I do appreciate the intent to compare the MT with
two architectures, I think that due the relatively small dataset (needed for
RNN) used it was predictable that the "Neural interpretation" is performing
worse than "moses interpretation". You came to the same conclusion after
seeing the results in Table3. In addition to comparing with this architecture,
I would've liked to see other configuration of the MT used with moses. Or at
least, you should provide some explanation of why you use the configuration
described in lines 433 through 442; to me this choice is not justified. 
  - thank you for your response, I understand it is difficult to write down all
the details but I hope you include a line with some of your answer in the
paper, I believe this could add valuable information.
When you presented SING, it is clear that you evaluate some of its components
beforehand, i.e. the MT. But other important components are not evaluated,
particularly, the clustering you used of positive and negative words. While you
did said you used k-means as a clustering algorithm it is not clear to me why
you wanted to create clusters with 10 words. Why not test with other number of
k, instead of 7 and 16, for positive and negative words respectively. Also you
could try another algorithm beside kmeans, for instance, the star clustering
algorithm (Aslam et al. 2004), that do not require a k parameter. 
   - thanks for clarifying.
You say that SIGN searches the tweet for sentiment words if it found one it
changes it for the cluster ID that contain that word. I am assuming that there
is not a limit for the number of sentiment words found, and the MT decides by
itself how many sentiment words to change. For example, for the tweet provided
in Section 9: "Constantly being irritated, anxious and depressed is a great
feeling" the clustering stage of SIGN should do something like "Constantly
being cluster-i, cluster-j and cluster-k is a cluster-h feeling", Is that
correct? If not, please explain what SIGN do.
    - Thanks for clarifying
- Minor comments:
In line 704, section 7, you said: "SIGN-context's interpretations differ
from the original sarcastic tweet in 68.5% of the cases, which come closer to
the 73.8% in the gold standard human interpretations." This means that 25% of
the human interpretations are the same as the original tweet? Do you have any
idea why is that?
In section 6, line 539 you could eliminate the footnote 7 by adding "its
cluster ID" or "its cluster number".
References:
Aslam, Javed A., Pelekhov, Ekaterina, and Rus, Daniela. "The star clustering
algorithm for static and dynamic information organization.." Journal of Graph
Algorithms and Applications 8.1 (2004): 95-129. <http://eudml.org/doc/51529>.