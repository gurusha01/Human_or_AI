This paper presents a method for translating natural language descriptions into
source code via a model constrained by the grammar of the programming language
of the source code.  I liked this paper - it's well written, addresses a hard
and interesting problem by taking advantage of inherent constraints, and shows
significant performance improvements. 
Strengths:
- Addresses an interesting and important problem space. 
- Constraints inherent to the output space are incorporated well into the
model. 
- Good evaluation and comparisons; also showing how the different aspects of
the model impact performance.
- Clearly written paper.
Weaknesses:
- My primary and only major issue with the paper is the evaluation metrics.
While accuracy and BLEU4 are easy to compute, I don't think they give a
sufficiently complete picture.                          Accuracy can easily miss
correctly
generated
code because of trivial (and for program functionality, inconsequential)
changes.  You could get 0% accuracy with 100% functional correctness.  As for
BLEU, I'm not sure how well it evaluates code where you can perform significant
changes (e.g., tree transformations of the AST) without changing functionality.
 I understand why BLEU is being used, but it seems to me to be particularly
problematic given its token level n-gram evaluation.  Perhaps BLEU can be
applied to the ASTs of both reference code and generated code after some level
of normalization of the ASTs?  What I would really like to see is an evaluation
testing for functional equivalence of reference and generated code. 
Understandably this is difficult since test code will have to be written for
each reference.  However, even if this is done for a random (reasonably small)
subsample of the datasets, I think it would give a much more meaningful
picture. 
Minor issues:
- Page 2, para 2: "structural information helps to model information flow
within the network": by "network", do you mean the AST?
- Section 4.2.1, Action Embedding: Are the action embedding vectors in W_R and
W_G simply one-hot vectors or do you actually have a non-trivial embedding for
the actions?  If so, how is it computed?  If not, what is the difference
between the vectors of W_R and e(r) in equation 4?
- Section 5.2, Preprocessing:  If you replace quoted strings in the
descriptions for the DJANGO dataset, how are cases where those strings need to
be copied into the generated code handled?  It is also mentioned (in the
supplementary material) that infrequent words are filtered out.  If so, how do
you handles cases where those words describe the variable name or a literal
that needs to be in the code?
I have read the author response.