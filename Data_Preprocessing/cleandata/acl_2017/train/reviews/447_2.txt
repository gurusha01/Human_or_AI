- Strengths:
The main strength of this paper is the incorporation of discourse structure in
the DNN's attention model, which allows the model to learn the weights given to
different EDUs.
Also the paper is very clear, and provides a good explanation of both RST and
how it is used in the model.
Finally, the evaluation experiments are conducted thoroughly with strong,
state-of-the-art baselines.
- Weaknesses:
The main weakness of the paper is that the results do not strongly support the
main claim that discourse structure can help text classification. Even the
UNLABELED variant, which performs best and does outperform the state of the
art, only provides minimal gains (and hurts in the legal/bills domain). The
approach (particularly the FULL variant) seems to be too data greedy but no
real solution is provided to address this beyond the simpler UNLABELED and ROOT
variants.
- General Discussion:
In general, this paper feels like a good first shot at incorporating discourse
structure into DNN-based classification, but does not fully convince that
RST-style structure will significantly boost performance on most tasks (given
that it is also very costly to build a RST parser for a new domain, as would be
needed in the legal/bill domains described in this paper). I wish the authors
had explored or at least mentioned next steps in making this approach work, in
particular in the face of data sparsity. For example, how about defining
(task-independent) discourse embeddings? Would it be possible to use a DNN for
discourse parsing that could be incorporated in the main task DNN and optimized
jointly  end-to-end? Again, this is good work, I just wish the authors had
pushed it a little further given the mixed results.