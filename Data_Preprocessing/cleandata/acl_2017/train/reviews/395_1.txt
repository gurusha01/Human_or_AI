This paper outlines a method to learn sense embeddings from unannotated corpora
using a modular sense selection and representation process. The learning is
achieved by a message passing scheme between the two modules that is cast as a
reinforcement learning problem by the authors.
- Strengths:
The paper is generally well written, presents most of its ideas clearly and
makes apt comparisons to related work where required. The experiments are well
structured and the results are overall good, though not outstanding. However,
there are several problems with the paper that prevent me from endorsing it
completely.
- Weaknesses:
My main concern with the paper is the magnification of its central claims,
beyond their actual worth.
1) The authors use the term "deep" in their title and then several times in the
paper. But they use a skip-gram architecture (which is not deep). This is
misrepresentation.
2) Also reinforcement learning is one of the central claims of this paper.
However, to the best of my understanding, the motivation and implementation
lacks clarity. Section 3.2 tries to cast the task as a reinforcement learning
problem but goes on to say that there are 2 major drawbacks, due to which a
Q-learning algorithm is used. This algorithm does not relate to the originally
claimed policy.
Furthermore, it remains unclear how novel their modular approach is. Their work
seems to be very similar to EM learning approaches, where an optimal sense is
selected in the E step and an objective is optimized in the M step to yield
better sense representations. The authors do not properly distinguish their
approach, nor motivative why RL should be preferred over EM in the first place.
3) The authors make use of the term pure-sense representations multiple times,
and claim this as a central contribution of their paper. I am not sure what
this means, or why it is beneficial.
4) They claim linear-time sense selection in their model. Again, it is not
clear to me how this is the case. A highlighting of this fact in the relevant
part of the paper would be helpful. 
5) Finally, the authors claim state-of-the-art results. However, this is only
on a single MaxSimC metric. Other work has achieved overall better results
using the AvgSimC metric. So, while state-of-the-art isn't everything about a
paper, the claim that this paper achieves it - in the abstract and intro - is
at least a little misleading.