This paper describes a system to assist written test scoring.
- Strengths:
The paper represents an application of an interesting NLP problem --
recognizing textual entailment -- to an important task -- written test scoring.
- Weaknesses:
There isn't anything novel in the paper. It consist of an application of an
existing technology to a known problem.
The approach described in the paper is not autonomous -- it still needs a human
to do the actual scoring. The paper lacks any quantitative or qualitative
evaluation of how useful such system is. That is, is it making the job of the
scorer easier? Is the scorer more effective as compared to not having automatic
score?
The system contains multiple components and it is unclear how the quality of
each one of them contributes to the overall experience.
The paper needs more work with the writing. Language and style is rough in
several places.
The paper also contains several detailed examples, which don't necessarily add
a lot of value to the discussion.
 For the evaluation of classification, what is the baseline of predicting the
most frequent class?
- General Discussion:
I find this paper not very inspiring. I don't see the message in the paper
apart from announcing having build such a system