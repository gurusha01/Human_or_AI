- Strengths: A nice, solid piece of work that builds on previous studies in a
productive way. Well-written and clear. 
- Weaknesses:
 Very few--possibly avoid some relatively "empty" statements:
191 : For example, if our task is to identify words used similarly across
contexts, our scoring function can be specified to give high scores to terms
whose usage is similar across the contexts.
537 : It is educational to study how annotations drawn from the same data are
similar or different.
- General Discussion:
In the first sections I was not sure that much was being done that was new or
interesting, as the methods seemed very reminiscent of previous methods used
over the past 25 years to measure similarity, albeit with a few new statistical
twists, but conceptually in the same vein. Section 5, however, describes an
interesting and valuable piece of work that will be useful for future studies
on the topic. In retrospect, the background provided in sections 2-4 is useful,
if not necessary, to support the experiments in section 5. 
In short, the work and results described will be useful to others working in
this area, and the paper is worthy of presentation at ACL.
Minor comments:
Word, punctuation missing?
264 : For word annotations, we used PPMI, SVD, and SGNS (skipgram with negative
sampling from Mikolov et al. (2013b)) word vectors released by Hamilton et al.
(2016).
Unclear what "multiple methods" refers to :
278 : some words were detected by multiple methods with CCLA