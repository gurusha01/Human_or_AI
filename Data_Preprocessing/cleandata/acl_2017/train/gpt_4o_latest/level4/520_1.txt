This paper introduces a method for constructing datasets of images from basic building blocks, along with corresponding logical forms and language descriptions. 
The primary objective appears to be the development of a framework where the complexity of images and their associated descriptions can be systematically controlled and parameterized.
- The most significant limitation of the proposed approach is the restricted maximum complexity it can achieve, which falls far short of the complexity typically encountered in tasks like image-captioning and other multimodal challenges.  
- Additionally, the simplicity of the proposed method contrasts sharply with the referenced bAbI tasks, which span the full qualitative spectrum of reasoning difficulties, from easy to hard. In contrast, the proposed method only allows for a quantitatively harder image recognition task (e.g., by increasing the number of objects or adding noise in artificial ways) without introducing qualitatively harder reasoning challenges.  
- This limitation is also evident in the experimental section. When performance results are suboptimal, the issues seem to stem from basic overfitting or underfitting, which could likely be addressed by adjusting the network capacity or using more data. It is difficult to identify any deeper qualitative insights from the experiments.  
- The introduction claims that the "goal is not to achieve optimal performance" but rather to determine whether "architectures are able to successfully demonstrate the desired understanding." However, there is a fundamental contradiction here: the proposed task is intended to evaluate whether architectures exhibit "understanding," yet the resulting scores are not meant to be interpreted as meaningful or significant.
General comments:  
The overall approach should be clarified and made more concrete earlier in the paper, preferably in the introduction rather than waiting until Section 3.