Thank you for the author response. It addresses some of my concerns, though much of it consists of promises ("we will...")—which is understandable given space constraints. However, this highlights a key issue: I would prefer to see a revised version of the paper to verify that the identified shortcomings have been addressed. The required changes are significant, and the new experimental results the authors propose to include would not undergo peer review if the paper is accepted in its current form. I remain uncertain whether the necessary revisions can be entrusted to the authors without an additional review cycle. I have upgraded my score to a 3 to reflect this ambivalence (I appreciate the research presented in the paper, but its presentation is highly disorganized).
---
Strengths:
The paper tackles a creative and valuable topic: extracting common knowledge from text while addressing the well-known issue of reporting bias (i.e., people often omit stating the obvious, such as a person being larger than a ball). The proposed approach involves joint inference on information extracted from text, which is an ambitious and worthwhile goal.
---
Weaknesses:
1. Several aspects of the proposed approach require clarification (see detailed comments below). My primary concern is that the paper does not clearly explain how the approach facilitates the interaction between knowledge about objects and knowledge about verbs to overcome reporting bias. The paper delves into technical details too quickly, without adequately outlining the overarching approach or justifying its effectiveness.
2. The experiments and their discussion are incomplete. For instance, the results for one of the two tasks (lower half of Table 2) are not discussed. Additionally, a critical experiment is missing: Variant B of the authors' model performs significantly better than Variant A on the first task, but only Variant A is tested for the second task—and it fails to outperform the baseline.
---
General Discussion:
The paper requires substantial revisions before it is ready for publication.
---
Detailed Comments:
- Line 026: "five dimensions," not six.
- Figure 1, caption: How do you determine which physical relations are implied?
- Figure 1 and Lines 113-114: The approach appears to aim at extracting lexical entailments (as defined in formal semantics; see Dowty 1991). Please explicitly link this to the relevant literature.
  - Dowty, David. "Thematic proto-roles and argument selection." Language (1991): 547-619.
- Line 135: Clarify the key insight of your approach here—how and why does joint inference over these two types of information help overcome reporting bias?
- Line 141: Replace "values" with "value."
- Line 143: Consider incorporating related work on multimodal distributional semantics, such as:
  - Bruni, Elia, et al. "Distributional semantics in technicolor." Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1. Association for Computational Linguistics, 2012.
  - Silberer, Carina, Vittorio Ferrari, and Mirella Lapata. "Models of Semantic Representation with Visual Attributes." ACL (1), 2013.
- Line 146: Clarify that your contribution lies in the specific task and approach, as commonsense knowledge extraction from language is a long-standing task.
- Line 152: Define "grounded" at this point.
- Section 2.1: Explain why these dimensions were chosen and how the selection process was conducted.
- Line 177: Define "pre-condition" and "post-condition" and explain their relevance.
- Lines 197-198: Provide an example of the full distribution for an item (e.g., model-generated, crowd-sourced, or "ideal").
- Figure 2: The "x is slower than y" part is unclear. This seems related to the distinction in formal semantics between stage-level and individual-level predicates. For example, when a person throws a ball, the ball is faster than the person (stage-level), but this is not generally true (individual-level). This also ties into the pre-condition vs. post-condition issue. Please clarify the type of information you aim to extract.
- Line 248: Missing determiner in "Above definition."
- Section 3:
  - "Action verbs": Specify which 50 classes were selected and the criteria for their selection. Are all verbs explicitly tagged as action verbs by Levin?
  - Line 306ff: Define "action frames" and explain how they were chosen.
  - Line 326: How do you determine whether a frame is under- or over-generating?
  - Table 1: Clarify whether partitions are made by frame, verb, or another method. Are verbs or frames reused across partitions? Additionally, proportions are provided for two cases (2/3 and 3/3 agreement), but counts are only given for one case—please clarify.
  - Line 336: Missing information ("with... PMI").
  - Line 371: Were the partitions created randomly?
  - Line 376: "rate the general relationship."
  - Line 378: How do you decide which knowledge dimensions to annotate for each frame?
- Section 4:
  - Provide sufficient background on factor graphs for a computational linguistics audience. Define "factor graph," "substrates," and "factors," and explain their roles. How does a factor graph differ from a standard graph? Include a high-level description of your model and its rationale at the start of this section.
  - Line 420: Missing antecedent for "both classes of knowledge."
  - Line 421: Clarify "object first type."
  - Line 445: Selectional preference factors are introduced abruptly despite their apparent importance. Consider introducing them earlier. Their role is unclear—please elaborate.
  - Line 461: Clarify "also."
  - Line 471: Explain the source of verb-level similarities.
  - Figure 3: The figure is difficult to interpret. Consider improving its clarity and ensuring it is readable in black-and-white, per ACL submission guidelines.
  - Line 598: Define "message" and its role in the factor graph.
  - Line 621: Justify the need for a "soft 1" instead of a hard 1.
  - Lines 647ff: Provide more details about the EMB-MAXENT classifier, including training data, input encoding, and why it is an appropriate baseline.
  - Line 654: Clarify "more skimp seed knowledge."
  - Lines 659 and 681: Correct table references (should be Table 2).
  - Line 664ff: The example provided is unclear. In what sense is the entity larger than the revolution? Additionally, "larger" is not synonymous with "stronger."
  - Line 681: Discuss results for the object knowledge inference task and include results for model (B). Consistent terminology for models across Tables 1 and 2 would be helpful.
  - Line 778: Why are objects not mentioned when discussing latent knowledge in verbs?
  - Line 781: Missing antecedent for "both tasks."
- References: Check formatting (e.g., capitalization in Grice, Sorower et al) and ensure bibliographic details are complete (e.g., VerbNet reference).