This paper addresses the challenge of interpreting sarcasm on Twitter by identifying sentiment words and employing a machine translation engine to generate an equivalent non-sarcastic tweet.
- Strengths:
One of the notable strengths of this work is the parallel corpus that has been presented. This resource has the potential to be highly beneficial for researchers working on sarcasm detection and interpretation in social media. Another significant contribution is the effort to evaluate the parallel corpus using established metrics commonly applied in machine translation tasks. Additionally, the use of human judgments to assess the corpus in terms of fluency, adequacy, and equivalent sentiment adds considerable value to the study.
- Room for Improvement:
Approaching the problem of sarcasm interpretation as a monolingual machine translation task is an interesting perspective. While the intent to compare the MT performance across two architectures is appreciated, the relatively small dataset used (which is critical for RNNs) makes it unsurprising that the "Neural interpretation" performs worse than the "Moses interpretation." This conclusion is also evident from the results presented in Table 3. Beyond this comparison, it would have been beneficial to explore alternative configurations of the MT system with Moses. At the very least, the choice of the configuration described in lines 433–442 should be justified, as it currently lacks explanation.  
   - Thank you for your response. I understand that it can be challenging to include all the details, but I encourage you to incorporate a line summarizing your explanation in the paper, as it could provide valuable context for readers.
When introducing SIGN, it is evident that some of its components, such as the MT system, were evaluated beforehand. However, other critical components, such as the clustering of positive and negative words, were not evaluated. While you mention using k-means as the clustering algorithm, it is unclear why clusters with 10 words were chosen. Why not experiment with other values for k, beyond 7 and 16 for positive and negative words, respectively? Additionally, it would be worthwhile to explore alternative clustering algorithms, such as the star clustering algorithm (Aslam et al., 2004), which does not require a predefined k parameter.  
   - Thank you for clarifying.
You describe SIGN as searching for sentiment words in a tweet and replacing them with the cluster ID corresponding to those words. I assume there is no limit on the number of sentiment words that can be replaced, and the MT system independently determines how many sentiment words to modify. For instance, in the example provided in Section 9, "Constantly being irritated, anxious and depressed is a great feeling," the clustering stage of SIGN would presumably transform this into something like "Constantly being cluster-i, cluster-j and cluster-k is a cluster-h feeling." Is this understanding correct? If not, please clarify the process.  
   - Thank you for clarifying.
- Minor Comments:
In line 704, Section 7, you state: "SIGN-context's interpretations differ from the original sarcastic tweet in 68.5% of the cases, which come closer to the 73.8% in the gold standard human interpretations." Does this imply that 25% of the human interpretations are identical to the original sarcastic tweet? If so, do you have any insights into why this might be the case?
In Section 6, line 539, you could simplify the text by removing footnote 7 and instead adding "its cluster ID" or "its cluster number" directly into the sentence.
- References:
Aslam, Javed A., Pelekhov, Ekaterina, and Rus, Daniela. "The star clustering algorithm for static and dynamic information organization." Journal of Graph Algorithms and Applications 8.1 (2004): 95–129. <http://eudml.org/doc/51529>.