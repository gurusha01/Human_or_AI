- Strengths:  
The paper presents solid results and utilizes a valuable dataset. There is limited research on Creole-like languages, particularly English-based Creoles, making this work a notable contribution.
- Weaknesses:  
The work gives off a general sense of familiarity, as many similar techniques have been applied to other domains and resource-scarce languages. If we were to replace word embeddings with clusters and neural models with older methods from five years ago, the approach would resemble prior work on languages like Urdu or out-of-domain parsing. While I enjoyed the paper, I would have appreciated a stronger emphasis on the authors' unique contributions and a clearer positioning of their work within the broader literature.
- General Discussion:  
This paper describes a series of experiments aimed at (a) demonstrating the effectiveness of a neural parser in a low-resource setting and (b) introducing a new dataset for Creole English (Singlish, from Singapore). Despite the dataset being relatively small (1,200 annotated sentences, supplemented with 80k unlabeled sentences for word embedding induction), the authors achieve commendable results through an interesting approach. However, the use of features from closely related languages is not new to the parsing community (e.g., work on parsing Urdu/Hindi or Arabic dialects using MSA-based parsers).  
Given that Singlish can be seen as an extreme case of out-of-domain English, I am curious why the authors did not explore classical domain-adaptation techniques, such as training on UD_EN combined with 90% of the Singlish data in a 10-fold cross-validation setup. This could have provided an additional baseline (both with and without word embeddings, and potentially with bilingual embeddings if sufficient parallel data were available).  
Overall, the paper is engaging, but I would have liked to see a stronger contextualization of the work within existing research on parsing low-resource languages and extreme domain adaptation. Including a table comparing results for Irish or other very small treebanks would have been helpful. Additionally, the low inter-annotator agreement (IAA) for labeled relations is concerning and warrants further clarification.
---
Note after reading the authors' response:  
Thank you for the detailed clarifications, particularly for revisiting the IAA evaluation. Based on your responses, I have updated my recommendation to a score of 4, and I hope the paper will be accepted.