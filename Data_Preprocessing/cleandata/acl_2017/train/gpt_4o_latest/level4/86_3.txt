Review
Strengths:  
The paper presents a reasonable approach, supported by experimental results that suggest its potential. The proposed method has two notable features. First, it targets general-purpose programming languages, potentially extending to Java, C++, and others, though this claim requires further proof. Second, it employs a data-driven syntactic neural model, as detailed in Section 3 (and partially in Section 4). This neural model achieves approximately a 10% improvement in accuracy over a comparable approach, LPN, based on the experimental data. Overall, the paper is well-motivated, methodologically sound, supported by thorough data analysis, and clearly presented.
Weaknesses:  
1. At Line 110, the term "hypothesis space" is introduced, but its meaning only becomes clear after consulting the supplementary materials. Since these materials will not be part of the full paper, it would be better to include an explanation of "hypothesis space" within the main text.  
2. Section 3 discusses the grammar model, while Section 4 focuses on action probability estimation. My understanding is that the latter is a subset of the former. However, the section titles do not reflect this relationship, and Section 3 does not fully explain the grammar model.  
3. Regarding the experimental data, it is unclear how the model was trained prior to the experiments. For instance, how many datasets were used? Does increased training lead to higher accuracy? Additionally, the paper does not address the efficiency comparison between the proposed approach and LPN.  
4. The paper does not clarify whether there are significant differences between neural network-based approaches for code generation in general-purpose programming languages and those used for domain-specific languages.  
5. The authors claim that their approach scales to the generation of complex programs. However, the paper does not provide any evidence or arguments to substantiate this claim.  
Minor Comments:  
- Line 117: What does "underlying syntax" refer to? Is it the syntax of the natural language (NL) or the programming language (PL)?  
- Line 148: Are there any constraints on \(x\)?  
- Line 327: "The decoder uses a RNN" â†’ "The decoder uses an RNN"?  
- References: The formatting is inconsistent.  
General Discussion:  
This paper introduces a data-driven, syntax-based neural network model for code generation in general-purpose programming languages, specifically Python. The core idea involves generating an optimal AST using a probabilistic grammar model for a given natural language statement, followed by converting the AST into source code using deterministic generation tools. While the second step (AST-to-code) is relatively straightforward, the novelty lies in the first step (natural language-to-AST). Experimental results demonstrate that the proposed approach outperforms several state-of-the-art methods.