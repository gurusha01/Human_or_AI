This paper investigates the appropriate evaluation of systems that generate ghostwritten rap lyrics.  
The authors propose a manual evaluation framework focusing on three key aspects: fluency, coherence, and style matching. Additionally, they introduce automatic metrics that assess uniqueness through maximum training similarity and stylistic similarity via rhyme density.  
The paper contains some intriguing analysis and discussion. In particular, the approach to manually evaluating style matching appears logical and well-founded.  
However, I have several significant concerns.  
First, I am not fully persuaded by the decision to conduct fluency and coherence evaluations solely at the line level. While the authors cite Wu (2014) as justification, I believe that work addresses a different context—hip-hop lyrical challenges and responses—which inherently warrant line-level analysis. In contrast, this study deals with full verses composed of multiple lines, which should ideally exhibit topical and structural coherence. As such, I see no compelling reason to avoid evaluating fluency and coherence at the verse level.  
Second, I question the reliance on automatic metrics, particularly given the stated goal of generating "similar yet unique lyrics." For uniqueness evaluation, the calculations are performed at the verse level. However, many rappers tend to write lyrics centered around a limited set of themes or topics. If a system merely combines lines from different verses, it might produce a fluent and coherent verse with a low similarity score at the verse level, yet this would not necessarily indicate strong generalization capabilities. Regarding stylistic similarity to a specified artist, I find rhyme density insufficient as a sole metric. Since rhyme density is position-independent, it may fail to capture the full stylistic nuances of an artist's work.  
Furthermore, the automatic metrics do not appear to have been validated against corresponding manual ratings for uniqueness or stylistic matching. I also wonder whether semantic content commonly associated with a specific rapper should be evaluated in addition to rhythm, as this could provide a more comprehensive assessment.  
While I appreciate the study's motivation to address the lack of robust evaluation methodologies, I find one particular claim problematic: "our methodology produces a continuous numeric score for the whole verse, enabling better comparison." Prioritizing ease of comparison seems less critical than providing slightly less precise but more reliable and convincing evaluations.  
Minor issue:  
There is an error in the quotation marks on Line 389.