In this paper, the authors propose a method for training a zero-resource Neural Machine Translation (NMT) system by leveraging training data from a pivot language. Unlike traditional approaches, which often rely on two-step decoding inspired by Statistical Machine Translation (SMT), the authors adopt a teacher-student framework. In this framework, the teacher network is trained on pivot-target language pairs, while the student network is trained on source-pivot data, using the teacher network's predictions for the target language.
- Strengths:
The results presented in the paper suggest that the proposed method is promising. Additionally, the authors provide multiple sets of results that support and validate their assumptions.
- Weaknesses:
Despite its potential, there are several critical issues that need to be addressed before the paper can be considered for publication.
1) Missing Crucial Information:
The description of the training and decoding processes in the proposed framework is incomplete. The equations provided do not fully clarify the approach. Including a few concrete examples would help make the method more comprehensible.
Furthermore, the details of the Monte Carlo sampling process are not sufficiently explained. How exactly is this sampling performed?
2) Organization:
The paper suffers from organizational issues. For instance, the results are scattered across multiple subsections when they would be better presented in a unified section. Additionally, the arrangement of tables is confusingâ€”Table 7 is referenced before Table 6, which disrupts the flow and makes the results section harder to follow.
3) Inconclusive Results:
The results section does not provide clear conclusions. As the authors themselves note, the observed outcomes could be attributed to the total size of the corpus used in their experiments (621). This makes it difficult to assess the true efficacy of the proposed method.
4) Excessive Focus on Assumptions:
While the authors' effort to elaborate on their assumptions is appreciated, dedicating an entire section of the paper and additional experimental results to this topic seems excessive and takes up valuable space.
- General Discussion:
Other Comments:
- Line 578: The authors state, "We observe that word-level models tend to have lower valid loss compared with sentence-level methods." Is it valid to compare losses derived from two different loss functions?
- Section 3.2: The notations are unclear. For example, what does script(Y) represent? Additionally, the process for obtaining p(y|x) is never explained.
- Equation 7: This equation requires further explanation or should be removed if it is not essential.
- Line 320: The approach used should be described here for clarity.
- Line 392: Did the authors mean "2016" instead of the stated year?
Nitty-Gritty Issues:
- Line 742: "import" should be corrected to "important."
- Line 772: Inline citation style needs to be fixed.
- Line 778: "can significantly outperform" should be rephrased for consistency.
- Line 275: Assumption 2 requires revision. The phrasing, "a target sentence y from x should be close to that from its counterpart z," is unclear and needs rewording.