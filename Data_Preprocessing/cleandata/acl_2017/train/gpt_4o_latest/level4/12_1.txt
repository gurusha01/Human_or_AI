This paper presents a rule-based method for extracting time expressions. The core idea is that time expressions are generally short and include at least one time-related token. The approach begins by identifying time tokens using a combination of dictionary lookups, regular expressions, and part-of-speech (POS) tagging. It then expands the identified time segment in both directions from the time token based on a set of heuristic rules. Finally, the method consolidates the expanded segments into a single time expression using another set of rules. The evaluation of this approach against both rule-based and machine learning (ML) systems across three datasets demonstrates notable improvements.
- Strengths:
The paper is well-written and clearly structured. The proposed rules are grounded in empirical observations of the data and appear well-justified, as evidenced by the evaluation results.
- Weaknesses:
Some aspects of the methodology are underspecified, making it challenging to reproduce the results. Specific details are outlined below.
- General Discussion:
* Section 4.1: Why are there five seasons? How are cases like Ramadan month or Holiday Season handled?  
* Section 5.1: Should "two benchmark datasets" be corrected to "three datasets"?  
* Section 5.2: Including an example of a time expression without a time token would be helpful.  
* Section 5.2: Considering that 93% of time expressions contain a time token and the system achieves 92% recall, how do you plan to improve performance further, given the approach is nearing its performance ceiling?  
* Is there any intention to release the complete set of rules or the software used?