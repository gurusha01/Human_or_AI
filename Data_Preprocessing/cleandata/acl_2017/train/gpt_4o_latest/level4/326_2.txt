The paper introduces a method for training models for Chinese Word Segmentation (CWS) on datasets with multiple segmentation criteria.
- Strengths:
1. The concept of multi-criteria learning is both intriguing and promising.
2. The proposed model demonstrates notable improvements over the baselines and is conceptually interesting.
- Weaknesses:
1. The method is not benchmarked against other CWS models. The baseline model (Bi-LSTM) referenced in [1] and [2] was originally designed for POS tagging and Named Entity (NE) tagging, not for CWS. Consequently, the statement in Section 2, "In this paper, we employ the state-of-the-art architecture ...," is misleading.
2. The objective of the experiments in Section 6.4 is unclear. While the section aims to explore whether "datasets in traditional Chinese and simplified Chinese could help each other," the experimental setup involves training the model separately on simplified and traditional Chinese, with shared parameters fixed after training on simplified Chinese. The rationale behind fixing the shared parameters is not well explained.
- General Discussion:
The paper would be more compelling if it included a more detailed discussion about the datasets and the reasons why adversarial multi-criteria learning does not enhance performance.
[1] Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF models for sequence tagging. arXiv preprint arXiv:1508.01991.  
[2] Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF. arXiv preprint arXiv:1603.01354.