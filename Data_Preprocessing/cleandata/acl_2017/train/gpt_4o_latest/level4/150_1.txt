Review
Strengths:
The paper introduces an innovative adaptation of encoder-decoder neural machine translation (MT), employing a methodology that begins and concludes with characters, while utilizing representations of morphemes and characters in the intermediate stages.
The authors provide open access to both their codebase and the final trained models for fr-en, cs-en, and en-cs language pairs. This transparency facilitates validation of their findings and supports replication and further exploration by other researchers.
The proposed system demonstrates the ability to produce translations of reasonable quality even after the initial training epoch, with observable improvements in subsequent epochs.
The system effectively learns morphological tokenizations and exhibits the capability to handle previously unseen words, including nonce words, by implicitly reverting to morpheme-level representations.
Weaknesses:
The paper does not clearly specify which WMT test and development sets were used for the reported results. This omission complicates efforts by readers to compare the results with prior work (e.g., results available on matrix.statmt.org). The reviewer only discovered this information by consulting the README file in the code supplement, which identifies the test set as newstest2015 and the development set as newstest2013. This critical detail should have been explicitly mentioned in the paper.
The software README instructions are adequate but could be improved. The sections on training and testing would benefit from explicit examples of how to execute the respective commands. Additionally, the software should support a `--help` flag, which is currently absent.
The paper outlines a six-layer architecture, but the diagram in Figure 2 appears to depict fewer than six layers. This discrepancy is unclear. The figure caption should provide more detail, and if the figure does not represent all layers, an additional figure (even in an appendix) should be included to illustrate the complete architecture.
The results compare the proposed system to other character-based neural MT systems but do not include comparisons with state-of-the-art results from other types of MT systems. Results from WMT (and matrix.statmt.org) indicate that the state-of-the-art performance on these datasets is significantly higher than the results reported in this paper. This gap should be acknowledged and, ideally, discussed in the paper.
There are several minor issues with English phrasing, typographical errors, and LaTeX formatting (e.g., incorrect quotation marks). These should be addressed.
General Discussion:
The paper is a valuable contribution to the body of research on character-based neural machine translation.