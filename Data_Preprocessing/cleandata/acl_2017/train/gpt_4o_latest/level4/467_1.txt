- Strengths:  
This paper introduces an iterative approach for inducing bilingual word embeddings from large monolingual corpora, starting with minimal (or automatically derived numeral) mappings between two languages. In comparison to state-of-the-art methods that rely on larger bilingual dictionaries or parallel/comparable corpora, the proposed method achieves remarkable and impressive results while requiring little to no manually curated input.
- Weaknesses:  
The paper would benefit from a discussion of the method's errors and a consideration of potential adjustments to address these shortcomings.
- General Discussion:  
Does the frequency of the seed words in the monolingual corpora influence the results?  
It would be valuable to observe the intermediate stages (e.g., after n iterations) of the mapping evolution between words in the two languages, particularly for a few specific examples.  
How does the method handle different translations of the same word (e.g., words with multiple senses)?  
A notable distinction between German and English is the frequent use of compounds in German. How are these compounds handled by the method? What are they mapped to? Would a preprocessing step, such as splitting compounds (potentially using corpus-internal unigram information), improve the results?  
What is the theoretical upper bound for this approach? An analysis of errors—such as words that are mapped far from their counterparts in the other language—would be highly insightful. Additionally, a discussion on the origins of these errors and whether the proposed method could be adapted to mitigate them would enhance the paper.