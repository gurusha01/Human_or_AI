- Strengths:
The primary strength of this paper lies in its integration of discourse structure into the attention mechanism of the DNN, enabling the model to effectively learn the importance of different EDUs.
Additionally, the paper is well-written, offering a clear and detailed explanation of both RST and its application within the proposed model.  
Lastly, the evaluation experiments are comprehensive and benchmarked against robust, state-of-the-art baselines.
- Weaknesses:
The key limitation of the paper is that the results do not strongly substantiate the central claim that discourse structure enhances text classification. Even though the UNLABELED variant achieves the best performance and surpasses the state of the art, the improvements are marginal and even detrimental in the legal/bills domain. Furthermore, the approach, particularly the FULL variant, appears overly data-intensive, and no substantial solution is proposed to mitigate this issue beyond the simpler UNLABELED and ROOT variants.
- General Discussion:
Overall, this paper represents a promising initial attempt at incorporating discourse structure into DNN-based classification. However, it does not convincingly demonstrate that RST-style structure can significantly improve performance across most tasks, especially given the high cost of developing an RST parser for new domains, as highlighted in the legal/bills domain examples. It would have been valuable if the authors had explored or at least discussed potential next steps to enhance this approach, particularly in addressing data sparsity. For instance, could task-independent discourse embeddings be defined? Alternatively, might it be feasible to employ a DNN for discourse parsing that could be integrated into the main task DNN and optimized jointly in an end-to-end manner? While this is commendable work, it would have been even stronger if the authors had pushed the boundaries further, given the mixed results.