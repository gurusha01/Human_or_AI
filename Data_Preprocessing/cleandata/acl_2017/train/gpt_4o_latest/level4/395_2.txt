This paper presents a novel method for learning multi-sense word representations using reinforcement learning. The approach employs a CBOW-like architecture for sense selection, where a score for each sense is computed as the dot product between the sum of word embeddings in the current context and the corresponding sense vector. A second module, inspired by the skip-gram model, is used to train sense representations based on the outputs of the sense selection module. The training process leverages Q-Learning, with the Q-value derived from the CBOW-based sense selection module and the reward defined as the skip-gram negative sampling likelihood. Additionally, the authors propose a non-parametric method for determining the number of senses per word by introducing new senses when existing Q-values fall below a threshold of 0.5.
The proposed approach demonstrates strong performance under the "MaxSimC" metric and achieves results comparable to prior methods under "AvgSimC." The authors suggest that their method could enhance downstream task performance by replacing word embeddings with their most probable sense embeddings. However, this claim would have been more compelling if it had been empirically validated, for instance, in a sequential labeling task such as POS-tagging or NER, particularly given prior work questioning the utility of multi-sense representations in downstream applications. Furthermore, the suggestion that relying on MaxSimC could reduce overhead in real-world scenarios seems somewhat misleading, as sense disambiguation (with its associated parameters) would still be required alongside the sense embeddings. A clustering-based approach using a weighted average of sense representations would likely entail similar overhead. Additionally, the claim of outperforming word2vec using 1/100 of the data on SCWS is not particularly surprising and does not represent a significant advancement over prior work.
One notable strength of the proposed approach is its modular design, which offers flexibility that could have been explored further. For instance, the sense disambiguation module employs a vector averaging (CBOW) approach, but the modular framework should allow for the substitution of alternative context composition methods, such as those based on other neural architecture composition techniques.
Overall, the paper addresses a well-studied problem with an interesting approach. While the results on standard benchmarks are comparable to prior work and not particularly groundbreaking, the use of reinforcement learning to create a modular framework for multi-sense representation learning goes beyond a simple extension of the skip-gram model. Ideally, the modularity of the framework and its potential for broader applications would have been explored in greater depth. Nevertheless, the approach itself is novel and may be sufficiently interesting to warrant acceptance, as it could provide a foundation for further advancements in this area.
 A number of typos should be corrected (line 190: "representations", line 331: "selects", line 492: "3/4th").
NOTE: Thank you to the authors for their response.