The authors present "morph-fitting," a method designed to retrofit pre-trained word embeddings using a morphological objective that (1) clusters inflectional forms of the same word (e.g., "slow" and "slowing") and (2) separates derivational antonyms (e.g., "expensive" and "inexpensive"). This approach aims to enhance the representation of low-frequency word inflections and address the issue of corpus-based embeddings assigning similar representations to antonyms. The method relies on straightforward, manually-crafted morphological rules and is evaluated across four languages: English, German, Italian, and Russian. The experiments include intrinsic word similarity benchmarks, where morph-fitting improves performance across various embeddings, and extrinsic evaluations, where it achieves state-of-the-art results for German and Italian in dialog state tracking.
Strengths:
- The proposed method is straightforward and demonstrates consistent performance improvements across multiple evaluations and languages. Unlike prior knowledge-based retrofitting methods (e.g., Faruqui et al., 2015), it uses a small set of manually-defined rules rather than requiring a large-scale ontology or knowledge base.
- Similar to other retrofitting techniques, this method can be easily applied to existing embeddings, making the accompanying software potentially valuable to the community.
- The paper provides a clear and well-structured description of the method and experiments.
Weaknesses:
- The paper lacks an in-depth analysis of why morph-fitted embeddings perform better in evaluations and how this aligns with the authors' intuitive motivations.
- The authors introduce Morph-SimLex, a synthetic word similarity dataset created by applying their morphological rules to SimLex999. While this expands the dataset with morphologically variable pairs, the similarity scores are assumed to be preserved from SimLex999 without manual annotation, making them less reliable. Moreover, since the dataset is generated using the same rules employed for morph-fitting, the results on this dataset may be biased. The authors should explicitly acknowledge this limitation in their paper.
- While (Soricut and Och, 2015) is mentioned as a potential source of morphological knowledge, it is also an alternative approach for generating morphologically-aware embeddings. The authors should clarify this distinction and better position their work relative to it.
- The evaluation does not include strong baselines that incorporate morphological information, which would provide a more comprehensive comparison.
General Discussion:
Despite the noted limitations, this work represents a meaningful contribution to the field. The authors propose a simple yet effective approach that demonstrates performance gains across various embeddings, evaluations, and languages. I believe this work would be a valuable addition to the conference.
Minor Comments:
- Line 200: The phrasing "We then query â€¦ of linguistic constraints" is unclear and could be revised for clarity.
- Section 2.1: It would be helpful to elaborate on the differences between the model used in this paper and the one from Wieting (2015). It appears that the primary addition is the REPEL component, but this should be clarified.
- Line 217: Consider explicitly presenting the cost function as an equation for better clarity.
- Line 223: Clarify that x and t in the equations represent the vector representations of words. Additionally, specify whether the vectors are L2-normalized before processing and indicate whether cosine similarity or dot product is used for nearest neighbor computations.
- Lines 297-299: Move this text to Section 3 and include the note about not fine-tuning parameters in the main text rather than in a footnote.
- Line 327: The example "(create, creates)" appears to be incorrect for the rule described. Please revise.
I have reviewed the author response.