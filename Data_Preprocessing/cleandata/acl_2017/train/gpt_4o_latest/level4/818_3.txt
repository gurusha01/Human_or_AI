The paper addresses an intriguing problem of extracting relative physical knowledge about actions and objects from unstructured text by performing inference over a factor graph composed of two types of subgraphs: an action graph and an object graph. The work is based on a key insightâ€”that common knowledge about the physical world influences how people communicate, even though such knowledge is rarely made explicit.
- Strengths:
The paper tackles a compelling and challenging problem. The difficulty arises due to reporting bias, and the key insight and approach presented in the paper are thought-provoking.
The proposed model is novel and well-articulated. The use of semantic similarity factors to address text sparsity is particularly well-suited to the problem.
The empirical results convincingly demonstrate the model's effectiveness compared to other baselines.
The paper is well-written and includes informative visualizations. However, there are minor inconsistencies, such as referencing six dimensions in the abstract while mentioning five elsewhere in the paper.
- Weaknesses:
The advantages and limitations of the model components are insufficiently explored, making it difficult to fully understand their contributions based on the limited quantitative results provided.
For instance, is there any fundamental inconsistency between cross-verb frame similarity, within-verb frame similarity, and action-object compatibility? Consider frames like A throw B and C thrown by D, which share the verb primitive throw. If A>B is known, should the model infer C>D through within-verb similarity? Conversely, frames like C thrown by D and E kicked by F share the frame XXX by. If F>E is known, should the model infer D>C? How does the current model handle such discrepancies?
The paper could benefit from more qualitative analysis and additional evidence to assess the difficulty of the task and dataset.
For example, are the actions or objects that the model misclassifies also ambiguous for humans? What types of actions or objects does the model struggle with most? Is the model more prone to errors with verbs that have a greater variety of frame types?
Moreover, how are the errors made? Are they influenced by the proposed semantic similarity factors in any systematic way?
A deeper analysis of the model components and qualitative results could potentially inspire a more general framework for addressing this task.
- General Discussion:
/ After author response /
After reviewing the author response, I am inclined to maintain my current rating and recommend accepting this paper. The response adequately addresses my concerns, and I believe that with some reorganization and the addition of one extra page, the necessary background and experimental analyses can be incorporated without significant difficulty.
/ Before author response /
Overall, this paper is solid and engaging. I am inclined to recommend acceptance, though addressing the questions raised above would further strengthen the work.