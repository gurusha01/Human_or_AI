- Strengths:
This paper takes a meaningful step toward creating more challenging corpora for training sentence planners in data-to-text NLG, which is both an important and timely research direction.
- Weaknesses:
It is not clear whether the work presented in this paper constitutes a significant improvement over the method for content selection proposed by Perez-Beltrachini et al. (2016). The authors do not directly compare their approach to that prior work. The primary novelty of this paper seems to lie in the additional analysis, which, unfortunately, lacks depth.
While the authors provide a comparison of how an NNLG baseline performs on this corpus versus the Wen et al. (2016) corpus, the BLEU scores reported in Wen et al.'s paper are significantly higher. This raises concerns about whether the NNLG baseline used here is adequate for drawing meaningful comparisons.
- General Discussion:
The authors need to better articulate why this work should be considered a substantial advancement over Perez-Beltrachini et al.'s prior work and why the NNLG baseline results should be taken seriously. Unlike LREC, ACL rarely publishes main session papers on corpus development methodologies unless accompanied by novel system results utilizing the corpus.
The paper would be more compelling if it included an analysis of the syntactic constructions in the two corpora, which would strengthen the argument that the new corpus is more complex. Additionally, the methodology for determining the number of different path shapes should be detailed and linked to specific syntactic constructions.
Finally, the authors should acknowledge the limitation that their method does not incorporate richer discourse relations, such as Contrast, Consequence, or Background, which are central to NLG. In this regard, the corpora described by Walker et al. (JAIR-2007) and Isard (LREC-2016) are more compelling and should be discussed in relation to the proposed method.
References:
- Marilyn Walker, Amanda Stent, François Mairesse, and Rashmi Prasad. 2007. Individual and domain adaptation in sentence planning for dialogue. Journal of Artificial Intelligence Research (JAIR), 30:413–456.
- Amy Isard, 2016. "The Methodius Corpus of Rhetorical Discourse Structures and Generated Texts," Proceedings of the Tenth Conference on Language Resources and Evaluation (LREC 2016), Portorož, Slovenia, May 2016.
---
Addendum Following Author Response:
Thank you for the detailed and informative response. Based on the clarifications provided, I have raised my overall rating. Regarding the comparison to Perez-Beltrachini et al., while this may be more relevant to the program committee than to the eventual readership, it remains unclear to this reviewer why the advance over that work was not made more explicit. Although Perez-Beltrachini et al. focus "only" on content selection, this is a critical aspect of how this dataset differs from Wen et al.'s. The "complete methodology" for constructing the data-to-text dataset seems to involve straightforward crowd-sourcing steps, and if these steps are particularly innovative or essential, they should be emphasized. The rejection of 8.7% of crowd-sourced texts during verification is noteworthy; it would be helpful to include examples of rejected texts and discuss whether this indicates higher-quality outputs compared to Wen et al.'s dataset. Collecting these crowd-sourced texts enables comparisons with Wen et al.'s corpus at both the data and text levels, which this reviewer recognizes as central to the paper's contributions.
Regarding the NNLG baseline, the concern is that the relative performance difference between the two corpora might vanish if Wen et al.'s much higher-performing method were used. The assumption that this relative difference would persist even with more advanced methods should be explicitly stated, perhaps in a footnote. Despite this limitation, the comparison remains a valuable component of the overall evaluation of the datasets.
On the question of whether a dataset creation paper should be accepted without system results, while such cases are not unprecedented, the key consideration is the novelty and significance of the dataset. In this case, this reviewer acknowledges the importance of the dataset relative to existing ones, even if the primary advance lies in the previously published content selection work.
Finally, this reviewer agrees with Reviewer 1 that the final version of the paper, if accepted, should clarify the role of domain dependence and define what is meant by "wide coverage."