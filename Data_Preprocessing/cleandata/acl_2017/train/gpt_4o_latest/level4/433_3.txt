The authors present a novel dataset comprising 1,200 Singlish (Singaporean English) sentences annotated with Universal Dependencies. They demonstrate that leveraging English syntactic knowledge through a neural stacking model enhances the performance of both a POS tagger and a dependency parser on the Singlish corpus.
- Strengths:  
Singlish is a low-resource language, and the NLP community greatly benefits from additional datasets for such languages. The dataset introduced in this paper is a valuable contribution. Furthermore, there is limited NLP research on creoles, and this work provides an important exploration of transfer learning for analyzing creoles, making it a noteworthy addition to the field.  
The authors' experimental setup is well-structured, and they present compelling evidence that integrating English-trained parser knowledge into a Singlish parser yields better results than using either an English-only or Singlish-only parser. Additionally, the paper offers a clear discussion of the syntactic differences between English and Singlish, along with an insightful analysis of how various parsing models address Singlish-specific constructions.
- Weaknesses:  
Three primary concerns arise with this paper:  
1. There is limited comparison to the UD annotations of non-English languages. Many constructions identified as unique to Singlish also appear in other UD languages, and the annotations should ideally align with those languages for consistency.  
2. The paper does not analyze the impact of training data size. Since a central claim is that English data improves performance on a low-resource language like Singlish, it would be valuable to determine how much additional Singlish data would be required to eliminate the need for English data.  
3. The authors do not evaluate a simpler baseline: training a single POS/dep parsing model on a concatenated dataset of UD Web and Singlish data. Demonstrating that neural stacking outperforms this baseline would strengthen the case for its use.  
- General Discussion:  
Line 073: Clarify that the statement "POS taggers and dependency parsers perform poorly on such Singlish texts based on our observations" will be quantified later, as it currently feels vague.  
Line 169: The paper lacks a direct comparison to multilingual neural network parsing approaches, such as mapping Singlish and English word embeddings into a shared embedding space.  
Line 212: When introducing UD Eng, note that the Singlish data is also web-based, ensuring a domain match with UD Eng.  
Line 245: The statement "All borrowed words are annotated according to their original meanings" requires clarification. Does this refer to the POS in the source language or the POS based on their usage in Singlish?  
Figure 2: Including standard English glosses would aid in understanding the constructions and verifying the correctness of the UD relations.  
Line 280: The discussion on topic prominence should compare with the "dislocated" label in UD, which captures preposed and postposed elements. If Singlish syntax differs, the distinction should be explicitly explained.  
Line 294: The analysis of noun phrases modifying predicates with prepositions as "nsubj" (nominal subject) needs clarification. If these phrases modify the predicate, they should use modification relations rather than core argument relations. A gloss would help determine the appropriateness of this analysis.  
Line 308: The discussion of copula handling in Singlish should explicitly reference the UD decision to treat predicative "be" as the only copula for parallelism with non-copular languages. The remaining discussion on copula handling may not be necessary.  
Line 322: The handling of NP deletion (null subjects or objects) should reference similar phenomena in other languages (e.g., zero-anaphora in Spanish, Italian, Russian, Japanese) and how UD annotations address these cases.  
Line 330: Subj/verb inversion in interrogatives and tag questions should be compared to similar constructions in other languages to ensure consistency with UD annotations.  
Section 3.3: Data Selection and Annotation  
The selection of Singlish sentences appears biased toward constructions that English parsers handle poorly. It would be helpful to assess how a standard English parser performs on unfiltered Singlish data and the prevalence of out-of-vocabulary terms or unique constructions discussed in Section 3.2.  
The dataset may not fully capture unusual sentence structures, particularly those involving long-distance dependencies. Did the selection method adequately represent the grammatical differences between Singlish and English described in Section 3.2?  
Line 415: The reported inter-annotator agreement (UAS: 85.30%, LAS: 75.72%) seems low compared to Silveira et al. (2014), who achieved 94% agreement on a per-token basis for UD-Eng. What accounts for this discrepancy? Additionally, what is the agreement on POS tags, and is this integrated with LAS?  
POS Tagging and Dependency Parsing Sections  
For both tasks, an analysis of training set size would be valuable. How much additional Singlish data would be needed to match the accuracy of the stacked model using only Singlish-trained models?  
What are the results of training on a hybrid dataset combining English and Singlish? This simpler baseline should be evaluated to contextualize the gains from neural stacking.  
Line 681: Typo: "pre-rained" should be corrected to "pre-trained."  
Line 742: The neural stacking model performs well across most categories but struggles slightly with "NP Deletion" cases. This may be due to the English data biasing the parser toward explicit subjects/objects. Consider experimenting with deleting subjects/objects from some English sentences to improve performance on this construction.