The paper introduces a method for sequence labeling using multitask learning, where language modeling serves as an auxiliary objective. Specifically, a bidirectional neural network is trained to predict both the output labels and the preceding or following word in a sentence. This joint optimization results in performance gains over baseline models in tasks such as grammatical error detection, chunking, named entity recognition (NER), and part-of-speech (POS) tagging.
- Strengths:
The paper is generally well-written and easy to understand. The proposed model is described in sufficient detail, and the experimental evaluation is thorough within the defined scope. The advantages of incorporating an auxiliary objective are clearly demonstrated.
- Weaknesses:
The paper exhibits a limited engagement with related work, despite the extensive literature available for the tasks under consideration. Tables 1-3 only compare the three proposed systems (Baseline, +dropout, and +LMcost), with minimal textual discussion of other approaches.
For a contribution claiming novelty and improvements over prior state-of-the-art methods, it is essential to document these advancements comprehensively. This should include reporting relevant baseline scores alongside the proposed results and, ideally, replicating prior work for direct comparison. Given that the datasets used are publicly available, and prior results and systems are well-documented and accessible, this omission is a significant shortcoming.
In particular, the sentence "The baseline results are comparable to the previous best results on each of these benchmarks" is problematic. It misleadingly implies that the baseline system encompasses all prior contributions, which is both unclear on first reading and demonstrably inaccurate upon reviewing related work.
The paper also claims "new state-of-the-art results for error detection on both FCE and CoNLL-14 datasets." However, upon examining the CoNLL-2014 shared task report and related work, such as Rei and Yannakoudakis (2016), this claim is not immediately verifiable. The paper should substantiate this assertion by including or replicating results from relevant prior work.
- General Discussion:
The treatment of POS tagging feels secondary and underdeveloped. The comparison to Plank et al. (2016) is at least partially unfair, as their work evaluates across multiple languages using the Universal Dependencies framework, achieving strong performance across diverse language families. This raises important questions about the scalability of the proposed system to multilingual or low-resource settings, which the paper does not address. A discussion on how the approach generalizes to such scenarios would strengthen the contribution.
I appreciate the idea of incorporating language modeling as an auxiliary task and find the architecture and sections 1-4 compelling. However, there is a noticeable disconnect between these sections and the experimental results described in sections 5-8.
I recommend further refinement before publication. This should include a more comprehensive and fair engagement with related work, potentially including replication, as well as a discussion on multilinguality and scalability. Given the availability of data and systems in the field, the paper should reflect the growing maturity of the domain rather than sidestep it. With these improvements, I believe the paper could become a strong contribution. For now, I vote borderline.