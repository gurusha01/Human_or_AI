The paper introduces an approach that combines pre-trained word embeddings and pre-trained neural language model embeddings (via concatenation) to enhance performance in English chunking and named entity recognition (NER) on the respective CoNLL benchmarks, as well as on an out-of-domain English NER test set. The proposed method achieves state-of-the-art results for both tasks.
- Strengths:
The paper is, for the most part, well-written and easy to understand. The proposed method is described in detail, and the discussion provided is both comprehensive and well-rounded.
- Weaknesses:
It is important to note that sequence tagging encompasses more than just chunking and NER. The absence of experiments on part-of-speech (POS) tagging is surprising, and the inclusion of additional sequence tagging tasks, such as grammatical error detection, supersense tagging, or CCG supertagging, would have been beneficial. Consequently, the paper focuses solely on chunking and NER for English, rather than addressing sequence tagging as a broader category, as it lacks both a multilingual component and a wider range of tasks.
Although the detailed explanation of the method is appreciated, figures 1 and 2 appear redundant, and one of them could have been omitted without any loss of clarity.
Additionally, the method itself is relatively straightforward and simple. While simplicity is not inherently a drawback, the contribution feels more suited to a short paper format. The extensive discussion section is enjoyable and adds value, but the core methodological contribution does not come across as particularly innovative or substantial. It aligns more with the "focused contribution" criteria of a short paper rather than the "substantial" expectations of a long paper.
- General Discussion:
In essence, the paper combines two types of embeddings and demonstrates performance improvements in English chunking and NER.
The key question is whether this contribution justifies publication as a long paper at ACL. I remain ambivalent, and my score reflects this uncertainty, though I lean slightly toward a negative recommendation. The primary reason is the lack of breadth in the work: (a) the inclusion of more sequence tagging tasks and (b) the exploration of additional languages would have strengthened the paper.
Furthermore, the scalability of the method to low-resource scenarios remains unclear. What happens when pre-trained embeddings are unavailable or significantly smaller in size? While the experiments touch on this aspect, they do not fully explore the low-resource range. A multi-task learning setup that could learn embeddings within the model itself would have been a more substantial contribution in this regard.
For these reasons, I rate the paper as borderline, with a low score for originality. While the idea of leveraging embeddings for contextual information is appealing, this specific implementation leaves much to be desired.