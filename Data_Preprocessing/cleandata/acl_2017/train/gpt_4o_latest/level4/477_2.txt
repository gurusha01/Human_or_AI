- Summary:  
The authors conduct an extensive comparison of various approaches to sub-word modelling in language modelling and demonstrate that incorporating morphological information yields superior results compared to purely character-based approaches. Additionally, they perform precision experiments that reveal the most significant gains in sub-word modelling occur for morphologically rich word classes, such as nouns and verbs. The paper is thorough, and the experiments convincingly support its primary claims.
- Strengths:  
1) The paper provides a detailed exploration of different methods and architectures for sub-word level modelling, supported by numerous experiments that validate the central claim that morpheme-based modelling achieves the best performance.  
2) The authors propose a novel sub-word modelling technique based on character tri-grams, demonstrating its superiority over traditional methods across a diverse set of languages.  
3) The division of languages by typological features and the analysis of model performance across these typologies is a valuable contribution, bridging linguistic insights with advancements in language modelling.  
4) The analysis of perplexity reduction for specific word classes in Russian and Czech is particularly insightful, highlighting how character-level and morpheme-level models handle rare words more effectively. Based on these findings, it would be interesting to hear the authors' perspective on the balance between semantic understanding and morphosyntactic knowledge in language modelling.  
- Weaknesses:  
1) The choice of character tri-grams for the LSTM model appears somewhat arbitrary. Did the authors experiment with other n-gram sizes, such as bi-grams or 4-grams? While tri-grams may approximate morphemes in some languages (e.g., Semitic languages), the rationale for focusing on tri-grams is unclear. Additionally, with 26Â³ = 17,576 possible tri-grams in the Latin alphabet, this is comparable to a word embedding table. Did the authors consider only observed tri-grams? If so, how many unique tri-grams were observed?  
2) The claim of evaluating character-level models on root-and-pattern morphology is questionable given that the dataset lacks vocalisation, which is essential for capturing the "pattern" aspect of root-and-pattern morphology. While obtaining vocalised Arabic and Hebrew data can be challenging, its absence limits the validity of this analysis.  
3) Reduplication seems to differ fundamentally from the other morphological typologies examined, as it is more of a lexical phenomenon than a strictly morphological one. Furthermore, languages like Indonesian and Malay exhibit additional affixation processes alongside reduplication. Separating reduplication from other typologies may not be fully justified.  
- General Discussion:  
1) The paper is well-structured and highly readable.  
2) The choice of 200-dimensional character embeddings is puzzling. When the embedding dimensionality exceeds the size of the character vocabulary (i.e., the number of characters in the alphabet), it is unclear what additional benefit is gained.  
- Final Remarks:  
After reviewing the authors' response, my overall assessment remains unchanged. The strengths and weaknesses outlined above still hold.