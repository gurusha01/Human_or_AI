This paper presents Neural Symbolic Machines (NSMs), a deep neural architecture augmented with discrete memory to support symbolic execution. The NSM framework consists of three key components: (1) a manager that enables weak supervision for training, (2) a differentiable programmer based on a neural sequence-to-sequence model, which encodes input instructions and generates simplified Lisp programs by leveraging partial execution results stored in external discrete memory, and (3) a symbolic computer that executes the programs and assists the programmer by pruning the search space. The authors evaluate the proposed approach on the WebQuestionsSP semantic parsing task and demonstrate that (1) NSM effectively captures language compositionality by saving and reusing intermediate execution results, (2) Augmented REINFORCE outperforms vanilla REINFORCE for sequence prediction tasks, and (3) NSM, when trained end-to-end with weak supervision, surpasses the current state-of-the-art method (STAGG).
- Strengths
* The integration of discrete symbolic memory into neural execution models is innovative. While the implementation may primarily involve copying previously executed variable tokens from an auxiliary buffer, this method is notable for its effectiveness on a large-scale semantic parsing task.
* The proposed augmented REINFORCE training scheme, which incorporates imperfect hypotheses derived from maximum likelihood training, is both intriguing and effective. This approach has the potential to inspire further research into combining ML and RL training for neural sequence-to-sequence models.
* The experimental scale exceeds that of prior studies on neural execution and program induction, and the results are compelling.
* The paper is generally well-written and clear, though certain aspects could benefit from additional clarification (e.g., the role of keys ($v_i$ in Fig. 2) of variable tokens in computing action probabilities, and inconsistent notations where $v$ refers to variables in Tab. 1 but memory keys in Fig. 1).
Overall, I find this paper to be a strong contribution and would recommend its acceptance at the conference.
- Weaknesses
* [Dataset Choice] The authors evaluate their approach using WebQuestionsSP. However, it would be more intuitive and straightforward to use the widely adopted WebQuestions dataset (Berant et al., 2013), as NSM only requires weak supervision. This would also enable direct comparisons with mainstream QA research.
* [Compositionality Analysis] One of the key contributions of this work is leveraging symbolic intermediate execution results to model language compositionality. A deeper analysis of how the model handles questions with varying levels of compositional depth would be valuable. For instance, simple one-hop questions are relatively straightforward, while complex multi-hop questions involving filtering or superlative operations (e.g., argmax/argmin) are significantly more challenging. The authors should provide a detailed breakdown of performance across question sets with different compositional depths.
* [Missing References] Several relevant works are not cited. For example, prior RL-based methods for knowledge-based semantic parsing (e.g., Berant and Liang, 2015), the sequence-level REINFORCE training method (Ranzato et al., 2016), which is closely related to augmented REINFORCE, and the Neural Enquirer work (Yin et al., 2016), which employs continuous differentiable memories for neural execution modeling, should be referenced.
* Miscellaneous
* Why is the REINFORCE algorithm initialized randomly (Algo. 1) rather than using parameters pre-trained with iterative maximum likelihood?
* What does the KG server in Figure 5 represent?