This paper introduces a method to enhance existing approaches for the lexical substitution task by incorporating word sense inventories to filter substitution candidates. The authors first present a metric to evaluate the mutual substitutability of sense inventories with human judgments for the lexsub task and empirically assess the substitutability of inventories from sources such as WordNet and PPDB. Subsequently, they propose a multi-view clustering approach to group paraphrases of a word from PPDB, thereby generating a sense inventory automatically instead of relying on pre-existing inventories. Finally, they apply these clusters in conjunction with a naive (majority in top 5) WSD technique to refine the ranked list of substitution candidates.
- Strengths:
* The central idea of combining vector space model-based methods with sense inventories for the lexsub task is promising, as these techniques provide complementary information. This is particularly valuable since vector space models often lack awareness of sense distinctions and polysemy.
* The oracle evaluation is a compelling addition, as it provides a clear benchmark for the potential gains achievable in the best-case scenario. While there remains a notable gap between the oracle and actual scores, the substantial improvement between the unfiltered GAP and the oracle GAP underscores the utility of the proposed approach.
- Weaknesses:
* The effectiveness of the multi-view clustering approach is unclear. Across most evaluations, the paraphrase similarity view consistently outperforms other views and their combination. This raises questions about the contribution of the other views. While the paper provides one empirical example involving the word 'slip' to illustrate how different views aid in clustering, there is insufficient analysis of how these views differ or complement each other. Without a deeper exploration of the similarities and differences between the views, it is challenging to draw meaningful conclusions about their individual utility.
* The paper lacks clarity on an initial read, as the connections between sections are not immediately apparent, making the work feel somewhat fragmented. For example, the relationship between section 2.1 and section 4.3 is unclear. Adding forward and backward references between sections could improve readability. Additionally, the multi-view clustering section (3.1) requires refinement, as the subsections appear disorganized, and some citations are missing (e.g., lines 392 and 393).
* The relatively weak performance on nouns is concerning. While TWSI's strong performance is expected due to its design, the fact that the oracle GAP for PPDBClus surpasses most clustering approaches is troubling. A deeper investigation into this gap is necessary. Moreover, this finding contradicts the claim that the clustering approach is generalizable across all parts of speech (lines 124-126), as the performance is clearly inconsistent.
- General Discussion:
The paper employs relatively straightforward techniques and experiments. Nonetheless, the authors demonstrate clear improvements on the lexsub task using their two-pronged approach, with the potential for further gains by integrating more robust WSD algorithms.
Some additional questions for the authors:
* Lines 221-222: What is the rationale for including hypernyms/hyponyms?
* Lines 367-368: Why is it necessary for X^{P} to be symmetric?
* Lines 387-389: The weighting scheme appears somewhat arbitrary. Was this choice indeed arbitrary, or is it based on a principled approach?
* Does the high performance of SubstClus^{P} stem from tuning the number of clusters based on this view? Would tuning the clusters using other matrices alter the results and conclusions?
* Could this approach generalize to related tasks beyond lexsub, or is it specifically tailored to this task?