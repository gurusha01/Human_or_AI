- Strengths:  
The methods introduced in this paper demonstrate the potential to significantly reduce memory usage and enhance decoding speed on CPUs, all while maintaining performance levels or experiencing only minimal performance degradation.
- Weaknesses:  
The selection of convolutional codes in Algorithm 2 and Algorithm 3 appears to have a direct impact on the overall performance. It would be beneficial for the authors to investigate and propose an effective approach for determining these codes. Additionally, the claim in the Abstract that "Experiments show the proposed model achieves translation accuracies that approach the softmax, while reducing memory usage on the order of 1/10 to 1/1000, and also improving decoding speed on CPUs by x5 to x20" lacks rigor. Based on the experimental results with "Binary" and "Hybrid-512" settings on the ASPEC corpus, the reported x20 improvement in decoding speed on CPUs comes at the cost of significantly lower BLEU scores, which undermines the validity of this conclusion.
- General Discussion:  
This paper introduces an efficient prediction approach for neural machine translation by encoding each word as a binary code, thereby reducing prediction complexity. The authors further propose an enhanced error-correction-based binary coding method to improve prediction accuracy, along with a hybrid softmax/binary model to strike a balance between accuracy and efficiency. The methods presented in this work effectively reduce memory usage and improve decoding speed, with little to no compromise in performance. Overall, I believe this is a strong contribution to the field.