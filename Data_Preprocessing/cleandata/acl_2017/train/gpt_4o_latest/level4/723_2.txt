This paper builds upon prior work on applying word embeddings to the task of unsupervised morphological segmentation (e.g., Soricut & Och, 2015; Üstün & Can, 2016). The proposed method, MORSE, employs a local optimization approach for segmenting individual words, leveraging a set of orthographic and semantic rules alongside a few heuristic threshold values.
- Strengths:
The paper introduces several methods for evaluating segmentation hypotheses using word embeddings, which could also prove beneficial for other approaches. The results on English and Turkish datasets are compelling.
The manuscript is well-written and structured, with an extensive bibliography.
The submission includes software for testing the English MORSE model and provides three small datasets used in the experiments.
- Weaknesses:
The contributions of the paper are somewhat incremental, primarily building on the work of Soricut & Och (2015). However, the main concerns lie in the lack of meaningful comparisons to prior work and insufficient analysis of the method's limitations.
Firstly, the proposed method does not offer a robust solution for segmenting compounds. Section 5.3 indicates that the method segments some compounds, but it treats one of the constituents as an affix. Unsurprisingly, this limitation is particularly evident in the results for Finnish, a highly compounding language. While this issue is briefly acknowledged in the discussion section, the introduction and experiments seem to overlook it.
Specifically, the inability to effectively model compounds makes the evaluation in Sections 4.4 and 5.3 problematic. Morfessor, for example, excels at segmenting compounds (Ruokolainen et al., 2014), whereas MORSE appears to handle them only incidentally. Consequently, it is unsurprising that Morfessor segments a larger proportion of semantically non-compositional compounds. A fairer comparison would involve an equal number of compounds that are expected to be segmented into their constituents.
Another issue with the evaluations (Sections 4.2 and 4.3) pertains to hyperparameter tuning. While MORSE's hyperparameters are optimized on tuning data, it appears that Morfessor's are not. Recent versions of Morfessor (Kohonen et al., 2010; Grönroos et al., 2014) include a single hyperparameter that balances precision and recall in segmentation. Although MORSE outperforms Morfessor in both precision and recall in many cases, this discrepancy in tuning should at least be acknowledged.
Some critical details about the evaluations and results are missing. For instance, the "morpheme-level evaluation" method in Section 5.2 should be described or cited. Additionally, Table 7 seems to compare results from different evaluation sets: Morfessor and Base Inference results are from official Morpho Challenge evaluations, LLSM results are from Narasimhan et al. (2015), which uses aggregated Morpho Challenge data (likely including both development and training sets), and MORSE results are from the Morpho Challenge 2010 development set. While this may not affect the conclusions due to the large differences in scores, it should still be explicitly mentioned.
The software package provided does not appear to support training, only testing with the included English model.
- General Discussion:
The paper places significant emphasis on segmenting semantically non-compositional compounds, which is problematic for two reasons. First, as noted earlier, the proposed method does not seem to provide a meaningful approach for segmenting any compounds. Second, distinguishing between lexicalized base forms (e.g., "freshman") and morphemes as the smallest meaning-bearing units (e.g., "fresh" and "man") represents two distinct tasks with different applications (e.g., the former is more relevant for phrase-based SMT, while the latter is more suitable for ASR). Unsupervised segmentation methods like Morfessor typically target the latter, and critiquing them for not addressing a different goal is misleading.
Moreover, there is a continuum in the semantic compositionality of compounds, and the decision to segment them is inherently somewhat arbitrary. Unfortunately, many gold standards, including the Morpho Challenge datasets, exhibit inconsistencies in their segmentation decisions.
Sections 4.1 and 5.1 briefly mention computational efficiency and the limitation to one million input word forms but do not provide sufficient details. What is the bottleneck—collecting transformations, support sets, and clusters, or solving the optimization problem? What were the computation times, and how do they scale?
The discussion highlights some advantages of the MORSE approach, such as adaptability as a stemmer, control over precision and recall, and the need for only a small number of gold-standard segmentations for tuning. However, many of these benefits also apply to Morfessor variants (Creutz & Lagus, 2005; Kohonen et al., 2010; Grönroos et al., 2014). While Morfessor often performs well in a fully unsupervised setting, its extensions offer at least as much flexibility as MORSE.
(Ref: Mathias Creutz and Krista Lagus. 2005. Inducing the Morphological Lexicon of a Natural Language from Unannotated Text. In Proceedings of the International and Interdisciplinary Conference on Adaptive Knowledge Representation and Reasoning (AKRR'05), Espoo, Finland, June 15-17.)
- Miscellaneous:
The abstract should clarify that this is a minimally supervised method (unsupervised to the extent typical for such approaches, excluding hyperparameter tuning).
In Section 3, it should be explicitly stated that phi represents an empty string.
In Section 5, the specific variant (and implementation) of Morfessor used in the experiments should be mentioned.
At the end of Section 5.2, the claim that increasing the size of the input vocabulary would improve performance for Finnish seems doubtful. For a morphologically complex language like Finnish, it is unlikely that even all possible inflections of word forms, let alone derivations and compounds, would be encountered in the data.
The format of the datasets could be improved (e.g., adopting a structure similar to the Morpho Challenge datasets). For instance, using "aa" as a separator for multiple analyses is confusing and limits the format's applicability to other languages.
In the references, several proper nouns and abbreviations in titles are incorrectly written in lowercase. Additionally, the publication details for Narasimhan et al. (2015) are missing.