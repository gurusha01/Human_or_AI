- Strengths: The paper provides a valuable modeling contribution and introduces potentially useful annotated data for a significant task—event extraction focused on relationships between countries as expressed in news text.
- Weaknesses: Several aspects of the paper are poorly explained, leaving critical gaps in understanding.
- General Discussion:
This paper addresses an important and compelling event extraction problem: identifying positive and negative interactions between country pairs (or actors affiliated with countries) based on news text. Its main contribution lies in applying supervised, structured neural network models to sentence-level event/relation extraction. While prior research has explored related tasks, this work appears to be the first to provide publicly available sentence-level annotated data for this specific problem. If released, the annotated dataset could serve as a valuable resource for future researchers in this domain.
The proposed models, which seem to leverage various tree-structured recursive neural network architectures, exhibit notable performance improvements over a broad and reasonably convincing set of baselines (assuming the results can be trusted; see concerns below). Additionally, the paper includes a manual evaluation of inferred time series from a news corpus, which is a welcome addition.
However, I have mixed feelings about this paper. The problem is highly relevant, and the application of recursive models represents a meaningful contribution. Yet, the paper suffers from significant shortcomings in clarity and detail regarding the models, experiments, and evaluations. With better writing and more thorough explanations, this work could have been much stronger.
Specific Notes:
- Baselines: The baselines require more detailed explanations. For instance, the sentiment lexicon used for the SVM is not described. Similarly, the LSTM classifier is left vague (L407-409). There are multiple ways to use an LSTM for classification—how exactly was it implemented and trained? Is there a reference for the approach? If off-the-shelf code was used, it should be cited and referenced to aid reproducibility. As it stands, the baselines cannot be replicated based on the limited information provided.
- Code: While it is commendable that the authors provided code for the recursive NN models, the baselines are not included. This omission is notable given the lack of detail in the paper about the baselines, making their replication nearly impossible.
- Recursive NN Models: The training process for the recursive neural network models is not explained.
- Visualization Section: The visualization section is a minor contribution with no significant innovation or findings regarding what works or does not work.
Line-by-Line Comments:
- L97-99: The statement is unclear. Why is this problem difficult, and compared to what? Additionally, the sentence is somewhat ungrammatical.
- L231: The paper mentions that the trees are binarized but does not explain how.
- Footnote 2: The reference to "the tensor version" requires a citation to clarify what is being discussed.
- L314: How are non-state verbs defined? Does the definition of "event words" stem from prior work? If so, the paper should provide appropriate references.
- Footnote 4: The authors note that the collapsed form does not work but fail to explain why. The collapsed form in Stanford dependencies is designed to incorporate prepositions into dependency labels, so this point needs clarification.
- L414: How are the CAMEO/TABARI categories mapped to positive and negative entries? Is the model's performance sensitive to this mapping? Given the complexity of mapping hundreds of CAMEO categories, did the authors consider using Goldstein scaling, as employed in political science and prior work by O'Connor et al.? If not, why?
- L400-401: What is the sentiment lexicon, and why is it suitable for this task?
- L439-440: The statement "We failed at finding an alpha meeting the requirements for the FT model" is unclear. What are the requirements, and what steps did the authors take to find this alpha?
- L447, L470: The phrase "precision and recall values are based on NEG and POS classes" is ambiguous. If there is a 3x3 contingency table for gold and predicted classes (POS, NEU, NEG), how exactly are precision and recall calculated?
- 5.1 Aggregations: The temporal smoothing function used seems ad hoc and lacks justification. Why was this approach chosen over simpler alternatives, such as a fixed window average?
- 5.2 Visualizations: The visualizations appear ad hoc and are not well justified. The graph visualization does not seem to provide meaningful insights. Additionally, the authors should discuss related work on 2D spatial visualization of country-country relationships, such as that by Peter Hoff and Michael Ward.
- 5.3:
  - L638-639: The term "unions of countries" is not well defined. Perhaps the authors meant "international organizations"?
  - L646-648: How were the five strong and five weak peaks selected? If there were more than five, what criteria were used to choose these specific examples?
  - L680-683: The process of judging the polarity of a peak needs more explanation and examples. What does it look like when the algorithm is wrong? How difficult was this task to assess, and what was the agreement rate (if measurable)?
- L738-740: The claim that Gerrish and O'Connor et al. have different "purposes and outputs" is inaccurate. Both works aim to extract time series or statistical information about country relationships (similar to this paper) and also explore topical keywords to explain these relationships. While this paper focuses solely on the first goal, the prior works address both. The authors' statement misrepresents the scope of previous research.
Finally, Gerrish and O'Connor evaluate their methods using the MID (Military Interstate Disputes) database from political science. Why did the authors of this paper not conduct a similar evaluation? While the MID data has its limitations, the lack of such an evaluation needs to be discussed or justified.