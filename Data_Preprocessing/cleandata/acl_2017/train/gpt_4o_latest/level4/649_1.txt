- Strengths:  
This paper introduces an evaluation metric designed for automatically assessing the quality of dialogue responses in non-task-oriented dialogue systems. The proposed metric leverages continuous vector space representations derived from RNNs and consists of two components: one that evaluates the relationship between the context and the given response, and another that compares the given response to a reference response. These comparisons are performed using dot products after projecting the response into the respective context and reference response spaces. The projection matrices are trained by minimizing the squared error between the model's predictions and human annotations.
This work represents a significant advancement in the evaluation of non-task-oriented dialogue systems. Unlike prior approaches in this domain, which primarily focused on semantic similarity, the authors take an innovative step by learning projection matrices that map the response vector into both context and reference space representations. This approach effectively goes beyond pure semantic similarity in a sophisticated manner. I am particularly interested in understanding how the projection matrices M and N evolve from their initial identity initialization after training. Including a more detailed discussion on this aspect would enhance the paper's value, as opposed to placing excessive emphasis on the resulting correlations.
- Weaknesses:  
The paper leaves several implementation details unclear. For example, it is not specified whether the human scores used for training and evaluation were derived from single AMT annotations or averaged across multiple annotations. Additionally, the methodology for splitting the dataset into train/dev/test sets is not described, nor is it mentioned whether n-fold cross-validation was performed. Furthermore, in Table 2, it is unclear why correlations for ADEM-related scores are reported for the validation and test sets, while for other scores, they are presented for the full dataset and test set. The section discussing pre-training with VHRED is also poorly structured and difficult to follow. A higher-level explanation of the pre-training strategy and its benefits, with fewer technical details, would improve clarity.
- General Discussion:  
"There are many obvious cases where these metrics fail, as they are often incapable of considering the semantic similarity between responses (see Figure 1)." Be cautious with such statements. The issue here is not with semantic similarity itself. On the contrary, the challenge lies in the fact that pragmatically valid responses can arise from entirely different semantic cues. Thus, semantic similarity alone is insufficient for evaluating dialogue system responses. Evaluation must extend beyond semantics—this is precisely what your M and N matrices aim to achieve.
"an accurate model that can evaluate dialogue response quality automatically — what could be considered an automatic Turing test —" The original purpose of the Turing Test was to serve as a proxy for identifying or defining intelligent behavior. It evaluates whether a machine can imitate human behavior to the extent that a typical human cannot distinguish between the machine's responses and those of a human. While this concept is tangentially related to dialogue system performance, it is inaccurate to equate automatic evaluation of dialogue response quality with an automatic Turing Test. The title of the paper, "Towards an Automatic Turing Test," is therefore somewhat misleading.
"the simplifying assumption that a 'good' chatbot is one whose responses are scored highly on appropriateness by human evaluators." This is indeed the right perspective for framing the problem of non-task-oriented dialogue systems, rather than invoking the Turing Test. On this topic, you may want to refer to related work from the WOCHAT workshop series, particularly the shared task descriptions and corresponding annotation guidelines.
In the discussion section: "and has has been used" should be corrected to "and it has been used."