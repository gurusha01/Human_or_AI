- Strengths:
  * A knowledge-lean, language-agnostic methodology.
- Weaknesses:
  * Niche task/setting.
  * Limited improvement over W_Emb (Fu et al., 2014).
  * Inefficient use of space.
  * Language clarity is inconsistent.
- General Discussion:
This paper appears to closely resemble (Fu et al., 2014) and offers only minor enhancements. It includes considerable redundancy (e.g., overlapping content in Sections 1 and 2), uninformative visualizations (e.g., Figure 1 compared to Figure 2), and overly detailed yet unnecessary explanations of MLP and RNN. A shorter format might have been more appropriate.
The task itself seems somewhat specialized and only applicable if one already possesses a method that accurately identifies all and only the hypernyms of a given word, which seems to rely on (Fu et al., 2013).
Regarding Figure 4: why are the first two stars joined by conjunction while the last two are connected by disjunction? Additionally, why is the output "1" (dark star) when all three inputs are "0" (white stars)?
In Section 4.2 (lines 587-589), there is an implication that thresholds were tuned on the test data, which raises concerns.
The explanation of W_Emb is insufficiently detailed (lines 650-652).
Certain sections of the text are unclear. For instance, the section titled "Combined with Manually-Built Hierarchies" is difficult to interpret, as is Section 4.4. Additionally, the meaning of the red and dashed lines in this section is not explained.