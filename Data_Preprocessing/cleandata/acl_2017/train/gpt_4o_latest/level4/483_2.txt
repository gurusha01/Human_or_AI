The paper explores the application of Pointer Networks, a type of recurrent neural network originally designed for algorithmic tasks, to two subtasks within Argumentation Mining: identifying the types of Argument Components and determining the links between them. The proposed model achieves state-of-the-art performance.
Strengths:
- Comprehensive review of related work specific to the formulation of argument mining addressed in this study.
- Straightforward yet effective adaptation of an existing model to suit the task. The model is generally well-explained.
- Strong empirical results compared to prior work in this domain.
Weaknesses:
- 071: The paper focuses on one specific formulation of argumentation mining, but this is just one of several possible subtask divisions, which should be acknowledged. For instance, [1] proposes detecting and classifying claims before identifying supporting evidence. Additionally, [2] has already applied neural networks to this task, making the claim in the abstract that this is the first NN-based approach inaccurate.
- The presentation of the model requires clarification in two areas: (1) The pooling method used for embedding features (line 397) is not specified. (2) Equation (7) on line 472 is unclear—does E_i represent the type of AC i or its identity? Both are modeled (the latter via feature representation) and need explicit definitions. Moreover, the left-hand side of Equation (7) appears to represent a conditional probability but is not clearly stated as such.
- Table 2 raises several questions: First, why are the first three baselines evaluated only by macro F1, with individual F1 scores omitted? This is not addressed in the text. Second, why is only the "PN" model included? Is this the same PN as in Table 1, or does it refer to the Joint Model? What about the other three models?
- The dataset used for the experiment in Table 4 is not specified.
General Discussion:
- 132: The introduction to pointer networks should be expanded to include a broader explanation of recurrent neural networks and sequence-to-sequence models for readers unfamiliar with these concepts. The citation of Sutskever et al. (2014) in line 145 should appear at the first mention of the term, and the distinction from recursive neural networks should be clarified before the paragraph starting on line 233 (tree structure, etc.).
- 348: The elu activation function requires both an explanation and a citation, as it is not yet widely recognized.
- 501: The labels "MC," "Cl," and "Pr" need to be defined.
- 577: A brief explanation of how the hyperparameters were chosen would be helpful.
- 590: The rationale for using only link prediction accuracy for early stopping should be explained (e.g., why not include type accuracy?).
- 594: The description of inference during test time is too brief and would benefit from additional details.
- 617: Clarify whether the length of an AC is measured in words or another unit.
- 644: The referent of "these" in "Neither of these" is ambiguous and should be clarified.
- 684: The word "Minimum" should be corrected to "Maximum."
- 694: While the performance with limited training data is impressive, other models have achieved nearly comparable results. This is particularly noteworthy given that neural networks typically require more data. This observation should be included.
- 745: Alternatively, the results could suggest that structural cues are less critical for this task.
- Minor typographical errors should be corrected (e.g., "which is show" on line 161).
[1] Rinott, Ruty, et al. "Show Me Your Evidence—An Automatic Method for Context-Dependent Evidence Detection." EMNLP. 2015.
[2] Laha, Anirban, and Vikas Raykar. "An Empirical Evaluation of Various Deep Learning Architectures for Bi-Sequence Classification Tasks." COLING. 2016.