This paper presents a model for cross-lingual named entity recognition (NER). The authors utilize conditional random fields, maximum entropy Markov models, and neural network-based NER approaches. Additionally, they propose two methods for combining the outputs of these approaches (probability-based and ranking-based) and introduce a technique for selecting optimal training instances from cross-lingual comparable corpora. The cross-lingual projection is implemented using a modified version of Mikolov's method. Overall, the paper is well-structured, easy to follow, and written in clear English. The results obtained from the combined annotations are noteworthy.
Detailed comments:
I am curious about the motivation for proposing a variation of the Continuous Bag-of-Words (CBOW) model. The paper does not provide sufficient details about this variation or the parameters used. Was the original CBOW model (or the Continuous Skip-gram model) yielding suboptimal results? I recommend including the results of the original CBOW model so that readers can better understand the improvements achieved by your approach. Since you employ a decay factor for the surrounding embeddings, I suggest considering the exponential decay method described in [1].
In line with the previous comment, I would like to see a comparison between the original Mikolov cross-lingual projection method and your frequency-weighted projection approach. These contributions would be more impactful if readers could clearly observe the superiority of your method.
"The proposed data selection scheme is very effective in selecting good-quality projection-labeled data and the improvement is significant" ‚Üê Have you conducted a statistical significance test? It would be helpful to confirm whether the differences in results reported in this work are statistically significant.
I recommend integrating the content of Section 4.4 into the beginning of Section 4.2 for better organization. Additionally, I suggest moving the evaluation presented in Table 2 to the evaluation section for consistency.
The paper lacks a dedicated related work section. While the introduction includes some related work, I suggest dividing the introduction into two sections to clearly separate the background and related work.
The evaluation section is relatively brief (1.5 pages, including the conclusion). Since you achieve state-of-the-art results, I would appreciate a more detailed discussion and analysis of the results.
Suggested references:
[1] Iacobacci, I., Pilehvar, M. T., & Navigli, R. (2016). Embeddings for word sense disambiguation: An evaluation study. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Vol. 1, pp. 897-907).