Paraphrased Review
Strengths:  
The distinction between "vocal" users and "average users" is a compelling finding that could serve as a basis for identifying different user types.
Weaknesses:  
This work appears to be an initial exploration of a novel topic that warrants further development in the future. Incorporating a comparison with matrix factorization techniques and related areas in distributional semantics (e.g., latent semantic analysis) would enhance the study.
General Discussion:  
The paper presents a method for modeling the stance or sentiment of Twitter users on various topics, with a specific focus on inter-topic preference modeling. This task involves quantifying the extent to which stances on different topics are interrelated. The authors claim that their work advances the state of the art in this domain, as prior studies were limited to case-specific analyses, whereas their approach generalizes to an unlimited number of topics using real-world data.  
The proposed methodology follows these steps: First, a set of linguistic patterns was manually curated, which facilitated the collection of a large dataset of tweets expressing stances on diverse topics. These texts were then represented as triples comprising user, topic, and evaluation. The relationships captured in these triples were organized into a sparse matrix, which was subsequently subjected to matrix factorization and low-rank approximation. The optimal rank was empirically determined to be 100. Cosine similarity was employed to measure topic similarity, enabling the detection of latent preferences not evident in the original sparse matrix. Additionally, cosine similarity was used to identify inter-topic preferences.  
A preliminary empirical evaluation demonstrates that the model can predict missing topic preferences. Furthermore, the predicted inter-topic preferences show moderate correlation with corresponding values derived from a crowdsourced gold-standard dataset. According to the related work section, no prior systems exist for direct comparison in the task of inter-topic preference prediction, making this approach promising.  
Specific comments are detailed below:  
- Rows 23 and 744, "high-quality": What criteria define "high-quality"? If this is not clearly specified, I suggest removing all instances of "high-quality" from the paper.  
- Row 181 and caption of Figure 1: Consider removing the term "generic."  
- Row 217: Replace "This section collect" with "We collected" or "This section explains how we collected."  
- Row 246: Replace "ironies" with "irony."  
- Row 269, "I support TPP": Since the procedure can identify various patterns such as "to A" or "this is A," the authors should clarify that all potential patterns containing the topic are collected and then manually filtered.  
- Rows 275 and 280, "unuseful": Replace with "useless."  
- Row 306: Replace "including" with "are including."  
- Row 309: Clarify that "of" or "it" are not topics but likely terms mistakenly retrieved as topics.  
- Rows 317-319: Remove the first sentence and begin with "Twitter user..."  
- Rows 419-439: The procedure for determining the optimal k is commendable. Unlike prior works that often assume this value, empirically determining it adds value.  
- Row 446, "let": Should this be "call"?