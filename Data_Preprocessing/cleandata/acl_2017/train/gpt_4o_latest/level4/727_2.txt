- Strengths: The authors tackle a complex and nuanced problem in political discourse, achieving a relatively high level of success.  
The task of detecting political framing is likely to be of interest to the ACL community.  
The paper is exceptionally well written.  
- Weaknesses: The quantitative results are presented solely for the authors' PSL model, with no comparisons to standard baseline classification algorithms. This omission makes it difficult to assess the necessity or effectiveness of their model. The lack of comparisons with alternative approaches leaves the reader uncertain about the paper's key contributions.  
While the qualitative analysis is intriguing, the selected visualizations are challenging to interpret and contribute little to the discussion. Collapsing data across individual politicians might yield clearer and more meaningful visuals.  
- General Discussion: The submission is well written and addresses a topic that could be of interest to the ACL community. However, it falls short in providing adequate quantitative baselines for comparison.  
Minor comments:  
- Line 82: The Boydstun et al. citation should include the publication year.  
- The assumption that similar tweeting behavior (in terms of timing) necessarily indicates similar framing is unclear and lacks supporting citations.  
- The related work section covers a broad range of topics but overlooks the most directly relevant areas (e.g., PSL models and political discourse research). Conversely, it spends too much time discussing tangentially related work (e.g., unsupervised models using Twitter data).  
- In Section 4.2, it is unclear whether Word2Vec embeddings were trained on the authors' dataset or if pre-trained embeddings were used.  
- The rationale for using unigrams to predict frames and bigrams/trigrams to predict party affiliation is not explained.  
- The authors state that temporal similarity performed best with one-hour intervals but do not discuss how critical this assumption is to their results. Even if full results cannot be provided, it would be helpful to give readers an idea of how performance might change with wider time windows.  
- Table 4: The caption should explicitly state that the values are F1 scores and clarify how the F1 scores are weighted (e.g., micro or macro). This clarification should also be included in the "evaluation metrics" section on page 6.