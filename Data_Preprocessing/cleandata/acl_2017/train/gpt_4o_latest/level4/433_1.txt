The paper introduces a deep-learning-based approach for parsing the creole Singaporean English (Singlish) into Universal Dependencies (UD). The authors adapt the parser by Dozat and Manning (2016) and enhance it with neural stacking, following the method of Chen et al. (2016). Their approach involves training an English parser and leveraging some of its hidden representations as input to a Singlish parser. This strategy allows them to utilize a large English training dataset in conjunction with a small annotated Singlish treebank. Their results demonstrate that this method (LAS 76.57) outperforms both using an English parser directly (LAS 65.6) and training a parser solely on the Singlish dataset (LAS 64.01). Additionally, they analyze how their approach improves parsing quality for common Singlish constructions.
The authors also present and evaluate a stacked POS tagging model based on Chen et al. (2016). They discuss the UD framework's treatment of common Singlish constructions and provide an annotated treebank of 1,200 sentences. Of these, 100 sentences underwent double annotation, achieving an inter-annotator agreement (IAA) of 85.3 UAS and 75.7 LAS.
Strengths:
- The authors achieve strong results with a well-designed experimental setup.
- They conduct detailed analyses, examining the impact of various model parameters.
- The paper contributes a small Singlish treebank annotated according to UD v1.4 guidelines.
- They propose well-founded guidelines for analyzing common Singlish constructions in UD.
- The method is linguistically informed, effectively leveraging similarities between standard English and Singlish.
- The work addresses challenges in low-resource language processing.
- The proposed method is not merely an adaptation of an English parser but offers a framework applicable to other closely related language pairs.
- The sentence selection process for the treebank is well-motivated.
- The paper is well-written and accessible.
Weaknesses:
- The annotation quality appears suboptimal. The IAA for the 100 doubly annotated sentences is only 75.72% LAS, raising concerns about the reliability of the LAS scores reported for the model. Notably, the model's LAS slightly exceeds the IAA.
UPDATE: The authors' rebuttal clarified that the second annotator, who annotated the 100 sentences for IAA calculation, did not initially adhere to the annotation guidelines for certain constructions. After these issues were addressed, the IAA improved to a reasonable level. As a result, I no longer view this as a significant concern.
General Discussion:
While I remain somewhat cautious about the potential impact of annotation quality on the results, I found the paper to be a strong contribution overall. The work is well-executed and would be a valuable addition to the conference.
Questions for the Authors:
1. Who annotated the sentences? The paper mentions that 100 sentences were annotated by one of the authors for IAA calculation but does not specify who annotated the full dataset.
2. Why was the initial IAA so low? What were the main sources of disagreement, and were the disputed annotations subsequently resolved?
3. Table A2: The treebank contains a high number of discourse relations, nearly as many as dobj relations. Is this a characteristic of colloquial Singlish, or were "discourse" labels applied to constructions that might not be considered discourse in other UD languages?
4. Table A3: Are all the listed items discourse particles, or are some a combination of discourse particles and imported vocabulary? If the latter, separating them into distinct tables and including glosses would improve clarity.
Low-Level Comments:
- It would have been useful to compare your approach to Martinez et al. (2017, https://arxiv.org/pdf/1701.03163.pdf). Consider citing this paper in the references.
- The term "grammar" is used in an unconventional way. Replacing it with "syntactic constructions" (e.g., line 90) would improve clarity.
- Line 291: The construction described does not seem to align with it-extraposition. While I agree with the analysis in Figure 2, this sentence could be omitted.
- Line 152: The parser by Dozat and Manning (2016) is no longer state-of-the-art. Consider rephrasing to "a high-performing model" or similar.
- Including glosses in Figure 2 would enhance readability and understanding.