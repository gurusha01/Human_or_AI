Review
Summary and Contributions
This paper introduces TextFlow (XF), a novel standalone text similarity measure inspired by DNA sequence alignment algorithms. Unlike traditional similarity measures that rely on token overlap or n-grams, TextFlow considers the sequential nature of language by representing text pairs as continuous curves and calculating similarity based on sub-sequence matching, positional differences, and unmatched words. The authors also propose a neural network architecture for task-specific parameter optimization of TextFlow. The paper evaluates TextFlow on eight datasets across three tasks: textual entailment recognition, paraphrase detection, and ranking relevance, demonstrating its superior performance compared to state-of-the-art similarity measures. Key contributions include:
1. A novel similarity measure (TextFlow) that integrates sequence matching and positional information.
2. A neural network-based framework for training task-specific parameters for TextFlow.
3. Comprehensive empirical evaluation across multiple datasets and tasks, introducing a new evaluation metric (CORE) for performance consistency.
Strengths
1. Novelty of Approach: The introduction of a similarity measure inspired by DNA sequence alignment is innovative and addresses limitations of traditional measures like n-grams and skip-grams. The asymmetric nature of TextFlow adds flexibility for different tasks.
2. Empirical Validation: The experiments are thorough, covering eight datasets across three tasks. TextFlow consistently outperforms baseline measures in accuracy, precision, and CORE, demonstrating its robustness and generalizability.
3. Task-Specific Adaptability: The neural network-based parameter training for TextFlow is a significant strength, allowing the measure to be fine-tuned for specific tasks, such as optimizing for accuracy or F1 score.
4. Practical Utility: TextFlow is computationally efficient (O(nm)) and does not require training corpora for its canonical version, making it a practical tool for real-world applications like plagiarism detection and ranking relevance.
5. Reproducibility: The authors provide implementation details, including code and datasets, which enhances the reproducibility of their work.
Weaknesses
1. Limited Discussion of Limitations: While the paper briefly acknowledges areas for improvement (e.g., incorporating word weights), it does not sufficiently discuss the limitations of TextFlow, such as its reliance on token-level matching, which may struggle with semantic variations.
2. Recall Performance: TextFlow underperforms on recall compared to some baselines, particularly for the trained version (XFt). This is attributed to its optimization for accuracy, but the trade-off could be better explored.
3. Evaluation Scope: While the evaluation is extensive, the datasets are predominantly English-based and focused on sentence-level tasks. The applicability of TextFlow to multilingual or document-level tasks remains unexplored.
4. Complexity of Neural Network Training: The neural network architecture for parameter training adds complexity and may not be accessible to all users. A more detailed explanation of its design and hyperparameter choices would be beneficial.
Questions to Authors
1. How does TextFlow handle semantic variations, such as synonyms or paraphrasing, beyond token-level matching? Could embeddings or semantic similarity measures be integrated into the framework?
2. Have you evaluated the scalability of TextFlow on larger datasets or document-level tasks? If not, what are the anticipated challenges?
3. Could you elaborate on the choice of the CORE metric and its advantages over traditional evaluation metrics like mean rank or variance?
Recommendation
I recommend acceptance of this paper, as it presents a novel and practical contribution to text similarity measures, supported by strong empirical results. Addressing the identified weaknesses, particularly the recall performance and applicability to broader tasks, could further enhance its impact.