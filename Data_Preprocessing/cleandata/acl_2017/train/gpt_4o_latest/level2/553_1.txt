Review of the Paper
Summary and Contributions
This paper introduces a general framework for Cross-Context Lexical Analysis (CCLA), enabling the study of how term meanings and representations vary across different contexts. The authors demonstrate the versatility of CCLA by applying it to three tasks: (1) semantic change detection, (2) comparative lexical analysis over contexts, and (3) word embedding stability evaluation. The framework is notable for its flexibility, accommodating any notion of context, similarity function, or word annotation. The authors provide experimental results on publicly available datasets (e.g., COHA, IMDB, and Yelp) and make their code and data available for reproducibility. The claimed contributions include:  
1. A formalized and generalizable framework for CCLA.  
2. Applications of CCLA to diverse tasks, including semantic change detection and embedding stability.  
3. Empirical evidence demonstrating the utility of CCLA in uncovering linguistic and contextual insights.
Strengths
1. Generalizability and Flexibility: The framework is highly adaptable, supporting various notions of context (e.g., temporal, sentiment-based) and similarity metrics. This makes it broadly applicable to numerous NLP tasks, including semantic change detection and domain adaptation.
2. Novelty in Contextual Analysis: Unlike traditional topic models, which focus on topic-level variations, CCLA enables fine-grained lexical analysis, offering new insights into word-level changes across contexts.
3. Empirical Validation: The paper provides thorough experimental results across multiple datasets and tasks, demonstrating the framework's effectiveness. For instance, the semantic change detection experiments align well with prior work, while the embedding stability evaluation offers a novel perspective on word vector consistency.
4. Reproducibility: The authors provide open-source code and datasets, ensuring that the work can be replicated and extended by the community.
5. Potential Applications: The paper highlights several promising applications, such as framing bias detection, domain adaptation, and word sense disambiguation, showcasing the framework's practical relevance.
Weaknesses
1. Limited Comparison to Baselines: While the paper compares its semantic change detection results to prior work, other tasks (e.g., comparative lexical analysis and embedding stability) lack rigorous benchmarking against alternative methods. This limits the ability to assess the framework's relative performance.
2. Scalability Concerns: The computational complexity of the framework, particularly for large corpora or high-dimensional embeddings, is not explicitly addressed. This could hinder its adoption for large-scale applications.
3. Ambiguity in Scoring Functions: The choice of scoring functions (e.g., φ) is task-specific and user-defined, but the paper does not provide sufficient guidance on how to select or design these functions for new tasks. This could pose challenges for practitioners unfamiliar with the framework.
4. Evaluation of Novelty: While the framework is general and flexible, some of its applications (e.g., semantic change detection) build on existing methods without introducing significant methodological innovations. The novelty of the framework itself could be better articulated.
5. Limited Discussion of Limitations: The paper does not adequately discuss potential limitations of the framework, such as sensitivity to noisy data or the impact of overlapping contexts.
Questions to Authors
1. How does the framework scale with increasing corpus size or embedding dimensionality? Have you tested its performance on larger datasets?  
2. Can you provide more concrete guidelines for selecting or designing scoring functions (φ) for new tasks?  
3. How robust is the framework to noisy or imbalanced datasets, particularly in contexts with sparse data?  
4. Could you elaborate on how CCLA compares to other unsupervised methods for domain adaptation or transfer learning?  
Overall Assessment
This paper presents a promising and flexible framework for cross-context lexical analysis, with applications to a variety of NLP tasks. The work is well-motivated and empirically validated, and its open-source nature enhances its potential impact. However, the lack of rigorous comparisons to baselines and limited discussion of scalability and limitations weaken its overall contribution. With additional benchmarking and refinement, this framework could become a valuable tool for the NLP community.  
Recommendation: Accept with minor revisions.