Review
Summary and Contributions  
This paper addresses the challenge of constructing semantic hierarchies by automatically discovering hypernym-hyponym ("is-a") relations. The authors propose a novel fusion learning architecture that combines discriminative and generative models, supplemented with a simple lexical structure rule. The method achieves an F1-score of 74.20% with a precision of 91.60%, outperforming prior state-of-the-art approaches. Notably, the architecture is language-independent and can be applied to other languages. The authors further demonstrate that combining their method with manually-built hierarchies improves the F1-score to 82.01%. The three main contributions of the work are:  
1. A unified fusion architecture combining generative and discriminative models for semantic hierarchy construction.  
2. Superior performance compared to state-of-the-art methods, particularly in precision, making it more suitable for practical applications.  
3. A language-independent approach that integrates lexical structure rules to enhance performance.  
Strengths  
1. Innovative Fusion Architecture: The combination of generative and discriminative models is a novel approach to improving precision and recall in semantic hierarchy construction. The use of Boolean "AND" logic to filter false positives is particularly effective.  
2. High Precision: The achieved precision of 91.60% is a significant improvement over existing methods, making the approach highly applicable in real-world scenarios where precision is critical.  
3. Language Independence: The method's ability to generalize across languages is a valuable feature, broadening its applicability beyond Chinese.  
4. Integration with Manually-Built Hierarchies: The authors demonstrate that their method complements existing resources like Wikipedia and CilinE, further enhancing its utility.  
5. Comprehensive Evaluation: The paper provides detailed comparisons with previous methods and evaluates performance on both in-domain and out-of-domain data, showcasing robustness.  
Weaknesses  
1. Limited Novelty in Components: While the fusion of generative and discriminative models is novel, the individual components (MLP and RNN) are standard techniques. The paper could benefit from a deeper exploration of how these models are specifically tailored for this task.  
2. Dependence on Pre-trained Word Embeddings: The method relies heavily on high-quality pre-trained word embeddings, which may not always be available for low-resource languages or domains.  
3. Lexical Rule Simplicity: The lexical structure rule, while effective for compound nouns, is overly simplistic and may not generalize well to more complex linguistic structures.  
4. Limited Discussion of Limitations: The paper does not sufficiently discuss the limitations of its approach, such as potential challenges in scaling to larger datasets or adapting to languages with different morphological structures.  
5. Reproducibility Concerns: While the method is described in detail, the lack of publicly available code or pre-trained models may hinder reproducibility and adoption by the community.  
Questions to Authors  
1. How does the method perform on languages with complex morphology (e.g., agglutinative or polysynthetic languages)?  
2. Could the lexical structure rule be extended to handle more complex linguistic phenomena beyond compound nouns?  
3. What are the computational costs of training and inference for the proposed fusion architecture compared to simpler methods?  
Conclusion  
This paper presents a strong contribution to the field of semantic hierarchy construction, particularly in its innovative fusion learning architecture and high precision. While there are some concerns regarding the novelty of individual components and the simplicity of the lexical rule, the overall approach is well-motivated and demonstrates significant improvements over prior work. With some refinements and a broader discussion of limitations, this work has the potential to make a lasting impact on the field. I recommend acceptance with minor revisions.