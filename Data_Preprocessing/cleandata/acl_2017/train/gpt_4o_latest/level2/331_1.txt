Review of the Submitted Paper
Summary and Contributions
This paper introduces a novel task in natural language processing: concept-map-based multi-document summarization (MDS). The authors propose a framework for generating summaries in the form of concept maps, which are structured, graph-based representations of information. The key contributions of the paper are: (1) the formalization of the concept-map-based MDS task, (2) the creation of a new benchmark dataset using a novel crowdsourcing approach, (3) the release of an evaluation protocol and baseline system, and (4) the provision of publicly available resources to encourage further research in this area. The dataset is particularly notable for its large-scale, heterogeneous document clusters and high-quality annotations, addressing a gap in existing summarization corpora.
Strengths
1. Novelty of the Task: The paper introduces a new summarization paradigm that aligns with observed user behavior, where users often organize information into structured formats like concept maps. This is a significant departure from traditional textual summarization and has the potential to open new avenues of research.
   
2. High-Quality Dataset: The authors present a well-constructed dataset that is both large-scale and diverse, featuring heterogeneous web documents. The dataset creation process is meticulously described, ensuring reproducibility and transparency. The combination of automatic preprocessing, scalable crowdsourcing, and expert annotations is innovative and effective.
3. Crowdsourcing Methodology: The proposed low-context importance annotation scheme is a methodological contribution in itself. The authors demonstrate its reliability through rigorous pilot studies and quality control measures, making it a valuable tool for other annotation tasks.
4. Baseline and Evaluation Protocol: The inclusion of a baseline system and detailed evaluation metrics provides a strong foundation for future work. The proposed metrics, particularly the use of METEOR and ROUGE-2 for concept map evaluation, are thoughtful and appropriate.
Weaknesses
1. Baseline Performance: The baseline system performs poorly, with only 17% of gold-standard concepts included in the final maps and low proposition matching scores. While the authors acknowledge this as a challenge, the lack of a stronger baseline limits the paper's ability to demonstrate the feasibility of the task.
2. Limited Discussion of Limitations: While the paper is comprehensive in its description of the dataset and methodology, it does not sufficiently discuss the limitations of the proposed task or dataset. For instance, the reliance on extractive summarization may constrain the expressiveness of the generated concept maps.
3. Scalability of Expert Annotations: The final step of concept map construction relies heavily on expert annotators, which may not scale well for larger datasets or more diverse topics. This reliance could hinder the widespread adoption of the proposed framework.
4. Generalizability: The dataset focuses on educational topics, which may limit the generalizability of the findings to other domains. A broader range of topics would strengthen the dataset's applicability.
Questions to Authors
1. How do you envision addressing the scalability challenges of expert annotations in the concept map construction step?
2. Have you considered extending the dataset to include non-educational domains to improve generalizability?
3. Could the baseline system be improved by incorporating more advanced techniques, such as neural models for relation extraction or concept ranking?
Recommendation
This paper makes a strong case for the introduction of concept-map-based MDS as a novel and valuable task in NLP. The dataset and methodology are significant contributions, and the work has the potential to inspire future research. However, the weak baseline performance and limited discussion of limitations suggest that the task is still in its early stages of development. I recommend acceptance with minor revisions, focusing on addressing the scalability of expert annotations and providing a more robust baseline system.