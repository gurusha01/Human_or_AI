Review of the Paper
Summary and Contributions
This paper presents a novel approach to relation extraction by reframing it as a reading comprehension task. The authors propose associating natural-language questions with relation slots, enabling the use of neural reading comprehension models for relation extraction. The key contributions of the paper are as follows:
1. Reduction of Relation Extraction to Reading Comprehension: The paper introduces a method to map relations to natural-language questions, allowing the use of reading comprehension models for extracting relation slots.
2. Zero-Shot Learning for Relation Extraction: The approach supports zero-shot learning, enabling the extraction of relations unseen during training by defining them with natural-language questions at test time.
3. Large-Scale Dataset Creation: The authors construct a dataset of over 30 million question-sentence-answer examples using a cost-effective schema querification method, combining distant supervision and crowdsourcing.
4. Model Adaptation for Answerability: The paper extends a state-of-the-art reading comprehension model (BiDAF) to handle unanswerable questions, a critical requirement for relation extraction tasks.
Strengths
1. Innovative Framing of the Problem: The reduction of relation extraction to reading comprehension is a creative and promising approach. It bridges two active research areas and opens up new possibilities for leveraging advances in machine reading.
2. Zero-Shot Generalization: The ability to extract unseen relations by defining them with natural-language questions is a significant contribution, addressing a major limitation of traditional relation extraction systems.
3. Scalable Dataset Creation: The schema querification process is highly efficient, generating a massive dataset at a relatively low cost. This scalability is a notable advantage over instance-level annotation methods.
4. Strong Experimental Results: The proposed method demonstrates competitive performance on unseen entities, unseen question templates, and unseen relations. The results are well-documented, with detailed analyses of error cases and performance breakdowns.
5. Practical Utility: The natural-language API for defining new relations makes the approach accessible to non-experts, increasing its potential for real-world applications.
Weaknesses
1. Limited Generalization to Complex Relations: While the method performs well on simple slot-filling tasks, its ability to handle more complex relations or multi-hop reasoning is not explored. This limits its applicability to more challenging extraction scenarios.
2. Dependence on Question Quality: The approach relies heavily on the quality of the natural-language questions. Although the authors address this with a verification phase, the method may struggle with ambiguous or poorly phrased questions.
3. Evaluation on a Narrow Domain: The experiments are conducted primarily on Wikipedia-based data, which may not generalize well to other domains or less-structured text corpora.
4. Limited Discussion of Limitations: The paper does not sufficiently discuss the limitations of the approach, such as its reliance on pre-trained embeddings and the potential challenges in adapting it to low-resource languages or domains with sparse data.
Questions to Authors
1. How does the method perform on more complex relations that require multi-hop reasoning or contextual understanding beyond a single sentence?
2. Could the approach be extended to handle relations with multiple arguments or nested structures?
3. How robust is the method to noisy or incomplete training data, particularly in real-world scenarios where distant supervision may introduce significant noise?
Additional Comments
The paper is well-written and provides a thorough explanation of the proposed method, dataset creation, and experimental results. However, a deeper exploration of the method's limitations and potential extensions would strengthen the work. Overall, this paper makes a valuable contribution to the fields of relation extraction and machine reading, and it lays a solid foundation for future research in zero-shot learning for information extraction.