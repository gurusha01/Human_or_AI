Review of the Paper
Summary and Contributions
This paper proposes an extension to A* CCG parsing by incorporating dependency information into the parsing process while maintaining efficiency and tractability. The authors introduce a factored probabilistic model that combines supertagging and dependency predictions, leveraging bi-directional LSTMs and biaffine transformations. The model achieves state-of-the-art results on English and Japanese CCG parsing, demonstrating its effectiveness across languages with different syntactic characteristics. The paper also explores dependency conversion strategies and introduces a tri-training approach to improve performance using silver data.
Key contributions of the paper include:
1. Integration of Dependency Information into A Parsing: The paper extends the supertag-factored A parsing framework to include bilexical dependencies, addressing attachment ambiguities without relying on deterministic heuristics.
2. Precomputing Probabilities for Efficiency: The proposed model retains the tractability of A* parsing by precomputing probabilities for both supertags and dependencies, ensuring efficient search.
3. Empirical Insights on Dependency Conversion Rules: The evaluation of different dependency conversion strategies (e.g., HEADFIRST, LEWISRULE) provides valuable insights into their impact on parsing accuracy and normal-form violations.
Strengths
1. Innovative Extension of A Parsing: The integration of dependency information into A parsing is a significant advancement, offering a principled solution to attachment ambiguities while preserving efficiency.
2. Effective Precomputation Technique: The use of precomputed probabilities for both supertags and dependencies is a clever and practical approach that ensures the model remains computationally efficient.
3. Insightful Evaluation of Normal-Form Violations: The analysis of normal-form violations, particularly in relation to the HEADFIRST strategy, is a thoughtful addition that highlights the model's ability to enforce structural constraints implicitly.
4. Cross-Linguistic Evaluation: The inclusion of experiments on Japanese parsing demonstrates the model's adaptability to languages with freer word order, showcasing its broader applicability.
5. State-of-the-Art Results: The model achieves competitive or superior performance compared to existing parsers, particularly in English and Japanese, validating its effectiveness.
Weaknesses
1. Limited Analysis of Specific Dependency Structures: While the paper addresses attachment ambiguities, it lacks a detailed analysis of challenging dependency structures, such as coordination and relative clauses, which could provide deeper insights into the model's strengths and weaknesses.
2. Insufficient Comparison with Other Dependency Parsers: The discussion on how the proposed model reconciles predicate-argument dependencies with those produced by other dependency parsers is underdeveloped. This limits the contextualization of the contributions within the broader parsing landscape.
3. Focus on Constructions with Improvement: The paper could benefit from a more detailed analysis of the constructions where the model achieves significant improvements, particularly in English and Japanese, to better understand the factors driving performance gains.
Questions to Authors
1. Can you provide a more detailed analysis of how the model handles specific challenging dependency structures, such as coordination and relative clauses?
2. How does the proposed dependency representation compare qualitatively with those produced by other state-of-the-art dependency parsers? Are there any notable differences or trade-offs?
3. Could you elaborate on the linguistic or structural factors that contribute to the model's significant improvement in Japanese parsing?
Conclusion
This paper presents a novel and effective extension to A* CCG parsing by integrating dependency information, achieving state-of-the-art results in English and Japanese parsing. While the work is a valuable contribution, further analysis of specific dependency structures and a deeper discussion of the model's relationship to other dependency parsers would strengthen its impact. Overall, the paper is well-executed and merits acceptance.