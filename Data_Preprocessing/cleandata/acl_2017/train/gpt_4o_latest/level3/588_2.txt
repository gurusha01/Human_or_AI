Review of the Paper
Summary and Contributions:
This paper introduces the novel task of rare entity prediction, where models predict missing entities in web documents using both document context and external lexical resources, specifically Freebase definitions. The authors also present a new dataset, the Wikilinks Rare Entity Prediction dataset, which is an augmented version of the Wikilinks dataset. The primary contributions of the paper are:  
1. Task Definition and Dataset: The rare entity prediction task is well-motivated as it addresses the challenge of predicting infrequent entities, which is underexplored in existing reading comprehension tasks. The dataset could serve as a benchmark for evaluating hybrid systems that integrate structured knowledge with unstructured text.  
2. Model Architectures: The paper proposes two models, Double Encoder (DOUBENC) and Hierarchical Double Encoder (HIERENC), which leverage Freebase definitions to improve prediction accuracy. The hierarchical model incorporates document-level context, achieving the best performance.  
3. Empirical Results: The results demonstrate the importance of external knowledge, with the proposed models significantly outperforming baselines that rely solely on context or simplistic use of lexical resources.
Strengths:
1. Novel Task and Dataset: The rare entity prediction task is a meaningful addition to the NLP domain, addressing limitations of existing reading comprehension tasks. The dataset is well-constructed and could serve as a valuable resource for future research on hybrid NLP systems.  
2. Integration of External Knowledge: The paper effectively demonstrates the utility of external knowledge (Freebase definitions) in improving performance on tasks involving rare entities. This highlights the importance of combining structured and unstructured data.  
3. Hierarchical Model: The HIERENC model is a thoughtful extension of the Double Encoder, incorporating document-level context to improve predictions. This approach aligns with the task's requirements and achieves the best results.  
4. Challenging Benchmark: The dataset's focus on rare entities makes it a challenging benchmark, encouraging the development of more sophisticated models.
Weaknesses:
1. Limited Contextual Information: Most models, including the proposed ones, do not fully leverage broader contextual information beyond the immediate sentence. This raises concerns about their ability to generalize to more complex scenarios.  
2. Unconventional Predictors: The use of context-definition similarity as a predictor is unconventional, and its effectiveness is not well-justified. A more detailed comparison with alternative predictors would strengthen the paper.  
3. Unclear Model Description: The description of the HIERENC model is somewhat unclear, particularly regarding the averaging of entity representations. This approach may introduce noise by treating all candidate entities equally, regardless of their relevance.  
4. Lack of Detailed Analysis: The results section lacks a deeper analysis of type-level accuracies or performance variations based on entity frequency. Such insights would provide a better understanding of the models' strengths and weaknesses.  
5. Assumption Validation: The assumption that entity definitions (d_e) are good replacements for entity embeddings is not explicitly tested. This is a critical aspect that should have been validated experimentally.
Questions to Authors:
1. Was the assumption that entity definitions (d_e) are good replacements for entity embeddings explicitly tested? If so, what were the results?  
2. Did you consider using a classifier with h_i^e as inputs instead of relying on context-definition similarity? If not, why was this approach not explored?  
3. Could you provide more clarity on how averaging representations of all candidate entities in HIERENC avoids introducing noise?  
Final Remarks:
While the task and dataset are valuable contributions, the paper has several weaknesses that limit its impact. The lack of clarity in model descriptions, insufficient analysis of results, and untested assumptions reduce the interpretability and generalizability of the findings. Additionally, the dataset would benefit from human evaluation to assess its difficulty and benchmark potential. Overall, the paper introduces an important problem and dataset, but the current results and methodology leave room for improvement.