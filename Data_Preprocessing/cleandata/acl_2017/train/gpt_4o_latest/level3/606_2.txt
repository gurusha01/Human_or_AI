Review of the Submission
Summary and Contributions
This paper introduces the Neural Symbolic Machine (NSM), a novel framework that integrates neural networks with symbolic reasoning for semantic parsing tasks. The primary contributions of the paper are:
1. Novel Use of Discrete, Symbolic Memories: NSM employs a Lisp-based symbolic "computer" to execute programs, which is a significant departure from prior work that relied on differentiable memory. This approach enables scalable and precise operations on large knowledge bases (KBs).
2. Augmented REINFORCE Training Schema: The paper proposes a hybrid training method that combines reinforcement learning (REINFORCE) with iterative maximum likelihood (ML). This innovation improves stability and performance in sequence-to-sequence models trained with weak supervision.
3. State-of-the-Art Results on WEBQUESTIONSSP: The model achieves impressive performance on the WEBQUESTIONSSP dataset, significantly narrowing the gap between weak and full supervision approaches. The scale of experiments and the results are commendable.
Strengths
1. Novelty and Effectiveness: The use of symbolic memories for program execution is a novel and impactful contribution. It addresses scalability and compositionality challenges in semantic parsing, which are critical for large-scale KBs like Freebase.
2. Innovative Training Approach: The augmented REINFORCE method is well-motivated and demonstrates clear benefits over standard REINFORCE and iterative ML. The empirical results validate its effectiveness.
3. Comprehensive Experiments: The paper conducts large-scale experiments, outperforming the state-of-the-art on WEBQUESTIONSSP without requiring feature engineering or domain-specific knowledge. The ablation studies and error analysis provide valuable insights.
4. Clarity of Writing: The paper is generally well-written, with clear explanations of the model architecture and training procedure. The inclusion of figures and tables aids understanding.
Weaknesses
1. Dataset Choice: The use of WEBQUESTIONSSP, rather than the more widely used WEBQUESTIONS dataset, limits the ability to compare results with mainstream QA research. This choice could reduce the broader impact of the work.
2. Limited Analysis of Compositional Depth: The paper lacks a detailed analysis of how NSM handles questions with varying levels of compositional complexity, especially multi-hop queries. This is a critical aspect of semantic parsing that warrants further exploration.
3. Missing Citations: The paper omits references to relevant prior work, such as RL-based semantic parsing and sequence-level REINFORCE methods. This oversight diminishes the contextualization of the contributions.
4. Random Initialization in REINFORCE: The decision to initialize REINFORCE randomly, rather than using pre-trained parameters, raises questions about the efficiency and convergence of the training process.
5. Unclear Role of KG Server in Figure 5: The role and functionality of the KG server in the system architecture are not adequately explained, leaving a gap in understanding the implementation.
Questions to Authors
1. Why was WEBQUESTIONSSP chosen over WEBQUESTIONS, and how does this choice impact the generalizability of the results?
2. Could you provide more analysis on how NSM performs on questions with varying compositional depth, particularly multi-hop queries?
3. What motivated the decision to randomly initialize REINFORCE rather than using pre-trained parameters? How does this impact training efficiency?
4. Can you clarify the role of the KG server in Figure 5? How does it interact with the decoders and trainer?
Recommendation
This paper presents a strong contribution to the field of semantic parsing and program induction, with novel ideas and state-of-the-art results. However, the weaknesses, particularly the dataset choice and limited compositional analysis, slightly temper its impact. I recommend acceptance with minor revisions, contingent on addressing the questions and weaknesses outlined above.