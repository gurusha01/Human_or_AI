Review of the Paper
Summary and Contributions
This paper introduces a novel deep Convolutional Neural Network (CNN) framework that integrates cognitive features derived from eye-movement data with traditional textual features for sentiment analysis and sarcasm detection. The primary contribution of the work is the automatic extraction of cognitive features from gaze data, eliminating the need for manual feature engineering. The proposed framework demonstrates improved classification performance over existing systems that rely on handcrafted features and CNNs using only textual inputs. The authors validate their approach on publicly available datasets enriched with gaze information, showing statistically significant improvements in sentiment analysis and moderate gains in sarcasm detection. The paper also provides a detailed analysis of the learned features, offering insights into how gaze data complements textual information in capturing linguistic subtleties.
Strengths
1. Novelty and Innovation: The integration of automatically learned cognitive features with textual features using CNNs is a novel approach. The work addresses the limitations of manual feature extraction in cognitive NLP systems, which is a significant advancement.
2. Performance Improvements: The proposed framework achieves notable improvements in sentiment classification, with a maximum F-score gain of 3.8% over existing systems and 5% over text-only CNNs. These results are statistically significant and demonstrate the utility of gaze data.
3. Comprehensive Evaluation: The authors conduct experiments on multiple datasets and compare their results with both traditional feature-based systems and state-of-the-art CNN models. This thorough evaluation strengthens the validity of their claims.
4. Insightful Analysis: The paper includes an analysis of the learned features, providing evidence that gaze data helps capture linguistic subtleties, particularly in sarcastic and semantically complex texts.
Weaknesses
1. Data Limitations: The reliance on datasets with gaze data raises concerns about replicability and scalability. Eye-tracking data is not readily available for most NLP tasks, limiting the practical applicability of the proposed framework.
2. Limited Impact on Sarcasm Detection: While the framework improves sarcasm detection over traditional systems, the gains from incorporating gaze data are marginal (1.36%) and statistically insignificant. This suggests that the model's effectiveness in this task may be limited.
3. Insufficient Explanation of Gaze Data Utility: The paper lacks a detailed explanation of why and how specific gaze features (e.g., fixation duration, saccades) contribute to sarcasm and sentiment classification. This makes it difficult to assess the broader applicability of the approach.
Questions to Authors
1. How does the model handle sarcastic utterances that lack explicit textual or gaze-based cues? Can you provide examples where the gaze data significantly influenced the classification decision?
2. Given the limited availability of gaze-enriched datasets, how do you envision scaling this approach to tasks where such data is unavailable? Could synthetic gaze data or transfer learning be viable alternatives?
3. Can you elaborate on the specific contributions of fixation and saccade channels in sarcasm detection? Why does the multichannel gaze configuration underperform in some cases?
Recommendation
The paper presents a novel and promising approach to combining cognitive and textual features for sentiment and sarcasm classification. However, the limited availability of gaze data and the marginal gains in sarcasm detection temper its broader applicability. Addressing these limitations and providing further clarification on the utility of gaze features could strengthen the paper. I recommend acceptance with minor revisions.