Review of Submission
Summary and Contributions
This paper introduces a novel LDA-based model, segLDAcop, which jointly segments documents into topically coherent segments and assigns topics to words within these segments. The model innovatively incorporates a copula-based mechanism to ensure topic coherence within segments and introduces both document-specific and segment-specific topic distributions to capture fine-grained topic variations. The authors claim that their model subsumes prior LDA-based approaches and achieves state-of-the-art performance on multiple datasets in terms of perplexity, topic coherence (NPMI), and text classification (Micro F1). The key contributions of this work, as I see them, are:
1. The integration of copulas to bind topics within segments, ensuring topical coherence.
2. The joint segmentation and topic assignment mechanism, which allows for flexible, data-driven segmentation without reliance on external tools.
3. The efficient segment sampling method with O(M) complexity, which is crucial for scalability and practical applicability.
Strengths
1. Novelty and Technical Contribution: The use of copulas to enforce topic coherence within segments is a novel and well-motivated idea. The model's ability to simultaneously segment and assign topics is a significant advancement over prior work that relies on predefined or fixed segmentations.
2. Efficient Computation: The proposed segment sampling method with O(M) complexity is a strong technical contribution, addressing computational challenges inherent in segmentation-based topic models.
3. Comprehensive Experiments: The paper evaluates the model on six diverse datasets and demonstrates consistent improvements in perplexity, NPMI, and Micro F1 compared to baseline methods. The results convincingly establish the superiority of the proposed approach.
4. Clarity and Structure: The paper is well-written and logically structured. The Abstract and Introduction sections provide clear intuition, and the Related Work section situates the contribution effectively within the literature.
Weaknesses
1. Visualization and Interpretability: The visualization of topic assignments and segmentations (e.g., Figure 5) is weaker compared to prior work (e.g., Balikas COLING16). The use of longer exemplars and consistent color assignments would improve interpretability and confidence in the results.
2. Model Flexibility and Underfitting: While the model's flexibility is a strength, it may also lead to underfitting in certain cases. The authors should provide a more detailed discussion or empirical analysis of how the model balances flexibility with robustness.
3. Computational Efficiency: Although the segment sampling method is efficient, the overall training process may still be computationally intensive. Exploring faster inference methods, such as Variational Inference, could make the model more scalable for large datasets.
Questions to Authors
1. How does the model handle cases where segment-specific topics dominate over document-specific topics, or vice versa? Is there a mechanism to balance these distributions dynamically?
2. Can you provide additional examples or case studies to illustrate the interpretability of the generated segments and topics?
3. Have you considered using Variational Inference for faster training? If so, how would it compare to Gibbs sampling in terms of performance and scalability?
Recommendation
This paper presents a significant contribution to the field of topic modeling by introducing a novel segmentation and topic assignment framework. While there are minor concerns regarding visualization and computational efficiency, the strengths far outweigh the weaknesses. I recommend acceptance with minor revisions to address the interpretability and efficiency concerns.