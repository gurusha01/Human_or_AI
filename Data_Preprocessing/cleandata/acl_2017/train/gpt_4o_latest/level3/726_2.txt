Review of the Paper
Summary and Contributions
This paper introduces an attention-based RNN model for directly generating SQL queries from natural language, bypassing intermediate representations. The proposed approach leverages iterative crowd annotation and user feedback for data augmentation, enabling rapid deployment and continuous improvement of semantic parsers in new domains. The authors demonstrate their method's effectiveness through experiments on benchmark datasets (GeoQuery and ATIS) and a live user study in the academic domain. A new dataset, SCHOLAR, is also released, containing natural language utterances paired with SQL queries.
The primary contributions of the paper are:
1. Direct SQL Generation: The model avoids intermediate representations, directly mapping natural language to SQL, which is a significant step toward reducing domain-specific engineering.
2. Feedback-Driven Learning: The iterative learning framework integrates user feedback and crowd annotations to improve the model over time, showcasing a practical and scalable approach to semantic parsing.
3. Dataset Release: The release of the SCHOLAR dataset provides a valuable resource for the community, facilitating further research in natural language interfaces to databases.
Strengths
1. Avoidance of Intermediate Representations: The direct mapping to SQL is a notable strength, as it simplifies the pipeline and leverages SQL's expressivity. This approach reduces the need for specialized meaning representations, making the method more generalizable.
2. Data Augmentation and Feedback Loop: The use of schema templates, paraphrasing, and iterative user feedback is innovative and demonstrates promise in reducing annotation efforts while improving model accuracy over time.
3. Practical Deployment: The live user study and the demonstration of the model's ability to learn from scratch in a new domain highlight the practicality of the approach.
4. Dataset Contribution: The release of the SCHOLAR dataset on Google Scholar is a valuable addition to the field, providing a benchmark for future research.
Weaknesses
1. Unsupported Claims of Near-SOTA Performance: The paper claims near-state-of-the-art (SOTA) performance but does not provide competitive results on benchmark datasets like GeoQuery and ATIS. For example, the model achieves 82.5% accuracy on GeoQuery, which is below the 89.3% reported by Jia and Liang (2016).
2. Lack of Clarity in Key Terms: The term "minimal intervention" is ambiguous and requires clarification. It is unclear whether this refers to reduced engineering, annotation effort, or both.
3. Incomplete Analysis: The paper does not adequately analyze the 48% of user questions that could not be generated during the live experiment. Understanding these cases could provide insights into the model's limitations.
4. Unexplained Performance Dips: Figure 3 shows sharp dips in performance around the 8th and 9th stages of the simulated experiments, which are not explained in the text.
5. Crowd Worker Expertise: The expertise level of the crowd workers annotating SQL queries is not specified, raising concerns about the quality and consistency of the annotations.
Questions to Authors
1. Could you clarify what is meant by "minimal intervention"? Does this refer to reduced feature engineering, annotation effort, or something else?
2. Can you provide a breakdown of correctness vs. incompleteness in Table 6 to better understand the types of errors users encountered?
3. What expertise level was required of the crowd workers who annotated SQL queries? Were they trained in SQL or provided with guidelines?
4. Why do the performance curves in Figure 3 exhibit sharp dips around the 8th and 9th stages? Could this be related to specific characteristics of the data or the feedback loop?
5. In Table 4, what splits were used for the ATIS dataset, and how do they compare to prior work?
Recommendation
The paper makes significant contributions to the field of semantic parsing, particularly in its direct SQL generation approach and feedback-driven learning framework. However, the unsupported claims of near-SOTA performance and the lack of clarity in key areas weaken its overall impact. I recommend acceptance with minor revisions, provided the authors address the concerns regarding their claims, clarify ambiguous terms, and provide additional analysis of their results.