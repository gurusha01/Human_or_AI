Review of the Paper
Summary and Contributions:
This paper introduces a novel method for improving lexical substitution rankings by leveraging word sense inventories. The authors propose a multi-view clustering approach to group paraphrases into substitutable sense clusters, incorporating various views such as context substitutability, paraphrase similarity, shared translations, and WordNet synsets. The resulting clusters are used as filters to enhance the performance of existing lexical substitution models. The paper demonstrates that their method improves substitutability metrics and achieves better lexical substitution rankings compared to baseline sense inventories like WordNet and TWSI.
The primary contributions of the paper are:
1. A novel multi-view clustering algorithm tailored for lexical substitutability, which integrates diverse representations of paraphrase relationships.
2. A substitutability-focused evaluation metric (B-Cubed F-Score) to assess the quality of sense clusters.
3. An application of the proposed sense clusters as filters to improve the rankings of existing lexical substitution models, with demonstrated improvements in GAP scores.
Strengths:
1. Novelty in Methodology: The multi-view clustering approach is innovative and effectively combines multiple perspectives to generate substitutable sense clusters. The use of substitutability as a guiding principle is well-motivated and addresses a gap in prior work.
2. Improved Performance: The proposed method outperforms existing sense inventories in substitutability metrics and lexical substitution tasks, as evidenced by higher Oracle and Best-Fit GAP scores.
3. Scalability and Generalizability: The method is designed to scale across different parts of speech and languages, making it broadly applicable in NLP tasks.
4. Comprehensive Evaluation: The paper provides thorough experimental results, comparing the proposed method against multiple baselines and analyzing performance across different parts of speech.
Weaknesses:
1. Limited Broader Impact: While the method improves lexical substitution rankings, the paper does not convincingly demonstrate its practical utility in real-world NLP applications. Given the dominance of continuous word representations in modern NLP systems, the relevance of lexical substitutability as a standalone task is questionable.
2. Motivation Issues: The reliance on outdated references and small-scale datasets (e.g., CoInCo) undermines the paper's relevance to contemporary NLP challenges. The authors fail to address why lexical substitutability remains important in the context of transformer-based models.
3. Subjectivity in Task Definition: Lexical substitutability is inherently subjective, as substitutes may alter sentence semantics. For example, the distinction between "paper" and "sheet" in Table 1 highlights the ambiguity in defining "good" substitutes.
4. Missing Citations: Section 3.1.4 lacks citations for prior work on translation-based sense clustering, which weakens the paper's scholarly rigor.
Final Evaluation:
While the paper introduces a novel and technically sound method for clustering paraphrases by sense, its broader impact and practical relevance to modern NLP are limited. The task of lexical substitutability, as framed in this work, appears somewhat disconnected from current trends in NLP, where contextualized embeddings and transformer-based models dominate. The authors should better articulate the motivation and end applications of their work to strengthen its case for acceptance. Additionally, addressing the subjectivity inherent in lexical substitutability and providing missing citations would improve the paper's overall quality.
Questions to Authors:
1. How does the proposed method compare to transformer-based models like BERT or GPT in tasks involving contextual word substitutions?
2. Can the authors provide concrete examples of real-world NLP applications where their method outperforms existing approaches?
3. How does the method handle cases where multiple senses of a word are equally valid in a given context?
Recommendation:
Borderline Reject: While the paper offers a novel method and demonstrates technical improvements, its limited practical relevance and unclear motivation reduce its overall impact. Addressing these concerns could make the work more compelling for future submissions.