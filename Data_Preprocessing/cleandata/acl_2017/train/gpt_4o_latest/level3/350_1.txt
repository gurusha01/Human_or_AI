Review of Submission
Summary and Contributions
This paper presents a rule-based approach for automatically labeling training data for large-scale event extraction (EE) using a combination of world knowledge (Freebase) and linguistic knowledge (FrameNet). The proposed method involves three stages: identifying key arguments using Freebase, detecting and refining trigger words using FrameNet, and employing a soft distant supervision (SDS) framework to generate labeled data. The authors demonstrate that the resulting dataset achieves competitive quality compared to human-annotated data and significantly improves the performance of EE models when combined with existing datasets. The primary contributions of the paper are:
1. A novel pipeline for generating large-scale labeled EE data by combining Freebase and FrameNet.
2. A demonstration that the automatically labeled data can augment human-annotated datasets to improve EE performance.
3. The release of a large-scale labeled dataset and a baseline model (DMCNN-MIL) for further research.
Strengths
1. State-of-the-Art Results: The proposed method achieves state-of-the-art results on a non-trivial benchmark, demonstrating its practical utility for improving EE systems. The experiments show that the automatically labeled data can effectively augment human-annotated datasets, improving both trigger and argument identification.
2. Scalability and Practicality: The approach addresses a critical bottleneck in EE—limited annotated data—by automating the labeling process. This scalability makes it potentially applicable to other domains where labeled data is scarce.
3. Comprehensive Evaluation: The paper provides both manual and automatic evaluations of the labeled data, demonstrating its quality and utility. The inclusion of a baseline model (DMCNN-MIL) further strengthens the reproducibility and practical relevance of the work.
4. Well-Written and Organized: The paper is well-structured and clearly explains the methodology, experiments, and results. The inclusion of detailed examples and ablation studies enhances the reader's understanding.
Weaknesses
1. Limited Novelty: While the combination of Freebase and FrameNet is effective, the individual components (e.g., distant supervision, multi-instance learning) are well-established techniques. The novelty of the method lies primarily in its integration of existing resources rather than introducing fundamentally new ideas.
2. Generalizability Concerns: The selection process for event types and key arguments from Freebase and ACE datasets is not sufficiently justified. It is unclear how well the method generalizes to other domains or event types not covered in the current experiments.
3. Manual Effort in Mapping: The reliance on manual mapping of event types between Freebase and ACE datasets introduces subjectivity and limits reproducibility. This could hinder comparisons with future work.
4. Reproducibility Challenges: The method requires significant manual effort for mapping event types and relies on external resources like FrameNet and Freebase, which may evolve or become unavailable over time.
Questions to Authors
1. Can the proposed method be extended to handle event types not covered by Freebase or FrameNet? If so, how?
2. How sensitive is the method to the choice of hyperparameters (e.g., the number of key arguments, trigger rate thresholds)?
3. Could the authors provide more details about the manual mapping process between Freebase and ACE datasets? Is there a systematic way to automate this step?
Additional Comments
- The paper could benefit from minor clarifications, such as elaborating on the limitations of the proposed approach and potential future directions.
- Typographical errors and formatting inconsistencies should be addressed in the final version.
Recommendation
While the paper lacks significant novelty, its practical contributions and strong experimental results make it a valuable addition to the field. I recommend acceptance with minor revisions to address the concerns about generalizability and reproducibility.