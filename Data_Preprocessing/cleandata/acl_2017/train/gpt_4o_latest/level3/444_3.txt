Review of Submission
Summary and Contributions  
The paper proposes a methodology for evaluating automatically generated rap lyrics, aiming to assess fluency, coherence, and stylistic similarity to a target artist. The authors introduce both manual and automated evaluation techniques, including a line-by-line annotation scheme for fluency and coherence, and automated metrics like rhyme density and tf-idf-based similarity. The paper also presents a dataset of rap lyrics from 13 artists, annotated for style matching, which can serve as a resource for future work. The authors claim that their evaluation methodology provides a comprehensive foundation for analyzing the performance of generative models in the domain of rap lyric ghostwriting.
The primary contributions of the paper are:  
1. A manual evaluation methodology that decomposes fluency and coherence into line-level annotations, enabling fine-grained assessments of generated verses.  
2. An automated evaluation methodology that integrates rhyme density and tf-idf similarity, with improvements to handle repetitive text.  
3. A publicly available dataset annotated for stylistic similarity, which can serve as a benchmark for future research.  
Strengths  
1. Comprehensive Evaluation Framework: The paper addresses the multifaceted nature of evaluating creative text generation by combining manual and automated metrics. This is a significant step forward compared to prior work, which often focused on isolated aspects like fluency or rhyming.  
2. Public Dataset and Benchmark: The annotated dataset of rap lyrics from 13 artists is a valuable contribution to the research community, offering a resource for future studies on stylistic text generation.  
3. Insightful Analysis: The paper provides a detailed analysis of the limitations of current generative models, such as the LSTM's inability to integrate new vocabulary effectively, and highlights the need for complementary evaluation metrics.  
Weaknesses  
1. Unreliable Manual Evaluation: The low inter-annotator agreement (IAA) for coherence (0.43) and style matching raises concerns about the reliability of the manual evaluation methodology. This undermines the validity of the proposed metrics as a benchmark for future work.  
2. Misalignment Between Automated and Human Evaluations: The automated metrics, particularly rhyme density and tf-idf similarity, fail to reliably align with human judgments of fluency, coherence, and style. This limits their utility as proxies for human evaluation.  
3. Scope of Coherence Evaluation: The line-by-line evaluation of coherence is overly restrictive and fails to capture the broader narrative or thematic coherence of an entire verse, which is crucial in rap lyrics.  
4. Terminology Issues: The term "style matching" is misleading, as many artists produce work in multiple styles. "Artist matching" would be a more accurate descriptor.  
5. Lack of Clarity in Experimental Setup: The paper does not specify the number of human judges used for manual evaluation or whether they were familiar with the target artists' work. This lack of transparency could introduce bias or inconsistencies in the evaluation.  
Questions to Authors  
1. How were the human annotators selected, and what measures were taken to ensure their familiarity with the target artists' styles?  
2. Why was coherence evaluated at the line level rather than at the verse level, and how does this limitation affect the validity of the results?  
3. Could you clarify how the automated metrics were validated against human evaluations, given the observed misalignment?  
Conclusion  
While the paper makes notable contributions in proposing a comprehensive evaluation methodology and providing a valuable dataset, it falls short in achieving its stated goals due to issues with reliability, alignment, and scope. The low IAA and misalignment between automated and human evaluations are significant weaknesses that undermine the validity of the proposed metrics. Additionally, the line-by-line coherence evaluation and ambiguous experimental setup limit the generalizability of the findings. The paper provides a useful starting point for future work but requires substantial revisions to address these concerns.