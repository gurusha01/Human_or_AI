Review of the Paper
Summary and Contributions  
This paper presents a novel approach for rapidly building natural language interfaces to databases (NLIDBs) that map user utterances directly to SQL queries without requiring intermediate representations or extensive domain-specific engineering. The proposed method leverages neural sequence-to-sequence models, data augmentation techniques, and an interactive feedback loop to iteratively improve performance over time. The key contributions of the paper are:  
1. The development of a feedback-based learning framework that enables semantic parsers to improve iteratively with minimal intervention.  
2. The release of a new semantic corpus (SCHOLAR) for academic database queries and the conversion of two benchmark datasets (GEO880 and ATIS) to SQL format, which will benefit future research.  
3. The demonstration of the system's effectiveness across three domains (academic, geographic, and flight booking) and in a live interactive learning setting.  
Strengths  
1. Clarity and Presentation: The paper is well-written, clearly structured, and enjoyable to read. The authors effectively position their work within the broader context of semantic parsing and NLIDBs.  
2. Performance Across Domains: The model achieves competitive performance on GEO880 and ATIS datasets, demonstrating its robustness and generalizability. The small-scale online experiment for the academic domain further validates the approach.  
3. Interactive Feedback Loop: The proposed feedback loop is promising, showcasing the potential for real-time improvement with user interaction. This is particularly valuable for deploying NLIDBs in new domains with minimal labeled data.  
4. Resource Contribution: The release of the SCHOLAR dataset and the SQL-formatted versions of existing corpora is a significant contribution to the community, enabling reproducibility and further research.  
Weaknesses  
1. Entity Anonymization: The rationale for progressively reducing the span length during entity anonymization (Section 4.2) is not clearly explained, which could impact the reproducibility of this component.  
2. Data Augmentation Details: The timing and specifics of data augmentation in the benchmark experiments (Section 5) are unclear, leaving questions about its impact on performance.  
3. Evaluation Metrics: The evaluation metrics in Tables 2 and 3 are ambiguous, and the comparison between SQL and non-SQL results requires further clarification.  
4. Scalability Concerns: The SCHOLAR dataset is relatively small, and its scalability to larger datasets or more complex domains is not adequately discussed.  
5. Interactive Learning Limitations: The lack of objective comparison metrics and details about the three-stage online experiment (e.g., user demographics, query statistics, and dataset size) makes it difficult to assess the broader applicability and replicability of the interactive learning framework.  
6. Data Recombination Technique: The applicability of the data recombination method from Jia and Liang (2016) is mentioned but not explored, which could have strengthened the results.  
Minor Comments  
- Typographical errors: "requires" should be "require" (Line 48), and "Is is" should be "It is" (Line 218).  
- Footnote 1 is excessively long and would be better integrated into the main text.  
- Algorithm 1's caption needs clarification, and "new utterances" should be explicitly defined.  
- A forward reference to anonymization in Line 278 would improve readability.  
Conclusion  
Overall, this paper makes a strong contribution to the field of semantic parsing and NLIDBs by proposing a novel feedback-based learning framework and releasing valuable resources. While the paper has some weaknesses, particularly in clarifying certain methodological details and addressing scalability, these issues are not insurmountable. I recommend acceptance of this paper, contingent on the authors addressing the raised questions and providing additional clarifications in the final version.