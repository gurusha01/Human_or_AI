Review
Summary and Contributions
This paper presents a novel approach to extending word embedding methods by incorporating ontology-based identifiers for phrases and concepts. The proposed method involves creating a "tagged" corpus by replacing phrases and words with concept identifiers and appending it to the original corpus. The embeddings are trained using a modified skip-gram model, and the approach is evaluated in the biomedical domain using corpora like PubMed and clinical notes, as well as ontologies such as UMLS and YAGO. Additionally, the authors introduce a new dataset for evaluating word similarity and relatedness for real-world entities.
The primary contributions of this work are:
1. Introduction of a novel test dataset for real-world entity similarity and relatedness, which fills a gap in existing resources and has potential for broader applications.
2. A scalable method for embedding concepts, phrases, and words jointly, which does not require manual annotation and achieves competitive performance on biomedical similarity and relatedness tasks.
3. Empirical evaluation of embeddings across multiple datasets, demonstrating the ability to preserve semantic relationships and clustering of similar concepts.
Strengths
1. Novel Dataset Contribution: The introduction of a new dataset for real-world entity similarity and relatedness is a significant contribution. It addresses a gap in existing resources and could be valuable for future research in both general and domain-specific semantic tasks.
2. Scalability and Automation: The proposed method eliminates the need for manual annotation, making it highly scalable. This is particularly beneficial for domains like biomedicine, where manual annotation is costly and time-consuming.
3. Competitive Performance: The embeddings achieve results comparable to state-of-the-art methods on biomedical similarity and relatedness tasks, despite using distant supervision. This demonstrates the effectiveness of the approach.
4. Well-Written Paper: The paper is clear and well-structured, making it easy to follow the methodology and experimental results.
Weaknesses
1. Limited Scope: The evaluation is restricted to the biomedical domain, which limits the generalizability of the method. While the authors include YAGO for general-domain concepts, the focus remains heavily domain-specific.
2. Substantial Contribution Questionable: The method, while novel in its combination of techniques, does not represent a significant leap in methodology. The approach builds naturally on existing work, and its novelty lies more in its application and evaluation than in the core technical contribution.
3. Technical Issue in Equation 8: The MAP calculation incorrectly refers to a probability, which needs clarification. This could impact the validity of the results presented in the compositionality analysis.
4. Compositionality Tradeoff: The high similarity between concepts and their representative phrases suggests that the embeddings may not fully capture non-lexical information about concepts. This limits the method's ability to model more abstract semantic relationships.
5. Minor Grammatical Error: The phrase "most concepts has" should be corrected to "most concepts have."
Questions to Authors
1. Can you clarify the issue in Equation 8 regarding the MAP calculation? Specifically, how does this affect the reported results in Section 5.5?
2. Have you considered evaluating the embeddings on downstream tasks (e.g., entity linking or analogy completion) to provide stronger evidence of their utility beyond similarity and relatedness tasks?
3. How does the method perform when applied to general-domain corpora without biomedical ontologies? Could this approach generalize to other domains with less structured ontologies?
Recommendation
While the paper makes a meaningful contribution, particularly with the new dataset, the limited scope and incremental nature of the method reduce its overall impact. The technical issue in Equation 8 also raises concerns that should be addressed. I recommend acceptance with minor revisions, contingent on clarifying the MAP calculation and providing additional discussion on the generalizability of the method.