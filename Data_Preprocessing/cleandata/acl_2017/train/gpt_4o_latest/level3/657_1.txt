Review of the Paper
Summary and Contributions:
This paper addresses the problem of interpreting LSTM models in the context of categorizing written justifications in values-affirmation essays. It introduces a hypothesis-driven approach inspired by experimental psychology to analyze the sequential class probabilities emitted by the LSTM model. The authors aim to uncover gender-specific linguistic patterns in essay justifications, linking these patterns to sociological and psychological theories of gendered self-construal. The primary contributions of the paper, as I see them, are:
1. Application of Experimental Psychology to LSTM Interpretability: The paper proposes a novel approach to interpreting LSTM models by treating them as input-output devices and systematically crafting stimuli to probe their learned representations. This is an interesting methodological contribution that could inspire further work in model interpretability.
   
2. Exploration of Linguistic Patterns in Values-Affirmation Essays: The study provides a preliminary exploration of gender-specific linguistic patterns in the context of values-affirmation essays, a relatively underexplored area in psychological and educational research.
3. Comparison of LSTM and SVM Interpretability: The authors attempt to validate their interpretability approach by correlating LSTM token probability shifts with SVM coefficients, offering a baseline comparison.
Strengths:
1. Novel Problem Framing: The paper tackles the intriguing problem of interpreting LSTMs in a psychologically motivated context, which is a novel and interdisciplinary contribution.
   
2. Methodological Innovation: The hypothesis-driven approach to probing LSTM outputs is a creative adaptation of experimental psychology methods, which could be generalized to other interpretability tasks.
3. Educational Relevance: The focus on values-affirmation essays and their potential links to academic outcomes is a meaningful application, with implications for educational interventions.
Weaknesses:
1. Clarity of Goals: The paper oscillates between two objectives—interpreting LSTMs and validating sociological assumptions—without clearly defining or prioritizing either. This lack of focus dilutes the impact of the work and makes it difficult to assess its primary contribution.
2. Unsupported Claims: The claim that gender differences in essay justifications align with theories of gendered self-construal is not adequately supported by the data. The evidence presented is weak (e.g., modest probability shifts, low correlations) and does not robustly validate the hypothesis.
3. Weak Validation of Interpretability: The correlation between LSTM token probability shifts and SVM coefficients is low (ranging from 0.32 to 0.43) and insufficient to establish the interpretability of the LSTM model. The authors fail to provide a compelling argument for why these correlations are meaningful.
4. Insufficient Methodological Details: The explanation of the multilevel Bayesian models used to analyze gender-based self-construal is sparse, making it difficult to assess the appropriateness and robustness of this methodology.
5. Ambiguity in Psychological Queries: While the crafted stimuli approach is interesting, the results are inconclusive, with weak evidence for gender-specific patterns. The posterior distributions for key comparisons (e.g., other-focused justifications) show minimal effects, undermining the claims.
Questions to Authors:
1. Could you clarify whether the primary goal of the paper is to interpret LSTM models or to validate sociological assumptions? How do you envision these two objectives complementing each other?
2. How do you justify the low correlation values between LSTM token probability shifts and SVM coefficients as evidence of interpretability? Would alternative validation methods strengthen your argument?
3. Could you provide more details on the multilevel Bayesian models, including priors, convergence diagnostics, and why this approach was chosen over simpler alternatives?
Recommendation:
While the paper introduces a novel and interdisciplinary approach to LSTM interpretability, its lack of clarity in goals, weak validation of claims, and insufficient methodological rigor limit its impact. I recommend rejection at this stage, but I encourage the authors to refine their focus, strengthen their validation methods, and provide more robust evidence for their claims in a future submission.