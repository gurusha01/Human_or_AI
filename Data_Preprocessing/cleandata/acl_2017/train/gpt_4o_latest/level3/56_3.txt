Review
Summary and Contributions
This paper extends traditional word embedding methods by incorporating bigram-bigram co-occurrence statistics, aiming to capture richer syntactic and semantic information. The authors adapt four popular embedding models—SGNS, GloVe, PPMI, and SVD—to include ngram co-occurrences, and propose a computationally efficient algorithm to handle the increased computational burden of large co-occurrence matrices. The paper claims that the inclusion of bigrams improves embeddings' performance on word analogy and similarity tasks and provides qualitative evidence of the utility of bigram embeddings in capturing linguistic patterns like antonyms, collocations, and syntactic structures. The authors also release their implementation as the "ngram2vec" toolkit.
Strengths
1. Natural Extension of Existing Methods: The paper builds on well-established embedding techniques, making the integration of bigrams a logical and intuitive step. This extension has the potential to capture richer linguistic information, as demonstrated by qualitative evaluations.
2. Computational Efficiency: The proposed algorithm for constructing ngram co-occurrence matrices is a valuable contribution. By combining "mixture" and "stripes" strategies, the authors significantly reduce the computational and memory overhead, enabling the use of ngram-based embeddings on modest hardware.
3. Qualitative Insights: The qualitative evaluation of bigram embeddings is compelling. The examples provided (e.g., antonyms, syntactic patterns) demonstrate the embeddings' ability to capture nuanced linguistic relationships.
Weaknesses
1. Lack of Quantitative Evaluation on Relevant Tasks: While the paper demonstrates improvements on analogy and similarity tasks, it does not evaluate the bigram embeddings on tasks where they would be most relevant, such as paraphrasing, sentiment analysis, or text classification. This omission limits the practical impact of the proposed method.
2. Inconsistent and Statistically Insignificant Results: The quantitative results across different datasets and models are inconsistent. For example, while SGNS benefits significantly from bigram integration, GloVe and SVD show only minor or negligible improvements. Furthermore, the paper does not report statistical significance for many of the observed improvements, raising concerns about their robustness.
3. Writing Quality: The paper suffers from numerous grammar and spelling issues, which detract from its readability and professionalism. Significant editing is required to improve clarity and presentation.
4. Limited Exploration of Hyperparameters: The authors acknowledge that the hyperparameters were not optimized for the ngram-based models. This lack of tuning may have contributed to the underwhelming performance of some methods (e.g., GloVe, SVD) and should have been addressed more thoroughly.
Open Questions to Authors
1. Could you provide more details on the differences between overlap and non-overlap cases? How do these differences manifest in the learned embeddings, and why do they lead to varying performance across tasks?
2. Why were tasks like paraphrasing or sentiment analysis not included in the evaluation? These tasks seem more directly relevant to the proposed bigram embeddings.
3. Have you considered extending the method to higher-order ngrams (e.g., trigrams)? If so, what challenges or trade-offs do you anticipate?
Recommendation
The paper presents a promising extension to existing word embedding methods and introduces a computationally efficient algorithm for handling ngram co-occurrence matrices. However, the lack of quantitative evaluation on relevant tasks, inconsistent results, and writing issues significantly weaken the submission. I recommend a major revision to address these concerns, particularly the need for more robust evaluations and improved writing quality.