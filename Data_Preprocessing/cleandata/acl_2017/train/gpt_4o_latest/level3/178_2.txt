Review of the Paper
Summary and Contributions
This paper introduces a method for embedding words, phrases, and concepts into a shared vector space by leveraging an ontology of concepts and adapting the skip-gram model. The primary contribution is the proposal of a framework that enables the joint embedding of these linguistic units without requiring manual annotation, relying instead on distant supervision. The authors demonstrate competitive performance on concept similarity and relatedness tasks, particularly in the biomedical domain, and release a software implementation, cui2vec, alongside a novel dataset for real-world entity similarity and relatedness. The work addresses the challenge of representing semantically similar but lexically dissimilar phrases and non-compositional phrases, which are common in biomedical and general-domain corpora.
Strengths
1. Addressed Problem: The paper tackles an important issue in natural language processing (NLP)â€”the representation of semantically close but lexically dissimilar phrases and non-compositional phrases. The proposed method shows competitive performance on concept similarity tasks, particularly on larger datasets, and highlights the importance of integrating structured knowledge into embedding models.
2. Practical Utility: The released software, cui2vec, and the accompanying dataset are valuable contributions to the NLP community, especially for biomedical researchers. These resources can facilitate further research and applications in concept representation and related tasks.
3. Scalability: The method scales to a significantly larger vocabulary compared to prior approaches that rely on human annotation, demonstrating its potential for broader applicability.
Weaknesses
1. Limited Novelty: The proposed model is a relatively minor modification of the skip-gram method, with the primary innovation being the incorporation of ontology-based supervision. While this adaptation is useful, it lacks significant methodological novelty compared to existing embedding techniques.
2. Performance Issues: The model underperforms on key datasets compared to simpler baselines, such as the Choi and Chiu models. This raises concerns about the practical benefits of the proposed approach, especially given its complexity.
3. Ambiguity in Terminology and Experimental Setup: The term "distant supervision" is used ambiguously, deviating from its traditional definition. Additionally, the explanation of how phrase/word vectors are used to compute concept similarities in Table 4 is unclear, making it difficult to fully assess the experimental results.
4. Ontology Redundancy: Results in Table 5 suggest that the ontology may not be necessary, as approximating concepts with phrase averages achieves better performance. This undermines the core premise of the paper.
5. Unused Notation and Surprising Parameter Choices: Notation introduced in Section 3.2 (e.g., \(E_W\)) is not utilized elsewhere, which detracts from the clarity of the methodology. Furthermore, the global compositionality parameter (\(\beta\)) is surprising, with cross-validation results (e.g., \(\beta = 0\)) suggesting that compositionality may not play a significant role.
Questions to Authors
1. Can you clarify the specific advantages of using the ontology-based approach over simpler baselines, given that phrase averages often outperform the proposed embeddings?
2. How does the ambiguity in the term "distant supervision" align with the methodology? Would a different term better reflect the process described?
3. Can you provide more details on how phrase/word vectors are used to compute concept similarities in Table 4? This aspect is critical for understanding the evaluation.
4. Given the underperformance of the proposed model on smaller datasets, how do you envision its applicability in real-world scenarios where data may be limited?
Recommendation
While the paper addresses an important problem and provides useful resources, the limited methodological novelty, performance concerns, and ambiguities in the experimental setup weaken its overall impact. I recommend major revisions to address these issues before considering acceptance.