Review of the Paper
Summary and Contributions
This paper proposes a semantic parser that directly maps natural language utterances to SQL queries using an encoder-decoder neural architecture. The approach bypasses intermediate representations, leveraging SQL's expressivity and editability. The model is evaluated on two benchmark datasets, Geo880 and ATIS, as well as a novel academic document search dataset (SCHOLAR). The authors introduce a feedback-based learning mechanism that iteratively improves the parser's performance through user feedback and crowd-sourced annotations. Key contributions include:
1. A neural sequence-to-sequence model for direct SQL generation, which achieves competitive performance on benchmark datasets without database-specific engineering.
2. A novel feedback-driven learning loop that enables rapid deployment and improvement of semantic parsers in new domains.
3. Data augmentation techniques using schema templates and paraphrasing to bootstrap the model and enhance generalization.
4. The release of the SCHOLAR dataset, which provides a valuable resource for academic database search tasks.
Strengths
1. Solid Execution of a Well-Established Technique: The paper effectively adapts sequence-to-sequence models for SQL generation, achieving near state-of-the-art results on Geo880 and ATIS. The use of SQL as the target representation is a practical choice, given its widespread adoption and expressivity.
2. Feedback-Driven Learning: The interactive learning framework is innovative and demonstrates the feasibility of building semantic parsers for new domains with minimal intervention. The live deployment experiment is particularly impressive, showing real-world applicability.
3. Data Augmentation: The use of schema templates and paraphrasing for data augmentation is well-motivated and contributes to the model's initial performance in low-resource settings.
4. Resource Contribution: The release of the SCHOLAR dataset is a significant contribution to the community, enabling further research in academic database search.
Weaknesses
1. Expressivity of SQL: While SQL is inherently expressive, the datasets used (Geo880, ATIS, SCHOLAR) may not fully showcase its advantages over other semantic formalisms. The paper could benefit from a discussion on whether the model exploits SQL's full potential or is limited to simpler query patterns.
2. Error Analysis: The paper lacks a detailed analysis of ill-formed SQL queries and the effort required for crowd worker post-editing. Additionally, the accuracy of crowd workers in constructing SQL queries is not thoroughly evaluated.
3. Annotator Agreement: The absence of inter-annotator agreement metrics, particularly for subjective feedback categories like "Incomplete Result," raises concerns about the reliability of the feedback used for model training.
4. Unsubstantiated Claims: The assertion that generating SQL directly is harder than using intermediate representations is not adequately supported with evidence or comparisons.
5. Minor Issues: Several minor issues, such as unclear terminology ("non-linguists," "anonymized utterance") and typos (e.g., "Is is" at l218), detract from the paper's clarity. The grayscale differentiation in visuals (l700) and inconsistencies in references also need attention.
Questions to Authors
1. Can you provide evidence or examples to support the claim that generating SQL directly is harder than using intermediate representations?
2. How much of SQL's expressivity does the model capture? Are there specific types of queries (e.g., nested, aggregate) that the model struggles with?
3. What measures were taken to ensure the quality and consistency of crowd worker annotations? Were annotators trained or provided with guidelines?
4. Could you elaborate on the paraphrasing scope mentioned in l403? How were paraphrases selected, and what impact did they have on model performance?
Overall Impression
This paper presents a strong contribution to the field of semantic parsing, particularly in its practical approach to building natural language interfaces for databases. The feedback-driven learning framework and the release of the SCHOLAR dataset are noteworthy achievements. However, the paper would benefit from a more thorough analysis of the model's SQL generation capabilities, error patterns, and the reliability of crowd-sourced annotations. Addressing these concerns would significantly strengthen the work.