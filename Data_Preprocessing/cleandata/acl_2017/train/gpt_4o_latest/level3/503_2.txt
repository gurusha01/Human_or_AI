Review of the Paper
Summary and Contributions
This paper investigates Regular Graph Languages (RGLs), a subfamily of Hyperedge Replacement Languages (HRLs) and Monadic Second Order Languages (MSOLs), with the aim of identifying a class of graph languages that are both probabilistic and closed under intersection. The authors present two key contributions: (1) they prove that RGLs are closed under intersection, and (2) they introduce a parsing algorithm for RGLs with linear runtime in the size of the input graph under specific conditions. These contributions are significant for natural language processing (NLP), particularly in semantic parsing, where graphs are increasingly used to represent compositional semantics.
Strengths
1. Clarity and Motivation: The paper is exceptionally clear and well-motivated, providing a thorough introduction to the problem and situating the work within the broader context of NLP and formal language theory. The motivation for exploring RGLs as a middle ground between expressivity and computational efficiency is compelling.
2. Theoretical Insights: The generalization of hyperedge grammars and Earley's algorithm to RGLs is insightful and demonstrates a strong theoretical foundation. The formal correctness of the results is well-supported, and the constructive proofs for intersection closure and parsing are valuable contributions.
3. Practical Relevance: The proposed parsing algorithm has practical implications for semantic parsing, particularly in reranking hypergraphs. Its linear complexity under certain assumptions makes it appealing for real-world NLP applications.
4. Terminological Precision: The paper effectively addresses differences in terminology across graph language families, ensuring accessibility to a diverse audience.
Weaknesses
1. Incomplete Introduction: While the introduction is well-written, it does not explicitly mention the reranking use case, which is an important practical application of the algorithm. Including this would strengthen the paper's relevance to NLP practitioners.
2. Complexity Limitations: The claim of linear parsing complexity is limited to specific assumptions, such as bounded graph degree and normal ordering. The paper does not adequately address the exponential complexity that arises in NLP contexts where input strings generate exponential graphs.
3. Ambiguity in Parsing Contexts: The distinction between semantic parsing (from strings) and parsing of semantic parses (graphs) is unclear. This lack of clarity may confuse readers unfamiliar with the nuances of these tasks.
4. Handling Ambiguity: The paper does not discuss how the parser would handle ambiguous or non-deterministic grammars, which are common in NLP and can lead to exponential parses.
5. Lexical Anchors and Linear Order: The lack of control over the linear order of 0-arity edges could lead to exponential complexity in string-parser variants. Additionally, the implications of lexical anchors introduced in Definition 7 are not fully explored.
Easily Correctable Issues
The paper contains several minor textual issues (e.g., misleading phrasing, missing words, and unclear definitions) that can be easily corrected. Specific examples include clarifying "such distribution" (lines 102-106), defining "rank" earlier (line 206), and linking table axioms to corresponding text.
Questions to Authors
1. How does the parsing complexity change when input strings generate exponential graphs in NLP contexts?
2. Can the Earley algorithm be adapted for non-deterministic, ambiguous regular tree grammars assigning trees to frontier strings?
3. What prevents Regular Graph Grammars (RGGs) from generating hypergraphs whose 0-arity edges are linearized, and how is the linear order determined?
4. Are the graphs generated by RGGs non-crossing in the sense of Kuhlmann & Jonsson (2015)?
5. How does the parser handle ambiguous or non-deterministic grammars with exponential parses?
Recommendation
This paper makes a valuable theoretical contribution to the study of graph languages and their applications in NLP. While it has some limitations, particularly in addressing practical challenges like ambiguity and exponential complexity, these do not detract significantly from its overall merit. I recommend acceptance, provided the authors address the identified weaknesses and clarify the practical implications of their work.