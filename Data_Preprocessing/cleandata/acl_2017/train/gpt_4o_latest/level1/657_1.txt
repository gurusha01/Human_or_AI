Review of the Submission
Summary
This paper presents a novel approach to interpreting Long-Short Term Memory (LSTM) neural networks by treating the model as an input-output device and querying it with carefully constructed stimuli inspired by experimental psychology. The authors apply this method to analyze gender-specific differences in essays written as part of a values-affirmation intervention, hypothesizing that male and female students exhibit distinct patterns of self-focused and other-focused justifications. The LSTM model outperforms a baseline SVM classifier and provides interpretable insights into the linguistic features associated with gendered writing styles. The paper also validates its interpretability framework by correlating LSTM output probabilities with SVM coefficients.
Contributions
1. Interpretability Framework for LSTMs: The primary contribution is a hypothesis-driven approach to interpreting LSTM predictions by analyzing output distributions in response to systematically varied inputs. This method bridges neural network interpretability and experimental psychology, offering a novel way to probe what the model has learned.
2. Application to Gendered Writing Styles: The paper provides empirical evidence supporting psychological theories of gendered self-construal by demonstrating that male and female students differ in their use of self-focused and other-focused justifications in values-affirmation essays.
3. Validation of Interpretability Method: The authors validate their interpretability framework by showing correlations between LSTM probability shifts and SVM coefficients, adding credibility to their approach.
Strengths
1. Novel Interpretability Approach: The hypothesis-driven method for probing LSTM predictions is innovative and well-motivated, offering a flexible and intuitive way to analyze neural network behavior. This approach could be extended to other domains and tasks.
2. Interdisciplinary Contribution: The paper effectively integrates methods from experimental psychology with machine learning, demonstrating the utility of neural networks in exploring psychological hypotheses. This interdisciplinary approach broadens the applicability of LSTMs in social science research.
3. Empirical Validation: The authors provide robust empirical validation of their interpretability framework by comparing LSTM probability shifts with SVM coefficients. This strengthens the case for their method's reliability.
4. Real-World Application: The study addresses a practical and socially relevant problemâ€”understanding the linguistic features of values-affirmation essays, which have been shown to mitigate achievement gaps in education.
Weaknesses
1. Limited Dataset: The dataset is relatively small (6,224 essays from 1,233 students), which may limit the generalizability of the findings. While the authors acknowledge this, the paper would benefit from a discussion of how the small dataset impacts the robustness of the results.
2. Modest Performance Gains: The LSTM model achieves only a modest improvement in macro F1 score (0.60 vs. 0.53 for the SVM baseline). While the focus is on interpretability, the limited performance gain raises questions about the practical utility of the proposed method.
3. Ambiguity in Psychological Insights: While the results align with gendered self-construal theories, the effect sizes are small, and the findings for other-focused justifications are weak (mean Fpref = 0.06). The paper could benefit from a deeper discussion of these limitations and their implications for psychological theory.
4. Complexity of Bayesian Analysis: The Bayesian modeling approach used to quantify the effects of justifications is not well-explained, making it difficult for readers unfamiliar with these methods to fully understand the results.
Questions to Authors
1. How does the small dataset size impact the generalizability of your findings? Have you considered augmenting the dataset or testing your method on additional datasets?
2. Can you elaborate on the practical implications of the modest performance gains of the LSTM model over the baseline SVM?
3. The effect sizes for other-focused justifications are weak. How do you interpret this in the context of psychological theories of gendered self-construal?
Additional Comments
The paper makes a valuable contribution to the interpretability of neural networks and their application in social science research. However, addressing the limitations in dataset size, performance gains, and the clarity of Bayesian analysis would strengthen the submission.