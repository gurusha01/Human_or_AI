Review of the Paper
Summary:  
This paper proposes a novel generative model for keyphrase prediction using an encoder-decoder framework with recurrent neural networks (RNNs). The model, termed "CopyRNN," incorporates a copy mechanism to address two major limitations of prior keyphrase extraction methods: (1) the inability to generate absent keyphrases (keyphrases not present in the source text) and (2) the lack of semantic understanding in ranking candidate keyphrases. The authors conduct extensive experiments on five datasets, demonstrating that their model significantly outperforms baseline methods in both extracting present keyphrases and generating absent keyphrases. Additionally, the paper explores the model's transferability to a different domain (news articles) and discusses its potential applications in information retrieval and summarization.
Main Contributions:  
1. Copy Mechanism in Keyphrase Generation:  
   The integration of a copy mechanism into the RNN encoder-decoder framework is the primary contribution. This mechanism allows the model to generate keyphrases containing out-of-vocabulary words by copying them directly from the source text, addressing a critical limitation of prior methods. The empirical results show that this mechanism significantly improves performance, especially for present keyphrase extraction.
2. Absent Keyphrase Prediction:  
   The paper is the first to explicitly address the challenge of predicting absent keyphrases in scientific publications. The proposed model demonstrates a recall of up to 20% for absent keyphrases, which is a notable advancement over existing methods that are incapable of handling this task.
3. Comprehensive Evaluation:  
   The authors conduct rigorous experiments on five benchmark datasets and introduce a new large-scale dataset (KP20k) for testing. The model is also evaluated on a domain transfer task (news articles), showcasing its generalizability and robustness across different text types.
Strengths:  
1. Innovative Approach:  
   The application of the copy mechanism within an RNN-based generative model is a novel and effective solution for handling out-of-vocabulary words and generating absent keyphrases. This innovation addresses a significant gap in the field.
2. Empirical Rigor:  
   The paper provides extensive experimental results, including comparisons with six baseline methods, evaluations on multiple datasets, and detailed analyses of both present and absent keyphrase prediction. The results consistently demonstrate the superiority of the proposed model.
3. Practical Relevance:  
   The model has clear practical applications in information retrieval, document summarization, and indexing. Its ability to generate absent keyphrases is particularly valuable for tasks requiring semantic understanding.
4. Scalability:  
   By training on a large dataset of over 500,000 scientific articles, the authors demonstrate the scalability of their approach, which is critical for real-world applications.
Weaknesses:  
1. Limited Discussion on Correlation Between Keyphrases:  
   While the authors acknowledge that their model does not consider the correlation among target keyphrases, this limitation is not explored in depth. Incorporating such correlations could further improve the quality of generated keyphrases.
2. Domain Transfer Performance:  
   The model's performance on the news article dataset (DUC-2001) is relatively modest compared to its performance on scientific publications. This indicates that the model may require domain-specific training to achieve optimal results, which limits its immediate applicability to other domains.
3. Evaluation Metrics:  
   The evaluation relies heavily on precision, recall, and F1 scores. While these are standard metrics, additional qualitative evaluations (e.g., human judgment of keyphrase quality) could provide a more nuanced understanding of the model's effectiveness.
Questions to Authors:  
1. How does the model handle cases where absent keyphrases are highly abstract or require external knowledge beyond the source text?  
2. Have you considered incorporating pre-trained language models (e.g., BERT) into the encoder-decoder framework to further enhance semantic understanding?  
3. Could the model's performance on domain transfer tasks be improved with fine-tuning on a small amount of domain-specific data?
Overall Assessment:  
This paper presents a significant advancement in keyphrase prediction by addressing the limitations of prior extraction-based methods. The proposed CopyRNN model is innovative, well-evaluated, and demonstrates strong performance across multiple datasets. While there are some areas for improvement, particularly in domain transfer and correlation modeling, the paper makes a valuable contribution to the field and is a strong candidate for acceptance.