Review of the Submission
Summary and Contributions  
This paper explores the potential of Regular Graph Languages (RGLs) as a formalism for representing probabilistic models of graphs in natural language processing (NLP). The authors position RGLs as a subfamily of both Hyperedge Replacement Languages (HRLs) and Monadic Second Order Languages (MSOLs), inheriting properties of probabilistic interpretation and closure under intersection, respectively. The paper makes two primary contributions:  
1. A proof that RGLs are closed under intersection, leveraging their MSOL properties.  
2. The development of a top-down parsing algorithm for RGLs, with a runtime linear in the size of the input graph, under certain constraints.  
The authors argue that RGLs strike a balance between expressivity and computational efficiency, making them suitable for semantic graph representations in NLP tasks. They also discuss the limitations of RGLs and suggest potential extensions to broader subfamilies of strongly context-free languages (SCFLs).
Strengths  
1. Novel Exploration of RGLs in NLP: The paper introduces RGLs, a relatively underexplored formalism, to the NLP community. The authors provide a compelling case for their relevance by highlighting their probabilistic and intersection-closure properties, which are critical for tasks like semantic parsing and machine translation.  
2. Theoretical Contributions: The proof of RGLs' closure under intersection is a significant theoretical result. It establishes RGLs as a viable alternative to HRLs and MSOLs for graph-based NLP applications, addressing a key limitation of HRLs (lack of intersection closure).  
3. Efficient Parsing Algorithm: The proposed top-down parsing algorithm is well-motivated and demonstrates a clear computational advantage over general HRG parsing. The analysis of its complexity, particularly the focus on boundary representations and normal ordering, is thorough and insightful.  
4. Connections to Broader Formalisms: The discussion of RGLs in the context of SCFLs and related formalisms (e.g., Tree-like Grammars and Restricted DAG Grammars) is valuable. It situates the work within a broader theoretical landscape and opens avenues for future research.  
Weaknesses  
1. Limited Empirical Validation: While the theoretical contributions are strong, the paper lacks empirical evaluation to demonstrate the practical utility of RGLs in real-world NLP tasks. For instance, applying the parsing algorithm to datasets like AMR or comparing its performance to existing HRG-based methods would strengthen the paper.  
2. Expressivity Concerns: The paper acknowledges that RGLs may be too restrictive for certain semantic graph representations, as illustrated by the unnatural derivation of the example graph in Figure 4. This limitation raises questions about the applicability of RGLs to complex NLP tasks.  
3. Clarity of Presentation: The dense theoretical content, while rigorous, could benefit from clearer exposition. For example, the description of the parsing algorithm and its inference rules might be challenging for readers unfamiliar with HRG parsing. Simplified examples or visual aids could improve accessibility.  
4. Assumptions in Parsing: The assumption that external nodes are identifiable in the input graph may not always hold in practical scenarios. While the authors briefly discuss relaxing this assumption, a more detailed treatment of its implications would be helpful.  
Questions to Authors  
1. Have you conducted any experiments to evaluate the practical performance of the proposed parsing algorithm on NLP datasets? If not, how do you envision its application in real-world tasks?  
2. How do RGLs compare to other formalisms like Tree-like Grammars or Restricted DAG Grammars in terms of expressivity and computational efficiency?  
3. Could you provide more concrete examples of NLP tasks where RGLs would be particularly advantageous compared to HRLs or MSOLs?  
Overall Assessment  
This paper makes a strong theoretical contribution by introducing RGLs to NLP and proving their closure under intersection. The proposed parsing algorithm is a valuable addition, though its practical utility remains to be demonstrated. While the work is limited by its focus on theory and the restrictive nature of RGLs, it opens up exciting directions for future research. I recommend acceptance, provided the authors address the clarity and applicability concerns in the final version.