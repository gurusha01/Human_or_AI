Review
Summary and Contributions  
This paper investigates how different writing tasks influence writing style, using the story cloze task as a case study. The authors demonstrate that stylistic features can distinguish between three types of writing tasks: writing an original story, writing a coherent ending, and writing an incoherent ending. They develop a simple linear classifier based on stylistic features, which achieves high accuracy in distinguishing these tasks without considering the story context. Furthermore, the classifier achieves state-of-the-art performance on the story cloze challenge, surpassing deep learning models. The claimed contributions are:  
1. Evidence that writing tasks impose measurable stylistic differences, shedding light on how cognitive processes influence writing style.  
2. Insights into the design of NLP tasks, emphasizing the importance of task instructions to avoid unintended stylistic biases.  
3. A new state-of-the-art result on the story cloze task, achieved by combining stylistic features with a neural language model.  
Strengths  
1. Novel Insight into Writing Style and Task Framing: The paper provides compelling evidence that writing tasks influence style, even for subtle differences like writing coherent vs. incoherent endings. This is a significant contribution to understanding how cognitive processes manifest in language.  
2. Strong Empirical Results: The classifier achieves impressive accuracy (64.5â€“75.6%) in distinguishing writing tasks and sets a new state-of-the-art (75.2%) on the story cloze challenge. The combination of stylistic features with a neural language model is particularly effective.  
3. Methodological Simplicity and Interpretability: The use of a linear classifier with well-defined features (e.g., n-grams, sentence length) is a strength, as it provides interpretable insights into stylistic differences. The analysis of salient features further enhances the paper's explanatory power.  
4. Practical Implications for NLP Task Design: The paper highlights the unintended biases introduced by task instructions, offering actionable recommendations for designing more robust NLP datasets.  
Weaknesses  
1. Limited Generalizability Beyond the Story Cloze Task: While the findings are robust within the story cloze framework, it is unclear how well they generalize to other writing tasks or domains. The paper would benefit from experiments on additional datasets to validate its broader applicability.  
2. Overemphasis on Style Without Context: The classifier's reliance on stylistic features without considering story context raises concerns about whether it truly captures task-specific cognitive processes or merely exploits superficial patterns. A deeper exploration of the relationship between style and coherence would strengthen the claims.  
3. Limited Discussion of Cognitive Implications: While the paper hints at connections between writing tasks, mental states, and cognitive load, these claims are not rigorously explored. Incorporating psychological or cognitive science perspectives would enhance the theoretical depth.  
Questions to Authors  
1. How well do the findings generalize to other datasets or writing tasks beyond the story cloze task?  
2. Can the classifier's reliance on style features without context lead to overfitting to dataset-specific biases? How might this affect its performance on unseen tasks?  
3. Have you considered incorporating more nuanced cognitive or psychological measures to strengthen the connection between writing tasks and mental states?  
Overall Assessment  
This paper makes a valuable contribution to understanding the interplay between writing tasks and style, with strong empirical results and practical implications for NLP task design. However, its generalizability and theoretical depth could be improved. I recommend acceptance with minor revisions.