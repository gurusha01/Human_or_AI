This manuscript presents a novel methodology for acquiring multi-sense word representations through the application of reinforcement learning techniques. The approach employs a CBOW-like architecture to facilitate sense selection, wherein a score is computed for each sense by calculating the dot product between the aggregate of word embeddings in the current context and the corresponding sense vector. A secondary module, grounded in the skip-gram model, is utilized to train sense representations, leveraging the outputs from the sense selection module. The training of these modules is achieved through Q-Learning, where the Q-value is derived from the CBOW-based sense selection module, and the reward is determined by the skip-gram negative sampling likelihood. Furthermore, the authors propose a non-parametric method for determining the number of senses for each word, which involves the creation of new senses when the Q-values for existing senses fall below a threshold of 0.5.
The proposed approach yields favorable results under the "MaxSimC" metric and achieves performance comparable to preceding approaches under the "AvgSimC" metric. The authors suggest that their methodology could potentially enhance the performance of downstream tasks by substituting word embeddings with the most probable sense embedding. However, it would be beneficial to explore this claim further, potentially through the application of sequential labeling tasks such as POS-tagging or NER, particularly in light of prior research questioning the efficacy of multi-sense representations in downstream tasks. The suggestion that reliance on MaxSimC could reduce overhead in real-world applications is somewhat misleading, as the sense disambiguation step, along with its associated parameters, would still be required, in addition to the sense embeddings. A clustering-based approach utilizing a weighted average of sense representations would incur similar overhead. The claims regarding improvements over word2vec using a fraction of the data are not particularly surprising on the SCWS dataset and do not significantly advance or differ from prior work.
A notable aspect of the proposed approach is its modular nature, which affords flexibility that could be further explored. The sense disambiguation module employs a vector averaging approach (CBOW), and a positive feature of the model is its potential to accommodate alternative context composition approaches through the use of different neural architecture composition techniques. The manuscript applies an intriguing approach to a problem that has been extensively explored in various ways. While the results on standard benchmarks are comparable to prior work, they are not particularly surprising or noteworthy. However, the approach extends beyond a simple extension of the skip-gram model for multi-sense representation learning by providing a modular framework grounded in reinforcement learning. Ideally, this aspect would be explored further, but overall, the approach itself may be sufficiently interesting to warrant consideration for acceptance, as it could contribute to advancing research in this area.
* The manuscript contains several typos that should be addressed (e.g., line 190, line 331, line 492).
NOTE: Appreciation is extended to the authors for their response.