Strengths:
The discovery of the deviation between "vocal" and "average" users is a notable finding that can be utilized to identify distinct user types, offering potential applications in user characterization.
Weaknesses:
This work is viewed as an initial exploration of a novel topic, warranting future expansion. A comparative analysis between matrix factorization and related concepts in distributional semantics, such as latent semantic analysis, would provide additional insights and enhance the study's comprehensiveness.
General Discussion:
This paper presents an approach to modeling Twitter users' stance or sentiment towards various topics, with a specific focus on inter-topic preference modeling. This task involves quantifying the degree of mutual relationship between stances on different topics. The authors claim that their work advances the state of the art in this area, as previous studies were limited to case studies, whereas this approach is applied to unlimited topics using real-world data. The methodology employed consists of several steps: a set of linguistic patterns was manually created to collect a large number of tweets expressing stance towards various topics. These tweets were then represented as triples containing user, topic, and evaluation, which were arranged into a sparse matrix. Following matrix factorization, a low-rank approximation was performed, with the optimal rank identified as 100. Cosine similarity was used to measure the similarity between topics, enabling the detection of latent preferences not explicitly represented in the original sparse matrix. Additionally, cosine similarity was utilized to identify inter-topic preferences. Preliminary empirical evaluation demonstrates that the model can predict missing topic preferences, and the predicted inter-topic preferences show moderate correlation with the corresponding values from a crowdsourced gold-standard collection of preferences. According to the overview provided in the related work section, the absence of previous systems for comparing inter-topic preference prediction renders this work promising.
Specific comments are listed below:
- Rows 23 and 744: The term "high-quality" is used without clear definition; it is suggested that all occurrences of "high-quality" be removed from the paper if a proper definition is not provided.
- Row 181 and the caption of Figure 1: The term "generic" could be removed for clarity.
- Row 217: The sentence "This section collect" should be revised to "We collected" or "This section explains how we collected" for grammatical correctness.
- Row 246: The term "ironies" should be corrected to "irony".
- Row 269: The example "I support TPP" raises the question of whether all possible patterns containing the topic are collected and then manually filtered; an explanation of this process would enhance clarity.
- Rows 275 and 280: The term "unuseful" should be corrected to "useless".
- Row 306: The word "including" could be replaced with "are including" for better readability.
- Row 309: The terms "of" and "it" are not topics but appear to be terms mistakenly retrieved as topics.
- Rows 317-319: The first sentence could be removed, and the paragraph could start with "Twitter user" for a more direct approach.
- Rows 419-439: The procedure used to empirically find the optimal k is commendable, as this value is often assumed in previous works without empirical justification.
- Row 446: The word "let" might be more appropriately replaced with "call" for clarity and correctness.