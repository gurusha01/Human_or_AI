Strengths:
- The approach to generating a dataset for evaluating out-of-coverage items is a notable contribution, with potential applications in assessing other grammars.
- The paper's writing style is commendable, offering clear and engaging exposition that deviates from the typical tone found in ACL publications.
Weaknesses:
- The evaluation datasets employed are limited in size, which diminishes the convincing power of the results, particularly concerning the alchemy45 dataset where the most favorable outcomes were achieved.
- The analysis presented is somewhat superficial, relying heavily on F1 scores and coverage scores without delving deeper into the results. A more detailed examination, such as categorizing errors by type or grammatical construction, would be beneficial.
- The proportion of out-of-coverage items attributable to various factors, including resource constraints, genuine grammatical constructions, extra-grammatical elements, and lexical gaps, remains unclear to this reviewer.
General Discussion:
This paper tackles the issue of robustness and coverage limitations in a hand-written HPSG grammar, specifically the English Resource Grammar. It presents a comparative analysis of methods aimed at enhancing coverage and introduces innovative strategies for compiling evaluation datasets, a challenging task given the inherent lack of gold standard data for out-of-coverage inputs.
Despite hand-written precision grammars falling out of favor in recent years, overshadowed by statistical treebank-based grammars, continued research in this area is warranted. The unique strengths of hand-written grammars, including high precision and in-depth semantic analysis, have yet to be fully replicated by non-hand-written approaches. In light of this, and acknowledging the paper's shortcomings, a score of 4 is assigned.