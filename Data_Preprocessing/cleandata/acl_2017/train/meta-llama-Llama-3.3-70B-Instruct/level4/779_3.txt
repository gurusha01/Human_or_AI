Strengths:
The paper is well-written and exhibits clarity for the most part, making it easy to follow.
The experimental comparisons presented are of high quality, demonstrating a thorough approach to evaluation.
The design and execution of the experiments are commendable, showcasing a strong methodology.
The concept of leveraging Knowledge Distillation (KD) for zero-resource Neural Machine Translation (NMT) is particularly noteworthy and impressive.
Weaknesses:
One notable issue is the tendency of the authors to overload single sentences with excessive information, which can hinder comprehension. Breaking up such sentences into multiple, clearer ones would enhance readability.
A more detailed explanation of the method employed would be beneficial, as the current description is somewhat glossed over, making it challenging for readers to grasp the idea solely from the provided sections.
A significant drawback of this approach is the requirement for the source-pivot corpus during test time, a point that is not adequately addressed in the paper. It is essential for the authors to acknowledge and discuss this limitation.
General Discussion:
This paper explores the application of knowledge distillation to enhance zero-resource translation, building upon techniques similar to those proposed by Yoon Kim et al. The innovative aspect lies in its application to zero-resource translation, alongside comparisons with other prominent works in the field. Notably, this approach eliminates the need for double decoding, presenting a streamlined solution.
Detailed comments:
- The structure in lines 21-27 could be simplified into two straightforward sentences for better clarity.
- Line 41 should acknowledge that Johnson et al. have achieved state-of-the-art results for English-French and German-English translations.
- The statement in lines 77-79 regarding the increased complexity due to the combination of multiple languages lacks evidence and seems to contradict existing literature. Either provide supporting evidence or retract this statement.
- The text in lines 416-420 is repetitive, having been mentioned in the preceding paragraph, and could be removed for conciseness.
- Line 577 incorrectly references Figure 3; it should refer to Figure 2 instead.