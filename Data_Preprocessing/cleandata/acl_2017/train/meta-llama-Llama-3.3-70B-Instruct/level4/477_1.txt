Review:
- Strengths:
i. The paper effectively motivates its research question.
ii. It offers a comprehensive comparison of various models across a diverse range of languages.
- Weaknesses:
i. The conclusion drawn is potentially biased due to the specific selection of languages.
ii. The experimental scope does not fully encompass the claims made in the paper.
- General Discussion:
This paper poses a fundamental question regarding word representation, specifically what subunit of a word is most suitable for representing morphologies and how these units should be composed. To address this, the paper explores word representations using different subunits (such as characters, character-trigrams, and morphs) and composition functions (including LSTM, CNN, and simple addition) within the context of a language modeling task. The aim is to identify the most effective combination, with evaluations conducted across more than 10 languages due to their typological diversity and potential impact on word representation and composition function outcomes. The findings suggest that character-level representations are more effective, although they still have limitations when compared to models incorporating explicit morphological knowledge. Additionally, character-trigrams are found to yield reliable perplexity results in the majority of languages examined.
However, several issues remain unaddressed:
- Firstly, the selection of experimental languages may introduce bias. With ten languages chosen from four categories (up to three languages per category), it is questionable whether these languages are truly representative of their respective categories. The assumption that languages within the same category share the same tendencies in word representation and composition function is not substantiated. For instance, the paper itself notes differing results between two languages of the same typology (agglutinative), suggesting that focusing on the tested languages rather than drawing broad conclusions might be more appropriate.
- There appears to be a discrepancy between the claims made and the experimental design. It is unclear whether language modeling is the optimal task for validating the paper's claims, and there is a possibility that these claims may not hold in other tasks, necessitating further explanation.
- The evaluation in Section 5.2 is limited to Arabic. Given the availability of automatic morphological analyzers for languages like Japanese and Turkish, it is puzzling why the experiment was not extended to these languages.
- The paper exclusively considers character-trigrams among various n-grams without providing a clear rationale for this choice. It is also unclear whether character-trigrams consistently outperform character-bigrams or character-fourgrams, as the effectiveness of n-grams in language modeling can be influenced by corpus size and other factors.
Minor typos:
- A reference is missing in the Introduction (line 88, Page 1).
- "root-and-patter" should be corrected to "root-and-pattern" (line 524, Page 6).