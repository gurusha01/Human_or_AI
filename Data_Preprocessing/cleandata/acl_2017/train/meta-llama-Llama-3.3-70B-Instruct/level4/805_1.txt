The submission exhibits several strengths, including the novelty of the CORE evaluation measure, the high accuracy of the proposed similarity measure, and the extensive evaluation across a large and diverse range of datasets.
However, there are some weaknesses that need to be addressed. Firstly, the manuscript contains several typos that should be corrected, including:
- Line 116-117: The phrase "to design of a new" should be revised to "to design a new".
- Line 176-177: The reference to "figure 2" should be changed to "figure 1".
- Line 265: The phrase "among the the top" contains a redundant word and should be corrected to "among the top".
- Line 320: The mention of "figure 4" should be introduced earlier in the article body for better context.
- Line 434: The sentence "the dataset was contains" should be corrected to "the dataset contains" for proper grammar.
- Line 486-487: The reference to "table 3" should be corrected to "table 1" to maintain consistency.
- Additionally, all instances of "Tensorflow" should be replaced with "TextFlow" to ensure accuracy.
Furthermore, there are some imprecisions that require clarification. 
- The computation accuracy of features such as lemma, part-of-speech (POS), or WordNet synset should be detailed in the paper. It is also essential to discuss whether these accuracies impact the overall similarity accuracy evaluation.
- Although the neural networks are implemented in Python, the availability of the code for replication of the experiment is not mentioned. 
- The sharing of training and evaluation sets is mentioned, but the specifics of how these are shared (e.g., on demand, under license) are not provided, which is crucial for reproducing the experiment.
In the general discussion, these points should be considered to enhance the clarity, reproducibility, and overall quality of the submission.