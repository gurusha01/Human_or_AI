This paper proposes a compelling model for reading comprehension, capturing the complex interactions between a query and local context within a document through a novel gated-attention approach. The research is robust, yielding near state-of-the-art results across four cloze-style datasets. Further refinements could potentially enhance performance in similar tasks.
However, several concerns warrant attention:
1. Although the authors cite numerous arXiv papers, some pertinent studies appear to be overlooked. Notably, the works by Caiming Xiong et al. (https://openreview.net/pdf?id=rJeKjwvclx) and Shuohang Wang et al. (https://openreview.net/pdf?id=B1-q5Pqxl) focus on enhancing attention mechanisms to model document-query interactions, albeit with an evaluation on SQuAD rather than cloze-style corpora. A comparative analysis, either experimentally or theoretically, could provide valuable insights.
2. Existing studies have explored attention mechanisms and variants specifically designed for reading comprehension tasks, sharing similarities with the ideas presented in this paper. To strengthen the experimental component, it is suggested that comparisons be made with such related works, potentially leading to a more comprehensive understanding of the proposed model's efficacy.