Strengths:
The problem of zero-shot relation extraction is intriguing, and the authors have made a significant contribution by creating a substantial dataset for relation extraction framed as question answering, which is likely to be a valuable resource for the community.
Weaknesses:
A major limitation of the paper is the lack of comparison and acknowledgment of existing work, which raises concerns about the novelty of the contributions presented.
General Discussion:
The authors approach relation extraction as a reading comprehension task. To train reading comprehension models for relation extraction, they developed a large dataset consisting of 30 million "querified" relations by leveraging mechanical turk annotators to convert relations from a schema into natural language queries. They utilized the reading comprehension model proposed by Seo et al. in 2016, with an additional capability to return "no relation," unlike the original model which always returns an answer. The primary motivation and outcome of the paper seem to be the ability to perform zero-shot relation extraction, extracting relations that are only seen during testing.
Although the paper is well-written and the idea is interesting, it falls short in terms of experimental evaluation and comparison to prior work, making it challenging to convince that the paper's contributions are indeed novel and impactful.
Firstly, the authors have overlooked a significant amount of related work. For instance, Neelakantan et al. in 2015 (https://arxiv.org/abs/1504.06662) performed zero-shot relation extraction using RNNs over knowledge base paths, while Verga et al. in 2017 (https://arxiv.org/abs/1606.05804) conducted relation extraction on unseen entities. The authors cite Bordes et al. (https://arxiv.org/pdf/1506.02075.pdf), who collected a similar dataset and performed relation extraction using memory networks commonly used for reading comprehension. However, they merely note that their data was annotated at the "relation" level rather than the triple (relation, entity pair) level, but it is unclear why Bordes et al. could not have done the same. Furthermore, a NAACL 2016 paper (https://www.aclweb.org/anthology/N/N16/N16-2016.pdf) performed relation extraction using a new model based on memory networks, and there are likely more relevant studies. Given the similarity of the work to existing research, it is essential to cite and establish novelty with respect to at least some of these studies early on, ideally in the introduction, to clarify the differences.
Secondly, the authors fail to 1) evaluate their model on another dataset or 2) assess any previously published models on their dataset. This significantly weakens their empirical results. Considering the wealth of existing work on the same task and the lack of novelty in this work, the authors need to include experiments that demonstrate their technique outperforms others on this task or show that their dataset is superior to others (e.g., due to its larger size, does it allow for better generalization?).