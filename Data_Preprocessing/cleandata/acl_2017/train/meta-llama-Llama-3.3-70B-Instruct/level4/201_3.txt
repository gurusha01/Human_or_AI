This paper presents a comprehensive examination of the impact of context types (linear and dependency-based) and representations (bound and unbound words) on word embedding learning, utilizing three prominent models (Generalized Bag-Of-Words, Generalized Skip-Gram, and Glove) across a range of tasks including word similarity, word analogy, sequence labeling, and text classification.
The key strengths of this work include:
1. The paper is well-organized and clearly written, making it accessible to readers.
2. The experimental evaluation is rigorous and thorough, providing valuable insights that can inform the selection of word embeddings and potentially inspire the development of new models.
3. The accompanying software has the potential to benefit the broader research community.
However, a notable weakness is the limited novelty of the work.
In the context of dependency-based context types, it would be beneficial to explore how dependency parsing influences overall performance. Furthermore, it is essential to consider whether the comparison between linear and dependency-based context types is fair, given that the latter relies on predicted dependency parsing results (in this case, from CoreNLP), whereas the former does not.