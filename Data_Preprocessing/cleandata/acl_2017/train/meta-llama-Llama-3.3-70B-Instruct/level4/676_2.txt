Strengths:
  The paper's clarity and well-structured figures facilitate easy comprehension of the methodology, even for readers solely relying on the visual aids. 
  The approach of directly predicting binary code to reduce parameter space is innovative, and the error-correction code's effectiveness is noteworthy, achieving 26 out of 31 BLEU with just 44 bits. 
  This parameter reduction technique is distinct from existing methods like weight pruning and sequence-level knowledge distillation, offering a unique contribution. 
  The methodology's applicability extends beyond Neural Machine Translation to tasks with large output vocabularies.
Weaknesses:
  A significant concern is the proposed model's performance on larger datasets, such as ASPEC, where it falls short of the softmax model by 1 BLEU point. This gap may widen with even larger datasets like French-English, which contains up to 12 million sentences. 
  The performance on other language pairs is also unclear, warranting further investigation. 
  The authors may benefit from referencing a relevant paper (https://arxiv.org/abs/1610.00072) that achieves a 10x speedup in decoding with minimal BLEU loss.
General Discussion:
  The paper presents a novel approach to reducing parameters in large vocabulary softmax by leveraging error-corrected codes and hybrid softmax methods, resulting in BLEU scores comparable to the original full vocab softmax model. 
  A crucial detail missing from the experiment setup is the hidden dimension size of the models. 
  While achieving 26 out of 31 BLEU with 44 bits on E2J is impressive, it is reasonable to expect that increasing the number of bits could enhance classification power without significantly impacting computation time on GPUs. 
  The prediction of binary code, which essentially predicts word ranks, raises questions about the interpretation of bit-embeddings and their semantic relationships, particularly for words with odd ranks, suggesting that the model might be relying on memorization rather than capturing meaningful patterns.