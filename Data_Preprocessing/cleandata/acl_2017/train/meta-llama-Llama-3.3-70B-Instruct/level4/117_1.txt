The paper explores a pertinent research area, namely learning the correspondence between natural language and Knowledge Base (KB) relations, particularly in the context of Question Answering (QA) where only partial information is available for one of the arguments, and when dealing with a vast number of potential target relations.
The proposed method involves combining two distinct representations of the input text: one at the word level, which includes segmentation of both the target relation names and the input text, and another where relations are treated as a single token, thus forgoing segmentation of both relation names and input text.
A key contribution of this work to QA appears to be its capability to re-rank entities following the Entity Linking step.
The results demonstrate an improvement over the current state of the art.
However, a limitation of the approach is its evaluation on a restricted dataset.
In terms of organization, it might be beneficial to integrate the content of section 3.1 into the related work section, allowing section 3.2 to become the new section 3, which could then be subdivided more effectively.