The paper's primary advantage lies in its integration of discourse structure into the DNN's attention mechanism, enabling the model to learn weighted importance of different EDUs. Additionally, the paper is well-structured and provides a clear explanation of RST and its application in the model. The evaluation experiments are also comprehensive, featuring robust state-of-the-art baselines.
However, a significant limitation of the paper is that the results do not substantially substantiate the claim that discourse structure enhances text classification. Even the UNLABELED variant, which yields the best performance and surpasses the state-of-the-art, only achieves marginal gains and performs poorly in the legal/bills domain. The approach, particularly the FULL variant, appears to be overly reliant on large amounts of data, but no effective solution is proposed to address this issue beyond the simpler UNLABELED and ROOT variants.
Overall, this paper can be seen as a promising initial attempt to incorporate discourse structure into DNN-based classification, but it falls short of convincingly demonstrating that RST-style structure will significantly improve performance in most tasks, especially considering the high cost of developing a RST parser for new domains. It would be beneficial for the authors to explore potential next steps to improve this approach, particularly in addressing data sparsity. For instance, they could investigate defining task-independent discourse embeddings or utilizing a DNN for discourse parsing that can be jointly optimized with the main task DNN in an end-to-end manner. While this is a good effort, it would be more impactful if the authors had further developed their ideas, given the mixed results.