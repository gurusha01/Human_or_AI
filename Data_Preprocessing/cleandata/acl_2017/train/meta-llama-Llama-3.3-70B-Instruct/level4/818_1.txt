I appreciate the author's response, which addresses some of my concerns, although it largely consists of promises for future revisions, a necessity given the space constraints. However, this highlights the issue: I would like to review the revised paper to verify that the identified drawbacks have been adequately addressed. The required changes are substantial, and the new experimental results promised will not have undergone review if the paper is accepted in its current state. I remain uncertain about relying solely on the authors to make the necessary changes without an additional review round. I have upgraded my score to 3, reflecting my ambivalence - I appreciate the research's creativity, but the presentation is extremely messy.
Strengths:
The paper's topic is highly creative, and its purpose is worthwhile, aiming to extract common knowledge from text by overcoming the well-known problem of reporting bias through joint inference on extractable information from text.
Weaknesses:
1. Many aspects of the approach require clarification. My primary concern is the lack of understanding of how the approach integrates object knowledge with verb knowledge to overcome reporting bias. The paper quickly delves into technical details without clearly explaining the overall approach or its merits.
2. The experiments and discussion are incomplete. Notably, there is no discussion of the results for one of the tasks (lower half of Table 2), and a crucial experiment is missing: Variant B of the authors' model yields better results on the first task than Variant A, but only Variant A is tested for the second task, failing to improve over the baseline.
General Discussion:
The paper requires significant work before it is publication-ready.
Detailed Comments:
- Page 26: The paper mentions five dimensions, not six.
- Figure 1 caption: The term "implies physical relations" is unclear - how do the authors determine which physical relations are implied?
- Figures 1 and 113-114: The approach seems to extract lexical entailments for verbs, similar to those defined in formal semantics (e.g., Dowty, 1991). A explicit link to this literature would be beneficial.
- Page 135: The key insight of the approach - how and why joint inference over the two pieces of information helps overcome reporting bias - needs to be explained.
- Page 141: "Values" should be "value".
- Page 143: Consideration of work on multimodal distributional semantics, potentially in the related work section, would be valuable. Relevant papers include Bruni et al. (2012) and Silberer et al. (2013).
- Page 146: Clarification that the contribution is the specific task and approach, as commonsense knowledge extraction from language is a long-standing task, is necessary.
- Page 152: The term "grounded" is unclear at this point.
- Section 2.1: The choice of dimensions and the rationale behind them need to be explained.
- Page 177: Terms "pre-condition" and "post-condition" should be explained, along with their relevance.
- Pages 197-198: An example of the full distribution for an item would aid understanding.
- Figure 2: The distinction between stage-level and individual-level predicates, as in formal semantics, seems relevant but is not clearly explained.
- Page 248: A determiner is missing in the definition.
- Section 3: The selection of "action verbs" and the criteria for choosing them, including whether they are explicitly tagged as such by Levin, need clarification.
- Pages 306ff: The concept of "action frames" and how they are chosen or generated should be explained.
- Page 326: The method for determining whether a frame is under- or over-generating is not provided.
- Table 1: The method for partitioning (by frame, verb, or otherwise) and the reuse of verbs or frames across partitions should be detailed.
- Page 336: The use of PMI is mentioned, but details such as thresholds are missing.
- Page 371: The method for partitioning - whether random or based on specific criteria - should be stated.
- Page 376: The phrase "rate the general relationship" is unclear.
- Page 378: The criteria for choosing which knowledge dimensions to annotate for each frame are not provided.
- Section 4: A higher-level description of the model, including its components (such as factor graphs, substrates, and factors), and why it is a good approach, is necessary for a CL audience.
- Page 420: The antecedent for "both classes of knowledge" is missing.
- Page 421: The term "object first type" is unclear.
- Page 445: The introduction of selectional preference factors seems abrupt; their role and introduction earlier in the paper would be beneficial.
- Page 461: The word "also" seems out of place.
- Page 471: The source of verb-level similarities is not provided.
- Figure 3: The figure is difficult to understand and may benefit from a clearer textual explanation or an alternative, more intuitive representation. Ensure it is readable in black-and-white.
- Page 598: The term "message" and its role in the factor graph should be defined.
- Page 621: The necessity for a "soft 1" instead of a hard 1 should be explained.
- Pages 647ff: More details about the EMB-MAXENT classifier, including training, input data, and encoding, are needed, along with justification for its use as a baseline.
- Page 654: The phrase "more skimp seed knowledge" is unclear.
- Page 659 and 681: There is an issue with the table reference, which should be Table 2.
- Pages 664ff: The example provided may not be the best choice, as the comparison between an entity and a revolution is not straightforward.
- Page 681: Discussion of the results for the task of inferring knowledge on objects and inclusion of results for model (B) are necessary. Consistent terminology for the model in Tables 1 and 2 would be beneficial.
- Page 778: The mention of "latent in verbs" without reference to objects seems incomplete.
- Page 781: The antecedent for "both tasks" is missing.
The references should be checked for format consistency, including capitalization and bibliographic details, as seen in references like Grice and Sorower et al.