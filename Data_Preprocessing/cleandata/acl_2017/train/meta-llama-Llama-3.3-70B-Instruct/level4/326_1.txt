Strengths:
The authors leverage established neural network techniques, specifically adversarial networks (Goodfellow et al, NIPS-2014), to exploit eight distinct Chinese word breaking test sets, each with its own definition of a word in Chinese. This approach has potential implications for various NLP tasks where the notion of correctness can vary. The application of Goodfellow et al's method offers a novel perspective on addressing the challenge of adapting to different criteria, which could be more effective than traditional adaptation methods.
Weaknesses:
A suitable term is needed to describe the problem at hand; "the elusive gold standard" is a preferable term to "multi-criteria." The motivation presented in the paper appears overly narrow, as the elusive gold standard issue arises in numerous applications beyond Chinese Word Segmentation. Furthermore, the motivation makes assumptions about the reader's familiarity with Chinese, which may not be the case. Many non-Chinese readers may underestimate the complexity of Chinese, assuming it to be simpler than it actually is. The point highlighted in Table 1, that there is significant room for disagreement among native Chinese speakers, could be more effectively made by acknowledging that this issue is not unique to Chinese Word Segmentation. In fact, many NLP tasks, such as machine translation, information retrieval, and web search, inherently involve multiple correct answers due to the subjective nature of evaluation metrics. Other tasks, like part-of-speech tagging, often overlook the elusive gold standard problem, which can hinder progress. When annotators disagree, it is a difference of opinion, but when a machine disagrees, it is typically considered an error. The use of the term "adversary" from the NIPS paper may not be the most helpful way to frame differences of opinion, as it implies a competitive or adversarial relationship, whereas the elusive gold standard problem is more about accommodating varying perspectives. Clarifying that the established method from NIPS is being applied to address the elusive gold standard problem, and acknowledging the broader applicability of this issue, could enhance the paper's impact.
General Discussion:
The paper was found to be unnecessarily challenging to follow, partly due to the reviewer's limited background in Chinese and NIPS. However, there are also issues with English usage and exposition that could be improved. For instance, Table 4 requires closer examination to support the assertions made about the first block and depth of networks. Key terms such as P, R, and F are assumed to be understood as precision, recall, and the F measure, respectively, but explicit explanations would be beneficial. The abundance of numbers in Table 4 raises questions about significance, comparability across columns, and the performance metrics used. The claim of a significant solution to the elusive gold standard problem, as stated in line 794, needs clearer justification from the data presented in Table 4. Minor suggestions for improvement include correcting "works" to "work" where appropriate, as "work" is a mass noun, and addressing specific line edits, such as "each dataset" instead of "each datasets," and "randomize" instead of "random."