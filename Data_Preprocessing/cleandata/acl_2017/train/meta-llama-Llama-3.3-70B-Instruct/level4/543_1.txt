Update after rebuttal
I appreciate the authors' efforts to address my concerns and provide additional clarifications on their implementation of the baseline and the significance of their reported improvements. These clarifications should be incorporated into the camera-ready version. The idea of leveraging visual features for languages like Chinese, Japanese, and Korean remains compelling, and I look forward to seeing its potential in tackling more challenging tasks in future research.
- Strengths:
- The concept of visually processing Chinese, Japanese, and Korean characters is innovative and promising.
- Weaknesses:
- The experimental results demonstrate only marginal improvements over the baseline, and the evaluation methodology makes it challenging to substantiate the central claim that visual features enhance performance when processing rare or unseen words.
- Certain details regarding the baseline implementation are lacking, which hinders the interpretation of the results and reproducibility of the work.
- General Discussion:
This paper proposes utilizing computer vision techniques, specifically CNNs applied to text images, to enhance language processing for Chinese, Japanese, and Korean languages, which often feature compositional characters. The authors evaluate their model on a text classification task, assigning Wikipedia page titles to categories, and show that a simple one-hot character representation outperforms the CNN-based representation. However, combining visual representations with standard one-hot encodings yields better results than using either alone. They also provide evidence suggesting that visual features outperform one-hot encodings on rare words and present qualitative results indicating that the CNN learns meaningful semantic character embeddings.
While the idea of visually processing languages like Chinese and Japanese is intriguing, I remain unconvinced by the experimental results. The evaluations are relatively weak, making it difficult to determine their robustness. I would prefer to see more rigorous evaluations to make the paper suitable for publication. If the results are statistically significant, as indicated in the author response, I would support accepting the paper, but ideally, I would like to see an alternative evaluation approach.
More specific comments:
- In Section 3, the "lookup model" paragraph lacks explicit information about the embeddings used and whether they were fine-tuned via backpropagation like the visual embeddings. Clarification on the baseline implementation is necessary. If the baseline was not task-specifically tuned, whereas the visual embeddings were, this raises concerns about the comparability of their performances.
- The choice of evaluating the model on classifying Wikipedia page titles is unclear, as the primary argument for using the visual model is its ability to generalize to rare or unseen characters. A more direct evaluation approach, such as machine translation of out-of-vocabulary words, might be more effective in highlighting the weaknesses of the standard approach and demonstrating the need for visual features.
- The statistical significance of the improvements in Table 5 should be confirmed.
- Figure 4 is difficult to understand and could be presented more clearly to showcase the contribution of the model. As I interpret it, the x-axis represents the rank of word rarity (possibly log frequency), with the rarest words on the left. The visual model's intersection with the x-axis to the left of the lookup model suggests that it performs better on ranking rare words. However, it is unclear why both models do not intersect at the same point on the x-axis, given that they are evaluated on the same set of titles and trained with the same data. A concise summary of the figure's intended message would be helpful in the author response.
- The fallback fusion approach could be more thoroughly evaluated by showing performance for different thresholds, rather than just the threshold of 0, which may not be representative of the technique's general performance.
- The simple experiment on unseen characters is a good idea but feels like an afterthought. More evaluation in this direction, such as classifying unseen words, would be beneficial.
- Consider adding translations to Figure 6 for readers who do not speak Chinese.