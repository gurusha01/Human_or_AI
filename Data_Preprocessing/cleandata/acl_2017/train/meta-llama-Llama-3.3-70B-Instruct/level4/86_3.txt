Strengths:
The proposed approach in the paper appears to be well-founded, and the experimental results suggest that it holds promise. Two notable features of this approach are its applicability to general-purpose programming languages, such as Java and C++, although further validation is required to confirm this. Additionally, the data-driven syntactic neural model, described in Sections 3 and 4, yields a 10% improvement in accuracy over the LPN approach. Overall, the paper presents a clear motivation, methodology, data analysis, and well-organized presentation, making it a commendable piece of work.
Weaknesses:
1. The concept of "hypothesis space" mentioned at Line 110 is unclear without referencing the supplementary materials, which will not be included in the final paper. It would be beneficial to provide a brief explanation of this term to ensure clarity.
2. Sections 3 and 4 introduce the grammar model and action probability estimation, respectively. However, it seems that the latter is a component of the former, which is not reflected in the section titles. Furthermore, Section 3 does not provide a comprehensive explanation of the grammar model.
3. The experimental data raises questions about the training process, including the number of datasets used and whether increased training leads to higher accuracy. A comparison of the efficiency between the proposed approach and LPN would also be informative.
4. It is unclear whether there are differences between neural network-based approaches for code generation in general-purpose languages and those in domain-specific languages.
5. The claim that the approach can scale up to generate complex programs lacks supporting evidence in the paper.
Minor comments:
Line 117: The phrase "the underlying syntax" should specify the language (NL or PL) to which it refers.
Line 148: It would be helpful to clarify if there are any constraints on the variable x.
Line 327: The sentence "The decoder uses a RNN" should be revised to "The decoder uses an RNN" for grammatical correctness.
Reference: The formatting is inconsistent and should be standardized.
General Discussion:
This paper presents a data-driven syntax-based neural network model for code generation in general-purpose programming languages, specifically Python. The approach involves generating a probable AST using a probabilistic grammar model from a given natural language statement, followed by encoding the AST into source code using deterministic generation tools. The key challenge lies in the first step, as generating code from an AST is relatively straightforward. The experimental results demonstrate that the proposed approach outperforms other state-of-the-art methods.