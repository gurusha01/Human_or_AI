This paper applies Pointer Networks, a type of recurrent neural network originally designed for algorithmic tasks, to two subtasks of Argumentation Mining: identifying Argument Component types and determining links between them, achieving state-of-the-art results.
The paper's strengths include:
- A comprehensive review of prior work in the specific formulation of argument mining addressed in this paper.
- A straightforward yet effective modification of an existing model to suit the task, with clear explanations for the most part.
- The model demonstrates strong performance compared to prior art in this task.
However, several weaknesses are noted:
- The paper should acknowledge that the formulation of argumentation mining presented is just one of several proposed subtask divisions. For instance, other works such as [1] detect and classify claims before identifying supporting evidence, and [2] has already applied neural networks to this task, contradicting the claim that this work is the first neural network-based approach to argumentation mining.
- The presentation of the model requires improvement in two key areas: (1) specifying the pooling method used for embedding features (as mentioned in line 397), and (2) clarifying Equation (7) in line 472, particularly whether E_i represents the type or identity of Argument Component i, and potentially reformulating the left-hand side as a conditional probability.
- Table 2 raises several questions: why the first three baselines are only evaluated by macro F1 without individual F1 scores, the relationship between the "PN" model presented and those in Table 1 or the Joint Model, and the omission of the other three models.
- The dataset used for the experiment in Table 4 is not specified.
In general discussion:
- A more detailed introduction to pointer networks, including their relation to recurrent neural networks and sequence-to-sequence models, would benefit readers unfamiliar with these concepts. The citation of Sutskever et al. (2014) should be moved to the first mention of the term, and the distinction from recursive neural networks should be explained before discussing tree structures.
- The use of the elu activation function requires explanation and citation, as it is not widely known.
- Labels such as "MC", "Cl", and "Pr" should be explained.
- A description of how hyperparameters were obtained would be useful.
- The decision to use early stopping based solely on link prediction accuracy should be justified.
- Inference at test time needs more detailed explanation.
- The unit of measurement for the length of an Argument Component should be specified.
- Several minor corrections, including clarifying ambiguous references and correcting typos like "which is show" in line 161, are necessary.
- The surprising performance with limited training data, especially considering neural networks typically require more data, should be addressed, noting that other models have achieved similar results.
- An alternative interpretation could be that structural cues are less critical for this task.
References:
[1] Rinott, Ruty, et al. "Show Me Your Evidence-an Automatic Method for Context Dependent Evidence Detection." EMNLP. 2015.
[2] Laha, Anirban, and Vikas Raykar. "An Empirical Evaluation of various Deep Learning Architectures for Bi-Sequence Classification Tasks." COLING. 2016.