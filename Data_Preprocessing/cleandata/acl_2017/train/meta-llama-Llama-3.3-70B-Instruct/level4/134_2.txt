The paper presents a comprehensive neural approach to argumentation mining, exploring multiple methodologies, including: 
1) formulating the problem as a dependency parsing task, utilizing various parsers, 
2) framing it as a sequence labeling problem, 
3) employing multi-task learning based on a sequence labeling model, 
4) leveraging an out-of-the-box neural model (LSTM-ER) for entity and relation labeling, and 
5) incorporating ILP-based state-of-the-art models. 
The performance of these approaches is evaluated using F1 scores defined on concepts and relations. 
The results indicate that dependency-based solutions are less effective, while sequence labeling solutions yield better outcomes. 
Notably, the out-of-the-box LSTM-ER model demonstrates exceptional performance, particularly at the paragraph level. 
Both sequence labeling and LSTM-ER models outperform the ILP approach. 
A detailed supplement is provided, outlining the technical aspects of model training and hyper-parameter optimization. 
Furthermore, it is shown that sequence labeling models can be significantly enhanced through a multi-task approach, with the claim task contributing more than the relation task. 
This paper constitutes a thorough investigation of neural-based approaches to end-to-end argumentation mining.
Major concerns include:
- The potential issue with the dataset, where essays in the training and test sets may cover the same topics, leading to information leakage and overly optimistic performance estimates. Although this issue may also affect ILP models, it is worth discussing.
- The fact that one of the best-performing models, LSTM-ER, is essentially an out-of-the-box application of a model from related work. Nevertheless, given the success of sequence-based models and the valuable lessons learned from the experiments, this work deserves publication.
Minor remarks and questions:
- The explanation of reconstructing the full graph from a tree output (lines 222-226) is unclear.
- The ordering of sections (lines 443-444) would be easier to follow if the sequence tagging and dependency-based sections were reversed.
- The statement that the model "de-couples" relation information from entity information while jointly modeling them (line 455) is confusing, as it seems contradictory. Clarification is needed.
- The system's ability to "de-couple" relation information from entity information (lines 477-479) is unclear; it is recommended to provide a clearer explanation.
- It is uncertain whether the F1 scores in paragraph and essay settings are comparable, particularly for relation tasks, as paragraph-based models may miss cross-paragraph relations by default.