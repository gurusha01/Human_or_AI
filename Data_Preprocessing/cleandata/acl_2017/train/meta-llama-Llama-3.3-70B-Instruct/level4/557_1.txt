The paper presents several notable strengths, including its clear and well-structured writing style. The application of novel techniques, such as global optimization, to end-to-end neural relation extraction, as well as the direct incorporation of parser representation, is a noteworthy aspect. Furthermore, the proposed system demonstrates state-of-the-art performance on both the ACE05 and CONLL04 datasets, and the authors provide several informative analyses.
However, there are also some weaknesses to consider. The approach appears to be incremental, essentially combining existing methods, which may limit its overall impact. Additionally, the performance improvements, at 1.2 percentage points on the dev set, are relatively modest, and the absence of significance test results raises questions about the robustness of these gains.
In terms of general discussion, several major comments are warranted. Firstly, it would be beneficial to understand how the employment of a recent parser and GloVe word embeddings influenced the relation extraction performance. Secondly, clarification is needed on how the authors handled illegal predictions during the prediction phase.
Some minor comments are also in order. The introduction's description of local optimization as completely "local" is misleading, as it actually considers structural correspondences between incremental decisions. Furthermore, the points in Figures 6 and 7 would be more effectively presented with straight lines rather than curves. The representation of entities in the "-segment" context is also unclear and requires further explanation. Lastly, some citations are incomplete, such as Kingma et al. (2014), which was accepted to ICLR, and Li et al. (2014), which lacks page numbers.