This paper presents Neural Symbolic Machines (NSMs), a novel deep neural model that leverages discrete memory to enable symbolic execution. The NSM architecture comprises three key components: (1) a manager that provides weak supervision for learning, (2) a differentiable programmer based on neural sequence-to-sequence models, which encodes input instructions and predicts simplified Lisp programs using partial execution results stored in external discrete memories, and (3) a symbolic computer that executes programs and provides code assistance to the programmer to prune the search space. The authors evaluate their model on the WebQuestionsSP semantic parsing task and demonstrate that (1) NSM can effectively model language compositionality by saving and reusing intermediate execution results, (2) Augmented REINFORCE outperforms vanilla REINFORCE for sequence prediction problems, and (3) NSM trained end-to-end with weak supervision achieves state-of-the-art results, surpassing existing methods like STAGG.
The strengths of this paper include:
* The innovative use of discrete, symbolic memories for neural execution models, which, although simple in implementation, yields impressive results on a large-scale semantic parsing task.
* The proposed revised REINFORCE training schema, which utilizes imperfect hypotheses derived from maximum likelihood training, is an interesting and effective approach that could inspire future research in combining ML and RL training for neural sequence-to-sequence models.
* The scale of the experiments is larger than previous works in neural execution and program induction, with impressive results.
* The paper is generally well-written and clear, although some points require further clarification, such as the role of variable tokens ($v_i$'s in Fig. 2) in computing action probabilities and the conflicting notation of $v$ in Tab. 1 and Fig. 1.
Overall, this paper is well-structured and presents a compelling idea, making it a strong candidate for inclusion in the conference.
However, there are some weaknesses that need to be addressed:
* The choice of dataset is questionable, as the authors use WebQuestionsSP instead of the more popular WebQuestions benchmark set. Using WebQuestions would be more intuitive and facilitate direct comparison with mainstream QA research.
* The analysis of compositionality is limited, and it would be beneficial to present a detailed analysis of the model's performance on question sets with varying compositional depth, including simple one-hop questions and complex multi-hop questions that require filtering and superlative operations.
* Some relevant papers in the field are not cited, including previous RL-based methods for knowledge-based semantic parsing, sequence-level REINFORCE training methods, and neural enquirer work that uses continuous differentiable memories for modeling neural execution.
Additionally, some minor points need to be clarified:
* Why is the REINFORCE algorithm randomly initialized (Algo. 1) instead of using parameters pre-trained with iterative ML?
* What is the KG server in Figure 5?