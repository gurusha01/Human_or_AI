The paper presents several notable strengths, including:
1) Its effort to integrate Stochastic Gradient MCMC and Stochastic Optimization within the context of deep learning, offering a more systematic approach to Bayesian learning-based algorithms that can benefit the deep learning community, particularly in reducing overfitting through techniques like dropout and variational inference.
2) The demonstration that the proposed SG-MCMC optimizer, when combined with dropout, outperforms RMSProp with dropout in language modeling tasks, highlighting the potential of uncertainty modeling in improving accuracy by reducing overfitting.
3) The provision of detailed model and experiment setups, facilitating the reproducibility of the results.
However, the paper also has several weaknesses:
1) It lacks a deeper theoretical analysis, failing to provide proofs and convergence properties of the proposed algorithm, which is a critical aspect for understanding its efficacy and reliability.
2) The comparative analysis is limited, primarily focusing on the comparison between SG-MCMC and RMSProp without exploring other relevant comparisons that could offer a more comprehensive understanding of the algorithm's performance and its relationship to other methods, such as the connection between pSGLD and RMSProp beyond their classification as counterparts in different families.
3) The discussion on the impact of the proposed method on training speed is insufficient, requiring more detailed analysis to fully appreciate its practical implications.
In general discussion, the paper's contributions and limitations highlight the need for further research and analysis to fully exploit the potential of integrating stochastic gradient MCMC with stochastic optimization in deep learning contexts.