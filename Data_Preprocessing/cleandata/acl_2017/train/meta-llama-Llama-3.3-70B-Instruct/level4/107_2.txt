This manuscript presents a cross-lingual named entity recognition (NER) model, leveraging conditional random fields, maximum entropy Markov, and neural network-based NER approaches. The authors propose two methods for combining the output of these approaches, namely probability-based and ranking-based, as well as a method for selecting the most effective training instances from cross-lingual comparable corpora. Cross-lingual projection is achieved through a variant of Mikolov's method. Overall, the paper is well-organized, easy to follow, and exhibits good English quality. The combined annotation results are noteworthy.
Detailed comments:
The motivation behind proposing a variant of the Continuous Bag-of-word (CBOW) model is unclear, and insufficient details are provided about the model or its parameters. It would be beneficial to include the results obtained using the CBOW model to allow readers to assess the improvements of the proposed approach. Considering the use of a decay factor for surrounding embeddings, it may be worthwhile to explore the exponential decay approach presented in [1].
Similarly, a comparison between the original Mikolov's cross-lingual projections and the proposed frequency-weighted projections would be valuable. The significance of these contributions would be more apparent if readers could see that the proposed method offers superior performance.
The claim that "the proposed data selection scheme is very effective in selecting good-quality projection-labeled data and the improvement is significant" warrants further scrutiny. It is essential to determine whether the differences in results are statistically significant.
Reorganizing the text by integrating Section 4.4 into the beginning of Section 4.2 would improve clarity. Additionally, the evaluation of Table 2 would be better suited in the evaluation section.
A dedicated related work section is lacking, with some relevant information currently embedded in the introduction. Consider dividing the introduction into two separate sections to address this.
The evaluation section is concise, spanning only 1.5 pages, including the conclusion. Given the state-of-the-art results achieved, a more in-depth discussion and analysis of the results would be appreciated.
Recommended references include [1] Iacobacci, I., Pilehvar, M. T., & Navigli, R. (2016). Embeddings for word sense disambiguation: An evaluation study. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Vol. 1, pp. 897-907).