Strengths: 
The evaluation of bag-of-words and "bound" contexts, derived from either dependencies or sentence ordering, is a crucial contribution that will serve as a valuable reference for the community. The experiments conducted were relatively comprehensive, although some of the choices made could benefit from further justification. Notably, the authors employed downstream tasks for evaluation instead of relying solely on intrinsic assessments.
Weaknesses: 
A significant concern is the modification of the objective function in GBOW from p(c|\sum wi) to p(w|\sum ci). While this change is partially justified by the dependency-based context with a bound representation having only one word available for predicting the context, a more detailed discussion is warranted to clarify the rationale behind this decision. It is unclear whether non-dependency context with a bound representation would also be affected by this limitation, and how previous studies, such as Ling et al. (2015), addressed this issue. A notable weakness is the lack of comparison with the original objective function, which would have provided a more comprehensive understanding of the changes made. Furthermore, the authors modified GSG to align with GBOW without comparing it to the original objective, and including results from word vectors trained using the original GBOW and GSG objective functions would help justify these modifications. Additionally, the hyperparameter settings should be discussed in more detail, as they played a crucial role in Levy et al. (2015), and experimenting with different hyperparameter values may yield varying results depending on the task. 
Moreover, the description of the model trained in section 3.4 is unclear, with the authors only referring to it as a "simple linear classifier." In contrast, section 3.5 employs logistic regression with the average of the word vectors as input, labeled as a Neural Bag-of-Words model. Although previous work has used this terminology, it may be misleading, as it is essentially a linear model. Clarifying whether the models trained in sections 3.4 and 3.5 are identical is essential to determine whether the differing conclusions are due to changes in the task or the model.
General Discussion: 
This paper provides a valuable evaluation of context derived from dependency parses versus word position in a sentence, as well as bag-of-words versus tokens with relative position indicators. The findings of this study will be beneficial to the community, as they offer guidance on when and where to use word vectors trained using different approaches.
Emphasis to improve: 
The primary takeaway from this paper, which will be of most interest to future researchers, is presented at the end of sections 3.4 and 3.5 but should be summarized at the beginning of the paper. Specifically, the authors should include in the abstract that bound representations outperform bag-of-words representations for POS, chunking, and NER tasks, and that dependency contexts generally work better than linear contexts. Additionally, for a simple text classification model, bound representations perform worse than bag-of-words representations, with no significant difference between the different models or context types.
Small points of improvement: 
The term "unbounded" context should be referred to as "bag of words" to avoid potential confusion with the Generalized Bag-Of-Words technique. A minor correction is needed on page 043, where "distributional hypothesis" should be used instead of "Distributed Hypothesis." On page 069, citations should be separated by commas rather than semicolons. The abbreviation "DEPS" should be consistently capitalized throughout the paper and introduced as dependency parse tree context (Deps). Finally, a typo on page 085 should be corrected to read "How different contexts do affect model's performances..."