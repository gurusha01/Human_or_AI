This paper proposes a novel approach to generating code from natural language descriptions by leveraging a grammar model to capture the underlying syntax of the target programming language. The main contributions of this work are:
1. Syntax-driven neural code generation: The authors propose a neural code generation model that uses a grammar model to generate an abstract syntax tree (AST) from a natural language description. This approach allows the model to capture the structural information of the target code and generate well-formed code.
2. Grammar model: The authors define a probabilistic grammar model that factorizes the generation process of an AST into sequential application of actions, including applying production rules and emitting terminal tokens.
3. Parent feeding mechanism: The authors introduce a parent feeding mechanism that allows the model to pass information from parent actions to child actions, enabling the model to capture the recursive structure of the AST.
The strengths of this paper are:
1. State-of-the-art results: The authors achieve state-of-the-art results on two Python code generation tasks, outperforming existing sequence-to-sequence and semantic parsing approaches.
2. Effective use of syntax information: The authors demonstrate the importance of modeling syntax information in code generation, showing that their approach can generate well-formed code and improve performance on complex code generation tasks.
3. Robustness to AST size: The authors show that their approach is robust to the size of the reference ASTs, achieving good performance even on large ASTs.
The weaknesses of this paper are:
1. Limited evaluation: The authors only evaluate their approach on two Python code generation tasks and one semantic parsing task, which may not be representative of all code generation tasks.
2. Complexity of the model: The authors' approach requires a significant amount of engineering to define the grammar model and implement the parent feeding mechanism, which may be challenging to replicate.
3. Lack of interpretability: The authors do not provide a clear explanation of how the model generates code, which may make it difficult to understand and improve the model.
Questions to authors:
1. How do the authors plan to extend their approach to other programming languages, and what challenges do they anticipate?
2. Can the authors provide more insight into how the parent feeding mechanism works and how it contributes to the model's performance?
3. How do the authors plan to address the complexity of the model and make it more accessible to other researchers and practitioners?