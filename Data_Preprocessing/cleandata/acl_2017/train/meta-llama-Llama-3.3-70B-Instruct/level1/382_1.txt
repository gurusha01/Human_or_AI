This paper presents a novel framework for semi-automatically creating linguistically challenging NLG corpora from existing Knowledge Bases. The main contributions of this work are:
1. A framework for creating data-to-text corpora: The authors propose a generic framework for creating training corpora for NLG from existing Knowledge Bases, which can be used to train KB verbalisers.
2. A crowdsourcing approach for associating data with text: The authors use a crowdsourcing platform to associate data units with human-authored texts, ensuring a direct match between text and data.
3. A comparison with existing benchmarks: The authors compare their dataset (DBPNLG) with an existing dataset (RNNLG) and show that DBPNLG is more diverse in terms of attributes, input patterns, and input shapes.
The strengths of this paper are:
1. Novel framework: The proposed framework is a significant contribution to the field of NLG, as it provides a way to create challenging datasets from existing Knowledge Bases.
2. Improved diversity: The DBPNLG dataset shows improved diversity in terms of attributes, input patterns, and input shapes, making it a more challenging and interesting dataset for NLG tasks.
3. Comparison with existing benchmarks: The comparison with RNNLG provides a thorough evaluation of the proposed framework and highlights its strengths and weaknesses.
4. Experiments with sequence-to-sequence models: The experiments with sequence-to-sequence models demonstrate the challenges of generating linguistically complex texts from rich data and highlight the need for more advanced models.
The weaknesses of this paper are:
1. Limited size of the dataset: The DBPNLG dataset is smaller than the RNNLG dataset, which may limit its usefulness for training and testing NLG models.
2. High complexity of the dataset: The DBPNLG dataset is more complex and diverse than the RNNLG dataset, which may make it more challenging to work with.
3. Need for more advanced models: The experiments with sequence-to-sequence models show that more advanced models are needed to generate linguistically complex texts from rich data.
Questions to authors:
1. How do you plan to extend the DBPNLG dataset to make it larger and more comprehensive?
2. Can you provide more details on the crowdsourcing process and how you ensured the quality of the collected texts?
3. How do you think the proposed framework can be used to create datasets for other NLG tasks, such as dialogue generation or text summarization?