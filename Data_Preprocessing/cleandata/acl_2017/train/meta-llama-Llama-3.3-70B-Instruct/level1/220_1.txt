This paper presents a novel approach to metonymy resolution (MR) using a minimalist neural network architecture and a new feature extraction method called Predicate Window (PreWin). The authors claim that their approach achieves state-of-the-art results on the SemEval 2007 task on MR and introduce a new Wikipedia-based MR dataset called ReLocaR.
The main contributions of this work are:
1. The introduction of the PreWin method, which extracts a small window of context around the target entity using dependency parsing, and achieves better results than traditional methods that rely on a larger context window.
2. The creation of the ReLocaR dataset, which addresses the shortcomings of the SemEval 2007 dataset and provides a more balanced distribution of literal and metonymic examples.
3. The demonstration of the effectiveness of a minimalist neural network architecture in achieving state-of-the-art results on MR tasks.
The strengths of this paper are:
1. The authors provide a thorough evaluation of their approach on two datasets, SemEval 2007 and ReLocaR, and demonstrate its effectiveness in achieving state-of-the-art results.
2. The introduction of the PreWin method, which is a novel and effective approach to feature extraction for MR tasks.
3. The creation of the ReLocaR dataset, which addresses the need for more diverse and balanced datasets for MR tasks.
The weaknesses of this paper are:
1. The authors rely heavily on the SpaCy dependency parser, which may not be the best parser for all languages or domains.
2. The PreWin method may not generalize well to other classification tasks or datasets, and may require significant tuning and adaptation.
3. The authors do not provide a detailed analysis of the errors made by their approach, which could provide valuable insights into its limitations and areas for improvement.
Questions to authors:
1. How do the authors plan to address the issue of parser errors, which can significantly impact the performance of the PreWin method?
2. Can the authors provide more details on the annotation guidelines used for the ReLocaR dataset, and how they differ from those used for the SemEval 2007 dataset?
3. How do the authors plan to evaluate the generalizability of the PreWin method to other classification tasks and datasets, and what adaptations or modifications may be necessary to achieve good performance?