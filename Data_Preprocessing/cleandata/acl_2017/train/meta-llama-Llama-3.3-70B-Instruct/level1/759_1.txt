This paper presents a joint modeling approach to identify salient discussion points in spoken meetings and label the discourse relations between speaker turns. The main contributions of this work are: 
1. A novel joint model that leverages the interaction between content and discourse to improve prediction performance on both phrase-based content selection and discourse relation prediction tasks.
2. The use of a variation of the model to treat discourse relations as latent variables when true labels are not available for learning.
3. The application of the model to predict the consistency among team members' understanding of their group decisions, which is a critical aspect of meeting analysis.
The strengths of this paper are:
1. The proposed joint model outperforms SVM-based classifiers on both phrase selection and discourse relation prediction tasks, demonstrating the effectiveness of the joint modeling approach.
2. The use of latent discourse relations allows the model to be applied to scenarios where true labels are not available, making it more practical and widely applicable.
3. The evaluation of the model on predicting consistency of understanding in meetings shows that it can be used to improve the performance of state-of-the-art models in this task.
The weaknesses of this paper are:
1. The model relies on a set of predefined features, which may not capture all the nuances of human communication and may require careful tuning for optimal performance.
2. The use of a simple scoring function for the joint learning algorithm may not be optimal, and more sophisticated scoring functions may be needed to further improve the performance of the model.
3. The model is evaluated on a limited set of datasets, and its performance on other datasets and in different scenarios may vary.
Questions to authors:
1. How do the authors plan to address the issue of feature engineering, and what methods can be used to automatically extract relevant features from the data?
2. Can the authors provide more details on the scoring function used in the joint learning algorithm, and how it was chosen?
3. How do the authors plan to extend the model to handle more complex scenarios, such as multi-party meetings or meetings with multiple topics?