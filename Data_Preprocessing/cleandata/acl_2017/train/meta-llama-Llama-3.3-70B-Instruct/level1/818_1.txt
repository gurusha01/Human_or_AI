This paper presents a novel approach to learning commonsense knowledge from natural language text, focusing on physical implications of actions and relative physical relations among objects. The authors introduce a new task of commonsense knowledge extraction from language and propose a model that can infer relations over grounded object pairs together with first-order relations implied by physical verbs.
The main contributions of this work are:
1. Introduction of a new task of commonsense knowledge extraction from language, focusing on physical implications of actions and relative physical relations among objects.
2. Proposal of a model that can infer relations over grounded object pairs together with first-order relations implied by physical verbs.
3. Development of a new dataset, VERBPHYSICS, that compiles crowd-sourced knowledge of actions and objects.
The strengths of this paper are:
1. The authors address a significant challenge in natural language processing, which is learning commonsense knowledge from text.
2. The proposed model is able to infer physical implications of actions and relative physical relations among objects, which is a crucial aspect of human reasoning.
3. The authors provide a comprehensive evaluation of their model, including experiments on both frame prediction and object pair prediction tasks.
4. The paper is well-written, and the authors provide a clear explanation of their approach and results.
5. The dataset and code will be made publicly available, which will facilitate future research in this area.
The weaknesses of this paper are:
1. The model relies on a large amount of crowd-sourced data, which may be time-consuming and expensive to collect.
2. The authors do not provide a detailed analysis of the errors made by their model, which could provide insights into areas for improvement.
3. The model is limited to learning physical implications of actions and relative physical relations among objects, and it is not clear how it can be extended to learn other types of commonsense knowledge.
4. The authors do not provide a comparison with other state-of-the-art models for learning commonsense knowledge from text.
5. The paper could benefit from a more detailed discussion of the potential applications of the proposed model and the implications of the results.
Questions to authors:
1. How do the authors plan to extend their model to learn other types of commonsense knowledge, such as social norms or abstract concepts?
2. Can the authors provide more details about the crowd-sourcing process and the criteria used to select the object pairs and frames?
3. How do the authors plan to address the issue of reporting bias, which is a significant challenge in learning commonsense knowledge from text?
4. Can the authors provide more insights into the errors made by their model and how they plan to improve its performance?
5. How do the authors plan to make their dataset and code publicly available, and what are the plans for future research in this area?