This paper proposes a novel approach to relation extraction by reducing it to a reading comprehension problem. The authors map each relation to a set of natural-language questions and use a reading comprehension model to answer these questions, thereby extracting the relation. The main contributions of this work are:
1. Reduction of relation extraction to reading comprehension: The authors show that relation extraction can be reduced to a reading comprehension problem, allowing for the use of existing reading comprehension models and techniques.
2. Zero-shot learning: The authors demonstrate that their approach can generalize to unseen relations, allowing for zero-shot learning and reducing the need for large amounts of labeled training data.
3. Large-scale dataset creation: The authors create a large-scale dataset of over 30 million question-sentence-answer examples using a crowdsourcing approach, which can be used for training and evaluating reading comprehension models.
The strengths of this paper are:
1. Novel approach: The authors propose a novel approach to relation extraction, which has the potential to improve the state-of-the-art in this area.
2. Extensive experiments: The authors conduct extensive experiments to evaluate their approach, including experiments on unseen entities, unseen question templates, and unseen relations.
3. Large-scale dataset creation: The authors create a large-scale dataset, which can be used by other researchers to train and evaluate their own models.
The weaknesses of this paper are:
1. Limited evaluation: While the authors conduct extensive experiments, they only evaluate their approach on a single dataset (WikiReading) and do not compare it to other state-of-the-art relation extraction models.
2. Lack of analysis: The authors do not provide a detailed analysis of the errors made by their model, which could provide insights into how to improve it.
3. Dependence on reading comprehension model: The authors' approach relies on the quality of the reading comprehension model used, which may not always be accurate.
Questions to authors:
1. How do the authors plan to improve the accuracy of their model, particularly in cases where the reading comprehension model is not accurate?
2. Can the authors provide more details on the crowdsourcing approach used to create the large-scale dataset, including the cost and time required to create it?
3. How do the authors plan to evaluate their approach on other datasets and compare it to other state-of-the-art relation extraction models?