This paper introduces a new deep learning model for semantic role labeling (SRL) that achieves state-of-the-art results on the CoNLL 2005 and 2012 datasets. The model uses a deep highway BiLSTM architecture with constrained decoding, and the authors provide a detailed analysis of the model's strengths and limitations.
The main contributions of this work are:
1. A new state-of-the-art deep network for end-to-end SRL, supported by code and models that will be publicly available.
2. An in-depth error analysis indicating where the models work well and where they still struggle, including discussion of structural consistency and long-distance dependencies.
3. Experiments that point toward directions for future improvements, including a detailed discussion of how and when syntactic parsers could be used to improve these results.
The strengths of this paper are:
1. The model achieves state-of-the-art results on the CoNLL 2005 and 2012 datasets, with a 10% relative error reduction over the previous state of the art.
2. The authors provide a detailed analysis of the model's strengths and limitations, including an examination of the types of errors the model makes and how it performs on different types of dependencies.
3. The paper explores the potential for syntactic parsers to improve the model's performance, and provides experimental results demonstrating the benefits of using gold syntax and automatic syntax.
The weaknesses of this paper are:
1. The model requires a large amount of computational resources to train, which may limit its applicability in some settings.
2. The authors do not provide a detailed comparison with other state-of-the-art models, which makes it difficult to fully understand the model's strengths and weaknesses.
3. The paper assumes that the reader is familiar with the basics of SRL and deep learning, which may make it difficult for non-experts to follow.
Questions to authors:
1. Can you provide more details on how the model's performance varies depending on the quality of the input syntax?
2. How do you plan to address the issue of computational resources required to train the model?
3. Can you provide more comparisons with other state-of-the-art models to better understand the model's strengths and weaknesses?