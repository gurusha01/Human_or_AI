This paper proposes a method to determine the subjectivity of a corpus and demonstrates that word embeddings trained on task-specific corpora tend to outperform those trained on generic data. The authors also examine ways to combine information from generic and task-specific datasets and show that their method can work well for under-resourced languages.
The main contributions of this work are:
1. The proposal of a method to quantify the subjectivity of a corpus, which can be used to determine the usefulness of a corpus for sentiment analysis tasks.
2. The demonstration that word embeddings trained on task-specific corpora can outperform those trained on generic data, and that combining information from both sources can lead to even better results.
3. The development of a technique to approximate task-specific data by extracting subjective portions from generic corpora, which can be useful for under-resourced languages.
The strengths of this paper are:
1. The thorough evaluation of the proposed method on multiple datasets, including the Rotten Tomatoes and OpeNER datasets, which demonstrates the effectiveness of the approach.
2. The comparison of different techniques for combining information from generic and task-specific datasets, which provides insights into the best approach to use in different scenarios.
3. The extension of the method to under-resourced languages, which shows that the technique can be useful in a variety of settings.
The weaknesses of this paper are:
1. The reliance on a single metric (subjectivity) to determine the usefulness of a corpus, which may not capture all the relevant information.
2. The lack of a clear explanation of why the proposed method works, which makes it difficult to understand the underlying mechanisms.
3. The limited evaluation of the method on other tasks beyond sentiment analysis, which may limit its applicability.
Questions to authors:
1. Can you provide more insight into why the subjectivity metric is effective in determining the usefulness of a corpus for sentiment analysis tasks?
2. How do you plan to extend the method to other tasks beyond sentiment analysis, and what challenges do you anticipate facing?
3. Can you provide more details on the lexical overlap and diversity of the corpora used in the experiments, and how these factors affect the results?