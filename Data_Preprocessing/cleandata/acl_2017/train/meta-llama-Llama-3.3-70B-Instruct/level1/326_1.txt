This paper proposes an adversarial multi-criteria learning approach for Chinese word segmentation (CWS) by integrating shared knowledge from multiple heterogeneous segmentation criteria. The main contributions of this work are:
1. Multi-criteria learning for CWS: The authors propose three shared-private models to integrate multiple segmentation criteria, which can improve the performance of each criterion by exploiting shared information.
2. Adversarial training for shared layer: The authors introduce an adversarial strategy to force the shared layer to learn criterion-invariant features, which can prevent criterion-specific features from creeping into the shared space.
3. Extensive experiments on multiple datasets: The authors conduct experiments on eight CWS datasets with different segmentation criteria, demonstrating the effectiveness of their approach.
The strengths of this paper are:
1. Improved performance: The proposed approach achieves significant improvements over single-criterion methods on multiple datasets.
2. Effective use of shared information: The authors demonstrate that shared information across different criteria can be effectively exploited to improve performance.
3. Robustness to criterion-specific features: The adversarial training strategy helps to prevent criterion-specific features from affecting the shared layer.
The weaknesses of this paper are:
1. Complexity of the model: The proposed approach involves multiple components, including shared and private layers, and adversarial training, which may increase the complexity of the model.
2. Limited analysis of error distributions: While the authors provide some analysis of error distributions, more detailed analysis could provide further insights into the strengths and weaknesses of the approach.
3. Limited comparison to other multi-task learning approaches: The authors could provide more comparison to other multi-task learning approaches to demonstrate the effectiveness of their approach.
Questions to authors:
1. How do the authors plan to extend this approach to other NLP tasks that involve multiple criteria or annotations?
2. Can the authors provide more analysis on the learned shared features and how they relate to the different criteria?
3. How do the authors plan to address the potential issue of overfitting to the shared layer, especially when the number of criteria increases?