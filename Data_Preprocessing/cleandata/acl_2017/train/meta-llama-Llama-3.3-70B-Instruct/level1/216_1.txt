This paper presents a novel LDA-based model, segLDAcop, that generates topically coherent segments within documents by jointly segmenting documents and assigning topics to their words. The model relies on both document and segment-specific topic distributions and uses a copula to bind the topics associated with the words of a segment.
The main contributions of this work are:
1. Joint segmentation and topic assignment: The model simultaneously segments documents and assigns topics to words, allowing for more flexible and natural topic assignments.
2. Use of copulas: The model uses Frank's copula to bind the topics associated with the words of a segment, ensuring topic coherence.
3. Document and segment-specific topic distributions: The model relies on both document and segment-specific topic distributions, allowing for fine-grained differences in topic assignments.
The strengths of this paper are:
1. Improved perplexity: The model outperforms other state-of-the-art LDA-based models in terms of perplexity on six publicly available datasets.
2. Better topic coherence: The model produces more coherent topics, as measured by the Normalized Pointwise Mutual Information (NPMI) score.
3. Effective text classification: The model achieves better results in text classification tasks, as measured by the Micro F1 score.
The weaknesses of this paper are:
1. Computational complexity: The model's inference process may be computationally expensive due to the use of Gibbs sampling and the calculation of copula-based probabilities.
2. Hyperparameter tuning: The model has several hyperparameters that need to be tuned, which can be time-consuming and may require significant computational resources.
3. Limited interpretability: The use of copulas and joint segmentation and topic assignment may make it more challenging to interpret the results and understand the relationships between topics and segments.
Questions to authors:
1. How do the authors plan to address the computational complexity of the model's inference process?
2. Can the authors provide more insights into the hyperparameter tuning process and the sensitivity of the model's performance to different hyperparameter settings?
3. How do the authors plan to improve the interpretability of the model's results, particularly in terms of understanding the relationships between topics and segments?