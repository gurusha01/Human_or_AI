This paper proposes a scalable Bayesian learning framework for recurrent neural networks (RNNs) using stochastic gradient Markov Chain Monte Carlo (SG-MCMC) methods. The main contributions of this work are:
1. Scalable Bayesian learning for RNNs: The authors propose a framework that leverages SG-MCMC to learn weight uncertainty in RNNs, which is a key factor in preventing overfitting.
2. Effective regularization: The proposed approach provides a principled way to regularize RNNs, by adding gradient noise during training and using model averaging when testing.
3. State-of-the-art performance: The authors demonstrate the effectiveness of their approach on several natural language processing tasks, including language modeling, image captioning, and sentence classification.
The strengths of this paper are:
1. Theoretical foundations: The authors provide a clear and concise explanation of the theoretical foundations of SG-MCMC and its application to RNNs.
2. Extensive experiments: The authors conduct extensive experiments on several benchmark datasets, demonstrating the effectiveness of their approach.
3. Comparison to state-of-the-art methods: The authors compare their approach to several state-of-the-art methods, including stochastic optimization and dropout.
The weaknesses of this paper are:
1. Computational overhead: The proposed approach requires multiple times of forward-passing for model averaging in testing, which may increase the computational overhead.
2. Limited analysis of uncertainty: While the authors demonstrate the effectiveness of their approach in modeling weight uncertainty, they do not provide a detailed analysis of the uncertainty estimates.
3. Lack of comparison to other Bayesian methods: The authors do not compare their approach to other Bayesian methods, such as variational inference or Monte Carlo dropout.
Questions to authors:
1. How do the authors plan to address the computational overhead of their approach in testing?
2. Can the authors provide a more detailed analysis of the uncertainty estimates obtained by their approach?
3. How does the proposed approach compare to other Bayesian methods, such as variational inference or Monte Carlo dropout?