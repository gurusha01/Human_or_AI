Summary of the Paper
The paper proposes a novel neural architecture for generating source code from natural language descriptions. The approach is based on a grammar model that captures the underlying syntax of the target programming language. The model generates an abstract syntax tree (AST) by sequentially applying actions, which are either production rules or terminal tokens. The AST is then converted to surface code. The paper evaluates the approach on two Python code generation tasks and a semantic parsing benchmark, achieving state-of-the-art results.
Main Contributions
1. Syntax-driven neural code generation: The paper proposes a novel approach to code generation that leverages the underlying syntax of the target programming language.
2. Grammar model: The paper introduces a probabilistic grammar model that factorizes the generation process of an AST into sequential application of actions.
3. Improved performance: The approach achieves state-of-the-art results on two Python code generation tasks and a semantic parsing benchmark.
Strengths
1. Effective use of syntax: The approach effectively leverages the underlying syntax of the target programming language to generate well-formed code.
2. Improved performance: The approach achieves significant improvements in accuracy and BLEU score compared to existing methods.
3. Robustness to AST size: The approach is robust to the size of the reference ASTs, with performance dropping gradually as the size increases.
Weaknesses
1. Limited evaluation: The approach is evaluated on only two Python code generation tasks and a semantic parsing benchmark.
2. Lack of comparison to other grammar-based methods: The paper does not compare the approach to other grammar-based methods for code generation.
3. Limited analysis of failure cases: The paper does not provide a detailed analysis of failure cases, which could provide insights into the limitations of the approach.
Questions to Authors
1. How does the approach handle out-of-vocabulary tokens in the input natural language description?
2. Can the approach be extended to generate code in other programming languages?
3. How does the approach compare to other grammar-based methods for code generation?