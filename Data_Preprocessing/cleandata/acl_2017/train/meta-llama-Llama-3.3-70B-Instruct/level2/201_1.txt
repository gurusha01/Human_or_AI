This paper presents a systematic investigation of different context types and representations for learning word embeddings. The authors evaluate the effectiveness of various context types (linear and dependency-based) and representations (unbound and bound) on several tasks, including word similarity, word analogy, part-of-speech tagging, chunking, named entity recognition, and text classification.
The main contributions of this paper are:
1. A comprehensive evaluation of different context types and representations for learning word embeddings, which provides insights into their strengths and weaknesses.
2. The introduction of a new toolkit, word2vecPM, which allows for the easy implementation and comparison of different word embedding models with various context types and representations.
3. The finding that context representations play a more important role than context types in learning word embeddings, and that bound representation is essential for sequence labeling tasks.
The strengths of this paper include:
1. The thorough evaluation of different context types and representations, which provides a clear understanding of their effects on various tasks.
2. The use of a wide range of tasks to evaluate the word embedding models, which demonstrates their applicability and effectiveness in different areas of natural language processing.
3. The introduction of a new toolkit, which facilitates the reproduction and extension of the results.
The weaknesses of this paper include:
1. The lack of a clear conclusion on the best context type and representation for learning word embeddings, as the results vary across tasks.
2. The limited analysis of the results, which could be further explored to provide a deeper understanding of the effects of context types and representations on word embedding models.
3. The absence of a comparison with other word embedding models, such as those using subword or character-level representations, which could provide a more comprehensive understanding of the strengths and weaknesses of the evaluated models.
Questions to authors:
1. How do the results vary when using different corpora or hyper-parameters for training the word embedding models?
2. Can the authors provide a more detailed analysis of the effects of context types and representations on the word embedding models, including the impact on the learned representations and the performance on specific tasks?
3. How do the evaluated word embedding models compare to other models, such as those using subword or character-level representations, in terms of their performance on various tasks?