Summary of the Paper
The paper investigates the effectiveness of automatic evaluation metrics for Natural Language Generation (NLG) systems. The authors evaluate a wide range of metrics, including word-based and grammar-based ones, and demonstrate that they only weakly reflect human judgments of system outputs. The paper also proposes a new metric, RAINBOW, which combines the strengths of different automatic scores and achieves a higher correlation with human judgments.
Main Contributions
1. Evaluation of automatic metrics: The paper provides a comprehensive evaluation of various automatic metrics for NLG systems, including word-based and grammar-based metrics.
2. Proposal of a new metric: The authors propose a new metric, RAINBOW, which combines the strengths of different automatic scores and achieves a higher correlation with human judgments.
3. Analysis of the limitations of automatic metrics: The paper analyzes the limitations of automatic metrics, including their sensitivity to different systems and datasets, and their inability to distinguish between outputs of medium and good quality.
Strengths
1. Comprehensive evaluation: The paper provides a comprehensive evaluation of various automatic metrics for NLG systems, which is a significant contribution to the field.
2. Proposal of a new metric: The proposal of a new metric, RAINBOW, which achieves a higher correlation with human judgments, is a significant contribution to the field.
3. Analysis of the limitations of automatic metrics: The paper's analysis of the limitations of automatic metrics provides valuable insights into the challenges of evaluating NLG systems.
Weaknesses
1. Limited scope: The paper's evaluation is limited to a specific type of NLG system, namely end-to-end data-driven NLG systems.
2. Lack of comparison to other metrics: The paper does not provide a comparison of RAINBOW to other metrics that have been proposed in the literature.
3. Need for further evaluation: The paper's evaluation of RAINBOW is limited to a specific dataset and system, and further evaluation is needed to determine its effectiveness in other contexts.
Questions to Authors
1. How do the authors plan to extend the evaluation of RAINBOW to other types of NLG systems and datasets?
2. How does RAINBOW compare to other metrics that have been proposed in the literature?
3. What are the potential applications of RAINBOW in real-world NLG systems?