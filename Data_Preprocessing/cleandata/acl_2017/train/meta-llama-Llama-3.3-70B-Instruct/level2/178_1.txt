Summary of the Paper
The paper proposes a novel method for jointly learning concept, phrase, and word embeddings from an unlabeled text corpus using distant supervision from an ontology. The authors evaluate their approach on biomedical and general-domain concepts, demonstrating competitive performance with existing methods that require human-annotated data.
Main Contributions
1. Joint Embedding Model: The authors propose a joint embedding model that learns concept, phrase, and word embeddings from an unlabeled text corpus using distant supervision from an ontology.
2. Competitive Performance: The authors demonstrate that their approach achieves competitive performance with existing methods on biomedical and general-domain concept similarity and relatedness tasks.
3. Novel Dataset: The authors introduce a novel dataset of similarity and relatedness judgments for real-world entities, which can be used to evaluate the performance of concept embedding models.
Strengths
1. Effective Use of Distant Supervision: The authors demonstrate the effectiveness of using distant supervision from an ontology to learn concept embeddings without requiring human-annotated data.
2. Competitive Performance: The authors show that their approach achieves competitive performance with existing methods on biomedical and general-domain concept similarity and relatedness tasks.
3. Novel Dataset: The introduction of a novel dataset of similarity and relatedness judgments for real-world entities provides a valuable resource for evaluating concept embedding models.
Weaknesses
1. Limited Analysis of Hyperparameters: The authors could provide a more detailed analysis of the hyperparameters used in their model and their impact on performance.
2. Lack of Comparison to Other Joint Embedding Models: The authors could compare their approach to other joint embedding models that learn concept, phrase, and word embeddings.
3. Limited Evaluation on Downstream Tasks: The authors could evaluate the performance of their concept embeddings on downstream tasks, such as entity linking or question answering.
Questions to Authors
1. Can you provide more details on the hyperparameter tuning process and the impact of different hyperparameters on performance?
2. How does your approach compare to other joint embedding models that learn concept, phrase, and word embeddings?
3. Can you evaluate the performance of your concept embeddings on downstream tasks, such as entity linking or question answering?