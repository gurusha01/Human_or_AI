Summary of the Paper
This paper proposes a novel approach to event detection (ED) by exploiting argument information explicitly via supervised attention mechanisms. The authors argue that existing joint methods for ED and argument extraction (AE) do not effectively utilize argument information for ED, and instead propose a neural network-based approach that uses annotated arguments to improve ED performance. The approach involves constructing gold attention vectors using annotated arguments and employing them as supervision to train the attention mechanism. Experimental results on the ACE 2005 dataset demonstrate the effectiveness of the proposed approach, which outperforms state-of-the-art methods.
Main Contributions
1. The paper proposes a novel approach to ED that explicitly utilizes argument information via supervised attention mechanisms.
2. The authors introduce two strategies to construct gold attention vectors using annotated arguments.
3. The paper demonstrates the effectiveness of the proposed approach through systematic experiments on the ACE 2005 dataset.
Strengths
1. The paper addresses a significant limitation of existing joint methods for ED and AE, which do not effectively utilize argument information for ED.
2. The proposed approach is novel and innovative, and demonstrates significant improvements over state-of-the-art methods.
3. The experimental results are thorough and well-presented, and provide a clear understanding of the effectiveness of the proposed approach.
4. The paper provides a detailed analysis of the results, including an investigation of the impact of using events from FrameNet as extra training data.
5. The authors provide a clear and concise explanation of the proposed approach, making it easy to understand and replicate.
Weaknesses
1. The paper assumes that annotated arguments are available, which may not always be the case in real-world applications.
2. The proposed approach requires significant computational resources and may not be suitable for large-scale datasets.
3. The paper does not provide a detailed comparison with other attention-based methods for ED, which would be useful for understanding the strengths and limitations of the proposed approach.
4. The authors do not provide a clear explanation of how the proposed approach can be extended to other NLP tasks, such as argument extraction or event extraction.
5. The paper does not provide a detailed analysis of the errors made by the proposed approach, which would be useful for understanding its limitations and areas for improvement.
Questions to Authors
1. How do the authors plan to address the issue of annotated arguments not being available in real-world applications?
2. Can the proposed approach be extended to other NLP tasks, such as argument extraction or event extraction?
3. How do the authors plan to improve the computational efficiency of the proposed approach for large-scale datasets?
4. Can the authors provide a detailed comparison with other attention-based methods for ED?
5. How do the authors plan to analyze and address the errors made by the proposed approach?