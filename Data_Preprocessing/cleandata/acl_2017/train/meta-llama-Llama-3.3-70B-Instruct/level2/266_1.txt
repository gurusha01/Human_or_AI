Summary of the Paper
The paper proposes a method to improve sentiment analysis using word embeddings by quantifying the subjectivity of a corpus and combining information from generic and task-specific datasets. The authors demonstrate that word embeddings trained on task-specific corpora outperform those trained on generic data and that concatenating vectors trained on both datasets leads to better results. They also show that extracting subjective portions from generic corpora can approximate task-specific data and improve sentiment classification for under-resourced languages.
Main Contributions
1. Quantifying subjectivity: The authors propose a method to quantify the subjectivity of a corpus using OpinionFinder, which can help determine the usefulness of a corpus for sentiment analysis.
2. Combining generic and task-specific datasets: The authors demonstrate that concatenating vectors trained on generic and task-specific datasets outperforms a single representation trained on both datasets.
3. Approximating task-specific data: The authors show that extracting subjective portions from generic corpora can approximate task-specific data and improve sentiment classification for under-resourced languages.
Strengths
1. Novel approach: The paper proposes a novel approach to improving sentiment analysis using word embeddings by quantifying subjectivity and combining generic and task-specific datasets.
2. Extensive experiments: The authors conduct extensive experiments on multiple datasets, including under-resourced languages, to demonstrate the effectiveness of their approach.
3. Practical implications: The paper has practical implications for improving sentiment analysis in real-world applications, particularly for under-resourced languages.
Weaknesses
1. Limited analysis of results: The authors could have provided a more in-depth analysis of the results, particularly in terms of the impact of subjectivity on sentiment analysis.
2. Lack of comparison to other methods: The authors could have compared their approach to other methods for improving sentiment analysis, such as using polarity as a metric.
3. Limited discussion of limitations: The authors could have discussed the limitations of their approach, such as the potential bias in the OpinionFinder tool.
Questions to Authors
1. How do the authors plan to address the potential bias in the OpinionFinder tool, which may impact the accuracy of the subjectivity scores?
2. Can the authors provide more insight into the types of words that are missing from the embeddings models and how they impact sentiment analysis?
3. How do the authors plan to extend their approach to other tasks beyond sentiment analysis, such as text classification or information retrieval?