Summary of the Paper
This paper proposes a system, DrWiki, for open-domain question answering using Wikipedia as the unique knowledge source. The system consists of two components: Document Retriever, which finds relevant articles, and Document Reader, a multi-layer recurrent neural network model that detects answer spans in the retrieved articles. The authors evaluate their system on multiple existing QA datasets and demonstrate that it is highly competitive with respect to existing counterparts.
Main Contributions
1. Effective Document Retriever: The authors propose a simple yet effective document retrieval system that outperforms the built-in Wikipedia search engine.
2. State-of-the-art Document Reader: The authors develop a multi-layer recurrent neural network model that achieves state-of-the-art results on the SQuAD benchmark.
3. Multitask Learning with Distant Supervision: The authors demonstrate that multitask learning with distant supervision is an effective way to improve the performance of the system on multiple datasets.
Strengths
1. Strong Performance on SQuAD: The authors' Document Reader model achieves state-of-the-art results on the SQuAD benchmark, demonstrating its effectiveness in machine comprehension tasks.
2. Effective Use of Distant Supervision: The authors' use of distant supervision to generate additional training data for Document Reader is a key contribution, allowing the system to learn from multiple datasets.
3. Simple yet Effective Document Retriever: The authors' document retrieval system is simple to implement yet effective in retrieving relevant articles, making it a useful component of the overall system.
Weaknesses
1. Limited Contextual Understanding: While the authors' system performs well on machine comprehension tasks, it may struggle with questions that require a deeper understanding of context or nuances of language.
2. Dependence on Wikipedia: The system's reliance on Wikipedia as the unique knowledge source may limit its ability to answer questions that require information from other sources.
3. Room for Improvement in End-to-End Training: The authors note that end-to-end training across the Document Retriever and Document Reader pipeline could potentially improve the system's performance, but this is not explored in the paper.
Questions to Authors
1. How do the authors plan to address the limitation of relying on Wikipedia as the unique knowledge source?
2. Can the authors provide more details on the ablation analysis of the paragraph representations of the Document Reader model?
3. How do the authors plan to improve the system's performance on questions that require a deeper understanding of context or nuances of language?