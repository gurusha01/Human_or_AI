This paper proposes a novel approach to keyphrase prediction using a generative model based on an encoder-decoder framework. The main contributions of this work are: 
1. The proposal of an RNN-based generative model for keyphrase prediction, which incorporates a copy mechanism to handle out-of-vocabulary words.
2. The application of this model to predict both present and absent keyphrases in scientific publications, achieving state-of-the-art results.
3. The demonstration of the model's ability to generalize to other domains, such as news articles, without requiring additional training.
The strengths of this paper include:
1. The novelty of the approach, which combines the strengths of generative models and copy mechanisms to handle keyphrase prediction.
2. The thorough evaluation of the model on multiple datasets, including a newly introduced large-scale dataset (KP20k).
3. The demonstration of the model's ability to predict absent keyphrases, which is a challenging task that has not been addressed by previous work.
However, there are also some weaknesses:
1. The lack of detail in the evaluation results, particularly for the absent keyphrase prediction task, makes it difficult to fully understand the model's performance.
2. The model's reliance on a large amount of training data may limit its applicability to smaller datasets or domains.
3. The paper could benefit from a more detailed analysis of the model's limitations and potential areas for improvement.
Some questions to the authors include:
1. Can you provide more details on the evaluation results for the absent keyphrase prediction task, such as precision and recall curves?
2. How does the model perform on smaller datasets or domains, and are there any plans to adapt the model to these scenarios?
3. Have you considered exploring other architectures or techniques, such as transfer learning or multi-task learning, to further improve the model's performance?