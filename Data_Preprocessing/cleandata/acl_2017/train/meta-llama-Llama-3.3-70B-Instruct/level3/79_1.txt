The paper proposes a novel approach to computational argumentation mining (AM) using neural techniques for end-to-end learning. The authors frame AM as a dependency parsing problem, a sequence tagging problem, and a multi-task learning problem, and evaluate the performance of different models on a dataset of persuasive essays. The main contributions of the paper are the presentation of the first neural end-to-end solutions to AM, the demonstration that these solutions perform better than a competing feature-based ILP formulation, and the finding that a standard neural sequence tagging model performs robustly in different environments.
The strengths of the paper include the thorough evaluation of different models and the detailed analysis of the results. The authors provide a clear explanation of the different framings of AM and the models used to solve them, and the results are well-presented and easy to understand. The paper also highlights the importance of considering the relationship between components and relations in AM, and the need for a more restrained modeling approach when dealing with long documents.
However, there are some weaknesses in the paper. The authors do not provide a clear motivation for why AM should be framed as a dependency parsing problem, and the results for this framing are not as strong as those for the sequence tagging problem. Additionally, the paper could benefit from a more detailed discussion of the related work in the field, particularly with regards to the use of neural techniques for AM.
Some potential questions for the authors include: How do the results of the paper compare to those of other studies on AM? What are the implications of the findings for the development of AM systems in practice? How could the models presented in the paper be improved or extended to handle more complex AM tasks?
Overall, the paper presents a significant contribution to the field of AM, and the results have important implications for the development of AM systems. However, there are some areas where the paper could be improved, and the authors could benefit from addressing these in future work. 
The main contributions of this work are: 
1. The presentation of the first neural end-to-end solutions to computational AM.
2. The demonstration that these solutions perform better than a competing feature-based ILP formulation.
3. The finding that a standard neural sequence tagging model performs robustly in different environments.
The strongest arguments supporting the acceptance of this submission are: 
1. The paper presents a novel approach to AM using neural techniques for end-to-end learning.
2. The authors provide a thorough evaluation of different models and a detailed analysis of the results.
3. The paper highlights the importance of considering the relationship between components and relations in AM.
The strongest arguments against the acceptance of this submission are: 
1. The authors do not provide a clear motivation for why AM should be framed as a dependency parsing problem.
2. The results for the dependency parsing framing are not as strong as those for the sequence tagging problem.
3. The paper could benefit from a more detailed discussion of the related work in the field.
Questions to authors: 
1. How do the results of the paper compare to those of other studies on AM?
2. What are the implications of the findings for the development of AM systems in practice?
3. How could the models presented in the paper be improved or extended to handle more complex AM tasks?