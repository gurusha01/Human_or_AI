This paper proposes a novel approach to keyphrase generation, leveraging an encoder-decoder architecture with an attention mechanism and a copy mechanism. The model is designed to generate keyphrases not present in the source text, which is a significant advantage over existing methods. 
The main contributions of this work are: 
1. The introduction of a probabilistic framework for querying a database given the agent's beliefs over its fields, allowing for a differentiable and end-to-end trainable dialogue agent.
2. The development of a Soft-KB lookup method, which provides more information to the downstream reinforcement learner, enabling it to discover better dialogue policies.
3. The presentation of an end-to-end (E2E) agent, which demonstrates strong learning capability in simulations but suffers from overfitting when tested on real users.
The strengths of this paper include:
1. The proposed Soft-KB lookup method, which allows for a differentiable and end-to-end trainable dialogue agent, providing more information to the downstream reinforcement learner.
2. The development of an E2E agent, which demonstrates strong learning capability in simulations, making it a promising approach for personalized dialogue agents.
3. The evaluation of the proposed methods using both simulated and real users, providing a comprehensive understanding of their performance.
However, there are also some weaknesses:
1. The lack of clarity on whether all evaluated models are trained and tested on the same datasets, which raises concerns about the evaluation methodology.
2. The distinction between absent keyphrases and out-of-vocabulary (OOV) words is not clear, and the usage of OOV is inconsistent throughout the paper.
3. The exposition of the copy mechanism is unclear and misleading, and the intuition behind it is not well-explained, particularly with regards to its ability to generate absent keyphrases.
To address these weaknesses, the authors should provide more details on the evaluation methodology, clarify the distinction between absent keyphrases and OOV words, and provide a clearer explanation of the copy mechanism. Additionally, the authors should consider using more advanced techniques to improve the performance of the E2E agent on real users, such as using pre-trained language models or incorporating more diverse training data. 
Some questions to the authors include:
1. Can you provide more details on the evaluation methodology, including the datasets used for training and testing each model?
2. How do you distinguish between absent keyphrases and OOV words, and how do you handle OOV words in the proposed model?
3. Can you provide a clearer explanation of the copy mechanism and its intuition, particularly with regards to its ability to generate absent keyphrases?