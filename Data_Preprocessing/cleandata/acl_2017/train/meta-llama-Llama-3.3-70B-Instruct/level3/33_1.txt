This paper presents a novel approach to learning semantic hierarchies using a fusion of discriminative and generative architectures, combined with a simple lexical structure rule. The key strength of the paper is the innovative idea of incorporating sentiment information through regularization, which is a key contribution to the field. 
The main contributions of this work are: 
1. A uniform fusion architecture that can learn semantic hierarchies via word embeddings without any background knowledge.
2. The method outperforms state-of-the-art methods on a manually labeled test dataset, especially with a high precision value for application.
3. The fusion learning architecture is language-independent, which can be easily expanded to be suitable for other languages.
The strengths of this paper include:
1. The innovative idea of incorporating sentiment information through regularization, which is a key strength of the paper.
2. The experiments appear to be well-done from a technical point of view, and the in-depth analysis of the model is useful.
3. The related work section provides a good review of sentiment literature, which helps to contextualize the contributions of the paper.
However, there are also some weaknesses:
1. The idea is very close to distant supervision, which may not be entirely novel.
2. The baselines used in the paper are mostly poorly informed, which makes the comparison to related work somewhat shaky.
3. The explanation of the regularizers in the paper is lengthy and repetitive, with inconsistent notation that is hard to follow.
4. The paper could benefit from some proofreading to fix grammatical errors and typos, and the figures and tables are too small to be read in print.
Some questions to the authors include:
1. How do the authors plan to address the issue of distant supervision, and what modifications can be made to the model to make it more novel?
2. Can the authors provide more details on the baselines used in the paper, and how they were selected?
3. How do the authors plan to improve the readability of the paper, particularly with regards to the explanation of the regularizers and the notation used?