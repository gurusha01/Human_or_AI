This paper proposes a novel approach to constructing semantic hierarchies using a fusion learning architecture based on word embeddings. The method combines a discriminative model and a generative model to discover hypernym-hyponym relations, and is assisted by a simple lexical structure rule to improve performance. The paper claims to achieve state-of-the-art results on a manually labeled test dataset, with an F1-score of 74.20% and a precision-value of 91.60%.
The main contributions of this paper are:
1. A novel fusion learning architecture that combines discriminative and generative models to learn semantic hierarchies.
2. The use of a simple lexical structure rule to assist the fusion architecture in discovering hypernym-hyponym relations.
3. State-of-the-art results on a manually labeled test dataset, with a significant improvement in precision-value over previous methods.
The strengths of this paper are:
1. The proposed method tackles an important issue in natural language processing, namely the construction of semantic hierarchies.
2. The use of word embeddings and a fusion learning architecture is a well-chosen approach to this problem.
3. The experimental results demonstrate the effectiveness of the proposed method, with state-of-the-art results on a manually labeled test dataset.
However, there are also some weaknesses in this paper:
1. The evaluation and presentation of the results could be improved, with a lack of clarity in the list of baselines and numerous errors in writing.
2. The comparison to the state-of-the-art approach is not convincing, with small differences in performance on the first dataset and a lack of reference to the previous state-of-the-art method, Memb.
3. The paper lacks originality and novelty in its approach, but its application to a problem that has not been addressed with deep learning yet makes it interesting and worthy of consideration.
4. The evaluation section needs to be reorganized to properly list baseline systems, show the benefit of the approach, and highlight where others fail, with the addition of significance tests to support the claims made.
Overall, this paper makes a significant contribution to the field of natural language processing, but could be improved with more careful evaluation and presentation of the results, as well as a more convincing comparison to state-of-the-art approaches. 
Questions to authors:
1. Can you provide more details on the training process of the fusion architecture, including the optimization algorithm used and the hyperparameter tuning process?
2. How do you plan to address the issue of limited coverage of the training data, and what strategies can be employed to improve the performance of the model on out-of-vocabulary words?
3. Can you provide more insights into the lexical structure rule used in the fusion architecture, and how it is designed to capture the semantic relationships between words?