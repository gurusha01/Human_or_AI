This paper presents a novel approach to automated short-answer scoring for university entrance examinations in Japan. The proposed system utilizes a combination of machine learning and human evaluation to score written answers. The main contributions of this work include the development of a scoring support system that can handle short-answer tests with high accuracy, the use of random forests for machine learning, and the incorporation of semantic similarity measures to improve scoring accuracy.
The strengths of this paper include the clear breakdown of the system into components, sound empirical analysis through performance evaluation, and impressive results. The system's ability to handle short-answer tests with high accuracy is a significant contribution, especially given the challenges of recognizing textual entailment and semantic similarity in written answers. The use of random forests for machine learning is also a strength, as it allows for effective handling of multiple predictor variables and estimation of variable importance.
The weaknesses of this paper include the lack of details on the ensemble model and its creation, which the authors are requested to describe in the rebuttal and paper. Additionally, the paper could be improved with a qualitative analysis of example cases where the components of gating, character embedding, and self-embedding become crucial in answering questions correctly.
The main contributions of this work can be summarized as follows:
1. Development of a scoring support system for short-answer tests that can handle high accuracy scoring.
2. Use of random forests for machine learning to improve scoring accuracy.
3. Incorporation of semantic similarity measures to improve scoring accuracy.
The strengths of this paper can be summarized as follows:
1. Clear breakdown of the system into components.
2. Sound empirical analysis through performance evaluation.
3. Impressive results in terms of scoring accuracy.
The weaknesses of this paper can be summarized as follows:
1. Lack of details on the ensemble model and its creation.
2. Need for qualitative analysis of example cases to demonstrate the effectiveness of the system's components.
Questions to authors:
1. Can you provide more details on the ensemble model and its creation?
2. How do you plan to address the issue of obtaining a sufficiently large number of human scores for supervised learning?
3. Can you provide more examples of how the system's components, such as gating, character embedding, and self-embedding, contribute to accurate scoring?