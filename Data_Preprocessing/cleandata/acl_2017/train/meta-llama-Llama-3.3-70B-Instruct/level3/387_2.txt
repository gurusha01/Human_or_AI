This paper presents a novel approach to sentiment analysis and sarcasm detection by combining cognitive and textual features using a deep CNN framework. The proposed framework automatically extracts features from eye-movement data and text, outperforming existing systems that rely on handcrafted features or text-only inputs.
The main contributions of this work are:
1. The introduction of a multimodal ensemble of features learned from text and eye-movement data using CNNs.
2. The demonstration of significant performance improvements over existing systems on multiple published datasets.
3. The analysis of learned features, which confirms their ability to represent deep linguistic subtleties in text.
The strengths of this paper include:
1. The novelty of the approach, which combines cognitive and textual features for sentiment analysis and sarcasm detection.
2. The thorough experimentation and evaluation of the proposed framework on multiple datasets.
3. The detailed analysis of the learned features, which provides insights into their effectiveness.
However, there are some weaknesses:
1. The lack of replicability due to insufficient data for feature extraction, making it difficult for researchers to improve the system.
2. The need for more details on the model's suitability for sarcastic/non-sarcastic utterances and the usefulness of eye-movement data beyond textual features.
3. The potential overfitting issue in the CNN model, particularly for dataset 2, which may require tuning of regularization parameters.
To address these weaknesses, the authors could provide more information on the data collection process and make the dataset publicly available. Additionally, they could conduct further experiments to investigate the model's performance on different types of utterances and provide more insights into the usefulness of eye-movement data.
Questions to the authors:
1. How do you plan to address the issue of replicability and make the dataset publicly available?
2. Can you provide more details on the model's performance on different types of utterances, such as sarcastic vs. non-sarcastic texts?
3. How do you plan to investigate the usefulness of eye-movement data beyond textual features and provide more insights into its effectiveness?