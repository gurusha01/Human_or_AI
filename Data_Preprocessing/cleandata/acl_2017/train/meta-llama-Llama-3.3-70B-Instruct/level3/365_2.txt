This paper presents a sequence-to-sequence approach for German historical text normalization, utilizing a multi-task learning framework to improve performance. The authors argue that this approach replaces the need for an attention mechanism, but it would be beneficial to investigate why attention harms performance in this context.
The paper's novelty lies in its application of sequence-to-sequence models to historical text correction, but it lacks reference to past work on sequence-to-sequence multi-task learning. The main contributions of this paper are:
1. The application of sequence-to-sequence models to historical text normalization, which has not been extensively explored in previous research.
2. The use of a multi-task learning framework to improve performance, which shows promise in this context.
3. The development of a system that can be used to support human raters in scoring short-answer tests, which has potential practical applications.
The strengths of this paper include:
1. The paper presents a clear and well-structured approach to historical text normalization, which is a challenging task.
2. The use of a multi-task learning framework is a good choice, as it allows the model to learn multiple related tasks simultaneously.
3. The paper provides a thorough evaluation of the system's performance, including an analysis of the variables that contribute to distinction.
However, there are also some weaknesses:
1. The paper only tests the system on one German historical text dataset, which limits the generalizability of the results.
2. The paper does not evaluate the system on other languages or datasets, which would be necessary to demonstrate its broader applicability.
3. The paper could benefit from a more detailed analysis of why attention does not work in this context, and how the multi-task learning framework addresses this issue.
Questions to the authors:
1. Can you provide more insight into why attention does not work in this context, and how the multi-task learning framework addresses this issue?
2. How do you plan to extend this work to other languages and datasets, and what challenges do you anticipate in doing so?
3. Can you provide more details on the system's performance on different types of historical texts, and how it handles variations in language and style?