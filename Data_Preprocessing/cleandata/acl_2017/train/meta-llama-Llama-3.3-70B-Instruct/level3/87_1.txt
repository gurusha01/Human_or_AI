This paper presents a novel approach to answering cloze-style questions over documents, introducing the Gated-Attention (GA) reader. The GA reader combines a multi-hop architecture with a novel attention mechanism, allowing the model to build query-specific representations of tokens in the document for accurate answer selection. 
The main contributions of this work are: 
1. The introduction of the GA reader, which achieves state-of-the-art performance on several large-scale benchmark datasets.
2. The design of a novel multiplicative gating mechanism, which is shown to be superior to addition and concatenation operations for implementing gated-attentions.
3. An ablation study demonstrating the importance of the GA module and other components of the model, such as character embeddings and token-specific attentions.
The strengths of this paper include:
1. The GA reader's ability to achieve state-of-the-art performance on several benchmark datasets, demonstrating its effectiveness in answering cloze-style questions.
2. The novel attention mechanism, which allows the model to focus on different aspects of the query and document at different layers.
3. The thorough ablation study, which provides insight into the importance of different components of the model.
The weaknesses of this paper include:
1. The lack of comparison to other state-of-the-art methods, which makes it difficult to fully evaluate the effectiveness of the GA reader.
2. The limited analysis of the attention distributions, which could provide further insight into the model's decision-making process.
3. The use of a relatively simple baseline, which may not fully represent the current state-of-the-art in the field.
Questions to the authors:
1. How does the GA reader compare to other state-of-the-art methods, such as SemGraph and Unsupervised Keyphrase Extraction?
2. Can the authors provide further analysis of the attention distributions, such as visualizations or quantitative metrics?
3. How does the GA reader perform on other types of question-answering tasks, such as open-domain or multi-step reasoning questions?