Summary of the Paper
The paper proposes a novel summarization task, concept-map-based multi-document summarization (MDS), which aims to create a concept map that represents the most important content of a set of related documents. The authors introduce a new crowdsourcing scheme, low-context importance annotation, to determine the importance of propositions in a document cluster. They use this scheme to create a gold-standard corpus of 30 topics, each with a summarizing concept map. The corpus is designed to be larger and more heterogeneous than existing summarization corpora.
Main Contributions
1. Proposal of a novel summarization task, concept-map-based MDS.
2. Introduction of a new crowdsourcing scheme, low-context importance annotation.
3. Creation of a gold-standard corpus for concept-map-based MDS.
Strengths
1. The paper addresses a significant gap in the field of summarization by proposing a new task that can effectively represent complex relationships between concepts.
2. The low-context importance annotation scheme is a novel and efficient approach to crowdsourcing importance annotations.
3. The created corpus is large and heterogeneous, making it a valuable resource for future research.
Weaknesses
1. The paper relies heavily on crowdsourcing, which may raise concerns about the quality and reliability of the annotations.
2. The baseline method proposed in the paper is relatively simple and may not be competitive with state-of-the-art summarization methods.
3. The evaluation metrics used in the paper may not be comprehensive enough to fully capture the quality of the generated concept maps.
Questions to Authors
1. How do the authors plan to address the potential quality issues with crowdsourcing, and what measures can be taken to ensure the reliability of the annotations?
2. Can the authors provide more details on the baseline method and its limitations, and how it can be improved to better compete with state-of-the-art summarization methods?
3. Are there any plans to explore other evaluation metrics or human evaluation protocols to more comprehensively assess the quality of the generated concept maps?