This paper proposes a novel approach to keyphrase prediction using a generative model based on the encoder-decoder framework. The model utilizes recurrent neural networks (RNNs) and a copy mechanism to capture the semantic meaning of the text and generate keyphrases. The authors claim that their model can predict both present and absent keyphrases, outperforming existing supervised and unsupervised extraction methods.
The main contributions of this paper are: 
1. The proposal of an RNN-based generative model for keyphrase prediction, which incorporates a copy mechanism to handle rarely-occurred phrases.
2. The model's ability to predict absent keyphrases, which is a challenging task that existing methods cannot handle.
3. The comprehensive empirical study on six datasets, demonstrating the effectiveness of the proposed model for generating both present and absent keyphrases.
The strengths of this paper include:
1. The novelty of the approach, which combines the encoder-decoder framework with a copy mechanism to capture the semantic meaning of the text.
2. The comprehensive empirical study, which demonstrates the effectiveness of the proposed model on various datasets.
3. The ability of the model to predict absent keyphrases, which is a significant improvement over existing methods.
However, there are some weaknesses in the paper:
1. The presentation of the model needs improvement, including clarification on the pooling method used for embedding features and the definition of variables in Equation (7).
2. The paper lacks clarity in presenting results, including missing individual F1 scores in Table 2 and unclear explanations for the experiment in Table 4.
3. The introduction to pointer networks and recurrent neural networks needs to be lengthier and more explanatory for unfamiliar readers.
4. The paper requires additional explanations and citations for certain terms and concepts, such as the elu activation function and hyperparameter selection.
To improve the paper, the authors should address these weaknesses and provide more detailed explanations of their model and results. Additionally, they should consider comparing their model with human annotators and evaluating the quality of predicted phrases by human judges in future work. 
Questions to authors:
1. Can you provide more details on the pooling method used for embedding features and the definition of variables in Equation (7)?
2. How do you plan to address the issue of correlation among target keyphrases in future work?
3. Can you provide more explanations on the elu activation function and hyperparameter selection used in the model?