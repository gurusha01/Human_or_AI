This paper presents a novel approach to answering cloze-style questions over documents, introducing the Gated-Attention (GA) Reader. The model combines a multi-hop architecture with a gated-attention mechanism, allowing it to iteratively refine token representations and focus on relevant parts of the document. The GA Reader achieves state-of-the-art results on several large-scale benchmark datasets, including CNN, Daily Mail, and Who Did What.
The main contributions of this work are:
1. The introduction of the GA Reader, which combines a multi-hop architecture with a gated-attention mechanism to achieve state-of-the-art results on several benchmark datasets.
2. The demonstration of the effectiveness of multiplicative gating in implementing gated-attentions, which is shown to be superior to addition and concatenation operations.
3. The provision of an ablation study, which shows statistically significant improvements of using Gated Attention as information filters.
The strengths of this paper are:
1. The GA Reader achieves state-of-the-art results on several benchmark datasets, demonstrating its effectiveness in answering cloze-style questions.
2. The model's design is backed up by an ablation study, which provides evidence for the importance of the gated-attention mechanism.
3. The paper provides a thorough analysis of the model's performance, including attention visualization, which helps to understand how the model arrives at its answers.
The weaknesses of this paper are:
1. The lack of explanation for the differences in performance across different datasets and variants of the model.
2. The absence of information on statistical significance, including which test was used and the p-value, in the experimental results.
3. The need for additional feature engineering for optimal performance on certain datasets, such as CBT.
Questions to the authors:
1. Can you provide more insight into why the GA Reader performs differently across different datasets and variants of the model?
2. How do you plan to address the issue of statistical significance in the experimental results?
3. Can you discuss the potential applications of the GA Reader beyond text comprehension, and how it may be adapted for other tasks?