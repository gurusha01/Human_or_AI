This paper proposes a novel approach to sentiment and sarcasm detection by leveraging cognitive features extracted from eye-movement data using Convolutional Neural Networks (CNNs). The authors introduce a framework that automatically extracts cognitive features from gaze data and combines them with textual features to improve classification performance.
The strengths of the paper include the originality of the proposed approach, the good accuracy of the similarity measure, and the large number and diversity of datasets used for evaluation. The use of CNNs to learn features from both gaze and text data is a significant contribution, as it allows for the automatic extraction of cognitive features without manual feature engineering.
However, there are several weaknesses and imprecisions in the paper. The authors do not provide sufficient detail on the computation of features and their impact on similarity accuracy evaluation. Additionally, the code and training and evaluation sets are not made available, making it difficult to replicate the experiments. The paper also contains several typos and formatting errors, such as incorrect figure and table references and grammatical mistakes.
The main contributions of this work are:
1. The proposal of a novel approach to sentiment and sarcasm detection using cognitive features extracted from eye-movement data.
2. The use of CNNs to learn features from both gaze and text data, allowing for automatic extraction of cognitive features.
3. The evaluation of the proposed approach on multiple published datasets, demonstrating significant performance improvements over existing systems.
The strengths of the paper are:
1. The originality of the proposed approach and the use of CNNs to learn features from gaze data.
2. The good accuracy of the similarity measure and the large number and diversity of datasets used for evaluation.
3. The potential of the proposed approach to improve sentiment and sarcasm detection performance in various applications.
The weaknesses of the paper are:
1. The lack of detail on feature computation and their impact on similarity accuracy evaluation.
2. The unavailability of the code and training and evaluation sets, making it difficult to replicate the experiments.
3. The presence of typos and formatting errors, which can make the paper difficult to follow.
Questions to the authors:
1. Can you provide more detail on the computation of features and their impact on similarity accuracy evaluation?
2. Will you make the code and training and evaluation sets available to facilitate replication of the experiments?
3. How do you plan to address the issue of overfitting, which was observed in some of the experiments?