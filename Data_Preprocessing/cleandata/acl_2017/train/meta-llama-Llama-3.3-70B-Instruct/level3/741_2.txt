This paper proposes a comprehensive evaluation methodology for the task of ghostwriting rap lyrics, which captures complementary aspects of this task and its goals. The main contributions of this paper are: 
1. A manual evaluation methodology that assesses several key properties of generated verse, including fluency, coherence, and style matching.
2. A dataset of authentic verse, manually annotated for style matching, which can be used as a gold standard for future work on automatic representation of similarity between artists' styles.
3. A fully automated evaluation method that replicates the results of a previously available semi-automatic method and can be used to inspect the performance of ghostwriter models.
The strengths of this paper are:
1. The proposed evaluation methodology is comprehensive and captures multiple aspects of the ghostwriting task, providing a more complete understanding of the task's goals and challenges.
2. The manual evaluation methodology is well-designed and provides a clear understanding of the fluency, coherence, and style matching of generated verses.
3. The automated evaluation method is fully automated and can be used to evaluate the performance of ghostwriter models on a large scale.
The weaknesses of this paper are:
1. The paper lacks a clear discussion on the nature of the task and the chosen metrics, including the impact of lexical sparsity on performance.
2. The paper has some unclear points, such as how the authors obtained vectors for word senses used in their analysis.
3. The evaluation results highlight the truly multifaceted nature of the ghostwriting task, but the paper could benefit from a more in-depth analysis of the results and their implications for future work.
Questions to authors:
1. Can you provide more details on how you obtained vectors for word senses used in your analysis?
2. How do you plan to address the issue of lexical sparsity in future work, and what implications does this have for the evaluation methodology?
3. Can you provide more insight into the results of the evaluation, particularly with regards to the correlation between the number of verses and coherence score? 
Overall, this paper presents a solid work on evaluating ghostwriting models, and the proposed evaluation methodology has the potential to be useful for other similar generation tasks. The paper is recommended for presentation at the ACL Meeting.