This paper presents a comprehensive evaluation methodology for the task of ghostwriting rap lyrics, which is a valuable contribution to the field of natural language generation. The authors develop a manual evaluation method that assesses several key properties of generated verse, including fluency, coherence, and style matching, and create a dataset of authentic verse manually annotated for style matching.
The main contributions of this paper are: 
1. A comprehensive manual evaluation methodology for ghostwriting rap lyrics, which captures complementary aspects of this task and its goals.
2. A dataset of authentic verse manually annotated for style matching, which can be used as a gold standard for future work on automatic representation of similarity between artists' styles.
3. A fully automated evaluation method that replicates the results of a previously available semi-automatic method and confirms that the LSTM model generalizes better than the baseline model.
The strengths of this paper are:
1. The authors provide a thorough analysis of the ghostwriting task and its challenges, and develop a comprehensive evaluation methodology that addresses these challenges.
2. The paper presents a detailed description of the dataset and the evaluation methodology, which makes it easy to follow and replicate the results.
3. The authors provide a clear and concise discussion of the results, highlighting the strengths and weaknesses of the proposed evaluation methodology.
However, there are also some weaknesses:
1. The authors lack awareness of related work, particularly in the area of NLG and DBPedia, and rely too heavily on a single obscure paper.
2. The feasibility of domain-independent microplanning is questionable, and the authors need to discuss this concern and show awareness of the domain-dependent nature of microplanning.
3. The quality of the crowdsourced texts used to train the microplanner is a concern, as random crowdsourcers may not produce well-written or easy-to-read texts.
4. The presentation of the paper needs improvement, particularly in terms of font size, with some text in figures being tiny and difficult to read.
Some questions to the authors:
1. How do the authors plan to address the lack of awareness of related work, particularly in the area of NLG and DBPedia?
2. Can the authors provide more details on the feasibility of domain-independent microplanning and how they plan to address this concern?
3. How do the authors plan to improve the quality of the crowdsourced texts used to train the microplanner?
4. Can the authors provide more details on the presentation of the paper, particularly in terms of font size and figure readability?