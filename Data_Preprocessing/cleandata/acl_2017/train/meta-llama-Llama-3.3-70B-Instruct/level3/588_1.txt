This paper proposes a novel approach to semantic parsing by introducing the Neural Symbolic Machine (NSM), which integrates a sequence-to-sequence neural "programmer" with a symbolic non-differentiable computer. The NSM framework is designed to support abstract, scalable, and precise operations through a friendly neural computer interface. The paper's main contribution is the proposed task and data, which has the potential to drive the field forward.
The strengths of this paper include a well-chosen collection of baselines, well-chosen main models, and clear and well-argued text. The authors provide a thorough explanation of the NSM framework, including the "programmer" and "computer" components, and demonstrate its effectiveness on the WEBQUESTIONSSP dataset. The use of curriculum learning and augmented REINFORCE training are also notable strengths of the paper.
However, one weakness of the paper is that the authors do not provide a detailed analysis of the errors made by the NSM model. While they mention that search failure and ranking failure are two main sources of errors, they do not provide a thorough breakdown of the types of errors made by the model. Additionally, the authors could have provided more details on the hyperparameter settings and the training process, which would have made the paper more reproducible.
The main contributions of this paper are:
1. The proposal of the Neural Symbolic Machine (NSM) framework, which integrates a sequence-to-sequence neural "programmer" with a symbolic non-differentiable computer.
2. The demonstration of the effectiveness of the NSM framework on the WEBQUESTIONSSP dataset, achieving state-of-the-art results with weak supervision.
3. The introduction of curriculum learning and augmented REINFORCE training, which are shown to improve the performance of the NSM model.
Overall, this paper presents a significant contribution to the field of semantic parsing and has the potential to drive future research in this area. 
Questions to authors:
1. Can you provide more details on the hyperparameter settings and the training process, including the learning rate schedule and the batch size?
2. How do you plan to address the issue of overfitting, which is mentioned as a major problem in the paper?
3. Can you provide a more detailed analysis of the errors made by the NSM model, including a breakdown of the types of errors and their frequencies?