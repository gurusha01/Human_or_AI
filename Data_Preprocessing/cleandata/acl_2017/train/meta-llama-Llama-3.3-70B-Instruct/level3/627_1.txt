This paper proposes a dialogue agent, KB-InfoBot, which helps users search knowledge bases without composing complicated queries. The agent uses a joint optimization framework with a reinforce algorithm to learn from user simulator interactions in two training phases. The key contribution of the paper is the integration of differentiable access to the knowledge base in the joint optimization framework.
The main contributions of this work are:
1. The proposal of a probabilistic framework for querying a knowledge base given the agent's beliefs over its fields.
2. The development of an end-to-end trainable dialogue agent for information access.
3. The evaluation of the proposed agent against a user simulator and real users, demonstrating its effectiveness in discovering better dialogue policies.
The strengths of this paper are:
1. The use of a probabilistic framework for querying the knowledge base, which allows for differentiable access and end-to-end training.
2. The evaluation of the proposed agent against a user simulator and real users, which demonstrates its effectiveness in real-world scenarios.
3. The proposal of a deployment strategy that allows a dialogue system to be tailored to specific users via learning from agent-user interactions.
The weaknesses of this paper are:
1. The use of a reinforce algorithm, which has a high variance problem and may not be the most effective choice for this task.
2. The lack of a truly end-to-end system, as response generation is handcrafted rather than learned.
3. The overfitting of the end-to-end model to the simulator, which results in poor performance in human evaluation.
Questions to the authors:
1. How did you choose the hyperparameters for the reinforce algorithm, and did you consider other algorithms for training the dialogue agent?
2. Can you provide more details on the user simulator and the natural language generator used in the experiments?
3. How do you plan to address the overfitting issue of the end-to-end model, and what strategies do you propose for improving its performance in human evaluation?