This paper presents a comprehensive evaluation methodology for the task of ghostwriting rap lyrics, which is a challenging and timely direction in natural language generation (NLG). The authors develop a manual evaluation methodology that assesses several key properties of generated verse, including fluency, coherence, and style matching. They also create a dataset of authentic verse, manually annotated for style matching, and propose a fully automated evaluation method that replicates the results of a previously available semi-automatic method.
The main contributions of this paper are: 
1. A comprehensive manual evaluation methodology for ghostwriting rap lyrics, which captures complementary aspects of this task and its goals.
2. A dataset of authentic verse, manually annotated for style matching, which can be used as a gold standard for future work on automatic representation of similarity between artists' styles.
3. A fully automated evaluation method that replicates the results of a previously available semi-automatic method and can be used to inspect the performance of ghostwriter models.
The strengths of this paper are:
1. The authors provide a clear and comprehensive evaluation methodology for ghostwriting rap lyrics, which is a challenging task in NLG.
2. The paper presents a detailed analysis of the results, including correlations between different metrics and insights into future directions for generative models.
3. The authors make their dataset and annotation interface publicly available, which can facilitate future research in this area.
The weaknesses of this paper are:
1. The work reported in the paper may not represent a substantial advance over previous methods for evaluating ghostwriting models, and the authors do not directly compare their method to other existing methods.
2. The comparison of the NNLG baseline to other models is limited, and the baseline may not be sufficient for an informative comparison due to the substantially higher performance of other models.
3. The authors do not provide a clear explanation of why their method should be considered a substantial advance over previous methods, and they do not discuss the limitations of their approach.
Questions to authors:
1. How do the authors plan to address the limitations of their method, such as the lack of comparison to other existing methods and the limited comparison of the NNLG baseline?
2. Can the authors provide more details on how their method can be used to evaluate other types of generative models, such as models for generating poetry or dialogue?
3. How do the authors plan to extend their work to include richer discourse relations, such as Contrast, Consequence, and Background, which are central to NLG?