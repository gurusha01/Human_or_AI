This paper presents a well-written and solid experimental setup for an automated Japanese short-answer scoring and support system. The system utilizes a combination of machine learning and human rater input to evaluate the semantic similarity between model answers and actual written answers. The authors demonstrate the effectiveness of their approach through an evaluation of eight test items in social studies, achieving a high concordance rate between human ratings and automated scores.
The main contributions of this work are: 
1. The development of a scoring support system that combines machine learning with human rater input to evaluate short-answer responses.
2. The use of random forests to effectively utilize multiple predictors and achieve high accuracy in scoring.
3. The implementation of a mechanism to choose the biggest score among same labels, allowing for the preparation of different transcriptions of a correct answer.
The strengths of this submission include:
1. A well-designed experimental setup and thorough evaluation of the system's performance.
2. The use of a robust machine learning approach, random forests, to handle multiple predictors and achieve high accuracy.
3. The incorporation of human rater input to ensure the accuracy and validity of the scoring results.
However, the weaknesses of this submission are:
1. The lack of novelty in the models and techniques used, making it a better fit for the applications area rather than a main conference track.
2. The limited evaluation of the system's performance, with only eight test items in social studies.
3. The need for further clarification on the assumption of aligned hidden layer spaces between the two models.
Questions to the authors include:
1. How do the authors plan to address the issue of limited human score data for supervised learning, particularly in cases where actual written answer scores are often zero?
2. Can the authors provide more details on the implementation of the mechanism to choose the biggest score among same labels and its effectiveness in handling different transcriptions of a correct answer?
3. How do the authors plan to extend their approach to other subjects, such as Japanese literature, and what challenges do they anticipate in doing so?