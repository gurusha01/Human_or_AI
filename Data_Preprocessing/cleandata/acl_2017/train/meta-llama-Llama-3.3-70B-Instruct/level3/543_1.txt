This paper proposes a novel approach to building a multi-turn dialogue agent, called KB-InfoBot, which helps users search Knowledge Bases (KBs) without composing complicated queries. The key idea is to replace symbolic queries with a probabilistic framework, called Soft-KB lookup, which induces a posterior distribution over the KB entities based on the agent's beliefs about the user's goals. This approach allows for end-to-end training of the dialogue agent using reinforcement learning.
The main contributions of this work are:
1. Soft-KB lookup: The authors propose a probabilistic framework for querying a KB, which provides a differentiable and uncertainty-aware way of retrieving relevant entities.
2. End-to-end trainable dialogue agent: The authors demonstrate that the Soft-KB lookup enables end-to-end training of the dialogue agent using reinforcement learning, which leads to better performance and adaptability.
3. Evaluation on simulated and real users: The authors evaluate their approach on both simulated and real users, showing promising results and highlighting the potential of their approach for building more effective and personalized dialogue agents.
The strengths of this paper are:
1. Novel approach: The Soft-KB lookup is a novel and innovative approach to querying KBs, which addresses the limitations of traditional symbolic queries.
2. End-to-end training: The authors demonstrate the feasibility of end-to-end training of the dialogue agent, which is a significant step towards building more adaptive and effective dialogue systems.
3. Evaluation on real users: The authors evaluate their approach on real users, which provides valuable insights into the performance and limitations of their approach.
The weaknesses of this paper are:
1. Limited evaluation: The evaluation is limited to a specific domain (movie search) and a relatively small number of users, which may not be representative of more general scenarios.
2. Overfitting: The authors mention that the end-to-end agent suffers from overfitting, which may limit its generalizability to new users and scenarios.
3. Lack of comparison: The authors do not provide a comprehensive comparison with other state-of-the-art approaches, which makes it difficult to assess the relative strengths and weaknesses of their approach.
Overall, this paper presents a promising approach to building more effective and personalized dialogue agents, and the authors' evaluation on simulated and real users provides valuable insights into the potential and limitations of their approach. However, further evaluation and comparison with other approaches are necessary to fully assess the strengths and weaknesses of this work. 
Questions to authors:
1. How do you plan to address the overfitting issue in the end-to-end agent?
2. Can you provide more details on the user simulator and the natural language generator used in the evaluation?
3. How do you plan to extend this approach to more general domains and scenarios?