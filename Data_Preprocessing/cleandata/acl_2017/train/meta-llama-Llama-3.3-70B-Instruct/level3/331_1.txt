This research paper proposes a novel task of concept-map-based multi-document summarization (MDS) and presents a newly created corpus of concept maps that summarize heterogeneous collections of web documents on educational topics. The paper provides a detailed description of the corpus creation process, which combines automatic preprocessing, scalable crowdsourcing, and high-quality expert annotations.
The main contributions of this work are: (1) the proposal of a novel summarization task, concept-map-based MDS, (2) the development of a new crowdsourcing scheme, low-context importance annotation, to create reference summaries, (3) the creation of a new dataset for the proposed task, and (4) the provision of an evaluation protocol and baseline.
The strengths of this paper include the detailed guidelines and illustrations provided, which are explicit and easy to follow. The creation of a new benchmark corpus for concept-map-based MDS is a significant contribution, as it fills a gap in the existing literature. The corpus is well-organized and clearly written, with sufficient supplementary materials.
However, there are some weaknesses in the paper. One major weakness is the use of unreliable document-independent crowdsourcing annotation, which may lead to inconsistent and low-quality annotations. The paper also raises questions about the necessity of treating concept map extraction as a separate task, as it bears similarities to generic summarization systems. Additionally, the importance of a concept is difficult to determine independently of the documents, as it highly depends on the context and content of the documents.
The contributions of this work can be summarized as follows: 
1. Proposal of a novel summarization task: The paper proposes a new task of concept-map-based MDS, which is a significant contribution to the field of natural language processing.
2. Development of a new crowdsourcing scheme: The paper develops a new crowdsourcing scheme, low-context importance annotation, which is used to create reference summaries.
3. Creation of a new dataset: The paper creates a new dataset for the proposed task, which is a significant contribution to the field.
The strengths of this paper can be summarized as follows: 
1. Detailed guidelines and illustrations: The paper provides detailed guidelines and illustrations, which are explicit and easy to follow.
2. Creation of a new benchmark corpus: The paper creates a new benchmark corpus for concept-map-based MDS, which is a significant contribution to the field.
3. Well-organized and clearly written corpus: The corpus is well-organized and clearly written, with sufficient supplementary materials.
The weaknesses of this paper can be summarized as follows: 
1. Unreliable document-independent crowdsourcing annotation: The paper uses unreliable document-independent crowdsourcing annotation, which may lead to inconsistent and low-quality annotations.
2. Similarity to generic summarization systems: The paper raises questions about the necessity of treating concept map extraction as a separate task, as it bears similarities to generic summarization systems.
3. Difficulty in determining concept importance: The paper highlights the difficulty in determining the importance of a concept independently of the documents, as it highly depends on the context and content of the documents.
Questions to the authors: 
1. How do you plan to address the issue of unreliable document-independent crowdsourcing annotation?
2. Can you provide more details on the similarity between concept map extraction and generic summarization systems?
3. How do you plan to determine the importance of a concept independently of the documents?