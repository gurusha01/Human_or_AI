This paper proposes a self-learning bootstrapping approach to learning bilingual word embeddings, which achieves competitive results with minimal bilingual supervision. The method's original contribution is not a breakthrough finding, but rather connects prior work, drawing inspiration from various papers on the subject. 
The main contributions of this work are: 
1. The proposal of a self-learning framework that can learn bilingual word embeddings from small seed dictionaries, 
2. The demonstration that the method can achieve competitive results with state-of-the-art systems using much richer bilingual resources, 
3. The analysis of the underlying optimization objective, which shows that the method is implicitly optimizing a meaningful objective function that is independent from any bilingual data.
The strengths of this paper are: 
1. The simplicity and effectiveness of the proposed self-learning framework, 
2. The thorough experimental evaluation, which demonstrates the method's competitiveness with state-of-the-art systems, 
3. The analysis of the optimization objective, which provides insights into the method's behavior and opens opportunities for future research.
The weaknesses of this paper are: 
1. The lack of a thorough recognition of related work, including comparisons with relevant baselines, 
2. The fact that the idea of bootstrapping bilingual vector spaces is not new and has been explored in previous work, 
3. The similarity between the proposed bootstrapping algorithm and Artetxe et al.'s model, with the only difference being reparametrization, 
4. The failure to compare with relevant prior work, such as Duong et al., Vulic and Korhonen, and Smith et al., 
5. The limitation of current "offline" approaches, as suggested by the algorithm's performance being almost invariant to the starting seed lexicon size.
Questions to the authors: 
1. How do you plan to address the limitation of current "offline" approaches and improve bilingual lexicon induction results? 
2. Can you provide more insights into the optimization objective and how it relates to the seed dictionary and the bilingual data? 
3. How do you think your method can be extended to learn bilingual word embeddings without any bilingual evidence at all? 
4. Can you compare your method with other state-of-the-art systems that use parallel corpora or other types of bilingual resources? 
5. How do you plan to explore non-linear transformations and alternative dictionary induction methods in future work?