This paper presents a comprehensive study on neural end-to-end solutions for computational argumentation mining (AM). The authors investigate several approaches, including framing AM as a dependency parsing problem, a sequence tagging problem, and a multi-task learning problem. They also compare their results with a feature-based ILP model.
The main contributions of this paper are: 
1. The authors present the first neural end-to-end solutions to computational AM, which eliminate the need for manual feature engineering and costly ILP constraint designing.
2. They show that BiLSTM taggers perform very well for component detection, and that relation detection is more difficult, especially when there are many entities in a text.
3. The authors demonstrate that naively coupling component and relation detection is not optimal, but both tasks should be treated separately and modeled jointly.
The strengths of this paper include:
1. The authors provide a detailed description of their approach, allowing for reproduction of the experiments.
2. They present a thorough comparison with previous state-of-the-art results, demonstrating the effectiveness of their approach.
3. The paper highlights the importance of considering the complexity of the argumentation structure and the need for more restrained modeling when dealing with long documents.
However, there are some weaknesses:
1. The paper lacks statistical significance tests, which would strengthen the validity of the results.
2. The linearization order experiment should be repeated with different random seeds to overcome bias.
3. The form of the paper could be improved, with suggestions including proofreading, adding figures, and providing a formal conclusion.
4. Minor errors and typos are present throughout the paper, which should be corrected.
Some questions to the authors include:
1. How do the authors plan to address the issue of data overlap between the Gigaword and Semeval 2016 datasets in future work?
2. Can the authors provide more details on the hyperparameter optimization process and the choice of pre-trained word embeddings?
3. How do the authors think their approach could be extended to other related tasks, such as discourse parsing or sentiment analysis?