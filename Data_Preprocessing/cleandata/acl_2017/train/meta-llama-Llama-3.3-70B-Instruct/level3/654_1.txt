This paper presents a novel approach to semantic role labeling using a Neural Symbolic Machine (NSM), which combines a neural "programmer" with a symbolic "computer" to execute programs against a large knowledge base. The NSM is trained using a combination of iterative maximum likelihood and REINFORCE, allowing it to learn from weak supervision and directly optimize the task reward.
The main contributions of this paper are:
1. Introduction of the Neural Symbolic Machine: The NSM is a novel framework that integrates neural networks with a symbolic non-differentiable computer, enabling abstract, scalable, and precise operations.
2. Use of iterative maximum likelihood and REINFORCE: The paper proposes a training procedure that combines iterative maximum likelihood with REINFORCE, allowing the model to learn from weak supervision and directly optimize the task reward.
3. State-of-the-art results on the WEBQUESTIONSSP dataset: The NSM achieves new state-of-the-art results on the WEBQUESTIONSSP dataset with weak supervision, significantly closing the gap between weak and full supervision.
The strengths of this paper are:
1. Strong model and insightful discussion/error analysis: The paper provides a clear and detailed explanation of the NSM and its components, as well as an insightful analysis of the errors and limitations of the model.
2. Well-written and well-structured: The paper is well-organized and easy to follow, with clear headings and concise language.
3. Comprehensive overview of related work: The paper provides a thorough review of related work in the field, highlighting the contributions and limitations of previous approaches.
The weaknesses of this paper are:
1. Limited insights regarding the SRL task itself: The paper focuses primarily on the technical aspects of the NSM and its training procedure, without providing much insight into the semantic role labeling task itself.
2. Overfitting: The paper notes that overfitting is a major problem for the NSM, and that various techniques are used to mitigate this issue.
Questions to the authors:
1. How do the authors plan to address the issue of overfitting in future work?
2. Can the NSM be applied to other tasks beyond semantic role labeling, such as question answering or text generation?
3. How does the NSM compare to other approaches that combine neural networks with symbolic reasoning, such as Neural Programmer or Dynamic Neural Module Network?