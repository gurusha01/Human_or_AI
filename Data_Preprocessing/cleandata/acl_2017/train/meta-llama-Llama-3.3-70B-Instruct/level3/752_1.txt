This paper presents a comprehensive study on neural end-to-end solutions for computational argumentation mining (AM). The authors investigate several framings, including dependency parsing, sequence tagging, and multi-task learning, and evaluate their performance on the PE dataset. The main contributions of this paper are: (1) the presentation of the first neural end-to-end solutions to AM, (2) the demonstration that several of these solutions perform better than the state-of-the-art joint ILP model, and (3) the finding that a standard neural sequence tagging model performs robustly in different environments.
The strengths of this paper include its thorough evaluation of different framings and the presentation of new state-of-the-art results in end-to-end AM on the PE dataset. The authors also provide a detailed analysis of the performance of each framing and discuss the implications of their findings.
However, there are several weaknesses to this paper. One major weakness is the lack of clarity on the implementation details, such as the final sequence length used and the motivation behind certain modifications to the encoder. Additionally, the paper's claim of over 5 points improvement over the state-of-the-art in AMR realization is questionable due to differences in training data used. The reviewer also questions whether there is overlap between the sentences in the Gigaword sample and the test sentences of LDC2015E86, which could lead to test set contamination.
The contributions of this work can be summarized as follows: 
1. The paper demonstrates the effectiveness of seq2seq models in AMR parsing and realization tasks by linearizing pre-processed AMR graphs and using paired training.
2. The paper shows that utilizing additional monolingual data via back-translation is effective for AMR realization, but comparisons to other work are complicated due to differences in training data and information used.
3. The paper investigates the use of multi-task learning for AM, which improves performance on the AM problem.
The strengths of this paper include:
1. The thorough evaluation of different framings for AM, including dependency parsing, sequence tagging, and multi-task learning.
2. The presentation of new state-of-the-art results in end-to-end AM on the PE dataset.
3. The detailed analysis of the performance of each framing and the discussion of the implications of the findings.
The weaknesses of this paper include:
1. The lack of clarity on the implementation details, such as the final sequence length used and the motivation behind certain modifications to the encoder.
2. The questionable claim of over 5 points improvement over the state-of-the-art in AMR realization due to differences in training data used.
3. The potential overlap between the sentences in the Gigaword sample and the test sentences of LDC2015E86, which could lead to test set contamination.
Questions to the authors include:
1. Can you provide more details on the implementation, such as the final sequence length used and the motivation behind certain modifications to the encoder?
2. How do you address the potential overlap between the sentences in the Gigaword sample and the test sentences of LDC2015E86?
3. Can you provide more information on the training data used and how it differs from other work in the field?