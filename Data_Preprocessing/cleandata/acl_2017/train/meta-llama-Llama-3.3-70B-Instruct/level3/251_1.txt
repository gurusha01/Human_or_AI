This paper proposes a general framework for cross-context lexical analysis, which enables the comparison of word meanings and representations across different contexts. The framework is flexible and can accommodate various notions of context, similarity functions, and word annotations. The authors demonstrate the framework's applicability to three tasks: semantic change detection, comparative lexical analysis over context, and word embedding stability evaluation.
The paper's primary contribution is the introduction of the cross-context lexical analysis (CCLA) framework, which provides a unified approach to analyzing word meanings and representations across different contexts. The framework's flexibility and generality make it a valuable tool for various natural language processing tasks.
The paper's strengths include:
1. Novel framework: The CCLA framework is a new and innovative approach to cross-context lexical analysis, which has the potential to impact various areas of natural language processing.
2. Flexibility: The framework is flexible and can accommodate various notions of context, similarity functions, and word annotations, making it a versatile tool for different applications.
3. Comprehensive evaluation: The authors provide a thorough evaluation of the framework on three tasks, demonstrating its effectiveness and potential.
However, the paper also has some weaknesses:
1. Linguistic naivety: The paper's discussion of compositionality and linguistic concepts could be more nuanced and informed by linguistic theory.
2. Disconnection between sections: The section on Sufficient Dimensionality Reduction seems disconnected from the rest of the paper, and the authors could provide more clarification on its relevance to the CCLA framework.
3. Minor comments: The paper's abstract is too long and could be shortened, and there are some minor issues with notation, terminology, and literature references.
Overall, the paper's contribution to understanding cross-context lexical analysis is significant, and the CCLA framework has the potential to be a valuable tool for various natural language processing tasks. With some revisions to address the weaknesses, the paper could be even stronger.
Questions to authors:
1. Can you provide more clarification on the relationship between the CCLA framework and Sufficient Dimensionality Reduction?
2. How do you plan to address the issue of linguistic naivety and provide a more nuanced discussion of compositionality and linguistic concepts?
3. Can you provide more details on the potential applications of the CCLA framework and how it can be used in larger systems?