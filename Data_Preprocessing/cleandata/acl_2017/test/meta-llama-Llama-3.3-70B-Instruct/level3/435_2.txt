This paper proposes a method for detecting causal relations between clauses using neural networks, specifically an LSTM-based architecture. The proposed system improves by 0.5-1.5% F1 over a previous SVM classifier-based system and performs well on generalizations where the relation is not explicitly marked.
The main contributions of this work are:
1. The proposal of a neural network-based method for detecting causal relations between clauses, which improves upon previous methods.
2. The creation of a novel dataset for evaluating causal relation detection, which is larger and more challenging than existing datasets.
3. The demonstration of the effectiveness of the proposed method on both monolingual and cross-lingual datasets.
The strengths of this paper are:
1. The proposed method achieves state-of-the-art results on the task of causal relation detection, outperforming previous methods.
2. The paper provides a thorough evaluation of the proposed method, including experiments on multiple datasets and comparisons to baseline systems.
3. The authors make their code and data available, which is appreciated and allows for reproducibility.
However, there are also some weaknesses:
1. The paper could benefit from a clearer explanation of the differences between this task and implicit connective recognition, as well as a discussion of why previous methods cannot be used.
2. The use of "bootstrapping" to extend the corpus is not clearly explained, and the construction of the corpus could be further elaborated.
3. The merits of the proposed system are not entirely convincing, as the best configuration was found on the test data, rather than the devset, and the improvement may not be statistically significant.
4. The reliability of the gold-standard annotation is also a concern, as the annotation obtained from the English/SimpleEnglish Wikipedia is not perfect, which may affect the scores.
Questions to the authors:
1. Can you provide more details on the "bootstrapping" process used to extend the corpus?
2. How did you ensure the quality of the gold-standard annotation, and what measures were taken to address potential errors or inconsistencies?
3. Can you provide more analysis on the performance of the proposed method on different types of causal relations, such as implicit and explicit relations?