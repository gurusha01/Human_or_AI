This paper proposes a convolutional neural network approach to model text coherence based on the entity grid representation. The approach is well-motivated and clearly described, with a focus on Japanese predicate argument structure (PAS) analysis. The model is evaluated on several tasks, showing that it beats previous methods, although there are some inconsistencies in reproducing previous results.
The main contributions of this work are:
1. The proposal of a neural model that automatically induces features sensitive to multi-predicate interactions from word sequence information of a sentence.
2. The demonstration that the model achieves state-of-the-art results on Japanese PAS analysis without syntactic information.
3. The introduction of a grid-type neural architecture that effectively captures multi-predicate interactions.
The strengths of this submission are:
1. The model's ability to capture long-distance dependencies and multi-predicate interactions, which is beneficial for Japanese PAS analysis.
2. The use of a grid-type neural architecture, which is a novel approach to modeling text coherence.
3. The achievement of state-of-the-art results on Japanese PAS analysis without syntactic information.
The weaknesses of this submission are:
1. The model's simplicity, which may limit its ability to capture complex linguistic phenomena.
2. The lack of explanation and justification for some design choices, such as the use of 100-dimensional vectors.
3. The inconsistencies in reproducing previous results, which may indicate some issues with the experimental setup or the model's robustness.
Questions to authors:
1. Can you provide more details on the experimental setup and the hyperparameter tuning process?
2. How do you plan to address the inconsistencies in reproducing previous results?
3. Can you provide more analysis on the model's ability to capture long-distance dependencies and multi-predicate interactions?