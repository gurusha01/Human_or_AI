This manuscript proposes an LSTM-based approach for identifying causal relations in connective uses, leveraging the idea that neural models can capture the diverse and abstract nature of causal expressions more effectively than syntactic methods. The experiments, conducted on the AltLex corpus, yield modest yet consistent results supporting this concept and provide preliminary insights into model development. The paper includes TensorFlow-based models used in the experiments.
Several critical points and questions arise:
* The introduction resembles a literature review rather than a comprehensive overview of the paper's content, leading to redundancy with the subsequent related work section. A non-standard introduction may be acceptable, but this one fails to take a clear stance on causation, instead only highlighting its non-reducibility to syntax. The positive contribution is not clearly stated until the final paragraph.
* The paper lacks clarity on the underlying theory of causation. The authors seem to adopt a counterfactual view, similar to David Lewis', but this is not explicitly stated, and the associated problems with this theory are not addressed. The comments on line 238 and the temporal constraint on page 3 are unclear, and it is uncertain what theory is being assumed.
* The discussion of the example on line 256 is confusing, as the authors appear to regard the sentence as false, yet a causal link should exist if the sentence is true. The issues surrounding event division and their impact on causal theories are not explored, leaving the explanation unclear.
* The caption for Figure 1 is misleading, as it depicts the "Pair_LSTM" variant, and the diagram is imprecise. The empty circles between the input and "LSTM" boxes are unclear, and the number of representation layers is not specified. The connection between the "LSTM" boxes and the layers above should be clearly depicted.
* The sentence starting on line 480 is unclear, as the models do not inherently require padding. If this is a requirement for TensorFlow or efficient training, it should be stated. The final clause is also unclear, as the relationship between padding and causal meaning encoding is not explained.
* The authors find that using two independent LSTMs ("Stated_LSTM") is more effective than a single LSTM, but this issue is reminiscent of discussions in the natural language entailment literature. Further investigation is needed to determine the optimal approach for causal relations. The conclusion on line 587 is surprising, as it suggests that the assumption about the relation between input event meanings does not hold, and independent encoding is preferred.
* The hyperparameters that led to the best performance across tasks are difficult to interpret. Comparing lines 578 and 636, it is unclear whether these results should be attributed to the unpredictability of model-data interactions.
* Section 4.3 claims that the system can correctly disambiguate the causal meaning of the connective 'which then', whereas Hidey and McKeown's system cannot. However, a single example is insufficient to support this claim. To substantiate this point, a range of examples should be created to test the system's performance and determine whether the result is due to chance.