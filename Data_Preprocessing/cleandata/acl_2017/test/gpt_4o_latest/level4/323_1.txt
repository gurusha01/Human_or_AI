The paper presents an enhancement to the entity grid model by incorporating a convolutional neural network to learn sequences of entity transitions that reflect coherence. This approach enables better generalization over longer sequences of entities compared to the direct transition probability estimates used in the original model.
This is a well-executed and clearly written paper. Rather than proposing a fully neural solution, the authors build upon existing work, leveraging a neural network to address specific limitations in one component. While this is a reasonable approach, it would be beneficial to expand the comparison to the neural coherence model proposed by Li and Hovy. The authors acknowledge their surprise at the very low performance of the Li and Hovy model on their task, which raises questions about whether there might have been an error in the experimental setup, whether the low performance is corpus-dependent, and, if so, how the proposed model would perform on a dataset or task where the Li and Hovy model excels. A more thorough exploration of these aspects would significantly strengthen the paper's argument.
Overall, the paper is well-written and easy to follow, but there are numerous instances where definite articles are missing (e.g., on lines 92, 132, 174, 488, 490, 547, 674, 764, and potentially others). I recommend carefully proofreading the paper with a focus on article usage. Additionally, the phrase "...limits the model to do X..." appears repeatedly and sounds somewhat unconventional. Alternatives such as "limits the model's capacity to do X" or "prevents the model from doing X" might be clearer.
---
Final recommendation revised to 4 after considering the authors' response. I agree that challenges in running third-party software should not be held against the authors. However, the difficulties encountered while testing the Li and Hovy system should be documented in the paper. Additionally, I recommend that the authors attempt to reproduce the results of Li and Hovy on their original datasets as a sanity check (if this has not already been done), to verify whether the system performs as expected in its original context.