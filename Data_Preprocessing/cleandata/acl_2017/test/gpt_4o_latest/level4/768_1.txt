- Strengths: The paper is well-written and explores the innovative idea of incorporating context into the lexical entailment task. It presents a clearly defined approach, a robust experimental setup, and provides a thorough analysis of the results.
- Weaknesses: Certain details are either missing or inadequately explained. For instance, the table captions could be more descriptive, and a clear explanation of each word type feature should be included.
General Discussion:
The paper proposes the integration of context into the lexical entailment task. Experimental results indicate that context-aware models outperform context-agnostic models in this task.
I appreciated the novel approach of generating negative examples to obtain negative annotations automatically, as described in the paper using WordNet positive examples. This method for creating a new dataset is both interesting and practical.
I also found the transformation of existing context-agnostic representations into contextualized representations to be a compelling idea. The authors experimented with different methods for obtaining contextualized representations (e.g., using "mask" and context2vec) and evaluated their model on three distinct datasets, demonstrating generalizability not only across datasets but also across languages.
The motivations behind various experimental design choices were well-articulated. For example, the rationale for the specific split used in CONTEXT-PPDB was thoughtfully explained, reflecting careful consideration of the methodology.
Regarding Lines 431-434, the authors could briefly clarify how the class weights were determined and incorporated to address the unbalanced data in the CONTEXT-WN experiments. Additionally, it would be helpful to discuss whether this adjustment impacts direct comparisons with prior work and, if so, in what ways.
Suggested changes:
- Line 589: Replace "directionality 4" with "directionality," consistent with Table 4.
- Line 696-697: Replace "is-a hierarchy of WordNet" with '"is-a" hierarchy of WordNet.'
- For completeness, include "mask" in Figure 1.
I have reviewed the author response.