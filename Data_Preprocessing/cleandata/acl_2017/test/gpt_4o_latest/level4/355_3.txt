This paper introduces a joint neural modeling approach for PAS analysis in Japanese, leveraging Grid-RNNs and comparing it against a traditional single-sequence RNN approach.
The paper is well-executed, addressing a well-established task in Japanese while achieving state-of-the-art results. It presents the task in a manner that is largely accessible to readers unfamiliar with Japanese. However, I believe the complexity of the task could have been emphasized more. For instance, in relation to the example in Figure 1, you could elaborate on the inherent ambiguity between the NOM and ACC arguments of the first predicate, as well as the NOM argument of the second predicate. Additionally, a clearer explanation of how this task differs from SRL—particularly in terms of ambiguity introduced by zero pronouns—would have been beneficial. I also would have appreciated statistics on the proportion of zero pronouns that are intra-sententially resolvable, as this adds another layer of complexity to the task (i.e., distinguishing between intra- and inter-sentential zero anaphors). One point I found unclear: in cases where an inter-sentential zero pronoun serves as an argument for a predicate, how is this represented? Is the argument left unmarked entirely, or is it explicitly marked as empty? My interpretation of the paper suggests the former, which would mean there is no explicit representation of the zero pronoun. This seems like a potentially suboptimal representation that could hinder the model's ability to capture zero pronouns. A discussion on this point would have been valuable.
The model also appears to lack certain constraints that are explicitly modeled in some ILP-based SRL methods. For example: (1) a predicate typically has only one argument of a given type (e.g., NOM and ACC), and (2) an argument generally fills only one slot for a given predicate. An analysis of the model's output to assess how well it learns these constraints would have been insightful. Furthermore, considering the mixed results in Table 3 between the Single-Seq and Multi-Seq models (where Multi-Seq shows improvement primarily for NOM), I would have liked to see a discussion on the differences in their outputs. Are the outputs largely similar, or are they significantly different but comparable in aggregate performance? In what contexts do the two models diverge? Such an analysis could provide valuable insights into the internal workings of the models and elevate the paper from solid to strong. This, along with including results for SRL (though I acknowledge this would require substantial additional work), represents the main area for improvement.
The paper's presentation is strong, with the figures effectively aiding comprehension of the model. While there are some minor language issues, they do not detract significantly from the overall quality:
- l19: "the error propagation" → "error propagation"
- l190: "an solution" → "a solution"
- l264 (and Figure 2): "a bread" → "bread"
- l351: "the independence" → "independence"
- l512: "the good" → "good"
- l531: "from their model" → "of their model"
- l637: "significent" → "significance"
- l638: "both of" → "both"
Additionally, please ensure proper casing in references (e.g., "japanese" → "Japanese," "lstm" → "LSTM," "conll" → "CoNLL," "ilp" → "ILP").