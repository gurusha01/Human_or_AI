The paper proposes a convolutional neural network approach to model the
coherence of texts. The model is based on the well-known entity grid
representation for coherence, but puts a CNN on top of it. 
The approach is well motivated and described, I especially appreciate the clear
discussion of the intuitions behind certain design decisions (e.g. why CNN and
the section titled 'Why it works').
There is an extensive evaluation on several tasks, which shows that the
proposed approach beats previous methods. It is however strange that one
previous result could not be reproduced: the results on Li/Hovy (2014) suggest
an implementation or modelling error that should be addressed.
Still, the model is a relatively simple 'neuralization' of the entity grid
model. I didn't understand why 100-dimensional vectors are necessary to
represent a four-dimensional grid entry (or a few more in the case of the
extended grid). How does this help? I can see that optimizing directly for
coherence ranking would help learn a better model, but the difference of
transition chains for up to k=3 sentences vs. k=6 might not make such a big
difference, especially since many WSJ articles may be very short.
The writing seemed a bit lengthy, the paper repeats certain parts in several
places, for example the introduction to entity grids. In particular, section 2
also presents related work, thus the first 2/3 of section 6 are a repetition
and should be deleted (or worked into section 2 where necessary). The rest of
section 6 should probably be added in section 2 under a subsection (then rename
section 2 as related work).
Overall this seems like a solid implementation of applying a neural network
model to entity-grid-based coherence. But considering the proposed
consolidation of the previous work, I would expect a bit more from a full
paper, such as innovations in the representations (other features?) or tasks.
minor points:
- this paper may benefit from proof-reading by a native speaker: there are
articles missing in many places, e.g. 'the WSJ corpus' (2x), 'the Brown ...
toolkit' (2x), etc.
- p.1 bottom left column: 'Figure 2' -> 'Figure 1'
- p.1 Firstly/Secondly -> First, Second
- p.1 'limits the model to' -> 'prevents the model from considering ...' ?
- Consider removing the 'standard' final paragraph in section 1, since it is
not necessary to follow such a short paper.