This paper proposes a joint neural modelling approach to PAS analysis in
Japanese, based on Grid-RNNs, which it compares variously with a conventional
single-sequence RNN approach.
This is a solidly-executed paper, targeting a well-established task from
Japanese but achieving state-of-the-art results at the task, and presenting
the task in a mostly accessible manner for those not versed in
Japanese. Having said that, I felt you could have talked up the complexity of
the task a bit, e.g. wrt your example in Figure 1, talking through the
inherent ambiguity between the NOM and ACC arguments of the first predicate,
as the NOM argument of the second predicate, and better describing how the
task contrasts with SRL (largely through the ambiguity in zero pronouns). I
would also have liked to have seen some stats re the proportion of zero
pronouns which are actually intra-sententially resolvable, as this further
complicates the task as defined (i.e. needing to implicitly distinguish
between intra- and inter-sentential zero anaphors). One thing I wasn't sure of
here: in the case of an inter-sentential zero pronoun for the argument of a
given predicate, what representation do you use? Is there simply no marking of
that argument at all, or is it marked as an empty argument? My reading of the
paper is that it is the former, in which case there is no explicit
representation of the fact that there is a zero pronoun, which seems like a
slightly defective representation (which potentially impacts on the ability of
the model to capture zero pronouns); some discussion of this would have been
appreciated.
There are some constraints that don't seem to be captured in the model (which
some of the ILP-based methods for SRL explicitly model, e.g.): (1) a given
predicate will generally have only one argument of a given type (esp. NOM and
ACC); and (2) a given argument generally only fills one argument slot for a
given predicate. I would have liked to have seen some analysis of the output
of the model to see how well the model was able to learn these sorts of
constraints. More generally, given the mix of numbers in Table 3 between
Single-Seq and Multi-Seq (where it is really only NOM where there is any
improvement for Multi-Seq), I would have liked to have seen some discussion of
the relative differences in the outputs of the two models: are they largely
identical, or very different but about the same in aggregate, e.g.? In what
contexts do you observe differences between the two models? Some analysis like
this to shed light on the internals of the models would have made the
difference between a solid and a strong paper, and is the main area where I
believe the paper could be improved (other than including results for SRL, but
that would take quite a bit more work).
The presentation of the paper was good, with the Figures aiding understanding
of the model. There were some low-level language issues, but nothing major:
l19: the error propagation -> error propagation
l190: an solution -> a solution
l264 (and Figure 2): a bread -> bread
l351: the independence -> independence
l512: the good -> good
l531: from their model -> of their model
l637: significent -> significance
l638: both of -> both
and watch casing in your references (e.g. "japanese", "lstm", "conll", "ilp")