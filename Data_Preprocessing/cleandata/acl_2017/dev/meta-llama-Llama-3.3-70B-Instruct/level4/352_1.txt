This paper presents novel configurations and training objectives for neural sequence models in a multi-task setting, which is crucial as some tasks share information and learning multiple tasks can enhance overall performance. The authors effectively highlight the importance of this setting.
The methods section is generally clear and logical, although it could benefit from improved organization. Upon closer examination, it becomes apparent that the authors address two primary issues: the presence of shared features in private feature spaces and the presence of private features in shared spaces. They introduce two innovative methods to tackle these problems: an adversarial loss to prevent task-specific features from entering shared representations and orthogonality constraints to prevent shared features from entering task-specific representations. However, the adversarial system is a point of confusion, particularly the additional layer, D(s^kT, Î¸D), which relies on parameters U and b, and its output is considered a probability distribution compared to the actual distribution. This raises concerns that the system may simply learn to mask task-specific information from LSTM outputs rather than guaranteeing its removal.
The evaluation section largely aligns with the expected experimental design, providing a solid foundation for demonstrating the validity of the proposed methods. Including the best-known results on these tasks would be beneficial for context. A more significant concern is the lack of deeper motivation for the approach, as the extension to partially shared features seems like a reaction to issues in fully shared models. A clearer argument flow, starting from the limitations of fully shared models, the potential of shared-private models, and the practical issues with the latter, would strengthen the introduction.
The paper could also benefit from a more logical explanation of the issues with shared-private models, potentially using simple examples and highlighting the general trends that lead to certain terms being shared or private. Table 4 provides some insight into what goes wrong with shared-private models and how the proposed methods address these issues. Additionally, the research ties into other uncited multi-task learning (MTL) work, such as deep hierarchical MTL, which discusses the qualities that make MTL possible and concludes that MTL only works when tasks are sufficiently similar. The proposed model could potentially learn what "sufficiently similar" means, allowing it to adaptively decide when to share information between tasks.