This paper presents two neural network-based methodologies for automatically generating rhythmic poetry, with the second approach offering enhanced control over poetic form.
- Strengths:
The proposed method for generating rhythmic poetry is well-structured and effective.
The authors suggest incorporating control mechanisms for theme and poetic devices, such as alliteration, consonance, and asonance, which is a notable contribution.
The evaluation of rhythm yields strong results, demonstrating the approach's potential.
- Weaknesses:
The literature review on existing poetry generation methods is inadequate, failing to provide a comprehensive overview of prior research.
There is a lack of comparison with existing approaches to poetry generation, which makes it difficult to assess the novelty and impact of the proposed method.
The evaluation of results on theme and poetic devices is also missing, which limits the understanding of the approach's effectiveness in these areas.
- General Discussion:
The introduction accurately frames the problem of poetry generation as comprising two subtasks: content (semantics) and form (aesthetic rules). The proposed solutions address both subtasks to some extent, utilizing neural networks trained on poetry corpora to encode linguistic continuity and ensure meaningful output. However, it is an overstatement to claim that this approach provides the poem with appropriate semantics. The problem of form is partially addressed, particularly in terms of rhythm, and some poetic devices are also considered. Nevertheless, larger-scale structural aspects, such as stanzas and rhyme schemes, remain unaddressed.
The review of related work in section 2 is insufficient, omitting key previous efforts, including those cited later in the paper (Manurung et al., 2000, and Misztal and Indurkhya, 2014).
Notable research efforts that the authors should consider include:
- Gabriele Barbieri et al.'s (2012) work on Markov constraints for generating lyrics with style, which addresses similar problems of n-gram-based generation and constrained generation processes.
- Stephen McGregor et al.'s (2016) research on process-based evaluation of computer-generated poetry, which models language at a phonological level and considers word n-gram levels and sentiment, offering relevant insights for evaluation.
- M. Ghazvininejad et al.'s (2016) work on generating topical poetry, which combines finite-state machinery with deep learning to produce iambic pentameter, providing an interesting contrast to the proposed approach.
The authors should also consider extending their classification of poetry generation systems to include evolutionary solutions, as they have already mentioned the evolutionary work of Manurung.
Overall, the paper lacks a thorough comparison with prior approaches to poetry generation, particularly in cases where similar problems are addressed or similar methods are applied. The authors should strive to contextualize their work within the existing research landscape to demonstrate its novelty and impact.