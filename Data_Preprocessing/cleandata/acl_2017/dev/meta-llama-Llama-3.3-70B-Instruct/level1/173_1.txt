This paper proposes a nonparametric clustering framework for document analysis using word embeddings. The main contributions of this work are: 
1. The development of a scalable and efficient document clustering approach based on the Wasserstein distance, which outperforms existing methodologies on various document clustering tasks.
2. The provision of a tool to quantitatively evaluate the effectiveness of word embeddings in document analysis, allowing for the inspection of how well a word-embedding model fits the data and the gain or loss obtained compared to traditional bag-of-words models.
The strengths of this paper are:
1. The proposed framework is intuitive, robust, and easy to use, making it a valuable tool for document analysis.
2. The approach achieves state-of-the-art clustering performances across heterogeneous text data, demonstrating its effectiveness in various applications.
3. The paper provides a thorough evaluation of the proposed framework, including experiments on six datasets and comparisons with ten baseline methods.
4. The authors discuss the sensitivity of the approach to word embeddings and demonstrate its robustness to different word embedding models.
5. The paper highlights the importance of considering the gain or loss obtained from using word embeddings in document analysis, providing insights into the effectiveness of word embeddings in various tasks.
The weaknesses of this paper are:
1. The computational cost of the proposed framework may be high, especially for large datasets, which could limit its applicability in practice.
2. The approach relies on the quality of the word embeddings used, which may not always be optimal for a specific task or dataset.
3. The paper could benefit from a more detailed analysis of the results, including a discussion of the limitations and potential biases of the proposed framework.
4. The comparison with other baseline methods could be more comprehensive, including a discussion of the strengths and weaknesses of each approach.
5. The paper could provide more insights into the potential applications and future directions of the proposed framework.
Questions to authors:
1. How do the authors plan to address the computational cost of the proposed framework, especially for large datasets?
2. Can the authors provide more insights into the sensitivity of the approach to different word embedding models and hyperparameters?
3. How do the authors plan to extend the proposed framework to other natural language processing tasks, such as text classification or information retrieval?
4. Can the authors provide more details on the experimental setup and the datasets used in the evaluation?
5. How do the authors plan to make the proposed framework more accessible to practitioners and researchers in the field?