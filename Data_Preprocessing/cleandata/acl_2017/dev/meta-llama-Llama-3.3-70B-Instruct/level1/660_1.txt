This paper proposes two novel methodologies for the automatic generation of rhythmic poetry in various forms. The main contributions of this work are:
1. Phonetic-level model: A neural language model trained on a phonetic encoding of poetry to learn an implicit representation of both form and content.
2. Constrained character-level model: A pipeline approach that combines a generative language model with a discriminative model to represent form, allowing for more control over the style of generated poetry.
3. Evaluation methodology: A large-scale extrinsic evaluation that demonstrates the effectiveness of the proposed models in generating high-quality rhythmic verse.
The strengths of this paper are:
1. Novel approach: The use of phonetic encoding and constrained character-level models is a new and innovative approach to poetry generation.
2. High-quality output: The generated poetry is of high quality, with 54% of participants considering machine-generated poems to be written by humans.
3. Flexibility: The constrained character-level model allows for greater control over the style of generated poetry, including themes and poetic devices.
4. Evaluation methodology: The extrinsic evaluation is well-designed and provides a thorough assessment of the proposed models.
5. Comparison to human poetry: The comparison to human poetry provides a useful benchmark for evaluating the quality of the generated poetry.
The weaknesses of this paper are:
1. Limited generalizability: The phonetic-level model is limited in its ability to generalize to novel forms of verse.
2. Transliteration errors: The phonetic-level model is prone to transliteration errors, which can affect the quality of the generated poetry.
3. Dependence on training data: The quality of the generated poetry is dependent on the quality of the training data.
4. Lack of interpretability: The neural language models used in this paper can be difficult to interpret, making it challenging to understand why certain poetry is generated.
5. Limited analysis of results: The analysis of the results is limited, and more in-depth analysis could provide further insights into the strengths and weaknesses of the proposed models.
Questions to authors:
1. How do the proposed models handle out-of-vocabulary words, and what strategies can be employed to improve their handling of such words?
2. Can the constrained character-level model be used to generate poetry in languages other than English, and what modifications would be necessary to achieve this?
3. How do the proposed models compare to other state-of-the-art poetry generation models, and what are the advantages and disadvantages of each approach?