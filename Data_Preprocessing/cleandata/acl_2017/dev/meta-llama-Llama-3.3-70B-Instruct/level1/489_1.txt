This paper presents a comprehensive comparison of three models for referential word meaning, which link visual object representations to lexical representations in a distributional vector space. The main contributions of this work are: 
1. The authors propose and evaluate three different models for referential word meaning, including direct cross-modal mapping, lexical mapping through individual word classifiers, and word prediction via cross-modal similarity mapping.
2. The authors demonstrate that combining these models can improve performance in both standard and zero-shot object naming tasks, suggesting that they capture complementary aspects of referential word meaning.
3. The authors provide a detailed analysis of the strengths and weaknesses of each model, including their ability to capture taxonomic aspects of object names, detect specific instances of word use, and generalize to unseen words.
The strengths of this paper include: 
1. The authors provide a thorough review of related work in the area of referential word meaning and object naming, highlighting the limitations of previous approaches and the contributions of their own work.
2. The authors evaluate their models on a range of tasks, including standard and zero-shot object naming, and provide detailed analysis of the results, including examples and quantitative metrics.
3. The authors demonstrate the potential of their approach for real-world applications, such as referring expression generation and conversational agents.
The weaknesses of this paper include: 
1. The authors' evaluation is limited to a relatively small vocabulary and dataset, which may limit the generality of their conclusions.
2. The authors do not provide a detailed comparison of their approach to other state-of-the-art methods for object naming and referring expression generation.
3. The authors' analysis of the results is largely qualitative, and could be strengthened by more quantitative evaluation metrics and statistical analysis.
Questions to authors: 
1. How do the authors plan to scale up their approach to larger vocabularies and datasets, and what challenges do they anticipate in doing so?
2. How do the authors' models compare to other state-of-the-art methods for object naming and referring expression generation, and what are the key differences and advantages of their approach?
3. What additional evaluation metrics and analysis could be used to further demonstrate the effectiveness and robustness of the authors' approach?