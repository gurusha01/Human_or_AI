AFTER AUTHOR RESPONSE
I accept the response about emphasizing novelty of the task and comparison with
previous work. Also increase ratings for the dataset and software that are
promised to become public before the article publishing.
======================
GENERAL 
The paper presents an interesting empirical comparison of 3 referring
expression generation models. The main novelty lies in the comparison of a yet
unpublished model called SIM-WAP (in press by Anonymous). The model is
described in SECTION 4.3 but it is not clear whether it is extended or modified
anyhow in the current paper.  
The novelty of the paper may be considered as the comparison of the unpublished
SIM-WAP model to existing 2 models. This complicates evaluation of the novelty
because similar experiments were already performed for the other two models and
it is unclear why this comparison was not performed in the paper where SIM-WAP
model was presented. A significant novelty might be the combined model yet this
is not stated clearly and the combination is not described with enough details.
The contribution of the paper may be considered the following: the side-by-side
comparison of the 3 methods for REG; analysis of zero-shot experiment results
which mostly confirms similar observations in previous works; analysis of the
complementarity of the combined model.                     
WEAKNESSES
Unclear novelty and significance of contributions. The work seems like an
experimental extension of the cited Anonymous paper where the main method was
introduced.    
Another weakness is the limited size of the vocabulary in the zero-shot
experiments that seem to be the most contributive part. 
Additionally, the authors never presented significance scores for their
accuracy results. This would have solidified the empirical contribution of the
work which its main value.   
My general feeling is that the paper is more appropriate for a conference on
empirical methods such as EMNLP. 
Lastly, I have not found any link to any usable software. Existing datasets
have been used for the work.  
Observations by Sections: 
ABSTRACT
"We compare three recent models" -- Further in the abstract you write that you
also experiment with the combination of approaches. In Section 2 you write that
"we present a model that exploits distributional knowledge for learning
referential word meaning as well, but explore and compare different ways of
combining visual and lexical aspects of referential word meaning" which
eventually might be a better summarization of the novelty introduced in the
paper and give more credit to the value of your work. 
My suggestion is to re-write the abstract (and eventually even some sections in
the paper) focusing on the novel model and results and not just stating that
you compare models of others.                  
INTRODUCTION 
"Determining such a name is is" - typo 
"concerning e.g." -> "concerning, e.g.," 
"having disjunct extensions." - specify or exemplify, please 
"building in Figure 1" -> "building in Figure 1 (c)"
SECTION 4
"Following e.g. Lazaridou et al. (2014)," - "e.g." should be omitted  
SECTION 4.2
"associate the top n words with their corresponding distributional vector" -
What are the values of N that you used? If there were any experiments for
finding the optimal values, please, describe because this is original work. The
use top N = K is not obvious and not obvious why it should be optimal (how
about finding similar vectors to each 5 in top 20?)    
SECTION 4.3 
"we annotate its training instances with a fine-grained similarity signal
according to their object names." - please, exemplify. 
LANGUAGE   
Quite a few typos in the draft. Generally, language should be cleaned up ("as
well such as"). 
Also, I believe the use of American English spelling standard is preferable
(e.g., "summarise" -> "summarize"). Please, double check with your conference
track chairs.