Paper summary
This paper presents a method for learning well-partitioned shared and
task-specific feature spaces for LSTM text classifiers. Multiclass adversarial
training encourages shared space representations from which a discriminative
classifier cannot identify the task source (and are thus generic). The models
evaluates are a fully-shared, shared-private and adversarial shared-private --
the lattermost ASP model is one of the main contributions. They also use
orthogonality constraints to help reward shared and private spaces that are
distinct. The ASP model has lower error rate than single-task and other
multi-task neural models. They also experiment with a task-level cross
validation to explore whether the shared representation can transfer across
tasks, and it seems to favourably. Finally, there is some analysis of shared
layer activations suggesting that the ASP model is not being misled by strong
weights learned on a specific (inappropriate) task.
Review summary
Good ideas, well expressed and tested. Some minor comments.
Strengths
* This is a nice set of ideas working well together. I particularly like the
focus on explicitly trying to create useful shared representations. These have
been quite successful in the CV community, but it appears that one needs to
work quite hard to create them for NLP.
* Sections 2, 3 and 4 are very clearly expressed.
* The task-level cross-validation in Section 5.5 is a good way to evaluate the
transfer.
* There is an implementation and data.
Weaknesses
* There are a few minor typographic and phrasing errors. Individually, these
are fine, but there are enough of them to warrant fixing:
 l:84 the "infantile cart" is slightly odd -- was this a real example
from the data?
 l:233 "are different in" -> "differ in"
 l:341 "working adversarially towards" -> "working against" or
"competing with"?
 l:434 "two matrics" -> "two matrices"
 l:445 "are hyperparameter" -> "are hyperparameters"
 Section 6 has a number of number agreement errors
(l:745/746/765/766/767/770/784) and should be closely re-edited.
 The shading on the final row of Tables 2 and 3 prints strangelyâ€¦
* There is mention of unlabelled data in Table 1 and semi-supervised learning
in Section 4.2, but I didn't see any results on these experiments. Were they
omitted, or have I misunderstood?
* The error rate differences are promising in Tables 2 and 3, but statistical
significance testing would help make them really convincing. Especially between
SP-MLT and ASP-MTL results to highlight the benefit of adversarial training. It
should be pretty straightforward to adapt the non-parametric approximate
randomisation test (see
http://www.lr.pi.titech.ac.jp/~takamura/pubs/randtest.pdf for promising notes a
reference to the Chinchor paper) to produce these.
* The colours are inconsistent in the caption of Figure 5 (b). In 5 (a), blue
is used for "Ours", but this seems to have swapped for 5 (b). This is worth
checking, or I may have misunderstood the caption.
General Discussion
* I wonder if there's some connection with regularisation here, as the effect
of the adversarial training with orthogonal training is to help limit the
shared feature space. It might be worth drawing that connection to other
regularisation literature.