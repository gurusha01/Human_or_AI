This paper introduces new configurations and training objectives for neural
sequence models in a multi-task setting. As the authors describe well, the
multi-task setting is important because some tasks have shared information
and in some scenarios learning many tasks can improve overall performance.
The methods section is relatively clear and logical, and I like where it ended
up, though it could be slightly better organized. The organization that I
realized after reading is that there are two problems: 1) shared features end
up in the private feature space, and 2) private features end up in the 
shared space. There is one novel method for each problem. That organization up
front would make the methods more cohesive. In any case, they introduce one 
method that keeps task-specific features out of shared representation
(adversarial
loss) and another to keep shared features out of task-specific representations
(orthogonality constraints). My only point of confusion is the adversarial
system.
After LSTM output there is another layer, D(s^kT, \thetaD), relying on
parameters
U and b. This output is considered a probability distribution which is compared
against the actual. This means it is possible it will just learn U and b that
effectively mask task-specific information from  the LSTM outputs, and doesn't 
seem like it can guarantee task-specific information is removed.
Before I read the evaluation section I wrote down what I hoped the experiments
would look like and it did most of it. This is an interesting idea and there
are 
a lot more experiments one can imagine but I think here they have the basics
to show the validity of their methods. It would be helpful to have best known
results on these tasks.
My primary concern with this paper is the lack of deeper motivation for the 
approach. I think it is easy to understand that in a totally shared model
there will be problems due to conflicts in feature space. The extension to 
partially shared features seems like a reaction to that issue -- one would 
expect that the useful shared information is in the shared latent space and 
each task-specific space would learn features for that space. Maybe this works
and maybe it doesn't, but the logic is clear to me. In contrast, the authors
seem to start from the assumption that this "shared-private" model has this
issue. I expected the argument flow to be 1) Fully-shared obviously has this
problem; 2) shared-private seems to address this; 3) in practice shared-private
does not fully address this issue for reasons a,b,c.; 4) we introduce a method
that more effectively constrains the spaces.
Table 4 helped me to partially understand what's going wrong with
shared-private
and what your methods do; some terms are usually one connotation
or another, and that general trend can probably get them into the shared
feature
space. This simple explanation, an example, and a more logical argument flow
would help the introduction and make this a really nice reading paper.
Finally, I think this research ties into some other uncited MTL work [1],
which does deep hierarchical MTL - supervised POS tagging at a lower level,
chunking
at the next level up, ccg tagging higher, etc. They then discuss at the end
some of the qualities that make MTL possible and conclude that MTL only works
"when tasks are sufficiently similar." The ASP-MTL paper made me think of this
previous work because potentially this model could learn what sufficiently
similar is -- i.e., if two tasks are not sufficiently similar the shared model
would learn nothing and it would fall back to learning two independent systems,
as compared to a shared-private model baseline that might overfit and perform
poorly.
[1]
@inproceedings{sogaard2016deep,
  title={Deep multi-task learning with low level tasks supervised at lower
layers},
  author={S{\o}gaard, Anders and Goldberg, Yoav},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for
Computational Linguistics},
  volume={2},
  pages={231--235},
  year={2016},
  organization={Association for Computational Linguistics}
}