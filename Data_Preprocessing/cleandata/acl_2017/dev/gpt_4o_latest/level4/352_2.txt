Paper Summary
This paper introduces a method for learning well-partitioned shared and task-specific feature spaces tailored for LSTM-based text classifiers. The approach employs multiclass adversarial training to encourage shared space representations that are generic, such that a discriminative classifier cannot identify the task source. The models evaluated include fully-shared, shared-private, and adversarial shared-private (ASP) architectures, with the ASP model being a key contribution. Orthogonality constraints are also applied to ensure that shared and private spaces remain distinct. The ASP model achieves a lower error rate compared to single-task and other multi-task neural models. Additionally, the authors conduct task-level cross-validation to assess the transferability of shared representations across tasks, which yields favorable results. Lastly, an analysis of shared layer activations suggests that the ASP model avoids being misled by strong weights learned on task-specific data.
Review Summary
The paper presents strong ideas that are well-articulated and thoroughly evaluated. A few minor comments are provided for improvement.
Strengths
* The paper integrates a compelling set of ideas that work effectively together. The emphasis on explicitly constructing useful shared representations is particularly noteworthy. While such representations have seen success in the CV domain, the paper highlights the challenges and efforts required to achieve similar outcomes in NLP.
* Sections 2, 3, and 4 are written with exceptional clarity.
* The task-level cross-validation in Section 5.5 is a robust approach to evaluating transferability.
* The authors provide an implementation and data, which enhances reproducibility.
Weaknesses
* There are several minor typographic and phrasing issues. While individually minor, their cumulative presence warrants attention:
   l:84 The phrase "infantile cart" seems slightly unusual—was this an actual example from the dataset?
   l:233 "are different in" → "differ in"
   l:341 "working adversarially towards" → "working against" or "competing with"
   l:434 "two matrics" → "two matrices"
   l:445 "are hyperparameter" → "are hyperparameters"
   Section 6 contains several number agreement errors (e.g., l:745/746/765/766/767/770/784) and would benefit from careful re-editing.
   The shading on the final row of Tables 2 and 3 appears distorted when printed.
* Table 1 mentions unlabelled data, and Section 4.2 discusses semi-supervised learning, but no results for these experiments are presented. Were these omitted, or is there a misunderstanding on my part?
* While the error rate differences in Tables 2 and 3 are promising, statistical significance testing would strengthen the claims. In particular, testing the differences between SP-MTL and ASP-MTL results would better highlight the advantages of adversarial training. Adapting the non-parametric approximate randomization test (see [this reference](http://www.lr.pi.titech.ac.jp/~takamura/pubs/randtest.pdf) and the Chinchor paper) should be straightforward and would add rigor.
* The colors in Figure 5 (b) are inconsistent with those in Figure 5 (a). For example, blue represents "Ours" in 5 (a), but this appears to change in 5 (b). This discrepancy should be clarified, or I may have misinterpreted the caption.
General Discussion
* There may be a connection to regularization worth exploring. The combined effect of adversarial training and orthogonal constraints seems to limit the shared feature space, which aligns with principles in regularization literature. Drawing this connection could enrich the discussion and situate the work within broader research contexts.