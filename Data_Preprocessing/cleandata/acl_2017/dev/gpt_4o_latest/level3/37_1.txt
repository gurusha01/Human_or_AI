Review of the Paper
Summary and Contributions
This paper introduces a Sequential Matching Network (SMN) for response selection in multi-turn conversations for retrieval-based chatbots. The authors address two key challenges: (1) retaining important information from utterance-response pairs and (2) modeling relationships among utterances in a conversation context. SMN matches responses with individual utterances at multiple granularities, distills matching information using convolutional and pooling operations, and accumulates it chronologically via a GRU. The authors also release a new human-labeled dataset, the Douban Conversation Corpus, to complement the Ubuntu Corpus. The main contributions of this paper are:
1. A novel context-based matching model (SMN) for multi-turn response selection.
2. The publication of the Douban Conversation Corpus, a large-scale human-labeled dataset for multi-turn conversations.
3. Empirical evidence demonstrating the effectiveness of SMN, outperforming state-of-the-art methods on multiple datasets.
Strengths
1. Novelty and Technical Rigor: The proposed SMN model effectively extends the "2D" matching paradigm to multi-turn conversations, addressing the critical issue of preserving utterance relationships. The use of GRUs to accumulate matching vectors in chronological order is well-motivated and technically sound.
2. Empirical Validation: The experimental results on both the Ubuntu and Douban datasets convincingly demonstrate the superiority of SMN over baseline methods. The significant improvements in metrics like R10@1 and MAP highlight the model's effectiveness.
3. Dataset Contribution: The release of the Douban Conversation Corpus is a valuable contribution to the research community, providing a human-labeled, open-domain dataset for multi-turn response selection.
4. Visualization and Analysis: The visualization of similarity matrices and GRU gates provides clear insights into how the model identifies and accumulates important information, enhancing interpretability.
Weaknesses
1. Ambiguity in Terminology: The paper uses inconsistent terminology, such as "segment level" and "sequence-sequence similarity matrix," which could confuse readers. A clearer definition of terms like "segment" is necessary.
2. Variable Overloading: The use of the variable "n" to represent both the number of words in an utterance and the number of utterances in a dialogue is confusing. Distinct symbols should be used for clarity.
3. Weak Human Comparison Results: The human evaluation comparing SMN to a generation-based model (VHRED) shows only marginal superiority, with SMN winning in 238 cases versus VHRED's 207. This raises questions about the practical significance of the model's improvements.
4. Unsupported Claims: The claim of chatbot performance superiority is not adequately supported by statistical significance tests in the human evaluation study.
5. Presentation Issues: Table 1 could be made more readable by numbering past turns. Figure 1 would benefit from explicitly labeling the layers to align with the text. Additionally, the phrasing in some parts (e.g., "to meet") is unclear, and the paper contains grammatical errors and typos that detract from its readability.
Questions to Authors
1. Could you clarify the definition of "segment" and how it differs from "sequence" in the context of the similarity matrices?
2. How does the performance of SMN vary with different attention mechanisms in the matching accumulation layer? Could this be explored further?
3. Can you provide statistical significance tests for the human comparison results with VHRED to strengthen the claim of chatbot superiority?
Additional Comments
While the paper presents a strong technical contribution, the presentation could be improved to enhance clarity and readability. Addressing the issues with terminology, variable naming, and statistical validation would significantly strengthen the submission.