Review of the Paper
Summary and Contributions
This paper presents a novel nonparametric clustering framework for document analysis, leveraging the Wasserstein distance (Earth Mover's Distance) to quantify dissimilarities between documents represented as empirical measures over word embedding space. The authors propose an adaptation of the D2-clustering framework, which incorporates recent algorithmic advancements for efficiently computing Wasserstein barycenters. The claimed contributions are twofold: (1) a scalable and computationally feasible document clustering tool that outperforms existing methods across heterogeneous datasets and (2) a quantitative evaluation framework to assess the gains of word embeddings compared to traditional bag-of-words models. The authors validate their approach through extensive experiments on six datasets, demonstrating its robustness and effectiveness.
Strengths
Unfortunately, the paper lacks clear strengths that can be highlighted for acceptance. While the proposed method appears to address a relevant problem and demonstrates empirical improvements, the presentation and clarity of the work are severely hindered by numerous weaknesses (discussed below). The lack of a polished and coherent narrative makes it difficult to fully appreciate the potential merits of the proposed approach.
Weaknesses
1. Grammar and Writing Quality: The paper contains numerous grammatical errors, including in critical sections such as the abstract and introduction. These errors significantly detract from the readability and professionalism of the submission. For example, phrases like "word embeddings have become widelyused" and "how muchbenefit Wasserstein distance brings" are indicative of careless editing.
   
2. Clarity and Structure: The paper is dense and overly technical in its presentation, making it difficult to follow for a general audience. Key concepts, such as the intuition behind the Wasserstein distance and its role in clustering, are not explained in an accessible manner. The mathematical formulations, while detailed, are not accompanied by sufficient intuitive explanations.
3. Novelty and Positioning: While the authors claim that their work differs from prior studies (e.g., Kusner et al., 2015) by focusing on scalable clustering rather than nearest-neighbor graphs, this distinction is not convincingly articulated. The novelty of the method is unclear, as it appears to build heavily on existing frameworks like D2-clustering and recent advancements in Wasserstein barycenter computation.
4. Evaluation and Insights: The experimental results, while extensive, lack depth in analysis. For example, the authors acknowledge that their method performs poorly on domain-specific datasets like Ohsumed but do not provide sufficient insights into why this is the case or how it could be addressed. Additionally, the discussion on the sensitivity of word embeddings is superficial and does not offer actionable takeaways.
5. Computational Complexity: Although the authors claim that their approach is computationally feasible, the reported runtimes (e.g., 121 seconds per iteration for Newsgroups data) suggest that the method may still be impractical for large-scale applications. This limitation is not adequately discussed.
Questions to Authors
1. How does the proposed method compare to other recent advancements in document clustering that also utilize Wasserstein distance or word embeddings? What specific gaps does this work address?
2. Can you provide more intuitive explanations or visualizations to help readers understand the role of Wasserstein distance in clustering?
3. How does the performance of your method scale with larger datasets or higher-dimensional embeddings? Are there any plans to further optimize the computational efficiency?
Recommendation
I recommend rejection of this paper in its current form. While the topic is relevant and the proposed approach shows promise, the paper suffers from significant issues in clarity, grammar, and novelty. A major revision is required to improve the presentation, address the computational limitations, and provide deeper insights into the method's contributions and limitations.