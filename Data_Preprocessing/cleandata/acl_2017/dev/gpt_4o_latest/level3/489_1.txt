Review of the Paper
Summary and Contributions
This paper explores models of referential word meaning by integrating visual and lexical knowledge, focusing on object naming tasks in both standard and zero-shot setups. The authors compare three models: (1) Direct Cross-Modal Mapping (TRANSFER), (2) Lexical Mapping via Word Classifiers (WAC), and (3) Word Prediction via Cross-Modal Similarity Mapping (SIM-WAP). The key contributions of the paper are:
1. Comparative Analysis of Approaches: The paper rigorously evaluates the strengths and weaknesses of different approaches to linking visual object representations with lexical semantics. Notably, it highlights the complementary nature of these models, as evidenced by improved performance through model combination.
   
2. Zero-Shot Naming Evaluation: The study extends the evaluation to zero-shot naming, providing insights into how models generalize to unseen object names and their lexical relations (e.g., hypernyms, singular/plural pairs).
3. Novel Use of Distributional Knowledge: The SIM-WAP model introduces a novel way to incorporate lexical similarity into training, enabling predictors for unseen words, which shows promise in zero-shot tasks.
Strengths
1. Novel Problem Addressed: The paper tackles the underexplored problem of referential word meaning, which is highly relevant for REG and grounded language understanding. Its focus on integrating lexical and visual knowledge is a significant step forward.
   
2. Comprehensive Experiments: The paper provides a thorough experimental evaluation, comparing multiple models across standard and zero-shot naming tasks. The analysis of model combinations and their complementary strengths is particularly insightful.
3. Practical Contributions: The findings have practical implications for REG systems, especially in scenarios requiring generalization to unseen categories, such as conversational agents or real-world image datasets.
4. Effective Use of Techniques: The use of the ReferIt dataset, along with distributional word embeddings and visual features from GoogleNet, demonstrates a strong grasp of state-of-the-art techniques.
Weaknesses
1. Unclear Hypothesis: The central hypothesis regarding the integration of visual and lexical knowledge is not clearly articulated. The distinction between multi-modal distributional semantics and cross-modal mapping remains vague, which undermines the paper's conceptual clarity.
2. Dataset Limitation: The subset of the ReferIt dataset used is highly restricted, and the motivation for this choice is insufficiently justified. This limits the generalizability of the findings.
3. Clarity Issues: Several aspects of the paper, such as dataset details, feature extraction, and task definitions (e.g., Section 6), are not clearly explained. The lack of examples for certain tasks further hampers understanding.
4. Overemphasis on Minor Differences: The paper occasionally overstates the significance of small numerical differences in model performance, even when these differences are statistically insignificant.
5. Originality Concerns: While the problem is novel, the methods and dataset have been explored in prior work. The contribution of the SIM-WAP model, though interesting, is incremental rather than groundbreaking.
Questions to Authors
1. Can you clarify the hypothesis and explicitly differentiate between multi-modal distributional semantics and cross-modal mapping? How does this distinction impact your findings?
2. Why was a restricted subset of the ReferIt dataset used, and how might this choice affect the generalizability of your results?
3. Could you provide an example to clarify the task in Section 6? This would help readers better understand the setup and evaluation.
4. Have you considered reporting cosine distances as similarities instead of distances, to align with standard practice?
Additional Comments
- The title could be more concise and focused to reflect either the general exploration of referential word meaning or the key findings.
- Missing references in Section 2 should be addressed to provide a more comprehensive overview of related work.
- The ensemble classifier's reliance on majority voting could be improved by exploring learning-based aggregation methods.
- Some results, such as those in Table 3, are under-analyzed. Further insights into these findings could strengthen the paper.
- Formatting inconsistencies (e.g., unclear terms like "flat hit @k metric") and dataset statistics presentation should be improved.
Conclusion
Overall, the paper makes a relevant and novel contribution to the field of REG and referential word meaning. However, the unclear hypothesis, dataset limitations, and incremental originality weaken its impact. With revisions to improve clarity, justify methodological choices, and better articulate the hypothesis, the paper could be a valuable addition to the conference.