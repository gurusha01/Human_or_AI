Review of the Paper
Summary and Contributions:  
This paper introduces an adversarial multi-task learning framework (ASP-MTL) for text classification, which effectively separates shared and task-specific feature spaces using adversarial training and orthogonality constraints. The key contributions of this work are:  
1. The ASP-MTL model, which extends binary adversarial training to a multi-class setting, ensuring that shared representations are task-invariant and generic.  
2. The introduction of orthogonality constraints to minimize redundancy and ensure clear separation between shared and private feature spaces.  
3. Demonstration of the transferability of shared representations to new tasks, showcasing the utility of the learned shared layer as off-the-shelf knowledge.  
Strengths:  
1. Clear and Effective Methodology: The paper presents a well-structured approach to address the contamination of shared spaces with task-specific features, a key limitation in existing multi-task learning models. The use of adversarial training and orthogonality constraints is innovative and well-motivated.  
2. Performance Improvements: The ASP-MTL model consistently outperforms baseline single-task and multi-task models across 16 text classification tasks, achieving significant reductions in error rates. The results are robust and demonstrate the superiority of the proposed method.  
3. Transferability of Representations: The task-level cross-validation experiments highlight the model's ability to transfer shared knowledge to unseen tasks, a valuable contribution for practical applications.  
4. Qualitative Analysis: The visualization of neuron activations and the analysis of shared and task-specific patterns provide valuable insights into the model's behavior, supporting the quantitative results.  
5. Reproducibility: The availability of implementation details and hyperparameter settings enhances the reproducibility of the work.  
Weaknesses:  
1. Lack of Statistical Significance Testing: The paper does not include statistical significance testing for the reported performance improvements, particularly between SP-MTL and ASP-MTL. This weakens the robustness of the claims.  
2. Missing Semi-Supervised Results: While the paper mentions the potential for semi-supervised learning, no experimental results are provided to validate this claim.  
3. Typographic and Presentation Issues: There are minor typographic and phrasing errors, as well as inconsistencies in figure colors, which slightly detract from the paper's readability.  
4. Limited Connection to Regularization Literature: The paper could benefit from a deeper exploration of the connections between adversarial training and regularization techniques, which might provide additional theoretical grounding.  
Questions to Authors:  
1. Can you provide statistical significance testing for the performance differences between SP-MTL and ASP-MTL?  
2. Do you have any experimental results to validate the semi-supervised learning potential of the ASP-MTL model?  
3. How does the choice of hyperparameters (e.g., λ and γ) affect the model's performance, and how sensitive is the model to these values?  
Conclusion:  
This paper presents a novel and effective approach to multi-task learning, with strong empirical results and insightful analysis. However, addressing the lack of statistical testing and providing semi-supervised results would further strengthen the work. Overall, the paper makes a meaningful contribution to the field and is well-suited for acceptance at the conference.