Review of the Paper
Summary and Contributions  
This paper explores models of referential word meaning by linking visual object representations to lexical representations in a distributional vector space. Three models are compared: (1) Direct Cross-Modal Mapping (TRANSFER), (2) Lexical Mapping Through Individual Word Classifiers (WAC), and (3) Word Prediction via Cross-Modal Similarity Mapping (SIM-WAP). The authors evaluate these models on object naming tasks, including a zero-shot setup, and propose that combining visual and lexical information enhances referential word meaning prediction. The main contributions of the paper are:  
1. Proposal of SIM-WAP: A novel model that integrates lexical similarity into training individual word predictors, showing improved performance in zero-shot naming tasks.  
2. Empirical Comparison of Models: A systematic evaluation of TRANSFER, WAC, and SIM-WAP, highlighting their complementary strengths and weaknesses in both standard and zero-shot object naming tasks.  
3. Model Combination: Evidence that combining predictions from different models improves naming accuracy, suggesting complementary roles of visual and lexical information.  
Strengths  
1. Novelty of SIM-WAP: The SIM-WAP model introduces an innovative approach by incorporating lexical similarity during training, which allows for better generalization in zero-shot naming tasks. This is a significant advancement over existing methods like TRANSFER and WAC.  
2. Thorough Evaluation: The paper provides a comprehensive comparison of models across multiple setups, including standard and zero-shot object naming tasks. The use of diverse test scenarios (e.g., hypernyms, singular/plural splits) strengthens the validity of the findings.  
3. Complementarity of Models: The demonstration that combining models improves performance is a valuable insight, as it suggests that different models capture distinct aspects of referential meaning. This finding could inform future research on hybrid approaches.  
4. Relevance to REG: The work addresses a critical problem in referring expression generation (REG) by focusing on the selection of appropriate object names, which is foundational for downstream tasks.  
Weaknesses  
1. Limited Vocabulary Size: The experiments are conducted on a relatively small vocabulary (159 words), which may limit the generalizability of the findings to larger, real-world datasets. Scaling up the approach is necessary to validate its broader applicability.  
2. Lack of Contextual Information: The models operate in isolation without considering contextual cues from the surrounding scene or referring expressions. This limits their utility in practical REG systems, where context often plays a crucial role.  
3. Evaluation Metrics: The evaluation relies heavily on accuracy metrics (e.g., hit@k) and cosine distances, but additional human evaluation or task-specific metrics (e.g., success rates in REG tasks) would provide a more nuanced understanding of model performance.  
4. Ambiguity in Zero-Shot Results: While SIM-WAP performs well in zero-shot tasks, the paper does not fully explore why TRANSFER struggles to generalize. A deeper analysis of failure cases would strengthen the conclusions.  
Questions to Authors  
1. How does the performance of SIM-WAP scale when applied to larger vocabularies or datasets, such as those used in conversational agents?  
2. Could contextual information (e.g., relationships between objects in a scene) be integrated into the models to improve referential word prediction?  
3. How do the models perform in tasks beyond object naming, such as full referring expression generation or attribute selection?  
Conclusion  
This paper makes a meaningful contribution to the field of referential word meaning by proposing and evaluating innovative models. While the work is promising, addressing the limitations of vocabulary size, contextual information, and evaluation metrics would further enhance its impact. I recommend acceptance with minor revisions to address these concerns.