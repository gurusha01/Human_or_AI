This paper evaluates a minimally supervised dependency parser -- a version of
the DMV model with manually set prior probabilities -- on (most of) the
treebanks from Universal Dependencies, v1.2. It reports results that are on
average slightly lower than a couple of delexicalized transfer parsers but
(sometimes substantially) better on a few non-Indo-European languages.
The idea of biasing an otherwise unsupervised parser with some basic
"universal" rules have been used a number of times before in the literature, so
the main value of the present paper is an empirical evaluation of this approach
on the new UD treebanks. However, the approach and evaluation leaves some 
questions unanswered.
First of all, I want to know why only unlabeled parsing is considered. This may
have been appropriate (or at least necessary) before dependency labels were
standardised, but the whole point of UD is to give a uniform analysis in terms
of typed dependencies, and any parsing approach that does not take this into
account seems misguided. And since the approach is based on manually defined
universal rules, it would have been easy enough to formulate rules for labeled
dependencies.
Second, I would like to know more about how the prior probabilities were set
or, in other words, what universal grammar they are meant to encode and how.
Were alternatives tested and, if so, how were they evaluated? In the present
version of the paper, we are just presented with a bunch of numbers without any
explanation or justification except that they are "based on UD annotation
style".
Third, one of the main claims of the paper is that the unsupervised system
works better for non-Indo-European languages. This seems to be supported by the
raw numbers, but what exactly is going on here? What types of dependencies are
handled better by the unsupervised system? Even though a full error analysis
would be out of scope in a short paper, an analysis of a small sample could be
really interesting.
Finally, the comparison to the delexicalized transfer parsers seems to be
biased by a number of factors. Restricting it to unlabeled dependencies is one
such thing, since the delexicalized parser could easily have produced labeled
dependencies. Another thing is the amount of training data, which was
arbitrarily restricted to 10,000 tokens per treebank. Finally, it seems that
the delexicalized parsers were not properly tuned. Just replacing word forms
and lemmas by underscores without revising the feature models is not likely to
produce optimal results.