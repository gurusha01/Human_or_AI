The paper describes a method for in-domain data selection for SMT with a
convolutional neural network classifier, applying the same framework as Johnson
and Zhang, 2015. The method performs about 0.5 BLEU points better than language
model based data selection, and, unlike the other methods, is robust even if
only a very small in-domain data set is provided. 
The paper claims improvements of 3.1 BLEU points. However, from the results we
see that improvements of this magnitude are only achieved if there are
in-domain data in the training set - training only on the in-domain data
already produces +2.8 BLEU. It might be interesting to also compare this to a
system which interpolates separate in- and out-domain models. 
The more impressive result, in my opinion, comes from the second experiment,
which demonstrates that the CNN classifier is still effective if there is very
little in-domain data. However, the second experiment is only run on the zh2en
task which includes actual in-domain data in the training set, possibly making
selection easier. Would the result also hold for the other tasks, where there
is no in-domain data in the training set? The results for the en2es and en2zh
task already point in this direction, since the development sets only contain a
few hundred sentence pairs. I think the claim would be better supported if
results were reported for all tasks when only 100 sentence pairs are used for
training.  
When translating social media text one often has to face very different
problems from other domains, the most striking being a high OOV rate due to
non-conventional spelling (for Latin scripts, at least). The texts can also
contain special character sequences such as usernames, hashtags or emoticons.
Was there any special preprocessing or filtering step applied to the data?  
Since data selection cannot address the OOV problem, it would be interesting to
know in more detail what kinds of improvements are made through adaptation via
data selection, maybe by providing examples.   
The following remarks concern specific sections:
Section 3.2:
- It could be made clearer how the different vectors (word embeddings, segment
vectors and one-hot vectors) are combined in the model. An illustration of the
architecture would be very helpful. 
- What was the "designated loss function"?
Section 5.2:
For completeness' sake, it could be mentioned how the system weights were
tuned.