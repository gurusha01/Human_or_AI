The paper presents the first broad-coverage semantic parsers for UCCA, one
specific approach to graph-based semantic representations. Unlike CoNLL
semantic dependency graphs, UCCA graphs can contain "nonterminal" nodes which
do not represent words in the string. Unlike AMRs, UCCA graphs are "grounded",
which the authors take to mean that the text tokens appear as nodes in the
semantic representation. The authors present a number of parsing methods,
including a transition-based parser that directly constructs UCCA parses, and
evaluate them.
Given that UCCA and UCCA-annotated data exist, it seems reasonable to develop a
semantic parser for UCCA. However, the introduction and background section hit
a wrong note to my ear, in that they seem to argue that UCCA is the only
graph-based semantic representation (SR) formalism that makes sense to be
studied. This doesn't work for me, and also seems unnecessary -- a good UCCA
parser could be a nice contribution by itself.
I do not entirely agree with the three criteria for semantic representation
formalisms the authors lay out in the introduction. For instance, it is not
clear to me that "nonterminal nodes" contribute any expressive capacity. Sure,
it can be inconvenient to have to decide which word is the head of a
coordinated structure, but exactly what information is it that could only be
represented with a nonterminal and not e.g. with more informative edge labels?
Also, the question of discontinuity does not even arise in SRs that are not
"grounded". The advantages of "grounded" representations over AMR-style ones
did not become clear to me. I also think that the word "grounded" has been used
for enough different concepts in semantics in the past ten years, and would
encourage the authors to find a different one ("anchored"? "lexicalized"?).
Thus I feel that the entire introductory part of the paper should be phrased
and argued much more carefully.
The parser itself seems fine, although I did not check the details. However, I
did not find the evaluation results very impressive. On the "primary" edges,
even a straightforward MaltParser outperforms the BSP parser presented here,
and the f-scores on the "remote" edges (which a dependency-tree parser like
Malt cannot compute directly) are not very high either. Furthermore, the
conversion of dependency graphs to dependency trees has been studied quite a
bit under the name "tree approximations" in the context of the CoNLL 2014 and
2015 shared tasks on semantic dependency parsing (albeit without "nonterminal"
nodes). Several authors have proposed methods for reconstructing the edges that
were deleted in the graph-to-tree conversion; for instance, Agic et al. (2015),
"Semantic dependency graph parsing using tree approximations" discuss the
issues involved in this reconstruction in detail. By incorporating such
methods, it is likely that the f-score of the MaltParser (and the LSTM-based
MaltParser!) could be improved further, and the strength of the BSP parser
becomes even less clear to me.