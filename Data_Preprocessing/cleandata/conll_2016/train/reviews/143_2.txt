This paper proposes two dictionary-based methods for estimating multilingual
word embeddings, one motivated in clustering (MultiCluster) and another in
canonical correlation analysis (MultiCCA).
In addition, a supersense similarity measure is proposed that improves on QVEC
by substituting its correlation component with CCA, and by taking into account
multilingual evaluation.
 The evaluation is performed on a wide range of tasks using the web portal
developed by the authors; it is shown that in some cases the proposed
representation methods outperform two other baselines.
I think the paper is very well written, and represents a substantial amount of
work done. The presented representation-learning and evaluation methods are
certainly timely. I also applaud the authors for the meticulous documentation.
My general feel about this paper, however, is that it goes (perhaps) in too
much breadth at the expense of some depth. I'd prefer to see a thorougher
discussion of results (e.g. regarding the conflicting outcome for MultiCluster
between 59- and 12-language set-up; regarding the effect of estimation
parameters and decisions in MultiCluster/CCA). So, while I think the paper is
of high practical value to me and the research community (improved QVEC
measure, web portal), I frankly haven't learned that much from reading it, i.e.
in terms of research questions addressed and answered.
Below are some more concrete remarks.
It would make sense to include the correlation results (Table 1) for
monolingual QVEC and QVEC-CCA as well. After all, it is stated in l.326--328
that the proposed QVEC-CCA is an improvement over QVEC.
Minor:
l. 304: "a combination of several cross-lingual word similarity datasets" ->
this sounds as though they are of different nature, whereas they are really of
the same kind, just different languages, right?
p. 3: two equations exceed the column margin
Lines 121 and 147 only mention Coulmance et al and Guo et al when referring to
the MultiSkip baseline, but section 2.3 then only mentions Luong et al. So,
what's the correspondence between these works?
While I think the paper does reasonable justice in citing the related works,
there are more that are relevant and could be included:
Multilingual embeddings and clustering:
Chandar A P, S., Lauly, S., Larochelle, H., Khapra, M. M., Ravindran, B.,
Raykar, V. C., and Saha, A. (2014). An autoencoder approach to learning
bilingual word representations. In NIPS.
Hill, F., Cho, K., Jean, S., Devin, C., and Bengio, Y. (2014). Embedding word
similarity with neural machine translation. arXiv preprint arXiv:1412.6448.
Lu, A., Wang, W., Bansal, M., Gimpel, K., & Livescu, K. (2015). Deep
multilingual correlation for improved word embeddings. In NAACL.
Faruqui, M., & Dyer, C. (2013). An Information Theoretic Approach to Bilingual
Word Clustering. In ACL.
Multilingual training of embeddings for the sake of better source-language
embeddings:
Suster, S., Titov, I., and van Noord, G. (2016). Bilingual learning of
multi-sense embeddings with discrete autoencoders. In NAACL-HLT.
Guo, J., Che, W., Wang, H., and Liu, T. (2014). Learning sense-specific word
embeddings by exploiting bilingual resources. In COLING.
More broadly, translational context has been explored e.g. in
Diab, M., & Resnik, P. (2002). An unsupervised method for word sense tagging
using parallel corpora. In ACL.