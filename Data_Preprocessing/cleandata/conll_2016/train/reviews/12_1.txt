I reviewed this paper earlier, when it was an ACL 2016 short paper draft. At
that point, it had a flaw in the experiment setup, which is now corrected.
Since back then I suggested I'd be willing to accept the draft for another *ACL
event provided that the flaw is corrected, I now see no obstacles in doing so.
Another reviewer did point out that the setup of the paper is somewhat
artificial if we focus on real low-resource languages, relating to the costs of
finding vs. paying the annotators. I believe this should be exposed in the
writeup not to oversell the method.
There are relevant lines of work in annotation projection for extremely
low-resource languages, e.g., Johannsen et al. (2016, ACL) and Agic et al.
(2015, ACL). It would be nice to reflect on those in the related work
discussion for completeness.
In summary, I think this is a nice contribution, and I vote accept.
It should be indicated whether the data is made available. I evaluate those
parts in good faith now, presuming public availability of research.