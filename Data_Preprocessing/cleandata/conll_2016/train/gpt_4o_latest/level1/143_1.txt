Review
Summary
This paper introduces two novel methods, multiCluster and multiCCA, for estimating multilingual word embeddings across 59 languages using monolingual corpora and bilingual dictionaries, without requiring parallel corpora. Additionally, the authors propose a new evaluation metric, multiQVEC-CCA, which improves upon existing intrinsic evaluation methods by addressing theoretical shortcomings and achieving better correlation with downstream tasks such as text classification and dependency parsing. A web portal is also developed to facilitate standardized evaluation of multilingual embeddings.
Contributions
1. Proposed Estimation Methods: The primary contribution is the introduction of multiCluster and multiCCA, dictionary-based methods for training multilingual embeddings. These methods are scalable to a large number of languages and do not rely on parallel corpora, making them accessible for low-resource languages. Among the two, multiCCA consistently outperforms multiCluster in both intrinsic and extrinsic evaluations, demonstrating its robustness.
   
2. Improved Evaluation Metric: The paper introduces multiQVEC-CCA, an extension of QVEC, which addresses issues of basis invariance and normalization. This metric correlates better with downstream tasks compared to previously used intrinsic metrics, providing a more reliable measure of embedding quality.
3. Evaluation Portal: The development of a web portal for evaluating multilingual embeddings is a significant contribution to the field. It provides researchers with tools to benchmark their methods using standardized datasets and metrics, promoting reproducibility and comparability.
Strengths
1. Scalability and Accessibility: The proposed methods are designed to work with bilingual dictionaries, making them applicable to a wide range of languages, including low-resource ones. This is a notable improvement over methods that require parallel corpora.
   
2. Comprehensive Evaluation: The paper evaluates the proposed methods using a diverse set of intrinsic and extrinsic metrics, including multilingual word similarity, word translation, document classification, and dependency parsing. The use of downstream tasks strengthens the validity of the proposed methods.
3. Correlation Analysis: The authors provide a detailed analysis of how intrinsic metrics correlate with extrinsic tasks, highlighting the limitations of existing metrics and the advantages of multiQVEC-CCA. This analysis is valuable for guiding future research in evaluation methodologies.
4. Open-Source Tools: The release of a web portal and open-source code demonstrates a commitment to reproducibility and practical impact, which will likely accelerate progress in multilingual NLP.
Weaknesses
1. Limited Comparison with Parallel Data Methods: While the paper compares multiCluster and multiCCA to parallel data-based methods (e.g., multiSkip and translation-invariance), the experiments are limited to a subset of 12 languages. A broader comparison across all 59 languages would provide a more comprehensive assessment of the proposed methods' scalability.
2. Cluster Ambiguity in multiCluster: The multiCluster method suffers from semantic ambiguity due to its reliance on shared embeddings for translationally equivalent words. This limitation is particularly pronounced when scaling to 59 languages, as evidenced by its lower performance compared to multiCCA.
3. Dependence on Supersense Annotations: The proposed evaluation metrics (multiQVEC and multiQVEC-CCA) rely on supersense annotations, which are not consistently available across languages. This limits the generalizability of these metrics to languages without such resources.
Questions to Authors
1. How does the performance of multiCluster and multiCCA vary with the quality of the bilingual dictionaries used? Have you evaluated their robustness to noisy or incomplete dictionaries?
2. Can the multiQVEC-CCA metric be adapted for languages without supersense annotations? If so, how?
3. Have you considered extending the evaluation portal to include additional downstream tasks, such as machine translation or cross-lingual information retrieval?
Conclusion
This paper makes significant contributions to the field of multilingual NLP by proposing scalable methods for multilingual embeddings, improving evaluation metrics, and providing tools for standardized benchmarking. While there are some limitations, particularly in the reliance on supersense annotations and the scalability of comparisons with parallel data methods, the overall impact of the work is substantial. I recommend acceptance, as the paper addresses critical challenges in multilingual NLP and provides valuable resources for the community.