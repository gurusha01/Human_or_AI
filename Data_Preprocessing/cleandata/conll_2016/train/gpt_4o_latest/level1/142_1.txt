Review of the Submission
Summary and Contributions:
This paper addresses the challenge of incorporating uncertainty estimates into Machine Translation Quality Estimation (QE), a task traditionally evaluated using point estimate metrics. The authors propose the use of Gaussian Processes (GPs) for probabilistic modeling in QE, leveraging their ability to provide well-calibrated uncertainty estimates. They introduce novel extensions, including the use of Matèrn kernels and Warped Gaussian Processes, to better handle noisy data and non-Gaussian response variables. The paper evaluates these models using Negative Log Predictive Density (NLPD), a metric that accounts for uncertainty, and demonstrates their utility in asymmetric risk scenarios, such as post-editing and gisting workflows. The work also highlights the limitations of traditional point estimate metrics in capturing differences in uncertainty modeling.
The main contributions of the paper, as I see them, are:
1. Introduction of Uncertainty-Aware Metrics for QE: The use of NLPD to evaluate QE models represents a significant step forward in capturing the quality of uncertainty estimates, which is overlooked by traditional metrics like MAE and Pearson's r.
2. Application of Warped Gaussian Processes to QE: The extension of GPs with warping functions to model non-Gaussian response variables is a novel and impactful contribution, particularly in the context of QE datasets with noisy and skewed distributions.
3. Exploration of Asymmetric Risk Scenarios: The application of predictive distributions to asymmetric loss functions (e.g., AL and linex losses) demonstrates the practical utility of uncertainty-aware models in real-world translation workflows.
Strengths:
1. Novelty and Relevance: The paper addresses a critical gap in QE research by focusing on uncertainty modeling, which is highly relevant for real-world applications like post-editing and gisting.
2. Comprehensive Evaluation: The use of multiple datasets, cross-validation, and a variety of metrics (NLPD, MAE, Pearson's r) ensures a thorough evaluation of the proposed models. The experiments convincingly demonstrate the advantages of probabilistic approaches.
3. Practical Impact: The exploration of asymmetric risk scenarios highlights the practical implications of uncertainty-aware QE models, making the work highly applicable to industry settings.
4. Theoretical Rigor: The paper provides a solid theoretical foundation for the proposed methods, including detailed discussions of Matèrn kernels, Warped GPs, and Bayes risk estimators for asymmetric losses.
Weaknesses:
1. Limited Discussion on Scalability: While GPs are known to struggle with scalability in large datasets, the paper does not address how the proposed methods would perform in scenarios with larger QE datasets or higher-dimensional feature spaces.
2. Unclear Generalizability Beyond QE: Although the authors claim that the methods can be applied to other text regression tasks, the paper lacks concrete examples or experiments to support this claim.
3. Inconclusive Results for Linex Loss in Pessimistic Scenarios: The results for linex loss in pessimistic settings are inconsistent and raise questions about the suitability of the proposed models for such scenarios. This issue warrants further investigation.
Questions to Authors:
1. How do you plan to address the scalability challenges of GPs for larger QE datasets or higher-dimensional feature sets?
2. Can you provide examples or experiments to demonstrate the applicability of your methods to other text regression tasks beyond QE?
3. Could you elaborate on why the linex loss results in pessimistic scenarios were inconclusive, and how this issue might be resolved in future work?
Conclusion:
This paper makes significant contributions to the field of QE by introducing uncertainty-aware probabilistic models and metrics. While there are some limitations, particularly in scalability and generalizability, the work is well-motivated, methodologically sound, and practically relevant. I recommend acceptance, provided the authors address the scalability concerns and clarify the generalizability of their methods.