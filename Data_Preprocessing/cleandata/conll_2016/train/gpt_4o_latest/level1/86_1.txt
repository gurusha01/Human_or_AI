Review of the Paper
Summary and Contributions
This paper introduces two sentiment analysis tools, App2Check and Tweet2Check, designed for app reviews and tweets in both Italian and English. The tools leverage supervised learning techniques to create predictive models for sentiment quantification. The authors conduct an extensive experimental evaluation comparing their tools against 19 state-of-the-art sentiment analysis tools and demonstrate superior performance across multiple benchmarks. The main contributions of the paper, as I see them, are:
1. Development of App2Check and Tweet2Check: These tools achieve state-of-the-art performance in sentiment analysis for app reviews and tweets, surpassing existing tools in both accuracy and macro-F1 scores. The tools are particularly notable for their ability to handle both Italian and English, with App2Check achieving over 80% accuracy on app reviews, exceeding the theoretical human agreement threshold.
   
2. Comprehensive Benchmarking: The authors provide a thorough evaluation of their tools against 19 existing sentiment analysis tools using diverse datasets, including app reviews (11,000 in Italian and English) and tweets (4,899 in Italian and English). The inclusion of new test sets for app reviews, made available to the research community, is a valuable contribution.
3. Domain-Specific Adaptability: The tools demonstrate the ability to improve performance through domain-specific training, as shown in the evaluation on tweets. This flexibility is a significant advantage for real-world applications where domain-specific sentiment analysis is often required.
Strengths
1. Strong Empirical Results: The experimental results convincingly demonstrate the superiority of App2Check and Tweet2Check over existing tools, particularly in terms of accuracy and macro-F1 scores. The tools consistently outperform competitors across multiple datasets and languages.
2. Focus on Underexplored Domains: The paper highlights the unique challenges of sentiment analysis in app reviews, a domain that has received relatively little attention compared to tweets. This focus broadens the scope of sentiment analysis research.
3. Practical Utility: The tools' ability to handle both Italian and English, along with their adaptability to specific domains, makes them highly practical for a wide range of applications, from app store analytics to social media monitoring.
4. Availability of Resources: By providing new benchmark datasets and demo access to the tools, the authors contribute to the reproducibility and further development of sentiment analysis research.
Weaknesses
1. Limited Methodological Transparency: The paper provides insufficient details about the underlying algorithms and training processes of App2Check and Tweet2Check, citing non-disclosure restrictions. This lack of transparency hinders reproducibility and the ability to critically assess the novelty of the methods.
2. Overemphasis on Performance Metrics: While the tools' performance is impressive, the paper does not sufficiently discuss the broader implications of the results or the potential limitations of the tools, such as handling of ambiguous or highly contextual sentiment.
3. Neutral Sentiment Classification: The tools, like many others, struggle with the neutral class, as evidenced by low F1 scores for this category. A deeper analysis of this challenge and potential solutions would strengthen the paper.
4. Evaluation Bias: The inclusion of domain-specific training for Tweet2Check during evaluation raises concerns about fairness in comparison with tools that do not support such customization. A clearer distinction between baseline and domain-adapted results is needed.
Questions to Authors
1. Can you provide more details about the supervised learning techniques and feature engineering used in App2Check and Tweet2Check? Are the models based on traditional machine learning or deep learning approaches?
2. How do the tools handle ambiguous or mixed sentiment in app reviews and tweets? Are there specific strategies to address these challenges?
3. Could you clarify the rationale for including domain-specific training in the evaluation of Tweet2Check? How do you ensure a fair comparison with tools that do not support such training?
Additional Comments
Overall, the paper presents a strong contribution to sentiment analysis research, particularly in the underexplored domain of app reviews. However, greater methodological transparency and a more balanced discussion of limitations would enhance its impact.