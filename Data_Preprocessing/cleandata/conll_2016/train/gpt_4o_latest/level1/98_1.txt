Review of Submission
Summary and Contributions  
This paper investigates the performance of delexicalized transfer parsers and minimally supervised dependency parsers across 32 languages from the Universal Dependencies (UD) treebank collection. The minimally supervised parser incorporates handcrafted universal grammatical rules or learns external prior probabilities from other treebanks. The study finds that while the delexicalized transfer parser achieves higher average attachment scores, the minimally supervised parser outperforms it on less-resourced, non-Indo-European languages. The authors argue that their minimally supervised approach is particularly suited for parsing low-resource languages where annotated treebanks are unavailable.
The primary contributions of the paper are:  
1. Empirical Comparison of Parsing Methods: The paper provides a thorough comparison of delexicalized transfer parsing and minimally supervised parsing methods, highlighting their strengths and weaknesses across diverse languages.  
2. Minimally Supervised Parsing Framework: The authors propose a minimally supervised parser that incorporates external prior probabilities, either manually defined or learned from other treebanks, and demonstrate its utility for less-resourced languages.  
3. Insights into Parsing Low-Resource Languages: The paper identifies that minimally supervised parsers generalize better to non-Indo-European languages, offering a valuable direction for low-resource language parsing.
---
Strengths  
1. Comprehensive Evaluation: The authors evaluate their methods on 32 languages from the UD treebank collection, providing a broad and diverse dataset for analysis. This strengthens the generalizability of the findings.  
2. Focus on Low-Resource Languages: The work addresses an important gap in dependency parsing research by focusing on less-resourced, non-Indo-European languages, which are often neglected in mainstream studies.  
3. Novel Use of External Priors: The incorporation of external prior probabilities into the unsupervised parser is a creative approach that bridges the gap between unsupervised and supervised methods. The comparison between manually defined and learned priors is particularly insightful.  
4. Improved Parsing for Specific Languages: The minimally supervised parser demonstrates superior performance on several non-Indo-European languages, such as Tamil, Basque, and Hindi, showcasing its practical utility for low-resource scenarios.  
5. Contribution to Universal Dependencies: The paper highlights the benefits of the UD framework for cross-linguistic parsing, showing improved results compared to prior work using less harmonized treebanks.
---
Weaknesses  
1. Limited Novelty in Delexicalized Parsing: While the comparison is thorough, the delexicalized transfer parsing methods used are relatively standard and do not introduce significant methodological innovations.  
2. Manual Priors Lack Scalability: The manually defined external priors, while effective, may not scale well to a larger number of languages or more complex linguistic phenomena. This limits the broader applicability of the approach.  
3. Evaluation Metrics: The paper focuses solely on unlabeled attachment scores (UAS). Including labeled attachment scores (LAS) or other metrics could provide a more nuanced understanding of parser performance.  
4. Insufficient Analysis of Learned Priors: The paper does not delve deeply into the characteristics of the learned priors or how they differ across languages. A qualitative analysis could enhance the interpretability of the results.  
5. Lack of Error Analysis: The paper does not include a detailed error analysis to explain why the minimally supervised parser performs better on certain languages. This would strengthen the claims about its suitability for non-Indo-European languages.
---
Questions to Authors  
1. How sensitive is the performance of the minimally supervised parser to the choice of Î» parameters for combining external priors?  
2. Could the manually defined priors be extended or automated using linguistic typology databases?  
3. Have you considered evaluating the parsers using labeled attachment scores (LAS) or other metrics to provide a more comprehensive evaluation?  
4. Can you provide qualitative insights into the learned priors? For example, do they capture language-specific syntactic patterns?  
5. How does the minimally supervised parser perform on low-resource languages with noisy or incomplete POS tagging?
---
Overall Recommendation  
This paper makes a valuable contribution to dependency parsing, particularly for low-resource languages. While the methodological novelty is limited, the empirical findings and focus on non-Indo-European languages are significant. With additional analysis and refinement, this work could have a strong impact on the field.