This paper evaluates the performance of delexicalized transfer parsers and an unsupervised parser augmented with external probabilities, using results derived from the UD treebanks.
The paper is engaging, but there are areas where it could be improved.
(5.2) "McDonald et al. (2011) presented 61.7% of averaged accuracy over 8 languages. On the same languages, our transfer parser on UD reached 70.1%." It is important to clarify that McDonald et al. could not utilize the UD treebanks since these resources were not available at the time. This distinction should be explicitly mentioned.
In footnote 9, you state: "We used the Malt parser with its default feature set. Tuning in this specific delexicalized task would probably bring a bit better results." Since you are using MaltParser with default settings, why not employ MaltOptimizer? Optimizing the model would likely be straightforward and could yield improved results. Similarly, MSTParser could also benefit from further optimization. Additionally, why not explore more recent parsers that have demonstrated superior performance? These newer parsers have already been applied to universal dependencies using the leave-one-out setup (see references below). For instance, the authors claim that the unsupervised parser "performs better for languages from less resourced language families (non-Indo-European)," but it would be valuable to verify whether this claim holds true when using more recent (and cross-lingual) parsers.
Probabilities: The choice of probabilities in Tables 3 and 4 (especially Table 3) appears somewhat arbitrary. More details or a set of experiments are needed to justify their use and demonstrate their validity.
There are several relevant papers that the authors should consider:
1. Cross-Lingual Dependency Parsing with Universal Dependencies and Predicted PoS Labels  
   J Tiedemann  
2. One model, two languages: training bilingual parsers with harmonized treebanks  
   D Vilares, MA Alonso, C Gómez-Rodríguez (this paper presents results with MaltParser)  
For results with more recent parsers (including delexicalized parsers):  
1. Crosslingual dependency parsing based on distributed representations  
   Jiang Guo, Wanxiang Che, David Yarowsky, Haifeng Wang, and Ting Liu. 2015. In Proc. of ACL  
2. Many languages, one parser  
   W Ammar, G Mulcaire, M Ballesteros, C Dyer, NA Smith  
-Minor points:  
I do not believe Table 1 and Table 2 are necessary. The information in Table 1 could be replaced with a footnote linking to the UD website. Table 2 might be justified due to its relevance to the probabilities, but Table 1 is redundant and should be omitted.