This paper investigates a minimally supervised dependency parser, specifically a variant of the DMV model with manually assigned prior probabilities, applied to (most of) the treebanks from Universal Dependencies, v1.2. The results, on average, are slightly below those of a few delexicalized transfer parsers but are (sometimes significantly) better for certain non-Indo-European languages.
The concept of introducing bias into an otherwise unsupervised parser using basic "universal" rules has been explored multiple times in prior research. Consequently, the primary contribution of this paper lies in its empirical evaluation of this approach using the new UD treebanks. However, the methodology and evaluation raise several unresolved questions.
First, it is unclear why the study focuses exclusively on unlabeled parsing. While this might have been reasonable (or unavoidable) before dependency labels were standardized, the central goal of UD is to provide a consistent analysis using typed dependencies. Any parsing approach that disregards this aspect appears misaligned with the UD framework. Moreover, given that the approach relies on manually defined universal rules, extending these to labeled dependencies should have been straightforward.
Second, more details are needed regarding how the prior probabilities were determined—specifically, what aspects of universal grammar they aim to encode and the methodology behind their formulation. Were alternative priors considered, and if so, how were they evaluated? The current version of the paper presents numerical results without sufficient explanation or justification, other than a vague reference to being "based on UD annotation style."
Third, the claim that the unsupervised system performs better for non-Indo-European languages is intriguing but insufficiently explored. While the raw results seem to support this assertion, the underlying reasons remain unclear. What specific types of dependencies are better handled by the unsupervised system? Although a comprehensive error analysis may be beyond the scope of a short paper, even a limited analysis of a small sample could provide valuable insights.
Lastly, the comparison with delexicalized transfer parsers appears to be influenced by several biases. Limiting the evaluation to unlabeled dependencies is one such issue, as the delexicalized parser could have generated labeled dependencies. Additionally, the training data was arbitrarily capped at 10,000 tokens per treebank, which may have impacted the results. Furthermore, it seems that the delexicalized parsers were not adequately optimized—simply replacing word forms and lemmas with underscores without adjusting the feature models is unlikely to yield optimal performance.