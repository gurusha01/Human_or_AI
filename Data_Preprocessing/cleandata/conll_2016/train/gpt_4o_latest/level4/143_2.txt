This paper introduces two dictionary-based approaches for estimating multilingual word embeddings: one inspired by clustering (MultiCluster) and the other by canonical correlation analysis (MultiCCA). Additionally, the authors propose a supersense similarity measure that enhances QVEC by replacing its correlation component with CCA and incorporating multilingual evaluation. The methods are evaluated across a diverse set of tasks using a web portal developed by the authors, demonstrating that the proposed representations outperform two baseline methods in certain scenarios.
The paper is well-written and reflects a significant amount of effort. The representation-learning and evaluation techniques presented are timely and relevant. I also commend the authors for their thorough documentation.
However, my overall impression is that the paper sacrifices some depth in favor of breadth. A more detailed discussion of the results would be beneficial, particularly regarding the conflicting outcomes for MultiCluster between the 59-language and 12-language setups, as well as the impact of estimation parameters and design choices in MultiCluster and MultiCCA. While the paper offers high practical value to the research community (e.g., the improved QVEC measure and the web portal), I found it less informative in terms of addressing and answering specific research questions.
Below are some specific comments:
It would be helpful to include the correlation results (Table 1) for monolingual QVEC and QVEC-CCA, as it is claimed in lines 326â€“328 that QVEC-CCA improves upon QVEC.
Minor points:
- Line 304: "a combination of several cross-lingual word similarity datasets" could be misleading, as it implies the datasets are of different types, whereas they are similar in nature but pertain to different languages.
- Page 3: Two equations exceed the column margin.
- Lines 121 and 147 reference Coulmance et al. and Guo et al. for the MultiSkip baseline, but Section 2.3 only mentions Luong et al. Clarification on the relationship between these works would be useful.
While the paper appropriately cites related work, additional relevant references could be included:
Multilingual embeddings and clustering:
- Chandar A P, S., Lauly, S., Larochelle, H., Khapra, M. M., Ravindran, B., Raykar, V. C., and Saha, A. (2014). An autoencoder approach to learning bilingual word representations. In NIPS.
- Hill, F., Cho, K., Jean, S., Devin, C., and Bengio, Y. (2014). Embedding word similarity with neural machine translation. arXiv preprint arXiv:1412.6448.
- Lu, A., Wang, W., Bansal, M., Gimpel, K., & Livescu, K. (2015). Deep multilingual correlation for improved word embeddings. In NAACL.
- Faruqui, M., & Dyer, C. (2013). An Information Theoretic Approach to Bilingual Word Clustering. In ACL.
Multilingual training of embeddings for improved source-language embeddings:
- Suster, S., Titov, I., and van Noord, G. (2016). Bilingual learning of multi-sense embeddings with discrete autoencoders. In NAACL-HLT.
- Guo, J., Che, W., Wang, H., and Liu, T. (2014). Learning sense-specific word embeddings by exploiting bilingual resources. In COLING.
Broader exploration of translational context:
- Diab, M., & Resnik, P. (2002). An unsupervised method for word sense tagging using parallel corpora. In ACL.