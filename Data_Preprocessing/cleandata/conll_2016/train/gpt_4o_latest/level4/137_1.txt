Paraphrased Review
---
General Comments  
The paper presents experiments aimed at predicting the degree of compositionality of English compounds. The dataset employed is a pre-existing collection of 90 compounds, with compositionality scores ranging from 1 to 5, as determined by an unspecified number of judges.  
The experimental framework involves computing cosine similarity between the vector representation of the compound (treated as a single token) and the composition of the vectors of its components. The evaluation is conducted using Spearman correlation to compare the cosine similarity values with human judgments.  
The experiments vary along two dimensions:  
- The type of vectors used, i.e., neural embeddings versus syntactic-context count vectors.  
- For the syntactic-context count vectors, whether plain or "aligned" vectors are used for the dependent component of the compound. The alignment technique, which attempts to model the shift from the dependent to the head, was introduced in a previously suppressed reference by the authors.  
The results show that syntactic-context count vectors outperform neural embeddings. However, using aligned vectors alone performs worse than using unmodified vectors, while a carefully optimized combination of aligned and unaligned vectors yields a slight improvement.  
In terms of presentation, the introduction is well-written, but other sections, such as Section 5.1, are challenging to follow despite the relatively straightforward underlying concepts. Including running examples could improve clarity.  
Regarding the substance, I have several concerns:  
- The primary innovation compared to Reddy et al. appears to be the use of aligned vectors, but these were already introduced in a prior suppressed reference by the authors.  
- The dataset is small and insufficiently described. For instance, frequency ranges likely influence the results, but this is not addressed. Given the marginal improvements achieved with aligned vectors, the small dataset size, and the unclear selection criteria for the compounds, the findings in the paper appear fragile.  
---
Detailed Comments and Questions  
Section 3  
The introduction of the term "packed anchored tree" seems unnecessary. It appears to be a straightforward extraction of paths between two lexical items in a dependency tree, which is a natural extension of traditional syntactic distributional representations of words (e.g., paths of length one or two, with collapsed prepositions, as seen in Lin 1998).  
Additionally, why is it referred to as a "tree"? What exactly are "elementary APTs" as mentioned in Section 5.1?  
In Table 2, it seems that features of order greater than 3 are excluded, as indicated by the absence of features like NMOD.overline(NSUBJ).DOBJ in the bottom-left cell of the table. Is this exclusion due to the elimination of incompatible types mentioned in the text? If so, an example would help clarify this point.  
Section 4  
Since the Reddy et al. dataset is central to the work, more details about its composition are necessary. How were the 90 compounds selected? What are the frequency ranges for the compounds and their components? These factors likely affect the results.  
How many judgments were collected for each compound? Are there many compounds with identical compositionality scores? If so, does this pose a problem for ranking them when computing Spearman correlation?  
The term "constituent" is used to refer to components of the N-N sequence, but "component" might be more appropriate, as "constituent" can also refer to phrases or syntagms.  
The statement, "the intuition that if a constituent is used literally within a phrase, then it is highly likely that the compound and the constituent share co-occurrences," seems valid for the head of the phrase but less so for other components. For example, in "spelling bee," the distribution of "spelling" does not align with that of the compound.  
Section 5  
The sentence, "Note that the elementary representation for the constituent of a compound phrase will not contain any of the contextual features associated with the compound phrase token unless they occurred with the constituent in some other context," would benefit from a running example to clarify the objects being discussed. Does "compound phrase token" refer to the merged components of the compound?  
In Section 5.1, are "elementary APTs" defined as triplets consisting of a target word (w), a dependency path (r), and another word (w')? The terminology is somewhat confusing.  
Please clarify whether "shifted PMI" refers to the PMI defined in Equation (3).  
The sentence, "Removing features which tend to go with lots of things (low positive PMI) means that these phrases appear to have been observed in a very small number of (highly informative) contexts," is unclear. Does "these phrases" refer to "things"? The sentence seems contradictory and requires clarification.  
The statement, "In general, we would expect there to be little overlap between APTs which have not been properly aligned," is ambiguous. Does "not properly aligned" mean "not aligned at all"?  
The reasoning in Paragraphs 558–563 is unclear. Why would there be significant overlap specifically in the case of the NMOD relation between the two components?  
Paragraphs 575–580 are also puzzling. The paper relies on higher-order dependency features throughout, yet at the critical point of measuring similarity between composed and observed phrasal vectors, only first-order features are used. Note 3 attempts to explain this, but the reasoning for the unreliability of second-order paths in composed representations is unclear and needs further elaboration.  
Section 6  
The claim that "smoothing the PPMI calculation with a value of α = 0.75 generally has a small positive effect" is not immediately evident from Table 3.  
What are the optimal values for h and q in Equations (8) and (9)? These values are crucial for understanding the extent to which the hybrid approach contributes to the slight gains over unaligned results.  
In Table 4, it appears that the results correspond to the additive combination method. Including this information in the legend would be helpful. Additionally, could results for compound phrases using word2vec vectors be provided?  
The intuition behind the FREQ baseline is unclear. Why would frequent compounds tend to be compositional? This suggests a potential bias in the dataset.  
---