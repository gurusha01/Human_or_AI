The paper introduces a positive-only projection (PoP) word embedding technique, which is a random projection method employing a random projection matrix with a positive expected value. The authors claim that this enables the use of PPMI, which is otherwise not feasible with a zero-expected-value matrix, and that being a random projection method, their approach offers computational efficiency.
My primary concern with this paper lies in its lack of clarity. Specifically:
1. I was unable to discern the fundamental distinction between the proposed method and existing random projection techniques. Consequently, I could not fully grasp how (or whether) the claimed advantages are achieved.
2. The paper's arguments, starting from the introduction, are difficult to follow.
3. Several claims in the paper lack adequate support:
   - Line 114: The sentence beginning with "in addition"  
   - Line 137: The sentence beginning with "Since"  
   - Line 154: The sentence beginning with "thus"  
4. Although I have experience in vector space modeling (as do many in the field), I am not a specialist in random projections and have not applied them in my research. The paper did not provide sufficient context or explanation to make the reasoning behind this research direction accessible. I believe a paper should be self-contained and comprehensible to readers with general expertise in the field.
5. The paper contains numerous grammatical and stylistic errors (e.g., Line 86: "To a large extend," Line 142: "such PPMI").
Additionally, I find it problematic that the evaluation is conducted solely on the MEN dataset. There are several standard benchmarks (e.g., MEN, WordSim, SimLex, among others), and for a novel method, evaluating on only one dataset seems insufficient unless a strong justification is provided.
I recommend that the authors significantly enhance the clarity and presentation of the paper and consider resubmitting to a different conference after addressing these issues.