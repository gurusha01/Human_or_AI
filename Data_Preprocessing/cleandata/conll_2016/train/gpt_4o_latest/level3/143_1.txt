Review of the Paper
Summary and Contributions
This paper introduces four methods for estimating multilingual word embeddings and proposes a novel evaluation metric, multiQVEC-CCA, which addresses limitations in prior intrinsic evaluation methods. The primary contributions of the paper are as follows:
1. Estimation Methods for Multilingual Embeddings: The paper presents two dictionary-based methods, multiCluster and multiCCA, which do not require parallel corpora. MultiCluster creates multilingual clusters using dictionaries and derives embeddings for these clusters, while multiCCA extends bilingual CCA embeddings to a multilingual setting using English as an anchor space. Additionally, the paper adapts Luong et al.'s bilingual embedding method (multiSkip) and discusses the translation-invariance approach, which aligns word embeddings using low-rank decomposition of word PMI matrices.
2. Evaluation Metrics: The authors propose multiQVEC and multiQVEC-CCA, which extend the monolingual QVEC metric to multilingual embeddings. MultiQVEC-CCA addresses theoretical shortcomings of QVEC, such as invariance to linear transformations and normalization across embedding dimensions, and demonstrates better correlation with downstream tasks like text categorization and dependency parsing.
3. Web Portal for Evaluation: The paper introduces a web portal that provides a suite of evaluation tasks for multilingual embeddings, facilitating reproducibility and further research in this area.
Strengths
1. Novel Evaluation Metric: The introduction of multiQVEC-CCA is a significant contribution, as it improves upon existing intrinsic evaluation methods and shows strong correlation with downstream tasks. This is a critical step towards standardizing evaluation practices for multilingual embeddings.
2. Scalability to Many Languages: The dictionary-based methods (multiCluster and multiCCA) are scalable to a large number of languages (59 in this study) and do not rely on parallel corpora, making them applicable in resource-constrained settings.
3. Comprehensive Evaluation: The paper evaluates embeddings using both intrinsic and extrinsic metrics, providing a holistic view of the performance of the proposed methods. The correlation analysis between intrinsic and extrinsic metrics is particularly insightful.
4. Open-Source Contribution: The development of a web portal and the release of resources (data, embeddings, and evaluation tools) demonstrate a commitment to reproducibility and community engagement.
Weaknesses
1. Lack of Novelty in Translation-Invariance: The translation-invariance approach appears to be heavily based on Gardner et al.'s prior work, and the novelty of its adaptation to multilingual embeddings is not clearly articulated. This diminishes its contribution relative to the other methods.
2. Coverage Issues in Evaluation: The evaluation results are sometimes confounded by differences in coverage across methods, particularly in intrinsic metrics. While the authors attempt to address this by reporting coverage percentages, the impact of these differences on the reported scores remains unclear.
3. Inconsistent Results: The performance of the proposed methods is inconsistent across evaluation metrics. For example, multiCluster performs poorly on intrinsic metrics but surprisingly well on extrinsic tasks like dependency parsing. The reasons for these discrepancies are not adequately explored.
4. Limited Exploration of Alternatives: The paper does not investigate the use of real multilingual dictionaries (e.g., curated lexicons) instead of dictionaries extracted from parallel corpora or Google Translate. This could have provided additional insights into the robustness of the proposed methods.
Questions to Authors
1. What is the performance loss when fixing word embeddings in dependency parsing, and how does this compare to using random embeddings in the LSTM stack parser?
2. Is Table 1 an average over the 17 embeddings described in Section 5.1? If so, why were these specific embeddings chosen for correlation analysis?
3. Are there advantages to using multiSkip over bilingual embeddings combined with multiCCA, given its consistently lower performance in evaluations?
4. Did the authors explore using curated multilingual dictionaries instead of those extracted from parallel corpora or Google Translate? If not, what are the anticipated challenges or limitations?
Recommendation
While the paper makes significant contributions in terms of evaluation metrics and scalability of multilingual embeddings, the lack of clarity regarding the novelty of certain methods and the inconsistent results across metrics are notable weaknesses. I recommend acceptance with minor revisions, contingent on addressing the questions and clarifying the novelty of the translation-invariance approach.