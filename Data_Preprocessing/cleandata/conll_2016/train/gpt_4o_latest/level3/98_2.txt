Review of the Paper
Summary and Contributions
This paper evaluates a minimally supervised dependency parser, based on the Dependency Model with Valence (DMV), against delexicalized transfer parsers across 32 Universal Dependencies (UD) v1.2 treebanks. The primary contribution of the paper is the empirical analysis of incorporating universal grammatical rules into an unsupervised parser through manually set prior probabilities. The authors also experiment with learning these priors from other treebanks, offering a middle ground between unsupervised and supervised parsing. While the minimally supervised parser underperforms on average compared to delexicalized parsers, it demonstrates superior performance on non-Indo-European languages, which often lack annotated treebanks. This insight is valuable for parsing low-resource languages.
Strengths
1. Focus on Low-Resource Languages: The paper highlights the potential of minimally supervised parsers for non-Indo-European languages, which are typically underrepresented in treebank resources. This is a significant contribution to the field of multilingual parsing.
2. Empirical Evaluation Across Diverse Languages: The study evaluates the proposed approach on a wide range of languages, providing a comprehensive analysis of its strengths and weaknesses. The inclusion of 32 languages from various families strengthens the generalizability of the findings.
3. Comparison of Supervision Levels: By testing fully unsupervised, minimally supervised (manual and learned priors), and delexicalized parsers, the paper provides a nuanced understanding of how different levels of supervision affect parsing performance.
Weaknesses
1. Unlabeled Parsing Limitation: The paper focuses solely on unlabeled parsing, which is a significant limitation given that labeled dependencies are central to the UD framework. Incorporating labeled parsing would have provided a more complete evaluation of the proposed method.
2. Lack of Clarity on Prior Probabilities: The process of setting prior probabilities is insufficiently detailed. The paper does not explain the rationale behind the manually set priors, the universal grammar they encode, or whether alternative configurations were tested.
3. Insufficient Analysis of Non-Indo-European Results: While the claim that the minimally supervised parser performs better on non-Indo-European languages is intriguing, the paper lacks an in-depth analysis of why this is the case. For example, it does not explore which dependency types are handled better or how linguistic properties influence performance.
4. Comparison Bias: The comparison with delexicalized transfer parsers appears biased due to constraints such as limiting training data to 10,000 tokens and suboptimal tuning of the transfer parsers. These factors may have artificially lowered the performance of the baseline methods.
Questions to Authors
1. Why was labeled parsing not considered, given its importance in the UD framework? Could the proposed method be extended to labeled dependencies?
2. How were the manually set prior probabilities determined? Were alternative configurations tested, and if so, what were the results?
3. Can you provide a more detailed analysis of the parser's performance on non-Indo-European languages? For example, which dependency types or linguistic features contributed to its success?
Recommendation
While the paper provides valuable insights into minimally supervised parsing and its application to low-resource languages, the lack of labeled parsing, insufficient clarity on prior probabilities, and limited analysis of key claims weaken its overall contribution. I recommend acceptance only if the authors address the concerns regarding labeled parsing and provide additional analysis of the non-Indo-European results during the author response period.