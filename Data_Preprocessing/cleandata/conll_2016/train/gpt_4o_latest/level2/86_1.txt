Review of the Paper
Summary and Contributions  
This paper introduces two sentiment analysis tools, App2Check and Tweet2Check, designed for app reviews and tweets in both Italian and English. The authors claim that these tools, based on supervised learning techniques, outperform 19 state-of-the-art research tools and commercial systems in terms of accuracy and macro-F1 scores. The primary contributions of the paper are:  
1. The development of App2Check and Tweet2Check, which achieve superior performance compared to existing tools on app reviews and tweets, including surpassing the theoretical human agreement benchmark of 80% accuracy in some cases.  
2. The introduction of new benchmark datasets for app reviews in Italian and English, which are made available for the research community.  
3. A comprehensive evaluation of sentiment analysis tools, highlighting the challenges of neutral sentiment detection and domain-specific performance.  
Strengths  
1. Performance Superiority: The experimental results convincingly demonstrate that App2Check and Tweet2Check outperform existing tools on multiple datasets, especially for app reviews in both Italian and English. The tools achieve high accuracy and macro-F1 scores, which are critical metrics for sentiment analysis.  
2. Domain-Specific Adaptability: The tools' ability to adapt to specific domains through retraining is a significant advantage. This feature is particularly useful for applications requiring high accuracy in niche areas, such as politics or product reviews.  
3. Benchmark Contribution: The authors provide new benchmark datasets for app reviews, which are a valuable addition to the research community and enhance the reproducibility of the experiments.  
4. Comprehensive Evaluation: The paper includes a detailed comparison with 19 state-of-the-art tools, offering a thorough analysis of strengths and weaknesses across different datasets and languages.  
Weaknesses  
1. Lack of Methodological Transparency: The paper does not provide sufficient details about the supervised learning techniques and algorithms used in App2Check and Tweet2Check, citing non-disclosure restrictions. This limits the reproducibility and scientific rigor of the work.  
2. Neutral Sentiment Detection: While the tools perform well overall, their performance on neutral sentiment detection remains weak, as evidenced by low F1(x) scores. This limitation is acknowledged but not adequately addressed in the paper.  
3. Limited Novelty: While the tools achieve impressive results, the underlying approach (supervised learning for sentiment analysis) is not novel. The paper does not introduce significant methodological innovations beyond the application of existing techniques.  
4. Overemphasis on Performance Metrics: The paper heavily focuses on quantitative results without providing qualitative insights into why the tools outperform competitors or how they handle specific linguistic challenges in Italian and English.  
Questions to Authors  
1. Can you provide more details about the supervised learning techniques and feature engineering used in App2Check and Tweet2Check?  
2. How do the tools handle domain-specific linguistic nuances, such as sarcasm or idiomatic expressions, particularly in Italian?  
3. What steps could be taken to improve the detection of neutral sentiments, given their importance in certain applications?  
Conclusion  
Overall, the paper presents a strong case for the practical utility of App2Check and Tweet2Check in sentiment analysis, particularly for app reviews and tweets. While the lack of methodological transparency and limited novelty are concerns, the tools' performance and the contribution of new benchmarks make this work a valuable addition to the field. I recommend acceptance with minor revisions to address the methodological gaps and provide more qualitative analysis.