Review
Summary and Contributions
This paper introduces a novel approach to sentiment analysis (SA) by augmenting traditional linguistic features with cognitive features derived from eye-movement patterns of human annotators. The authors claim that these cognitive features enable sentiment analyzers to better handle complex constructs such as irony, sarcasm, and thwarted expectations. The paper demonstrates a statistically significant improvement in F-scores (3.7% and 9.3% on two datasets) over systems that use only traditional features. The key contributions of this work are:  
1. Integration of Cognitive Features: The paper is the first to use eye-movement data for SA, providing a new dimension to feature engineering in NLP.  
2. Feature Significance Analysis: The authors demonstrate the importance of gaze-based features, particularly for complex constructs like sarcasm, through a held-out dataset and statistical tests.  
3. Feasibility Discussion: The paper addresses practical concerns regarding the availability of eye-tracking technology and its integration into real-world applications, such as e-commerce and online learning platforms.
Strengths
1. Novelty: The use of cognitive features derived from eye-tracking data is a significant innovation in sentiment analysis. The paper provides a compelling case for how these features can complement traditional linguistic features, especially for nuanced text.  
2. Empirical Validation: The experiments are well-designed, with results showing consistent improvements across multiple classifiers and datasets. The use of a held-out dataset to validate the efficacy of cognitive features for complex constructs is particularly commendable.  
3. Feature Engineering: The paper introduces a rich set of gaze-based features, including both basic and graph-based features, which are well-motivated and grounded in psycholinguistic literature.  
4. Practical Considerations: The discussion on the feasibility of using mobile eye-trackers and potential applications adds value, addressing concerns about the real-world applicability of the approach.  
Weaknesses
1. Limited Scope of Datasets: The datasets used are relatively small (994 and 1059 snippets), which raises concerns about the generalizability of the results. Larger and more diverse datasets would strengthen the claims.  
2. Dependency on Eye-Tracking Hardware: While the authors discuss the feasibility of mobile eye-trackers, the approach is still constrained by the availability of such technology, which limits its immediate applicability.  
3. Comparison with Deep Learning Models: The paper explicitly excludes state-of-the-art deep learning models, such as those based on transformers, from its experiments. While the authors justify this by focusing on feature-based approaches, a comparison with deep learning methods would provide a stronger baseline.  
4. Error Analysis: The error analysis is relatively shallow and does not provide detailed insights into specific failure cases or how they might be addressed.  
Questions to Authors
1. How do you envision scaling this approach to larger datasets or real-world applications where eye-tracking data may not be readily available?  
2. Have you considered combining gaze-based features with deep learning models, such as transformers, to further improve performance?  
3. Can you provide more details on the computational overhead introduced by gaze-based features, particularly for real-time applications?  
Overall Assessment
This paper presents a novel and promising direction for sentiment analysis by integrating cognitive features derived from eye-tracking data. The results are compelling, and the contributions are significant, particularly in addressing complex linguistic constructs. However, the approach's reliance on specialized hardware and the limited scope of datasets are notable limitations. Addressing these concerns in future work could make this approach more impactful and widely applicable.  
Recommendation: Accept with minor revisions.