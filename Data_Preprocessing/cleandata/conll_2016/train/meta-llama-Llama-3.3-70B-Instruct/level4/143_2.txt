This paper presents two novel dictionary-based approaches for estimating multilingual word embeddings, namely MultiCluster, which is grounded in clustering, and MultiCCA, which is based on canonical correlation analysis. Additionally, the authors propose a supersense similarity measure that enhances QVEC by replacing its correlation component with CCA and incorporating multilingual evaluation. The evaluation of these methods is conducted across a diverse range of tasks using a web portal developed by the authors, demonstrating that the proposed representation methods outperform two baseline methods in certain cases.
The paper is well-written and reflects a significant amount of work. The representation-learning and evaluation methods presented are timely and relevant. The authors are commended for their meticulous documentation.
However, upon reviewing the paper, it appears that the breadth of coverage may come at the expense of depth. A more thorough discussion of the results would be beneficial, particularly regarding the conflicting outcomes for MultiCluster between the 59- and 12-language setups, as well as the impact of estimation parameters and decisions in MultiCluster and CCA. While the paper holds high practical value for the research community, including the improved QVEC measure and the web portal, it does not significantly advance our understanding of the research questions addressed.
Some specific remarks are noted below.
Including the correlation results (Table 1) for monolingual QVEC and QVEC-CCA would provide a more comprehensive comparison, given that QVEC-CCA is positioned as an improvement over QVEC.
Minor issues include the description of cross-lingual word similarity datasets, which could be clarified to indicate that they are of the same nature but in different languages. Additionally, equations on page 3 exceed the column margin.
There is an inconsistency in the citation of the MultiSkip baseline, with different references provided in different sections. Clarification on the correspondence between these works would be helpful.
While the paper adequately cites related works, additional relevant studies could be included, such as those on multilingual embeddings and clustering, and multilingual training of embeddings for improved source-language embeddings. Examples include works by Chandar et al., Hill et al., Lu et al., Faruqui et al., Suster et al., Guo et al., and Diab et al.