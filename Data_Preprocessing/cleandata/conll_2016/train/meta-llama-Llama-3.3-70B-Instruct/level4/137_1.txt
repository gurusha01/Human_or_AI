Review - General Comments
=============================
This paper presents experimental results on predicting the compositionality of English compounds, utilizing a dataset of 90 compounds with human-ranked compositionality scores ranging from 1 to 5. The experiments involve calculating cosine similarity between compound vectors and compositions of component vectors, with evaluation based on Spearman correlation with human judgments. The study explores variations in vector types, including neural embeddings and syntactic-context count vectors, as well as the use of aligned vectors to capture shifts between dependent and head components.
The findings indicate that syntactic-context count vectors outperform embeddings, while the use of aligned vectors alone yields inferior results compared to unmodified vectors. A highly tuned combination of aligned and unaligned vectors achieves a slight improvement. However, the paper's form and substance raise several concerns. The introduction is well-written, but other sections, such as 5.1, are difficult to follow despite the underlying notions being relatively straightforward. Rephrasing with running examples could enhance readability.
Regarding the substance, concerns include the limited innovation compared to Reddy et al., with the use of aligned vectors being the primary novelty, albeit previously published by the authors. The dataset is small and inadequately described, with frequency ranges potentially impacting results. The improvements using aligned vectors are marginal, and the findings appear fragile due to the small dataset and unclear compound selection process.
More Detailed Comments/Questions
================================
Section 3
---------
The introduction of the term "packed anchored tree" is unclear, seeming to refer to a straightforward extraction of paths between lexical items in a dependency tree, similar to traditional syntactic distributional representations. The term "tree" is also unclear, and the concept of "elementary APTs" (Section 5.1) requires further explanation. Table 2 appears to omit features of order more than 3, which may be related to the elimination of incompatible types, but an example would be helpful for clarification.
Section 4
---------
The selection process for the 90 compounds in the Reddy et al. dataset is unclear, and frequency ranges for compounds and components are not provided. The number of judgments per compound and potential issues with ranking compounds based on compositionality scores are also not addressed. The use of "constituent" to refer to a component of an N-N sequence may be confusing, as it can also refer to a phrase or syntagm. The intuition that a constituent used literally within a phrase is likely to share co-occurrences with the compound is true only if the constituent is the head of the phrase.
Section 5
---------
The explanation of the elementary representation for a compound phrase constituent could be clarified with a running example. The term "compound phrase token" is unclear, and it is uncertain whether it refers to the merged components of the compound. The concept of "shifted PMI" and its relation to equation (3) requires further explanation.
Section 5.1
---------
The definition of "elementary APTs" as a triplet of target word, dependency path, and other word is unclear, and the name may be confusing. The sentence regarding the removal of features with low positive PMI appears contradictory and requires clarification. The expectation of little overlap between unaligned APTs is unclear, and the potential overlap in the case of the NMOD relation between components is puzzling. The use of higher-order dependency features throughout the paper, only to switch to first-order features when measuring similarity between composed and observed phrasal vectors, is unclear and requires explanation.
Section 6
---------
The claim that smoothing the PPMI calculation with a value of Î± = 0.75 has a small positive effect is not evident from Table 3. The optimal values for h and q in equations 8 and 9 are not provided, making it difficult to estimate the contribution of hybridity to the results. The results in Table 4 appear to correspond to the add combination, and including this information in the legend would be helpful. The results from word2vec vectors for compound phrases are not provided, and the intuition behind the FREQ baseline is unclear, potentially indicating a bias in the dataset.