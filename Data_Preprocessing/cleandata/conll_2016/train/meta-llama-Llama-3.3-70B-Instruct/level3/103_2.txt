This paper proposes a novel approach to dependency parsing by comparing delexicalized transfer and minimally supervised parsing techniques on 32 languages from the Universal Dependencies treebank collection. The main contributions of this work are: 
1. The introduction of a minimally supervised parser that uses external prior probabilities to improve parsing accuracy, 
2. The comparison of delexicalized transfer parsing methods with minimally supervised parsing methods, and 
3. The evaluation of these methods on a large number of languages from different language families.
The strengths of this paper include: 
1. The proposed minimally supervised parser achieves competitive results with state-of-the-art delexicalized transfer parsers, especially for non-Indo-European languages, 
2. The use of Universal Dependencies treebank collection allows for a unified evaluation of parsing methods across multiple languages, and 
3. The paper provides a thorough comparison of different parsing methods, including delexicalized transfer parsers and unsupervised dependency parsers with external prior probabilities.
The weaknesses of this paper include: 
1. The lack of clear explanation for why the proposed method should work, particularly in terms of the relationship between the external prior probabilities and the parsing accuracy, 
2. The paper could benefit from more detailed descriptions of the techniques used, particularly in Section 3, where the use of passive voice makes it difficult to follow the design choices, and 
3. The results could be strengthened by providing significance tests, such as those in Table 1, to demonstrate the statistical significance of the differences between the parsing methods.
Questions to authors: 
1. Can you provide more insight into why the minimally supervised parser performs better on non-Indo-European languages? 
2. How do the external prior probabilities affect the parsing accuracy, and are there any plans to investigate other types of prior probabilities? 
3. Are there any plans to extend this work to other NLP tasks, such as part-of-speech tagging or semantic role labeling?