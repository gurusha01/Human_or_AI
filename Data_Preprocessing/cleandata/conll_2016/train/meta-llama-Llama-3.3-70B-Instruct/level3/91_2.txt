This paper presents a novel approach to cross-lingual named entity recognition (NER) using a cross-lingual wikifier to disambiguate words and phrases to the English Wikipedia. The proposed model is language-independent and can be applied to all languages in Wikipedia, requiring only a multilingual Wikipedia dump.
Summary of the Paper:
The paper introduces a cross-lingual NER model that uses a wikifier to ground words and phrases in non-English languages to the English Wikipedia, providing language-independent features for NER. The model is evaluated on a wide range of languages, including high-resource languages (English, Spanish, German, and Dutch) and low-resource languages (Turkish, Tagalog, Yoruba, Bengali, and Tamil). The results show significant improvements over strong baselines, demonstrating the effectiveness of the proposed approach.
Main Contributions:
1. Cross-lingual wikifier features: The paper proposes a novel approach to generating language-independent features for NER using a cross-lingual wikifier.
2. Language-independent NER model: The proposed model can be applied to all languages in Wikipedia, requiring only a multilingual Wikipedia dump.
3. Extensive evaluation: The paper evaluates the proposed model on a wide range of languages, including high-resource and low-resource languages.
Strengths:
1. Effective use of wikifier features: The paper demonstrates the effectiveness of using wikifier features for NER, especially in low-resource languages.
2. Language independence: The proposed model is language-independent, making it applicable to a wide range of languages.
3. Extensive evaluation: The paper provides a thorough evaluation of the proposed model on various languages, demonstrating its effectiveness.
Weaknesses:
1. Limited analysis of wikifier features: The paper could provide a more detailed analysis of the wikifier features and their impact on NER performance.
2. Comparison to existing work: The paper could provide a more comprehensive comparison to existing work on cross-lingual NER, including parallel projection and generating training data from Wikipedia automatically.
3. Future work: The paper mentions potential future work, such as incorporating other techniques for multilingual NER, but could provide more concrete directions for future research.
Questions to Authors:
1. How do the wikifier features compare to other language-independent features, such as word embeddings or lexical features?
2. Can the proposed model be applied to other NLP tasks, such as part-of-speech tagging or dependency parsing?
3. How does the size of the Wikipedia dump impact the performance of the proposed model, and are there any plans to explore the use of other knowledge bases or resources?