This paper proposes a language-independent model for cross-lingual Named Entity Recognition (NER) using a cross-lingual wikifier to disambiguate every n-gram. The model works on all languages in Wikipedia and requires only a Wikipedia dump. The authors evaluate their model on a wide range of languages in both monolingual and cross-lingual settings, showing significant improvements over strong baselines.
The main contributions of this work are:
1. The proposal of a language-independent model for cross-lingual NER using a cross-lingual wikifier.
2. The demonstration of the effectiveness of the model on a wide range of languages, including low-resource languages.
3. The analysis of the quality of wikifier features and their dependence on Wikipedia size.
The strengths of this paper are:
1. The authors address a significant problem in NLP, which is the lack of annotated data for low-resource languages.
2. The proposed model is language-independent, making it applicable to all languages in Wikipedia.
3. The authors provide a thorough analysis of the quality of wikifier features and their dependence on Wikipedia size.
4. The model outperforms strong baselines on several languages, including low-resource languages.
The weaknesses of this paper are:
1. The paper may be artificial for real low-resource languages, and this limitation should be acknowledged in the writeup to avoid overselling the method.
2. The related work discussion should be expanded to include relevant lines of work in annotation projection for extremely low-resource languages.
3. The paper could benefit from a more detailed discussion of the limitations of the model and potential avenues for future work.
Overall, this paper is a nice contribution to the field of NLP, and the proposed model has the potential to be useful for low-resource languages. However, the authors should be careful not to oversell the method and should provide a clear discussion of the limitations and potential avenues for future work.
Questions to authors:
1. Can you provide more details on how the cross-lingual wikifier is trained and how it handles ambiguity?
2. How do you plan to address the limitation of the model for real low-resource languages?
3. Can you provide more information on the datasets used for evaluation and how they were collected?
4. Have you considered using other techniques for multilingual NER, such as parallel projection and generating training data from Wikipedia automatically? If so, how do you plan to integrate them into your model?