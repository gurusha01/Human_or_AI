This paper proposes a neural-styled topic model that extends word2vec to learn document embeddings. However, the paper lacks empirical evaluation to assess its true worth, and the model's effectiveness cannot be determined without comparison to standard or neural topic models through supervised document categorization or direct evaluation on a dataset with document similarity annotations.
The paper's main contributions are the proposal of a transition-based broad-coverage semantic parser (BSP) that supports multiple parents, non-terminal nodes, and discontinuous units, and the experimentation with UCCA parsing. The BSP parser obtains comparable F-scores to existing parsers, such as MaltParser and UPARSE, in terms of primary edges, but is also able to predict some remote edges.
One of the strengths of the paper is the release of the code, which is appreciated. However, publishing the GitHub link compromises anonymity, which could lead to outright rejection of the paper. Another strength is the experimentation with UCCA parsing, which is a novel contribution.
However, there are several weaknesses in the paper. The selection of examples in figures appears to be cherry-picked, and the process of selecting them is unclear. The method of identifying "tokens" using SpaCy is unclear, and the use of word2vec pre-trained embeddings raises questions about handling multiword terms. The model's ability to handle out-of-vocabulary (OOV) terms is unclear, and the updating of word2vec token embeddings may make OOV embeddings non-comparable.
The paper should compare itself to other neural topic models, such as those proposed by Cao et al., Nguyen et al., and Shamanta et al. Additionally, there are several low-level issues, including grammatical errors, inconsistent reference formatting, and unclear terminology.
To improve the paper, the authors should provide more empirical evaluation, compare their model to other neural topic models, and address the low-level issues. They should also clarify the selection of examples, the method of identifying tokens, and the handling of OOV terms.
Questions to the authors include: How do you plan to address the lack of empirical evaluation? How do you compare your model to other neural topic models? How do you handle OOV terms and multiword terms? How do you plan to improve the clarity and consistency of the paper? 
In terms of contributions, the paper makes the following contributions: 
1. Proposal of a transition-based broad-coverage semantic parser (BSP) that supports multiple parents, non-terminal nodes, and discontinuous units.
2. Experimentation with UCCA parsing, which is a novel contribution.
3. Release of the code, which is appreciated.
The strengths of the paper are: 
1. The proposal of a novel parser that supports multiple parents, non-terminal nodes, and discontinuous units.
2. The experimentation with UCCA parsing, which is a novel contribution.
3. The release of the code, which is appreciated.
The weaknesses of the paper are: 
1. Lack of empirical evaluation to assess the true worth of the model.
2. Unclear selection of examples in figures and unclear process of selecting them.
3. Unclear method of identifying "tokens" using SpaCy and unclear handling of multiword terms.
4. Unclear ability to handle out-of-vocabulary (OOV) terms and unclear updating of word2vec token embeddings.
5. Lack of comparison to other neural topic models.
6. Several low-level issues, including grammatical errors, inconsistent reference formatting, and unclear terminology.