Summary of the Paper
The paper presents a novel model called lda2vec, which combines the strengths of distributed word representations and topic models to learn interpretable document representations. The model extends the Skipgram Negative-Sampling (SGNS) objective to incorporate document-wide feature vectors and simultaneously learn continuous document weights loading onto topic vectors. The authors demonstrate the effectiveness of lda2vec on two datasets: Twenty Newsgroups and Hacker News comments.
Main Contributions
1. Joint learning of word, topic, and document vectors: lda2vec learns a common representation space that preserves semantic regularities between word vectors while yielding sparse and interpretable document-to-topic proportions.
2. Interpretable document representations: The model produces sparse, interpretable document mixtures through a non-negative simplex constraint, allowing for easy interpretation of document topics.
3. Simple implementation in automatic differentiation frameworks: lda2vec can be easily incorporated into existing frameworks, making it a practical solution for unsupervised document representation learning.
Strengths
1. Effective topic modeling: lda2vec discovers coherent topics in both datasets, with high mean topic coherences in the Twenty Newsgroups corpus.
2. Learning of linear relationships between words: The model learns semantic relationships between tokens, enabling it to solve word analogies in the specialized vocabulary of the Hacker News corpus.
3. Simple and efficient implementation: lda2vec can be easily implemented in automatic differentiation frameworks, making it a practical solution for unsupervised document representation learning.
Weaknesses
1. Limited evaluation metrics: The paper primarily relies on topic coherence as an evaluation metric, which may not capture all aspects of the model's performance.
2. Lack of comparison to other models: The paper does not provide a comprehensive comparison to other topic modeling or document representation learning methods.
3. Dependence on hyperparameter tuning: The model's performance may be sensitive to hyperparameter tuning, which could limit its applicability in practice.
Questions to Authors
1. How do the authors plan to address the limited evaluation metrics and provide a more comprehensive comparison to other models?
2. Can the authors provide more insight into the hyperparameter tuning process and its impact on the model's performance?
3. How do the authors envision lda2vec being applied in real-world scenarios, and what potential applications do they see for this model?