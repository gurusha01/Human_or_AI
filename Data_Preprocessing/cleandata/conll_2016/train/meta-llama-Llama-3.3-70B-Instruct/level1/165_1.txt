This paper presents a novel approach to automatically discovering correspondences between words from two or more languages using the Minimum Description Length (MDL) principle. The authors propose an efficient algorithm for inferring statistically significant correspondence rules directly from data, without imposing arbitrary assumptions on the distribution or shape of correspondences.
The main contributions of this work are:
1. MDL-based approach: The authors introduce an MDL-based approach to discovering correspondences, which provides a statistically well-founded method for identifying the best model for given data.
2. Efficient algorithm: The authors propose an efficient algorithm for inferring correspondence rules, which can handle multiple languages and provides a deterministic solution.
3. Quantification of linguistic similarity: The authors demonstrate that their approach can quantify linguistic similarity not only between pairs of languages but also between all subsets of analyzed languages.
The strengths of this paper are:
1. Novel approach: The MDL-based approach is a new and innovative method for discovering correspondences, which has the potential to improve upon existing statistical approaches.
2. Efficient algorithm: The proposed algorithm is efficient and can handle multiple languages, making it a practical solution for linguistic analysis.
3. Quantification of linguistic similarity: The approach provides a quantitative measure of linguistic similarity, which can be useful for linguistic research and applications.
4. Deterministic solution: The algorithm provides a deterministic solution, which can be beneficial for linguists who want to input linguistic knowledge and obtain reliable results.
The weaknesses of this paper are:
1. Computational complexity: The algorithm has a high computational complexity, which may limit its applicability to large datasets or many languages.
2. Data quality: The approach relies on high-quality data, which may not always be available, especially for under-resourced languages.
3. Overfitting: The approach may suffer from overfitting, especially when dealing with small datasets or noisy data.
4. Lack of linguistic evaluation: The paper lacks a thorough linguistic evaluation of the discovered correspondences, which is essential to validate the approach.
Questions to authors:
1. How do the authors plan to address the computational complexity of the algorithm to make it more scalable?
2. How do the authors plan to evaluate the linguistic quality of the discovered correspondences, and what metrics will they use to measure their accuracy?
3. Can the authors provide more details on how the approach can be used for linguistic research and applications, such as language teaching or machine translation?