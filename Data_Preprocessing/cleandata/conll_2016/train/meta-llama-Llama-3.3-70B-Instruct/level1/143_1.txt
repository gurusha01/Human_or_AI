This paper introduces two novel methods, multiCluster and multiCCA, for estimating multilingual word embeddings in a shared vector space. The authors also propose a new evaluation metric, multiQVEC-CCA, which addresses the limitations of the existing QVEC metric. The paper makes the following contributions:
1. Novel estimation methods: The authors propose two dictionary-based methods, multiCluster and multiCCA, for estimating multilingual word embeddings. These methods use monolingual data and bilingual dictionaries to learn embeddings that capture semantic similarity within and across languages.
2. Improved evaluation metric: The authors propose multiQVEC-CCA, an improved evaluation metric that addresses the limitations of QVEC. multiQVEC-CCA uses canonical correlation analysis to measure the correlation between the embedding matrix and a linguistic matrix, providing a more robust and informative evaluation metric.
3. Web portal for evaluation: The authors create a web portal that allows researchers to upload their multilingual embeddings and evaluate them on a suite of evaluation metrics, facilitating comparison and replication of results.
The strengths of this paper include:
1. Novel and effective estimation methods: The proposed methods, multiCluster and multiCCA, demonstrate promising results in estimating multilingual word embeddings, especially when trained on a large number of languages.
2. Improved evaluation metric: multiQVEC-CCA shows better correlation with downstream tasks compared to existing intrinsic methods, providing a more reliable evaluation metric for multilingual word embeddings.
3. Facilitation of future research: The web portal created by the authors will facilitate future research in multilingual word embeddings by providing a standardized platform for evaluation and comparison of different methods.
The weaknesses of this paper include:
1. Limited comparison to existing methods: The paper could benefit from a more comprehensive comparison to existing methods for estimating multilingual word embeddings, including methods that use parallel data.
2. Dependence on bilingual dictionaries: The proposed methods rely on the availability of high-quality bilingual dictionaries, which may not be available for all language pairs.
3. Computational complexity: The paper could provide more details on the computational complexity of the proposed methods, especially for large-scale datasets.
Questions to authors:
1. How do the proposed methods perform when compared to existing methods that use parallel data, such as multiSkip?
2. Can the authors provide more details on the construction of the bilingual dictionaries used in the experiments?
3. How do the proposed methods handle out-of-vocabulary words, and what are the implications for downstream tasks?