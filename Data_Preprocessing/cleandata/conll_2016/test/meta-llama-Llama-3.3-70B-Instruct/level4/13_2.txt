This manuscript proposes a novel approach to event entity linking by leveraging sentential features extracted from Convolutional Neural Networks (CNNs) instead of relying on external knowledge sources. The authors develop a two-stage model, where the first component learns a representation for event mentions and the second component calculates a coreference score between two event entity mentions.
The paper is well-organized, clearly presented, and easy to understand. The analysis of argument sharing between event coreferences in the ACE corpus is noteworthy, and the discussion on the impact of dataset size is a compelling motivation for creating the ACE++ dataset. However, several significant concerns need to be addressed:
- The authors do not provide a clear motivation for using CNNs to generate mention representations, nor do they analyze the advantages and disadvantages of this choice. A comparison with other architectures, such as Recurrent Neural Networks (RNNs), is also lacking. Given the modest improvement of 2-3 points in F1 score over state-of-the-art models, more evidence is needed to demonstrate the superiority of this architecture.
- The novelty of using sentential features for event linking is not clearly established, as employing CNNs for classification tasks is not a new concept. The authors should explicitly highlight the innovative aspects of their approach and compare it to existing continuous space methods for event linking. The selection of methods in Table 3 is not comprehensive enough.
- The collection process for the ACE++ dataset is not described, which is a significant concern. The limited number of event types in the ACE dataset makes it constrained and biased. It is essential to know what event types are covered in ACE++ to support the claim that the proposed approach is more robust. To enable meaningful comparisons in the future, the authors should consider making the ACE++ dataset publicly available.
Some minor issues that require attention:
- It would be beneficial to include the performance of the model without gold references in Table 3 for a more comprehensive evaluation.
- Exploring the potential of augmenting the model with a vanilla coreference resolution system could provide valuable insights. For instance, the CoreNLP system can be used to link 'It' to 'bombing' in the example mentioned in line 687, which could be leveraged to create a stronger event entity linking baseline.
- Given the relatively small size of the ACE dataset, it is crucial to test the model on other available resources to demonstrate its robustness. This also motivates the need to work on entity and event coreference simultaneously. Testing on EventCorefBank in parallel with ACE is essential to ensure the model's effectiveness.
- The effectiveness of pairwise features, as shown in Table 5, suggests that feature engineering is still a critical component of developing a competitive model, at least on the scale of the ACE dataset. It would be interesting to know which features were most effective and why the current set was chosen. The authors should report on the feature selection process and any other features that were tried.