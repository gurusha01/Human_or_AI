This paper proposes a novel approach to event coreference resolution, which is the task of identifying coreferential event mentions in a document. The authors design a two-part model that first generates latent-feature representations for individual event mentions using convolutional neural networks, and then learns to make coreference decisions based on these representations and pairwise features.
The main contributions of this work are:
1. The proposal of a neural model for event coreference resolution that does not rely on external semantic features, but instead uses sentential features generated by convolutional neural networks.
2. The achievement of state-of-the-art performance on two datasets, one of which is publicly available.
3. An error analysis that highlights the challenges of the task and provides insights for future research.
The strengths of this paper are:
1. The authors provide a clear and detailed description of their model and its components, making it easy to understand and replicate.
2. The experimental evaluation is thorough and well-designed, with a comparison to state-of-the-art systems and an analysis of the impact of different feature classes and clustering strategies.
3. The error analysis provides valuable insights into the challenges of the task and the limitations of the current model.
The weaknesses of this paper are:
1. The authors do not provide a detailed comparison to other neural models for event coreference resolution, which would be useful to understand the strengths and limitations of their approach.
2. The model relies on pre-trained word embeddings, which may not be available for all languages or domains.
3. The authors do not discuss the potential applications of their model beyond event coreference resolution, which could be an interesting direction for future research.
Questions to authors:
1. How do the authors plan to address the challenge of pronoun resolution, which was identified as a major source of errors in the error analysis?
2. Can the authors provide more details on the hyperparameter tuning process and the sensitivity of the model to different hyperparameter settings?
3. How do the authors plan to extend their model to other languages or domains, where pre-trained word embeddings may not be available?