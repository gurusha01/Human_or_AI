This paper proposes an unsupervised dependency parser, UDP, which utilizes personalized PageRank and a small set of head-dependent rules to parse sentences without requiring any training data. The main contributions of this work are the adaptation of dependency head rules to Universal Dependencies (UD) compliant POS relations, the incorporation of UD restrictions on function words, and the use of personalized PageRank to improve main predicate identification.
The strengths of this paper include its ability to achieve competitive performance on all but two UD languages, its robustness to domain changes, and its simplicity. The use of personalized PageRank and a small set of head-dependent rules allows the parser to be less sensitive to sampling bias and more resilient to domain shifts. The paper also provides a thorough evaluation of the parser on three POS setups and across domains, demonstrating its effectiveness in handling different scenarios.
However, there are some weaknesses to this paper. The experimental setting has some limitations, such as the use of gold POS tags and the lack of comparison to other unsupervised dependency parsers. Additionally, some points in the paper are unclear, such as the generation of position embeddings and the use of left vs right neighbors. The paper could be improved with significance testing for results, comparison to more previous work, and clarification of unclear points.
Some potential questions to the authors include: How does the parser handle multiword expressions, coordination, and proper names? Can the use of personalized PageRank be expanded to directly score potential dependency edges? How does the parser perform on languages with different word orders or grammatical structures? Can the parser be augmented with partial edge labeling to improve its performance?
Overall, this paper presents a novel approach to unsupervised dependency parsing and demonstrates its effectiveness in handling different scenarios. With some improvements and clarifications, this work has the potential to make a significant contribution to the field of natural language processing. 
The main contributions of this work are: 
1. The proposal of an unsupervised dependency parser that requires no training data and estimates adposition direction directly from test data.
2. The adaptation of dependency head rules to Universal Dependencies (UD) compliant POS relations.
3. The incorporation of UD restrictions on function words and the use of personalized PageRank to improve main predicate identification.
The strengths of this paper are: 
1. The parser's ability to achieve competitive performance on all but two UD languages.
2. The parser's robustness to domain changes.
3. The simplicity of the parser and its ability to handle different scenarios.
The weaknesses of this paper are: 
1. The experimental setting has some limitations, such as the use of gold POS tags.
2. The lack of comparison to other unsupervised dependency parsers.
3. Some points in the paper are unclear, such as the generation of position embeddings and the use of left vs right neighbors.