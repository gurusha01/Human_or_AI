This paper presents a model for the task of event entity linking, where they
propose to use sentential features from CNNs in place of external knowledge
sources which earlier methods have used. They train a two-part model: the first
part learns an event mention representation, and the second part learns to
calculate a coreference score given two event entity mentions.
The paper is well-written, well-presented and is easy to follow. I rather like
the analysis done on the ACE corpus regarding the argument sharing between
event coreferences. Furthermore, the analysis on the size impact of the
dataset is a great motivation for creating their ACE++ dataset. However, there
are a few
major issues that need to be addressed:
- The authors fail to motivate and analyze the pros and cons of using CNN for
generating mention representations. It is not discussed why they chose CNN and
there are no comparisons to the other models (e.g., straightforwardly an RNN).
Given that the improvement their model makes according various metrics against
the
state-of-the-art is only 2 or 3 points on F1 score, there needs to be more
evidence that this architecture is indeed superior.
- It is not clear what is novel about the idea of tackling event linking with
sentential features, given that using CNN in this fashion for a classification
task is not new. The authors could explicitly point out and mainly compare to
any existing continuous space methods for event linking. The choice of methods
in Table 3 is not thorough enough.
- There is no information regarding how the ACE++ dataset is collected. A major
issue with the ACE dataset is its limited number of event types, making it too
constrained and biased. It is important to know what event types ACE++ covers.
This can also help support the claim in Section 5.1 that 'other approaches are
strongly tied to the domain where these semantic features are available…our
approach does not depend on resources with restricted…', you need to show
that those earlier methods fail on some dataset that you succeed on. Also,
for enabling any meaningful comparison in future, the authors should think
about making this dataset publicly available.
Some minor issues:
- I would have liked to see the performance of your model without gold
references in Table 3 as well.
- It would be nice to explore how this model can or cannot be augmented with a
vanilla coreference resolution system. For the specific example in line 687,
the off-the-shelf CoreNLP system readily links 'It' to 'bombing', which can be
somehow leveraged in an event entity linking baseline.
- Given the relatively small size of the ACE dataset, I think having a
compelling model requires testing on the other available resources as well.
This further motivates working on entity and event coreference simultaneously.
I also believe that testing on EventCorefBank in parallel with ACE is
essential. 
- Table 5 shows that the pairwise features have been quite effective, which
signals that feature engineering may still be crucial for having a competitive
model (at least on the scale of the ACE dataset). One would wonder which
features were the most effective, and why not report how the current set was
chosen and what else was tried.