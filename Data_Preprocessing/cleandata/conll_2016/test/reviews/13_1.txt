This paper models event linking using CNNs. Given event mentions, the authors
generate vector representations based on word embeddings passed through a CNN
and followed by max-pooling. They also concatenate the resulting
representations with several word embeddings around the mention. Together with
certain pairwise features, they produce a vector of similarities using a
single-layer neural network, and compute a coreference score. 
The model is tested on an ACE dataset and an expanded version with performance
comparable to previous feature-rich systems.
The main contribution of the paper, in my opinion, is in developing a neural
approach for entity linking that combines word embeddings with several
linguistic features. It is interesting to find out that just using the word
embeddings is not sufficient for good performance. Fortunately, the linguistic
features used are limited and do not require manually-crafted external
resources.  
Experimental setting
- It appears that gold trigger words are used rather than predicted ones. The
authors make an argument why this is reasonable, although I still would have
liked to see performance with predicted triggers. This is especially
problematic as one of the competitor systems used predicted triggers, so the
comparison isn't fair. 
- The fact that different papers use different train/test splits is worrisome.
I would encourage the authors to stick to previous splits as much as possible. 
Unclear points
- The numbers indicating that cross-sentential information is needed are
convincing. However, the last statement in the second paragraph (lines 65-70)
was not clear to me.
- Embeddings for positions are said to be generaties "in a way similar to word
embeddings". How exactly? Are they randomly initialized? Are they lexicalized?
It is not clear to me why a relative position next to one word should have the
same embedding as a relative position next to a different word.
- How exactly are left vs right neighbors used to create the representation
(lines 307-311)? Does this only affect the max-pooling operation?
- The word embeddings of one word before and one word after the trigger words
are appended to it. This seems a bit arbitrary. Why one word before and after
and not some other choice?  
- It is not clear how the event-mention representation v_e (line 330) is used?
In the following sections only v{sent+lex} appear to be used, not ve.
- How are pairwise features used in section 3.2? Most features are binary, so I
assume they are encoded as a binary vector, but what about the distance feature
for example? And, are these kept fixed during training?
Other issues and suggestions
- Can the approach be applied to entity coreference resolution as well? This
would allow comparing with more previous work and popular datasets like
OntoNotes. 
- The use of a square function as nonlinearity is interesting. Is it novel? Do
you think it has applicability in other tasks?
- Datasets: one dataset is publicly available, but results are also presented
with ACE++, which is not. Do you have plans to release it? It would help other
researchers compare new methods. At least, it would have been good to see a
comparison to the feature-rich systems also on this dataset.
- Results: some of the numbers reported in the results are quite close.
Significance testing would help substantiating the comparisons.
- Related work: among the work on (entity) coreference resolution, one might
mention the neural network approach by Wiseman et al. (2015)  
Minor issues
- line 143, "that" is redundant. 
- One of the baselines is referred to as "same type" in table 6, but "same
event" in the text (line 670).        
Refs
- Learning Anaphoricity and Antecedent Ranking Features for Coreference
Resolution. Sam Wiseman, Alexander M. Rush, Jason Weston, and Stuart M.
Shieber. ACL 2015.