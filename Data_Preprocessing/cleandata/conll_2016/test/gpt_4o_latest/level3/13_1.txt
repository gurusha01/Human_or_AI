Review of the Paper
Summary and Contributions:
This paper presents a convolutional neural network (CNN)-based model for event coreference resolution, which integrates word embeddings and limited linguistic features to generate event representations and compute coreference scores. The model achieves state-of-the-art performance on the ACE dataset and an expanded ACE++ dataset without relying on external semantic resources, a significant departure from prior feature-rich systems. The authors claim that their approach avoids the dependency on manually crafted resources, making it more adaptable across domains. The paper also introduces an interesting use of a square function as a nonlinearity in the similarity computation, which may have broader applicability. Additionally, the authors provide an error analysis and suggest directions for future research.
The primary contributions of the paper are:
1. A neural approach for event coreference resolution that eliminates the need for external semantic features, relying instead on sentential and pairwise features.
2. State-of-the-art performance on ACE and ACE++ datasets, demonstrating the model's efficacy.
3. A novel use of the square function as a nonlinearity for similarity computation, which could inspire future work in related tasks.
Strengths:
1. Elimination of External Semantic Resources: The model's independence from external semantic resources is a significant strength, as it enhances portability across domains. This addresses a key limitation of prior systems that relied heavily on domain-specific knowledge bases like WordNet or FrameNet.
2. Performance: The model achieves performance comparable to or better than feature-rich systems on the ACE dataset, demonstrating the effectiveness of the proposed approach. The inclusion of results on the larger ACE++ dataset further validates the model's scalability.
3. Error Analysis and Insights: The paper provides a thorough error analysis, identifying challenges such as pronoun resolution and annotation inconsistencies. This analysis is valuable for guiding future research in event coreference resolution.
4. Novelty in Nonlinearity: The use of a square function as a nonlinearity in the similarity computation is an intriguing design choice that could have implications for other tasks requiring similarity measures.
Weaknesses:
1. Gold vs. Predicted Triggers: The use of gold-standard event triggers in evaluation limits the practical applicability of the results. Without results on predicted triggers, the model's performance cannot be fairly compared to systems that operate in a fully automated pipeline.
2. Unclear Methodological Details: Several aspects of the methodology are insufficiently detailed, including the use of cross-sentential information, position embeddings, left/right neighbor features, and the representation of event mentions (v_e). This lack of clarity makes it difficult to fully understand and reproduce the model.
3. Dataset Accessibility: The ACE++ dataset, which is central to the paper's claims of scalability, is not publicly available. This hinders reproducibility and limits the impact of the work.
4. Train/Test Splits: The use of different train/test splits across papers is concerning, as it complicates direct comparisons with prior work. Adherence to established splits would improve the reliability of the reported results.
5. Significance Testing: The paper does not include statistical significance testing for its results, which is critical given the close performance numbers reported.
Questions to Authors:
1. How does the model perform when evaluated with predicted triggers instead of gold-standard triggers? Can you provide results to enable fair comparisons with other systems?
2. Could you clarify how cross-sentential information and position embeddings are incorporated into the model? Are these features learned or manually designed?
3. Are there plans to release the ACE++ dataset to facilitate reproducibility and further research in this area?
Additional Comments:
- The paper could benefit from a more detailed discussion of related work, particularly neural approaches to coreference resolution, such as Wiseman et al. (2015).
- Minor issues include a redundant word ("that") on line 143 and inconsistent baseline naming in Table 6 vs. line 670.
In conclusion, while the paper makes notable contributions to event coreference resolution, addressing the identified weaknesses would significantly strengthen its impact and applicability.