This paper introduces a model for event entity linking, proposing the use of sentential features derived from CNNs as an alternative to the external knowledge sources employed by prior approaches. The model comprises two components: the first learns a representation for event mentions, while the second computes a coreference score between pairs of event entity mentions.
The paper is well-written, well-structured, and easy to understand. I particularly appreciate the analysis performed on the ACE corpus, especially regarding argument sharing among event coreferences. Additionally, the discussion on the dataset size's impact provides a strong rationale for the creation of the ACE++ dataset. However, there are several significant issues that need to be addressed:
- The authors do not adequately motivate or analyze the advantages and disadvantages of using CNNs for generating mention representations. There is no discussion on why CNNs were chosen over other architectures (e.g., RNNs), nor any comparative analysis. Given that the model's improvement over the state-of-the-art is modest—just 2 to 3 F1 points—stronger evidence is needed to justify the superiority of this architecture.
- The novelty of using sentential features for event linking is not clearly established, as employing CNNs for classification tasks is not a new idea. The authors should explicitly highlight and compare their approach to existing continuous-space methods for event linking. Furthermore, the selection of methods in Table 3 is insufficiently comprehensive.
- The methodology for constructing the ACE++ dataset is not described. A key limitation of the ACE dataset is its small number of event types, which makes it overly constrained and biased. Clarifying the event types covered by ACE++ is crucial, as it would support the claim in Section 5.1 that "other approaches are strongly tied to the domain where these semantic features are available... our approach does not depend on resources with restricted..." To substantiate this claim, the authors need to demonstrate that earlier methods fail on datasets where their approach succeeds. Additionally, to enable meaningful future comparisons, the authors should consider making the ACE++ dataset publicly available.
Some minor issues:
- It would be helpful to include the model's performance without gold references in Table 3.
- Exploring how this model could be augmented with a standard coreference resolution system would be interesting. For instance, in the example on line 687, the CoreNLP system successfully links "It" to "bombing," which could potentially be leveraged in an event entity linking baseline.
- Given the limited size of the ACE dataset, testing the model on other available resources is necessary to establish its robustness. This also underscores the importance of jointly addressing entity and event coreference. Testing on EventCorefBank alongside ACE would be particularly valuable.
- Table 5 indicates that pairwise features are highly effective, suggesting that feature engineering remains important for competitive performance, at least on the scale of the ACE dataset. It would be useful to identify the most impactful features, explain how the current set was selected, and discuss any additional features that were considered but discarded.