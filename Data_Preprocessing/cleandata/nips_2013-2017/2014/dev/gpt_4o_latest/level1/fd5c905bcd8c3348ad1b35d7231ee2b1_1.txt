Review
This paper proposes a novel framework for modeling brain states using an infinite hidden Markov model (iHMM) combined with a state-dependent tensor factorization and Gaussian process (GP) spectral mixture kernels. The authors aim to address the limitations of existing methods for analyzing local field potential (LFP) data, such as their inability to model time dependencies, reliance on preprocessing, and lack of flexibility in capturing sub-state characteristics within brain states. The proposed model is validated on toy data and two novel electrophysiological datasets, demonstrating its ability to infer brain states and their spectral properties from raw LFP data.
The paper builds on prior work in neuroscience and machine learning, including dynamic causal modeling (DCM) [5], tensor factorization [8], and spectral mixture kernels for GPs [10]. It extends the infinite tensor mixture model (ITM) by incorporating temporal dynamics through an iHMM and introduces a variational Bayesian split-merge algorithm for efficient inference. This approach allows the model to estimate the number of brain states and clusters adaptively, while leveraging shared information across brain regions and animals. The results show that the proposed method outperforms simpler models (e.g., single-state or HDP-based approaches) in predictive performance and provides neuroscientifically meaningful insights, such as the discovery of additional sleep sub-states.
Strengths:
1. Technical Novelty: The integration of iHMMs, tensor factorization, and spectral mixture kernels is innovative and well-motivated. The split-merge inference scheme is a notable contribution to variational Bayesian methods.
2. Scientific Impact: The discovery of novel brain states and sub-states has significant implications for neuroscience, particularly in understanding arousal and sleep dynamics.
3. Validation: The model is rigorously validated on both synthetic and real-world datasets, with interpretable results that align with neuroscientific expectations.
4. Clarity of Results: The figures and results are well-presented, demonstrating the model's effectiveness in recovering known states and uncovering new ones.
Weaknesses:
1. Clarity of Presentation: While the methodology is detailed, the paper is dense and may be difficult for readers unfamiliar with variational inference or Gaussian processes to follow. Simplifying some sections or providing more intuitive explanations could improve accessibility.
2. Scalability: The computational cost of the model (20 seconds per iteration) may limit its applicability to larger datasets or higher-dimensional LFP recordings. A discussion of scalability and potential optimizations would strengthen the paper.
3. Generative Assumptions: The model assumes independence between brain regions within a state, which may overlook important cross-region coherence patterns. While the authors acknowledge this limitation, extending the model to capture such dependencies would be valuable.
4. Comparison to Baselines: Although the proposed method is compared to simpler models, it would benefit from a broader comparison to other state-of-the-art methods, such as deep learning-based approaches for time-series analysis.
Arguments for Acceptance:
- The paper introduces a technically sound and novel approach to a challenging problem in neuroscience.
- The results are significant and provide new insights into brain state dynamics.
- The methodology has potential applications beyond neuroscience, such as in other domains involving time-series data.
Arguments Against Acceptance:
- The paper's clarity could be improved, particularly for readers outside the immediate area of expertise.
- Scalability and computational efficiency are not fully addressed, which may limit practical applicability.
Recommendation: Accept with minor revisions. The paper makes a strong scientific and technical contribution, but addressing clarity and scalability concerns would enhance its impact.