The paper introduces Calibrated Multivariate Regression (CMR), a novel method for high-dimensional multivariate regression that addresses limitations in existing approaches. Specifically, CMR calibrates the regularization for each regression task based on its noise level, making it less sensitive to tuning and improving finite-sample performance. The authors propose a convex optimization framework for CMR, leveraging the nonsmooth \( L_{2,1} \)-loss function, and develop a smoothed proximal gradient (SPG) algorithm with a worst-case iteration complexity of \( O(1/\epsilon) \). Theoretical analysis demonstrates that CMR achieves optimal rates of convergence in parameter estimation. Extensive numerical simulations and a real-world application to brain activity prediction validate the method, showing that CMR consistently outperforms existing methods and is competitive with handcrafted models.
Strengths:
1. Novelty and Originality: The paper introduces a new approach to multivariate regression by calibrating regularization across tasks, which is a meaningful extension of existing methods. The use of the \( L_{2,1} \)-loss function for task calibration is innovative and well-motivated.
2. Theoretical Rigor: The authors provide a comprehensive theoretical analysis, including convergence guarantees for the SPG algorithm and optimal rates of parameter estimation. This adds significant credibility to the proposed method.
3. Practical Relevance: The application to brain activity prediction demonstrates the practical utility of CMR in a challenging real-world problem. The results, which are competitive with handcrafted models, highlight its potential impact.
4. Empirical Validation: The numerical experiments are thorough, comparing CMR against both ordinary multivariate regression (OMR) and an oracle estimator. The results convincingly show the advantages of CMR, particularly in scenarios with heterogeneous noise levels.
5. Algorithmic Efficiency: The proposed SPG algorithm is computationally efficient and outperforms ADMM in terms of runtime while achieving similar accuracy.
Weaknesses:
1. Clarity and Accessibility: The paper is dense and highly technical, which may limit its accessibility to a broader audience. For example, the derivation of the SPG algorithm and the theoretical results could benefit from additional intuitive explanations or visual aids.
2. Limited Real-World Applications: While the brain activity prediction task is compelling, the paper would be stronger with additional real-world applications to demonstrate the versatility of CMR across domains.
3. Comparison to Related Work: Although the authors briefly discuss related methods like square-root sparse multivariate regression, the comparison could be expanded. For instance, empirical results comparing CMR to these methods would strengthen the paper.
4. Scalability: While the SPG algorithm is efficient, the scalability of CMR to extremely large datasets or very high-dimensional problems is not explicitly addressed.
Arguments for Acceptance:
- The paper makes a significant theoretical and practical contribution to multivariate regression, a core topic in machine learning.
- The proposed method is novel, well-justified, and rigorously analyzed.
- Empirical results are strong and demonstrate the method's advantages over existing approaches.
Arguments Against Acceptance:
- The paper's clarity could be improved, particularly for readers less familiar with the technical details.
- The scope of real-world applications is somewhat narrow, limiting the demonstration of CMR's broader utility.
Recommendation:
Overall, this paper represents a high-quality contribution to the field of multivariate regression and is well-suited for NeurIPS. I recommend acceptance, with minor revisions to improve clarity and expand the discussion of related work.