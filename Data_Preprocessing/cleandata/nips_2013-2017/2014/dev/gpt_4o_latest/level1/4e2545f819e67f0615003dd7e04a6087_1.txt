The paper presents a novel circuit model for representing multidimensional real-valued probability distributions using a spatio-temporal spike-based neural code. The authors propose a distributed sampling approach that combines the strengths of spatial and temporal probabilistic coding schemes, addressing their respective limitations in flexibility and speed. The model encodes multiple Markov Chain Monte Carlo (MCMC) sampling trajectories within a single network of spiking neurons, enabling linear decoding of the underlying distribution from quasi-instantaneous neural responses. The authors demonstrate that their model reproduces key experimental observations, such as Poisson-like variability, stimulus-specific synchrony, and stimulus-dependent modulation of neural variability and covariability. Furthermore, the paper highlights the challenges of interpreting single-neuron activity in distributed representations and advocates for population-level decoding as a tool for investigating probabilistic neural computation.
Strengths:
1. Novelty and Contribution: The proposed model introduces a unique spatio-temporal coding scheme that bridges the gap between spatial and temporal codes for probabilistic computation. This is a significant advancement over prior work, such as linear probabilistic population codes (PPCs) and neural sampling models, which are limited in either flexibility or speed.
2. Biological Plausibility: The model employs simple leaky integrate-and-fire neurons with recurrent connectivity, making it biologically plausible. The authors also discuss potential mechanisms for implementing the required dynamics in neural circuits, such as spike-timing-dependent plasticity (STDP).
3. Experimental Relevance: The model reproduces a range of experimentally observed neural phenomena, including tuning curves, Fano factors, cross-correlograms, and spike-count correlations. This alignment with empirical data strengthens the model's credibility.
4. Scalability and Trade-offs: The distributed representation allows for a linear trade-off between network size and sampling speed, offering a practical framework for scaling probabilistic computations in neural circuits.
5. Decoding Framework: The paper provides a compelling argument for using linear decoding to infer the underlying probabilistic computations from population activity, which could have significant implications for analyzing neural data.
Weaknesses:
1. Clarity and Accessibility: While the paper is technically sound, the presentation is dense and may be challenging for readers unfamiliar with MCMC sampling or neural coding. Simplifying the exposition and providing more intuitive explanations would improve accessibility.
2. Experimental Validation: The model's predictions about neural variability and covariability under different uncertainty conditions are intriguing but lack direct experimental validation. Empirical tests of these predictions would strengthen the paper's claims.
3. Generality of Results: The simulations focus primarily on Gaussian distributions and low-dimensional cases. It is unclear how well the model generalizes to more complex, high-dimensional distributions or non-Gaussian cases.
4. Learning Dynamics: The paper briefly mentions that the recurrent connections can be learned via STDP but does not provide detailed insights into how such learning would occur in practice. This limits the model's applicability to real-world neural systems.
Arguments for Acceptance:
- The paper addresses a fundamental question in computational neuroscience: how the brain represents and computes with uncertainty.
- The proposed model is innovative, biologically plausible, and aligned with experimental data.
- The work opens new avenues for analyzing neural population data and understanding probabilistic computation in the brain.
Arguments Against Acceptance:
- The paper's clarity and accessibility could be improved, particularly for a broader audience at NIPS.
- The lack of experimental validation and limited exploration of non-Gaussian distributions reduce the immediate impact of the work.
Recommendation:
Overall, this paper makes a strong scientific contribution to the field of probabilistic neural computation. While there are areas for improvement, particularly in clarity and experimental validation, the novelty and significance of the work warrant acceptance. I recommend acceptance with minor revisions to improve accessibility and address the generality of the results.