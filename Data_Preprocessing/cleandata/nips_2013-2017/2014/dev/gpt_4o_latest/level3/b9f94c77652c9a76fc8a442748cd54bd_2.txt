The paper introduces a novel framework for unsupervised structured prediction by embedding a Conditional Random Field (CRF) model within an autoencoder architecture. The CRF is used as an encoding model to predict latent structures \( P(y|x) \), while the reconstruction model \( P(\hat{x}|y) \) is a generative component parameterized as a categorical distribution. This hybrid approach is both simple and innovative, prompting the reaction of "why hasn't this been done before?" The authors demonstrate its utility on two NLP tasks—part-of-speech (POS) induction and bitext word alignment—showing competitive results with state-of-the-art methods.
Strengths:
1. Originality and Simplicity: The proposed CRF autoencoder is an elegant combination of discriminative and generative modeling. Its ability to incorporate global, feature-rich representations without sacrificing computational efficiency is a significant contribution.
2. Empirical Results: The framework outperforms feature-rich HMM baselines in POS induction and achieves competitive results in word alignment, with notable improvements in alignment error rate (AER) and translation quality for certain language pairs.
3. Scalability: The authors convincingly argue that their method scales better than existing feature-rich alternatives, supported by runtime comparisons in the appendix.
4. Potential for Extension: The method could be extended to semi-supervised learning, though this is not explored in the current work.
Weaknesses:
1. Empirical Comparisons: The paper lacks comparisons with alternative methods that require marginalization over latent variables (e.g., MRFs with approximate inference). This omission weakens the empirical evaluation.
2. Coherence and Interpretability: While the authors claim that the model promotes "coherence and interpretability," these aspects are not explicitly evaluated, leaving the claim unsubstantiated.
3. Arbitrary Experimental Choices: The selection of CoNLL-X languages for POS induction experiments appears arbitrary and is not justified.
4. Scalability Evidence: While scalability is claimed, a graph showing test accuracy versus training data size would strengthen the argument.
5. Optimization Challenges: The paper does not discuss potential issues with local minima, initialization, or optimization stability, which are critical for models with latent variables.
6. Writing Issues: Minor grammatical errors and awkward phrasing (e.g., on pages 2 and 6) detract from the paper's clarity.
Suggestions for Improvement:
1. Include empirical comparisons with methods requiring \( Z \)-approximations to contextualize the results better.
2. Provide a detailed evaluation of coherence and interpretability, aligning with the stated goals.
3. Justify the choice of datasets and include experiments on additional languages or domains to demonstrate generalizability.
4. Add a graph showing test accuracy versus training data size to substantiate scalability claims.
5. Discuss optimization challenges and provide empirical evidence of robustness against local minima.
Recommendation:
The paper is well-written overall and presents a clean, impactful idea with promising results. Despite some weaknesses in empirical comparisons and evaluation of stated goals, the novelty and potential of the method make it a strong candidate for acceptance. Addressing the suggested improvements would further enhance its contribution to the field. I recommend acceptance, with minor revisions.