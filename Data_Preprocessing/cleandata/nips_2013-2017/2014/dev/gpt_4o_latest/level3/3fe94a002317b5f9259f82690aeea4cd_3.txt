The paper presents an in-depth investigation into the underperformance of Convolutional Neural Networks (CNNs) in scene recognition compared to object recognition, attributing this gap to the lack of a sufficiently large and diverse scene-centric dataset. To address this limitation, the authors introduce the "Places" database, the largest scene dataset to date, containing over 7 million labeled images across 476 categories. Through extensive experiments, the authors demonstrate that training CNNs on Places significantly improves scene recognition performance, achieving state-of-the-art results on multiple benchmarks. The paper also introduces novel density and diversity measures to compare datasets and highlights the differences in internal representations learned by object-centric and scene-centric CNNs.
Strengths:
1. Significant Contribution to Dataset Resources: The introduction of the Places database is a major contribution to the field, addressing a critical gap in scene recognition research. The dataset's scale and diversity surpass existing scene datasets, making it a valuable resource for the community.
2. Empirical Validation: The authors convincingly demonstrate that dataset size and type are critical for CNN performance, validating their hypothesis with extensive experiments. The improved results on multiple benchmarks underscore the dataset's utility.
3. Insightful Analysis: The visualization of CNN representations trained on object-centric (ImageNet) and scene-centric (Places) datasets provides valuable insights into the differences in learned features, advancing our understanding of CNN behavior.
4. Novel Dataset Comparison Metrics: The proposed density and diversity measures offer a systematic way to compare datasets, which could have broader applications in dataset evaluation.
Weaknesses:
1. Lack of Technical Novelty: Beyond the dataset creation and application, the paper lacks significant methodological innovation. The CNN architecture and training procedures are standard, limiting the technical contribution.
2. Unclear Visualization Method: The proposed visualization technique for CNN layers is not well-explained or contrasted with prior work, making it difficult to assess its novelty or effectiveness.
3. Missed Opportunities: The authors could have explored combining ImageNet and Places to train a joint network for both object and scene recognition, which might have yielded additional insights or performance gains.
4. Limited Discussion of Related Work: While the paper references prior datasets and benchmarks, it could more thoroughly situate its contributions within the broader context of scene recognition research.
Pro and Con Arguments for Acceptance:
Pro: The Places database is a significant resource that will likely have a lasting impact on scene recognition research. The empirical results and dataset comparison metrics provide valuable insights and tools for the community.
Con: The lack of technical novelty and missed opportunities for further experimentation (e.g., joint training with ImageNet) limit the paper's contribution beyond dataset creation.
Recommendation:
While the paper's primary contribution lies in dataset creation rather than methodological innovation, the Places database represents a substantial advancement for the field. The paper is well-executed, and the results are compelling. However, the authors should clarify the visualization method and consider additional experiments in the rebuttal phase. I recommend acceptance, with a suggestion to address the noted weaknesses.