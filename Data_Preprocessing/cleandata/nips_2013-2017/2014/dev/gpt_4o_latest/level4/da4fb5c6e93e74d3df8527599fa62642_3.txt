This paper introduces a novel method termed calibrated multivariate regression (CMR) for fitting high-dimensional multivariate regression models. The approach assumes that the noise matrix exhibits an uncorrelated structure and that different regression tasks are associated with distinct noise variances. Rather than employing a uniform tuning parameter lambda across all regression tasks, CMR adjusts for task-specific differences by solving a penalized weighted least squares problem, with weights defined in equation (2.3) (essentially an estimate of the noise standard deviation). The paper is well-organized and clearly written, with the appendix providing extensive technical details. The formulation of CMR appears to be technically sound. The proposed computational algorithms and the statistical properties presented are reasonable at a high level, though I did not verify every step of the derivations and proofs due to limited expertise in this specific area. The empirical evaluations on both simulated and real datasets produced encouraging results.
Line 129: Should "weighted least square program" be revised to "weighted least square problem"?
Another straightforward method for calibrating the parameter lambda could involve performing separate regressions on each response variable. How does this alternative compare to the proposed CMR? It would be valuable to evaluate both approaches on simulated and real datasets. In some cases, simpler models may yield superior or more interpretable results on real-world data compared to more complex methods. This paper presents a technically sound idea with promising empirical results.