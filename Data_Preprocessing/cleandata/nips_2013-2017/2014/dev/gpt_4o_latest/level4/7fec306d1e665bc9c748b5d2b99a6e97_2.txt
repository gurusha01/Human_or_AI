This paper introduces a DDP formulation tailored for models represented as Gaussian processes. The authors provide detailed derivations of the equations that bridge the Gaussian Process model with the DDP framework. The proposed method enables solving local optimal trajectory problems for systems with unknown dynamics. In this regard, the work shares similarities with PILCO. However, the simulated results demonstrate that the proposed approach achieves solutions significantly faster than PILCO.
Quality and Clarity
While the paper presents a compelling concept, it requires further refinement, particularly in the presentation and discussion of results. The results section is underdeveloped, with minimal discussion provided for figures 1 and 2. Claims such as "safe exploration" lack sufficient justification, and the conclusion regarding computational complexity is debatable. The overall writing would benefit from additional polishing iterations. Although there are no glaring issues with specific sentences, the manuscript feels incomplete in terms of clarity and presentation.
Originality and Significance
The use of DDP as the optimization method is noteworthy and relevant for both DDP/iLQG practitioners and the broader model-based optimization community. The work shares methodological and philosophical similarities with PILCO but distinguishes itself by proposing DDP as the optimizer and developing a complete framework, offering a self-contained solution. However, the paper would be significantly strengthened by providing a thorough and detailed comparison between PDDP and PILCO.
Questions
1. Line 33: The statement, "Compared to global optimal control approaches, the local optimal DDP shows superior scalability to high-dimensional problems," is incomplete. The trade-off is that DDP provides only local solutions and may converge to poor local optima. While local solutions are often the only feasible option for high-dimensional problems, the trade-off should be explicitly acknowledged. Otherwise, there would be no reason to consider full dynamic programming approaches.
2. Line 212: The claim, "... where the variance of control distribution and the off-diagonal entries of the state covariance matrix can be neglected because of no impact on control performances," is not immediately clear, particularly regarding the control distribution. Noise in control can significantly affect state integration over time and may influence the final cost. Are the authors assuming a deterministic system?
3. Line 294: The conclusion about computational complexity appears premature. While the complexity of the learning policy may not directly depend on the number of states, for fully actuated systems, the number of control inputs is typically proportional to the number of states. This would make the algorithm's complexity O(nÂ³).
4. Safe Exploration: The formulation of the "safe exploration" feature is unclear. Although Figure 3(a) provides an intuitive explanation, it is not evident how this intuition is implemented in the algorithm.
5. Line 322: The phrase "To keep the system stable" seems inappropriate unless referring to inherently unstable systems, such as an inverted pendulum. Is the intended meaning "final zero velocity"?
6. Variance in Figure 3(a): The variance appears unrealistically small, suggesting an almost deterministic system. Since the GP learns the system from samples, one would expect the variance to be large during initial iterations and decrease over time. A plot showing this variance evolution would be insightful.
7. Motivation for GPDDP: The rationale for introducing GPDDP is unclear. If the goal is to demonstrate the effect of uncertainty propagation, this could be achieved without introducing GPDDP as a new method. What specific benefits does GPDDP offer?
8. Comparison with Traditional DDP: The paper should include a comparison with traditional DDP results when the dynamics are fully known, particularly in figures 1 and 2.
Minor Questions
1. The legends in Figure 1 are too small, and the y-axes of subplots (a) and (c) should be aligned to the same range.
2. Why are the costs for PILCO not shown in figures 1(b) and 2(b)?
Summary
The paper provides a self-contained framework for GP-based DDP, which is of significant interest to the DDP/iLQG learning community. However, the clarity of the manuscript and the evaluation, particularly in comparison to PILCO, are insufficient and require substantial improvement.