Review - Summary:  
The authors introduce a novel Newton-like optimization method designed to minimize the sum of a smooth (convex) cost function and multiple decomposable norms. Their key contributions are: (1) an active subspace selection strategy that accelerates the solution of the quadratic approximation problem, and (2) a proof demonstrating that solving the quadratic approximation problem within the (dynamically changing) active subspace still ensures convergence. The authors supplement their theoretical contributions with numerical experiments, showing that their method achieves a 10x speedup over state-of-the-art approaches for two important problems. Additionally, the appendix provides numerical evidence quantifying the proportion of the speedup attributable to the quadratic approximation technique versus the active subspace selection method.
Quality:  
The extensive critical information provided in the appendix makes this work more appropriate for a journal than a conference. While I did not verify all the proofs, the ones I reviewed are correct and well-written, aside from a few minor typographical errors.
Clarity:  
The paper is exceptionally well-written and well-structured. Below are a few minor suggestions and questions for improvement:  
- The references could be reordered numerically.  
- Including a curly bracket inside the $\min$ in Equation (1) would improve clarity.  
- In line 114, should the subscript of $\|x\|$ be $(1,\alpha)$, as in line 116?  
- In Proposition 1 (line 236), it would be helpful to clarify that the orthogonal subspace depends on $\theta$.  
- In line 259, the over-bar notation for $Q$ appears to be undefined.  
- In line 266, it should be clarified that $D$ is not required to be diagonal.  
- Line 299 references Equation (11), while Theorem 1 (line 303) references Equation (8). The appendix also refers to Equation (8). This is potentially confusing, as Equation (11) involves constrained optimization, whereas Equation (8) does not. It would be helpful to explain that, due to the quadratic nature of the problem, optimizing over the "free" subspace is equivalent to optimizing over the entire space.  
- In line 308, "gives" should be corrected to "give."  
- In line 354, it would be useful to remind readers again that $\Delta_D$ is not required to be diagonal.  
- In Figure 1, the authors should clarify the meaning of the percentages and the time values.  
Originality:  
While the paper builds on existing ideas in the literature (which the authors duly acknowledge), the proposed active subspace selection method and the accompanying convergence proof are novel contributions.
Significance:  
The reported 10x speedup is highly promising, and the algorithm presented in this work is likely to have a significant impact on practitioners. This is a well-written paper with substantial theoretical and practical contributions. However, the extensive critical information relegated to the appendix makes it more suitable for a journal (where reviewers can thoroughly examine all proofs) than for a conference, which imposes an 8-page limit on the main content for review.