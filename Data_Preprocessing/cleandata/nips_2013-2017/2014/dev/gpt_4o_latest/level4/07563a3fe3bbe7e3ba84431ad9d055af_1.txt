This paper introduces a novel approach for training convolutional neural networks (CNNs) in an unsupervised manner, enabling the model to learn invariance to common transformations.
The proposed method is straightforward and, to some extent, elegant. The core idea is to train the CNN to differentiate between image patches and their transformations versus other image patches and their transformations.
This strategy facilitates the model's ability to learn invariance to common transformations. However, as acknowledged by the authors, the method is susceptible to "collisions," where distinct image patches—intended to be distinguished by the model—share identical content.
The approach is innovative and, while simple, is not necessarily intuitive (at least not to me). It is a clever concept, and I believe it merits publication with some minor revisions (outlined below).
The authors also present a theoretical analysis that they claim supports the argument that the model learns invariant features. However, I did not find this analysis particularly convincing, as it essentially asserts that if the model discovers a perfect invariant feature representation, it would achieve the global optimum of the objective function. This conclusion seems self-evident based on the definition of the objective function. Perhaps I missed a more nuanced point in their argument.
The empirical evaluation of the proposed method is relatively comprehensive and insightful. The experiments thoroughly examine the potential vulnerability to collisions as the number of surrogate "classes" (or base training patches) increases. Additionally, the experimental results include an assessment of the invariance properties of the learned representation. From an empirical standpoint, this work is solid and well-developed.
My only concern lies in the presentation of state-of-the-art results for STL-10, CIFAR-10, and Caltech-101. The authors fail to compare their method with the actual state-of-the-art (particularly for CIFAR-10). They explicitly state that they are not comparing to standard discriminatively-trained CNN models, but the rationale for this exclusion seems arbitrary and somewhat self-serving. The issue is that the paper's presentation leaves the impression that this method approaches state-of-the-art performance on these datasets, which is not accurate. It is unacceptable to leave readers with this misleading impression. I strongly recommend that the authors provide a comparison with the true state-of-the-art for each dataset, both with and without dataset transformations.
Overall, this is a strong paper presenting a simple yet clever idea that is well-supported by empirical exploration.