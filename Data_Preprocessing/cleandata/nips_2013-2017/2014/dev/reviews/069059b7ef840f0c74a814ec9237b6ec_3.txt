In this paper, the authors take a different look at discriminative clustering. Their central idea is the following: they imagine a classifier that separates the different (cluster) classes, and derive a bound for the generalization error induced by this classifier. This is the bound that they then attempt to optimize using a clustering algorithm (in this case, a belief-propagation based method). 
The main feature that distinguishes this work from prior work is that they reformulate the cost function as a new kind of similarity measure that makes use of a kernel density estimate, so as to avoid a parameter search problem. This is not to say that they don't have parameters in their formulation: but these are either balance paramters or a variance parameter for the kernel density function they estimate. 
Overall, I think this is a reasonable idea, and does have some merit in terms of reducing the number of parameters for discriminative clustering. It also provides a better story about what exactly the clustering algorithm is attempting to optimize. 
In terms of whether the idea has merit in practice, the paper is a little thinner. The main comparison is to a different exemplar-based clustering approach. This to me seems a little odd, since one of the claimed selling points of the paper is that it requires fewer parameters than other discriminative clustering methods. Would it have been more useful to compare to MM clustering or even the information-theoretic approaches as well ? The space spent proving consistency of the KDE could very well have been utilized for such a comparison, because the consistency results follow fairly directly from known results. 
I didn't find the paper very easy to read, mainly because of the excess of notation used to explain the main ideas. It would have benefited (somewhere) from a final "here is our algorithm" explanation that puts everything together. While I understand how the pieces fit together, I spent some time trying to track down various parameters (including the variance h) and how they were being used in the overall algorithm. 
 A reasonable idea that deserves consideration. But could do with a more thorough experimental evaluation.