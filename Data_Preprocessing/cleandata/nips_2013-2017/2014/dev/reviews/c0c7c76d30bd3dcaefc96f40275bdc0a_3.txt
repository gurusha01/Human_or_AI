"Zeta Hull Pursuits: Learning Non-convex Data Hulls" addresses the problem of column sampling in datasets by finding points that do not alter significantly the Ihara zeta function of a graph (presumably constructed via a kernel). They provide establish some basic facts about the zeta function and the effect that removing a vertex has on it. These they use to provide a fast greedy algorithm for selecting 'outlying' vertices, and a faster version using anchors. They demonstrate on some standard datasets that using these points can improve classification accuracy. 
The paper is fairly well written, with good organization and only minor typos. I have checked the proofs and did not find any mistakes. I am not sure that the method is motivated enough to merit acceptance, while it is in fact a novel idea.
The authors elude to the fact that this works for summarization of the data points without assuming that they are preserving the convex hull or enscribing ellipsoids. I believe that this is the primary merit of this paper, that they are able to find representative points in a combinatorial fashion. With that said, it is not exactly clear what is the motivation behind the use of the zeta function. If they had clearly argued for the use of points that minimize their epsilon objective, perhaps via the learning of non-convex hulls (which was never clearly defined) then my review might be better.
Also, I don't think that the Theorems are significant enough technical contributions to merit much attention. Theorem 1 reiterates an established fact regarding the a determinant form of the Zeta function (generalized to weighted graphs). Theorems 2 and 3 are straightforward results from matrix algebra and the SVD.
 The paper is well written and organized and the method is novel. However, I do not believe that the use of the method is well defended and motivated by this paper.