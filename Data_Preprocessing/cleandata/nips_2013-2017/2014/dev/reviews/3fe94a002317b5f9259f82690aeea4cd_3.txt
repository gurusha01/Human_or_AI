The authors analyze why the recent success of CNN for visual recognition is less pronounced for scene recognition. They hypothesize that it is a lack of data and therefore collect the largest scene dataset to date with over 6 million images. Training the same convolutional architecture that has proven so successful for object recognition also improves on the state of the art in scene recognition given this new dataset.
The authors do a good job at providing further insights by comparing scene dataset by density and diversity measures. In this sense, the new dataset also compares favorably in quality. 
The overall conclusion of the paper is that depending on the input data, one learns either a object-centric or scene-centric representation. They show that also either representation shows good performance on scene and object recognition task, state-of-the-art performance is only achieved with a very large dataset of the appropriate type (scene or object dataset). While this conclusion is not so surprising, up to now it was not possible to validate this hypothesis due to a lack of a large scene dataset.
I am unclear in which way the proposed visualization is different from previous ones. this is not contrasted in the paper. Please detail this in your rebuttal.
It remains somewhat disappointing that the authors didn't try the obvious experiment of combining imagenet and their new scene database and train a joint network for objects and scenes. Their conclusion reads as if we have to decide if we either learn a good scene or a good object representation. It is not clear that we can both by training the network jointly. The authors show that the success of CNNs in object recognition can be carried over to scene recognition by their newly collected huge scene dataset that is about a factor 60x larger than any other scene database available to us today. The dataset and the results are of great value, but there is basically no technical novelty.