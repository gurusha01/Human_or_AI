This paper described a novel method to train convolutional neural networks (CNNs) in an unsupervised fashion such that the model still learns to be invariant to common transformations.
The method proposed by the authors is simple and, some extent, elegant. The idea is to simply train the CNN to distinguish image patches and their transformations from other image patches and their transformations.
This approach allows the model to learn to be invariant to common transformation. However, as the authors mention, the method is vulnerable to "collisions" where distinct image patches -- that the model will try to distinguish -- share the same content. 
The method is novel and, while simple, isn't necessarily obvious (at least not to me). It's a clever idea and I think, with some minor changes (see below), it deserves to be published. 
The author also present theoretical result that the authors claim support the argument that the model learning invariant features. I did not find this analysis particularly compelling as it seems to basically just state that the if the model were to find a perfect invariant feature representation, then it would achieve the global optimum of the objective function. This seems obvious from the definition of the objective function. Perhaps I've missed something more subtle.
The empirical exploration of the proposed approach is relatively thorough and insightful, including experiments carefully exploring the potential vulnerability described above as the number of surrogate "classes" (or base training patches) increases. The experimental results also include an evaluation of the invariance properties of the learned representation. On
the empirical side, this work is relatively solid and mature.
My only quibble is that in presenting the state-of-the-art results for STL-10, CIFAR-10 and Caltech-101, the authors neglect to provide a comparison with the actual state-of-the-art (particularly for CIFAR-10). They state that they are not comparing to standard discriminatively-trained CNN models -- the motivation for this line in the sand seems arbitrary and frankly a bit self-serving. The problem is that the presentation in the paper clearly leaves the reader with the impression that this method approaches the state-of-the-art for all these datasets. This is clearly not the case and it isn't acceptable to leave that impression with the reader. I ask simply that the authors provide the true state-of-the-art for each of these datasets, with and without dataset transformations.
 A good paper about a simple, but clever idea well explored empirically.