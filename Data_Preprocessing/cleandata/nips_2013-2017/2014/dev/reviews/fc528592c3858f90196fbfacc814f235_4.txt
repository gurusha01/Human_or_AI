The paper describes two related algorithms for finding clusters under the stochastic block model assumption when there is partial information (in the sense that only a fraction of the columns of the adjacency matrix are revealed) or in a data streaming setting (where fewer than the size of the input bits are retained to perform the computation).
Pros: 
Another contribution to an area of recent interest, both with respect to data-constrained computation, clustering matrices, etc.
The main algorithm splits the problem into two steps, which is probably the correct way to do streaming clustering under model assumptions like this stochastic block model. Making that explicit highlights both important points.
Cons:
The algorithm is of theoretical interest, as it makes unrealistically strong assumptions for realistic networks of even moderate size and since it doesn't work at important "boundaries" of edge density, e.g., extremely sparse graphs.
Claims with respect to how this work fits into the streaming and community literature are very much overstated, as mentioned below.
The description of the algorithm seems to not make clear what I think is going on: that under the stochastic block model with large blocks, then input has very nice structure, and so the main goal of the algorithm is to make sure that the sampling doesn't overly concentrate certain quantities in the "empirical" estimates. For example, I think that is what the trimming step is doing, and I think that is similar to what Feige and others, Montaneri and others, and probably others have done. 
A few other comments. 
(1) The problem as stated is unrealistic for what most people would consider community detection in realistic networks. For example, the clusters don't overlap, and the results don't go through when the graphs are extremely sparse (which is typical) or extremely dense (which may arise occasionally). Thus, they are best viewed as contributing to the recent work on spectral-like algorithms for stochastic block (which also suffer from similar drawbacks) and related models under various computational constraints (which is of interest).
(2) No empirical evaluation. This isn't necessarily a bad thing, since if there were it would likely be trivial (in the sense that they would simply show a phase transition which they establish) or overly-idealized (i.e., they would have to "simulate" memory limitations, since dealing with realistic memory management is very nontrivial).
(3) The columns are revealed one by one. This is a rather strong assumption in terms of motivations, and it means that it is much easier to obtain much stronger results than if elements or blocks are revealed. For example, much stronger results are obtained in low-rank matrix approximation when columns are sampled than when elements are sampled. More formal data streaming models, e.g., in the theoretical computer science literature consider other data presentation formats.
(4) Finally, if the authors don't know of other related work on clustering or partitioning or community finding, it is for lack of effort. For example, a few quick web searches find many papers, including the following papers:
FENNEL: Streaming Graph Partitioning for Massive Scale Graphs, by Tsourakaki, et al.
Online Analysis of Community Evolution in Data Streams, by Aggarwal and Yu
Streaming Graph Partitioning for Large Distributed Graphs, by Stanton and Kliot
Sparse Cut Projections in Graph Streams, by Das Sarma, Gollapudi and Panigrahy
These papers are all sufficiently different than the present paper that there is novelty in the present paper and no overlap. But they illustrate that it much more accurate to describe the present paper as an interesting but relatively minor improvement on recent work on stochastic blockmodeling under various well-motivated memory constraints than as the first community detection algorithms in the data stream model or as a paper that introduces the problem of community detection with partial information, both of which are claimed but neither of which is correct.
 Overall a reasonable paper on a topic of interest. If the paper is accepted, I suggest that the authors adjust their claims to be more modest and correct and that they also work on the presentation to highlight their few nice contributions.