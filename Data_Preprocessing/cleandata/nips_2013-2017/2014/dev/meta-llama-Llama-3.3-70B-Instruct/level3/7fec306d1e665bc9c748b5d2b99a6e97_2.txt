This paper proposes a novel algorithm, QUIC & DIRTY, for optimizing superposition-structured statistical estimators. The method combines a quadratic approximation framework with active subspace selection to efficiently solve high-dimensional problems. The authors demonstrate the effectiveness of their approach on two real-world applications: Gaussian Markov Random Fields with latent variables and multi-task learning with superposition-structured regularizers.
The paper's concept is strong, and the proposed algorithm shows significant improvements over state-of-the-art methods in terms of computational efficiency. The authors provide a thorough theoretical analysis, including convergence guarantees and asymptotic quadratic convergence rates. The experimental results are impressive, with the algorithm outperforming other methods by a factor of 10 or more in some cases.
However, the presentation of the results is somewhat shallow and lacks discussion. The paper could benefit from a more detailed analysis of the algorithm's performance and a comparison to traditional methods. Additionally, some claims and conclusions seem questionable and require further support. The authors also raise several questions and concerns, such as incomplete statements, assumptions about system dynamics, and unclear formulations of certain features.
The work has significant implications for the model-based optimization community, particularly for DDP/iLQG practitioners. However, the paper shares similarities with existing methods, such as PILCO, and requires more extensive analysis and comparison to establish its novelty and impact. Minor issues with figure presentation and legend sizing also need to be addressed.
Overall, the paper has the potential to make a valuable contribution to the field, but it requires refinement in terms of presentation, clarity, and writing. The authors should carefully evaluate their method, provide more comprehensive analysis and discussion, and address the raised concerns to strengthen their claims.
Arguments pro acceptance:
* The paper proposes a novel and efficient algorithm for optimizing superposition-structured statistical estimators.
* The method shows significant improvements over state-of-the-art methods in terms of computational efficiency.
* The authors provide a thorough theoretical analysis, including convergence guarantees and asymptotic quadratic convergence rates.
Arguments con acceptance:
* The presentation of the results is somewhat shallow and lacks discussion.
* Some claims and conclusions seem questionable and require further support.
* The paper shares similarities with existing methods and requires more extensive analysis and comparison to establish its novelty and impact.
* Minor issues with figure presentation and legend sizing need to be addressed.