This paper proposes a new method called calibrated multivariate regression (CMR) for fitting high-dimensional multivariate regression models. The authors argue that CMR calibrates the regularization for each regression task with respect to its noise level, achieving improved finite-sample performance. The paper reviews relevant theoretical work and empirically demonstrates the effectiveness of CMR in overcoming the limitations of existing methods.
The paper is well-written and clear, making it easy to follow the authors' arguments. The authors provide a thorough analysis of the statistical properties of CMR, including its rate of convergence and tuning parameter selection. The numerical simulations demonstrate the superiority of CMR over existing methods, including ordinary multivariate regression (OMR) and the square-root sparse multivariate regression.
One of the strengths of the paper is its ability to address the problem of regularization parameter selection, which is a common challenge in multivariate regression. The authors propose a smoothed proximal gradient algorithm to solve the CMR optimization problem, which has a worst-case iteration complexity of O(1/Îµ). The algorithm is shown to be efficient and effective in numerical simulations.
However, there are some potential weaknesses in the paper. For example, the authors assume an uncorrelated structure for the noise matrix Z, which may not always be the case in practice. Additionally, the paper could benefit from more detailed comparisons with other existing methods, such as Hessian-free optimization.
In terms of originality, the paper proposes a novel approach to multivariate regression that calibrates the regularization for each task. The authors also provide a unique combination of theoretical analysis and numerical simulations to demonstrate the effectiveness of CMR.
The significance of the paper lies in its ability to address a difficult problem in multivariate regression, which is the calibration of regularization parameters. The authors demonstrate that CMR can achieve improved finite-sample performance and is competitive with handcrafted models created by human experts.
Overall, the paper is well-written, clear, and provides a significant contribution to the field of multivariate regression. The authors demonstrate the effectiveness of CMR through thorough numerical simulations and provide a detailed analysis of its statistical properties.
Arguments for acceptance:
* The paper proposes a novel approach to multivariate regression that calibrates the regularization for each task.
* The authors provide a thorough analysis of the statistical properties of CMR, including its rate of convergence and tuning parameter selection.
* The numerical simulations demonstrate the superiority of CMR over existing methods.
* The paper addresses a difficult problem in multivariate regression and provides a significant contribution to the field.
Arguments against acceptance:
* The authors assume an uncorrelated structure for the noise matrix Z, which may not always be the case in practice.
* The paper could benefit from more detailed comparisons with other existing methods.
* The authors may need to provide more detailed explanations of the smoothed proximal gradient algorithm and its implementation.