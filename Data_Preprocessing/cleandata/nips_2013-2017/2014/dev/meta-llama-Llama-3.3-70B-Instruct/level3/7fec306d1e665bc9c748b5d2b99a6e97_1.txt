This paper proposes a novel proximal Newton framework for optimizing superposition-structured statistical estimators, which combines quadratic approximation with active subspace selection to efficiently solve high-dimensional problems. The approach is applied to two real-world applications: latent Gaussian Markov random field structure learning and multi-task learning with superposition-structured regularizers. The experimental results demonstrate that the proposed algorithm is more than 10 times faster than state-of-the-art methods.
The paper is well-written, and the authors provide a clear and concise introduction to the problem and their approach. The technical sections are detailed and well-organized, making it easy to follow the development of the algorithm. The authors also provide a thorough discussion of the convergence properties of their algorithm, including global convergence and asymptotic quadratic convergence rate.
However, there are some weaknesses in the paper. The experimental validation is limited to two applications, and the comparison with other methods is not exhaustive. Additionally, the authors do not provide a thorough discussion of the noise in the exploration step of Algorithm 1 and its experimental setup. The claimed advantages of the proposed approach over other methods, such as PILCO, are not fully substantiated by the experimental results.
The paper's presentation of combining Gaussian Process Regression and Differential Dynamic Programming is nice, but the experimental validation is the principal downside. The authors should consider providing more extensive experimental results to demonstrate the effectiveness of their approach in various scenarios.
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis. However, the experimental results are weak, and the paper lacks a comparison of total cost between the proposed approach and other methods. The paper is well-organized, and the writing is clear, making it easy to understand the proposed approach.
The originality of the paper lies in the combination of quadratic approximation and active subspace selection for optimizing superposition-structured statistical estimators. The approach is novel and has the potential to be applied to various high-dimensional problems. However, the paper does not provide a thorough discussion of related work, and the authors should consider referencing other relevant papers in the field.
The significance of the paper lies in its potential to efficiently solve high-dimensional problems with superposition-structured statistical estimators. The proposed approach has the potential to be applied to various fields, including machine learning, signal processing, and statistics. However, the paper should provide more extensive experimental results to demonstrate the effectiveness of the approach in various scenarios.
Overall, the paper is well-written, and the proposed approach is novel and has the potential to be applied to various high-dimensional problems. However, the experimental validation is limited, and the paper lacks a thorough discussion of related work and noise in the exploration step of Algorithm 1.
Arguments for acceptance:
* The paper proposes a novel approach for optimizing superposition-structured statistical estimators.
* The approach combines quadratic approximation and active subspace selection to efficiently solve high-dimensional problems.
* The experimental results demonstrate that the proposed algorithm is more than 10 times faster than state-of-the-art methods.
Arguments against acceptance:
* The experimental validation is limited to two applications.
* The comparison with other methods is not exhaustive.
* The paper lacks a thorough discussion of noise in the exploration step of Algorithm 1 and its experimental setup.
* The claimed advantages of the proposed approach over other methods are not fully substantiated by the experimental results.