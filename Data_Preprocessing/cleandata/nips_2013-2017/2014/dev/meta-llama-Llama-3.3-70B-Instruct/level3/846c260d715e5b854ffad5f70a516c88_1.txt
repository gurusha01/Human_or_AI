This paper proposes a novel deep neural network, called Multi-View Perceptron (MVP), which can disentangle identity and view representations from a single 2D face image and generate a full spectrum of multi-view images. The authors draw inspiration from the primate brain's face-processing network, where neurons are specialized for either view or identity. The MVP model uses a combination of deterministic and random hidden neurons to learn identity and view features, respectively. The authors demonstrate the effectiveness of MVP on the MultiPIE dataset, achieving state-of-the-art performance on face recognition and viewpoint estimation tasks.
The paper is well-organized and clearly written, making it easy to follow the authors' arguments and methodology. The introduction provides a good overview of the challenges in face recognition and the inspiration from the primate brain. The related work section is comprehensive, covering both 2D and 3D-based methods for dealing with view variation.
The technical contributions of the paper are significant, particularly in the development of the MVP model and its learning algorithm. The use of random hidden neurons to capture view representation is a novel approach, and the authors demonstrate its effectiveness in generating multi-view images. The experiments are thorough, covering face recognition, viewpoint estimation, and viewpoint interpolation.
However, there are some areas that require improvement. The analysis in Section 5 could be more detailed, particularly in terms of the concentration of measure bounds. Additionally, the experiments in Section 6 are limited to data generated from the model and do not provide insight into the method's performance on real-world data. Furthermore, there are some minor issues with notation, comments, and formatting that need to be addressed to improve the paper's clarity and readability.
Overall, the paper makes a significant contribution to the field of face recognition and multi-view perception. The MVP model has the potential to be applied to a wide range of computer vision tasks, and the authors' demonstration of its effectiveness on the MultiPIE dataset is impressive. With some minor revisions to address the issues mentioned above, this paper has the potential to be a strong contribution to the NIPS conference.
Arguments pro acceptance:
* The paper proposes a novel and effective model for multi-view perception and face recognition.
* The authors demonstrate the effectiveness of the MVP model on a large and challenging dataset.
* The paper is well-organized and clearly written, making it easy to follow the authors' arguments and methodology.
Arguments con acceptance:
* The analysis in Section 5 could be more detailed and rigorous.
* The experiments in Section 6 are limited to data generated from the model and do not provide insight into the method's performance on real-world data.
* There are some minor issues with notation, comments, and formatting that need to be addressed to improve the paper's clarity and readability.