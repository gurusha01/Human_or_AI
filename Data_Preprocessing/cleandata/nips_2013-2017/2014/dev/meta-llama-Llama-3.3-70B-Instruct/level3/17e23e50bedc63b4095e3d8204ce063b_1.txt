This paper proposes a new method called calibrated multivariate regression (CMR) for fitting high-dimensional multivariate regression models. The authors introduce a new convex program that calibrates the regularization for each regression task with respect to its noise level, leading to improved finite-sample performance. The paper also develops an efficient smoothed proximal gradient algorithm to solve the optimization problem.
The key idea of CMR is to use the L2,1-loss function, which can be viewed as a special example of the weighted least square loss function. This allows CMR to calibrate different tasks by solving a penalized weighted least square program with weights defined based on the noise level of each task. The authors provide theoretical guarantees for the CMR estimator, showing that it achieves the optimal rates of convergence in parameter estimation.
The paper presents numerical experiments on both synthetic and real data, demonstrating that CMR outperforms existing multivariate regression methods. The authors also apply CMR to a brain activity prediction problem and show that it is competitive with handcrafted models created by human experts.
The strengths of the paper include its novel approach to calibrating regularization for each regression task, its efficient algorithm for solving the optimization problem, and its strong theoretical guarantees. The paper is well-written and clearly explains the methodology and results.
However, there are some weaknesses and areas for improvement. One potential issue is that the paper does not provide a clear comparison with other methods that also calibrate regularization, such as the square-root sparse multivariate regression. Additionally, the paper could benefit from more detailed analysis of the computational efficiency of the proposed algorithm and its scalability to large datasets.
In terms of the conference guidelines, the paper meets the criteria for quality, clarity, and originality. The paper is technically sound, well-organized, and provides sufficient information for the reader to reproduce the results. The methodology is novel and contributes to the field of multivariate regression. The paper also addresses a significant problem in the field and provides a unique solution.
Arguments for acceptance:
* The paper proposes a novel and efficient method for calibrated multivariate regression.
* The paper provides strong theoretical guarantees for the CMR estimator.
* The paper presents numerical experiments demonstrating the effectiveness of CMR.
* The paper is well-written and clearly explains the methodology and results.
Arguments against acceptance:
* The paper could benefit from more detailed analysis of the computational efficiency of the proposed algorithm.
* The paper does not provide a clear comparison with other methods that also calibrate regularization.
* The paper could benefit from more detailed discussion of the limitations and potential extensions of the proposed method.
Overall, I recommend accepting the paper, but with revisions to address the areas for improvement mentioned above.