REPLY TO AUTHOR RESPONSE
I appreciate your response, in which you mention: "It is possible we missed a related paper in the neural network literature. We would be grateful if you could provide citations of neural architectures which used hand-crafted features for unsupervised learning of structured outputs." 
However, I believe there may be a misunderstanding regarding my original point, as I was essentially reiterating the same concern raised by reviewer_26, to which you also responded.
As it happens, I am familiar with a related line of research that may be relevant to your inquiry. The work by Stoyanov et al. (AISTATS 2011, NAACL 2012) demonstrates how to derive the structure of a sum-product feed-forward network by unrolling loopy sum-product belief propagation on a given graphical model. In this framework, each potential function in the graphical model can be parameterized using hand-crafted features of its incident variables, which are then converted into parametric weights of the network. Furthermore, the structure of the network reflects the structure of the graphical model. The network is trained using backpropagation to minimize prediction error at designated output variables. While this may not be traditionally considered "unsupervised," the resulting feed-forward network learns to predict latent variables from input variables in a manner that facilitates prediction of output variables, which could be viewed as a form of unsupervised learning of latent structure. If the graphical model were to have an auto-encoder structure where the output equals the input, their method would yield an unsupervised system similar to yours.
SUMMARY
The paper proposes a method for unsupervised learning of latent structure y given input x, utilizing a bottleneck approach with an autoencoder p(x | y) p(y | x). Specifically, p(y | x) is a domain-specific CRF, while p(x | y) appears to be a simple independent model. The learned latent variables y are compared to human annotations.
The objective function (2) and its gradient can be efficiently computed. The objective is a regularized log-loss of the reconstruction, marginalizing over y.
More generally, the autoencoder can be represented as p(\hat{x} | y, phi) p(y | \hat{x}, x, phi), where \hat{x} is a simplified version of x and phi is side information.
COMMENTS
The results presented in the paper are impressive, with the method producing stable improvements across multiple languages for both POS tagging and alignment tasks. However, the paper and supplementary material appear to have been written in haste, making it challenging to understand the experimental details.
The method is formally appealing and has the potential to become an important building block for learning latent structure, particularly in multi-task learning settings where the learned latent variables can be useful for predicting other supervised properties of the input x.
However, the authors fail to provide a clear explanation for why their method should perform well in unsupervised learning. The objective is to match human annotations, rather than learning representations useful for other tasks. The common issue in this setting is that the latent variables may learn the "wrong" properties of the data. The authors acknowledge this problem but do not provide a convincing explanation for why their method should perform better.
The paper lacks a detailed analysis of the experimental results to understand what was learned and why. The comparisons with other methods are limited to single-number evaluations, without breakdowns or targeted experiments to understand the underlying factors contributing to the results.
It would be beneficial to investigate whether the improved results are due to reduced model error or reduced search error. For instance, if two methods, A and B, find latent distributions pA and pB over the latent variables y, it would be helpful to determine whether each method's objective prefers its own learned distribution or if they both prefer the same distribution.
The authors suggest that their autoencoder architecture is more suitable than neural autoencoders, but this claim is not supported by discussion, empirical comparison, or error analysis. The motivation behind this choice seems to be the ability to leverage efficient, feature-engineered work on supervised structured prediction in NLP. However, other architectures, including neural architectures, could also utilize such features.
DETAILED COMMENTS TO AUTHOR
The p(\hat{x} | y) model is not explicitly described, and I can only make an educated guess about its form. Please provide a clear explanation of this model.
It is unclear what exactly is being evaluated. At L172, the distribution p(y | x, \hat{x}, phi) is mentioned, where the probability of a given latent y is proportional to p(\hat{x} | y, phi) p(y | x, phi). Is the 1-best y from this distribution being evaluated, or are one or many samples from this distribution being used?
The features used in the model are not well-explained. For example, supplement L103 mentions that auto+full features include functions of the yi, but supplement Table 2 does not provide details about these features. It is also unclear whether "xi, x_{i-1}" in the "full" column of that table refers to conjoined features or a list of features.
At L147, it is mentioned that phi is side information available in the reconstruction phase. However, even before introducing phi, the encoding phase already allowed side information in the form of anything in x that was not part of \hat{x}. Perhaps it would be more accurate to say that phi is additional side information available in the reconstruction phase.
A potentially relevant reference is http://www.cs.cmu.edu/~nasmith/papers/gimpel+smith.naacl12b.pdf.
To improve the presentation of the supplementary material, I suggest formatting it as appendices to the main paper, following the bibliography, without duplicate material. This will allow for a single bibliography, a single set of figure and equation numbers, and cross-references with the main paper.
Overall, this is an attractive method with strong results, making it suitable for NIPS or ACL. However, the paper would benefit from a more detailed analysis of why the method works and a more careful description of the experiments.