This paper introduces a novel regression approach, termed calibrated multivariate regression (CMR), designed for the analysis of high-dimensional data. The manuscript not only presents the formulation of CMR but also delves into two primary aspects: (1) the utilization of a smoothed proximal gradient method for calculating the optimal solutions of CMR, and (2) an examination of the statistical properties of CMR.
A significant contribution of this work is the development of the CMR formulation, where the loss term is calibrated for each regression task based on its respective noise level. However, it would be beneficial to explore a more intuitive explanation for the role of noise levels in this calibration process. The authors are advised to provide a more detailed explanation on this aspect to enhance the understanding of CMR's underlying mechanisms.
Theoretical results, as presented in Theorem 3.2, indicate that CMR achieves convergence rates comparable to those of its non-calibrated counterpart, OMR. Given that OMR possesses a differentiable loss term, it appears to offer computational advantages over CMR. Therefore, the authors are encouraged to offer guidance on the criteria for selecting between CMR and OMR, highlighting scenarios where one might be preferred over the other. Overall, the paper proposes CMR as a new method for high-dimensional data analysis, outlining its computational approach via the smoothed proximal method and its statistical analysis, thereby contributing to the field of regression analysis.