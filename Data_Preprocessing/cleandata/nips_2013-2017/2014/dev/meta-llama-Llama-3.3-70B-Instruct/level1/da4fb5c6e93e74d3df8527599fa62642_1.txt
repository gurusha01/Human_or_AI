This paper proposes a new method called calibrated multivariate regression (CMR) for fitting high-dimensional multivariate regression models. The authors claim that CMR calibrates the regularization for each regression task with respect to its noise level, achieving improved finite-sample performance and tuning insensitivity. The paper provides a thorough analysis of the method, including its statistical properties, computational efficiency, and numerical simulations.
The paper is well-written, and the authors provide a clear explanation of the proposed method and its advantages over existing methods. The numerical simulations demonstrate the effectiveness of CMR in outperforming other multivariate regression methods, especially when the noise levels are different across tasks. The real data experiment on brain activity prediction also shows promising results.
The strengths of the paper include:
* The proposal of a new method that addresses the limitation of existing multivariate regression methods in handling different noise levels across tasks.
* A thorough analysis of the statistical properties of the proposed method, including its convergence rate and tuning insensitivity.
* Efficient computational algorithms for solving the proposed method, including a smoothed proximal gradient algorithm.
* Numerical simulations and real data experiments that demonstrate the effectiveness of the proposed method.
The weaknesses of the paper include:
* The paper assumes an uncorrelated structure for the noise matrix, which may not always be the case in practice.
* The proposed method requires the choice of a tuning parameter, which can be challenging in practice.
* The paper could benefit from more comparisons with other existing methods, such as the square-root sparse multivariate regression.
Arguments pro acceptance:
* The paper proposes a new method that addresses an important limitation of existing multivariate regression methods.
* The method has been thoroughly analyzed, and its statistical properties and computational efficiency have been established.
* The numerical simulations and real data experiments demonstrate the effectiveness of the proposed method.
Arguments con acceptance:
* The paper assumes an uncorrelated structure for the noise matrix, which may not always be the case in practice.
* The proposed method requires the choice of a tuning parameter, which can be challenging in practice.
* The paper could benefit from more comparisons with other existing methods.
Overall, I recommend accepting the paper, as it proposes a new method that addresses an important limitation of existing multivariate regression methods and has been thoroughly analyzed and demonstrated to be effective in numerical simulations and real data experiments. However, the authors should consider addressing the weaknesses of the paper, such as the assumption of an uncorrelated noise structure and the choice of tuning parameter, in future work. 
Quality: 8/10
The paper is well-written, and the authors provide a clear explanation of the proposed method and its advantages over existing methods. The statistical properties and computational efficiency of the method have been thoroughly analyzed.
Clarity: 9/10
The paper is well-organized, and the authors provide a clear explanation of the proposed method and its advantages over existing methods.
Originality: 8/10
The paper proposes a new method that addresses an important limitation of existing multivariate regression methods.
Significance: 9/10
The paper demonstrates the effectiveness of the proposed method in numerical simulations and real data experiments, and it has the potential to impact the field of multivariate regression.