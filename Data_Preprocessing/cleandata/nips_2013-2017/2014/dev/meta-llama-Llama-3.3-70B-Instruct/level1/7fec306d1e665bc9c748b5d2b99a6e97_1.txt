This paper presents a novel approach to trajectory optimization for systems with unknown dynamics, called Probabilistic Differential Dynamic Programming (PDDP). The authors combine Differential Dynamic Programming (DDP) with Gaussian processes (GPs) to learn a probabilistic model of the dynamics and perform local dynamic programming in Gaussian belief spaces. The proposed approach is compared to classical DDP and a state-of-the-art GP-based policy search method, PILCO, on two non-trivial tasks: cart-double inverted pendulum swing-up and six-link robotic arm reaching.
The paper is well-written, and the authors provide a clear and detailed explanation of the proposed approach, including the mathematical formulations and algorithmic implementations. The experimental evaluation demonstrates the effectiveness and efficiency of PDDP in terms of data-efficiency, learning speed, and applicability.
The strengths of the paper include:
* The proposed approach addresses the limitation of classical DDP, which relies on accurate and explicit dynamics models.
* PDDP takes into account model uncertainty using GPs, which provides a more robust and flexible framework for trajectory optimization.
* The authors provide a detailed comparison with PILCO, which is a state-of-the-art GP-based policy search method.
* The experimental evaluation demonstrates the potential of PDDP for challenging control and RL problems.
The weaknesses of the paper include:
* The computational complexity of PDDP is higher than classical DDP due to the GP dynamics propagations.
* The authors do not provide a thorough analysis of the convergence properties of PDDP.
* The comparison with PILCO is limited to two tasks, and it would be beneficial to evaluate PDDP on a wider range of tasks.
Arguments pro acceptance:
* The paper presents a novel and well-motivated approach to trajectory optimization for systems with unknown dynamics.
* The proposed approach addresses the limitation of classical DDP and provides a more robust and flexible framework for trajectory optimization.
* The experimental evaluation demonstrates the effectiveness and efficiency of PDDP.
Arguments con acceptance:
* The computational complexity of PDDP is higher than classical DDP.
* The authors do not provide a thorough analysis of the convergence properties of PDDP.
* The comparison with PILCO is limited to two tasks.
Overall, I believe that the paper presents a significant contribution to the field of trajectory optimization and control, and it has the potential to be a valuable resource for researchers and practitioners in the field. However, the authors should address the weaknesses mentioned above to further improve the paper.