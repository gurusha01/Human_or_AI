This paper describes a method for non-parametric model learning from incremental data. The example motivation is learning manipulator models in robotics, where the models are often high-dimensional and highly non-linear. The approach is to apply Gaussian regression over a series of smaller patches (which are also learned by pruning and greedy addition). The key innovation over current techniques is that the proposed method produces a generative probabilistic model and requires little parameter tuning.
The paper presents convincing test data that their method achieves its goals.
As minor suggestions for improvement, the authors hint at other benefits of using a fully probabilistic/generative model, it would be nice to explicitly state why a method that is fully probabilistic is important from a controls perspective. Also, it seems like the forgetting and learning rates of LGR are tuning parameters. Is there any way to show or quantify how many fewer and/or how much less sensitive the parameters of the proposed are compared to the state of the art techniques?
 This paper is well written and organized. The need for efficient non-parametric fitting of robotics data is convincing, as is the argument about less need for tuning.