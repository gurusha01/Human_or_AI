This paper introduces a framework for learning from options in reinforcement learning. An option is a policy which has some probability of terminating at a certain state. This paper introduces the notion of an "option policy", which is like a high-level policy that allows for multi-step transition between states. They show how to make the option model universal with respect to rewards, and provide an TD-style algorithm for learning with such models.
The universal option model proposed by this paper seems extremely interesting and useful, and I like the cool theory that they provide. It appears to me that this option model is a very elegant way of getting around the "memoryless" property of MDPs while still retaining much of their simplicity. I am not an expert on reinforcement learning, and hence I cannot judge the novelty of this work. However, I like the model, and as a result, I would recommend acceptance.
 This paper introduces an interesting model of reinforcement learning using options. I cannot judge the novelty of the work, but I like the model and hence will recommend acceptance.