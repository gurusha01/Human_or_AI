This paper develops a new method of performing blind source separation, by formulating the problem as an additive factorial HMM (AFHMM), and then applying signal aggregate constraints (SACs). The motivation behind this is that additional domain knowledge can be incorporated to improve the separation of the time series into components. The example used throughout the paper is energy disaggregation, where the components of domestic energy use (relating to individual appliances) can be better separated, when information relating to total (expected) usage of each appliance in a time period is incorporated. The objective function that is maximized to perform the separation (which is the log of the posterior distribution of the hidden chains given the observed data) is then transformed into a convex optimization problem. The efficacy of the method is demonstrated in practice with both a toy data set, and with real data from domestic energy output readings.
The paper is technically sound with a strong simulation section. The method, as expected, performs favorably in contrast to regular AFMM and also AFAMAP (a recently developed alternative method) - neither of which incorporate the SACs. The improvements are shown to be significant using t-tests. The author(s) also show that the speed of optimization is comparable to AFAMAP. My only question on the results section is why the author(s) used such a low noise variance in their toy example - is this to make the illustration of Figure 2 clear that they can separate the signal very well and other methods cannot? Some clarification would be good here otherwise the problem setup seems "overly" toy and rather easy. Or are these signal to noise ratios common in real data? On this note, the authors could also comment on the signal/noise ratio between the mains readings and the aggregate appliance output in the energy application.
The theoretical aspects of the paper are overall well presented and structured. The paper would perhaps benefit from a proof that the final procedure in equation (6) is indeed convex, as it is not quite clear to me using the reasoning provided. In addition, theoretical scaling arguments (with respect to data length and number of hidden states) would benefit the paper, and compliment the simulation findings. Are the methods tractable if used for much larger data sets and state spaces, and how would this contrast with AFAMAP?
The paper is well written and structured. The problem is nicely motivated in the introduction, with a clear description of relevant literature, though I am not that familiar with this problem, so cannot definitively state that nothing has been omitted here. I point to a small (potential) error on page 4 (line 202), in the unnumbered equation before (6), where I believe there should be no commas in the subscripts proceeding the object p, to be consistent with earlier notation on page 3 (unless new notation has been introduced here?)
To my knowledge the work is novel and original, though I am not an expert so cannot comment on the significance of these results to the HMM community and to the energy application studied.
Addendum: The authors satisfactorily answered my questions in the feedback phase, and I encourage them to make similar clarifications in the next version of the paper. This paper proposed a method of performing blind source separation using Additive Factorial HMMs with Signal Aggregate Constraints. The method performs very well, when compared with the state-of-the-art, particularly with real data from an energy disaggregation problem.