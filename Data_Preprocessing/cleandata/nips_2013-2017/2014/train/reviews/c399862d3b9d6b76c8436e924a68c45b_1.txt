This paper details an approach to online bandit optimization for smooth strongly convex losses. This setting is in contrast to the online "full information" setting, where the gradient is made available to learner, instead feedback is received only through point-wise evaluations of the function. The authors describe a meta-algorithm that, through careful sampling strategies, constructs and unbiased approximation of the gradient and subsequently supplies it an optimization routine for the full information setting. The authors provide theoretical analysis for this approach and contrast the resulting bound O(T^{1/2}) with existing approaches. 
The authors consider an important problem in online optimization, the paper is well written and each point is both clear and precise, and the final result is a clear improvement over existing methods. The proofs are straightforward and easy to follow and do not contain any obvious errors. 
The paper hints at an interesting potential for future work, in the form of either an improved O(T^{1/2}) upper bound for smooth, or strictly convex losses or, alternatively, an \Omega(T^{2/3}) lower bound. 
 Authors present algorithm for online bandit optimization for smooth strictly convex losses with improved regret bound, paper is clear and concise, strong accept.