Recall that there are tons of different voting rules. How can single any out, or propose new ones, in a principled way? One interesting line of work in computational social choice (e.g., Conitzer-Sandholm) asks which rules arise as the MLE in some setting (some do, some don't). This submission proposes reversing the process: posit a statistical decision-making model (prior over a ground truth and a loss function), solve for the optimal (i.e., expected loss-minimizing) rule, and see if you get something interesting. 
The authors carry out the general plan above in two variants of the Mallows model. In both cases there is a ground truth, and intuitively each pairwise ordering is flipped independently according to some noise parameter. The two models differ as to whether the ground truth is required to be consistent (i.e., a linear ordering) or not. The rules produced by the above paradigm are not necessarily the same as any of the well-studied rules. The authors study the new rules along three dimensions: first, which of the standard properties do they possess (e.g., monotonicity); second, in the limit with n iid inputs, how does their output compare to the well-known Kemeny rule; third, the computational complexity of computing these rules (hard when ground truth is a linear order, easy otherwise).
While none of the individual results are earth-shattering, the high-level idea is nice and the collection results is a thorough study of one natural instantiation of the framework. While none of the individual results are earth-shattering, the high-level idea is nice and the collection results is a thorough study of one natural instantiation of the framework.