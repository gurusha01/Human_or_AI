This paper presents a spectral algorithm for learning a mixture of hidden Markov models (MHMM). It shows that an existing spectral algorithm for learning HMMs (Anandkumar et al., 2012) can be used off-the-shelf by formulating an MHMM as a special case of HMM. It proposes a stabilization-based solution for parameter permutation by introducing an assumption that each HMM's transition matrix has a single eigenvalue of value 1. 
There seem to be some issues with notation. The authors definitely need to show more awareness of related work by providing references (e.g., initializing EM with spectral estimates is already explored in Chaganty and Liang (2013)). Experiments are quite basic, and I strongly recommend reporting results in a table format rather than the graphical format in Figure 4.
That said, the proposed scheme to dodge the problem of parameter permutation is interesting and intuitive. The authors also provide an analysis for the case with estimation noise, which leads to an intriguing usage of eigenvalues (Equation (7)) in the algorithm. 
Comments: 
- I was initially confused by the terms in Corollary 1. It'd be good to define 1J^T (as a row vector of length J filled with ones) and elaborate a bit on the structure of lim{e->inf} bar{A}^e (that it's JK x JK block diagonal where the columns within each J x J block are the same). 
- Generally, please define each vector/matrix along with its dimensions when it's first introduced. It will immensely help the presentation. 
- I find Figure 4 very hard to read: please replace with tables. Also, I'm not sure why EM is performing so badly in Table 1. Typically, even with random initialization, with enough iterations it beats spectral methods (despite the local optima problem). A standard practice is to report the best (not average) accuracy of EM: please include that result. 
- Nit: It might help readers if the paper conforms to the established notation of Hsu et al. (2009). Namely, use T for transition matrices (not A), use n, m for numbers of observation and hidden states (not L, J). 
 The paper proposes an algorithm for learning a mixture of hidden Markov models. This algorithm consists of an existing spectral algorithm for learning hidden Markov models followed by a novel stabilization step for undoing parameter permutation.