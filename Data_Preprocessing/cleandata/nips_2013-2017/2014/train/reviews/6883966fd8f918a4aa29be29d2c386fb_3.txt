This paper is hard to follow and not clear. It is based on recent results by Hsu et al on loss minimization (although their theorem is stated incorrectly). The paper lacks empirical validation; how we can benefit from active learning in parametric linear regression. The derivation of main theorems are not clear to me (if not wrong). 
In equation 1, ||X||_* has not been defined earlier. 
Please double check theorem 2.1. For sample complexity "n" should only appear once. I believe n > c log(n) is not what Hsu et al meant. 
The derivation of L(W,P) = L(W,D) (on page 3) does not seem correct to me. P is a measure and as a result the second line seems bizarre. I think the result is correct though. 
It is not clear what happens to the main theorem of the paper once \Lambda_D is unbounded. This happens once the distribution is heavy-tail. I think in such situations the gap between Lemma 3.1 and Theorem 5.1 will be huge.
It is very important to support the claims through a set of experiments. 
 I think this work needs improvement in terms of writing and stating the results. The authors should also make a better job in terms of writing the proofs. They are not clear. A set of real-world experiments are also missing.