Summary: 
The authors proposes a multi-class extension of Deep Boosting framework of Cortes and Mohri. First, the authors prove a generalization bound of linear combination of base hypotheses where each base hypotheses belong to
different sets with different Radmacher complexities. The bound improves the standard multi-class generalization bound of Koltchinskii and Panchenko. Then, motivated by the generalization bound, the authors formulate an optimization problem which minimizes an upper bound of the generalization error. The proposed algorithm is a coordinate-descent style algorithm solving the optimization problem. The experimental results show that the proposed algorithm with decision trees as base hypotheses outperforms standard multi-class boosting algorithms such as AdaBoost.MR and its variants.
Comments:
The optimization problem is well motivated by the improved generalization bound of the authors. Also, the formulation naturally implies an coordinate-descent algorithm to solve it. Interestingly enough, the derived criterion to choose a weak hypothesis is the sum of the weighted error and the complexity of the hypothesis class. 
The experimental result seems to show the effectiveness of the proposed method as well. But, it would be better, as done in the previous ICML'14 paper on Deep Boosting, to use validation sets to optimize parameters. 
Basically, the formulation is "primal", i.e, minimizing losses (say exponential or logistic loss), similar to AdaBoost or LogitBoost. 
Another formulation is based on "dual" view of boosting. For example, AdaBoost is motivated by minimizing the relative entropy from the last distribution on the sample under some linear constraints (see, Kivinen and Warmuth COLT99). Further investigations following the dual view are found in TotalBoost(Warmuth et al. ICML06), SoftBoost(Warmuth et al. NIPS07) and ERLPBoost (Warmuth et al. ALT08). The dual view for the proposed algorithm might be interesting and it might deepen the understanding of the algorithm.
After viewing the authors's comments:
Since the authors report the new experimental results based on reviewers' suggestion, I would raise my evaluation.
 I think the theoretical contribution is sufficient enough for the community of NIPS.