Summary:
This paper proposes a model for solving discriminative tasks with video inputs. The
model consists of two convolutional nets. The input to one net is an appearance
frame. The input to the second net is a stack of densely computed optical flow
features. Each pathway is trained separately to classify its input. The
prediction for a video is obtained by taking a (weighted) average of the
predictions made by each net.
The model is evaluated on two datasets. The results are impressive and match
(or come close to) the state-of-the-art methods which use intensively
hand-crafted features.
Strengths:
- This model is a simple application of convolutional nets that gets good results.
- Previous deep learning models have not tried to use optical flow (or other
hand-crafted features) for vision tasks, preferring to learn all features from
pixels directly. This paper shows that at least for action recognition, optical
flow fields are a useful input representation. This is an important contribution.
Weaknesses:
- The model does not take into account the overall sequence of
actions over the entire video but only models fixed length (L=10) adjacent frames.
Quality:
The experiments are well-designed. It would be more insightful if the authors also include some analysis of the error modes, for example, are their some classes or group of classes that the model is unable to classify well ? Is it possible to characterize the kind of videos on which the model does not work well ?
Clarity:
The paper is clearly written. The model is well explained.
Originality:
The application of a convolutional net to optical flow features is novel.
Significance:
This approach could have a significant impact on the research in using videos and motion for various vision problems. The model is a simple application of convolutional nets to video data and gets very promising results. The use of optical flow features as inputs to a conv net is a novel contribution.