The paper examines the problem of approximating Kernel functions by random features. 
The main result is that using an L1 regularisation one can use only O(1/\epsilon) random features that to obtain an \epsilon accurate approximation to kernel functions.
The paper develops Sparse random features algorithm which is analogous to functional gradient descent in boosting.
The algorithm require O(1/\epsilon) random features which compares extremely favourably with the state of the art 
which requires O1/\epsilon^2) features.
Detailed Convergence analysis are presented in the form of theorems. They appear to be correct.
The paper is well written.
This is an elegant result which should be of practical interest for solving large scale problems. 
 The proposed Sparse Random features algorithm is based on the idea of using L1 norm regularisation and yields significant improvement over existing work.