The paper extends Locally Weighting regression (LWR) where the loss function is not a weighted combination of local models but individual data points are weighted by each model. By putting a Gaussian prior on the coefficients of the models, they end up with the local models as Gaussian processes (GP). First the batch version of the algorithm is presented where the centers of the local models is assumed to be fixed. Then, an incremental version is also introduced (in a Bayesian spirit where old posteriors are considered to be the new prior) where new models can also be added.
Quality and Clarity
The paper is well written, easy to read. The transitions from LWR to LGP is well introduced.
The experiments present results from a robotic setup by learning the inverse dynamics of a SARCOS arm a KUKA arm. The results show that LGP outperforms LWPR that is considered to be one of the best state-of-the-art methods in inverse dynamics learning. Furthermore, better performance is achieved with less local models.
The authors mention article 'Local Gaussian process regression for real time' [16] but the connection between the presented method is loosely discussed. Comparison with [16] at the level of the experiments would be also very interesting.
Originality and Significance
The new weighting of the local models seems to be original and the experimental results highlight the significance of the presented method.
 The paper extends Locally Weighting regression (LWR) with a different weighting of the local models leading to local Gaussian models. Results show that the presented method outperforms the state-of-the-arm algorithm.