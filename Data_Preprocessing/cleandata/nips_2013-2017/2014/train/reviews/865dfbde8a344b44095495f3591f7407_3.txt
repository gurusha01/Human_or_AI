This paper provides an innovative method for solving HMM models using SVI. The algorithm samples subchains in sequence data, but also addresses the issue of dependency breaking at the edges of subchains. Specifically, this problem is resolved by expanding the scope of a buffer around the target subchain until the subchain posteriors, across different length buffers, converge. The experiments show that their method is much more efficient than the existing methods and applicable to the real data. This paper provides insights for applying online learning algorithms to time-dependent models. 
Minor comments:
Equation (1), p(y1|x1) is mising phi parameter
Line 355 " Table 4" -> Table 1
Table 1, What's the predictive log-likelihood in this experiment? What's the held-out percentage? What's the setting of hyper-parameters in this case? Why was ||A - A0||_F not compared as well in this experiment? The error is hard to tell in the log-predictive case.
For all these experiments, the author only mentioned the hyper-parameter setting for k, what about other hyper-parameters?
Page 8
In Human chromatin segmentation experiment, what's the runtime for DBN? An important advance in dealing with large scale HMM inference.