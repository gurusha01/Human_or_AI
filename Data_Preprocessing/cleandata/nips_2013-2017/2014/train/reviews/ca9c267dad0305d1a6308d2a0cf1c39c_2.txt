The paper introduced a novel multi-task framework where multiple online learners are sharing a single annotator. The proposed algorithm for the task is a perceptron like algorithm with an exploit and exploration strategy to decide the task to query for. The paper also includes an analysis of the proposed algorithm which bound the expected errors. The authors show that the algorithm can also be used to solve two different bandit problems. Empirical studies on standard machine learning dataset outperform weak baselines using naive query selection strategy under the same framework. The paper is well written. However, I found the proposed algorithm does not really leverage the relationship between different tasks to facilitate the learning, which in some senses are not as interesting as other multiple task learning algorithms. Moreover, the paper lacks an analysis on the sampling complexity of the proposed algorithm similar to the selective sampling literatures, which is very important for this kind of setup.
Detailed comments and suggestions:
1. The authors could include results for a full informative supervised learning baseline, it can help the reader learn the difficulty of the tasks. 
2. What is the advantage of learning the tasks together under the proposed framework compared to learning the tasks separately with K selective sampling algorithms? It will make the paper more interesting to discuss this matters in the paper, as well as show empirical results to prove the points. 
  The paper introduced a novel multi-task framework and proposed a perceptron like algorithm with theoretical guarantee to solve the task. A major drawback of the proposed algorithm is that it does not leverage the relationship between the tasks to facilitate the joint learning.