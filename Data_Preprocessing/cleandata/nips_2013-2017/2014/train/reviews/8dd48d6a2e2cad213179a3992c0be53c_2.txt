The authors propose a clustering framework in which max-margin constraints are invoked such that clusters are defined as a tradeoff between modeling the data density and separating observations in terms of cluster specific latent projections based on regularized Bayesian inference. The method is derived for standard DPGMM as well as topic modeling based on the cluster based topic model (CTM) forming the proposed DPMMGMM and MMCTM and the utility of the approach demonstrated on a synthetic dataset as well as several real datasets demonstrating that the ground truth information is better recovered when compared to standard non-parametric mixture modeling (DPGMM and cluster based topic modeling, CTM) as quantified respectively in terms of normalized mutual information and accuracy.
The framework is interesting and invoking separation of clusters is both reasonable and seems to provide significant utility which may warrant publication. The proposed framework extends the regularized Bayesian inference framework and the non-trivial implementation details are provided in the accompanying appendix. 
My main criticism has to do with the tuning of the regularization strength c and margin l. Clearly as also discussed in the paper these parameters have great influence on the results. However, their suggested tuning is a bit ad hoc and it would improve the paper to inspect their cross-validated tuning versus the proposed heuristic forming DPMMGMM. Furthermore, it is unclear what denotes the MMCTM framework it is just stated in the paper that this constitutes the optimal parameter setting - but how was this found (do you mean using the same number of topics as for CTM - Please clarify)? For the topic modeling results in particular it seems that the choice of c=9 and l=0.1 is a rather informed setting and it is unclear how this setting was selected. This should also be clarified or at least the influence of these choices be better accounted for as the tuning of these parameters for the approach seems to be somewhat of a key issue for performance.
Minor comments:
Please clarify what the lines denote in Figure 3. I assume they are representing \eta_k.
Gausses -> Gaussians
in the generate process -> in the generative process
needed to sampled -> needed to be sampled
to jointly sampled (yi,si) -> to jointly sample (yi,si)
many of the the sampling formula are -> many of the sampling formulas are
 An interesting framework for separating clusters in generative models that appears to have utility in extracting ground truth structure. However, adequate tuning of tradeoff and marging parameters seems to be essential.