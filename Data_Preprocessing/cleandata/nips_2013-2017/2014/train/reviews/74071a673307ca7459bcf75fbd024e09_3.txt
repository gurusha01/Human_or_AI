This paper proposes a framework for learning with prior constraints over the parameters and apply it in sparse learning with prior knowledge on the cardinality of the parameter support.
* While this paper offers a new perspective that constraint over parameters can be enforced by projecting in KL-divergence, it does not seem to lead to new interesting theoretical results or new algorithms.
* The proposed algorithm is not clearly presented. An outline, possibly in pseudocode, may be helpful.
* The experimental result shows that the proposed method (Sparse-G) outperforms all other methods but the reason is not clearly explained. Moreover, the Spike-and-slab performs significantly worse than Lasso, which is inconsistent with results in the literature. One possible reason could be the setting of the hyper-parameter.
* The writing is generally clear except: 
 - The concept "structure" needs to be better explained. 
 - Line 310 "... spike and slab does not return sparse estimates ..." is confusing as spike-and-slab is proven to be an effective 
 prior for sparse learning. The paper proposes a new framework for learning with prior constraint on parameters based projecting distributions in KL-divergence. This is kind of interesting but does not seem to have any very useful theoretical or algorithmic insight.