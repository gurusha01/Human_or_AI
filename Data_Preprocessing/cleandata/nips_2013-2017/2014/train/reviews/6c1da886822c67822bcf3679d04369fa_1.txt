This paper proposes a privacy-preserving mechanism for recommender systems
which are based on the popular matrix factorization. Specifically, the
authors propose splitting users into disjoint groups of public and private
users. Private users do not share any information (ratings) with the
system while public users share all of their information. The authors show
that under certain technical conditions one can bound the estimation
accuracy of the item features based on the number of observed ratings.
This estimate can further be used to bound the reconstruction error of the
private users. The authors further demonstrate the empirical performance
of their approach using the Movielens 10M dataset.
Privacy in recommender systems is an important problem that we are only
beginning to explore. As far as I know most formal previous approaches
rely on differential privacy. This paper considers that even the
recommender engine is not safe. This seems like a reasonable practical
setting. In that setting the authors develop an interesting framework.
The formalism developed in this paper is clear and seems sound as are the
derivations. The results (bounding the error of the item factors and
consequently the errors of the reconstruction) are interesting. It would
be nice to give a bit more intuition about Theorem 3.5.
Overall the paper is well written and easy to follow.
The experiments are also reasonable. They demonstrate what is needed and
the comparisons to other methods is reasonably convincing.
In the first set of experiments, it would be good to clarify what the
label "Percentage of Users" mean. I understood it to mean the percentage
of all users that were public.
The second set of experiments uses 100 public users and up to 400 private
users. It is a bit unclear why the authors are not reporting results with
more private uses (the dataset contains 10K users). What happens in that
setting? Do any of the DP methods (especially LAP eps=5) reach similar
performance as PMC and PMD. Was there a reason for stopping at 400 private
users? It would be good to show that PMC and PMD do well in a less
synthetic setting. It would also be nice to provide results in the case
where the private users aren't the ones that have necessarily consumed the
most items.
 Good paper which introduces an interesting way to preserve privacy inmatrix-factorization-based recommender systems. Both theoretical analysisand empirical results seem sound.