I think the paper is well-written and that the authors do a fine job of introducing us to the DC programming area and its potential relevance to reinforcement learning. Its hard to know how helpful this will eventually be, however. DC programming itself is not known to be computationally efficient. Further, the consistency results in Section 3 seem to be quite limited in scope (even the one the authors discuss that applies to a class of stochastic MDPs). The computational results show some potential, though for simple and very low-dimensional (2d) problems.
Some minor notes:
o In the last paragraph of page 3: "manly" --> "mainly" and why the "+" in one "+\inf" but not the other?
o Second paragraph of page 4: should "too important" be "too large"?
o Section 6 mentions the possibility of boosting as though it is something that may differentiate DCA. Why can't boosting also be used with other RL algorithms?
 Early-stage work introducing a new algorithmic approach to the area of reinforcement learning. Not clear yet how useful this will be eventually.