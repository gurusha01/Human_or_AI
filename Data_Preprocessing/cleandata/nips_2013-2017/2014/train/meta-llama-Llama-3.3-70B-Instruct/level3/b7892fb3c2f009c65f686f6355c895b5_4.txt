This paper proposes a novel control-theoretic framework for building functioning attractor networks that satisfy key physiological constraints, including Dale's law and the presence of recurrent and sparse synaptic connections. The authors directly optimize network parameters to force sets of arbitrary analog patterns to become stable fixed points of the dynamics, resulting in networks that operate in the balanced regime and are robust to corruptions of the memory cue and ongoing noise.
The paper is well-written and clearly organized, making it easy to follow the authors' arguments and understand the technical details. The introduction provides a thorough overview of the background and motivation, and the methods section clearly explains the optimization procedure and the cost function used. The results section presents a detailed analysis of the network's performance, including its ability to recall memories and its robustness to noise.
One of the strengths of the paper is its ability to overcome the limitations of previous models, which often violated Dale's law or restricted the representation of memories to a binary format. The authors' approach allows for the storage of multiple analog memories as stable fixed points of the dynamics, and the resulting networks are able to recall these memories in a robust and efficient manner.
The paper also provides a clear example of how to extend the conventional SVM framework to a Bayesian setting using a well-defined formulation with prior distributions. The authors introduce a Gaussian process extension of the Gaussian prior on the weight vectors, presenting a nonlinear SVM formulation and proposing two optimization methods for optimization.
However, I would like to see a more detailed derivation of the predictive distribution in Eq. (11), preferably in the paper or supplementary material. This would help to clarify the technical details and provide a more complete understanding of the authors' approach.
Overall, I believe that this paper is a nice contribution to the field and would be of interest to NIPS readers. The paper's strengths include its clear and well-organized presentation, its ability to overcome the limitations of previous models, and its robust and efficient performance. The paper's weaknesses are minor and include the lack of a detailed derivation of the predictive distribution.
Arguments pro acceptance:
* The paper proposes a novel and well-defined framework for building attractor networks that satisfy key physiological constraints.
* The authors provide a clear and well-organized presentation of their approach, making it easy to follow and understand.
* The paper overcomes the limitations of previous models and provides a robust and efficient approach to storing and recalling analog memories.
* The paper is well-suited for NIPS readers and would be of interest to researchers in the field.
Arguments con acceptance:
* The paper could benefit from a more detailed derivation of the predictive distribution in Eq. (11).
* The paper may not provide a complete understanding of the technical details for readers who are not familiar with the background material.
Quality: 8/10
Clarity: 9/10
Originality: 8/10
Significance: 8/10
Overall, I would recommend accepting this paper, but with the suggestion that the authors provide a more detailed derivation of the predictive distribution in Eq. (11) to clarify the technical details and provide a more complete understanding of their approach.