This paper introduces a novel multi-task framework with a perceptron-like algorithm that shares a single annotator among multiple online learners, utilizing an exploit and exploration strategy. The proposed algorithm, SHAMPO, is designed for online multi-task learning with a shared annotator and is analyzed in the mistake-bound model. The algorithm is shown to perform well compared to methods that observe all annotated data, and it can be applied to solve two different bandit problems.
The paper provides a thorough analysis of the algorithm, including a bound on the expected cumulative number of mistakes. The bound depends on the number of tasks, the input parameters, and the prior distribution over tasks. The algorithm is also evaluated empirically on several datasets, including OCR, vowel prediction, and document classification. The results show that SHAMPO outperforms other algorithms, including a uniform allocation algorithm and an exploit algorithm, in terms of average test error and score.
One of the strengths of the paper is its ability to handle multiple tasks simultaneously and to adapt to the hardness of each task. The algorithm's exploration-exploitation strategy allows it to focus on the harder tasks and improve overall performance. The paper also provides a thorough analysis of the algorithm's performance and provides insights into its behavior.
However, there are some weaknesses to the paper. One major drawback is that the algorithm fails to leverage the relationship between tasks to facilitate joint learning, making it less interesting compared to other multi-task learning algorithms. Additionally, the paper lacks an analysis on the sampling complexity of the proposed algorithm, which is crucial for this type of setup. The authors are also suggested to include results for a full informative supervised learning baseline to demonstrate the task difficulty and compare the advantage of learning tasks together versus separately.
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The paper is clearly written, and the organization is good. The originality of the paper is also high, as it introduces a new framework for online multi-task learning with a shared annotator. The significance of the paper is also high, as it addresses a difficult problem in a better way than previous research.
Overall, I would recommend accepting this paper, as it provides a novel and well-analyzed algorithm for online multi-task learning with a shared annotator. The paper's strengths, including its ability to handle multiple tasks simultaneously and its exploration-exploitation strategy, make it a valuable contribution to the field.
Arguments pro acceptance:
* The paper introduces a novel framework for online multi-task learning with a shared annotator.
* The algorithm is well-analyzed, and the bounds on the expected cumulative number of mistakes are provided.
* The empirical results show that SHAMPO outperforms other algorithms in terms of average test error and score.
* The paper provides insights into the behavior of the algorithm and its ability to adapt to the hardness of each task.
Arguments con acceptance:
* The algorithm fails to leverage the relationship between tasks to facilitate joint learning.
* The paper lacks an analysis on the sampling complexity of the proposed algorithm.
* The authors should include results for a full informative supervised learning baseline to demonstrate the task difficulty and compare the advantage of learning tasks together versus separately.