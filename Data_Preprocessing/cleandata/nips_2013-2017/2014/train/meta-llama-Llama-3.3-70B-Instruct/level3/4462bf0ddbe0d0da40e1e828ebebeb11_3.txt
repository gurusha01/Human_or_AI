This paper proposes a novel framework for learning distributed representations of attributes, which can be jointly learned with word embeddings. The authors introduce a third-order model where word context and attribute vectors interact multiplicatively to predict the next word in a sequence, leading to the notion of conditional word similarity. The paper provides a thorough explanation of the proposed model, including the use of a word embedding tensor and the learning of attribute representations.
The paper is well-written, and the authors provide a clear and concise explanation of their approach. The experiments demonstrate the effectiveness of the proposed model on several tasks, including sentiment classification, cross-lingual document classification, and blog authorship attribution. The results show that the proposed model outperforms several baselines and achieves competitive results with state-of-the-art approaches.
One of the strengths of the paper is the novelty of the proposed approach, which combines the ideas of word embeddings and attribute representations in a unique way. The use of a word embedding tensor and the learning of attribute representations through a multiplicative interaction with word context is a new and interesting contribution to the field.
Another strength of the paper is the thorough evaluation of the proposed model on several tasks. The authors provide a detailed analysis of the results, including qualitative and quantitative evaluations, which helps to demonstrate the effectiveness of the proposed approach.
However, there are some weaknesses in the paper. One of the limitations is the lack of comparison with other state-of-the-art models on some of the tasks. For example, on the sentiment classification task, the authors only compare their model with a few baselines, but not with other recent models that have achieved state-of-the-art results.
Another limitation is the lack of analysis of the learned attribute representations. While the authors provide some qualitative examples of the learned representations, it would be interesting to see a more thorough analysis of the properties of these representations and how they relate to the tasks being performed.
In terms of the conference guidelines, the paper meets most of the criteria. The paper is well-written, and the authors provide a clear and concise explanation of their approach. The experiments are thorough, and the results are well-analyzed. However, the paper could benefit from a more detailed comparison with other state-of-the-art models and a more thorough analysis of the learned attribute representations.
Arguments for acceptance:
* The paper proposes a novel and interesting approach to learning distributed representations of attributes.
* The experiments demonstrate the effectiveness of the proposed model on several tasks.
* The paper is well-written, and the authors provide a clear and concise explanation of their approach.
Arguments against acceptance:
* The paper lacks a detailed comparison with other state-of-the-art models on some of the tasks.
* The analysis of the learned attribute representations is limited.
* The paper could benefit from a more thorough evaluation of the proposed model on more tasks and datasets.
Overall, I would recommend accepting the paper, but with some revisions to address the limitations mentioned above. The paper has the potential to make a significant contribution to the field, and with some additional work, it could be even stronger.