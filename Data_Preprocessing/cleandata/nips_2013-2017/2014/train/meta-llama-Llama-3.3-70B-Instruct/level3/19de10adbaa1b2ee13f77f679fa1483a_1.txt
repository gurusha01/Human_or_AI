This paper presents a novel framework for constructing prior distributions with structured variables, utilizing the maximum entropy principle to define the prior as the information projection of a base distribution onto the constraint set of interest. The authors demonstrate the effectiveness of their approach in the context of sparse structure, where the optimal prior is intractable, and propose a family of parameterized approximations indexed by subsets of the domain. The paper is well-written, and the authors provide a clear and concise explanation of their methodology.
The strengths of this paper include its technical soundness, clarity, and significance. The authors provide a thorough analysis of their approach, including theoretical guarantees and experimental results on simulated and real-world data. The use of the maximum entropy principle to define the prior is a novel and interesting contribution, and the authors demonstrate its effectiveness in capturing structured variables. The experimental results show that the proposed approach outperforms several baseline models, including Lasso and Spike and Slab, in terms of support recovery and predictive accuracy.
One potential weakness of the paper is that the approach may not be scalable to very large datasets, as the computation of the information projection requires the calculation of a normalization constant, which can be computationally expensive. However, the authors propose a greedy forward selection procedure, which is guaranteed to achieve within a (1-1/e) factor of the global optimum, and demonstrate its effectiveness in practice.
The significance of this paper lies in its potential to improve the accuracy and interpretability of Bayesian models in high-dimensional settings, where structured variables are common. The authors demonstrate the effectiveness of their approach in the context of functional neuroimaging data, where the proposed approach achieves a positive R2 value, indicating good predictive performance.
In terms of originality, the paper presents a novel combination of familiar techniques, including the maximum entropy principle and sparse structure. The authors provide a thorough review of related work and demonstrate how their approach differs from previous contributions.
Overall, I would recommend accepting this paper, as it presents a significant contribution to the field of Bayesian modeling and demonstrates the effectiveness of the proposed approach in practice. The paper is well-written, and the authors provide a clear and concise explanation of their methodology, making it accessible to a wide range of readers.
Arguments pro acceptance:
* The paper presents a novel framework for constructing prior distributions with structured variables.
* The authors demonstrate the effectiveness of their approach in the context of sparse structure.
* The paper is well-written, and the authors provide a clear and concise explanation of their methodology.
* The experimental results show that the proposed approach outperforms several baseline models.
Arguments con acceptance:
* The approach may not be scalable to very large datasets.
* The computation of the information projection requires the calculation of a normalization constant, which can be computationally expensive.
However, the authors propose a greedy forward selection procedure, which is guaranteed to achieve within a (1-1/e) factor of the global optimum, and demonstrate its effectiveness in practice, mitigating these concerns.