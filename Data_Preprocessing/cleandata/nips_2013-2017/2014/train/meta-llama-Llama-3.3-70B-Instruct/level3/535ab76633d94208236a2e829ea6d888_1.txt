This paper proposes a novel approach to identify and filter out adversarial workers in crowdsourced classification problems. The authors introduce a method that assigns reputation values to workers based on their voting agreements with others and propose two versions of penalty algorithms. The paper provides theoretical analysis and experimental results on synthetic and real datasets to support their approach.
The problem addressed in the paper is interesting, and the proposed method has potential applications in crowdsourcing and machine learning. However, I have some concerns about the strong assumption of perfect honest workers in the theoretical analysis. This assumption may not hold in practice, and it would be beneficial to relax this assumption and analyze the robustness of the proposed method to worker errors.
The experimental results are promising, but I think they could be improved by showing all possible settings and modifying the ITER algorithm to handle datasets with varying task completion rates. Additionally, the paper's contribution is limited by the strong assumption of perfect workers, but the empirical evaluations help mitigate this shortcoming.
Here are some arguments for and against acceptance:
Arguments for acceptance:
* The paper proposes a novel approach to identify and filter out adversarial workers in crowdsourced classification problems.
* The authors provide theoretical analysis and experimental results to support their approach.
* The proposed method has potential applications in crowdsourcing and machine learning.
Arguments against acceptance:
* The strong assumption of perfect honest workers in the theoretical analysis may not hold in practice.
* The experimental results could be improved by showing all possible settings and modifying the ITER algorithm to handle datasets with varying task completion rates.
* The paper's contribution is limited by the strong assumption of perfect workers.
Overall, I think this is a borderline paper for acceptance. While the proposed method has potential, the strong assumption of perfect workers and the limitations of the experimental results are significant concerns. However, the empirical evaluations and the potential applications of the proposed method make it a worthwhile contribution to the field. 
Quality: 7
The paper is well-written, and the authors provide a clear explanation of their proposed method. However, the strong assumption of perfect honest workers in the theoretical analysis is a significant limitation.
Clarity: 8
The paper is well-organized, and the authors provide a clear explanation of their proposed method. The experimental results are easy to follow, and the tables and figures are well-presented.
Originality: 8
The paper proposes a novel approach to identify and filter out adversarial workers in crowdsourced classification problems. The authors provide a unique perspective on the problem and propose a new method to address it.
Significance: 7
The paper's contribution is significant, but it is limited by the strong assumption of perfect workers. The proposed method has potential applications in crowdsourcing and machine learning, but it requires further development and evaluation to fully realize its potential.