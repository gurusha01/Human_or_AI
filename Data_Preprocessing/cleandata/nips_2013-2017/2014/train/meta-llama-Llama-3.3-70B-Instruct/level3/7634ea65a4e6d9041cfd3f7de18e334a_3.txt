This paper proposes a novel framework for online multi-task learning with a shared annotator, where multiple learners share a single annotator with limited bandwidth. The authors introduce an algorithm, SHAMPO, which uses a combination of exploration and exploitation to select tasks to be labeled and updated. The algorithm is analyzed in the mistake-bound model, and the authors provide bounds on the expected cumulative number of mistakes.
The paper is well-written, and the authors provide a clear and concise introduction to the problem setting and the proposed algorithm. The analysis is thorough, and the authors provide a detailed proof of the mistake bound. The experimental results are also impressive, showing that SHAMPO outperforms other algorithms in various settings.
One of the strengths of the paper is its ability to handle multiple tasks with different levels of difficulty. The authors show that SHAMPO can focus the annotator on the harder instances, which improves overall performance. The paper also provides a good balance between theory and practice, with a clear and concise presentation of the algorithm and its analysis, as well as a thorough evaluation of its performance in various settings.
However, there are a few areas where the paper could be improved. One potential weakness is the lack of comparison to other algorithms in the experimental results. While the authors compare SHAMPO to a few baselines, it would be useful to see a more comprehensive comparison to other state-of-the-art algorithms. Additionally, the paper could benefit from a more detailed discussion of the limitations of the proposed framework and potential avenues for future work.
In terms of the conference guidelines, the paper meets all the criteria for quality, clarity, originality, and significance. The paper is technically sound, well-written, and provides a clear and concise introduction to the problem setting and the proposed algorithm. The analysis is thorough, and the authors provide a detailed proof of the mistake bound. The experimental results are also impressive, showing that SHAMPO outperforms other algorithms in various settings.
Overall, I would recommend accepting this paper to the conference. The paper provides a significant contribution to the field of online multi-task learning, and the authors have done a thorough job of analyzing and evaluating the proposed algorithm.
Arguments pro acceptance:
* The paper proposes a novel framework for online multi-task learning with a shared annotator.
* The algorithm is analyzed in the mistake-bound model, and the authors provide bounds on the expected cumulative number of mistakes.
* The experimental results are impressive, showing that SHAMPO outperforms other algorithms in various settings.
* The paper provides a good balance between theory and practice, with a clear and concise presentation of the algorithm and its analysis, as well as a thorough evaluation of its performance in various settings.
Arguments con acceptance:
* The paper could benefit from a more comprehensive comparison to other state-of-the-art algorithms.
* The paper could benefit from a more detailed discussion of the limitations of the proposed framework and potential avenues for future work.