This paper proposes a novel approach to kernel approximation, called Sparse Random Features, which learns a sparse non-linear predictor by minimizing an l1-regularized objective function over the Hilbert Space induced from a kernel function. The authors interpret the algorithm as Randomized Coordinate Descent in an infinite-dimensional space and show that it converges to a solution within Îµ-precision of that using an exact kernel method.
The paper is well-written and provides a clear explanation of the proposed approach. The authors also provide a thorough analysis of the convergence behavior of the algorithm and compare it to existing methods, such as Boosting. The experimental results demonstrate the effectiveness of the proposed approach in achieving sparse solutions that require less memory and prediction time while maintaining comparable performance on regression and classification tasks.
However, there are some limitations to the paper. The authors do not provide a clear discussion on the significance of the results and how they might carry over to other domains or lead to significant algorithmic improvements. Additionally, the empirical results rely on game-specific tunings, which devalues the results and raises questions about the effectiveness of uniform environment parametrization.
The paper could be improved by studying how well a policy or value function can be summarized into a deep network and exploring other research directions, such as regression on empirical return. The handling of partial observability is also an understudied question that needs further investigation, particularly in relation to the emergence of features from policy compilation.
In terms of originality, the paper proposes a new interpretation of Random Features that justifies its usage with l1-regularization, which is a novel contribution to the field. However, the relationship between the proposed UCC-I algorithm and the DAgger algorithm should be discussed to understand potential differences in sampling guarantees.
Overall, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. However, the paper could benefit from a more detailed discussion on the significance of the results and the potential applications of the proposed approach.
Arguments for acceptance:
* The paper proposes a novel approach to kernel approximation, which is a significant contribution to the field.
* The authors provide a thorough analysis of the convergence behavior of the algorithm and compare it to existing methods.
* The experimental results demonstrate the effectiveness of the proposed approach in achieving sparse solutions.
Arguments against acceptance:
* The paper lacks a clear discussion on the significance of the results and how they might carry over to other domains or lead to significant algorithmic improvements.
* The empirical results rely on game-specific tunings, which devalues the results and raises questions about the effectiveness of uniform environment parametrization.
* The paper could benefit from a more detailed discussion on the relationship between the proposed UCC-I algorithm and the DAgger algorithm.