This paper proposes a novel framework for online multi-task learning with a shared annotator, where multiple learners share a single annotator with limited bandwidth. The authors introduce an algorithm, SHAMPO, which learns to select a task to query its label and updates its models accordingly. The algorithm is analyzed in the mistake-bound model, and the authors provide bounds on the expected cumulative number of mistakes.
The paper is well-written, and the authors provide a clear and concise explanation of the problem setting, the algorithm, and the analysis. The experimental results demonstrate the effectiveness of the algorithm in various settings, including multi-task binary classification and contextual bandits.
The strengths of the paper include:
* The proposal of a novel framework for online multi-task learning with a shared annotator, which addresses a practical problem in many real-world applications.
* The introduction of an algorithm, SHAMPO, which is shown to be effective in various settings.
* The provision of bounds on the expected cumulative number of mistakes, which provides a theoretical guarantee on the performance of the algorithm.
The weaknesses of the paper include:
* The similarity with previous work on selective sampling and contextual bandits, which may raise concerns about the novelty of the approach.
* The lack of a clear comparison with other algorithms in the same setting, which makes it difficult to assess the relative performance of SHAMPO.
* The need for further investigation on the choice of hyperparameters, such as the tradeoff parameter b, and the prior distribution over tasks.
Arguments for acceptance:
* The paper proposes a novel framework for online multi-task learning with a shared annotator, which addresses a practical problem in many real-world applications.
* The algorithm, SHAMPO, is shown to be effective in various settings, including multi-task binary classification and contextual bandits.
* The provision of bounds on the expected cumulative number of mistakes provides a theoretical guarantee on the performance of the algorithm.
Arguments against acceptance:
* The similarity with previous work on selective sampling and contextual bandits may raise concerns about the novelty of the approach.
* The lack of a clear comparison with other algorithms in the same setting makes it difficult to assess the relative performance of SHAMPO.
* The need for further investigation on the choice of hyperparameters, such as the tradeoff parameter b, and the prior distribution over tasks.
Overall, I recommend accepting the paper, as it proposes a novel framework for online multi-task learning with a shared annotator and provides a effective algorithm, SHAMPO, with theoretical guarantees. However, the authors should be encouraged to address the weaknesses of the paper, including the similarity with previous work and the need for further investigation on hyperparameters.