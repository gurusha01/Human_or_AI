This paper proposes a unified framework for learning distributed representations of attributes in text data, which can be jointly learned with word embeddings. The authors introduce a third-order model where word context and attribute vectors interact multiplicatively to predict the next word in a sequence, leading to the notion of conditional word similarity. The paper demonstrates strong performance on several NLP tasks, including sentiment classification, cross-lingual document classification, and blog authorship attribution.
The paper has a strong mathematical foundation, and the experimental results show positive performance compared to other algorithms. The use of a tensor decomposition to model attribute-word interactions is a novel approach, and the authors provide a clear explanation of the model and its components. The paper also provides a thorough evaluation of the model on various tasks, including qualitative and quantitative results.
However, there are some areas that require further clarification and improvement. The choice of tuning parameters for different algorithms and data is unclear, and the authors should provide more details on how these parameters were selected. Additionally, the scalability of the approach to high-dimensional data is uncertain, particularly for data with more than 3 dimensions. The results lack confidence intervals, specifically in the multiple fold cross-validation results, which makes it difficult to assess the significance of the results.
The comparison between the proposed model and other algorithms, such as Tucker and Ortho, requires further discussion on significance and implications. The paper contains minor typos, which should be corrected to improve the overall quality of the paper. Furthermore, the authors could explore the application of their approach to more impactful areas, such as classifying anomalies in climate data.
Overall, the paper presents a novel and well-motivated approach to learning distributed representations of attributes in text data. While there are some areas that require further clarification and improvement, the paper demonstrates strong performance on several NLP tasks and has the potential to contribute to the field of natural language processing.
Arguments pro acceptance:
* The paper proposes a novel and well-motivated approach to learning distributed representations of attributes in text data.
* The paper demonstrates strong performance on several NLP tasks, including sentiment classification, cross-lingual document classification, and blog authorship attribution.
* The use of a tensor decomposition to model attribute-word interactions is a novel approach, and the authors provide a clear explanation of the model and its components.
Arguments con acceptance:
* The choice of tuning parameters for different algorithms and data is unclear, and the authors should provide more details on how these parameters were selected.
* The scalability of the approach to high-dimensional data is uncertain, particularly for data with more than 3 dimensions.
* The results lack confidence intervals, specifically in the multiple fold cross-validation results, which makes it difficult to assess the significance of the results.