This paper proposes a novel algorithm for Bandit Convex Optimization (BCO) with strongly-convex and smooth loss functions, achieving a near-optimal regret bound of Õ(√T). The algorithm employs a "shrinking exploration" scheme, which is a key ingredient in achieving this bound. The paper is well-written, addressing an interesting problem with both computational results and a thorough analysis.
The strengths of the paper include its ability to tackle a fundamental problem in online learning, providing a significant improvement over previous works. The algorithm is efficient and easy to implement, making it a practical solution for real-world problems. The paper also provides a thorough analysis of the algorithm's performance, including a proof of the regret bound.
One potential weakness of the paper is that the success of the approach may be attributed more to the problem space decomposition into features rather than the rational inference component. Additionally, the paper could benefit from a comparison to a reinforcement learning (RL) model with function approximation to further demonstrate the effectiveness of the approach.
The paper has some minor issues, including tiny fonts in Figure 1, grammatical errors, and complex equations that are hard to follow. However, these issues do not detract from the overall quality of the paper.
The paper's comparison to other algorithms is commendable and one of its strongest aspects, setting a good example for thorough evaluation in research. The authors provide a clear and concise summary of previous works and demonstrate how their algorithm improves upon existing solutions.
Overall, I would argue in favor of accepting this paper. The strengths of the paper, including its novel algorithm and thorough analysis, outweigh its weaknesses. The paper makes a significant contribution to the field of online learning and has the potential to impact real-world applications.
Arguments pro acceptance:
* The paper proposes a novel and efficient algorithm for BCO with strongly-convex and smooth loss functions.
* The algorithm achieves a near-optimal regret bound of Õ(√T).
* The paper provides a thorough analysis of the algorithm's performance, including a proof of the regret bound.
* The paper compares favorably to previous works and demonstrates a significant improvement over existing solutions.
Arguments con acceptance:
* The success of the approach may be attributed more to the problem space decomposition into features rather than the rational inference component.
* The paper could benefit from a comparison to an RL model with function approximation.
* The paper has some minor issues, including tiny fonts in Figure 1, grammatical errors, and complex equations that are hard to follow.