This paper introduces a new class of multi-class boosting algorithms with regularized base learners, which shows improvement over other approaches in experiments. However, the title of the paper is misleading as the approach is not "deep" in the sense of hierarchical representation, but rather a shallow architecture with a single layer of trees. 
The paper's claim that boosting has been observed to overfit in practice is outdated, as recent studies have shown that boosting can perform well with large trees and proper hyper-parameter optimization. Furthermore, the idea of adaptive regularization of base classifiers is not new and has been proposed in previous papers, such as \cite{KeWa04}.
The paper lacks a comprehensive survey of state-of-the-art multi-class boosting algorithms, including AOSO, ABC, and AB.MH with Hamming trees. The experimental setup is also flawed, as the authors validated on the test set, which can lead to overestimation of performance and tainted comparisons between algorithms.
The results show no significant improvement with the added regularization, contradicting the main message of the paper. The algorithm's good performance may be due to the tree-building procedure rather than the regularization. The paper tries to combine theoretical and practical contributions, but the theoretical results are irrelevant for practitioners, and the practical results are irrelevant for theoreticians, making it seem like two papers in one with a false conclusion.
Arguments for acceptance:
- The paper introduces a new class of multi-class boosting algorithms with regularized base learners.
- The experimental results show improvement over other approaches.
Arguments against acceptance:
- The title of the paper is misleading.
- The claim that boosting has been observed to overfit in practice is outdated.
- The idea of adaptive regularization of base classifiers is not new.
- The paper lacks a comprehensive survey of state-of-the-art multi-class boosting algorithms.
- The experimental setup is flawed.
- The results show no significant improvement with the added regularization.
- The paper tries to combine theoretical and practical contributions in a way that seems like two papers in one with a false conclusion.
Overall, while the paper has some positive aspects, the flaws and outdated claims outweigh the benefits, making it a weak submission.