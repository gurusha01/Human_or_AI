This paper proposes a novel approach to kernel approximation, called Sparse Random Features, which combines the benefits of random feature maps and sparse learning. The authors provide a thorough analysis of the algorithm, including its convergence properties and relations to existing methods, such as kernel methods and boosting. The experimental results demonstrate the effectiveness of the proposed approach in achieving sparse solutions with comparable performance to kernel methods, while reducing computational costs.
The paper is well-organized, and the authors provide a clear explanation of the technical details. The writing is generally clear, although some sections could be improved for better readability. The use of notation is consistent throughout the paper, and the authors provide a comprehensive list of references.
The key strengths of the paper are:
1. Novel approach: The proposed Sparse Random Features algorithm is a new and interesting approach to kernel approximation, which addresses the limitations of existing methods.
2. Theoretical analysis: The authors provide a thorough theoretical analysis of the algorithm, including its convergence properties and relations to existing methods.
3. Experimental results: The experimental results demonstrate the effectiveness of the proposed approach in achieving sparse solutions with comparable performance to kernel methods.
However, there are some areas for improvement:
1. Clarity: Some sections, such as the introduction and related work, could be improved for better readability.
2. Notation: While the notation is consistent throughout the paper, some symbols could be defined more clearly.
3. Comparison to existing methods: The authors could provide a more detailed comparison of their approach to existing methods, including kernel methods and boosting.
In terms of the conference guidelines, the paper addresses the following criteria:
1. Quality: The paper is technically sound, and the authors provide a thorough analysis of the algorithm.
2. Clarity: The writing is generally clear, although some sections could be improved for better readability.
3. Originality: The proposed approach is novel and interesting.
4. Significance: The paper demonstrates the effectiveness of the proposed approach in achieving sparse solutions with comparable performance to kernel methods.
Overall, I recommend accepting the paper, but with some revisions to improve clarity and readability. The authors should also consider providing a more detailed comparison of their approach to existing methods. 
Arguments for acceptance:
* The paper proposes a novel approach to kernel approximation.
* The authors provide a thorough theoretical analysis of the algorithm.
* The experimental results demonstrate the effectiveness of the proposed approach.
Arguments against acceptance:
* Some sections could be improved for better readability.
* The comparison to existing methods could be more detailed.
* The notation could be defined more clearly in some places.