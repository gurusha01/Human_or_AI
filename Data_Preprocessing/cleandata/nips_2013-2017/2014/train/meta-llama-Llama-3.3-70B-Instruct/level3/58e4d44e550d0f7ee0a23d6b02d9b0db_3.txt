This paper presents a novel control-theoretic framework for building functioning attractor networks that satisfy key physiological constraints, including Dale's law and the presence of recurrent and sparse synaptic connections. The authors propose a method to optimize network parameters, including synaptic connectivity, to embed multiple analog memories as stable fixed points of the dynamics. The resulting networks operate in the balanced regime, are robust to corruptions of the memory cue and ongoing noise, and explain the reduction of trial-to-trial variability following stimulus onset.
The paper is technically sound, and the writing is clear and well-organized. The authors provide a detailed description of their methods and results, including examples of successful storage and recall of analog memories. The use of a rate-based formulation of the circuit dynamics raises questions about the applicability of the method to understanding spiking memory networks, but the authors acknowledge this limitation and suggest potential avenues for future research.
One of the strengths of the paper is its ability to overcome the limitations of previous models, including the violation of Dale's law and the restriction of memory representation to a binary format. The authors' approach also provides a more realistic representation of neuronal activity, with graded levels of activity and firing rates that are kept within a limited range due to dynamic feedback inhibition.
However, the significance and impact of the presented research are not entirely clear. The authors compare their results to those of a previous SODA paper, but it is unclear how their work advances the state of the art in a demonstrable way. The paper's focus on the neural substrate of memory is important, but it is not clear how the results will be used in practice or how they will contribute to a deeper understanding of memory and its neural mechanisms.
Overall, the paper is well-written and technically sound, but its impact and significance are questionable. The authors provide a novel framework for building attractor networks, but it is unclear how this work will contribute to the broader field of neuroscience and artificial intelligence.
Arguments pro acceptance:
* The paper presents a novel control-theoretic framework for building attractor networks that satisfy key physiological constraints.
* The authors provide a detailed description of their methods and results, including examples of successful storage and recall of analog memories.
* The paper overcomes the limitations of previous models, including the violation of Dale's law and the restriction of memory representation to a binary format.
Arguments con acceptance:
* The significance and impact of the presented research are not entirely clear.
* The paper's focus on the neural substrate of memory is important, but it is not clear how the results will be used in practice or how they will contribute to a deeper understanding of memory and its neural mechanisms.
* The comparison to previous work is limited, and it is unclear how the authors' approach advances the state of the art in a demonstrable way.