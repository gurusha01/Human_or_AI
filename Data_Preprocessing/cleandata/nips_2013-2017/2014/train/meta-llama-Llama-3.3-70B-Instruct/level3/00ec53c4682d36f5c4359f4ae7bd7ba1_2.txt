This paper proposes a novel framework for learning distributed representations of attributes, which can be jointly learned with word embeddings. The authors introduce a third-order model where word context and attribute vectors interact multiplicatively to predict the next word in a sequence, leading to the notion of conditional word similarity. The model is evaluated on several NLP tasks, including sentiment classification, cross-lingual document classification, and blog authorship attribution, demonstrating strong performance and outperforming several baselines.
The paper is well-written, and the authors provide a clear and concise explanation of their model and experiments. The use of a tensor decomposition to represent word embeddings and attribute vectors is a novel and interesting approach. The experiments demonstrate the effectiveness of the model in capturing attribute-specific word similarities and improving performance on various NLP tasks.
One of the strengths of the paper is its ability to capture complex interactions between words and attributes, allowing for more nuanced and context-dependent representations. The authors also provide a thorough comparison of their model with existing approaches, highlighting its advantages and limitations.
However, there are some potential weaknesses and areas for improvement. For example, the model's performance on low-resource tasks, such as cross-lingual document classification with limited parallel data, could be further improved. Additionally, the authors could explore different frame sampling schemes for the spatial stream, as suggested by the reviewer.
Overall, the paper makes a significant contribution to the field of NLP, and its ideas and approaches have the potential to be widely adopted. The authors demonstrate a good understanding of the related work and provide a clear and well-organized presentation of their research.
Arguments pro acceptance:
* The paper proposes a novel and interesting approach to learning distributed representations of attributes.
* The model demonstrates strong performance on several NLP tasks, outperforming several baselines.
* The authors provide a thorough comparison of their model with existing approaches, highlighting its advantages and limitations.
* The paper is well-written, and the authors provide a clear and concise explanation of their model and experiments.
Arguments con acceptance:
* The model's performance on low-resource tasks could be further improved.
* The authors could explore different frame sampling schemes for the spatial stream.
* Some of the experiments could be more thoroughly evaluated, such as the use of conditional word similarity.
Quality: 8/10
Clarity: 9/10
Originality: 8/10
Significance: 8/10
Recommendation: Accept with minor revisions. The authors should address the potential weaknesses and areas for improvement mentioned above, and provide more thorough evaluations of their experiments.