This paper proposes a novel approach to multi-task learning using a tensor to represent task relatedness and enforces a low-rank structure to transfer knowledge among tasks. The authors introduce a new norm, called the scaled latent trace norm, which improves upon existing approaches like latent trace norm by normalizing along each dimension to address heterogeneous task dimensions. The paper provides a unified comparison of different norms and derives error bounds, relating them to the expected dual norm.
The core novelty of the paper is the scaled version of traditional latent trace norm, which suggests treating each task differently due to certain reasons. The authors argue that the proposed norm is better suited for multitask learning problems where the dimensions or ranks are heterogeneous. The paper also provides a theoretical analysis of the excess risk of the proposed norm and compares it with existing norms.
However, I have some concerns regarding the usefulness of tensor multi-task learning. Is it necessary to go beyond two-dimensional cases, and is the additional time cost worth the potential performance increase? The authors should provide more justification for the need for tensor-based approaches and discuss the trade-offs between performance and computational cost.
Furthermore, I would like to know more about the algorithm used to solve the formulation with the new norm, its complexity, and convergence time. The authors should provide more details on the optimization procedure and discuss the scalability of their approach.
In terms of experiments, the authors should compare their method to "flat" multi-task learning methods, such as trace norm, in terms of performance and efficiency. Additionally, I find it inconsistent that the authors use different evaluation metrics for the school data and suggest using MSE for consistency.
Minor comments include notation and typo issues, such as the confusing notation "W_{(k)}^{(k)}" and a typo "Turing" instead of "Turning". Overall, the paper is well-written, and the authors provide a clear and concise presentation of their approach. However, addressing the above concerns and providing more detailed explanations and justifications will strengthen the paper.
Arguments pro acceptance:
* The paper proposes a novel approach to multi-task learning using a tensor to represent task relatedness.
* The authors introduce a new norm, called the scaled latent trace norm, which improves upon existing approaches.
* The paper provides a unified comparison of different norms and derives error bounds.
Arguments con acceptance:
* The usefulness of tensor multi-task learning is not fully justified.
* The authors do not provide enough details on the optimization procedure and scalability of their approach.
* The paper uses different evaluation metrics for different datasets, which is inconsistent.