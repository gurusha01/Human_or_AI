This paper proposes a novel control-theoretic framework for building functioning attractor networks that satisfy key physiological constraints, including Dale's law and the presence of recurrent and sparse synaptic connections. The authors directly optimize network parameters to force sets of arbitrary analog patterns to become stable fixed points of the dynamics, resulting in networks that operate in the balanced regime and are robust to corruptions of the memory cue and ongoing noise.
The paper's main strengths lie in its ability to overcome previous limitations in modeling memory networks, such as the violation of Dale's law and the restriction of memory representations to binary formats. The authors' use of a rate-based formulation of circuit dynamics and a threshold-quadratic gain function allows for the creation of networks with realistic firing rate dynamics and connectivities that obey Dale's law.
However, the paper also has some weaknesses. The experiments are limited to a small number of neurons (n = 150) and a specific type of noise (Gaussian white noise), which raises questions about the scalability and generalizability of the approach. Additionally, the comparison to other methods is insufficient, with only a brief mention of the ideal observer and no comparison to more advanced state-of-the-art methods for binary classification tasks.
The related work section is also inadequate, failing to sufficiently discuss related works on discriminative feature-learning models, which motivates the paper's work. The authors could have provided a more comprehensive review of existing literature on attractor networks and memory models, highlighting the key differences and advantages of their approach.
In terms of originality, the paper's combination of control-theoretic framework and factor models is novel, but the extension of Bayesian linear SVM to a nonlinear version using standard kernel tricks is quite trivial. The paper's significance lies in its ability to provide a new perspective on the neural substrate of memory, but the results are not yet conclusive, and more experiments are needed to fully demonstrate the efficacy of the approach.
Arguments pro acceptance:
* The paper proposes a novel control-theoretic framework for building attractor networks that satisfy key physiological constraints.
* The authors demonstrate the robustness of their approach to corruptions of the memory cue and ongoing noise.
* The paper provides a new perspective on the neural substrate of memory.
Arguments con acceptance:
* The experiments are limited to a small number of neurons and a specific type of noise.
* The comparison to other methods is insufficient.
* The related work section is inadequate.
* The paper's originality is limited, with the extension of Bayesian linear SVM to a nonlinear version being quite trivial.
Overall, while the paper has some strengths, its weaknesses and limitations suggest that it may not be ready for acceptance in its current form. With additional experiments, a more comprehensive related work section, and a clearer comparison to other methods, the paper could be significantly improved.