This paper proposes a new algorithm for Bandit Convex Optimization (BCO) with strongly-convex and smooth loss functions, achieving a near-optimal regret bound of $\tilde{O}(\sqrt{T})$. This matches the existing best lower bound, providing a significant improvement over previous works. The algorithm employs a novel "shrinking exploration" scheme, which is crucial in achieving the optimal regret bound.
The paper provides a clear and well-structured introduction to the problem of BCO, including a thorough review of existing results and a clear explanation of the key concepts and challenges. The technical sections of the paper are generally well-written, with clear and concise proofs of the main results.
However, there are some areas where the paper could be improved. The presentation of existing and new results could be clearer, with better distinction between lemmas and the main theorem. Additionally, the paper dedicates too much space to reviewing existing results, delaying the presentation of the main result until the end of page 6. Some symbols, such as $\delta$ in Equation (4), are not clearly defined, and Lemma 9's applicability to any $\omega$ is not explicitly stated.
The algorithm presentation could also be improved, particularly Algorithm 2, which should be rewritten without a loop and with $\nabla ht(xt)$ as inputs. Furthermore, the paper could benefit from more discussion on the significance and implications of the results, as well as potential future directions.
In terms of the conference guidelines, the paper meets the criteria for quality, originality, and significance. The paper is technically sound, with well-supported claims and a clear analysis of the results. The problem of BCO is important and relevant to the field, and the paper provides a significant contribution to the understanding of optimal regret rates. The paper is also well-written and easy to follow, making it accessible to a wide range of readers.
Overall, I would recommend accepting this paper, but with some revisions to address the issues mentioned above. The paper has the potential to make a significant impact in the field, and with some improvements, it could be even stronger.
Arguments pro acceptance:
* The paper provides a significant improvement over previous works, achieving a near-optimal regret bound of $\tilde{O}(\sqrt{T})$.
* The algorithm is novel and well-motivated, with a clear explanation of the key concepts and challenges.
* The paper is well-structured and easy to follow, making it accessible to a wide range of readers.
Arguments con acceptance:
* The presentation of existing and new results could be clearer, with better distinction between lemmas and the main theorem.
* The paper dedicates too much space to reviewing existing results, delaying the presentation of the main result.
* Some symbols and results are not clearly defined or stated.