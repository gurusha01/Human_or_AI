This paper presents a novel approach to policy search in continuous control tasks, combining the benefits of model-based and model-free methods. The authors propose a hybrid method that uses iteratively refitted local linear models to optimize trajectory distributions, which can be used within the framework of guided policy search to learn policies with arbitrary parameterization. The key idea is to restrict the change in the trajectory distribution at each iteration, ensuring that the time-varying linear model remains valid under the new distribution.
The paper is well-written, and the authors provide a clear and concise explanation of the proposed method, including the mathematical derivations and algorithmic details. The experimental evaluation is thorough, and the results demonstrate the effectiveness of the proposed method in various simulated robotic manipulation and locomotion tasks.
The strengths of the paper include:
* The proposed method combines the strengths of model-based and model-free approaches, allowing for efficient optimization of trajectory distributions and learning of complex policies.
* The use of local linear models and a background dynamics distribution as a prior reduces the sample complexity and enables the method to handle complex and discontinuous dynamics.
* The experimental evaluation demonstrates the effectiveness of the proposed method in various tasks, including partially observed environments.
The weaknesses of the paper include:
* The method relies on the assumption that time-varying linear-Gaussians are a reasonable local approximation for the dynamics, which may not always be the case.
* The computational cost of the method may be high, particularly when using the GMM to construct a prior for the dynamics.
Overall, the paper presents a significant contribution to the field of policy search and reinforcement learning, and the proposed method has the potential to be applied to a wide range of complex control tasks.
Arguments pro acceptance:
* The paper presents a novel and well-motivated approach to policy search, combining the strengths of model-based and model-free methods.
* The experimental evaluation is thorough and demonstrates the effectiveness of the proposed method in various tasks.
* The paper is well-written, and the authors provide a clear and concise explanation of the proposed method.
Arguments con acceptance:
* The method relies on a strong assumption about the local linearity of the dynamics, which may not always be the case.
* The computational cost of the method may be high, particularly when using the GMM to construct a prior for the dynamics.
Recommendation: Accept, with minor revisions to address the potential limitations and assumptions of the proposed method.