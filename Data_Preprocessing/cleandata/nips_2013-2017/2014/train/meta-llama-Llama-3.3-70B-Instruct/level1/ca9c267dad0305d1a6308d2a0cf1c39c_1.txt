This paper introduces a new multi-task framework where K online learners share a single annotator with limited bandwidth. The authors propose an algorithm, SHAMPO, which learns in this setting and bounds its performance in the worst-case scenario. The algorithm is then applied to two contextual bandit problems, one-vs-rest and one-vs-one, and is shown to outperform other algorithms.
The paper is well-written and easy to follow, with clear explanations of the problem setting, algorithm, and analysis. The authors provide a thorough review of related work and demonstrate the effectiveness of their algorithm through empirical studies on various datasets.
The strengths of the paper include:
* The introduction of a new multi-task framework that addresses the problem of shared annotators, which is a common challenge in real-world applications.
* The proposal of a novel algorithm, SHAMPO, which is shown to be effective in this setting.
* The provision of a thorough analysis of the algorithm's performance, including bounds on the expected cumulative number of mistakes.
* The application of the algorithm to contextual bandit problems, which demonstrates its versatility.
The weaknesses of the paper include:
* The assumption that the input spaces for each task are the same, which may not always be the case in practice.
* The use of a uniform prior for the query distribution, which may not be optimal in all cases.
* The lack of comparison to other multi-task learning algorithms that do not use a shared annotator.
Arguments for acceptance:
* The paper introduces a new and interesting problem setting that has not been well-studied in the literature.
* The proposed algorithm, SHAMPO, is novel and effective, and the analysis provides valuable insights into its performance.
* The empirical studies demonstrate the effectiveness of the algorithm in various settings.
Arguments against acceptance:
* The paper assumes a uniform prior for the query distribution, which may not be optimal in all cases.
* The comparison to other algorithms is limited, and it is not clear how SHAMPO would perform in comparison to other multi-task learning algorithms.
Overall, I believe that the paper is well-written and makes a significant contribution to the field of multi-task learning. The introduction of a new problem setting and the proposal of a novel algorithm make it a strong candidate for acceptance. However, the authors could improve the paper by addressing the weaknesses mentioned above, such as exploring non-uniform priors and comparing SHAMPO to other multi-task learning algorithms.