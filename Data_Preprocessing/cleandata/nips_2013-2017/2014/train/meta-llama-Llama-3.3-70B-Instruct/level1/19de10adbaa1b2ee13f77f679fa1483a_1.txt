This paper introduces Deep Attention Selective Networks (dasNet), a novel architecture that combines the strengths of convolutional neural networks (CNNs) with the power of sequential processing and reinforcement learning. The authors propose a non-stationary CNN that can adapt its behavior post-training, allowing it to iteratively focus its internal attention on the most discriminative features in an image. This is achieved through a feedback structure that modulates the activity of the convolutional filters, enabling the network to correct its initial classification guesses.
The paper is well-written, and the authors provide a clear and concise overview of the dasNet architecture, its components, and the training procedure. The use of Separable Natural Evolution Strategies (SNES) to evolve the policy is an interesting choice, and the authors provide a detailed explanation of the algorithm.
The experiments on CIFAR-10 and CIFAR-100 demonstrate the effectiveness of dasNet, with a relative improvement of 6% over the vanilla CNN. The visualizations of the filter emphasis and de-emphasis patterns provide valuable insights into the network's decision-making process.
The paper's strengths include:
* Novel architecture that combines CNNs with sequential processing and reinforcement learning
* Effective use of SNES to evolve the policy
* State-of-the-art results on CIFAR-10 and CIFAR-100
* Well-written and clear explanation of the architecture and training procedure
The paper's weaknesses include:
* The training procedure is computationally expensive, requiring 4 days on a GTX 560 Ti GPU
* The number of steps (T) is experimentally determined and fixed at 5, which may not be optimal for all datasets
* The authors do not provide a detailed analysis of the dasNet policy's information content, relying on a simple nearest-neighbor and logistic regression classification
Arguments pro acceptance:
* The paper presents a novel and effective architecture that advances the state-of-the-art in image classification
* The use of SNES to evolve the policy is an interesting and innovative approach
* The experiments demonstrate the effectiveness of dasNet on challenging datasets
Arguments con acceptance:
* The training procedure is computationally expensive, which may limit the applicability of dasNet to large-scale datasets
* The paper could benefit from a more detailed analysis of the dasNet policy's information content and its relationship to the network's decision-making process
Overall, I recommend accepting this paper, as it presents a novel and effective architecture that advances the state-of-the-art in image classification. However, the authors should address the weaknesses mentioned above and provide a more detailed analysis of the dasNet policy's information content in future work.