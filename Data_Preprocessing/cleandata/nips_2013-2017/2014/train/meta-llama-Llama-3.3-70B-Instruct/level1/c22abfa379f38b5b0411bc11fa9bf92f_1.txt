This paper proposes a novel deep-learning based generative framework that utilizes attention to efficiently deal with high-dimensional sensory input. The framework is inspired by attention models in visual neuroscience and is designed to learn generative models of objects in large images where the location of the object is unknown. The authors demonstrate the effectiveness of their approach on face modeling, showing that their model can robustly attend to the face region of novel test subjects and learn generative models of new faces from a novel dataset.
The paper is well-written and clearly explains the technical details of the proposed framework. The authors provide a thorough review of related work in the field, including previous generative models and attention mechanisms. The experimental results are impressive, demonstrating the ability of the model to perform approximate inference, learn without labels, and perform identity-based attention.
The strengths of the paper include:
* The proposal of a novel attention-based generative framework that can efficiently deal with high-dimensional sensory input.
* The demonstration of the effectiveness of the approach on face modeling, including robust attention to the face region and learning of generative models of new faces.
* The use of a ConvNet-based approximate inference method, which is shown to be effective in initializing the gaze variables.
* The ability of the model to perform identity-based attention, which is a unique feature of the proposed framework.
The weaknesses of the paper include:
* The reliance on a supervised learning approach for training the ConvNet-based approximate inference method, which may limit the applicability of the framework to situations where labeled data is not available.
* The use of a simple Monte Carlo-based Expectation-Maximization algorithm for learning, which may not be efficient for large datasets.
* The lack of comparison to other state-of-the-art generative models and attention mechanisms, which makes it difficult to evaluate the performance of the proposed framework.
Overall, the paper is well-written and presents a novel and effective approach to generative modeling using attention. The experimental results are impressive, and the proposed framework has the potential to be applied to a wide range of tasks, including object recognition, speech perception, and language understanding.
Arguments pro acceptance:
* The paper proposes a novel and effective approach to generative modeling using attention.
* The experimental results are impressive, demonstrating the ability of the model to perform approximate inference, learn without labels, and perform identity-based attention.
* The paper is well-written and clearly explains the technical details of the proposed framework.
Arguments con acceptance:
* The reliance on a supervised learning approach for training the ConvNet-based approximate inference method may limit the applicability of the framework.
* The use of a simple Monte Carlo-based Expectation-Maximization algorithm for learning may not be efficient for large datasets.
* The lack of comparison to other state-of-the-art generative models and attention mechanisms makes it difficult to evaluate the performance of the proposed framework.