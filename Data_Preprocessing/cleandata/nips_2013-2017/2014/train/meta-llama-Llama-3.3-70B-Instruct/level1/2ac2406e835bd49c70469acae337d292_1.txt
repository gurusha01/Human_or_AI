This paper proposes a novel approach to learning Mixture of Hidden Markov Models (MHMM) using the Method of Moments (MoM). The authors demonstrate that an MHMM can be represented as a single Hidden Markov Model (HMM) with a block-diagonal transition matrix, allowing them to leverage existing MoM algorithms for HMMs. However, this approach introduces a permutation ambiguity, which the authors address by exploiting the spectral properties of the global transition matrix.
The paper is well-written, and the authors provide a clear and concise introduction to the problem and their approach. The technical sections are detailed and well-organized, making it easy to follow the authors' reasoning. The experimental results demonstrate the effectiveness of the proposed approach, both in terms of accuracy and computational efficiency.
The strengths of the paper include:
* The authors propose a novel and efficient approach to learning MHMMs, which addresses the limitations of traditional Expectation-Maximization (EM) algorithms.
* The paper provides a thorough analysis of the spectral properties of the global transition matrix and how they can be used to resolve the permutation ambiguity.
* The experimental results demonstrate the effectiveness of the proposed approach on both synthetic and real data.
The weaknesses of the paper include:
* The authors assume that the number of hidden states in each HMM is the same, which may not always be the case in practice.
* The paper does not provide a thorough comparison with other existing approaches to learning MHMMs, such as variational inference or Gibbs sampling.
* The authors do not discuss the potential limitations of their approach, such as the sensitivity to initialization or the choice of hyperparameters.
Arguments for acceptance:
* The paper proposes a novel and efficient approach to learning MHMMs, which addresses the limitations of traditional EM algorithms.
* The experimental results demonstrate the effectiveness of the proposed approach on both synthetic and real data.
* The paper provides a thorough analysis of the spectral properties of the global transition matrix and how they can be used to resolve the permutation ambiguity.
Arguments against acceptance:
* The paper assumes that the number of hidden states in each HMM is the same, which may not always be the case in practice.
* The paper does not provide a thorough comparison with other existing approaches to learning MHMMs.
* The authors do not discuss the potential limitations of their approach, such as the sensitivity to initialization or the choice of hyperparameters.
Overall, I believe that the paper is well-written and provides a significant contribution to the field of machine learning. The proposed approach is novel and efficient, and the experimental results demonstrate its effectiveness. However, the paper could be improved by addressing the limitations and potential drawbacks of the approach. I recommend acceptance with minor revisions to address these issues.