This paper introduces the concept of a pseudo-ensemble, a collection of child models spawned from a parent model by perturbing it with some noise process. The authors relate pseudo-ensembles to traditional ensemble methods and existing notions of robustness, and develop a novel regularizer, Pseudo-Ensemble Agreement (PEA), that minimizes variation in the output of a model when it is subject to noise on its inputs and internal state. The paper demonstrates the effectiveness of PEA regularization in both fully-supervised and semi-supervised settings, and shows that it can reproduce the performance of dropout in a fully-supervised setting while naturally extending to the semi-supervised setting.
The paper is well-written and clearly organized, making it easy to follow the authors' arguments and understand the technical details. The authors provide a thorough review of related work, including traditional ensemble methods and existing notions of robustness, and demonstrate a clear understanding of the strengths and weaknesses of their approach.
The strengths of the paper include:
* The introduction of a novel and well-motivated concept, pseudo-ensembles, which unifies several rapidly evolving lines of research
* The development of a novel regularizer, PEA, that performs well empirically and provides insight into the mechanisms behind dropout's success
* The demonstration of the effectiveness of PEA regularization in both fully-supervised and semi-supervised settings
* The clear and well-organized writing style, which makes the paper easy to follow and understand
The weaknesses of the paper include:
* The paper assumes a significant amount of background knowledge in machine learning and deep learning, which may make it difficult for non-experts to understand
* Some of the technical details, such as the derivation of the PEA regularizer, may be challenging to follow for readers without a strong mathematical background
* The paper could benefit from more discussion of the limitations and potential drawbacks of the pseudo-ensemble approach, as well as more comparison to other related work in the field
Overall, I would argue in favor of accepting this paper, as it presents a novel and well-motivated concept, develops a novel regularizer that performs well empirically, and demonstrates a clear understanding of the strengths and weaknesses of the approach. The paper is well-written and clearly organized, making it easy to follow and understand.
Arguments pro acceptance:
* The paper introduces a novel and well-motivated concept, pseudo-ensembles, which unifies several rapidly evolving lines of research
* The paper develops a novel regularizer, PEA, that performs well empirically and provides insight into the mechanisms behind dropout's success
* The paper demonstrates the effectiveness of PEA regularization in both fully-supervised and semi-supervised settings
* The paper is well-written and clearly organized, making it easy to follow and understand
Arguments con acceptance:
* The paper assumes a significant amount of background knowledge in machine learning and deep learning, which may make it difficult for non-experts to understand
* Some of the technical details, such as the derivation of the PEA regularizer, may be challenging to follow for readers without a strong mathematical background
* The paper could benefit from more discussion of the limitations and potential drawbacks of the pseudo-ensemble approach, as well as more comparison to other related work in the field.