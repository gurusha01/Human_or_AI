This paper presents a novel approach to addressing the problem of aggregating noisy labels from crowd workers in online crowdsourcing systems. The authors propose a reputation algorithm that identifies and filters out adversarial workers, who may employ arbitrary labeling strategies to degrade the accuracy of the inferred labels. The algorithm uses a combination of disagreement-based penalties and optimal semi-matchings to assign reputation scores to workers.
The paper relates to previous work on label aggregation algorithms, which have been designed under the assumption of random worker errors. However, the authors argue that this assumption is often violated in practice, and that adversarial workers can significantly impact the accuracy of the inferred labels. The proposed algorithm is designed to be robust to such adversarial strategies and can be used in conjunction with existing label aggregation algorithms to improve their performance.
The strengths of the paper include its thorough theoretical analysis, which provides strong guarantees for the performance of the reputation algorithm in various scenarios. The authors also present empirical results on real-world datasets, which demonstrate the effectiveness of the algorithm in improving the accuracy of label aggregation algorithms. The paper is well-written and easy to follow, with clear explanations of the proposed algorithm and its theoretical analysis.
The weaknesses of the paper include the fact that the algorithm requires a significant amount of computational resources, particularly for large datasets. Additionally, the authors assume that the worker-task assignment graph is known, which may not always be the case in practice. Furthermore, the algorithm may not perform well in scenarios where the adversaries are highly sophisticated and can adapt to the algorithm's behavior.
Arguments for acceptance:
* The paper presents a novel and well-motivated approach to addressing the problem of aggregating noisy labels from crowd workers.
* The theoretical analysis is thorough and provides strong guarantees for the performance of the reputation algorithm.
* The empirical results demonstrate the effectiveness of the algorithm in improving the accuracy of label aggregation algorithms.
Arguments against acceptance:
* The algorithm requires significant computational resources, which may be a limitation in practice.
* The assumption that the worker-task assignment graph is known may not always be valid.
* The algorithm may not perform well in scenarios where the adversaries are highly sophisticated.
Overall, I believe that the paper makes a significant contribution to the field of crowdsourcing and label aggregation, and that its strengths outweigh its weaknesses. I recommend acceptance, but suggest that the authors consider addressing the limitations of the algorithm in future work. 
Quality: 8/10
The paper is technically sound, and the theoretical analysis is thorough. However, the algorithm's computational requirements and assumptions about the worker-task assignment graph are limitations.
Clarity: 9/10
The paper is well-written and easy to follow, with clear explanations of the proposed algorithm and its theoretical analysis.
Originality: 8/10
The paper presents a novel approach to addressing the problem of aggregating noisy labels from crowd workers, but builds on existing work on label aggregation algorithms.
Significance: 9/10
The paper makes a significant contribution to the field of crowdsourcing and label aggregation, and has the potential to impact practice in this area.