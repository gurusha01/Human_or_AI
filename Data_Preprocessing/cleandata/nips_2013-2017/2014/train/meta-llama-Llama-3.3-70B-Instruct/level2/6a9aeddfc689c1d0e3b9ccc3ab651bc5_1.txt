This paper proposes a novel subsampling algorithm for large-scale corrupted linear regression, which limits the influence of data points with high influence. The authors introduce the concept of influence, which measures the effective impact of an individual data point on the overall estimate, and develop a randomized approximation of influence. The proposed algorithm, Influence Weighted Subsampling (IWS-LS), subsamples points according to their influence, resulting in a reduced bias and variance compared to the Ordinary Least Squares (OLS) estimator and other randomized approximations.
The paper is well-structured, and the authors provide a clear overview of the corrupted observation model, the concept of influence, and the proposed algorithm. The theoretical analysis of IWS-LS is thorough, and the authors provide an upper bound on the estimation error in the corrupted model. The experimental results demonstrate the effectiveness of IWS-LS and its fast approximation, aRWS-LS, in reducing bias and variance compared to other state-of-the-art methods.
The strengths of the paper include:
* The introduction of the concept of influence, which provides a new perspective on regression diagnostics and outlier detection.
* The development of a randomized approximation of influence, which enables the application of IWS-LS to large-scale datasets.
* The thorough theoretical analysis of IWS-LS, which provides a solid foundation for the algorithm's performance.
* The extensive experimental evaluation, which demonstrates the effectiveness of IWS-LS and aRWS-LS in various scenarios.
The weaknesses of the paper include:
* The assumption of a sub-Gaussian distribution for the data, which may not always hold in practice.
* The lack of comparison with other robust regression methods, such as the Least Absolute Deviation (LAD) estimator or the Huber estimator.
* The limited evaluation of the algorithm's performance on real-world datasets, with only one dataset (the airline delay dataset) being used to demonstrate the algorithm's effectiveness.
Overall, the paper presents a significant contribution to the field of robust regression and outlier detection, and the proposed algorithm has the potential to be widely applicable in various domains. However, further evaluation and comparison with other methods are necessary to fully assess the algorithm's performance and limitations.
Arguments for acceptance:
* The paper introduces a novel concept (influence) and develops a new algorithm (IWS-LS) that addresses a significant problem in robust regression.
* The theoretical analysis is thorough, and the experimental results demonstrate the effectiveness of the algorithm.
* The paper is well-structured, and the authors provide a clear overview of the proposed method and its applications.
Arguments for rejection:
* The assumption of a sub-Gaussian distribution may not always hold in practice, which could limit the algorithm's applicability.
* The lack of comparison with other robust regression methods may raise questions about the algorithm's performance relative to existing methods.
* The limited evaluation of the algorithm's performance on real-world datasets may not provide a comprehensive understanding of the algorithm's strengths and limitations.