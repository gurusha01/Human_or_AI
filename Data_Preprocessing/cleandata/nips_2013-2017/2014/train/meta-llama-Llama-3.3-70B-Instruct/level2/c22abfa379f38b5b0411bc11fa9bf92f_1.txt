This paper proposes a novel deep learning-based generative framework that utilizes attention to efficiently deal with high-dimensional sensory input. The authors draw inspiration from visual neuroscience and propose a model that can dynamically route relevant information to a generative model, ignoring background clutter. The model is based on a Gaussian Deep Belief Network (GDBN) and uses a 2D similarity transformation to propagate signals from the region of interest to a canonical representation.
The main claims of the paper are: (1) the proposed framework can learn generative models of objects in big images where the location of the object is unknown a-priori, and (2) the model can perform approximate inference using a Convolutional Network (ConvNet) and Hamiltonian Monte Carlo (HMC) sampling. The authors evaluate their model on face modeling tasks and demonstrate its ability to learn generative models without labels and perform identity-based attention.
The paper is well-written, and the authors provide a clear and concise explanation of their model and experiments. The use of attention in the model is novel and interesting, and the results demonstrate the effectiveness of the approach. The authors also provide a thorough analysis of the model's performance and compare it to other state-of-the-art methods.
The strengths of the paper include:
* The proposal of a novel attention-based generative framework
* The use of a ConvNet and HMC sampling for approximate inference
* The demonstration of the model's ability to learn generative models without labels
* The comparison to other state-of-the-art methods
The weaknesses of the paper include:
* The model's complexity and the need for careful initialization and tuning of hyperparameters
* The limited evaluation of the model on a single task (face modeling)
* The lack of a clear explanation of the ConvNet architecture and training procedure
Overall, the paper presents a significant contribution to the field of generative models and attention mechanisms. The proposed framework has the potential to be applied to a wide range of tasks and datasets, and the authors' experiments demonstrate its effectiveness in learning generative models without labels.
Arguments pro acceptance:
* The paper proposes a novel and interesting attention-based generative framework
* The model demonstrates state-of-the-art performance on face modeling tasks
* The authors provide a thorough analysis of the model's performance and compare it to other methods
Arguments con acceptance:
* The model's complexity and need for careful initialization and tuning of hyperparameters
* The limited evaluation of the model on a single task (face modeling)
* The lack of a clear explanation of the ConvNet architecture and training procedure
Recommendation: Accept with minor revisions. The authors should provide a clearer explanation of the ConvNet architecture and training procedure, and consider evaluating the model on additional tasks and datasets to demonstrate its generalizability.