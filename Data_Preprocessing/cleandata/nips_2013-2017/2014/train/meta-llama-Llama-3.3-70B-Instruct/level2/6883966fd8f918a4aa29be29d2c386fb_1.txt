This paper proposes a new active learning algorithm for parametric linear regression with random design, providing finite sample convergence guarantees for general distributions in the misspecified model. The algorithm is based on a stratification technique, which allows it to approach the optimal risk without prior knowledge of the conditional distribution of the labels given the inputs.
The main claim of the paper is that the proposed active learning algorithm can improve over passive learning in terms of the convergence rate of the expected squared error. The authors provide a theoretical analysis of the algorithm, including a finite sample convergence guarantee, and demonstrate its effectiveness through a simple example.
The paper is well-written, and the authors provide a clear and concise explanation of the algorithm and its analysis. The use of a stratification technique is a novel approach to active learning for regression, and the authors provide a thorough discussion of the advantages and limitations of their method.
The strengths of the paper include:
* The proposal of a new active learning algorithm for parametric linear regression with random design
* The provision of finite sample convergence guarantees for general distributions in the misspecified model
* The use of a stratification technique to approach the optimal risk without prior knowledge of the conditional distribution of the labels given the inputs
* A clear and concise explanation of the algorithm and its analysis
The weaknesses of the paper include:
* The algorithm requires a boundedness assumption on the error of the label relative to the optimal predictor, which may not always be satisfied in practice
* The convergence rate of the algorithm depends on the condition number of the marginal distribution of the inputs, which can be large in some cases
* The algorithm uses a static allocation of samples to stages and to partitions, which may not be optimal in all cases
Overall, the paper presents a significant contribution to the field of active learning for regression, and the proposed algorithm has the potential to improve over passive learning in terms of convergence rate. However, further research is needed to address the limitations of the algorithm and to explore its applicability to more general settings.
Arguments for acceptance:
* The paper proposes a new and novel approach to active learning for regression
* The algorithm has the potential to improve over passive learning in terms of convergence rate
* The paper provides a thorough and well-written analysis of the algorithm
Arguments against acceptance:
* The algorithm requires a boundedness assumption on the error of the label relative to the optimal predictor
* The convergence rate of the algorithm depends on the condition number of the marginal distribution of the inputs
* The algorithm uses a static allocation of samples to stages and to partitions, which may not be optimal in all cases
Recommendation: Accept, with minor revisions to address the limitations of the algorithm and to provide further discussion of its applicability to more general settings.