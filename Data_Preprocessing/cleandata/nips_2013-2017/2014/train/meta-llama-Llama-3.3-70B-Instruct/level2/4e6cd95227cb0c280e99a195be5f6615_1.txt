This paper introduces a novel sampling algorithm for Markov chain Monte Carlo-based Bayesian inference for factorial hidden Markov models (FHMMs). The algorithm, called Hamming ball sampling, uses an auxiliary variable construction to restrict the model space, allowing for iterative exploration in polynomial time. The authors claim that this approach overcomes the limitations of common conditional Gibbs samplers, which can become trapped in local modes due to asymmetric updates.
The paper is well-written, and the authors provide a clear explanation of the Hamming ball sampling algorithm and its extensions. The experiments demonstrate the effectiveness of the algorithm in escaping local modes and improving mixing, particularly in comparison to block Gibbs sampling. The authors also provide a thorough discussion of the limitations of the algorithm and potential avenues for future research.
The strengths of the paper include:
* The introduction of a novel sampling algorithm that addresses the limitations of existing methods for FHMMs
* A clear and concise explanation of the algorithm and its extensions
* A thorough evaluation of the algorithm through experiments on simulated and real data
* A discussion of the potential applications of the algorithm to other statistical models
The weaknesses of the paper include:
* The algorithm may not be suitable for very large values of K and N, as the time complexity can become prohibitively expensive
* The choice of the radius parameter m can significantly affect the performance of the algorithm, and the authors do not provide a clear guideline for selecting this parameter
* The algorithm may not be easily parallelizable, which could limit its scalability
Overall, the paper presents a significant contribution to the field of Bayesian inference for FHMMs, and the Hamming ball sampling algorithm has the potential to improve the accuracy and efficiency of inference in these models. However, further research is needed to address the limitations of the algorithm and to explore its applications to other statistical models.
Arguments pro acceptance:
* The paper introduces a novel sampling algorithm that addresses the limitations of existing methods for FHMMs
* The algorithm has been thoroughly evaluated through experiments on simulated and real data
* The paper provides a clear and concise explanation of the algorithm and its extensions
Arguments con acceptance:
* The algorithm may not be suitable for very large values of K and N
* The choice of the radius parameter m can significantly affect the performance of the algorithm
* The algorithm may not be easily parallelizable, which could limit its scalability
Recommendation: Accept with minor revisions. The authors should provide a clearer guideline for selecting the radius parameter m and discuss the potential limitations of the algorithm in more detail. Additionally, the authors should consider providing more experimental results to demonstrate the scalability of the algorithm.