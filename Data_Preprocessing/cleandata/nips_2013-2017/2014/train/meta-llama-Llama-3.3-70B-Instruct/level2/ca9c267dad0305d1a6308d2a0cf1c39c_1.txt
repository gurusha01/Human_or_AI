This paper introduces a new framework for online multi-task learning with a shared annotator, where multiple learners share a single annotator with limited bandwidth. The authors propose an algorithm, SHAMPO, which learns to select a task to query its label and updates its models based on the received feedback. The algorithm is analyzed in the mistake-bound model, and the authors show that it can perform well compared to methods that observe all annotated data.
The paper's main claims are: (1) the proposed framework and algorithm can efficiently learn multiple tasks with a shared annotator, and (2) the algorithm can be applied to contextual bandits settings with decoupled exploration and exploitation. The authors support these claims with theoretical analysis and empirical results on several datasets.
The strengths of the paper include:
* The introduction of a new framework for online multi-task learning with a shared annotator, which addresses a common problem in real-world applications.
* The proposal of a novel algorithm, SHAMPO, which is shown to be effective in selecting tasks to query and updating models.
* The theoretical analysis of the algorithm's performance in the mistake-bound model, which provides a solid foundation for understanding its behavior.
* The empirical results, which demonstrate the algorithm's effectiveness in various tasks and settings.
The weaknesses of the paper include:
* The assumption of a shared annotator with limited bandwidth, which may not always be the case in practice.
* The reliance on a uniform prior over tasks, which may not be optimal in all cases.
* The lack of comparison to other multi-task learning algorithms that do not use a shared annotator.
Arguments for acceptance:
* The paper introduces a new and interesting framework for online multi-task learning with a shared annotator.
* The proposed algorithm, SHAMPO, is novel and shown to be effective in various tasks and settings.
* The theoretical analysis provides a solid foundation for understanding the algorithm's behavior.
* The empirical results demonstrate the algorithm's effectiveness and potential for real-world applications.
Arguments against acceptance:
* The assumption of a shared annotator with limited bandwidth may not be realistic in all cases.
* The reliance on a uniform prior over tasks may not be optimal, and other priors may be more effective.
* The lack of comparison to other multi-task learning algorithms that do not use a shared annotator may limit the paper's impact.
Overall, the paper presents a novel and interesting framework for online multi-task learning with a shared annotator, along with a effective algorithm and theoretical analysis. While there are some limitations and potential areas for improvement, the paper's contributions and empirical results make it a strong candidate for acceptance.