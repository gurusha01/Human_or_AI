This work proposes a convolutional neural network (CNN) that incorporates feedback connections to enable visual attention learning, wherein feedback is facilitated by gating the activation of specific filters. The model is trained using reinforcement learning on top of a CNN framework. Although no individual component is particularly groundbreaking, the overall approach is well-conceived and, in my view, represents a promising direction. As anticipated, the authors demonstrate state-of-the-art performance on the CIFAR dataset, providing significant evidence that incorporating feedback and attention mechanisms is a viable path forward. The paper's quality and clarity are commendable. The approach, which combines CNNs with reinforcement learning-driven feedback attention, is a notable contribution to the field of vision. A potential future direction could involve applying this methodology to more complex challenges, such as ImageNet, if this has not already been undertaken.