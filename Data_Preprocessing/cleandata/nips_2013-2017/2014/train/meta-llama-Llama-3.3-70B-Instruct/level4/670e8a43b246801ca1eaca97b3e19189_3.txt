The paper explores the computational challenge of bipartite ranking, presenting a novel algorithm with linear computational complexity relative to the number of training instances, alongside a theoretical analysis of generalization error. The manuscript is complemented by extensive experimental evaluations.
Key strengths of the paper include its clear writing style and potential value in handling large datasets for bipartite ranking. The proposed generalization bound is novel, and the experiments section is detailed and comprehensive.
However, several questions arise regarding the paper's content and implications:
1. Given that bipartite ranking is a well-studied area with established algorithms that have been theoretically and empirically validated, the practical value of this study, particularly its restriction to ranking without query handling, is questionable. Its utility seems most pronounced in scenarios with very large datasets, which may not be the most common or practical case in bipartite ranking domains.
2. The derivation of the O(m+n/\sqrt(e)) error bound hinges on the introduction of a new target loss and the utilization of a smooth convex surrogate, facilitating the application of standard primal-dual techniques and accelerated gradient descent optimization. This approach raises questions about its effectiveness in promoting good ranking, especially at the top, without a position-based discount factor. Furthermore, optimizing an upper bound on rank loss, as opposed to directly addressing the rank loss, seems counterintuitive, especially considering the stated limitations of AUC optimization for prioritizing positives at the top.
3. While the conversion to a dual problem and the application of Nesterov's technique are elegantly executed, the novelty of this approach is debatable.
4. The empirical section suggests that TopPush, the proposed algorithm, does not significantly outperform logistic regression (LR) in terms of computational power or metrics like AP and NDCG. In fact, LR appears to be faster in several experiments. The advantages of TopPush over LR, particularly in terms of its unique selling points, are not clearly demonstrated.
A notable observation is that the computational complexity comparison with SVM (Rank, MAP) reveals that all these methods scale linearly with the training data size. The computational advantage of TopPush stems from its use of a smooth surrogate rather than the hinge loss used in SVMs.
5. The generalization bound provided focuses on scenarios that may not be the most practical, such as when there are fewer negative instances than positive ones. In more realistic scenarios where negative instances far outnumber positive ones, the significance and practical implications of the bound are less clear. The bound's behavior as the number of negative instances grows is particularly puzzling, with both the empirical loss and the bound itself potentially increasing, making the interpretation challenging.
In conclusion, while the paper presents interesting techniques and has potential, addressing the raised questions, particularly the comparison between TopPush and LR, is crucial for a thorough evaluation. The provisional rating is subject to change based on the authors' responses to these queries. Clarification on how TopPush offers advantages over LR will be pivotal in determining the paper's acceptability. 
Following the author feedback, several points were addressed, though some concerns remain:
1. The example of large m and n, while acknowledged, still raises questions about the practical applicability, especially in domains like online advertisement ranking, which often involves query-dependent ranking.
2. The justification for optimizing the new loss, given its relation to AUC and the stated goal of pushing positives to the top, was not fully addressed.
3. The comparison with LR highlighted that TopPush's advantage lies in specific metrics, suggesting it as an alternative rather than a universally superior method. The introduction might need revision to reflect this accurately.
4. The advantage over SVM-based methods was clarified to be the quadratic convergence rate rather than linear complexity, which both methods share.
5. The discussion on the generalization bound and its implications, especially in scenarios with a large number of negative instances, is critical and should be included in the revised draft.
Overall, the paper has potential and, with revisions addressing the raised concerns, could become a very good contribution. The decision to accept the paper is updated based on the expectation of these revisions.