Review- Summary:
This manuscript introduces an influence reweighted sampling method, referred to as IWS-LS, as well as a residual weighted sampling method known as RWS-LS, designed for large-scale least squares learning that exhibits robustness against certain types of data corruption, such as sub-Gaussian additive noise. The approach leverages existing approximation techniques to calculate the Ordinary Least Squares (OLS) estimate and leverage scores. A theoretical analysis of the estimation error for IWS-LS is provided. Additionally, the paper presents empirical results based on both synthetic and real-world datasets.
Comments:
The overall quality of the paper is high, with clear writing and a novel contribution through the influence reweighted subsampling method. Both the theoretical foundations and empirical results appear to be rigorous and sound.
However, the experimental section could be enhanced. For instance, the dataset comprising 100,000 samples in a 500-dimensional space, while sizable, is not exceptionally large, especially when compared to the real-world Airline delay dataset, which is even smaller. Given the computational complexity of O(n p^2), calculating the OLS estimate and leverage scores should be feasible on standard desktop hardware, albeit potentially time-consuming. Therefore, including the results of exact methods as a baseline for comparison would strengthen the paper. Details about the experimental environment and the running time of the algorithms would also be beneficial, as time efficiency is a critical aspect of large-scale learning.
The paper's focus on developing estimators robust to outliers resulting from data corruption is well-motivated. Nonetheless, it would be enlightening if the authors could discuss recent studies that utilize data corruption or nosing to enhance classification or regression performance. Examples include dropout training for deep neural networks, as explored in references [1] and [2], and learning with marginalized corrupted features, discussed in [3] and [4].
References:
[1] G. Hinton et al., Improving neural networks by preventing co-adaptation of feature detectors. arXiv:1207.0580v1, preprint.
[2] S. Wager, et al., Dropout training as adaptive regularization. NIPS, 2014.
[3] L. van der Maaten, et al., Learning with marginalized corrupted features. ICML, 2013.
[4] N. Chen, et al., Dropout Training for Support Vector Machines, AAAI, 2014.
Lastly, attention to detail is necessary to correct typographical errors, such as "more more realistic" on line 42 and "ideas from $4 and $4" on line 254. Overall, the paper is well-written, presents a novel method, and demonstrates sound theoretical and empirical results.