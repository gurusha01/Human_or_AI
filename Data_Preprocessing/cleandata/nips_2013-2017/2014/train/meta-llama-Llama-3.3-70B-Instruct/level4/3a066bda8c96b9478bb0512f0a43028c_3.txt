Summary: 
The authors propose a methodology for semantic labeling and object detection, wherein the former involves generating candidate segments, extracting features, and regressing on the Intersection-over-Union overlap ratio between candidate segments and ground truth. For object detection, weaker labels in the form of bounding boxes are utilized, with the precise spatial extent treated as a latent variable. Regression is achieved through the use of a weighted SVM and a weighted transductive SVM, yielding results comparable to the state of the art in semantic labeling and surpassing current benchmarks for object detection on VOC 2007.
Originality:
While the algorithmic contributions are somewhat limited, the authors' failure to acknowledge pertinent prior work is notable. Specifically, the weighted SVM has been previously explored (as seen in references [R1], [R2], and [R4], which are not cited in the paper). The introduction of a sum constraint on the weights may be a novel aspect, although a thorough literature review would be necessary to confirm this. Furthermore, the "latent e-SVM" proposed by the authors appears to be a weighted variant of the transductive SVM (as described in [R3], which is also not cited).
[R1] Suykens et al. Weighted least squares support vector machines: robustness and sparse approximation, Neurocomputing, 2002
[R2] X.Yang et al. Weighted Support Vector Machine for Data Classification, IJCNN, 2005
[R3] V. Vapnik, "Statistical Learning Theory", 1998
[R4] M.Lapin et al, Learning Using Privileged Information: SVM+ and Weighted SVM, Neural Networks, 2014
Significance:
The achievement of surpassing recent CNN results with a conventional learning approach is a significant accomplishment, holding considerable interest for the community.
Quality:
A major concern is the omission of crucial references to prior work. The object detection framework, while involving a substantial amount of engineering, remains within established norms. However, the use of a sum-constrained weighted SVM for regression on the unit interval should be compared to the default method of (regularized) logistic regression to justify its application. Additionally, the authors should provide more detailed information on the selection of regularization coefficients λW and λR. The primary strength of the paper lies in its empirical results.
Clarity:
The title and abstract do not accurately convey the core contribution of the paper. The abstract also implies that regression targets from the unit interval are less informative than binary class memberships, which is not the case, as the latter can be derived from the former through thresholding. For a NIPS audience, the paper dedicates excessive space to minor variations of well-known algorithms (up to page 4) and glosses over critical feature engineering details (lines 254ff).
Minor comments 
Line 19: "continues" should be replaced with "continuous"
Line 94: "boxes" should be changed to "box"
Line 98: The abbreviation "AP" is not introduced
Line 350: "SVM" should be replaced with "SVC"
Line 350: "with every different values" should be rephrased as "for all threshold values"
Given the assumption that the authors will address the relationship to prior work in a constructive manner, I have increased my quality score by one. The paper presents great results, albeit with deficient references to earlier work and limited algorithmic novelty. It is a paper that deserves publication, potentially after revisions, and possibly in a computer vision conference.