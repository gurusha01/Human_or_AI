This manuscript examines the challenge of determining accurate labels for objects within crowd-sourcing platforms, considering a broader range of adversarial voting strategies than previously explored. The authors introduce novel reputation-based algorithms that leverage user disagreements and semi-matchings to identify adversarial users, demonstrating improved vote aggregation quality for three commonly used algorithms. Additionally, they establish that their reputation definition aligns with user reliability and enables the detection of adversarial users, even under sophisticated strategies, assuming non-adversarial users exhibit high reliability. The authors also derive bounds on the minimum damage inflicted by intelligent adversaries.
I found the paper to be engaging and innovative, as it explores different adversary classes than those typically considered. However, the authors rely on several strong assumptions, including the accuracy of 'honest' user labeling (Assumption 1, Section 3.2), adversarial users' knowledge of honest voting patterns, and their awareness of the decision rule employed. These assumptions raise questions about the practical applicability of Theorems 3 and 4.
Another aspect that sparked my interest was the authors' rationale for not assigning credit for agreement (Section 2), aiming to prevent adversaries from aligning with honest users. While this approach may be justified when all honest user votes are known, its validity is less clear in scenarios where adversaries lack knowledge of the voting pattern.
Detailed comments:
- Investigating how the results in Section 4 are affected by the 20% threshold for removing users would be fascinating.
The manuscript presents a unique perspective on user filtering in crowd-sourcing, offering promising practical results and intriguing theoretical foundations, although the theoretical aspects rely on somewhat stringent assumptions.