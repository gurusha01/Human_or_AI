This paper proposes a novel class of multi-class boosting algorithms that utilize base learners regularized based on their Rademacher complexities, demonstrating significant improvements over existing multi-class approaches and the non-regularized version of the proposed algorithm through experiments.
However, several concerns need to be addressed. The title's use of the term "deep" is misleading, as it implies a hierarchical representation in a compositional sense, which is not applicable to trees used in boosting, even with large trees. This is essentially a shallow architecture, combining a single "hidden layer" of trees linearly.
The statement that boosting often overfits in practice is outdated and should be revised, as recent studies have shown that with proper hyper-parameter optimization, boosted trees can perform well without significant overfitting. For instance, boosting multi-class Hamming trees in AB.MH has been found to exhibit little overfitting, allowing for the boosting of large trees over numerous iterations without increasing test error.
The concept of adaptive regularization of base classifiers was first introduced in \cite{KeWa04}, sharing a similar intuitive idea and algorithmic structure with the proposed method. The paper should also acknowledge state-of-the-art multi-class boosting algorithms such as AOSO \cite{SuReZh12}, ABC \cite{Li09,Li09a}, Gao-Koller's iterative weak learner in hinge-boost \cite{GaKo11}, and AB.MH with Hamming trees \cite{Keg14}.
A critical issue lies in the experimental setup, where the parameter tuple with the lowest average error across all runs was recorded, and this average error was reported. This approach validates on the test set, a practice that should be avoided as it can lead to misleading comparisons with existing literature and tainted empirical comparisons between algorithms. The reported errors seem suspiciously low, and the improvements are within the range expected from harvesting the minimum of a larger sample.
Given the importance of the claims made, the experimental validation needs to be robust. Redoing the experiments using proper double cross-validation during the rebuttal period and providing new results would be beneficial. If the results are inconclusive, the paper could still be considered for acceptance, but the message should be altered to reflect that the regularization does not provide a significant advantage.
Providing an open-source implementation of the algorithm would enhance reproducibility and allow for further development. Additionally, clarifying the definitions of quantities in the pseudocode, such as $\Lambda$ and $S_t$, would be helpful for implementers.
Upon reviewing the revised experimental results, the errors increased significantly, validating the initial concern about overestimating performance by optimizing hyperparameters on the test set. The new results show no significant improvement from the added regularization, contradicting the paper's main message. While the results using AB.MR and AB.MR-L1 are promising, the lack of detail in the tree-building procedure hinders understanding of what contributes to its success.
In conclusion, the paper presents an interesting algorithm but fails to support its main claim with robust experimental evidence. The theoretical results, while potentially interesting, do not directly contribute to the algorithm's practical performance. Therefore, considering the current experimental setup, the decision should be a clear rejection, unless the authors are willing to revise the paper to honestly reflect the findings and potentially resubmit.