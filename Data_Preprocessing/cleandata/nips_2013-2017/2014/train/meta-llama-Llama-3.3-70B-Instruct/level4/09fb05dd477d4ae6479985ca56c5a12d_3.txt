This manuscript proposes a methodology to adapt a pre-trained Krizhevsky CNN network for object detection tasks, leveraging a limited number of classes with annotated bounding boxes. The approach involves a three-stage training process: 1) training a CNN for image classification across all classes, 2) training a CNN on regions of images from classes with bounding box annotations, including a background class, and 3) integrating the background class into the full CNN model with partial weight adaptation. During testing, the CNN processes multiple regions within a test image.
Quality: The paper presents an intriguing concept, yielding reasonable results that are largely built upon the foundation laid by Krizhevsky et al. While the methodology is not groundbreaking, it holds value for researchers in computer vision and machine learning. The approach is straightforward yet logical, with promising experimental outcomes. However, a comprehensive comparison to alternative baselines is lacking, including:
1) Utilizing full images as positive examples and images or regions from other classes as negative examples, followed by training and fine-tuning all CNN layers.
2) Employing a Multiple Instance Learning (MIL) approach, where the highest-scoring positive region is iteratively selected for each image.
3) Training and fine-tuning the CNN for classification, then predicting a single bounding box at the image center during testing.
It is uncertain whether the proposed method would outperform these baselines, and its superiority over baseline 1 is not clearly established. The inclusion of the third baseline is essential to provide context on the problem's difficulty and the dataset's characteristics.
Clarity: The manuscript is well-written and clear, although the experiments section could benefit from elaboration, particularly in explaining the methods outlined in Table 1 and clarifying the application of equations to specific CNN layers.
Originality: The paper demonstrates sufficient novelty to warrant acceptance, despite the simplicity of its core approach, which is tailored to specific CNN architectures.
Significance: The problem addressed and the results obtained are significant and valuable, as the paper tackles a relevant issue and achieves decent detection results on a large-scale dataset without requiring bounding box labels. Nevertheless, the omission of obvious baselines raises questions about whether the results are primarily due to the improved performance of CNN features or the introduction of a superior training methodology for object detectors using weak supervision.