This paper investigates the problem of tensor learning for linear multi-task learning, proposing a novel weighted variant of the previously introduced "latent trace norm" tensor norm. The authors demonstrate that this rescaling leads to improved bounds on excess risk and enhanced recovery performance in certain datasets. The paper is well-structured and clearly written, with the proposed rescaling having potential for significant practical impact, although more comprehensive experimental evaluation would be beneficial. The technical findings appear to be sound and accurately proven, with sufficient coverage of relevant literature. Notably, the tensor norms examined in this study can also be viewed as specific instances of a broader class of tensor penalties, as discussed in the recent work by A. Argyriou and F. Dinuzzo, "A Unifying View of Representer Theorems" (ICML 2014). Overall, the paper presents a thorough examination of recently proposed tensor norms, including a new weighted version, highlighting the benefits of such reweighting through both theoretical and empirical analysis, resulting in a well-written, organized, and potentially significant contribution.