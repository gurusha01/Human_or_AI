This paper presents a novel algorithm for Bandit Convex Optimization (BCO) with strongly-convex and smooth loss functions, utilizing an exploration scheme that diminishes over time. The authors have established that their proposed algorithm achieves a regret of \tilde{O}(\sqrt{T}) (as shown in Theorem 10), which aligns with the existing lower bound when disregarding logarithmic factors. The technical analysis appears to be sound.
The significance of this paper lies in its provision of a tighter regret bound for BCO with strongly-convex and smooth loss functions, improving from \tilde{O}(T^{2/3}) to \tilde{O}(T^{1/2}), and notably, this enhanced bound matches the lower bound established in (Shamir 2013). Overall, I recommend acceptance of this paper, albeit with a marginal rather than strong acceptance, due to concerns regarding the paper's clarity and presentation.
Specifically, several issues detract from the paper's quality:
1) The paper includes numerous lemmas, but without consulting the appendix, it is unclear which lemmas are existing results and which are original contributions, making it challenging to assess the technical significance of the paper.
2) The authors devote excessive space to reviewing existing results, with the main contribution of the paper only appearing towards the end of page 6.
3) Certain symbols, such as \delta in Eqn(4), are not properly defined, and some results lack clarity, for instance, the outcome of Lemma 9 should be valid for any \omega, but this is not explicitly stated.
4) Algorithm 2 requires revision, as it should not contain a loop, and \Nabla ht (xt) should be treated as inputs to the algorithm.
While the paper's result is significant, its presentation and writing require substantial improvement.