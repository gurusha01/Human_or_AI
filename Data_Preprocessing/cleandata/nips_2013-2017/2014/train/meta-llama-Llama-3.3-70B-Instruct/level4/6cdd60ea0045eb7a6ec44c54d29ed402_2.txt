This manuscript presents a novel approach to robust logistic regression, focusing on mitigating the impact of outliers with high leverage. It assumes that outliers originate from an unknown distribution, with their number specified in advance - a theoretically convenient yet practically somewhat troubling assumption.
The proposed method involves maximizing the sum of y*x'beta, but only considering observations that contribute the least to the objective function in absolute terms, effectively excluding outliers with large leverage. This can be formulated as a linear programming problem, which is an elegant solution.
The authors provide some risk bounds, although, like many such bounds, they are likely too loose for practical quantitative use but still offer value for qualitative interpretation.
A small simulation study demonstrates the proposed method's favorable performance compared to classical logistic regression.
Several detailed comments are warranted:
- The necessity of the preprocessing step is unclear, as observations with large ||x|| should also be among those with large y*x'beta and thus omitted by the algorithm. Furthermore, T decreases with n (approaching 0 as n increases), resulting in more observations being discarded by the preprocessing step as the dataset grows. For instance, what proportion of observations is removed by preprocessing in the simulation? It is surprising that T is not chosen based on n or lambda.
- It would be interesting to examine how logistic regression performs after applying the same preprocessing steps.
- The proposed method appears to be favored in situations where outliers have much larger variance in the covariates, as seen in the simulation. However, if the variance of the outliers (sigma_o) is decreased, making them less distinct, how will the method perform? Will its performance improve or deteriorate?
- A crucial question is the method's performance compared to logistic regression when there are no outliers. While the left end of figure 2 suggests minimal difference in estimating beta, a more substantial difference is observed in the misclassification rate. What is the cost of robustness?
- In practical applications, how should n be chosen, and how sensitive is the method to this choice?
The manuscript is well-written and clearly structured. The authors' approach to robust logistic regression, which essentially identifies observations with large leverage, is notable. The transformation of the problem into a linear programming problem is particularly impressive.