This manuscript presents a novel approach to preserving privacy in matrix factorization-based recommender systems. The authors propose a mechanism where users are divided into two distinct groups: public and private users, with the latter not sharing any rating information with the system. Under specific technical conditions, the authors demonstrate that it is possible to establish bounds on the estimation accuracy of item features based on observed ratings, which can subsequently be used to bound the reconstruction error for private users. The empirical performance of this approach is evaluated using the Movielens 10M dataset.
The issue of privacy in recommender systems is a crucial one that has only recently begun to receive attention. Unlike previous formal approaches that often rely on differential privacy, this paper assumes that even the recommender engine itself may not be secure, a scenario that seems practically reasonable. Within this context, the authors develop a compelling framework. The formalism and derivations presented in the paper appear to be clear and sound, yielding interesting results, particularly in terms of bounding the error of item factors and the subsequent reconstruction errors. However, providing additional intuition behind Theorem 3.5 would be beneficial.
Overall, the paper is well-written and easy to follow. The experiments conducted are reasonable, effectively demonstrating the necessary comparisons and convincingly showing the performance of the proposed method against others. In the initial set of experiments, clarifying the meaning of "Percentage of Users" would be helpful; it is interpreted here as the percentage of all users that are public.
The second set of experiments, which involves 100 public users and up to 400 private users, raises questions about the decision not to report results with a larger number of private users, given that the dataset includes 10,000 users. It would be insightful to explore how the performance of the proposed methods (PMC and PMD) compares to differential privacy methods, especially LAP with eps=5, in a setting with more private users. Understanding the rationale behind limiting the experiments to 400 private users and demonstrating the effectiveness of PMC and PMD in less synthetic scenarios would strengthen the paper. Additionally, providing results for cases where private users are not necessarily those who have consumed the most items would offer further insight.
In conclusion, this is a good paper that introduces an interesting method for preserving privacy in matrix factorization-based recommender systems. Both the theoretical analysis and empirical results appear sound, contributing positively to the field.