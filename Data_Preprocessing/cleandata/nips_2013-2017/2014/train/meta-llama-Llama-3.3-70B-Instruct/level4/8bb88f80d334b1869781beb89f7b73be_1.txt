Review of submission 1706:
Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning
Summary: 
A high-performance, deep neural network (NN) is trained for ALE Atari games using a slow, traditional game planner as the teacher, outperforming a recent approach [19], referred to as "DQN", which utilizes temporal difference-based reinforcement learning with a similar deep NN architecture.
Comments:
This study presents an intriguing approach. The simplicity of the methodology is commendable, and its implementation is a valuable contribution. 
However, the abstract and text could be significantly condensed, potentially in a style akin to the brief summary provided above, to enhance clarity and readability.
The discussion on previous work, specifically the statement "Over the last decade, deep learning... has emerged as a powerful technique for learning feature representations from data", is somewhat misleading due to its narrow focus on recent publications from a limited number of research groups. The referenced survey [7] primarily covers advancements since 2006, overlooking the broader history of deep learning. A more comprehensive survey, such as http://arxiv.org/abs/1404.7828, highlights the development of deep learning methods dating back to 1965, underscoring the need for a more balanced historical account.
General recommendation:
The submission offers interesting insights, albeit confirming expected outcomes: traditional game players, although slow, can effectively train faster deep networks through supervised learning, leading to better performance compared to similar networks trained with general reinforcement learning methods. The work is publishable, contingent upon the inclusion of a more nuanced and comprehensive overview of deep learning's historical development. 
This submission is notable for its confirmation of anticipated results, where slow yet proficient traditional game players can supervise the training of faster deep networks, which in turn outperform deep networks trained using more generalized reinforcement learning techniques. With the incorporation of a more balanced historical perspective on deep learning, this work is deemed suitable for publication.