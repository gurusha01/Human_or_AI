Review for Paper 1180: Deep Recursive Neural Networks for Compositionality in Language
This manuscript presents a novel architectural design, namely the deep recursive neural network (deep RNN), which is formed by stacking multiple recursive layers, and applies it to fine-grained sentiment classification.
Clarity
- Overall, the paper is well-structured and easy to follow, making it an enjoyable read.
Quality
- The technical aspects of the paper appear to be robust and well-founded.
- The core concept of the deep recursive neural network, constructed from multiple stacked layers of individual recursive networks, is noteworthy.
- The authors provide a sufficient amount of experimental data to assess various facets of their methodology.
Originality
- The proposed concept is straightforward and logical.
- However, it would be beneficial to include more in-depth discussions on:
  + The intuitive rationale behind the effectiveness of deeper networks for the specified task.
  + The rationale behind the selection of the particular network architecture used.
Significance
- The paper offers an intriguing concept, a clear contextual background, and experimental evidence that supports its claims.
- With its well-presented ideas, concise background information, and reasonable experimental support, the paper contributes meaningfully to the field.