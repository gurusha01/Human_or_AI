This paper explores the extension of dropout to various model classes by introducing parameter perturbations in the source model. For example, in the context of a mixture model, this could involve adding noise to the component means or covariance matrices. The authors propose a regularizer to ensure the robustness of the generated child models, which form a pseudo-ensemble, with respect to the noise process used for perturbation. The topic is of significant interest to the NIPS community and, in my opinion, worthy of presentation, although it represents a relatively straightforward extension of dropout. The paper is substantiated by several informative simulations on standard benchmark datasets.
Some specific comments:
1) The opening sentences lack clarity, particularly regarding the role of variables x and y. It is unclear whether the goal is to derive approximations of p(x,y) conditioned on x.
2) The claim that "many useful methods could be developed...by generating perturbations beyond the iid masking noise" is inaccurate. The original Hinton paper did not use iid noise, as dropout probabilities varied across layers. Moreover, reference [1] and its extended version (Artificial Intelligence, 210, 78â€“122, 2014) have already explored non-iid cases and other noise forms, demonstrating their connection to the current paper's theme.
3) A minor suggestion is to reconsider the terminology, as the term "pseudo-ensemble" may convey a negative connotation, whereas the intention is to introduce a novel learning approach.
4) The statement that dropout's mode of action is not well understood outside linear models is not entirely accurate. The ensemble and regularization properties of dropout in deep non-linear neural networks are reasonably well understood, as described in the aforementioned reference.
5) There are a few typos throughout the paper, suggesting the need for a spell-check. For instance, the last line of page 6 contains the error "northe images in the target domain".
6) The paper is well-supported by informative experiments on various benchmark datasets.
In summary, this paper presents an incremental generalization of dropout, a topic of current interest to the NIPS audience, supported by interesting simulations.