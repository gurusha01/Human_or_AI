This manuscript integrates selective attention into a convolutional neural network and proposes a training methodology for optimizing the network's classification performance by adjusting the gating parameters for attention. It tackles a crucial set of challenges in computer vision, specifically how to dynamically reconfigure complex, deep processing stages under limited resources and diverse task requirements. Although the classification results are noteworthy, the approach remains somewhat opaque, suggesting promising research directions without elucidating the underlying mechanisms of its effectiveness. The analysis of image representation lacks depth, and the role of the learned parameters, such as the mean and variance of the theta distribution, is not clearly understood. Nonetheless, this work represents a significant advancement beyond the current paradigm of large, feed-forward networks with fixed parameters post-learning. The presentation is generally clear, albeit with some typographical errors in the equations or areas needing further explanation.
Major Comments:
The authors should delve deeper into the connection with dynamical systems, as the work appears more closely related to recurrent networks than reinforcement learning. Given the immediate observation of rewards and the deterministic nature of the policy, training essentially involves navigating the space of recurrent "policy" parameters theta to maximize the observed objective function.
The analysis of the network's processing of the cat image did not significantly enhance understanding of how the model's new features contribute to recognition. For instance, the universal increase in layer 1 activations at the first iteration warrants explanation, as does its impact on the objective function or whether the output is invariant to global scalings. Focusing on a smaller image region and analyzing the evolution of gating variables could provide insights. Additionally, examining challenging cases, such as those misclassified by the standard Maxout network but correctly labeled by the proposed model, or further constraining the learned model parameters to elucidate their effects, would be beneficial.
Minor Comments:
In the description of Algorithm 1, the definition of \(h_M\) is not provided; clarification on whether this step involves collecting observations is needed. The placement of \(F[i]\) and \(\Theta[i]\) within the loop over images \(j\) suggests that image fitness values are either collected in an array or overwritten at each iteration, which requires clarification.
Equation 11 lacks specificity regarding the sum; it is unclear whether Equation 8 pertains to a single image and should be indexed by \(j\).
The text following Equation 11 references variables 'x' and 'd' without clear explanation of their significance.
The necessity of regularization of theta is not evident, given that theta is sampled from a prior and tends towards small values. Furthermore, the final optimization step, involving gradient updates on parameters after sampling and evaluating the fitness of thetas, is not well-explained in terms of gradient computation or theoretically justified, particularly concerning the adjustment of hyper-parameters of the posterior over policies.
This approach to constructing deep recurrent networks for recognition is intriguing. The high classification accuracy, relative to standard methods, implies that recurrent computation aids in extracting or focusing on more complex image features, although the opaque nature of the approach fails to provide insight into its effectiveness.