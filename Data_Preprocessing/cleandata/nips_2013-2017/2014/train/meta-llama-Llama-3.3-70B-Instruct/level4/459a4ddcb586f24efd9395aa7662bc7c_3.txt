This manuscript proposes a novel random feature-based approximation method for tackling the l1 regularized problem within a potentially infinite-dimensional Hilbert space. The presentation is clear and accessible, with Theorem 2 and its subsequent corollaries being particularly noteworthy as they constitute the core technical advancements.
Although the concept of solving l1 regularized problems in Hilbert spaces has been explored previously, as seen in works such as [1*], the introduction of a random feature algorithm along with its rigorous theoretical analysis offers a fresh and significant contribution to the field.
Several key points warrant consideration:
1. It would be beneficial to provide a comprehensive overview of prior research on l1 regularized problems in Hilbert spaces, including citations such as [1], and to discuss alternative approaches like [2] where appropriate.
2. Enhancing the empirical section through comparisons with [1*] could strengthen the manuscript.
3. The selection of \lambda values appears somewhat arbitrary; cross-validation for accuracy across all algorithms, along with reporting support vectors and sparsity, could offer more robust insights. Alternatively, presenting plots that illustrate the impact of varying \lambda could be invaluable.
4. A deeper discussion of the results, including the observed superior performance in regression tasks compared to classification, would provide valuable context.
References such as [1] (S. Rosset et al., l1 regularization in infinite dimensional feature spaces, COLT-2007) and [2] (G. Song et al., Reproducing kernel Banach spaces with the l1 norm, Journal of Applied and Computational Harmonic Analysis) are pertinent to this discussion.
In conclusion, while the paper presents compelling theoretical findings on the randomized feature-based approximation algorithm for the l1 problem in Hilbert spaces, there is considerable room for improvement in the simulations section to bolster the overall impact of the manuscript.