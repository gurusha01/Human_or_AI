This paper seeks to develop an unbiased and consistent methodology for accurately estimating covariance matrices in high-dimensional datasets with limited sample sizes, which are further complicated by internal autocorrelation. The approach builds upon the state-of-the-art method introduced by Sancetta [San08], where the covariance matrix is shrunk towards a diagonal matrix with a shrinkage intensity proportional to the variance of the covariance matrix. The key contribution of this paper is the proposal of an analytical estimate of shrinkage intensity that incorporates a bias correction, which relates the coefficient to the effective size of the data.
Although the proposed unbiased variance estimator represents an incremental advancement of existing work ([San08]) and does not introduce significant theoretical novelty, the solution's advantages are well-founded in theory. Empirical evaluations using both synthetic examples and a real EEG dataset demonstrate that the proposed estimate is comparable to, and in some cases surpasses, the original work, particularly for small, high-dimensional datasets. A more comprehensive comparison, including cross-validation (CV) and not just computational cost, would have strengthened the analysis.
From a technical standpoint, while the paper is generally clear, there are notable flaws. The notation is often used without prior explanation, making it challenging to follow certain formulations. Additionally, inconsistencies in notation are observed throughout the paper, such as the inversion of indexes, and the organization of X is ambiguously stated as either row-wise or column-wise. The figures often lack descriptive descriptions in both captions and the main text, hindering understanding. Despite presenting an incremental work with limited originality, the proposed solution offers proven theoretical and empirical advantages. However, technical improvements are necessary to enhance clarity, including the correction of index mistakes and the introduction of formal notation at its first occurrence.