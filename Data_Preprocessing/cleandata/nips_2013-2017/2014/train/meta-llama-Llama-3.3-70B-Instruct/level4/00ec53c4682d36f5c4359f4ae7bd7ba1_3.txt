This paper presents several novel approaches to video classification using deep learning, including a two-stream formulation and multi-task learning. The methodology, implementation, and procedures are thoroughly described, making for a clear and well-written paper that effectively argues for the proposed methods with promising results.
The proposed methods demonstrate novelty, building upon and improving the framework established in [13]. Notably, the two-stream framework is particularly intriguing, as it highlights the significant enhancements afforded by the optical flow component, a finding that is likely to resonate with many researchers. While the paper is well-organized and easy to follow, it appears to span multiple contributions rather than focusing on a single, unified theme. Nonetheless, the results show substantial improvements over [13] and are competitive with the current state-of-the-art.
To further enhance the paper, several suggestions are offered:
1. Given the prominence of the two-stream approach and the incorporation of optical flow, the abstract and introduction could benefit from a more concentrated theme to provide a clearer overview of the paper's central contributions.
2. The paper lacks citations to key works in deep learning, such as "Learning Hierarchical Spatio-temporal Features for Action Recognition with Independent Subspace Analysis" (CVPR 2011), and in computer vision, including "Evaluation of local spatio-temporal features for action recognition" (BMVC 2010).
The paper offers substantial practical contributions and introduces interesting ideas that complement the main concepts in deep learning. Based on its merits and the potential for improvement, I recommend accepting the paper for NIPS 2014, contingent upon the authors addressing the suggested improvements.