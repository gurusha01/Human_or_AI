Review - Summary:
This manuscript explores the utilization of Difference of Convex Functions (DC) algorithms for minimizing the norm of the Optimal Bellman Residual (OBR), demonstrating that the OBR norm can be expressed as a difference of convex functions. This representation offers theoretical advantages in terms of error bounds, providing a solid foundation for the proposed approach.
The authors' decomposition of the OBR into a difference of convex functions is intuitively understandable and establishes a novel connection, which, although seemingly straightforward, is an original contribution that has not been previously demonstrated.
The empirical analysis involves a comparative study of DC algorithms for OBR norm minimization against other reinforcement learning methods, including Least Squares Policy Iteration (LSPI) and Fitted-Q iteration, over a set of randomly generated finite-state Markov Decision Processes (MDPs). The results indicate comparable performance with reduced variance.
Discussion:
The paper presents a compelling application of non-convex optimization algorithms to reinforcement learning, effectively motivating the use of the OBR norm and its decomposition into a difference of convex functions. This novel direction shows promise and warrants further exploration based on the initial theoretical and empirical findings.
While the paper raises several questions, particularly regarding the empirical study's methodology, it contributes meaningfully to the field. 
Recommendations:
The empirical study's scope is limited and would benefit from expansion to include additional application domains and a detailed methodology discussion. Specifically, the choice and tuning of parameters for the DC, LSPI, and Fitted-Q algorithms require clarification. Furthermore, correcting the mathematical and textual errors, although not detrimental to the paper's overall quality, is necessary for precision.
This work introduces a novel approach to value-function-based reinforcement learning, offering an interesting contribution despite areas for improvement, particularly in the empirical study.