This paper introduces a novel norm, termed scaled latent trace norm, designed to relax the convexity constraint for tensor multilinear rank. The authors provide both theoretical and experimental evidence to demonstrate the advantages of this new norm, particularly in multitask learning scenarios with inhomogeneous dimensions and no prior knowledge of low-rank modes.
The strengths of this paper include:
1. The manuscript is well-written and clear in its presentation.
2. The authors derive significant theorems that establish the upper bound of the error between empirical and true risk across various scenarios involving overlapped trace norm, latent norm, and scaled latent norm.
3. A comprehensive comparison of sample complexities for matrix completion, multitask learning, and multilinear multitask learning is provided, facilitating a thorough understanding of the results.
4. Experimental results are presented to demonstrate the superior performance of the scaled latent norm in multitask learning tasks with inhomogeneous dimensions.
However, several aspects require clarification or improvement:
1. Given that the latent trace norm has been extensively studied, notably by R. Tomioka and T. Suzuki (2013), the contribution of this paper lies in the development of the "scaled" latent trace norm, which may be perceived as a relatively incremental advancement.
2. The results in Table 2 indicate only a marginal improvement in sample complexity for the scaled latent trace norm over the latent trace norm, making it challenging to conclusively determine the superiority of the scaled latent trace norm in tensor completion.
3. The upper bounds for all scenarios involving the three norms are proportional to the inverse square root of the number of training samples, which diminishes their distinguishing characteristics. Overall, the paper presents valuable theoretical results, contributing to the field.