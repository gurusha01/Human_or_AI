The authors investigate online convex optimization with bandit feedback, building upon existing knowledge of convergence rates of T^{2/3} for convex loss functions that are either smooth or strongly convex. They make both assumptions and demonstrate convergence in T^{1/2}, which, although an improvement, is achieved through an algorithm that essentially adapts existing methods (notably from Abernethy, Hazan & Rakhlin or Saha & Tewari) and employs proof techniques that are largely unchanged, with the exception of leveraging strong convexity to enhance one inequality.
This work can be seen as incremental, given that the algorithmic and technical contributions are closely aligned with prior research. A more compelling inquiry would involve exploring the possibility of eliminating assumptions beyond Lipschitz continuity while still achieving a convergence rate of T^{1/2}. As it stands, the paper represents another installment in the study of online convex optimization, characterized by multiple assumptions regarding the loss functions, which in my view, renders it somewhat incremental.