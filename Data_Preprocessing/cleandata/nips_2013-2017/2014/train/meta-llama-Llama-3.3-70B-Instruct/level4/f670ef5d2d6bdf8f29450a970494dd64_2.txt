This manuscript offers a novel perspective on sparsity-inducing regularizations by introducing the concept of group-majorization, demonstrating that various established regularizations can be derived by appropriately selecting a group G and a seed vector v. The authors also propose gradient-based optimization methods and a heuristic for the regularization path.
The paper is well-structured, and its central idea is clearly conveyed. The characterization of sparsity-inducing regularizations is crucial, given the fundamental role of sparsity in contemporary machine learning, and this work contributes to a deeper understanding of the subject.
A distinctive aspect of this research is the utilization of the orbitope. However, the discussion on its usefulness appears to be insufficient. As indicated in Corollary 4, the orbitope and atomic norm are related, with the permutohedra and sorted l1-norms discussed in the paper being instances of atomic norms. Although the orbitope and atomic norm may differ in general, it is unclear how this distinction yields new insights. Specifically, can the orbitope be used to derive practically useful new regularizations that existing studies cannot? Further exploration of this point would be beneficial. The regularization path heuristic presented in Section 6 may be one advantage of using the orbitope, as it enables adaptive tuning of the regularization, which is not possible with the atomic norm. This study provides a new framework for interpreting sparsity-inducing regularizations using the orbitope, with intriguing content, although the benefits of employing the orbitope remain to be fully clarified.