The paper presents a novel approach to enhancing the effectiveness of Robust Principal Component Analysis (RPCA) by utilizing Low Rank Representation (LRR) with a learned dictionary A. Notably, the authors demonstrate that the incoherence parameter μ, often considered a bottleneck in RPCA's recovery guarantee, can actually correspond to additional clustering structure in the data. Under certain conditions on dictionary A, they show that LRR can exploit this structure, partially alleviating the dependence on μ and yielding a theoretically stronger guarantee for both exact low-rank and sparse decomposition, as well as its noisy extension.
This method is both novel and significant, contributing substantially to the field. It bears a close relationship to the union-of-subspace structure assumed in prior subspace clustering papers, such as those by Wang and Xu, and Soltanolkotabi and Candes, although it is less explicit about the clustering assumption, which is reasonable and potentially more general. The simulation and real data experiments validate the theoretical analysis, suggesting that this new structure could be applicable to numerous real-world applications, including text data as mentioned in the paper.
In summary, the paper makes a substantial contribution to the field of compressed sensing, warranting its acceptance by NIPS. However, several discussions and stylistic suggestions are outlined below for further improvement.
1. Lines 80-82 require rephrasing for clarity, particularly the reference to "our data" and the conditions necessary for "perfect recovery" beyond capturing all problem structures.
2. Line 88 is unclear and should be revised for precision.
3. A thorough proofread is necessary to address issues like those mentioned above, ensuring specificity, precision, and clarity in language throughout the paper.
4. The work by Wang and Xu on "Noisy Sparse Subspace Clustering" highlights how a higher coherence parameter can be beneficial for subspace clustering, differing from RPCA and matrix completion. The structure exploited in this paper combines low-rank structure with union-of-subspace cluster structure, where each cluster, rather than the overall data, needs to be low-rank.
5. Comparing the proposed algorithm against a two-step approach involving noisy subspace clustering with an ℓ1 penalty followed by PCA for each subspace could be insightful, despite the lack of provable guarantees for the latter method.
6. Section 4.2 introduces a new method for solving the subspace clustering problem with sparse data corruption, leading to significant improvements over standard RPCA+SSC on the Hopkins155 dataset. This contribution should be highlighted, as the paper offers at least three key contributions: describing a clustering structure that leads to high coherence, demonstrating how to exploit this structure implicitly using a dictionary in LRR, and partially addressing the sparse corruptions problem in subspace clustering.