This paper presents a novel deep recursive neural architecture that achieves state-of-the-art results on a challenging sentiment classification dataset, showcasing impressive performance and clear exposition. 
The proposed modifications to existing RNN models are ingenious, well-justified, and empirically validated, including:
- Distinguishing between leaf and non-terminal nodes
- Utilizing rectified linear units within the recursive framework
- Leveraging large unsupervised word vectors alongside smaller hidden non-terminal nodes
- Employing a deep architecture that introduces connections between layers and tree nodes, rather than simply replacing a single RNN layer with a deep one - an alternative approach could be to only use the output of the last hidden layer at each node as input to the next parent node, effectively removing the connection from matrix V.
However, it is noted that the results in Table 1 (a) should have been based on the development set rather than the final test set, as the current approach may be overfitting to the test set.
Additionally, there are minor typos, such as "comprise a class of architecture" and "sentiment classificationd dataset", which should be corrected for clarity and accuracy.