This manuscript addresses the transportability problem, a generalization of causal effect identifiability under given causal assumptions or knowledge encoded in a causal diagram, building upon the work of Bareinboim et al. presented at NIPS last year. The transportability problem considers multiple domains - a target domain and one or more source domains - that share a known qualitative causal structure over observed and latent variables, with structural equations and selection variables in selection diagrams that may differ between domains. The goal is to determine if a certain interventional probability in the target domain can be identified non-parametrically from available observational and interventional distributions across all domains, where a subset of observed variables in each domain can be controlled for interventional data collection.
The paper presents significant contributions by demonstrating the completeness of the sound algorithm from Bareinboim et al.'s work and Pearl's do-calculus regarding this problem. These findings contribute to the important research areas of "external validity" and "meta-analysis". Although parts of the paper are dense and may be challenging for readers unfamiliar with prior work, the main ideas are clear. Several points require clarification or consideration:
1. Definition 1 implicitly adopts Pearl's definition of structural equation models, where each equation is associated with a single U-variable. However, the subsequent examples feature multiple U-variables, which may cause confusion.
2. Definition 2 assumes that if a set Z can be intervened upon in a domain, any subset of Z can also be intervened upon without affecting other variables in Z. It is worth exploring whether this assumption can be relaxed.
3. The statement of Theorem 1, originally from Bareinboim et al. (2013), seems unusual. The meaning of a do-operator having "no Si-variables" is unclear, as it appears to imply that the do-operator does not apply to any Si-variable, which would automatically follow if it applies to a subset of I_z^i.
4. Footnote 5 suggests using causal discovery methods to learn causal diagrams. However, it is essential to note that these algorithms rarely learn full causal diagrams with latent variables. Additionally, the process of learning selection diagrams from data requires further explanation.
5. Definition 5 is crucial but dense. Providing a separate definition for "hedge" before defining "mz-shedge" as a collection of hedges satisfying specific conditions could improve readability. Explicitly linking conditions 1, 2, and 3 to conditions (i) and (ii) in the subsequent paragraph would also aid understanding. The remark about potentially augmenting the root set R is unclear and warrants clarification.
Overall, the paper provides new and useful results on an interesting problem, contributing to the ongoing research in transportability and causal inference.