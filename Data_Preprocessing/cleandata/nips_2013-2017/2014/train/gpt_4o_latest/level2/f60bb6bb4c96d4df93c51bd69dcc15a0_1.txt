This paper introduces a novel continuous relaxation for the balanced k-cut problem, addressing limitations in existing methods such as spectral clustering and recent relaxations like the asymmetric ratio Cheeger cut. The authors propose a tight relaxation that ensures better alignment with the original objective of minimizing the normalized cut and develop a monotonic descent algorithm for optimizing the resulting non-convex sum-of-ratios problem. Extensive experiments demonstrate the superiority of the proposed method over state-of-the-art approaches across multiple datasets and balancing functions.
Strengths:
1. Novelty and Contribution: The paper presents a significant improvement over existing methods by proposing a tighter relaxation for the balanced k-cut problem. The authors also highlight the limitations of prior relaxations, such as those in [13], and demonstrate how their approach addresses these issues.
2. Theoretical Rigor: The paper provides strong theoretical guarantees, including proofs of the exactness of the relaxation under certain conditions and the monotonic descent property of the proposed algorithm. These contributions are well-grounded and advance the state of the art.
3. Algorithm Design: The monotonic descent algorithm for the sum-of-ratios optimization problem is a key contribution. Its ability to handle non-convex constraints and ensure feasible solutions is noteworthy and could have broader applications beyond this specific problem.
4. Comprehensive Experiments: The authors conduct extensive experiments on diverse datasets, comparing their method with a wide range of state-of-the-art clustering techniques. The results consistently show that the proposed method achieves the best or strictly best balanced k-cuts and competitive clustering errors.
5. Flexibility: The framework supports various balancing functions, including ratio cut, normalized cut, and asymmetric ratio Cheeger cut, making it adaptable to different application scenarios. The ability to incorporate label information in a transductive setting is another strength.
Weaknesses:
1. Complexity and Scalability: While the proposed method demonstrates strong performance, the computational complexity of the monotonic descent algorithm is not explicitly analyzed. It would be helpful to understand its scalability to very large graphs, especially compared to simpler methods like spectral clustering.
2. Clustering Performance vs. Balanced Cuts: In some cases (e.g., vertebral, 20news), the method achieves the best cuts but relatively high clustering errors. This discrepancy suggests that the method may prioritize balanced cuts over clustering quality in certain scenarios.
3. Limited Discussion of Limitations: While the authors acknowledge the failure of competing methods in degenerate cases, they do not explicitly discuss potential limitations of their own approach, such as sensitivity to graph construction parameters or initialization.
Suggestions for Improvement:
1. Provide a detailed complexity analysis of the proposed algorithm and discuss its scalability to larger datasets.
2. Explore strategies to balance the trade-off between achieving optimal balanced cuts and minimizing clustering errors.
3. Include a discussion of potential limitations, such as sensitivity to hyperparameters or graph construction, and suggest ways to mitigate these issues.
4. Consider extending the experimental evaluation to include runtime comparisons with competing methods.
Recommendation:
This paper makes a significant contribution to the field of graph-based clustering by addressing a long-standing challenge with a novel and theoretically sound approach. The proposed method is well-justified, and the experimental results are compelling. While there are some concerns about scalability and clustering performance in specific cases, these do not detract from the overall quality of the work. I recommend accepting this paper for presentation at the conference, as it represents a meaningful advancement in the domain of graph-based clustering and optimization.