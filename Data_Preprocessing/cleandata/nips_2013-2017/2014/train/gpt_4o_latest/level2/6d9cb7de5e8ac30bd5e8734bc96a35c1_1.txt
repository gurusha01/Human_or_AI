This paper addresses the problem of multitask learning (MTL) using tensor representations, proposing a new norm, the scaled latent trace norm, to overcome limitations of existing tensor norms. The authors argue that the existing overlapped and latent trace norms are suboptimal for tensors with heterogeneous dimensions or multilinear ranks, which are common in real-world MTL problems. The scaled latent trace norm is designed to adapt to these heterogeneities, offering improved theoretical guarantees and practical performance. The authors provide a rigorous analysis of the excess risk for the proposed norm and compare it against existing norms in various settings, including matrix completion, multitask learning, and multilinear multitask learning (MLMTL). Empirical results on synthetic and real-world datasets (Restaurant and School datasets) demonstrate the advantages of the scaled latent trace norm.
Strengths:
1. Novelty and Contribution: The introduction of the scaled latent trace norm is a significant contribution, addressing a key limitation of existing tensor norms. The theoretical analysis is thorough, with clear derivations of excess risk bounds and sample complexities.
2. Practical Relevance: The proposed norm is particularly useful for real-world MTL problems where tensor dimensions and ranks are heterogeneous. The experiments on real datasets (Restaurant and School) highlight the practical utility of the method.
3. Comprehensive Evaluation: The paper evaluates the scaled latent trace norm against both existing tensor norms and matrix-based MTL approaches. The results consistently show that the scaled latent trace norm performs competitively or better, particularly in heterogeneous settings.
4. Theoretical Rigor: The paper provides a detailed theoretical analysis, including Rademacher complexity bounds and sample complexity comparisons. The results are well-supported by both theory and experiments.
Weaknesses:
1. Clarity and Accessibility: While the theoretical analysis is rigorous, the presentation is dense and may be challenging for readers unfamiliar with tensor norms or multitask learning. Simplifying some derivations or providing intuitive explanations could improve accessibility.
2. Limited Discussion of Limitations: The paper does not explicitly discuss the computational complexity of the scaled latent trace norm or its scalability to very large datasets. This could be a practical concern for adoption in real-world applications.
3. Experimental Scope: Although the experiments are well-designed, additional comparisons with non-convex tensor decomposition methods or other state-of-the-art MTL approaches could strengthen the empirical evaluation.
4. Hyperparameter Selection: The paper mentions cross-validation for hyperparameter tuning but does not discuss the sensitivity of the scaled latent trace norm to these parameters. A more detailed analysis of hyperparameter robustness would be valuable.
Recommendation:
This paper makes a strong theoretical and practical contribution to the field of multitask learning and tensor methods. The scaled latent trace norm is a novel and well-motivated solution to a significant problem, and the results are compelling. However, the paper could benefit from improved clarity, a discussion of computational limitations, and broader experimental comparisons. I recommend acceptance, provided the authors address these concerns in the final version.
Pro Arguments:
- Novel and theoretically sound contribution.
- Practical utility demonstrated on real-world datasets.
- Comprehensive theoretical and empirical evaluation.
Con Arguments:
- Dense presentation may limit accessibility.
- Limited discussion of computational scalability and hyperparameter sensitivity.
Overall Rating: Strong Accept