The paper introduces a novel Low-Rank Time-Frequency Synthesis (LRTFS) model, bridging the gap between traditional nonnegative matrix factorization (NMF) approaches and generative models of raw audio signals. The authors propose a probabilistic framework that models the raw signal directly, rather than its short-time Fourier transform (STFT), enabling multi-resolution representations. Two estimation methods are presented: Maximum Joint Likelihood Estimation (MJLE) and Maximum Marginal Likelihood Estimation (MMLE), with a focus on MJLE due to its computational feasibility. The paper demonstrates the model's effectiveness in music decomposition and speech enhancement tasks, showing competitive performance compared to baseline methods.
Strengths:
1. Novelty and Contribution: The LRTFS model is a significant advancement over traditional NMF approaches, as it directly models raw signals and supports multi-resolution representations. This is a clear step forward in audio signal processing.
2. Theoretical Rigor: The paper is grounded in a solid probabilistic framework, with detailed derivations of the EM algorithms for MJLE and MMLE. The connection to sparse Bayesian learning (SBL) is insightful and positions the work within a broader context.
3. Practical Applications: The experiments demonstrate the model's utility in real-world tasks such as music decomposition and speech enhancement. The multi-resolution capability is particularly compelling, as it addresses limitations of fixed-resolution NMF approaches.
4. Clarity of Results: The experimental results are well-presented, with clear comparisons to baseline methods. The reported SNR improvements in speech enhancement are competitive, and the qualitative analysis of music decomposition is convincing.
Weaknesses:
1. Scalability of MMLE: While MMLE is theoretically promising, its computational complexity limits its practical applicability. The authors acknowledge this and defer scalable implementation to future work, but this leaves a gap in the current study.
2. Limited Experimental Scope: The experiments focus on two tasks (music decomposition and speech enhancement) with relatively small datasets. Broader evaluations, including diverse noise types and larger datasets, would strengthen the paper's claims.
3. Hyperparameter Sensitivity: The reliance on manual tuning of the hyperparameter Î» is a limitation. A more systematic approach to hyperparameter selection would enhance reproducibility and robustness.
4. Comparative Analysis: While the paper compares LRTFS to baseline methods like IS-NMF and OMLSA, it does not benchmark against other state-of-the-art generative models or deep learning approaches, which are increasingly prevalent in audio signal processing.
Suggestions for Improvement:
1. Develop a scalable algorithm for MMLE to fully realize its potential and compare it with MJLE in future work.
2. Expand the experimental section to include more diverse datasets and noise types, as well as comparisons to modern deep learning-based methods.
3. Automate or provide guidelines for hyperparameter selection to improve usability.
4. Include additional ablation studies to isolate the contributions of multi-resolution modeling and other design choices.
Recommendation:
The paper presents a novel and well-motivated approach with strong theoretical underpinnings and promising initial results. Despite some limitations, the work is a valuable contribution to the field of audio signal processing. I recommend acceptance, provided the authors address the scalability of MMLE and expand the experimental evaluation in future iterations.