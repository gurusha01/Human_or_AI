The paper presents a novel stochastic variational inference (SVI) algorithm tailored for Hidden Markov Models (HMMs) in time-dependent data settings. The primary contribution is the development of an SVI-based approach, termed SVIHMM, which addresses the computational challenges of applying Bayesian inference to very large time series datasets. The authors propose a method to handle dependencies within the chain by leveraging memory decay and introduce an adaptive buffering mechanism to mitigate edge effects in subchains. The algorithm is validated on synthetic datasets and a large genomics dataset, demonstrating its scalability and effectiveness compared to batch variational Bayes (VB) and other methods.
Strengths:
1. Significant Contribution: The paper addresses a critical gap in the application of SVI to time-dependent models, extending its applicability beyond independent or exchangeable data settings. This is a meaningful advancement for Bayesian inference in large-scale time series.
2. Scalability: The proposed algorithm demonstrates substantial computational efficiency, enabling Bayesian inference on datasets that are otherwise infeasible for batch methods. For example, the application to a 250-million-observation genomics dataset is impressive.
3. Theoretical Rigor: The authors provide theoretical guarantees for convergence to a local mode, which strengthens the reliability of the proposed method.
4. Practical Utility: The algorithm is shown to achieve comparable or better performance than batch VB and other methods in terms of predictive log-probability and false discovery rate (FDR), making it practically useful for real-world applications.
5. Robustness via Buffering: The adaptive buffering mechanism (GrowBuf) is a clever solution to edge effects, ensuring that subchain-based updates remain accurate without significant computational overhead.
Weaknesses:
1. Limited Novelty in Subsampling: While the buffering mechanism is innovative, the subsampling approach itself is a relatively straightforward extension of existing SVI techniques. The novelty primarily lies in its adaptation to HMMs.
2. Experimental Scope: The experiments are well-designed but limited in diversity. The synthetic datasets focus on specific scenarios (diagonally dominant and reversed cycles), which may not fully capture the variety of real-world time series data. Additional datasets from other domains could strengthen the empirical validation.
3. Clarity of Presentation: The paper is dense and highly technical, which may hinder accessibility for a broader audience. For instance, the detailed derivations could be supplemented with more intuitive explanations or diagrams to clarify key ideas.
4. Assumptions on Stationarity: The assumption of stationarity in the HMM may limit the applicability of the method to non-stationary time series, which are common in real-world scenarios.
Arguments for Acceptance:
- The paper introduces a scalable and theoretically sound method for Bayesian inference in large-scale time series, addressing a significant computational bottleneck.
- The proposed algorithm demonstrates strong empirical performance and practical utility in genomics, a field with pressing computational challenges.
- The adaptive buffering mechanism is a novel and effective solution to edge effects in subchain-based inference.
Arguments Against Acceptance:
- The experimental evaluation could be more comprehensive, particularly with additional datasets from diverse domains.
- The paper's presentation could be improved for clarity and accessibility, especially for readers less familiar with variational inference or HMMs.
Recommendation:
I recommend acceptance with minor revisions. The paper makes a valuable contribution to the field of scalable Bayesian inference, and its practical implications are significant. However, the authors should consider expanding the experimental evaluation and improving the clarity of the manuscript to maximize its impact.