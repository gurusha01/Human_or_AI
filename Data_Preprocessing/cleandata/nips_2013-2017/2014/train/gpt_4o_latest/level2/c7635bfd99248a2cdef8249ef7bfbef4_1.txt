The paper proposes a novel framework, "Inference by Learning" (IbyL), for optimizing graphical models, specifically Markov Random Fields (MRFs), with a focus on computer vision tasks. The key contribution is a multi-scale pruning scheme that leverages trained classifiers to progressively reduce the solution space while maintaining high accuracy. The authors demonstrate significant speed-ups and improved accuracy compared to traditional optimization methods, particularly for stereo matching, optical flow estimation, and image restoration tasks. The approach is generic, application-agnostic, and applicable to any MRF problem. The authors also provide experimental results and make their code publicly available.
Strengths:
1. Novelty and Innovation: The paper introduces a unique combination of multi-scale optimization and classifier-based label pruning. The use of trained classifiers to guide pruning decisions is a significant departure from heuristic-based methods, making the approach more robust and adaptable.
2. Practical Impact: The framework achieves substantial speed-ups (up to 10x for optical flow) while maintaining or improving solution accuracy. This is highly relevant for computationally intensive tasks in computer vision.
3. Generality: The method is designed to be application-agnostic, relying solely on energy function features. This makes it broadly applicable across various MRF problems, as demonstrated in the experiments.
4. Thorough Evaluation: The authors evaluate their method on multiple tasks and datasets, providing metrics such as energy ratio, speed-up factor, and label agreement. The results are compelling, with the framework outperforming baseline methods in both speed and accuracy.
5. Reproducibility: The availability of code and detailed experimental setup enhances the reproducibility of the work.
Weaknesses:
1. Limited Scope of Features: While the framework is general, the features used for training classifiers are relatively simple and not application-specific. Incorporating domain-specific features could further improve performance.
2. Classifier Training Overhead: The need for offline training of classifiers introduces an overhead that might limit the applicability of the method in scenarios where training data is scarce or diverse.
3. Evaluation on Advanced Grouping Functions: The paper uses basic 2Ã—2 subgrid grouping functions for model coarsening. More advanced grouping strategies, as mentioned in the future work, could have been explored to strengthen the results.
4. Focus on Pairwise MRFs: The framework is evaluated only on pairwise MRFs. Extending the approach to higher-order graphical models would better demonstrate its generality.
5. Limited Analysis of Failure Cases: While the method performs well overall, the paper does not extensively discuss scenarios where the pruning might fail (e.g., highly noisy or discontinuous regions).
Recommendation:
I recommend acceptance of this paper, as it presents a significant contribution to the field of graphical model optimization. The combination of multi-scale optimization and classifier-based pruning is both novel and impactful. The experimental results are robust, and the paper is well-written and clearly organized. However, the authors should consider addressing the limitations in future work, particularly by exploring advanced grouping functions, higher-order models, and application-specific features.
Pro and Con Arguments for Acceptance:
Pros:
- Novel and impactful approach to MRF optimization.
- Significant speed-ups and accuracy improvements demonstrated across multiple tasks.
- General framework applicable to various MRF problems.
- Thorough experimental evaluation and code availability.
Cons:
- Limited exploration of advanced grouping functions and higher-order models.
- Offline classifier training introduces overhead.
- Lack of detailed analysis of failure cases.
In summary, the paper makes a strong scientific contribution and is well-suited for presentation at the conference.