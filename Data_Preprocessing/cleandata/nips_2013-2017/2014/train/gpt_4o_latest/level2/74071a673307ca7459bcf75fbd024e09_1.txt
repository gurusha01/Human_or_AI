This paper introduces a framework for constructing structured priors in Bayesian models, with a focus on sparse structures. The authors propose defining priors via the information projection of a base distribution onto a constrained domain. For intractable cases, they suggest parameterized approximations indexed by subsets of the domain. The paper's key contributions include demonstrating the equivalence between information projection and density restriction, formulating sparse support estimation as a submodular optimization problem, and proposing an efficient greedy forward selection algorithm with a theoretical guarantee of (1-1/e) optimality. The framework is validated on simulated data and high-dimensional neuroimaging data, showing superior performance in support recovery and predictive accuracy compared to baseline methods.
Strengths:
1. Novelty and Theoretical Contributions: The paper provides a principled approach to designing structured priors using information projection, extending the maximum entropy principle to sparse domains. The theoretical results, such as the submodularity of the sparse support estimation problem and the guarantees for the greedy algorithm, are significant contributions.
2. Practical Relevance: The framework addresses a critical challenge in high-dimensional data analysis, particularly in neuroscience, where sparse priors are essential for interpretability and efficiency. The application to fMRI data demonstrates the method's utility in a real-world setting.
3. Experimental Validation: The experiments on simulated and neuroimaging data are comprehensive. The proposed method outperforms state-of-the-art baselines (e.g., Lasso, ARD, Spike and Slab) in both support recovery and predictive accuracy, particularly in challenging scenarios with limited samples or high noise.
4. Scalability: The method's scalability to high-dimensional problems, such as 100,000-voxel fMRI data, is noteworthy. The biologically plausible results further validate its applicability in neuroscience.
Weaknesses:
1. Clarity: While the theoretical derivations are rigorous, the paper's presentation is dense and may be challenging for readers unfamiliar with information theory or Bayesian inference. Simplifying the notation and providing more intuitive explanations would improve accessibility.
2. Limited Discussion of Limitations: The paper does not sufficiently discuss potential limitations, such as the reliance on the choice of base distribution or the impact of the mean-field approximation in Spike and Slab models. Addressing these would strengthen the work.
3. Comparative Analysis: While the method is compared to several baselines, the paper could benefit from a deeper exploration of why certain baselines (e.g., Spike and Slab) perform poorly and how the proposed method overcomes these challenges.
4. Generality: The focus is primarily on sparsity. While the authors mention future work on other structural constraints (e.g., low rank), it would be helpful to include preliminary results or insights on the generalizability of the framework.
Recommendation:
I recommend acceptance of this paper, as it makes a significant theoretical and practical contribution to Bayesian modeling with structured priors. The proposed framework is novel, well-supported by theory, and demonstrates strong empirical performance. However, the authors should consider improving the clarity of the presentation and addressing the aforementioned weaknesses in the final version.
Arguments Pro Acceptance:
- Strong theoretical foundation with novel contributions.
- Demonstrated practical utility in high-dimensional, real-world applications.
- Superior performance compared to state-of-the-art baselines.
Arguments Against Acceptance:
- Dense presentation may hinder accessibility for a broader audience.
- Limited discussion of limitations and generalizability.
Overall, this paper advances the state of the art in structured Bayesian inference and has the potential to impact both theoretical research and practical applications in fields like neuroscience.