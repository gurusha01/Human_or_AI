The paper presents a novel probabilistic regression framework, Local Gaussian Regression (LGR), which bridges the gap between Locally Weighted Regression (LWR) and Gaussian Process Regression (GPR). By leveraging a variational inference scheme, the authors propose a scalable and efficient method that retains the computational advantages of LWR while incorporating the probabilistic rigor of GPR. The approach is particularly relevant for real-time applications like robotics, where computational efficiency and adaptability to non-stationary data are critical. The paper demonstrates the method's efficacy through extensive experiments on synthetic and real-world robotic datasets, showing competitive or superior performance compared to state-of-the-art methods such as LWPR and I-SSGPR.
Strengths:
1. Novelty and Technical Contribution: The paper introduces a unique connection between LWR and GPR, offering a principled probabilistic model that addresses the limitations of both approaches. The variational approximation and incremental learning framework are well-motivated and technically sound.
2. Clarity and Presentation: The paper is well-written, with clear and consistent notation. The theoretical foundations are explained in detail, and the experimental results are presented comprehensively.
3. Significance: The method addresses a critical problem in robotics—real-time learning from large-scale, non-stationary data. The ability to adaptively add local models and update distance metrics online is a significant advancement.
4. Experimental Validation: The experiments are thorough, covering diverse datasets and comparing against strong baselines. The results demonstrate that LGR achieves comparable or better accuracy while using fewer resources and requiring less manual tuning than LWPR.
Weaknesses:
1. Implementation Availability: The paper does not mention the availability of the implementation, which would enhance reproducibility and utility for the community.
2. Probabilistic Evaluation: While the method is probabilistic, the experiments focus primarily on MSE and nMSE metrics. Evaluating predictive uncertainty (e.g., log p(y*)) would strengthen the paper, especially for applications like robotics where uncertainty quantification is crucial.
3. Variational Approximation: The paper does not provide sufficient detail on the convergence behavior of the variational parameters (e.g., β). An analysis of how these approximations impact the results would be valuable.
4. Computational Cost: While the method is scalable, the global β parameters may introduce additional computational overhead. Clarification on the interlacing updates and their efficiency would improve the paper.
5. Fairness in Comparisons: The experimental setup for comparing LGR with I-SSGPR raises concerns about fairness, particularly regarding differences in feature/model complexity.
Arguments for Acceptance:
- The paper offers a novel and technically sound contribution to scalable probabilistic regression.
- The method is highly relevant to real-time robotics applications, addressing a critical need in the field.
- The experiments are robust and demonstrate the method's practical utility.
Arguments Against Acceptance:
- The lack of probabilistic evaluation metrics limits the demonstration of the method's full potential.
- Implementation details and availability are missing, which could hinder reproducibility.
- Some aspects of the variational approximation and computational cost require further clarification.
Recommendation:
The paper is a strong candidate for acceptance, contingent on addressing the concerns raised during the rebuttal phase. Specifically, the authors should clarify the variational approximation's impact, provide probabilistic evaluation metrics, and discuss implementation availability. Overall, the paper is a valuable contribution to the field and aligns well with the conference's focus on advancing scalable and efficient machine learning methods.