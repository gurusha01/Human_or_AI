The paper introduces a novel framework for online multi-task learning where multiple learners share a single annotator with limited bandwidth. The proposed algorithm, SHAMPO (SHared Annotator for Multiple PrOblems), is a perceptron-like method that employs an exploration-exploitation strategy for task querying. The authors provide a theoretical analysis bounding the expected cumulative errors and demonstrate the algorithm's applicability to contextual and dueling bandit problems. Empirical evaluations on diverse datasets, including OCR, vowel prediction, and document classification, show that SHAMPO outperforms naive baselines like uniform and exploit-only strategies.
Strengths:
1. Novelty: The framework addresses a practical and underexplored problem of shared annotation in multi-task learning, which is particularly relevant for resource-constrained settings.
2. Theoretical Rigor: The mistake-bound analysis is well-grounded, and the authors provide insights into the trade-offs between exploration and exploitation, as well as the role of priors in improving performance.
3. Empirical Validation: The experiments are comprehensive, covering multiple datasets and task configurations. The results convincingly demonstrate that SHAMPO achieves better performance for the same annotation cost, especially with aggressive updates and well-chosen priors.
4. Generality: The reduction of multi-task learning to contextual bandit problems broadens the applicability of the algorithm, making it relevant for settings like preference learning and multi-class classification.
Weaknesses:
1. Limited Use of Task Relationships: The algorithm does not leverage inter-task relationships, which is a significant limitation compared to other multi-task learning approaches that exploit shared structure or parameter sharing. This reduces its appeal for tasks with inherent correlations.
2. Lack of Sampling Complexity Analysis: While the mistake-bound analysis is insightful, the absence of sampling complexity results leaves a critical gap, as this is crucial for understanding the efficiency of the proposed querying strategy.
3. Weak Baselines: The empirical comparisons are limited to naive baselines (uniform and exploit-only). Including a fully supervised baseline would provide a clearer picture of task difficulty and the algorithm's relative performance.
4. Limited Discussion on Prior Selection: Although priors are shown to improve performance, the paper lacks a systematic discussion or methodology for generating effective priors, which could be critical in real-world applications.
Suggestions for Improvement:
1. Include results for a fully supervised baseline to better contextualize the difficulty of the tasks and the gains achieved by SHAMPO.
2. Compare the proposed framework to learning tasks separately using K selective sampling algorithms, both conceptually and empirically, to highlight the benefits of shared annotation.
3. Extend the analysis to include sampling complexity, which would strengthen the theoretical contribution and provide practical insights into the algorithm's efficiency.
4. Explore methods to incorporate task relationships, either through shared representations or explicit modeling of task dependencies, to enhance the framework's generality and applicability.
Pro and Con Arguments for Acceptance:
- Pro: The paper addresses a novel and practical problem, provides a theoretically sound algorithm, and demonstrates strong empirical performance across diverse tasks.
- Con: The lack of sampling complexity analysis and the omission of task relationships limit the paper's theoretical and practical impact. Additionally, the baselines are weak, and the absence of a fully supervised comparison leaves some questions unanswered.
Recommendation: Weak Accept. While the paper makes a meaningful contribution to the field of online multi-task learning, addressing the identified weaknesses would significantly enhance its impact and scope.