The paper presents "Large Scale Detection through Adaptation" (LSDA), a novel approach to transform image classifiers into object detectors, addressing the challenge of limited bounding box annotations for large-scale object detection. The method leverages the architecture of Krizhevsky et al.'s CNN, pre-trained on classification data, and fine-tunes it using a small subset of bounding box-labeled categories. The adaptation process involves three key steps: incorporating a background class, transferring category-invariant features, and approximating category-specific transformations for classes without bounding box annotations. The approach is evaluated on the ImageNet LSVRC-2013 detection challenge, demonstrating significant improvements over baseline methods.
Strengths:
1. Relevance and Significance: The problem of scaling object detection to tens of thousands of categories with limited bounding box annotations is highly relevant. The proposed LSDA algorithm offers a practical solution by leveraging abundant classification data, reducing the reliance on expensive and time-consuming annotation efforts.
2. Technical Contribution: The paper introduces a well-motivated domain adaptation framework, treating the transformation from classification to detection as a domain shift. The method achieves a 50% relative improvement in mean average precision (mAP) on held-out categories, showcasing its efficacy.
3. Scalability: The ability to produce a 7.6K-category detector using classification data for most categories is a compelling demonstration of the method's scalability.
4. Clarity: The paper is generally well-written, with a clear explanation of the LSDA algorithm and its components. The experiments are thorough, including ablation studies and error analysis, which provide insights into the method's strengths and limitations.
Weaknesses:
1. Baseline Comparisons: The paper lacks comparisons to key baselines, such as training on full images, a Multiple Instance Learning (MIL)-based iterative approach, or a simple classifier predicting a single bounding box. These comparisons would provide a more comprehensive evaluation of the proposed method's advantages.
2. Experimental Clarity: While the experiments are detailed, the presentation of results in Table 1 is somewhat unclear. The methods compared and their specific configurations need better explanation to aid reproducibility.
3. Dependence on CNN Features: The results suggest that much of the performance gain may stem from improvements in CNN features rather than the adaptation method itself. This raises questions about the generalizability of the approach to other architectures or feature representations.
4. Limited Novelty: While the approach is novel in its specific adaptation strategy, it builds heavily on existing work, such as R-CNN and domain adaptation techniques. The simplicity of the method may limit its broader impact.
Recommendation:
The paper addresses a significant problem and provides a practical, scalable solution with promising results. However, the lack of key baseline comparisons and limited novelty in the adaptation strategy temper its impact. I recommend acceptance, provided the authors address the clarity issues in the experiments section and include additional baseline comparisons in a future revision.
Arguments for Acceptance:
- Tackles a highly relevant problem with a practical and scalable solution.
- Demonstrates significant performance improvements on a challenging benchmark.
- Provides a clear and well-structured explanation of the method.
Arguments Against Acceptance:
- Missing comparisons to key baselines limit the evaluation's comprehensiveness.
- Relies heavily on existing architectures and feature improvements, with limited methodological novelty.
In conclusion, the paper makes a meaningful contribution to large-scale object detection and is a valuable addition to the conference, despite some areas for improvement.