The paper introduces Deep Gaussian Mixture Models (Deep GMMs) as a novel extension of Gaussian Mixture Models (GMMs) to multiple layers, positioning them as scalable and expressive generative models for real-valued data, particularly images. The authors propose an EM-based training algorithm, incorporating heuristics such as hard EM and a "folding" trick to simplify the optimization process. They demonstrate that Deep GMMs generalize better than shallow GMMs with comparable numbers of parameters and achieve competitive results in density estimation tasks on benchmark datasets. However, the paper raises concerns about its originality, particularly its overlap with the "Deep Mixtures of Factor Analyzers" (DMFA) model from ICML 2012, which shares key concepts like layer-wise pretraining and hierarchical structure.
Strengths:
1. Technical Soundness: The paper provides a clear mathematical formulation of Deep GMMs and their training process. The use of EM for optimization is well-justified, and the heuristics for scalability (e.g., hard EM and coordinate ascent) are practical and effective.
2. Scalability and Parallelization: The authors emphasize the parallelizability of their approach, making it suitable for large datasets. This is a significant contribution to the field of deep generative models, which often struggle with scalability.
3. Empirical Validation: The experiments on the BSDS300 and Tiny Images datasets are thorough, demonstrating that Deep GMMs outperform shallow GMMs and are competitive with state-of-the-art methods like RNADE.
4. Clarity: The paper is well-written and organized, with detailed explanations of the methodology, experiments, and results.
Weaknesses:
1. Originality: The paper's novelty is undermined by its similarity to the DMFA model. While the authors highlight differences (e.g., joint training of layers in Deep GMMs vs. layer-wise training in DMFA), these distinctions are not sufficiently emphasized. The "folding" trick, in particular, appears conceptually similar to DMFA's hierarchical clustering approach.
2. State-of-the-Art Comparison: While Deep GMMs perform well, they fall short of the ensemble RNADE model, which is the current state-of-the-art. The paper could benefit from a deeper discussion of why Deep GMMs are preferable despite this gap.
3. Limited Scope: The experiments are focused on image patches and downscaled images. Extending the analysis to other types of data (e.g., text, audio) would strengthen the paper's claims about the generality of Deep GMMs.
4. Significance of Contributions: The paper positions Deep GMMs as a scalable alternative to other deep generative models, but its practical impact is unclear given the availability of more expressive models like VAEs and GANs.
Recommendation:
While the paper makes a solid technical contribution and provides a scalable approach to deep generative modeling, its originality and significance are questionable due to overlaps with prior work. The authors should clarify the novel aspects of their method and explicitly differentiate it from DMFA. Additionally, expanding the scope of experiments and addressing the performance gap with state-of-the-art methods would enhance the paper's impact. 
Arguments for Acceptance:
- Well-written and technically sound.
- Scalable approach with practical heuristics for training.
- Competitive performance on benchmark datasets.
Arguments Against Acceptance:
- Insufficient differentiation from prior work (DMFA).
- Limited experimental scope and weaker performance compared to ensemble RNADE.
- Lack of clarity on the broader impact of the contributions.
Final Recommendation: Borderline Accept. The paper is a valuable contribution but requires stronger emphasis on originality and broader experimental validation to justify its acceptance.