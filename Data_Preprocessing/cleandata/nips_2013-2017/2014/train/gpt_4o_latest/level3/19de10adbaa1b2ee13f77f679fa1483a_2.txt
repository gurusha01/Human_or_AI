The paper introduces Deep Attention Selective Networks (dasNet), a novel architecture that incorporates selective attention into convolutional neural networks (CNNs) by dynamically altering convolutional filter sensitivities during classification. This feedback mechanism, inspired by biological vision systems, allows dasNet to iteratively refine its focus on specific features, improving classification performance. The authors leverage Separable Natural Evolution Strategies (SNES) to optimize the gating parameters of dasNet, enabling it to outperform state-of-the-art models on CIFAR-10 and CIFAR-100 datasets.
Strengths:
1. Innovative Approach: The paper presents a significant departure from traditional feedforward CNNs by introducing a feedback mechanism that adapts filter weights during evaluation. This is a meaningful step toward more biologically inspired and adaptive neural networks.
2. Performance Gains: DasNet achieves impressive classification accuracy, setting a new state-of-the-art for unaugmented CIFAR datasets. The focus on correcting misclassifications in ambiguous cases highlights the model's practical utility.
3. Relevance and Originality: The work is well-motivated and addresses a critical limitation of static CNNs. The use of SNES for optimizing a large parameter space is a novel application of evolutionary strategies in this context.
4. Clarity of Exposition: The paper is generally well-written, with a clear explanation of the dasNet architecture and its training process. The inclusion of Algorithm 1 and detailed experimental results enhances reproducibility.
Weaknesses:
1. Black Box Nature: While dasNet demonstrates strong performance, the reasons behind its effectiveness remain unclear. The analysis of learned parameters (e.g., gating variables and θ) and image representations is insufficiently detailed, limiting interpretability.
2. Unclear Theoretical Justifications: The necessity of regularizing θ, despite its small values due to sampling from a prior, is not well-explained. Similarly, the gradient updates on θ lack theoretical grounding.
3. Analysis of Difficult Cases: The paper misses an opportunity to analyze cases misclassified by standard CNNs but correctly classified by dasNet. Such insights could shed light on the model's unique contributions.
4. Connection to Dynamical Systems: The feedback mechanism aligns with recurrent networks, yet the paper does not explore potential links to dynamical systems, which could provide a richer theoretical framework.
5. Ambiguity in Visualizations: The analysis of the cat image (Figure 3) is not particularly illuminating. The changes in filter activations are described but not interpreted meaningfully.
6. Typos and Ambiguities: Some equations, such as Eqn. 11, lack clarity (e.g., summation indices are unspecified). Terms like 'x' and 'd' are undefined in the text following Eqn. 11, which could confuse readers.
Suggestions for Improvement:
1. Provide a more thorough analysis of gating variables and their evolution over successive passes, particularly in smaller image regions.
2. Investigate the model's performance on challenging cases and offer qualitative insights into why dasNet succeeds where standard CNNs fail.
3. Explore connections to dynamical systems and recurrent networks to contextualize the feedback mechanism.
4. Clarify ambiguous equations and address typos to improve readability.
Recommendation:
While the paper has notable strengths in originality and performance, its weaknesses in interpretability and theoretical grounding warrant further revisions. If the authors address these concerns, the paper could make a significant contribution to the field. Conditional acceptance is recommended.