The paper proposes a novel subsampling algorithm, Influence Weighted Subsampling (IWS-LS), to accelerate least squares linear regression while ensuring robustness to outliers and corrupted predictors. By leveraging the concept of influence, which measures the impact of individual data points on regression estimates, the authors develop a method that selectively avoids highly influential (and potentially corrupted) points. Theoretical analysis demonstrates that IWS-LS reduces both bias and variance under a generalized corrupted observation model. The paper also introduces two practical approximations, aIWS-LS and aRWS-LS, which achieve computational efficiency while maintaining performance. Experimental results on simulated and real-world datasets validate the proposed methods, showing improved robustness compared to state-of-the-art randomized least squares techniques.
Strengths:
1. Theoretical Rigor: The paper provides a thorough theoretical foundation for the proposed algorithm, including detailed error bounds and comparisons with existing methods. This contributes to the robustness of the claims.
2. Novelty in Approach: While the work builds on prior concepts like leverage-based subsampling, the use of influence as a diagnostic tool for robust subsampling is a novel contribution to the field.
3. Clarity and Reproducibility: The paper is generally well-written, with clear explanations of the methodology and sufficient detail for reproducibility. The inclusion of code availability further supports this.
4. Empirical Validation: The experiments, particularly on the real-world airline delay dataset, demonstrate the practical relevance of the proposed method in scenarios where standard assumptions (e.g., sub-Gaussian design) are violated.
Weaknesses:
1. Limited Experimental Scope: The experimental evaluation is somewhat narrow, relying heavily on simulated data and a single real-world dataset. Broader validation across diverse domains and larger-scale datasets would strengthen the paper's claims of general applicability.
2. Incremental Originality: While the use of influence is novel, the paper heavily builds on existing randomized least squares techniques, such as leverage-based subsampling. The originality of the contribution is thus somewhat limited.
3. Clarity Issues: Some details, such as dataset specifics and parameter settings in experiments, are insufficiently described. Additionally, minor typos and unclear labels in figures detract from the overall presentation.
4. Practical Significance: The focus on a specific regression method (least squares) limits the broader impact of the work. The lack of comparison with stochastic gradient descent (SGD) further narrows its relevance for large-scale regression tasks.
Recommendation:
The paper makes a meaningful contribution to robust regression via influence-based subsampling, with strong theoretical backing and promising empirical results. However, its limited experimental scope and incremental originality reduce its overall impact. To strengthen the paper, the authors should expand the experimental evaluation, address clarity issues, and explore broader applications of their method. I recommend acceptance contingent on these improvements.
Arguments for Acceptance:
- Strong theoretical contributions and novel use of influence for robust subsampling.
- Promising empirical results demonstrating robustness to corrupted predictors.
- Clear writing and reproducibility, supported by code availability.
Arguments against Acceptance:
- Limited experimental validation, with a narrow focus on one real-world dataset.
- Incremental originality, building heavily on prior work.
- Restricted practical significance due to the focus on least squares regression.