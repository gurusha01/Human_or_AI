The paper introduces RoLR, a novel robust logistic regression algorithm designed to handle adversarial outliers in the covariate matrix. By leveraging a linear programming framework, RoLR optimizes a trimmed correlation statistic, making it computationally efficient and scalable to large datasets. The authors provide theoretical guarantees for parameter recovery and classification performance, demonstrating robustness to a constant fraction of outliers. Empirical results confirm that RoLR outperforms classical logistic regression (LR) in the presence of outliers, though at the cost of slightly reduced performance in outlier-free scenarios.
Strengths:
1. Novelty and Theoretical Contributions: The reformulation of logistic regression into a linear programming problem is innovative and addresses a critical gap in handling adversarial outliers. The theoretical guarantees, including risk bounds and breakdown points, provide strong support for the method's robustness.
2. Scalability: The use of linear programming enhances computational efficiency, making RoLR applicable to large-scale datasets, a significant advantage over iterative reweighted methods.
3. Empirical Validation: The simulation study convincingly demonstrates RoLR's superiority over classical LR in outlier-heavy scenarios, with detailed analysis of parameter recovery and classification error rates.
4. Clarity: The manuscript is well-organized and clearly written, with sufficient detail for reproducibility. The authors provide a comprehensive comparison to related work, situating their contributions within the broader literature.
Weaknesses:
1. Assumption of Known Outlier Count: RoLR assumes the number of outliers is known, which is theoretically convenient but impractical in real-world applications. A discussion on how to estimate this parameter or adapt the method when it is unknown would strengthen the paper.
2. Preprocessing Concerns: The necessity and impact of the preprocessing step are unclear. While it removes high-leverage outliers, its effectiveness diminishes when outliers have smaller variance. Additionally, the authors should compare classical LR with the same preprocessing to isolate the contribution of the trimmed correlation optimization.
3. Robustness to Low-Variance Outliers: The method's performance may degrade when outliers have smaller variance, as these are harder to detect. This limitation warrants further investigation.
4. Trade-offs in Outlier-Free Scenarios: RoLR exhibits reduced accuracy compared to classical LR in clean datasets, highlighting a trade-off between robustness and performance. A deeper exploration of this trade-off, including practical guidance on when to use RoLR, would be valuable.
5. Parameter Sensitivity: The paper lacks practical guidance on choosing the parameter "n" (number of inliers) and does not analyze the method's sensitivity to this choice.
Recommendation:
The paper makes a significant contribution to robust logistic regression and is well-suited for the conference. However, addressing the practical limitations, such as the assumption of a known outlier count and the impact of preprocessing, would enhance its applicability. I recommend acceptance, contingent on the authors providing additional discussion on these points.
Arguments for Acceptance:
- Innovative reformulation of logistic regression into a linear programming framework.
- Strong theoretical guarantees and empirical validation.
- Clear writing and thorough comparison to related work.
Arguments Against Acceptance:
- Practical limitations, including the assumption of a known number of outliers.
- Insufficient exploration of preprocessing and robustness to low-variance outliers.
Overall, the paper is a valuable contribution to the field and advances the state-of-the-art in robust logistic regression.