The paper introduces the expectation loss SVM (e-SVM), a novel algorithm designed to handle situations where training data labels are continuous values within a bounded interval, termed "positiveness." This approach is particularly suited for weakly supervised learning, where precise labels (e.g., pixel-level annotations) are unavailable, and only approximate labels (e.g., bounding boxes) are provided. The authors validate their method on two key computer vision tasks—semantic segmentation and object detection—demonstrating state-of-the-art performance on the PASCAL VOC 2007 dataset. The paper also extends the standard multiple instance learning (MIL) framework by introducing a soft weighting mechanism for positive instances, applicable in both observed and latent settings.
Strengths:
1. Novelty and Technical Contribution: The e-SVM model is a significant extension of traditional SVMs and MIL frameworks, addressing a crucial gap in weakly supervised learning. By weighting labels instead of data points, the method introduces a unique approach to handling continuous-valued labels.
2. Applicability: The model's flexibility to operate under both strong and weak supervision makes it broadly applicable to real-world problems, particularly in scenarios where fine-grained annotations are impractical.
3. Experimental Validation: The authors present comprehensive experiments, comparing e-SVM against established methods like SVC and SVR. The results consistently demonstrate superior performance, with measurable improvements in semantic segmentation and object detection tasks.
4. Clarity and Organization: The paper is well-written, with clear motivation, detailed methodology, and thorough experimental results. The introduction of new evaluation metrics (TAPC and NDCG) for segment-wise prediction tasks is a valuable addition to the field.
5. Significance: The demonstrated improvement in object detection (e.g., a 1.5% increase in average precision on PASCAL VOC 2007) highlights the practical impact of the proposed method. The approach is likely to influence future research in weakly supervised learning and visual segmentation.
Weaknesses:
1. Limited Scope of Experiments: While the results on PASCAL VOC datasets are promising, the evaluation could be strengthened by testing on additional datasets (e.g., COCO or ImageNet) to establish broader generalizability.
2. Computational Complexity: The iterative optimization process for the latent e-SVM model may introduce computational overhead, though this is not discussed in detail. A comparison of runtime performance with baseline methods would be informative.
3. Regularization Design: The choice of regularization term for latent variables, while effective, could benefit from further theoretical justification or exploration of alternative designs.
Pro and Con Arguments:
Pro:
- Novel and technically sound contribution to weakly supervised learning.
- Demonstrates state-of-the-art performance on a challenging dataset.
- Clear and well-organized presentation with thorough experimental validation.
Con:
- Limited evaluation on diverse datasets.
- Potential computational overhead not addressed.
- Regularization design could be explored further.
Recommendation:
The paper makes a strong contribution to the field of weakly supervised learning and is well-aligned with the scope of NIPS. Its technical novelty, practical significance, and clear presentation outweigh the minor limitations. I recommend acceptance, with a suggestion to expand the evaluation to additional datasets and provide more insights into computational efficiency.