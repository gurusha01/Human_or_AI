This paper presents a novel approach to discovering efficient algebraic identities using a combination of attribute grammars and machine learning, including n-gram models and recursive neural networks (RNNs). The authors propose a framework that represents symbolic expressions as grammar trees and uses machine learning to guide the search for computationally efficient equivalents of target expressions. The paper demonstrates the ability to discover identities that reduce computational complexity, such as transforming \(O(n^3)\) expressions into \(O(n^2)\) or even polynomial-time approximations for exponential expressions. This work builds on prior research in symbolic computation, theorem proving, and recursive neural networks, while introducing new applications of these techniques to symbolic mathematics.
Strengths:  
1. Originality: The paper tackles a unique and underexplored problemâ€”applying machine learning to discover efficient symbolic expressions. The integration of attribute grammars with learning-based search strategies is novel and extends the applicability of machine learning to symbolic computation.  
2. Significance: The results demonstrate the potential for practical applications, such as optimizing mathematical computations in compilers or machine learning algorithms (e.g., RBM partition functions). The discovery of previously unknown identities is a notable contribution to the field.  
3. Technical Contribution: The use of RNNs to learn continuous representations of symbolic expressions is innovative and could have broader implications for symbolic AI. The curriculum learning approach and the use of integer-based descriptors to avoid numerical issues are well-motivated and technically sound.  
Weaknesses:  
1. Clarity: The explanation of the weight tensor \(W_3\) in the RNN is unclear, particularly regarding whether a neural tensor network is used instead of a linear network. This ambiguity undermines the reproducibility of the method.  
2. Problem Scope: The problem definition is narrowly scoped to homogeneous polynomials of fixed degree, limiting the generalizability of the framework. While the authors acknowledge this limitation, it constrains the potential impact of the work.  
3. Comparison to Related Work: The paper does not adequately address the findings of Bowman et al., who demonstrated the superiority of tensor networks over RNNs for similar tasks. A direct comparison or discussion of why RNNs were chosen would strengthen the paper.  
4. Clarity in Section 7.2: It is unclear whether RNNs are still used for classification during the search or only for proposal generation. This lack of clarity affects the reader's understanding of the experimental setup.  
5. Presentation Issues: Several typos and errors, such as the mislabeling of "RNN" as "TNN" in Figure 3, detract from the overall quality of the paper.  
Pro and Con Arguments for Acceptance:  
- Pro: The paper addresses a novel and challenging problem, demonstrates significant results, and introduces innovative techniques that could inspire future research.  
- Con: The narrow problem scope, lack of clarity in key sections, and insufficient discussion of related work weaken the paper's impact and accessibility.  
Recommendation:  
I recommend acceptance with minor revisions. While the paper has some clarity and presentation issues, its originality and technical contributions outweigh these weaknesses. The authors should address the unclear explanation of \(W_3\), improve the discussion of related work, and correct the typographical errors to enhance the paper's quality.