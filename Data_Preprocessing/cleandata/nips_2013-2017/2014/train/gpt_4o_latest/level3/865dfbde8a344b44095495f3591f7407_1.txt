The authors present a novel adaptation of Stochastic Variational Inference (SVI) to Hidden Markov Models (HMMs), addressing the challenge of scaling Bayesian inference to very large time-dependent datasets. The proposed SVIHMM algorithm introduces an approximate message-passing scheme that leverages the memory decay of Markov chains to mitigate errors arising from breaking dependencies in subsequences. The authors also propose a heuristic, GrowBuf, to adaptively determine the number of observations to buffer on either side of a subsequence, ensuring accurate local updates. The work is evaluated on synthetic datasets and a large genomics dataset, demonstrating computational efficiency and comparable performance to batch methods.
Strengths:
1. Scalability: The adaptation of SVI to HMMs enables efficient inference on massive datasets, such as the 250-million observation genomics dataset, where traditional batch methods are computationally infeasible.
2. Theoretical Guarantees: The authors provide convergence guarantees for their algorithm, ensuring that it reaches a local mode of the objective function.
3. Practical Contributions: The GrowBuf heuristic is a thoughtful addition that improves robustness to poor choices of subsequence length, addressing a key limitation of subsampling in dependent data settings.
4. Empirical Validation: The experiments on synthetic datasets effectively illustrate the trade-offs between subsequence length and minibatch size. The application to genomics demonstrates the algorithm's utility in a real-world scenario, achieving comparable false discovery rates (FDR) to a more complex dynamic Bayesian network (DBN) model.
Weaknesses:
1. Incomplete Presentation: Missing figures and tables, such as Table 4 and timing experiments, significantly detract from the paper's clarity and completeness. These omissions hinder a full assessment of the algorithm's computational efficiency.
2. Limited Novelty: While the adaptation of SVI to HMMs is a useful contribution, the work primarily extends existing techniques rather than introducing fundamentally new ideas. The heuristic for buffering, while practical, lacks rigorous justification or exploration of its limitations.
3. Long Introduction: The introduction and background sections are overly lengthy, delaying the presentation of the main contributions until page 4. This could be streamlined to improve readability and focus.
4. Key Details in Supplement: Important algorithmic details, such as GrowBuf, are relegated to the supplementary material, making it difficult for readers to fully understand the method without additional effort.
5. Limited Evaluation Metrics: The comparison to DBN-EM focuses primarily on FDR, with no detailed results on speed or robustness to noise. Additionally, the difference in FDR rates between SVIHMM and DBN is minimal, raising questions about the practical advantages of the proposed method.
Recommendation:
While the paper makes a useful contribution by extending SVI to HMMs and demonstrates its applicability to large-scale datasets, the incomplete presentation and limited novelty reduce its impact. The work would benefit from a more thorough experimental evaluation, including timing results and robustness analyses, as well as a clearer and more concise presentation. I recommend acceptance only if the missing figures and tables are provided and the manuscript is revised to address clarity and completeness issues.
Arguments for Acceptance:
- Addresses a relevant and challenging problem in scaling Bayesian inference for time-dependent data.
- Provides theoretical guarantees and practical heuristics for mitigating edge effects in subsequences.
- Demonstrates empirical success on both synthetic and real-world datasets.
Arguments Against Acceptance:
- Incomplete presentation due to missing figures and tables.
- Limited novelty as the work is a straightforward adaptation of existing techniques.
- Key algorithmic details are relegated to the supplement, reducing accessibility.
- Minimal difference in FDR rates compared to existing methods, with no speed or noise robustness results provided.
Overall Rating: Weak Accept (conditional on revisions).