This paper presents a novel Gibbs sampling algorithm for factorial hidden Markov models (FHMMs) that leverages an auxiliary variable, \( U \), to restrict the possible values of the hidden state matrix \( X \). By introducing the concept of a "Hamming ball" around \( X \), the algorithm enables efficient updates using forward-filtering backward-sampling (FFBS) within a reduced configuration space. This approach addresses the limitations of traditional Gibbs samplers, which often suffer from poor mixing due to locally asymmetric updates that can become trapped in local modes. The proposed method allows for symmetric, localized joint updates of the latent sequences, improving mixing and computational efficiency.
Strengths:
1. Originality and Innovation: The use of an auxiliary variable to define a restricted sampling space is a clever and novel idea. The Hamming ball construction provides a principled way to balance computational complexity and sampling efficiency, making the method applicable to a wide range of problems.
2. Technical Soundness: The paper is technically rigorous, with clear derivations and a well-justified approach. The authors demonstrate the ergodicity of the sampler and explore extensions, such as varying the Hamming ball radius dynamically.
3. Empirical Validation: The empirical evaluation is thorough, with experiments on both simulated and real-world datasets (e.g., energy disaggregation). The results convincingly show the superiority of the Hamming ball sampler over block Gibbs sampling in escaping local modes and achieving better posterior exploration.
4. Potential Impact: The method has significant potential for broader applications, including Bayesian variable selection and nonparametric models. Its extensibility to incorporate likelihood information into the definition of \( X \)'s possible values further enhances its utility.
5. Clarity: The paper is well-written and organized, with clear explanations of the method and its advantages. The intuition behind the algorithm is effectively conveyed, making it accessible to readers.
Weaknesses:
1. Minor Typos and Phrasing Issues: There are a few minor errors in phrasing and definitions, such as the description of "four bits" and the auxiliary variable. These should be addressed for clarity.
2. Limited Discussion of Computational Trade-offs: While the paper mentions the trade-off between computational complexity and sampling efficiency, a more detailed analysis of how this trade-off scales with increasing \( K \) and \( N \) would strengthen the discussion.
3. Comparative Baselines: Although the block Gibbs sampler is a reasonable baseline, additional comparisons with other advanced MCMC methods for FHMMs (e.g., variational inference or particle-based methods) would provide a more comprehensive evaluation.
Recommendation:
This paper is a significant contribution to MCMC methods for FHMMs and addresses a challenging problem with an elegant and effective solution. The originality, technical rigor, and potential impact of the proposed method make it a strong candidate for acceptance. The minor weaknesses noted do not detract from the overall quality of the work and can be addressed in a revision.
Arguments for Acceptance:
- Novel and impactful methodology.
- Strong empirical results demonstrating practical utility.
- Clear and well-organized presentation.
Arguments Against Acceptance:
- Minor clarity issues and limited comparative baselines.
Overall, I recommend acceptance with minor revisions to address the noted weaknesses.