This paper presents a framework for constructing structured priors in Bayesian inference using the maximum entropy principle and information projection. The authors focus on sparse structures, proposing an efficient algorithm based on submodular optimization and greedy forward selection. The paper is motivated by high-dimensional neuroimaging data, where sparsity constraints are critical for meaningful inference. Experimental results demonstrate the proposed method's effectiveness in support recovery and predictive accuracy compared to established baselines.
Strengths:
1. Technical Soundness and Formalization: The paper is technically rigorous, with clear derivations and proofs. The use of information projection to define structured priors is well-motivated and aligns with established principles in Bayesian inference.
2. Algorithmic Contribution: The proposed greedy forward selection algorithm for sparse inference is efficient and theoretically grounded, achieving a (1 - 1/e) approximation guarantee. This is a significant contribution for handling intractable optimization problems in high-dimensional settings.
3. Experimental Validation: The experimental results are thorough, covering both simulated and real-world neuroimaging data. The method outperforms baselines like Lasso, ARD, and Spike-and-Slab in support recovery and predictive accuracy, especially in challenging scenarios with limited samples or high noise.
4. Clarity and Organization: The paper is well-written and logically organized. Key concepts, such as information projection and submodularity, are explained clearly, making the work accessible to a broad audience.
Weaknesses:
1. Limited Novelty: While the framework and algorithm are well-executed, the core ideas—such as using information projection and submodular optimization—are not entirely novel. The results, though strong, are somewhat predictable given the theoretical guarantees of the greedy algorithm.
2. Unnecessary Technical Sections: Some technical details, such as the derivation of Corollary 4, feel tangential to the main algorithmic contribution. These sections could be streamlined to improve focus.
3. Scalability of Baselines: The inability of Spike-and-Slab to scale to the neuroimaging dataset raises questions about the fairness of comparisons. While Sparse-G performs well, the lack of scalable baselines limits the experimental scope.
Pro and Con Arguments for Acceptance:
Pros:
- Clear and rigorous formalization of structured priors using information projection.
- Effective algorithm with strong theoretical guarantees and practical performance.
- Demonstrated applicability to a challenging real-world problem (neuroimaging).
Cons:
- Limited novelty in the underlying concepts.
- Some technical sections could be condensed or omitted.
- Experimental comparisons are constrained by the scalability of baselines.
Recommendation:
Overall, this is a high-quality paper that makes a solid contribution to Bayesian inference with structural priors. While the novelty is somewhat limited, the technical rigor, clarity, and practical relevance make it a valuable addition to the field. I recommend acceptance, with minor revisions to streamline the technical sections and address scalability concerns in the experiments.