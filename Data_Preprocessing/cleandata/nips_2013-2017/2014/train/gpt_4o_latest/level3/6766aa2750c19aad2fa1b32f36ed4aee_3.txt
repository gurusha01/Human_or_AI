This paper presents a novel hybrid policy search method that combines trajectory optimization with guided policy search (GPS) to address the challenge of learning policies for systems with unknown and discontinuous dynamics. By iteratively fitting local linear-Gaussian models and constraining trajectory updates using KL-divergence, the proposed approach achieves sample-efficient learning while maintaining stability. The integration of this trajectory optimization method with GPS enables the learning of expressive, parameterized policies, such as neural networks, that generalize well to partially observed environments. The paper demonstrates the method's effectiveness through extensive evaluations on simulated robotic tasks, including peg insertion, octopus arm control, swimming, and bipedal walking.
Strengths:
1. Technical Contribution: The use of KL-divergence constraints to stabilize trajectory optimization under unknown dynamics is a significant and well-motivated innovation. This approach effectively balances exploration and exploitation, ensuring convergence without destabilizing the system.
2. Integration with GPS: Extending GPS to handle unknown dynamics is a meaningful contribution, as it broadens the applicability of GPS to real-world scenarios where accurate global models are unavailable.
3. Experimental Rigor: The paper provides extensive evaluations across diverse tasks, demonstrating superior performance compared to state-of-the-art methods. The results highlight the method's ability to handle high-dimensional, contact-rich, and partially observed environments.
4. Practical Relevance: The method's ability to learn policies that generalize to unseen scenarios (e.g., peg insertion with unknown hole positions) is particularly valuable for robotics applications.
5. Sample Efficiency: The use of Gaussian Mixture Models (GMM) as priors for local dynamics fitting significantly reduces the sample complexity, making the method more practical for real-world systems.
Weaknesses:
1. Clarity: Certain terms and concepts, such as "unknown dynamics" and the role of GMMs, are not clearly defined early in the paper, which may confuse readers. Additionally, the counterintuitive result of outperforming iLQG with a true model requires more thorough justification.
2. Experimental Scope: While the simulated tasks are diverse, the lack of real-world experiments limits the paper's impact. Demonstrating the method on physical systems involving contact or impact would strengthen its applicability.
3. Incremental Nature: The method builds on prior work in GPS and trajectory optimization, and while the contributions are meaningful, they are incremental in nature. The novelty lies primarily in adapting these techniques for unknown dynamics.
Arguments for Acceptance:
- The paper addresses a critical challenge in robot learning: policy search under unknown and discontinuous dynamics.
- It demonstrates strong empirical performance and sample efficiency, outperforming state-of-the-art methods in challenging tasks.
- The integration of trajectory optimization with GPS is a meaningful extension with practical implications.
Arguments Against Acceptance:
- The lack of real-world experiments limits the demonstration of the method's robustness and applicability.
- Some key concepts and results require clearer explanations and justifications to enhance the paper's accessibility.
Recommendation:
Overall, this paper makes a solid contribution to the field of robot learning by proposing a hybrid approach that bridges the gap between model-based and model-free methods. While there are some clarity and experimental limitations, the strengths outweigh the weaknesses. I recommend acceptance with minor revisions to address clarity issues and provide additional justification for counterintuitive results.