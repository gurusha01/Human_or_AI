Review
This paper introduces a novel framework for discovering efficient mathematical identities by combining symbolic computation techniques with machine learning. The authors propose an attribute grammar for representing symbolic expressions and explore two learning-based search strategies: an n-gram model and a recursive neural network (RNN). These strategies are trained on simpler expressions to guide the search for more complex ones. The framework demonstrates the ability to discover computationally efficient versions of symbolic expressions, including some previously unknown identities, and has potential applications in symbolic computation libraries and compiler optimization.
Strengths:
1. Novelty and Originality: The integration of machine learning into symbolic computation is innovative. The use of RNNs to learn continuous representations of symbolic expressions is particularly noteworthy, as it bridges the gap between symbolic and statistical learning.
2. Potential Impact: The framework could significantly benefit symbolic software libraries and compilers by automating the discovery of efficient mathematical identities. The application to expressions related to machine learning (e.g., RBM partition functions) adds practical relevance.
3. Empirical Results: The paper provides evidence that the proposed methods outperform random search strategies for many expression families, demonstrating the effectiveness of the learning-based approaches.
4. Open Source: The availability of code and data on GitHub enhances reproducibility and encourages further exploration by the community.
Weaknesses:
1. Scalability: The framework is limited to relatively simple expressions, and the paper does not provide a clear pathway for scaling to more complex ones. For instance, the RBM-2 family remains unsolved for \(k > 5\), highlighting the limitations of the current approach.
2. Lack of Complexity Constraints: The algorithm does not explicitly enforce constraints to prioritize expressions with lower computational complexity. While this is a key goal of the framework, potential solutions to address this limitation are not discussed.
3. Insufficient Justification: The restrictions in Section 2 (e.g., limiting to homogeneous polynomials) lack formal justification or empirical evidence to demonstrate their necessity or impact on the results.
4. Clarity and Structure: The paper is difficult to follow due to its dense structure and lack of clear explanations for some stages of the framework. For example, the role of the scheduler is not sufficiently clarified, and the supplementary material contains examples that appear invalid, raising concerns about the rigor of the evaluation.
5. Typos and Errors: Several typographical errors ("show for" on line 332, "has contains" on line 148, etc.) detract from the overall polish of the paper.
Arguments for Acceptance:
- The paper addresses an important and underexplored problem in symbolic computation.
- The proposed framework is novel and demonstrates promising results for certain families of expressions.
- The integration of machine learning into symbolic computation has the potential to inspire future research in this area.
Arguments Against Acceptance:
- The scalability of the approach is unproven, limiting its applicability to real-world problems.
- The lack of formal justification for key design choices and the absence of a discussion on addressing computational complexity constraints weaken the theoretical foundation.
- The paper's clarity and structure need significant improvement, making it challenging for readers to fully grasp the contributions.
Recommendation:
While the paper makes a novel contribution, the limitations in scalability, clarity, and justification prevent it from being a strong candidate for acceptance in its current form. A major revision addressing these issues, particularly scalability and clarity, would significantly strengthen the paper. For now, I recommend reject with encouragement to resubmit after addressing these concerns.