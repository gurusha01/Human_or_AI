The paper proposes a novel framework, "Inference by Learning" (IbyL), to accelerate Markov Random Field (MRF) optimization by employing a coarse-to-fine cascade of classifiers for label pruning. The method is particularly designed for MRFs with piecewise smooth solutions and demonstrates significant speed-ups in optimization tasks for computer vision problems like stereo matching, image restoration, and optical flow estimation. The authors claim that their approach not only reduces computational time but also achieves better or comparable accuracy compared to direct optimization methods.
Strengths:
1. Innovative Approach: The use of a learned cascade of classifiers for label pruning is an interesting and novel contribution. By leveraging classifiers trained on energy-based features, the method avoids heuristic pruning, potentially making it more generalizable across different MRF problems.
2. Practical Significance: The proposed framework addresses a critical bottleneck in MRF optimization—computational cost—while maintaining or improving accuracy. This is particularly relevant for large-scale computer vision applications.
3. Experimental Results: The reported speed-ups (up to 10x for optical flow) and high label agreement rates (>99% for most cases) are promising. The use of multiple datasets across different tasks adds credibility to the empirical evaluation.
4. Code Availability: The authors provide their code, which facilitates reproducibility and practical adoption.
Weaknesses:
1. Theoretical Justification: The greedy pruning method lacks rigorous theoretical analysis. While the empirical results are promising, the absence of guarantees or bounds on the pruning's impact on optimality limits the method's reliability.
2. Clarity Issues: Key concepts, such as the "active" pruning matrix and its updating process, are insufficiently explained. A toy example, as suggested, would greatly aid understanding. Additionally, Figure 2 is not very informative and could be moved to the appendix to streamline the main text.
3. Scope Limitation: The method is restricted to MRFs with piecewise smooth solutions, which narrows its applicability. This limitation should be more explicitly acknowledged in the paper.
4. Experimental Gaps: The experimental section lacks sufficient detail on hyperparameter tuning and comparison with state-of-the-art methods. The energy ratio behavior is also not well-explained, leaving some ambiguity about its significance.
5. Redundancy in Presentation: The proposed approach section is overly lengthy, with some content being repetitive. A more concise presentation would improve readability.
Suggestions for Improvement:
- Provide a toy example to clarify the pruning matrix and its updates.
- Add theoretical analysis or guarantees for the pruning method.
- Expand the experimental section with more detailed comparisons and hyperparameter analysis.
- Move Figure 2 to the appendix and replace it with more insightful visualizations or tables.
- Streamline the proposed approach section to reduce redundancy.
Recommendation:
While the paper presents an interesting and potentially impactful method, the lack of theoretical justification and clarity in key areas limits its overall quality. If the authors address these issues, particularly by adding theoretical insights and improving the clarity of their explanations, the paper could make a strong contribution to the field. For now, I recommend a weak accept with revisions. 
Pros:
- Novel and practical approach.
- Promising experimental results.
- Code availability.
Cons:
- Insufficient theoretical grounding.
- Clarity and presentation issues.
- Limited scope and experimental gaps.