The paper introduces a novel framework for online multi-task learning with a shared annotator, addressing the challenge of limited annotation bandwidth across multiple tasks. The proposed algorithm, SHAMPO (SHared Annotator for Multiple PrOblems), balances exploration and exploitation by leveraging task uncertainty (via margins) and randomness to allocate annotation resources effectively. Theoretical contributions include a mistake-bound analysis (Theorem 1), which guarantees that the algorithm's performance is competitive with methods that observe all labels. The paper also extends the framework to contextual bandit problems, demonstrating its versatility. Empirical evaluations on diverse datasets (OCR, vowel prediction, document classification) show that SHAMPO outperforms baseline methods, achieving higher accuracy for the same annotation cost.
Strengths:
1. Novelty and Originality: The paper addresses a unique problem of shared annotation in multi-task learning, which has not been extensively studied. The exploration-exploitation strategy for task selection is particularly innovative in this context.
2. Theoretical Rigor: The mistake-bound analysis provides strong theoretical guarantees, and the bounds are well-motivated and insightful.
3. Experimental Validation: The empirical results are comprehensive, spanning multiple datasets and scenarios. The comparisons with baselines (uniform and exploit strategies) convincingly demonstrate SHAMPO's advantages.
4. Clarity: The paper is well-written and organized, with clear explanations of the algorithm, theoretical results, and experimental setup. The inclusion of pseudo-code aids reproducibility.
5. Versatility: The extension to contextual bandits highlights the broader applicability of the framework, making it relevant to a wider audience.
Weaknesses:
1. Synchronic Assumption: The strict assumption that only one annotation is chosen per round may limit the framework's practical applicability. A total budget approach, where the annotator's effort is distributed across tasks over time, could be more realistic.
2. Limited Real-World Motivation: While the problem setting is novel, the paper lacks concrete real-world examples or applications where such a shared annotator framework is critical. Adding such motivation would strengthen the paper's significance.
3. Experimental Comparisons: The experiments could be enriched by including:
   - A scenario where all samples are annotated to explore the trade-off between accuracy and annotation cost.
   - An active learning approach applied to individual tasks with equal total annotations across tasks, to benchmark SHAMPO's performance more comprehensively.
4. Prior Selection: While the paper discusses the use of priors to focus on harder tasks, the method for generating good priors is heuristic and could benefit from further exploration or theoretical justification.
Recommendation:
The paper makes a strong contribution to the field of multi-task learning and shared annotation, with solid theoretical and experimental results. However, addressing the synchronic assumption, providing stronger real-world motivation, and expanding the experimental comparisons would enhance its impact. Overall, I recommend acceptance, as the paper advances the state of the art in multi-task learning with a novel and well-supported approach.
Arguments for Acceptance:
- Novel problem setting and algorithm.
- Strong theoretical guarantees.
- Comprehensive and convincing experimental results.
Arguments Against Acceptance:
- Practical limitations due to the synchronic assumption.
- Insufficient real-world motivation and additional experimental baselines.
In summary, the paper is a valuable contribution to the conference, with minor refinements needed to address practical concerns and broaden its applicability.