The paper addresses the critical trade-off between recommendation accuracy and user privacy in recommender systems, proposing a novel two-tiered privacy framework. The authors introduce a distinction between "public" users, who openly share their preferences, and "private" users, who require privacy guarantees. The key contributions include theoretical guarantees for accurate item feature estimation using public user data, a novel privacy mechanism for leveraging limited second-order information from private users while maintaining first-order deniability, and empirical demonstrations of the proposed methods on the Movielens dataset.
Strengths:
1. Novelty: The two-tiered privacy framework and the introduction of a second-order privacy mechanism are innovative. The paper departs from traditional differential privacy approaches, addressing a realistic scenario where the server is untrusted, and computations are divided between public and private users.
2. Theoretical Rigor: The authors provide detailed theoretical guarantees for the accuracy of item feature estimation and prediction error bounds. The analysis is grounded in restricted strong convexity and sub-Gaussian noise assumptions, which are standard in the field.
3. Empirical Validation: The experiments on the Movielens dataset convincingly demonstrate the effectiveness of the proposed methods. The results show that a small number of public users can achieve reasonable accuracy, and controlled contributions from private users further enhance performance.
4. Practical Relevance: The proposed privacy mechanism is practical and aligns with real-world scenarios where users have varying privacy preferences. The mechanism's ability to preserve second-order information while ensuring marginal privacy is a significant contribution.
Weaknesses:
1. Clarity: While the theoretical sections are thorough, they are dense and may be challenging for readers unfamiliar with matrix completion or privacy-preserving mechanisms. The paper could benefit from clearer explanations of key concepts, such as the privacy mechanism's intuition and practical implementation.
2. Comparisons with Prior Work: Although the paper references related work on differential privacy and matrix completion, the experimental comparisons with existing privacy-preserving methods (e.g., DP and SSLP) are limited. A more comprehensive evaluation against state-of-the-art methods would strengthen the claims.
3. Generality: The focus on second-order privacy mechanisms is compelling, but the paper does not explore how the approach generalizes to other types of privacy guarantees or recommendation tasks beyond matrix completion.
4. Assumptions: The reliance on public users with many ratings may limit the applicability of the method in domains where such users are scarce. Additionally, the assumption of i.i.d. samples and bounded noise may not hold in all real-world datasets.
Arguments for Acceptance:
- The paper makes a significant contribution to the intersection of recommender systems and privacy, introducing novel concepts and mechanisms.
- The theoretical and empirical results are robust, demonstrating the feasibility and effectiveness of the proposed approach.
- The topic is timely and relevant, addressing pressing concerns about user privacy in AI systems.
Arguments Against Acceptance:
- The paper's clarity and accessibility could be improved, particularly in the theoretical sections.
- The experimental comparisons with prior work are limited, and the assumptions may restrict the method's generalizability.
Recommendation:
I recommend acceptance with minor revisions. The paper presents a well-motivated and technically sound contribution to privacy-preserving recommender systems. Addressing the clarity issues and expanding the experimental comparisons would further enhance its impact.