The paper presents a novel contribution to the field of multitask learning by proposing the scaled latent trace norm, a new convex relaxation for tensor multilinear rank. The authors argue that existing norms, such as the overlapped trace norm and the latent trace norm, are suboptimal in settings with heterogeneous tensor dimensions or multilinear ranks. By introducing the scaled latent trace norm, the authors address these limitations, demonstrating both theoretically and empirically that their approach achieves better mean squared error scaling and excess risk bounds in multitask learning, tensor completion, and multilinear multitask learning (MLMTL) scenarios. The paper is well-grounded in prior work, referencing key contributions in tensor decomposition, multitask learning, and convex optimization (e.g., [1, 6, 17, 21]). It builds on these foundations by extending the theoretical analysis of tensor norms and offering a practical solution for real-world datasets with heterogeneous structures.
Strengths:
1. Novelty and Originality: The scaled latent trace norm is a significant advancement over prior norms, as it adapts to the mode with the lowest rank relative to its dimension. This is particularly important in heterogeneous settings, where existing norms fail to exploit the structure effectively.
2. Theoretical Rigor: The paper provides a comprehensive theoretical analysis, including excess risk bounds, Rademacher complexity, and sample complexity comparisons for the three norms. The results are clearly presented in tables and corollaries, offering valuable insights into the advantages of the proposed norm.
3. Empirical Validation: The experiments on both synthetic and real-world datasets (Restaurant and School datasets) convincingly demonstrate the superiority of the scaled latent trace norm in heterogeneous settings. The results align well with the theoretical findings.
4. Clarity of Problem Statement: The paper clearly identifies the limitations of existing norms and motivates the need for the scaled latent trace norm. The discussion of tensor-based multitask learning and its practical implications is compelling.
Weaknesses:
1. Complexity of Presentation: While the theoretical analysis is rigorous, the dense mathematical exposition may be challenging for readers unfamiliar with tensor norms or convex optimization. Simplifying some derivations or providing more intuitive explanations could improve accessibility.
2. Limited Discussion of Hyperparameters: Although the scaled latent trace norm reduces the need for mode-specific hyperparameter tuning, the paper does not extensively discuss the sensitivity of the regularization parameter Î» or its selection process.
3. Comparison with Nonconvex Methods: The paper focuses on convex relaxations but does not compare its approach with state-of-the-art nonconvex tensor decomposition methods, which may offer complementary insights.
Arguments for Acceptance:
- The paper addresses a critical gap in tensor-based multitask learning by proposing a theoretically sound and empirically validated norm.
- It advances the state of the art in handling heterogeneous tensor dimensions and ranks, a common challenge in real-world applications.
- The results are significant and likely to inspire further research in tensor-based learning and convex optimization.
Arguments Against Acceptance:
- The presentation could be more accessible to a broader audience, particularly those less familiar with tensor decomposition.
- The lack of comparison with nonconvex methods may limit the scope of the paper's impact.
Recommendation:
I recommend acceptance of this paper, as it makes a substantial contribution to the field of multitask learning and tensor analysis. While there are minor areas for improvement, the strengths of the paper far outweigh its weaknesses, and it is likely to be of significant interest to the NeurIPS community.