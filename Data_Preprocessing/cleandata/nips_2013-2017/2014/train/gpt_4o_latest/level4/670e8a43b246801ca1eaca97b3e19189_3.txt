The paper tackles the computational challenge of bipartite ranking. The authors introduce a novel algorithm with computational complexity that scales linearly with the number of training instances and provide a theoretical analysis of the generalization error. The work is complemented by an extensive experimental evaluation.
Strengths: The paper is well-written and could be valuable for bipartite ranking tasks involving large datasets. The generalization bound is innovative, and the experimental section is thorough.
That said, I have several questions about the paper:
1. While bipartite ranking is a well-studied problem, it is somewhat narrow in scope, as it pertains to ranking but does not handle queries. Given the existence of well-established algorithms for bipartite ranking that are both theoretically grounded and empirically validated, is this study truly impactful? For instance, the proposed algorithm would only be useful when both \(m\) and \(n\) are extremely large. Is this scenario common in bipartite ranking applications? I acknowledge this is my perspective, and I would appreciate the authors' insights, perhaps with examples to clarify.
2. The paper achieves an \(O(m+n/\sqrt{e})\) error bound primarily due to the newly defined target loss (Equation 2) and the use of a smooth convex surrogate, which enables a standard primal-dual approach to derive a smooth dual and apply accelerated gradient descent. However, according to target loss (2), a negative instance followed by all positive instances incurs a higher loss than a positive instance followed by all negative instances. Does this truly encourage good ranking at the top, especially in the absence of a position-based discount factor?
   Furthermore, the supplementary material states that maximizing positives at the top cannot be achieved through AUC optimization, yet target loss (2) is an upper bound on rank loss. Why should one optimize an upper bound on rank loss if AUC optimization itself is unsuitable for prioritizing positives at the top?
3. While the transition to the dual form and the application of Nesterov's technique is elegant once the convex surrogate is smoothed, I do not find this approach particularly novel.
4. Regarding the empirical section, I am unclear about the specific advantages of TopPush over logistic regression (LR). The computational efficiency of the proposed algorithm is highlighted as a key contribution, yet in 4 out of 7 experiments, LR is faster than TopPush. Additionally, TopPush does not demonstrate significant improvements in widely used metrics like AP and NDCG. While it performs slightly better in the "position at top" metric, it underperforms in AUC. Why should one prefer TopPush over LR? Am I misinterpreting the experimental results?
   A related point: When comparing computational complexity with SVM-based methods (e.g., Rank, MAP), all methods scale linearly with the size of the training data. The computational advantage of TopPush appears to stem from its use of a smooth surrogate instead of hinge loss, rather than from a unique property of the algorithm. Thus, linear computational complexity is not exclusive to TopPush.
5. Theoretical Analysis: In the generalization bound, shouldn't the focus be on scenarios with a large number of negative instances and relatively few positive instances? The reverse scenario is less practical, as even a basic ranking function would place a few positive instances at the top. However, when focusing on negative instances, I am unsure of the bound's practical implications. As \(n\) grows, the empirical loss is likely to increase since the normalizing factor depends only on \(1/m\) (with no dependence on \(n\)). While \(\delta\) will decrease, the left-hand side probability and the right-hand side bound are both likely to grow. I may be misunderstanding the significance of the bound in the context of \(n \gg m\). Could the authors clarify?
My current ratings are provisional, and I would like the authors to address the questions I have raised. Specifically, I would like more clarity on the comparison between TopPush and LR (point 4 in the empirical section). In my view, the decision to accept or reject hinges on demonstrating how TopPush offers advantages over LR. I am open to revisiting my decision after receiving the authors' feedback.
---
Update After Author Feedback:
1. Large \(m, n\) Example: While I am not an expert in bipartite ranking, I will defer to the authors' expertise on this point. However, from my understanding of online advertising, isn't ad ranking typically framed within the learning-to-rank paradigm (i.e., query-dependent)? I agree with the first reviewer that experiments on large, real-world datasets relevant to bipartite ranking would strengthen the paper.
2. AUC Optimization: The authors did not directly address my question. They highlighted the advantages of the new loss in terms of optimization and generalization bounds, but these points are independent of AUC. If AUC is unsuitable for prioritizing positives at the top, why should one optimize a loss function that is merely an upper bound on rank loss?
3. Comparison with LR: This is a critical point. I agree that TopPush outperforms LR in the Pos@Top metric. However, the paper's introduction should be revised to reflect this more accurately. The primary contribution of the paper is not a computational advantage over other algorithms, as TopPush does not outperform LR in this regard. Instead, TopPush should be presented as an alternative with specific strengths in certain metrics (and weaknesses in others).
4. SVM Comparison: The advantage over SVM-based methods lies in the quadratic convergence rate (\(O(1/T^2)\) vs. \(O(1/T)\)), not in the linear scaling with \(m+n\). Both SVM-based methods and TopPush scale linearly with \(m+n\), as shown in Table 1.
5. Generalization Bound: The discussion provided by the authors on this point is critical and should be included in the revised draft.
---
Overall, I find this paper interesting. With revisions, it has the potential to be a strong contribution. I have updated my decision to accept.