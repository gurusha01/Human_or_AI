The paper introduces an Expectation-Maximization (EM) algorithm for learning Determinantal Point Processes (DPPs). The proposed method integrates several sophisticated components: eigendecomposition of the kernel, optimization on the Stiefel manifold, representation of DPPs as mixtures of elementary DPPs, and the use of Jensen's Inequality to lower-bound the log-likelihood. Experimental results indicate that the proposed approach performs favorably when compared to a simpler "K-Ascent" scheme.
Quality: The methodology appears to be well-founded, and it is plausible that the proposed approach functions as described. However, the evaluation of the method leaves room for improvement. The experiments are relatively limited and do not include comparisons with alternative subset selection methods (e.g., those mentioned in the introduction). As a result, it is unclear how much the DPP-based approach improves upon existing techniques.
Clarity: The paper is not particularly well-written. The presentation is somewhat disorganized and difficult to follow. Some notation is undefined or introduced only after being used. Additionally, the writing is unnecessarily convoluted, as the text is structured to describe the process of arriving at the proposed approach, interspersed with side remarks about alternative methods and challenges. A more effective structure would present the developed method as clearly as possible, with discussions deferred to a later section.
Originality: The paper appears to be quite original, as I am not aware of any similar work in this area.
Significance: The method proposed in the paper represents a meaningful advancement and a valuable contribution to the subset selection literature.
Details:
- p.2, line 81: The marginal kernel \( K \) is used before being defined. What qualifies as a marginal kernel?
- p.2, line 100: The notation \( V \) is not defined.
- p.3, line 159: The phrase "minimizes the change to Frobenius norm" is unclear. It would be better to state, "chooses the closest (in Frobenius norm) positive semidefinite (PSD) matrix to \( Q \)."
- p.4: This section is difficult to follow. Instead of referring to [26], it would be helpful to outline the simpler approach directly, allowing readers to understand it without consulting the more complex original method.
- p.4, line 189: The term "weight" is not clearly explained.
- p.7, line 324: The rationale behind Equation (30) is unclear. Why is \( m_{ij} \) not used here? Additionally, why would using the empirical covariance matrix as the kernel not suffice for initialization?
In summary, the paper proposes a novel method for learning Determinantal Point Processes for subset selection. The approach is highly non-trivial and likely original. However, the clarity of the write-up is lacking, and the experiments fail to compare the method against non-DPP approaches.