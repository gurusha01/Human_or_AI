This paper explores the extension of dropout to other model classes by perturbing the parameters of the corresponding source model. For example, in the case of a mixture model, noise can be introduced to the means of the components or their covariance matrices. The authors propose a regularizer to enhance the robustness of the pseudo-ensemble of child models against the noise process used to perturb the parent model and generate the child models. The topic is of considerable interest to the NIPS community and, in my view, merits presentation, though the work represents a relatively straightforward extension of dropout. The proposed ideas are validated through a series of informative experiments on standard benchmark datasets.
Specific comments:
1) The first two sentences lack clarity, particularly regarding the roles of the variables x and y. For instance, is the goal to derive approximations of p(x,y) conditioned on x?
2) The claim "Many useful methods could be developed...by generating perturbations beyond the iid masking noise that has been considered for neural networks" is inaccurate. Even in the original work by the Hinton group, the noise was not iid, as the dropout probability in the input layer (e.g., 0.2) differed from that in other layers (e.g., 0.5). Additionally, non-iid cases were analyzed in reference [1], which should either be supplemented with or replaced by its more comprehensive version (Artificial Intelligence, 210, 78â€“122, 2014). This reference also examines other forms of noise, such as Gaussian noise added to unit activity, and demonstrates how these fit within the same framework. These points are highly relevant to the theme of this paper.
3) A minor suggestion: the authors might consider revising the terminology. The term "pseudo-ensemble" may carry a slightly negative connotation, whereas the intent is to present this as a novel approach to learning.
4) The statement "While dropout is well supported empirically, its mode of action is not well understood outside the limited context of linear models" is not entirely accurate. In the non-linear case, the ensemble properties of dropout in deep non-linear neural networks are reasonably well understood, as are its regularization effects, as detailed in the aforementioned reference.
5) Another minor point: the paper contains a few typographical errors and should be reviewed with a spell-checker. For instance, see the last line of page 6 ("northe images in the target domain").
6) The paper is supported by a range of informative experiments conducted on various benchmark datasets.
In summary, this paper presents an incremental generalization of dropout, a topic currently of high interest to the NIPS community. The work is supported by a set of compelling simulations.