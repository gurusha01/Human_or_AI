This paper is difficult to follow and lacks clarity. It builds on recent results by Hsu et al. regarding loss minimization (though their theorem appears to be incorrectly stated). The paper does not include empirical validation to demonstrate the potential benefits of active learning in parametric linear regression. Additionally, the derivations of the main theorems are unclear and may contain errors.
In Equation 1, the notation ||X||_* is introduced without prior definition.
The authors should carefully verify Theorem 2.1. For the sample complexity, the term "n" should appear only once. The condition n > c log(n) does not seem consistent with the intent of Hsu et al.
The derivation of L(W,P) = L(W,D) on page 3 appears problematic. Since P is a measure, the second line is particularly confusing. While the result itself seems correct, the reasoning provided is unclear.
It is also unclear how the main theorem of the paper holds when \Lambda_D is unbounded, which can occur under heavy-tailed distributions. In such cases, the gap between Lemma 3.1 and Theorem 5.1 could become significant.
The claims made in the paper should be supported by a set of experiments.
Overall, this work requires significant improvement in terms of clarity and presentation of results. The authors should also focus on improving the rigor and transparency of their proofs. Furthermore, the inclusion of real-world experiments is essential to substantiate the theoretical findings.