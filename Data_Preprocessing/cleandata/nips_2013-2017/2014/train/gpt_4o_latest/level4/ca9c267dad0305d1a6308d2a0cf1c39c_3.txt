This paper addresses the challenge of online multi-task learning, where a single annotator with limited capacity is shared across multiple tasks. The authors propose an online algorithm and provide an analysis of its performance.
Major Strengths:
The topic of online multi-task learning is both significant and timely, with the field of multi-armed bandits offering a well-established foundation. Drawing on concepts and results from multi-armed bandits to enhance multi-task learning methods is a promising direction, particularly given the practical scenario where some labels may remain unobserved. Moreover, this research aligns well with the interests and scope of NIPS.
Major Weaknesses:
A key aspect of multi-task learning lies in the interdependencies between tasks, which enable joint learning to be beneficial. However, the proposed work assumes no such dependencies, which marks a notable deviation from the core multi-task learning literature without providing sufficient justification. The absence of task-to-task knowledge transfer makes the approach resemble a multi-armed bandit formulation applied to multi-task learning. For example, why is only one feature allowed to be annotated at a time, even though all features are eligible for annotation? In practical scenarios, such as using Mechanical Turk as suggested, annotators may not perform equally well across all features. Thus, a more realistic setting might involve allowing only a subset of features to be annotated while others remain unannotated. While the authors claim to introduce a novel multi-task framework that need not adhere to traditional assumptions, stronger motivation and justification are required to highlight the importance of these differences.
One counterpoint to the above critique is provided by Romera-Paredes et al. in "Exploiting Unrelated Tasks in Multi-Task Learning" (AISTATS 2012). That work demonstrates how knowledge of task independence can be leveraged to prevent overfitting by sharing the same features. However, the current paper does not appear to utilize the absence of task dependencies in a similarly constructive manner.
Although less critical, it would have been insightful to evaluate how SHAMPO performs in comparison to a scenario where labels are available for all tasks, as suggested by the implication in lines 153-154 of Theorem 1.
Minor Notes:
- [25] "both allows"  
- [209] "outputs multicalss"  
- [347] Remove the comma.  
This paper introduces a new problem in multi-task learning and provides a thorough analysis of the proposed approach.