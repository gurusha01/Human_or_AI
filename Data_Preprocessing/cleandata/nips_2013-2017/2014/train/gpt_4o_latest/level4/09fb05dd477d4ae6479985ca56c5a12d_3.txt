This paper introduces a method to adapt a Krizhevsky CNN network, originally trained for classification without bounding box annotations, to perform object detection for a small set of classes with annotated bounding boxes. The proposed approach involves the following steps during training: 1) training a CNN for classification on images from all classes, 2) training a CNN on image regions for classes with bounding box annotations while incorporating a negative background region class, and 3) integrating the background class into the full CNN model and adapting certain CNN weights. At test time, the modified CNN is applied to multiple image regions within a test image.
Quality: The paper presents an interesting and reasonably compelling approach that achieves promising results. However, these results largely build upon the success of the Krizhevsky et al. model rather than introducing a radically novel concept. Despite this, the findings are likely to be valuable to researchers in computer vision and machine learning. The proposed method is straightforward and logical, with promising experimental results. That said, the paper lacks comparisons to several important baselines:
1) Training a CNN on full images as positive examples and using images and regions from other classes as negative examples, followed by fine-tuning all layers of the CNN.
2) A similar approach as above, but employing a MIL (Multiple Instance Learning) strategy where the highest-scoring positive region is iteratively selected for each image from set A instead of using the full image.
3) Training and fine-tuning the CNN for classification, then using the classifier at test time to predict a single bounding box at the center of the image (e.g., the mean bounding box for ImageNet).
It remains unclear whether the proposed method would outperform these baselines. In particular, the proposed approach does not seem more compelling than baseline 1 and appears less intuitive than baseline 2. Including the third baseline would also help provide readers with a clearer understanding of the difficulty of the problem and dataset.
Clarity: The paper is generally well-written and clear. However, the clarity of the experiments section could be improved, particularly by elaborating on the explanation of the methods referenced in Table 1 (e.g., does this involve applying Eq. 1 or 2 to specific CNN layers?).
Originality: While the approach is sufficiently novel to merit acceptance, it is relatively simple and tailored to specific types of CNN architectures.
Significance: The problem addressed and the results presented are significant and valuable. The paper tackles a relevant challenge, and the ability to achieve reasonable detection results on a large-scale dataset without bounding box annotations is noteworthy. However, the absence of key baselines raises concerns, as it is possible that the results stem more from the improved performance of CNN features rather than the proposed method itself offering a superior approach to training object detectors with weak supervision.