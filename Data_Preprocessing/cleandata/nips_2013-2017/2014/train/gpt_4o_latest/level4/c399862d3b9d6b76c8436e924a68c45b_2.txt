The authors address the problem of online convex optimization with bandit feedback. Existing results establish convergence rates of T^{2/3} under the assumption that the loss functions are convex and either smooth or strongly convex. In this work, the authors assume both smoothness and strong convexity and demonstrate an improved convergence rate of T^{1/2}.
The contribution of the paper is incremental. The proposed algorithm is essentially a straightforward modification of existing methods (e.g., those by Abernethy, Hazan & Rakhlin or Saha & Tewari), and the proof techniques closely mirror prior work, with the primary difference being a refinement of one inequality leveraging the strong convexity assumption.
A more compelling research direction would be to investigate whether the T^{1/2} convergence rate can be achieved without imposing additional assumptions beyond Lipschitz continuity. Overall, this paper presents yet another study on online convex optimization that relies on multiple assumptions about the loss functions, making the contribution appear incremental.