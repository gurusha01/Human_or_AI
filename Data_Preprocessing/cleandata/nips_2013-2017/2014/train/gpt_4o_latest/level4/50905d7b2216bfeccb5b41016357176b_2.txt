The paper is well-written, and the authors provide a solid introduction to the domain of DC programming and its potential applications in reinforcement learning. However, it is difficult to assess the eventual utility of this approach. DC programming is not generally recognized for its computational efficiency. Additionally, the consistency results presented in Section 3 appear to have a narrow scope, even for the specific stochastic MDP class discussed by the authors. The computational experiments demonstrate some promise, but they are limited to simple, low-dimensional (2D) problems.
Minor comments:
- Last paragraph of page 3: Replace "manly" with "mainly," and clarify the inconsistent use of "+" in "+\inf."
- Second paragraph of page 4: Should "too important" be revised to "too large"?
- Section 6: The authors suggest that boosting could differentiate DCA, but why wouldn't boosting also be applicable to other reinforcement learning algorithms?
This is early-stage work that introduces a novel algorithmic approach to reinforcement learning. However, its eventual impact and utility remain uncertain.