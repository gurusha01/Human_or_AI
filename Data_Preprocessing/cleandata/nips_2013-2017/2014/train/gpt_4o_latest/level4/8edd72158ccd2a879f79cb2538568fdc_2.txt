The paper introduces a framework for evaluating the quality of a vote among a team of agents (relative to an underlying true ranking), where the teams are constructed in two distinct ways: through multiple instantiations of the same agent ("Uniform") and through a single instantiation of several different types of agents ("Diverse"). The authors demonstrate that, under certain conditions, as the number of agents increases, the Diverse team converges in probability almost surely to selecting the correct choice, while the Uniform team retains a non-zero probability of error.
The paper is well-written, and the technical quality is high. The results are both significant and relevant. The central insight is that voting among a diverse team yields more robust decisions, whereas a population of identical agents lacks sufficient variance and behaves "too predictably." The authors provide a solid theoretical foundation to formalize these ideas and further demonstrate that even diversity derived from a single (widely-used) Go program with varying parameters can produce notable performance improvements in 9x9 Go (against identical copies of the optimally-tuned parameter version of the Go program) when paired with an appropriate voting scheme. Additionally, the authors connect their assumptions and voting rules to other approaches in the literature.
However, I have some concerns about the paper. First, there appears to be a disconnect between the theoretical framework and the experimental results. While the theoretical section is quite general, the experiments focus narrowly on a specific application to Go. I had anticipated experiments that explore different noise models, validate the assumptions outlined in Section 3, or establish a stronger connection between the theoretical and experimental components. For instance, there is no explicit discussion of whether the Go application satisfies assumptions 1-4, raising the question of whether Theorem 2 is applicable in this context. This issue extends to the discussion section, which also emphasizes the application to games, despite the generality of the theoretical framework. Furthermore, as this work builds heavily on prior research ([18,19]), the authors should better emphasize the novel contributions of this paper. While the noise model approach seems well-suited to the computer Go setting, where an underlying true ranking of alternatives exists, it may not generalize to other domains, such as elections, where the existence of a true ranking is uncertain. Can anything be said about the applicability of this approach in such settings?
Overall, this paper presents an important theoretical result that establishes the asymptotic optimality of diverse agent teams (under appropriate assumptions) while demonstrating the suboptimality of uniform agent teams. However, the experimental results, though significant, feel somewhat disconnected from the theoretical findings, and the originality relative to prior work could be more clearly articulated.