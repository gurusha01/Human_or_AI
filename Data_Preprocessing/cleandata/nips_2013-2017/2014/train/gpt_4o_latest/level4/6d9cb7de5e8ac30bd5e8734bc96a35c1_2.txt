In this paper, the authors introduce a novel norm, referred to as the scaled latent trace norm, as a relaxation of the convex condition for the tensor multilinear rank. They present both theoretical and experimental evidence to demonstrate the benefits of the scaled latent trace norm, particularly in multitask learning scenarios with inhomogeneous dimensions and without prior knowledge of which mode exhibits low rank.
Strengths of the paper:
1) The paper is well-written and clearly articulated.
2) The authors establish robust theorems that provide upper bounds on the error between the empirical risk and the true risk across various scenarios involving the overlapped trace norm, latent trace norm, and scaled latent trace norm.
3) The paper systematically compares sample complexities for matrix completion, multitask learning, and multilinear multitask learning, offering a comprehensive analysis of the results.
4) Experimental results are provided to illustrate that the scaled latent trace norm outperforms alternatives in multitask learning tasks with inhomogeneous dimensions.
Areas for clarification/improvement:
1) The latent trace norm has been extensively studied in prior work, particularly by R. Tomioka and T. Suzuki (2013). The main contribution of this paper lies in the introduction of the "scaled" latent trace norm, but the difference between the two norms is relatively minor.
2) Based on the results presented (e.g., Table 2), the sample complexity of the scaled latent trace norm shows only a slight improvement over the latent trace norm. In the context of tensor completion, it remains unclear whether the scaled latent trace norm consistently outperforms the latent trace norm.
3) The upper bounds derived for all three norms are proportional to the number of training samples raised to the power of negative 1/2, which limits the extent to which they can be fundamentally distinguished. Overall, this is a solid paper with strong theoretical contributions.