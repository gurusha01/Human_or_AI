This paper investigates the challenge of identifying and filtering adversarial workers in crowdsourced classification tasks. An adversarial worker is defined as one whose voting strategy deviates from the standard random process: voting correctly with probability p and incorrectly with probability 1-p, where p represents the worker's reliability. To address this issue, the paper introduces a reputation-based approach, where workers are assigned reputation values. These values are computed based on the extent to which a worker's votes align with those of other workers, with the novel idea of penalizing disagreements rather than rewarding agreements. The authors propose two penalty-based algorithms and rigorously analyze their properties under various adversarial voting strategies. They also validate their methods through experiments on both synthetic and real-world datasets.
This paper tackles an important and compelling problem. Unlike most prior work on label aggregation, which assumes workers' votes are i.i.d. samples from a distribution, this paper considers alternative voting strategies, making progress toward a more realistic framework. However, the theoretical analysis of the hard penalty algorithms is somewhat unsatisfactory due to two main issues: (1) the results are difficult to interpret, and (2) the analysis relies on a strong assumption that honest workers are perfect. Additionally, I have some reservations about the experimental results (see detailed comments below).
Detailed comments:
- In the analysis of the hard penalty assignment algorithm (and in the simulations), the assumption that honest workers are perfect—i.e., they always vote correctly with probability 1—appears overly strong. Is this assumption strictly necessary for your analysis? Could you provide insights or intuitions on how this assumption might be relaxed?
- The results of Theorems 3 and 4 are expressed in terms of the workers' voting graph \( B_H \). To improve clarity and aid reader understanding, it would be helpful to include illustrative examples that demonstrate the bounds.
- In Table 2, the number of users filtered out varies across different settings. To make the results more comprehensive, I suggest reporting all outcomes (e.g., by varying the number of filtered users from 1 to 10). In practical applications, the optimal parameters for your algorithm would not be known in advance, so presenting a broader range of results would enhance the paper's utility.
- In your experiments, your algorithm significantly boosts the performance of ITER (Karger et al., 2011). However, ITER assumes that all workers complete the same number of tasks. If you intend to apply ITER to datasets where this assumption does not hold, you should modify the algorithm by normalizing the messages during each step of the message-passing process. Without this adjustment, the performance of ITER could be disproportionately influenced by workers who complete the most tasks. Without such normalization, your algorithm primarily appears to filter out low-accuracy workers who complete many tasks, rather than demonstrating its ability to specifically target adversarial workers.
AFTER THE REBUTTAL:
Thank you for addressing my concern regarding the implementation of ITER. I have updated my scores accordingly. Please include the revised results if the paper is accepted.
In summary, I believe this is a solid paper that tackles an important and more realistic problem setting. While I remain somewhat concerned about the assumption of perfect workers, the empirical evaluations help mitigate this limitation. I am inclined to support acceptance. This paper addresses a valuable problem, but its contributions are somewhat constrained by the strong assumption. I also have lingering concerns about the experimental results. Overall, I regard this as a borderline paper and do not have a strong preference for either acceptance or rejection.