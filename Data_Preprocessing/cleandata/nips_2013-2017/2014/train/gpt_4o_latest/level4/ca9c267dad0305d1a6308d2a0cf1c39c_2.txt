The paper presents a novel multi-task framework in which multiple online learners share a single annotator. The proposed algorithm, inspired by the perceptron, incorporates an exploration-exploitation strategy to determine which task to query. The authors provide a theoretical analysis of the algorithm, establishing bounds on the expected errors. Additionally, they demonstrate that the algorithm can address two distinct bandit problems. Empirical evaluations on standard machine learning datasets show that the proposed approach outperforms weak baselines employing naive query selection strategies within the same framework. The paper is well-written. However, the proposed algorithm does not effectively exploit the relationships between tasks to enhance learning, which makes it less compelling compared to other multi-task learning approaches. Furthermore, the paper lacks an analysis of the sampling complexity of the algorithm, which is a crucial aspect in the context of selective sampling.
Detailed comments and suggestions:  
1. Including results for a fully supervised learning baseline would provide readers with a better understanding of the tasks' difficulty.  
2. The authors should discuss the benefits of learning tasks jointly under the proposed framework compared to learning them separately using K independent selective sampling algorithms. This discussion, along with empirical evidence, would make the paper more engaging and insightful.  
The paper introduces a novel multi-task framework and proposes a perceptron-like algorithm with theoretical guarantees. However, a key limitation of the algorithm is its inability to leverage task relationships to enhance joint learning.