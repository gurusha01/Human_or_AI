Review - Paper 1180: Deep Recursive Neural Networks for Compositionality in Language
This paper proposes a novel architecture â€” the deep recursive neural network (deep RNN), which is designed by stacking multiple recursive layers. The authors assess the effectiveness of their model on the task of fine-grained sentiment classification.
Clarity  
- Overall, the paper is well-written and enjoyable to read.
Quality  
- The paper appears to be technically sound.  
- The central idea, namely the deep recursive neural network constructed by stacking multiple layers of individual recursive networks, is compelling.  
- The authors have provided a reasonable amount of experimental results to evaluate different aspects of the proposed method.
Originality  
- The proposed concept is straightforward and logical.  
- However, it would be beneficial to include additional discussions on:  
  + Why a deeper network is intuitively advantageous for the target task?  
  + Why the specific network architecture was chosen?  
Significance  
- The paper presents an intriguing idea, a clear background explanation, and sufficient experimental evidence to support the proposed approach.