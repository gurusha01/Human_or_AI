Review - Summary:
This paper introduces a spatial attention mechanism for deep learning, grounded in a probabilistic generative model. The proposed method facilitates the identification of novel objects within large images, potentially enabling more effective utilization of unlabeled and uncropped data.
Main Comments:
The paper represents a significant advancement in applying deep learning techniques to large, uncropped, and unlabeled images. The motivation is strong, as traditional deep learning methods often rely on curated datasets where objects are centered and minimally occluded. Addressing this limitation could open the door to leveraging vast amounts of unlabeled data for training.
The experimental section includes several compelling experiments that validate the effectiveness of the approximate inference method and demonstrate the continued utility of HMC in this context. The network showcases its ability to perform unique and underexplored tasks, such as learning generative models from large, unlabeled images and shifting attention based on various target stimuli.
While the paper asserts that the algorithm operates in O(1) time relative to image size, this claim warrants closer examination. Initializations farther from the target image are likely to require additional steps for approximate inference, suggesting an implicit dependence on image size. It would be valuable to plot the number of required steps as a function of image size to better understand this scaling. Additionally, the size of the window patch provided to the convolutional network may need to increase for larger images, further challenging the O(1) claim.
The manuscript is well-written and easy to understand. Overall, this work makes a meaningful contribution toward enabling deep learning models to process large, uncropped, uncentered, and unlabeled images, potentially unlocking access to an abundance of unlabeled data.