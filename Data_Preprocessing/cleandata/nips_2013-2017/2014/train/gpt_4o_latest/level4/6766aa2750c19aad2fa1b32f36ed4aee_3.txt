Review - Summary:
The authors present a method that integrates trajectory optimization with policy learning for systems with unknown dynamics, which are approximated using locally linear models. The trajectory optimization algorithm is an adaptation of DDP/iLQG techniques. These local linear models, assumed to follow a Gaussian distribution, are derived from samples generated by the preceding policy solution. The paper extends the iLQG-based approach to accommodate these approximated local models. To ensure optimization remains feasible with these approximations, the authors constrain the modifications to the iLQG solution using KL-divergence. Additionally, the paper incorporates this trajectory optimization approach into the Guided Policy Search framework introduced in [11], enabling the iterative alternation between trajectory optimization and policy learning to train richer parameterized policies. The proposed method is evaluated through simulations.
Quality:
The paper is of commendable quality and is well-written overall. However, it occasionally relies heavily on descriptive prose (see detailed comments below), and some claims lack clear supporting evidence. The work is highly relevant to the robotics and robot learning community, particularly due to its focus on handling "unknown dynamics." That said, much of the contribution builds upon prior work in [11, 12, 13]. The evaluation is thorough, with extensive comparisons against several state-of-the-art methods. The simulated tasks are well-chosen and effectively highlight the performance differences.
Clarity and Questions:
Certain sections of the paper lack clarity, and while supporting details may be present, they are not always easy to locate. Below are specific points for improvement:
- Please clarify the terms "unknown dynamics" and "hybrid" in the introduction. The term "unknown dynamics" might misleadingly suggest a "model-free" approach, whereas the method appears to be model-based, as it constructs models from samples (similar to PILCO). Consider using a term like "local Gaussian models" instead of introducing "unknown dynamics."
- In line 52, the statement "parameterized policy never needs to be executed on the real system" is unclear. Does this imply that the Gaussian controller is used throughout the learning process, with the parameterized policy only being trained at the end based on the Gaussian controller's findings? If so, this seems to deviate from the GPS framework, where trajectory optimization and policy learning influence each other iteratively.
- In line 59, the conclusion that the method "...transforms a discontinuous deterministic problem into a smooth stochastic one" is a strong claim, but the reasoning behind it is not well-articulated. Can this be better explained? Additionally, since modeling contact dynamics is challenging and local models struggle with discontinuities, experimental results on tasks involving real physical contact or impact would significantly strengthen the paper.
- The use of GMMs for modeling background dynamics is introduced only in Section 3.2, despite being a key component (as suggested in lines 400-401). This delayed introduction can be confusing. If GMMs are integral to the method, consider presenting the approach as one that approximates unknown dynamics using a mixture of Gaussians from the outset.
- How does the method handle actuation limits? Real-world robots have actuation constraints, which could lead to command saturation. Does this affect the induction of Gaussian trajectory distributions? If so, how is it addressed?
- It is counterintuitive that iLQG with a true model performs worse than the proposed method, which uses approximated linear models. Can the authors provide a clear explanation for this result?
Originality and Significance:
While the paper builds incrementally on the works of [11, 12, 13], the contributions are meaningful. The ability to optimize trajectories and design controllers for systems with unknown dynamics is a significant advancement for the robotics community, addressing a gap not previously tackled by [11, 12, 13].
Conclusion:
Overall, the paper is well-written and accessible. It extends the Guided Policy Search framework [11, 12, 13] to systems with unknown dynamics by leveraging local Gaussian models. Despite being incremental, the work addresses a topic of substantial interest to the robotics community.