The paper presents a clustering approach that inherently addresses the issue of outlier detection. The methodology is rooted in the Facility Location with Outliers (FLO) problem, originally introduced and explored in theoretical computer science in 2001 (refer to [8] in the paper). The primary contribution of the proposed approach lies in its examination of the Lagrangian relaxation of the original integer linear programming problem. Specifically, the authors demonstrate that solving the Lagrangian relaxation is equivalent to solving the linear relaxation of FLO. They also analyze the convergence properties of the subgradient method employed, which enhances the scalability of the algorithm. The paper includes experimental results on both synthetic and real-world datasets (MNIST).
The manuscript is well-written, logically structured, and easy to follow, even with its technical depth. The motivations and objectives of the work are clearly articulated.
I appreciate the effort to introduce this seemingly novel clustering formulation to the machine learning community, as it appears to have been previously limited to the theoretical computer science domain. However, regarding the authors' claim that "clustering and outlier detection are often studied as separate problems," I would encourage them to consider recent clustering formulations that move away from the traditional partitioning paradigm and instead focus on the intrinsic definition of a cluster (see, e.g., M. Pelillo, "What is a cluster?" NIPS'09 Workshop on Clustering, and references therein). These non-partitional approaches inherently unify clustering and outlier detection, treating them as two aspects of the same problem.
A notable limitation of the proposed approach is that, while it eliminates the need to specify the number of clusters—a clear advantage—it still requires prior knowledge of the number of outliers, which can be even more challenging to determine in practice. Additionally, the method depends on defining the "cost" of creating a new cluster, which is not straightforward in real-world applications. The choices made in the experiments seem largely heuristic and lack clear justification.
Regarding the experimental validation, the results do not convincingly demonstrate a significant improvement over existing methods. This is particularly evident in the MNIST experiments (Table 1), where APOC and LR perform similarly, and k-means-- outperforms the proposed LR algorithm.
Minor comments:
- Definition 2 should be labeled as a Proposition.
Despite the limitations in experimental results and the reliance on problematic parameter settings, the ideas presented in this paper are conceptually interesting and exhibit a degree of novelty. Therefore, I would recommend allowing the authors to present their work at NIPS in a poster format, while encouraging them to strengthen the experimental evidence supporting the effectiveness of their approach.