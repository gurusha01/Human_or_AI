Secondary Review: The authors have addressed my concerns satisfactorily. Specifically, the issue with the proof of Theorem 1 can indeed be resolved by adopting the choice of epsilon suggested by the authors. However, the second-to-last inequality in their derivation appears unusual (the inclusion of the additional \( Vt^{2/3} \) term seems unnecessary). After confirming that "the first part still holds," they could proceed directly to the case where \( \epsilon = \frac{1}{4} \sqrt{\frac{K}{\tilde{\Delta}T}} \). Regarding line 424, while their explanation is clear, I see no justification for omitting the \( T^{1/3} \) term. This term provides valuable insight into the initial performance, and excluding it entirely could lead to a misleading interpretation.
I appreciate the authors' efforts in revising their derivations, and I am now willing to adjust my review scores accordingly.
---
Initial Review:
Summary of paper:  
The authors address the multi-armed bandit (MAB) problem in a setting where rewards are drawn from non-stationary distributions. They introduce a parameter (\( VT \)) that upper bounds the extent to which the reward means can vary over time. The authors define classes of MAB problems based on admissible ranges of \( VT \) and analyze the worst-case regret of algorithms compared to a non-stationary oracle within these classes. They derive a lower bound on the worst-case regret for any strategy in terms of \( VT \), the time horizon, and the number of arms. Additionally, they present a matching upper bound for an epoch-based variant of the Exp3 algorithm. This establishes a tight dependency of the regret bounds on \( VT \), supporting its interpretation as a quantitative measure of the cost of introducing non-stationarity into the standard MAB framework.
Quality and Clarity:  
The paper is well-written in some sections but less so in others. I found the details of the proofs and the introduction of new notations challenging to follow. Two primary issues stand out:  
1. There appears to be an error in the proof of Theorem 1. Specifically, on line 119 in the appendix, I do not see how the second inequality follows from the assumption \( T \geq KVT \). It seems to me that the numerator on the left-hand side of this inequality is at least \( T^{4/3}/8 \) if and only if \( (KVT)/T \geq \frac{(1+\sqrt{\log(4/3)}/2)^3}{2} \), which is not implied by the stated assumption. I would appreciate clarification on how the argument proceeds at this step.  
2. I struggled to reconstruct the bound (a) on line 424 in the proof of Theorem 2. Using the authors' assumption \( VT \geq K^{-1} \), I can bound the second term on the right-hand side of the inequality above (a) by \( K(\log K)^{2/3}T^{1/3} \). Importantly, this introduces a linear dependence on \( K \). I would like clarification on how this transforms into a dependence on \( (KVT)^{1/3} \). This derivation is critical because, without it, the bound would not match the lower bound in Theorem 1.  
Additional suggestions for improving readability:  
- Some notation and terminology differ from conventions in related literature and could be aligned for consistency. For example, the "Admissible policies, performance, and regret" section introduces policies in a non-standard way compared to many bandit and MDP papers. Typically, \( \pi \) is treated as a distribution over the arm set, measurable with respect to the history, with \( at \) or \( It \) denoting the chosen arm at time \( t \).  
- The two paragraphs following Theorem 2 could be highlighted more prominently, as they present important and interesting implications of the theorem and its proof.  
- It is unclear why the proof of Theorem 2 is relegated to the appendix within the main submission. It would be more natural to include it as a section preceding the discussion or immediately following Theorem 2.  
- The connection to reference [27] is mentioned multiple times but is not elaborated on in detail. Consolidating these references into a single, detailed discussion (e.g., in the discussion section) would improve clarity.
Originality and significance:  
The paper makes an original and significant contribution to the NIPS community. It provides new insights into the relationship between stationary and non-stationary MAB problems. While the authors do not propose direct real-world applications for the parameter \( V_T \), their work offers a novel perspective that could be of practical interest. This is an important addition to the multi-armed bandit literature, where the authors derive matching upper and lower bounds on worst-case regret for settings with non-stationary reward distributions.  
Note: In my initial review, I mentioned that the paper was difficult to read and poorly structured, with two technical issues in the proofs. These concerns have now been addressed.