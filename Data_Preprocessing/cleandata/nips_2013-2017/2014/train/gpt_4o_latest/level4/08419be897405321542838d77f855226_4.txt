The paper presents a novel application of neural networks: learning representations for symbolic expressions and identifying their mathematical equivalences. While the scope of expressions studied is quite restricted, and there is no evidence provided that the approach can generalize to more complex expressions, I find the work intriguing. It has the potential to make a meaningful contribution to symbolic computation libraries.
- The problem statement specifies a goal of identifying expressions with lower computational complexity. However, the algorithm does not explicitly enforce this constraint. I understand that addressing this is non-trivial, but have the authors considered potential methods to constrain the search space to solutions with reduced complexity?
- Regarding the limitations discussed in Section 2, is the scheduler the sole bottleneck for handling more complex mathematical expressions? It would have been helpful to include either a more formal analysis or empirical experiments to justify these restrictions.
- Additionally, the paper's structure is somewhat difficult to follow. Clarifying the stages of the approach would significantly improve readability.
- Is there any constraint on the size of the vector/matrix? For instance, in the case of k=1, n=1, the expression for RBM-1 in the supplementary material does not appear to be valid.
Some minor typographical errors:
- Line 332: "show for" → revise
- Line 148: "has contains" → revise
- Line 289: "is is" → revise
- Line 338: "by be" → revise
In summary, the paper introduces an innovative method for representing symbolic expressions and identifying their equivalences. While its applicability is currently limited, the approach is novel and holds promise.