The authors introduce a clustering framework that incorporates max-margin constraints, enabling clusters to be defined as a balance between modeling data density and separating observations through cluster-specific latent projections derived from regularized Bayesian inference. The proposed method is developed for both standard DPGMM and topic modeling, extending the cluster-based topic model (CTM) to form the DPMMGMM and MMCTM frameworks. The utility of the approach is demonstrated on synthetic and real-world datasets, showing improved recovery of ground truth information compared to standard non-parametric mixture models (DPGMM and CTM), as measured by normalized mutual information and accuracy, respectively.
The framework is innovative, and the inclusion of max-margin constraints for cluster separation is both logical and impactful, potentially justifying publication. The proposed method builds on the regularized Bayesian inference framework, and the accompanying appendix provides detailed implementation specifics for this non-trivial extension.
The primary concern lies in the tuning of the regularization strength \( c \) and margin \( l \). As acknowledged in the paper, these parameters significantly influence the results. However, the suggested tuning approach appears somewhat ad hoc. The paper would benefit from an analysis of cross-validated tuning compared to the proposed heuristic for DPMMGMM. Additionally, the description of the MMCTM framework is unclear—it is stated that this represents the optimal parameter setting, but the method for determining this is not explained. For instance, does this involve using the same number of topics as CTM? Please clarify. Specifically for the topic modeling results, the choice of \( c=9 \) and \( l=0.1 \) seems to be an informed decision, but the rationale behind this selection is not provided. This should be clarified, or at the very least, the influence of these parameter choices should be better addressed, as they appear to be critical for the method's performance.
Minor comments:
- Please clarify the meaning of the lines in Figure 3. I assume they represent \(\eta_k\).
- Typographical corrections:
  - "Gausses" → "Gaussians"
  - "in the generate process" → "in the generative process"
  - "needed to sampled" → "needed to be sampled"
  - "to jointly sampled (yi,si)" → "to jointly sample (yi,si)"
  - "many of the the sampling formula are" → "many of the sampling formulas are"
In summary, this is an intriguing framework for separating clusters in generative models, with apparent utility in uncovering ground truth structure. However, proper tuning of the tradeoff and margin parameters appears to be critical.