The paper introduces several novel methods for video classification using deep learning, specifically a two-stream formulation and multi-task learning. The methodology, implementation details, and procedures are described comprehensively. The paper is well-written, clear, and effectively demonstrates the merit of the proposed methods through strong results.
The proposed methods are innovative. While the paper builds upon the framework of [13], the two-stream approach is particularly compelling as it highlights the significant improvements achieved by incorporating the optical flow component. This finding is likely to attract considerable interest from researchers. The paper is well-structured and easy to follow, although it appears to be divided across multiple contributions rather than focusing on a single cohesive theme. Nonetheless, the results demonstrate impressive improvements over [13] and are competitive with state-of-the-art methods.
Suggestions for improvement:  
1. Since the primary significance lies in the two-stream approach and the integration of optical flow, the abstract and introduction could benefit from a more focused narrative.  
2. Missing citations in deep learning:  
   - Learning Hierarchical Spatio-temporal Features for Action Recognition with Independent Subspace Analysis. CVPR 2011.  
   Missing citations in computer vision:  
   - Evaluation of local spatio-temporal features for action recognition. BMVC, 2010.  
Overall, the paper provides substantial practical contributions and introduces intriguing ideas that complement the core concepts in deep learning. I recommend accepting the paper at NIPS 2014, provided the authors incorporate the suggested improvements.