Review - Paraphrased Version
Overview:  
This paper introduces a fast alternative to Monte Carlo (MC) methods for approximating intractable integrals.  
The core concept of Bayesian Quadrature (BQ) is to leverage assumptions and regularities in the likelihood surface, which are typically ignored by standard Monte Carlo approaches.  
In this work, the authors propose modeling the square root of the integrand (the likelihood/prior) as a Gaussian Process (GP). Sampling is then performed based on a specific criterion—here, samples are selected at the location of the maximal expected posterior variance of the integrand. Intuitively, this corresponds to regions where the model has the least information about the integrand, thus maximizing the potential information gain.  
A key emphasis is placed on the computational advantages of their BQ active sampling method compared to conventional Monte Carlo techniques.  
The authors demonstrate their method by approximating integrals in various contexts, including marginal likelihood estimation for GP regression and GP classification.  
Quality:  
This paper is technically robust: the problem is well-motivated, the methodology is clearly articulated, and the proposed approach performs well in comparison to other numerical integration techniques.  
Clarity:  
The paper is exceptionally well-written and well-structured. The authors effectively communicate all aspects of their analysis. They provide a clear explanation of Bayesian Quadrature (and the broader context of numerical integration), as well as a thorough comparison to existing methods. Their contributions are clearly delineated, and they excel in explaining their approach and the progression from problem to solution.  
Originality:  
The authors propose their method as an improvement over existing Bayesian Quadrature techniques, offering benefits in both speed and accuracy. They highlight two main contributions: the square root GP and their "fast active sampling" strategy.  
The square root GP represents an alternative approach to modeling a positive function (the likelihood), which is relatively underexplored. Additionally, the authors provide a detailed explanation of two strategies to address the intractability of inference under a non-linear GP transformation: linearization and moment matching.  
Significance:  
The paper introduces a novel tool for marginal likelihood computation—an important and challenging task. The utility of this tool lies in its speed, accuracy, and ease of implementation. The authors present a competitive alternative to existing approaches, excelling in these aspects. However, the broader impact of this work remains uncertain. It would be valuable to understand what future research directions this contribution might enable or inspire.  
Questions and Comments:  
- Figure 1: In this example, are the GP hyperparameters learned? If the covariance function is something like a squared exponential, how does the length-scale handle the highly variable section?  
- Line 208: How does the log transform compare to the square root transform? While it seems intuitive that an unconstrained GP would perform worse, how does another type of constrained GP fare?  
- Line 264: Why does the log transform result in worse variance (to the extent that it degrades the overall performance)?  
- Line 303: Is the task here simply to integrate over the mixture of Gaussians?  
- Figures 8 and 9: Consider presenting the converged values in a table for clarity. It is difficult to compare L, M, and AIS in their current form.  
Summary:  
This is a strong, technically sound paper that introduces a novel method for Bayesian Quadrature.