This paper integrates selective attention into a convolutional neural network and proposes a method for training gating parameters to enhance the network's classification performance. It tackles a significant set of challenges in computer vision—specifically, how to adaptively reconfigure deep, complex processing stages under resource constraints and varying task demands. While the classification results are impressive, the approach remains largely a black box, offering promising directions for future exploration but providing little insight into why the method works. The analysis of image representation is not particularly illuminating, and the role of the learned parameters (mean and variance of the theta distribution) is unclear. Nonetheless, this work represents an important advancement beyond the current paradigm of large, feed-forward networks with fixed parameters post-learning. The exposition is generally clear, though some equations contain typos or require better explanation.
Major Comments:
The authors should seriously consider exploring the connection to dynamical systems. The proposed approach appears more closely related to recurrent networks than to reinforcement learning. Since the reward is observed immediately and the policy is deterministic, training effectively involves navigating the space of recurrent "policy" parameters (theta) to maximize the observed objective function.
The analysis of the network processing the cat image does not provide much insight into how the model's new features aid recognition. For instance, why are layer 1 activations uniformly increased during the first iteration? Does this influence the objective function, or is the output invariant to global scalings? A more focused analysis, such as examining a smaller region of the image and tracking the evolution of gating variables within that region, could be more instructive. Additionally, analyzing challenging cases—those misclassified by the standard Maxout network but correctly classified by the proposed model—or further constraining the learned model parameters (mean and variance of theta) to tease out their effects would be valuable.
Minor Comments:
- Algorithm 1 Description: Where is \( h_M \) defined? Is this the step where observations are collected? Within the loop over images (\( j \)), are \( F[i] \) and \( \Theta[i] \) stored in an array or overwritten during each iteration?
- Equation 11: What is the summation over? Is Equation 8 specific to a single image and should therefore be indexed by \( j \)?
- Text After Equation 11: What do \( x \) and \( d \) represent?
- Regularization of Theta: It is unclear why regularization of theta is necessary, as theta is already sampled from the prior and is likely to have small values by default. Additionally, the final optimization step (gradient updates on parameters after sampling and evaluating the fitness of thetas) is not well explained. How are the gradients computed, and is this step theoretically justified? Are the authors effectively adjusting hyperparameters of the posterior over policies?
This is an intriguing approach to constructing deep recurrent networks for recognition. The high classification accuracy compared to standard methods suggests that recurrent computation aids in extracting or focusing on more complex image features. However, the black-box nature of the method leaves its effectiveness largely unexplained.