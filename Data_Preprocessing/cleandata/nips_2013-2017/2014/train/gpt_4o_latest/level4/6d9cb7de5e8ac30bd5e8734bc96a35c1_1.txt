In this paper, the authors address the problem of learning a tensor for linear multi-task learning. They introduce a weighted variant of a previously proposed tensor norm, referred to as the "latent trace norm," and demonstrate that this rescaling leads to improved bounds on the excess risk as well as enhanced recovery performance on certain datasets. The paper is well-structured and clearly written, and the proposed rescaling has the potential to make a notable practical impact, though a more comprehensive experimental evaluation would have been beneficial. The technical results appear to be sound and rigorously proven. The coverage of related literature seems adequate. It is worth noting that all the tensor norms explored in this work can also be interpreted as special cases of a broader class of tensor penalties presented in the recent paper:  
A. Argyriou, F. Dinuzzo. A Unifying View of Representer Theorems. ICML 2014.
The paper conducts an analysis of some recently introduced tensor norms, along with a new weighted version of one of them, showcasing the benefits of this reweighting both theoretically and empirically. Overall, the paper is well-written, well-organized, and potentially impactful.