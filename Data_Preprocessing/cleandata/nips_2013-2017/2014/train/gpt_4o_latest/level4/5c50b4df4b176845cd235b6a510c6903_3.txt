Recall that there exists a vast array of voting rules. How can one single out a specific rule or propose new ones in a systematic and principled manner? A notable line of research in computational social choice (e.g., Conitzer-Sandholm) explores which voting rules emerge as the MLE (maximum likelihood estimator) under certain settings (some do, while others do not). This paper takes a complementary approach: it begins by positing a statistical decision-making framework (including a prior over a ground truth and a loss function), derives the optimal rule that minimizes the expected loss, and examines whether the resulting rule offers novel insights.
The authors implement this general approach within two variations of the Mallows model. In both cases, there exists a ground truth, and each pairwise ordering is independently flipped with some probability determined by a noise parameter. The distinction between the two models lies in whether the ground truth must adhere to a consistent structure (i.e., a linear ordering) or not. The rules derived from this framework do not necessarily align with any of the well-known voting rules. The authors analyze these new rules across three dimensions: first, which standard properties they satisfy (e.g., monotonicity); second, how their outputs compare to the well-known Kemeny rule in the limit as the number of iid inputs grows large; and third, the computational complexity of determining these rules (computationally hard when the ground truth is a linear order, but computationally easy otherwise).
Although none of the individual results are groundbreaking, the overarching idea is compelling, and the collection of results represents a comprehensive exploration of a natural instantiation of the proposed framework.