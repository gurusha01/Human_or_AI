The manuscript "Speeding-up Graphical Model Optimization via a Coarse-to-fine Cascade of Pruning Classifiers" presents a framework aimed at enhancing MRF Optimization by employing a cascade of classifiers to iteratively prune the search space, transitioning from coarse to fine-grained models.
The proposed pruning scheme is innovative, compelling, and appears to perform well in practice while achieving faster results compared to existing methods. However, several parameters are pre-defined (e.g., C = 10, 5 scales, rho). The robustness of the method with respect to these parameter values is not entirely clear, though the consistent parameter settings across all evaluation datasets suggest that the approach is not overly tailored to specific cases. That said, line 294 mentions that C was set to 10 because it provided satisfactory accuracy, which implies the value may have been chosen based on test data observations.
The manuscript is well-written and highly accessible. The significant speed-up achieved by the proposed method suggests it could have a meaningful impact on the field.
Minor typos:
- Line 90: different classifiers per scale are used (not "is used")
- Lines 102-103: with a fine-grained pruning of the labels (not "fined-grained")
- Line 155: one with too much in the heading
- Line 363: all aggressiveness factors except lambda (not "expect lambda")
- Line 370: illustrated in column (d,e,f) (not "(d,e,g)")
The proposed pruning scheme is innovative, compelling, and appears to perform well in practice while achieving faster results compared to existing methods. The significant speed-up achieved by the proposed method suggests it could have a meaningful impact on the field.