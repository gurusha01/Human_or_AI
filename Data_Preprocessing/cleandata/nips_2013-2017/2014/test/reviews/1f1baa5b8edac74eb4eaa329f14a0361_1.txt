The paper strives to bridge the gap between the theory and practice of attribute-based zero-shot learning. The theory is that novel classes can be recognized automatically using pre-trained attribute predictors; in practice, however, learning these attribute classifiers can be as difficult or even more so than learning the object classes themselves. 
Random forests are trained to predict unseen classes from attribute vectors,
and the training procedure takes into account the reliability of the attribute
detectors by propagating a validation set through each decision tree at training
time. The authors show how the method can be extended to handle training with a
few training examples of test categories. The method achieves state-of-the-art
results on several attribute datasets.
QUALITY: The authors do a really nice job of handling this fundamental zero-shot learning problem using a random forest framework. The model is elegant and theoretically sound. Results on 3 standard datasets are strong. The authors do a nice job of performing ablation studies, introducing artificial noise, evaluating several setting (zero- versus few-shot learning), and comparing with the literature.
CLARITY: The paper is very well written. One confusion was in Section 3.2.1: when the threshold t is introduced, the attribute signatures are still binary, so t can be any value 0 < t < 1 without changing anything in equation (2). Then it is not clear in lines 207-212 how a novel test example can be propagated down the tree, since t seems to be ill-defined. This is cleared up in later sections.
ORIGINALITY: This is a nice application of a random forest framework to an important problem.
SIGNIFICANCE: The paper addresses a fundamental problem in zero-shot learning.
 The paper is strong, interesting, and sound. The results on 3 datasets in a variety of settings are convincing. The paper deserves to be published.