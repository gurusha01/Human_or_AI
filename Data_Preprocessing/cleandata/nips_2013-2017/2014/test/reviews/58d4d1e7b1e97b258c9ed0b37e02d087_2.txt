The manuscript tackles the important issue in cognitive modeling of
model identifiability. The manuscript is nicely written and quite clear.
However, the work is premised on a long list of assumptions that one
must buy into and make sense of, and this list is quite long relative
to the impact of the key results presented. Because the methodology
is interesting and innovative, I judge the work to be above threshold
for presentation at NIPS.
Insofar as key results go: In section 4.1, the interchangeability of sensory
and motor noise was little surprise (I questioned incorporating both into
the model as I was reading). It would help to indicate which condition
differences were reliable. (Maybe I'm just too dumb to read box plots.)
In section 4.2, isn't it essential to show that if the reference
observe did not have a slow-speed prior, the model could recover this
fact as well?
Specific comments:
line 106: Why is the stimulus drawn from a discrete distribution when it in
fact a continuous variable? I assume this is due to the typical
design of experiments, where the stimulus level is the independent
variables. But the authors may wish to clarify this point.
line 134: As the authors note, the log-stimulus transform (Equation 2) is
motivated by psychophysical laws. It seems that the success of their work
may be due in large part to the incorporation of this transform.
That is, the transform imposes a fairly strong constraint on inference
and thus, this work is really saying that Bayesian models are identifiable
given strong assumptions about representational transformations in the mind.
line 143: Do the constraints in Eq 4 and the maximization of differential
entropy ensure that Eqn 3 is fit to be a unimodal distribution? It seems like
the fit could yield in principle a bimodal distribution.
line 158: Why should the observer's prior favor the lattice representation
over a uniform representation? What does the user know about the true
stimulus distribution that allows them to have a prior which is 50% wider
than the true range?
Figure 1: Even after staring at the figure, I feel more confused by it
than enlightened. It seems like it would be clearer if Figure 1b were
integrated into Figure 1a, and p_est(s^*|x) were removed from the
Figure, since it is a derived inference.
line 252: Can the authors comment on the conditions on N that
make Equation 14 approximately correct, i.e., when Stirling's approximation
of the factorial and the holds, and under what circumstances E[xlogx] ~=
E[x]logE[x]. I have to say that by the point where the authors come up
with Equation 15---having abandoned priors on \theta and made some
questionable approximations---I feel that Equation 15 is justified only
by the fact that it yields an intuitive rule for assessing similarity
of predictions.
line 262, "sample from this unnormalized density": Which density? The dataset
distribution?
line 365: Why does learning of priors not matter in 2AFC? Innovative approach, important problem, less than overwhelming results