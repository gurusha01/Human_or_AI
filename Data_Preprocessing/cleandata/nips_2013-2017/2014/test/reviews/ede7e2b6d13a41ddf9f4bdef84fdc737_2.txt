This paper proposes a new incremental gradient algorithm based on the spirit of several relative methods proposed recently. This work makes some variances on the update rule of gradient. 
To my best of knowledge, the core idea of incremental gradient algorithm is to reduce the variance of the proximal gradient to get better convergence rate. From this kind of view, this work is not so attractive as the convergence rate doesn't improve significantly and the idea of this paper is not very novel. This also can be seen from the result of experiments. The result of the method in this paper gets similar convergence speed with the other methods and doesn't always outperform the existing methods. 
Besides, there maybe some small errors in the proof, e.g., the equation in line 324 may miss a scalar eta.
However, this is a completed work with relatively simple theory analysis and the author clarifies clearly the relationship of SAGA with the other related works. 
 This is a completed work with relatively simple theory analysis. However, the main contribution of this work is not very attractive.