Quality and originality: The focus on the online setting in recommendation is welcome — this is a genuinely challenging issue in domains like movies, books and music — and I find the introductory material to be of high quality. The performance guarantees and proofs seem correct to me, but I'm not at all an expert in that area. The Collaborative-Greedy model itself is less convincing. Though it outperforms two other models, the datasets used are so small that it's hard to get an intuition as to how it would work for more realistic datasets (Netflix prize, Million Song dataset). The authors show awareness of this pint in observing that a full validation would require an actual interactive online recommendation system. Also, the point of the paper seemed more to be a theoretical exploration of possibilities, and the datasets seem large enough to support the authors' claims. I find the final claim of the paper to be particularly thoughtful: that two types of exploration are useful for learning mixed distributions in an active learning setting.
Clarity and Significance: This paper was pretty far from my area of research. I found the paper to be "locally clear" (i.e. I think I understood each individual paragraph) but I fear I'm missing some of the bigger picture.  This paper explores the online setting in collaborative filtering, presents a model and learning problem for online recommendation, provides performance guarantees (with proofs) and discusses some experimental results.