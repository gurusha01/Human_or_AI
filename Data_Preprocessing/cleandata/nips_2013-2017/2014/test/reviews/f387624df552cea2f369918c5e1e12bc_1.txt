Problem definition:- The paper studies best-arm identification in linear bandits. In this problem there is a hidden unknown parameter \theta\in R^d and a finite set of arms X\subseteq R^d. When an arm is pulled you observe a reward x^T\theta+epsilon where epsilon is a zero mean i.i.d noise with bounded range. The goal is to identify argmax_{x\in X} x^T\theta* with the least number of samples. 
Results: The paper characterizes the sample complexity of static and dynamic allocation strategies to identify the best arm. 
Quality of the paper:- The techniques appear reasonably sound. In the experiments section it would also be nice to compare to the existing algorithms for linear bandits. (i.e run the existing algorithm for linear bandit till \hat{S}\subseteq C(x) and then count the number of steps to achieve this). The reason this comparison is important is that the paper mentions at the beginning of the paper that unlike MAB, the strategies to minimize sample complexity of best arm identification of LB could be different from regret minimization. 
Clarity of the paper:- The paper looks reasonably well written. 
Significance:- The paper proposes and solves a reasonably general problem. The paper does not necessarily do a good job mentioning applications, but I think it looks like an abstract problem which should have good applications. 
 The paper studies best-arm identification in linear bandits. It characterizes the sample complexity of static and dynamic allocation strategies to identify the best arm.