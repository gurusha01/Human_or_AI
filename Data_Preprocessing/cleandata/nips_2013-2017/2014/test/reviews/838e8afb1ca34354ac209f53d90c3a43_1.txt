This paper proposes a new regularization method for structured prediction. The idea is relatively straightforward: a linear chain model is segmented into smaller subchains, each of which is added as an independent training example. 
Theorems are provided (with proofs in the supplement) showing how this regularization can reduce generalization risk and accelerate convergence rates. Empirical comparisons with state of the art approaches suggest that the resulting method is both faster and more accurate. The accuracy improvements are small, but these are all well-studied tasks where small improvements can have impact.
My primary concern is the assumption of a linear chain. Is this a limitation of the method? If not, the notation should be generalized to accept graphical models of arbitrary structure. Otherwise, the article should be written assuming a linear chain. There are obvious additional difficulties when considering more complex models --- even if the scope of this paper is limited to linear chains, I think this is still a sufficient contribution. 
A secondary concern is that the paper should be better placed in the context of related work. How does this approach relate to other work that approximates structure at training time? E.g., piecewise training (Sutton & McCallum, ICML 2007) or Wainright's "Estimating the "Wrong" Graphical Model" paper (JMLR 2006). In general, please better situate this submission in the context of related work.
Finally, the paper could use a more thorough edit to remove some distracting errors and add additional clarifications. Some suggestions:
- Proposition 3: it is not clear why the learning rate is defined as such. Please motivate and clarify.
- Is Figure 2 accuracy or F1? The text seems to confuse these terms.
- I assume only the best performing StructReg results are used for computing significance? Surely it is not significant for all values of alpha.
058: confliction -> conflict
078: two-folds -> two-fold
098: local window of $ok$: "Window" typically denotes features of adjacent nodes in a chain, but this notation suggests the features are of observation $ok$. Please clarify.
138: draw -> drawn
164: Please define $N_\lambda$ in Eq. 1
193: I believe $g$ in Eq. 5 should be G, to be consistent with Eq. 4.
201: focus -> focuses
220: xvalue -> value (?)
229: value is bounded -> value be bounded
236: simplified as -> approximated by (?) Since you're ignoring small terms.
 This paper proposes a new regularization method for structured prediction, providing theoretical and empirical evidence of its efficacy. While the approach is straightforward, it appears to perform quite well, and has an interesting theoretical foundation; I feel this paper is a valuable contribution to structured classification problems.