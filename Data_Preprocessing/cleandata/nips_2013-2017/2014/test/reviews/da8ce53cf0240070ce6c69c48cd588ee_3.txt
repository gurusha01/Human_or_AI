The paper continues a line of work in graphical models to go beyond
Gaussian modeling of real-valued attributes. The apparent novelty is
the combination of a previous algorithm for non-parametric forest
density estimation, which rests on a non-parametric generalization of
the classical Chow-Liu algorithm for learning tree graphical models, with the standard
graphical LASSO (glasso), resulting on the authors call a "blossom tree
graphical model." The paper states a type of statistical-consistency
(theoretical) result, and a few experiments.
* On Section 3: Can the authors' comment on how much the stated result
says about machine learning properties (i.e., PAC or
large-deviation, as opposed to data-size-asymptotic bounds)? Can the
authors say anything at all about the properties of the constant N?
What would be an expression of a lower or upper bound, even if exact?
Just like the typical asymptotic convergence as the number of samples
goes to infinity (e.g., CLT), it is hard to know when the
large-deviation bounds of the kind provided in the paper start being
valid. Without such information regarding N and the exact number
of samples n, while it may be an interesting and useful statistical
result, it does not appear very useful to machine learning, IMHO.
Hence, I would have Section 3 moved fully to the supplementary
material and replace it with more experimental evaluations. For example,
I would have moved the sections Supplementary Simulations 1 and 2 into
the main body of the paper. But even then, a slightly more thorough
evaluation would be useful such as experimenting by changing the class
or form of the underlying ground-truth density, and the class of
underlying graphs, whenever applicable, the number of samples, and the
number of attributes/variables. 
* Given the nature of the paper, a reference to the Chow-Liu 
algorithm, from 1968, seems warranted, even if only in passing. 
C. K. Chow, and C. N. Liu, "Approximating Discrete Probability
Distributions with Dependence Trees," IEEE Transactions of Information
Theory, vol. IT-14, no. 3, May 1968
Despite the different statistical setups/models (i.e., discrete
vs. continuous), and the fact that the work in the submitted paper
goes beyond simple trees/forests/blossom representations, it is
undeniable that the core of the underlying approach has its roots on
Chow-Liu's work.
* It'd have been nice to see experiments on real-world data such as
those on microarray data that Liu et al (JMLR, 2011) performed. Is
the problem public access to the data? What about other datasets
(e.g., fMRI)?
* I am curious as the core distinctions among the following work and
forest density estimation, which serves as the foundation for the submission?
- Marwan Mattar, and Erik Learned-Miller. Improved generative models for
continuous image features through tree-structured non-parametric
distributions. UMass Amherst Technical Report 06-57, 10 pages, 2006.
- Mihai Datcu, Farid Melgani, Andrea Piardi, and Sebastiano
B. Serpico, "Multisource Data Classification With Dependence Trees,"
IEEE Transactions on Geoscience and Remote Sensing, vol. 40, no. 3,
pp. 609-617, March 2002. 
I am interested in directly ML-relevant, as opposed to statistical,
distinctions.
* It has been quite a long time since Chow and Liu's work in 1968. Hence,
I was originally skeptical that no one had actually tried anything like what the
authors' propose. If it exists, I have not been able to find it. So,
while somewhat surprising, I must give the authors their due for the
novelty and originality of their proposed approach... Now, I may
change my mind later, should I find a reference :) ... All kidding aside,
even if I find an old reference, it does not take much away from the
authors' originality/novelty, because no one in recent years have
proposed the technique, despite the intense attention to the problem
of modeling continuous/real-valued attributes going back a decade, at least!
 A nice, clean, interesting, and surprisingly novel approach tomodeling multiple real-valued attributes/random variables. It can benefitfrom further experimental/empirical evaluations.