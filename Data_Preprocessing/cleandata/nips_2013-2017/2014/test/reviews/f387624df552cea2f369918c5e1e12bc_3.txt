The paper deals with the pure exploration variant of linear bandits. Here, the input consists of K vectors of d dimensions. The player is allowed to query vectors and obtain a sample from a distribution whose mean is a fixed linear function of the vector. The objective is to find the arm with maximum value w.h.p using a minimal number of queries.
The authors provide a solution to the problem based on the experiment design framework. They offer two static allocation strategies, meaning methods for querying the arms that are not adaptive to the outcome of the queries. These strategies provide a result analogous to that of the uniform strategy w.r.t the classic best arm identification problem. The authors also provide a dynamic strategy achieving a provable result that can outperform the static strategy in some scenarios. In addition to the proposed solution, a problem-dependent optimal strategy is given that matches that of the classic best arm identification problem.
The main body of the paper is in general well written. Some of the proofs in the appendix can use a few more details but they hold, as far as I checked. The studied problem is interesting and the paper provides an extensive theoretical study of it. However, I found the experiments a bit lacking. The result for the adaptive sampling technique is a bit weak in the sense that there is a separation between it and static methods only in a very specific case in which, among other requirements, finding the second best arm is a much easier task than finding the best arm. It is an interesting question whether the true performance of the adaptive setting is indeed superior to the static only in this restricted scenario or whether it is superior in other scenarios as well. Proving such a statement may prove to be difficult but there should be experiments aimed to answer this question. Instead the experiments are made w.r.t an example carefully built to match the conditions in which the adaptive algorithm is provably superior.
Comments / typos:
•	Proposition 1: should be "w.p. 1-\delta, for all x \in …" rather than the other way
•	Line 101: D^k – small k rather than large K
•	Equations 3,4,5: It seems that the expression in the log be K/\delta rather than K^2/\delta. 
•	Given the optimal strategy, it seems rather easy to prove a lower bound for the sample complexity
•	In Lemma 2, H_LB is bounded from above and below. It would be interesting to see for some example data sets how close it is to the upper and lower bound
•	Theorem 1: N^G should be defined
•	Line 269: The comment after theorem 2 is too vauge. It seems that there is some expression "NG < ExpressionG < the given bound" and "NXY < ExpressionXY < the given bound" that is missing, since the bounds as given are exactly the same
•	Line 352: missing space
•	Section B: Wouldn't it be easier to simply sample from the strategy provided by the convex program? Matrix chernoff boundes should help ensure (w.h.p) that the sample converged well
•	Proof of lemma 6: Theorem 2.6 of the mentioned paper does not necessarily apply for D-optimal design. Also, Some reference is needed for the claim that G and D optimal design are equivalent, even w.r.t approximations (as the D-optimal problem is only approximated by the greedy strategy)
•	Equation 30: should be <, not \leq
•	Line 753: should be n_j > M^*
 Overall I recommend accepting the paper since the problem is interesting and the analysis is solid and extensive. However, the quality of the paper can potentially increase if the authors can manage to add more meaningful experiments, either on real data or on more plausible synthetic data.