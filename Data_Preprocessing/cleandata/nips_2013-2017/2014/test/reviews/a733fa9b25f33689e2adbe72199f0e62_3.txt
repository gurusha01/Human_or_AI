This paper provides an alternative based on Gaussian processes (GP) to standard GARCH-related methods for modeling the time-varying volatility of financial time series. The benefit of the GP approach is greater flexibility.
This submission is technically competent, but not of broad interest or great novelty. The mathematics and the Bayesian algorithm are specialized for this problem.
The experiments look rather unfair. The synthetic datasets are well-specified for GPs and mis-specified for GARCH variants, so it is not surprising that GPs do well. For real data "We used GARCH(1,1), EGARCH(1,1) and GJR-GARCH(1,1,1) models since these variants have the least number of parameters and are consequently less affected by overfitting" It seems there was no attempt to regularize GARCH variants, or to choose the best level of complexity for them. Even so, the authors method performs best on only 58% of datasets.
The author of this review is an experienced professor at a research university and "data science" director in industry. My advice to the author(s) is to apply their strong technical skills to a broader problem, and/or a less theoretical application.
COMMENTS ON THE AUTHORS' RESPONSE
The response seems valid technically to me, so I have upgraded my numerical evaluation of the paper. I still believe that the paper is not of broad interest in machine learning. This reviewer has served on the PhD committee of students in econometrics. If this paper is of interest to that community, it should be published there. 
The authors say that higher-order GARCH models do no better than almost-trivial GARCH models. The GP method here does better, but not dramatically so. As a practitioner in applied finance, I say that all these models are better as mathematics than as descriptions of reality. The research area needs to go in a different direction, back from mathematical sophistication towards insight into facts. Too narrow a problem.