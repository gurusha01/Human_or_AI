This paper introduces Global Belief Recursive Neural Networks (GB-RNNs), a novel extension of feedforward recursive neural networks that incorporates a backward step to allow phrase-level predictions to feedback to word embeddings and labels. The model is well-motivated and described, with a key contribution being the introduction of hybrid word vectors, which combine unsupervised and supervised word vector representations. The experimental comparisons demonstrate the effectiveness of the GB-RNN on the task of contextual sentiment analysis, outperforming several baselines and achieving state-of-the-art performance on the SemEval 2013 challenge.
The paper is technically sound, with a clear and well-organized presentation of the model and its components. The use of hybrid word vectors is a significant contribution, as it allows the model to capture both task-specific and general semantic information. The experimental results are also well-presented, with a clear comparison to other models and baselines.
However, there are some areas for improvement. The term "belief propagation" is considered misleading, and the term "forward-backward" may be more suitable. Additionally, Section 3.5 on training is too short and lacks details, such as the use of back-propagation through structure algorithm and the unfolding of the recursive model. Section 3.6 is also confusing and requires clarification on the difference between the proposed model and the work of Irsoy and Cardie.
The paper could also benefit from a clearer presentation of the task and parser constraints in Section 4.1, to make it more accessible to readers outside the NLP community. Furthermore, Sections 4.3 and 4.4 could potentially be merged for better organization.
In terms of originality, the paper presents a novel combination of familiar techniques, extending the definition of recursive neural networks to include a backward step. The use of hybrid word vectors is also a significant contribution, as it allows the model to capture both task-specific and general semantic information.
The significance of the paper lies in its ability to address a difficult problem in NLP, namely contextual sentiment analysis. The results demonstrate that the GB-RNN can successfully make use of surrounding context to improve sentiment analysis, which has important implications for a range of NLP applications.
Overall, the paper is well-written and presents a significant contribution to the field of NLP. With some revisions to address the areas mentioned above, it has the potential to be a strong paper.
Arguments pro acceptance:
* The paper presents a novel and well-motivated extension of recursive neural networks
* The use of hybrid word vectors is a significant contribution
* The experimental results demonstrate the effectiveness of the GB-RNN on the task of contextual sentiment analysis
* The paper is well-organized and clearly presented
Arguments con acceptance:
* The term "belief propagation" is considered misleading
* Section 3.5 on training is too short and lacks details
* Section 3.6 is confusing and requires clarification
* The paper could benefit from a clearer presentation of the task and parser constraints in Section 4.1.