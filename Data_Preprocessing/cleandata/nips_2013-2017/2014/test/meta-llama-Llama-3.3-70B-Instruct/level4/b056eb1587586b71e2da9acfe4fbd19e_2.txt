This manuscript explores the challenge of action recognition in videos by leveraging two categories of attributes that describe actions as high-level concepts: Human Labeled Attributes (HLA) and Data Driven Attributes (DDA). The authors propose a methodology to identify a subset of attributes that are both discriminative and compact, achieved by integrating submodular objectives. These objectives promote discrimination via entropy rate-based attribute selection and coverage through weighted maximum coverage-based attribute selection. Experimental evaluations are conducted on the Olympic Sports and UCF101 datasets, which are recognized for their difficulty in action recognition, and the results are compared against a range of baselines and state-of-the-art approaches.
The paper is generally well-structured, with the exception of a few sections that require clarification. The problem addressed is significant, given its standard presence in computer vision, and the choice of datasets for experimentation is relevant and challenging. The formulation of the attribute selection problem as a weighted maximum coverage problem combined with entropy rate maximization for a random walk presents a novel and intriguing approach.
At its core, the paper tackles the feature selection problem by attempting to select a subset of attribute classifiers that perform well. However, feature selection is a well-established problem with numerous straightforward approaches, such as methods utilizing L1 regularization (e.g., lasso, L1 regularized hinge loss, elastic net). It would be beneficial for the authors to directly compare their method to these simpler approaches, rather than solely focusing on comparisons with other submodular selection methods.
Notably, state-of-the-art results from other studies significantly surpass the performance reported in this paper, largely due to the utilization of superior dense feature vectors (e.g., 90.2% on the Olympic dataset as reported in [34], and other numbers from Jiang et al. (ECCV 12), Jain et al. (CVPR 13), Gaidon et al. (BMVC 12) approaching 80%). It would be insightful to investigate whether the proposed attribute selection method enhances performance when combined with these dense features.
Given that this work proposes a general method for feature selection not specific to action classes, to fully demonstrate its potential, the authors should consider conducting experiments in other vision domains that also utilize attributes (as referenced in [11] for additional datasets).
There are several errors in the equations that need correction if the paper is to be published:
- The equation for \(A{d,l}\) in L129 lacks clarity. Specifically, the variables \(u^d\) and \(uk^d\) are undefined; presumably, these should be \(\mu\). Furthermore, the reference to the mean and standard deviation of a "class" in L127 is unclear.
- Similarly, in Eq. 2, \(ui\) should possibly be \(\mui\).
- In L161, the variable \(T\) needs to be defined.
The overall formulation of attribute selection using submodular objective functions to encourage the selection of discriminative attributes is both novel and interesting. While the authors address a standard feature selection problem, the experimental scope is limited to video action datasets, and there is a lack of comparison to state-of-the-art results that leverage better features than those used in the paper.