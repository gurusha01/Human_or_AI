This paper explores the decomposition of structured output objects into smaller components in the context of Structured Output prediction. The authors provide a theoretical framework demonstrating that this decomposition approach yields better generalization capabilities than traditional SO models. Specifically, in the case of Conditional Random Fields (CRFs), they show that optimization using Stochastic Gradient Descent (SGD) achieves faster convergence rates. The experimental results on sequence models across four different applications are impressive, with three out of four applications showing superior performance and one showing competitive performance compared to state-of-the-art systems.
The theoretical analysis of the decompositional approach is a refreshing contribution, as previous proposals have focused on algorithmic aspects without rigorous theoretical underpinnings. However, the provided bounds are relatively loose compared to existing analyses of SO prediction models for hinge-loss, such as those presented by Taskar et al. (Max-Margin Markov Networks, NIPS 2003) and McAllister (Generalization bounds and consistency for Structured Labeling, in Predicting Structured Data, 2006), where the generalization bound is log(l) versus l4 in this paper, with l being the size of the structured object. It is unclear how the analysis of the decompositional approach would translate to more informative analyses.
The experimental results are noteworthy, particularly for segmentation tasks like Named Entity Recognition (NER) and Word Segmentation, where consistent labeling is crucial. The figures suggest that simply considering bigram labels yields the best performance for CRFs in Chinese word segmentation (46.6/20) and NER (26.5/~10). The authors should clarify whether this interpretation is correct. Assuming the same decomposition algorithm is applied during testing, it is notable that the performance on the test data (Table 1) closely aligns with the best hyperparameter values in Figure 2, which were set based on development data. A discussion on these aspects would be beneficial.
The decomposition of the model is performed randomly for each instance (Algorithm 1), which naturally extends to sequence models. As sequence modeling remains a representative SO prediction problem, it would be interesting to see an informal discussion on the consequences of the random decomposition approach for models with clique sizes larger than 2. Overall, the paper presents a decompositional approach to SO prediction with theoretical analysis and strong empirical support, although the theoretical analysis could be more informative.