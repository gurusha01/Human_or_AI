This manuscript presents a novel approach to zero-shot learning, leveraging a random forest framework that effectively accounts for the uncertainty associated with attribute classifier predictions. The uncertainty is quantified by assessing the performance of attribute classifiers, including metrics such as true positive rate and false positive rate, on a validation set held out from the training data. The proposed method incorporates this performance information into the computation of information gain during the construction of the random forest, specifically when exploring multiple paths of a decision tree for a given category-attribute signature. This integration allows the model to accommodate the uncertainty inherent in attribute predictions.
Quality: The manuscript provides robust empirical and quantitative support for the proposed ideas. However, it would benefit from additional qualitative analysis, such as examining the specific types of attributes and categories that are most impacted or improved by this approach. Furthermore, the selection process for certain parameters, including the rationale behind the 80%-20% training-validation split, lacks clarity.
Clarity: The writing is clear and accessible, making the paper easy to follow.
Originality: Although previous research has primarily focused on "attribute strength," this work distinguishes itself by addressing the less explored issue of "attribute reliability." While many learning algorithms implicitly consider classifier unreliability, this paper's explicit handling of unreliability is a novel contribution.
Significance: While the random forest method itself is not new, the concept of modeling unreliability by measuring classifier performance on validation data to enhance zero-shot learning performance is intriguing and thought-provoking for researchers in the field of attributes. Although the idea and method presented are not groundbreaking in terms of novelty, their application to improving zero-shot learning yields interesting and revealing insights.