This manuscript is one of the pioneering studies to investigate best arm identification in bandit models where the arms are correlated. The authors focus on the fixed-confidence setting and introduce a novel complexity measure that accounts for the correlation between arms. They propose algorithms that nearly achieve this complexity, including both static allocation strategies, which do not depend on collected rewards, and an adaptive strategy.
However, it is essential to note that this work is not the first to address best arm identification in linear bandit problems. For instance, Hoffmann et al. (AISTATS 2014) explored a linear bandit model with Gaussian noise in the fixed-budget setting. Although their complexity term involves a sum of squared gaps over all arms, it does not fully capture the correlations induced by the linear structure.
The theoretical foundations of the paper rely on Propositions 1 and 2 in Section 2. Nevertheless, the statements of these results could be more precise, particularly regarding whether 'n' is fixed or not. Proposition 2, derived from [1], should be expressed as \(P(\forall n\in\N, (2) \text{ holds}) \geq 1-\delta\), while Proposition 1 should be stated as: for every 'n' and every fixed sequence \(x_n\), \(P((1) \text{ holds}) \geq 1-\delta\). This distinction is crucial because an additional union bound over 'n' might be necessary when applying Proposition 1, even with a static sampling rule, due to its adaptive nature. Furthermore, a precise reference for Proposition 1 should be provided.
To enhance clarity, the terminology used in the paper should be more precise. In the context of best arm identification under the fixed-confidence setting, algorithms comprise a sampling rule, a stopping rule, and implicitly, a recommendation rule that selects the best arm based on the current least-square estimate as if it were the true parameter. The "static and adaptive strategies" mentioned in the paper pertain only to the sampling strategy, as the stopping strategy in the G-allocation strategy is adaptive. The proof of Theorem 1 appears to be missing a union bound over 'n' (similar to the comment on Proposition 1), which would introduce an additional logarithmic term, such as \(\log(CK^2/t^2\delta)\) for some constant \(C\). Moreover, the term 'beta-approximation' in Theorem 1's statement is not defined, neither in the text nor in Lemmas 5 and 6.
Regarding the oracle discussion in Section 3, the presentation is somewhat confusing because having access to the parameter \(\theta^\) would essentially solve the problem. It seems the authors assume algorithms based on confidence intervals that stop when one interval is contained in \(C(x)\), and they investigate the optimal shape of these intervals for quick inclusion in \(C(x^)\). However, the definition of the oracle appears imprecise, as knowing \(\theta^*\) would render the problem trivial. Typically, complexity in best arm identification is derived from a lower bound on the number of samples used by any \(\delta\)-PAC algorithm, which is not explicitly provided here. This omission raises questions about the claim of characterizing the problem's complexity in the introduction.
The algorithms are constructed from allocation strategies rooted in experimental design theory, many of which are adapted from [16] and presented in Appendix B. These strategies are challenging to implement and require approximation, making it unclear what the overall numerical complexity of the proposed algorithm is and how it scales with different parameters.
The numerical experiments section is limited by only comparing the methods introduced in the paper. A more informative approach would include benchmarks against algorithms designed for best arm identification in classic (unstructured) bandit problems, such as LUCB or UGapE. This comparison is particularly relevant given the experimental setting, where the arms are orthogonal except for two, closely resembling the classic d-armed bandit model. Comments on the choice of this specific setting for simulations would also be valuable.
Minor comments include:
- Notational overlap in the paragraph "the setting," where \(\Delta\) is defined in two ways, which could be distinguished more clearly for the reader's convenience.
- A potential typo in Footnote 1, where "used of all direction y" might be more appropriately stated as "for all vector x."
- A formatting error in Line 232, where "inthe" should be separated.
- An inconsistency in the boxed environment of page 4 (Figure 2), where Eq. 24 should be referenced instead of Eq. 22 on the second line.
- Figures 2 and 3, which define the algorithms, refer to equations only found in the supplementary material, making the main paper not self-contained.
This manuscript tackles the challenging issue of best-arm identification in linear bandit models, offering novelty and insights from optimal design theory. However, it falls short in providing a generic notion of sample complexity and presents methods with potentially high complexity. The experimental results are also somewhat limited, suggesting areas for further development and comparison.