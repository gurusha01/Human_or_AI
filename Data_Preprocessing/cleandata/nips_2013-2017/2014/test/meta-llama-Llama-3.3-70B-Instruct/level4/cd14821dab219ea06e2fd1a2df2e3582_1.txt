This manuscript examines the weighted majority algorithm, deriving consistency results (i.e., the error rate of the aggregator approaching zero) under two distinct scenarios: (1) when the competence level (or risk) of each expert is known a priori, and (2) when this level is estimated. The estimation of competence levels is approached through both frequentist and Bayesian methodologies for the second scenario.
In the first scenario, consistency is demonstrated by providing upper and lower bounds on the aggregator's error rate, involving standard calculations with the notable exception of using a result by Kearns and Saul to establish the upper bound, rather than relying on Hoeffding's inequality. For the second scenario under a frequentist framework, an independent set of labeled inputs is utilized to estimate each expert's competence level, yielding two estimates (and corresponding analyses) dependent on the chosen confidence level. Under the Bayesian framework, while the proposed estimator is relatively standard, the analysis is left entirely as an open problem.
A significant issue with the paper is its lack of novelty. The estimators and analyses presented are grounded in standard tools, failing to contribute novel theoretical insights. From a practical standpoint, the requirement for labeled samples to estimate competence levels is a drawback, especially when compared to the Dawid-Skene method, which can estimate both competence levels and ground truth without labeled data (as also discussed in related works [1] and [2]). However, the problem addressed is highly relevant, particularly due to its applications in crowd-sourcing. A potential strength of the weighted majority method over the Dawid-Skene model is its absence of modeling assumptions. Therefore, a theoretical analysis comparing the conditions under which weighted majority outperforms the Dawid-Skene method would significantly enhance the paper's impact.
References:
[1] http://jmlr.org/papers/v11/donmez10a.html
[2] http://arxiv.org/abs/1310.5764
This paper explores the weighted majority algorithm, establishing consistency results. A key drawback is the lack of novel theoretical contribution or significant practical implications, highlighting the need for more innovative analysis or comparison with existing methods like the Dawid-Skene model to bolster its relevance and impact.