This paper introduces SAGA, a novel incremental gradient technique that boasts impressive performance on strongly convex problems, surpassing SAG and SVRG while closely matching SDCA's speed. A key advantage of SAGA is its ability to function without modification in non-strongly convex settings, eliminating the need for explicit regularization. However, it requires knowledge of the Lipschitz and strong convexity constants to achieve linear convergence, which may be a limitation in practice. Notably, SAGA only needs to tune a single step-size parameter, labeled as Î· in the paper, which simplifies its implementation.
The paper provides a clear explanation of SAGA in Section 3, accompanied by a concise summary of other popular methods, including SDCA. This comparative analysis is valuable, as it clarifies the connections between various incremental gradient techniques. For instance, the discussion on SDCA reveals a intriguing transformation that highlights its relationship to primal-based methods like MISOmu.
SAGA offers several improvements over existing methods, including enhanced analysis, the ability to handle prox operators, fewer parameters to tune, and automatic adaptation to non-strongly convex problems. To further strengthen the paper's main argument, it would be beneficial to demonstrate that adding a small regularizer and using alternative methods like SDCA does not yield a superior solution technique.
The paper is generally well-written, with only a few minor errors noted, such as the confusion between "effect" and "affect" on line 121 and a typographical error on line 298. The unified exposition of incremental gradient methods is a significant contribution, making the paper a useful resource. To enhance the paper's impact, the authors could provide a more explicit comparison with other algorithms, addressing questions like the difficulty of tuning multiple parameters and the performance benefits of SAGA in non-strongly convex settings compared to regularized methods.