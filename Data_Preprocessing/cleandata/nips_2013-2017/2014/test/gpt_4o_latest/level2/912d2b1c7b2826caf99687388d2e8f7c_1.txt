This paper addresses the structured low-rank matrix minimization problem by introducing a novel reformulation and leveraging the Generalized Conditional Gradient (GCG) method. The authors claim significant improvements in computational efficiency, achieving a per-iteration complexity of \(O(MN)\) and a convergence rate of \(O(1/\epsilon)\). They support these claims with theoretical analysis and empirical evaluations on stochastic system realization (SSR) and spectral compressed sensing (SCS) tasks, demonstrating both scalability and effectiveness.
Strengths:
1. Novelty and Originality: The reformulation of the structured rank minimization problem is innovative, particularly in its use of the penalty method to eliminate linear constraints and its adaptation of GCG to maintain low-rank factorization throughout iterations. This approach is a clear departure from existing methods that rely on full Singular Value Decomposition (SVD) or augmented Lagrangian techniques.
2. Efficiency: The proposed method achieves a significant reduction in computational cost compared to state-of-the-art methods, as evidenced by both theoretical complexity analysis and empirical results. The linear per-iteration complexity \(O(MN)\) is particularly compelling for large-scale problems.
3. Empirical Validation: The experiments on SSR and SCS are well-designed and demonstrate the practical utility of the method. The results show faster convergence, lower running times, and effective recovery of low-rank solutions, even for large problem sizes.
4. Clarity of Contributions: The paper clearly outlines its contributions, including the reformulation of the problem, the adaptation of GCG, and the empirical validation. The related work section is thorough, situating the paper within the broader literature.
Weaknesses:
1. Limited Discussion of Limitations: While the authors acknowledge that the penalty method introduces inexactness in satisfying the linear constraints, they do not provide a detailed analysis of the trade-offs or potential failure cases. For instance, how sensitive is the method to the choice of the penalty parameter \(\lambda\)?
2. Reproducibility: Although the paper provides a detailed algorithmic description, it lacks sufficient implementation details (e.g., parameter settings, initialization strategies) to ensure reproducibility. Providing a code repository or pseudocode for key subroutines would strengthen the paper.
3. Generality of Results: The empirical evaluations focus on two specific applications (SSR and SCS). While these are compelling, it remains unclear how well the method generalizes to other structured rank minimization problems, such as those involving more complex structures or constraints.
4. Comparison with Non-Convex Methods: The paper primarily compares its method to convex optimization approaches. However, non-convex methods, which have gained traction in recent years, are not discussed or benchmarked.
Recommendation:
I recommend acceptance of this paper, as it presents a significant advancement in structured rank minimization with strong theoretical and empirical support. However, I encourage the authors to address the identified weaknesses in the final version. Specifically, a more detailed discussion of limitations, improved reproducibility, and broader empirical evaluations would enhance the paper's impact.
Arguments Pro Acceptance:
- Novel and efficient approach with clear theoretical guarantees.
- Strong empirical results demonstrating practical utility.
- Well-situated within the existing literature.
Arguments Against Acceptance:
- Limited discussion of limitations and sensitivity to parameters.
- Lack of broader empirical evaluations and comparisons with non-convex methods.
In summary, this paper makes a valuable contribution to the field of optimization and structured matrix rank minimization, and it is likely to be of interest to both researchers and practitioners.