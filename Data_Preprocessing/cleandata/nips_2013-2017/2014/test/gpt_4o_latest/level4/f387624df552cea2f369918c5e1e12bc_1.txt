Problem definition: The paper investigates the problem of best-arm identification in linear bandits. In this setting, there exists an unknown hidden parameter \(\theta^ \in \mathbb{R}^d\) and a finite set of arms \(X \subseteq \mathbb{R}^d\). When an arm is pulled, the observed reward is \(x^T\theta^ + \epsilon\), where \(\epsilon\) is zero-mean i.i.d. noise with a bounded range. The objective is to identify \(\arg\max_{x \in X} x^T\theta^*\) using the fewest number of samples.
Results: The paper provides a characterization of the sample complexity for both static and dynamic allocation strategies aimed at identifying the best arm.
Quality of the paper: The techniques employed in the paper appear to be reasonably robust. However, the experiments section could be improved by including comparisons with existing algorithms for linear bandits. Specifically, it would be helpful to run existing algorithms for linear bandits until \(\hat{S} \subseteq C(x)\) and then count the number of steps required to achieve this. This comparison is particularly important because the paper highlights early on that, unlike in multi-armed bandits, the strategies for minimizing the sample complexity of best-arm identification in linear bandits may differ from those used for regret minimization.
Clarity of the paper: The paper is reasonably well-written and clear.
Significance: The paper addresses and provides a solution to a fairly general problem. While it does not emphasize potential applications, the problem appears to be abstract yet likely to have meaningful applications. Overall, the paper studies best-arm identification in linear bandits and characterizes the sample complexity of both static and dynamic allocation strategies for solving the problem.