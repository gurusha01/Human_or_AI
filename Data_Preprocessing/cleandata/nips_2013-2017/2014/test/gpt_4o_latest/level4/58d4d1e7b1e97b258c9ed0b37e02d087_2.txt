The manuscript addresses a critical issue in cognitive modeling: model identifiability. It is well-written and generally clear. However, the work relies on a substantial list of assumptions that readers must accept and interpret, and this list feels disproportionately extensive relative to the significance of the primary results presented. Nonetheless, the methodology is both innovative and intriguing, leading me to conclude that the work meets the threshold for presentation at NIPS.
Regarding the key results: In section 4.1, the interchangeability of sensory and motor noise was unsurprising (I anticipated the inclusion of both in the model while reading). It would be beneficial to clarify which condition differences are statistically reliable. (Perhaps I am misinterpreting the box plots.) In section 4.2, isn't it crucial to demonstrate that if the reference observer lacked a slow-speed prior, the model would still be able to recover this absence?
Specific comments:
- Line 106: Why is the stimulus drawn from a discrete distribution when it is inherently a continuous variable? I assume this choice reflects the typical design of experiments, where stimulus levels serve as independent variables. However, the authors might want to explicitly clarify this reasoning.
- Line 134: The log-stimulus transform (Equation 2) is, as the authors note, inspired by psychophysical laws. It seems that much of the success of this work hinges on the inclusion of this transform. In essence, the transform imposes a strong constraint on inference, suggesting that Bayesian models are identifiable under robust assumptions about representational transformations in the mind.
- Line 143: Do the constraints in Equation 4 and the maximization of differential entropy ensure that Equation 3 results in a unimodal distribution? It seems plausible that the fit could, in principle, yield a bimodal distribution.
- Line 158: Why does the observer's prior favor a lattice representation over a uniform one? What knowledge does the observer possess about the true stimulus distribution that enables them to adopt a prior that is 50% wider than the actual range?
- Figure 1: Despite careful examination, I find the figure more confusing than informative. It might be clearer if Figure 1b were integrated into Figure 1a, and if \(p_{\text{est}}(s^*|x)\) were removed, as it is a derived inference.
- Line 252: Could the authors elaborate on the conditions for \(N\) under which Equation 14 holds approximately true? Specifically, when does Stirling's approximation of the factorial apply, and under what circumstances does \(E[x\log x] \approx E[x]\log E[x]\)? By the time the authors introduce Equation 15—having discarded priors on \(\theta\) and made some debatable approximations—it seems that Equation 15 is justified primarily because it produces an intuitive rule for evaluating prediction similarity.
- Line 262: The phrase "sample from this unnormalized density" is unclear. Which density is being referred to here? The dataset distribution?
- Line 365: Why is the learning of priors deemed irrelevant in the 2AFC task? This is an innovative approach to an important problem, but the results are less compelling than one might hope.