This significant paper proposes an incremental gradient method named SAGA for minimizing \( f + h \), where \( f \) is expressed as an average of \( n \) functions \( fi \) (e.g., in the context of empirical risk minimization, ERM), and \( h \) is a potentially non-smooth regularizer for which a proximal operator is known. The method achieves provable linear convergence rates when \( f \) (or each \( fi \), depending on the scenario) is strongly convex. Furthermore, the same algorithm, without modification, exhibits a \( 1/k \) convergence rate in the absence of strong convexity, thereby automatically adapting to the level of strong convexity in the problem and seamlessly interpolating between these rates.
A key contribution of the paper lies in its exploration of the connections between a wide range of existing algorithms designed for similar problems, such as SAG (which lacked provable handling of proximal operators and was not adaptive to strong convexity), SDCA (developed over the past few years), and more recent methods like MISO and SVRG. While the relationship to SAG is relatively straightforward (as suggested by the name SAGA), the connections to MISO, SVRG, and especially SDCA are particularly intriguing. 
One of the standout aspects of this work is its ability to provide clear, verbal explanations of why the proposed method performs well and how it relates to other algorithms. Notably, the use of a biased gradient in SAGA, unlike SAG, leads to reduced variance, which is an interesting insight. The comparison to SVRG is also noteworthy, as SVRG trades off computational cost for memory usage by not frequently storing and updating the \(\phi\) vectors. The relationship to MISO/Finito is less direct but equally compelling. Additionally, the paper's approach to viewing the SDCA algorithm in the primal space is independently valuable, as it is not immediately obvious that these algorithms are related. Rewriting SDCA in the same form as MISO is particularly thought-provoking.
The primary contribution of the paper is its simple and transparent convergence proofs (especially in comparison to SAG) for both the strongly convex and non-strongly convex cases, which are presented in the appendix. These proofs not only enhance the understanding of the proposed algorithm but also provide a foundation for designing new methods. The adaptivity of SAGA to the presence or absence of strong convexity makes it practically very useful, particularly in scenarios where the strong convexity constant is unknown.
Given the importance of these types of problems in machine learning (e.g., ERM with regularizers, with or without strong convexity) and the thorough comparison to existing methods, I believe this paper is highly relevant to a broad audience within the community. While optimization researchers may focus on the theoretical proofs, the practical applicability of the method makes it valuable to practitioners as well.
Potential typos: It appears that the "s" in several places (e.g., in the description of MISO and the proof of Lemma 1) should instead be "Î¼". Additionally, in the appendix, "manor" should be corrected to "manner." Overall, this paper presents a novel algorithm for minimizing finite sums with regularizers (adaptive to potentially non-strongly convex settings), accompanied by clear convergence proofs and insightful comparisons to existing literature. I consider this an important contribution that will appeal to both theoreticians and practitioners. I commend the authors for their effort in relating the proposed method to existing algorithms and presenting the proofs in an accessible manner. I strongly recommend this paper for acceptance.