This paper tackles the challenge of action recognition in video by encoding actions using two types of attributes that represent high-level concepts: 1) Human Labeled Attributes (HLA) and 2) Data Driven Attributes (DDA). The authors propose a novel method for selecting a subset of attributes that are both discriminative and compact by combining submodular objectives. These objectives promote discrimination via entropy rate-based attribute selection and ensure coverage through weighted maximum coverage-based attribute selection. The authors validate their approach through experiments on the Olympic Sports and UCF101 datasets, which are known to be challenging for action recognition, and compare their results against a range of baselines and state-of-the-art methods.
The paper is generally well written, though certain sections could benefit from further refinement. The problem addressed is significant, as action recognition is a standard challenge in computer vision, and the experiments are conducted on relevant and difficult datasets. The proposed formulation of the attribute selection problem as a combination of weighted maximum coverage and entropy rate maximization for a random walk is both novel and compelling.
The primary focus of this paper appears to be feature selection, as the authors aim to identify a subset of attribute classifiers that perform effectively. However, feature selection is a well-studied problem, and there exist simpler and widely used approaches, such as L1 regularization techniques like lasso, L1 regularized hinge loss, and elastic net. The authors are encouraged to include direct comparisons to these simpler methods, rather than limiting their comparisons to other submodular selection techniques.
The state-of-the-art results reported in other works are significantly higher, largely due to the use of superior dense feature vectors (e.g., 90.2% on the Olympic dataset as reported in [34], with other works such as Jiang et al. (ECCV 12), Jain et al. (CVPR 13), and Gaidon et al. (BMVC 12) reporting results close to 80%). It would be insightful to evaluate whether the proposed attribute selection method can enhance performance when combined with these more advanced dense features.
Additionally, the proposed method is general and not specific to action recognition. To fully demonstrate its potential, the authors are encouraged to conduct experiments in other vision domains that utilize attributes (e.g., datasets referenced in [11]).
There are also a few errors in the equations that should be addressed if the paper is accepted for publication:
- The equation for \( A{d,l} \) in L129 is unclear. What do \( u^d \) and \( uk^d \) represent in this equation? Are these intended to be \( \mu \)? Additionally, what do the mean and standard deviation of a "class" refer to in L127?
- In Eq. 2, \( ui \) should likely be \( \mui \).
- In L161, the variable \( T \) needs to be defined.
Overall, the formulation of attribute selection using submodular objective functions to encourage the selection of discriminative attributes is innovative and interesting. While the authors address a standard feature selection problem, the experiments are restricted to video action datasets, and the paper does not compare its results to state-of-the-art methods that leverage superior feature representations.