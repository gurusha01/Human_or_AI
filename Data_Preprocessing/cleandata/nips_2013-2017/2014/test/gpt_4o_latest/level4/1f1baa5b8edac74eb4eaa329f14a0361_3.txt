This paper introduces a method for attribute-based zero-shot learning leveraging random forests. Initially, attribute classifiers are trained using SVMs. A random forest is then trained on class-attribute signature vectors, with a validation set of images annotated with attribute labels being used to estimate attribute reliability at each tree node. Additionally, the paper proposes an extension to few-shot learning.
Clarity: The paper is well-written and clearly presented. It provides a concise and effective summary of related work.
Originality: While the novelty of the paper is moderate, it is sufficient for acceptance. However, the claim that the proposed method uniquely addresses unreliable attribute predictions, unlike prior work, seems somewhat exaggerated or misleading. For instance, direct attribute prediction [7] (DAP), which serves as a baseline in this paper and others, also incorporates mechanisms to handle attribute uncertainty. Both approaches share a common framework:  
a) Attribute classifiers are trained on image features (identical in both methods).  
b) A second-stage class probability estimator is trained as a function of attribute predictions, using a validation set to account for attribute reliability ([6] employs Platt scaling and a probabilistic model, while the proposed method introduces a random forest-based approach).
Thus, the proposed method does not represent a fundamentally new way of addressing attribute uncertainty. Instead, it enhances prior work by employing a more sophisticated model for handling attribute noise: (1) it uses an ROC-based reliability estimate rather than a sigmoidal model like Platt scaling, and (2) it accounts for joint attribute error statistics, as the validation set is propagated through the decision trees, unlike [6], which assumes attribute independence. Therefore, it might be more accurate to frame the contribution as an improved method for modeling attribute correlations. (For reference, Scheirer et al., "Multi-Attribute Spaces: Calibration for Attribute Fusion and Similarity Search," might be a relevant citation.)
One potential limitation of the proposed approach, compared to methods that treat attributes independently, is its reliance on a large validation set to produce reliable probability estimates, as the validation data is subdivided when propagated through the trees. This issue is not thoroughly addressed in the paper, and the proposed solution (line 323) appears heuristic. Additional experiments exploring the impact of training and validation set sizes would have strengthened the paper.
Quality: Overall, the paper is of good quality, with reasonable technical choices and clear descriptions. The experiments are appropriate and support the paper's claims, though the level of quantitative improvement is not substantial enough to justify acceptance based solely on empirical results. The extension to few-shot learning (Section 3.3) feels less developed compared to the rest of the paper. While the main sections are detailed and well-explained, this part is brief and less intuitive. For instance, a method that combines class-attribute priors with image attribute estimates for p(a|...) might seem more natural than the weighted combination of information gains (Eq. 6).  
In conclusion, this is a well-written paper with sound technical decisions and adequate experiments. However, the primary claim of introducing a novel approach to handling unreliable attributes is somewhat debatable.