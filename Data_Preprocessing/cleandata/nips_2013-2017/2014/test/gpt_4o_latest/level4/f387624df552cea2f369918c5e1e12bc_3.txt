The paper addresses the pure exploration variant of linear bandits. In this setting, the input comprises K vectors of d dimensions. The player can query these vectors to receive a sample from a distribution whose mean is a fixed linear function of the vector. The goal is to identify the arm with the maximum value with high probability (w.h.p) while minimizing the number of queries.
The authors propose a solution grounded in the experiment design framework. They introduce two static allocation strategies, which are non-adaptive methods for querying the arms, independent of the outcomes of previous queries. These strategies yield results analogous to those of the uniform strategy in the classical best arm identification problem. Additionally, the authors propose a dynamic strategy that achieves a provable performance improvement over the static strategies in certain scenarios. Beyond these contributions, they also present a problem-dependent optimal strategy that aligns with the optimality of the classical best arm identification problem.
The main body of the paper is generally well-written. While some proofs in the appendix could benefit from additional details, they appear to be correct based on my verification. The problem studied is compelling, and the paper provides a thorough theoretical analysis. However, the experimental section is somewhat lacking. The result for the adaptive sampling technique is relatively weak, as its advantage over static methods is demonstrated only in a narrowly defined scenario where, among other conditions, identifying the second-best arm is significantly easier than identifying the best arm. This raises an intriguing question: is the adaptive strategy truly superior to static methods only in this restricted setting, or does its advantage extend to other scenarios as well? While proving such a statement might be challenging, experiments should be designed to explore this question. Instead, the current experiments focus on a carefully constructed example that satisfies the conditions under which the adaptive algorithm is provably superior.
Comments / typos:
- Proposition 1: The phrasing should be "w.p. 1-\delta, for all x \in â€¦" rather than the reverse.
- Line 101: Use a lowercase k for D^k instead of an uppercase K.
- Equations 3, 4, 5: The term inside the logarithm appears to be K/\delta rather than K^2/\delta.
- Given the optimal strategy, deriving a lower bound for the sample complexity seems relatively straightforward.
- In Lemma 2, H_LB is bounded both above and below. It would be insightful to examine how closely it aligns with these bounds for specific example datasets.
- Theorem 1: The term N^G should be explicitly defined.
- Line 269: The comment following Theorem 2 is too vague. It seems that some expressions, such as "NG < ExpressionG < the given bound" and "NXY < ExpressionXY < the given bound," are missing, as the provided bounds are identical.
- Line 352: A space is missing.
- Section B: Would it not be simpler to sample directly from the strategy provided by the convex program? The matrix Chernoff bounds could ensure (w.h.p) that the sample converges appropriately.
- Proof of Lemma 6: Theorem 2.6 from the referenced paper does not necessarily apply to D-optimal design. Additionally, a reference is needed to support the claim that G- and D-optimal designs are equivalent, even approximately (since the D-optimal problem is only approximated by the greedy strategy).
- Equation 30: The inequality should be <, not \leq.
- Line 753: The condition should be n_j > M^*.
Overall, I recommend accepting the paper, as the problem is interesting and the theoretical analysis is both solid and comprehensive. However, the paper could be improved by including more meaningful experiments, either on real-world data or on more realistic synthetic datasets.