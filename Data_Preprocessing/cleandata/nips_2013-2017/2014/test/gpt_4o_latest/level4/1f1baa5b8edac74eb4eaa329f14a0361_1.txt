The paper aims to address the gap between the theoretical and practical aspects of attribute-based zero-shot learning. While the theory suggests that novel classes can be identified using pre-trained attribute predictors, the practical challenge lies in the fact that training these attribute classifiers can be as complex, if not more so, than directly learning the object classes.
The proposed approach leverages random forests to predict unseen classes from attribute vectors. The training process incorporates the reliability of the attribute detectors by propagating a validation set through each decision tree during training. Additionally, the authors demonstrate how the method can be adapted to accommodate scenarios with limited training examples for test categories. The approach achieves state-of-the-art performance on multiple attribute datasets.
QUALITY: The authors effectively tackle a core challenge in zero-shot learning by employing a random forest framework. The proposed model is both elegant and theoretically robust. The results on three standard datasets are compelling. The authors also provide thorough ablation studies, introduce artificial noise, evaluate both zero-shot and few-shot learning settings, and compare their approach with existing literature.
CLARITY: The paper is well-written and clear overall. However, there is some ambiguity in Section 3.2.1 regarding the threshold \( t \). When \( t \) is introduced, the attribute signatures remain binary, so any value \( 0 < t < 1 \) does not seem to affect equation (2). Consequently, it is unclear in lines 207-212 how a novel test example is propagated through the tree, as \( t \) appears to lack a precise definition. This issue is later clarified in subsequent sections.
ORIGINALITY: The paper presents an innovative application of a random forest framework to a critical problem in zero-shot learning.
SIGNIFICANCE: The work addresses a fundamental challenge in zero-shot learning. The paper is robust, engaging, and well-founded. The results across three datasets, evaluated under diverse settings, are highly convincing. This paper merits publication.