The paper presents a novel approach to zero-shot learning (ZSL) using random forests, which explicitly accounts for the unreliability of attribute predictions. By leveraging ROC-based estimates and modeling joint attribute error statistics, the method improves robustness in ZSL scenarios. The authors also propose an extension to few-shot learning, though this aspect is less developed compared to the primary ZSL framework. The paper is well-written, clearly organized, and provides a comprehensive review of related work, situating the proposed method within the broader ZSL literature.
Strengths:
1. Methodological Contribution: The use of random forests to model attribute unreliability is a notable advancement. The incorporation of ROC-based estimates and fractional propagation of attribute signatures is a key innovation, addressing a critical limitation in existing ZSL methods.
2. Clarity and Writing: The paper is well-structured, with clear explanations of the methodology and its relationship to prior work. The inclusion of detailed experimental setups and ablation studies enhances reproducibility.
3. Experimental Validation: The experiments on three datasets (AwA, aPY, and SUN) demonstrate the method's effectiveness, particularly in scenarios with noisy attribute predictions. The controlled noise experiments further validate the robustness of the approach.
4. Significance: The method addresses a practical challenge in ZSL—unreliable attribute predictions—making it a valuable contribution to the field. The few-shot extension, though underdeveloped, hints at the method's adaptability to related learning paradigms.
Weaknesses:
1. Few-Shot Learning Extension: The few-shot learning component is less polished and lacks sufficient detail. The integration of class-attribute priors and image attribute estimates could benefit from a more intuitive and theoretically grounded approach.
2. Validation Set Dependency: The method relies heavily on a large validation set to estimate attribute reliability, which may not always be feasible in real-world applications. This limitation is not thoroughly addressed in the paper.
3. Marginal Quantitative Gains: While the method outperforms baselines like DAP, the quantitative improvements are not substantial enough to claim a paradigm shift. The gains are more pronounced in scenarios with high attribute noise, but less so in ideal conditions.
4. Originality: The novelty is moderate, as the approach builds on existing methods like DAP and introduces complexity to handle attribute noise. While the ROC-based modeling is innovative, it may not constitute a fundamentally new direction in ZSL.
Arguments for Acceptance:
- The paper addresses a critical limitation in ZSL and proposes a well-motivated solution.
- The methodological contributions are supported by rigorous experiments and ablation studies.
- The writing is clear, making the paper accessible to a broad audience.
Arguments Against Acceptance:
- The few-shot learning extension is underdeveloped and lacks clarity.
- The reliance on a large validation set may limit the method's practical applicability.
- The quantitative improvements, while consistent, are not groundbreaking.
Recommendation:
Overall, the paper is a solid contribution to the ZSL literature, with a well-executed methodology and clear experimental validation. However, the few-shot extension and practical limitations warrant further refinement. I recommend acceptance with minor revisions, focusing on elaborating the few-shot extension and addressing the validation set dependency.