This paper introduces SAGA, a novel incremental gradient optimization method that builds upon and improves the theoretical foundations of existing methods such as SAG, SVRG, and SDCA. The authors demonstrate that SAGA achieves provably faster convergence rates than SAG and SVRG on strongly convex problems, while approaching the performance of SDCA. A key strength of SAGA is its ability to handle non-strongly convex problems without requiring explicit regularization, which sets it apart from SDCA. Additionally, SAGA requires tuning only a single step-size parameter and utilizes knowledge of Lipschitz and strong convexity constants to achieve linear convergence. The paper also provides a unified exposition of incremental gradient methods, highlighting connections between SDCA and primal-based methods like MISOmu, which is a valuable contribution to the field.
The paper is technically sound, with claims supported by rigorous theoretical analysis and experimental validation. The theoretical results are well-articulated, particularly the convergence guarantees for both strongly convex and non-strongly convex settings. The experiments on datasets such as MNIST and MILLIONSONG effectively validate the practical utility of SAGA, showing competitive performance compared to other methods. However, a clearer comparison of SAGA's performance with SDCA when a small regularizer is added would strengthen the experimental section.
The paper is well-written and organized, with Section 3 providing an insightful summary of related methods and their interconnections. The authors' explanation of SAGA as a midpoint between SAG and SVRG is particularly illuminating. However, minor errors on lines 121 and 298 should be corrected, and stronger differentiation from other algorithms, such as the practical implications of tuning one parameter versus two, would enhance the clarity of the paper's contributions.
In terms of originality, SAGA's ability to handle non-strongly convex problems without modification and its improved theoretical analysis represent significant advancements over prior work. The paper also provides a novel perspective by unifying existing methods and offering a primal interpretation of SDCA.
The significance of this work is high, as SAGA addresses practical challenges such as parameter tuning and regularization while advancing the theoretical understanding of incremental gradient methods. Researchers and practitioners are likely to adopt and build upon SAGA due to its simplicity, robustness, and versatility.
Pros:
1. Improved theoretical convergence rates over SAG and SVRG.
2. Automatic handling of non-strongly convex problems.
3. Unified exposition of related methods, clarifying their connections.
4. Fewer tunable parameters, enhancing practical usability.
Cons:
1. Lack of detailed comparison with SDCA when adding a small regularizer.
2. Minor errors and insufficient emphasis on practical differentiation from other methods.
Overall, this paper makes a strong scientific contribution and is well-suited for publication after addressing the noted weaknesses.