The paper introduces Global Belief Recursive Neural Networks (GB-RNNs), an extension of standard Recursive Neural Networks (RNNs) designed to address context-dependent sentiment classification. By incorporating a feedbackward step during inference, GB-RNNs allow phrase-level predictions to influence word-level representations, enabling the model to capture global sentence context. The authors demonstrate the effectiveness of GB-RNNs on the SemEval 2013 Task 2 dataset, achieving state-of-the-art results and outperforming both standard RNNs and the competition's winning system. The paper also explores hybrid word vector representations, combining unsupervised and supervised embeddings, and applies dropout to improve training.
Strengths:  
The paper is well-written and organized, providing a clear explanation of the GB-RNN architecture and its motivation. The proposed feedbackward step is an interesting extension to standard RNNs, and the hybrid word vector approach is a practical contribution that may generalize to other tasks. The authors demonstrate empirical improvements over strong baselines, including the SemEval 2013 competition winner, and provide detailed ablation studies to validate their design choices. The inclusion of additional training data and the two-step training process for context-specific sentiment classification are thoughtful enhancements.
Weaknesses:  
The paper's primary weakness lies in its evaluation methodology. The details of model tuning, ensemble composition, and benchmark comparisons are unclear, making it difficult to assess the robustness of the results. The use of ensemble models obfuscates the contributions of the GB-RNN itself, as it is unclear how much of the performance gain is attributable to the ensemble versus the core model. Additionally, the term "belief propagation" is misleading in this context, as it is traditionally associated with probabilistic graphical models and may confuse readers. The reliance on an off-the-shelf parser for tweets raises concerns about parsing accuracy on noisy social media text, which is not adequately addressed. Furthermore, the motivation for the feedbackward step lacks theoretical justification, and the incomplete citations (e.g., Irsoy and Cardie) detract from the paper's scholarly rigor.
Pro and Con Arguments for Acceptance:  
Pro:  
- The GB-RNN introduces a novel feedbackward mechanism that improves context-dependent sentiment classification.  
- The hybrid word vector approach and dropout application are practical contributions.  
- Empirical results demonstrate state-of-the-art performance on a benchmark dataset.  
Con:  
- The evaluation methodology is unclear, and the use of ensembles complicates the interpretation of results.  
- Theoretical motivation for the feedbackward step is weak, and the term "belief propagation" is misleading.  
- Concerns about the accuracy of the off-the-shelf parser and incomplete citations reduce the paper's overall quality.  
Recommendation:  
While the paper presents an interesting idea and achieves strong empirical results, the unclear evaluation methodology, lack of theoretical justification, and reliance on ensembles weaken its scientific contribution. I recommend acceptance only if the authors address these concerns in a revision.