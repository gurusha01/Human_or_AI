The paper presents a reinforcement learning-based recommendation algorithm, COLLABORATIVE-GREEDY, which addresses the challenge of balancing exploration and exploitation in online recommendation systems. The authors provide a theoretical framework to analyze its performance, a notable contribution given the limited theoretical work in this domain. The algorithm employs two types of exploration—random exploration for item discovery and joint exploration for learning user similarities—alongside cosine similarity for exploitation. Theoretical guarantees demonstrate near-optimal performance after an initial learning phase, with experimental results validating its superiority over existing methods on simulated datasets.
Strengths:
1. Theoretical Contribution: The paper addresses a critical gap in the theoretical understanding of online recommendation systems, particularly for collaborative filtering. The theoretical guarantees, under reasonable assumptions, are a significant contribution to the field.
2. Novel Exploration Strategy: The introduction of joint exploration to uncover user similarities is innovative and provides a fresh perspective on balancing exploration and exploitation.
3. Experimental Validation: The algorithm outperforms established methods like Popularity Amongst Friends (PAF) and Deshpande-Montanari (DM) on simulated datasets, demonstrating its practical utility.
4. Clarity of Assumptions: The paper clearly outlines its assumptions, such as user clustering and separability of likable items, which aids in understanding the scope and limitations of the results.
Weaknesses:
1. Unutilized User/Item Grouping: While the theoretical analysis relies on user clustering, the algorithm does not explicitly leverage this grouping in its recommendation process, potentially missing opportunities for further optimization.
2. Overlapping Clusters: The framework assumes distinct user clusters, which limits its applicability in real-world scenarios where user preferences often overlap. Recent bottom-up clustering methods could address this limitation.
3. Parameter Choice: The specific choice of \(\alpha = 4/7\) in Algorithm 1 is not well-justified, leaving room for questions about its optimality and generalizability.
4. Lack of Empirical Evidence for Thresholds: Definitions of \(\epsilonR(n)\) and \(\epsilonJ(t)\) are not empirically validated against constant thresholds, and the exploration of optimal \(\alpha\) is absent.
5. Experimental Limitations: The experiments are conducted on dense subsets of datasets, which may not reflect the sparsity and diversity of real-world recommendation systems. Additionally, the lack of interactivity in the datasets limits the realism of the evaluation.
Minor Issues:
1. Figure Presentation: Lines in Figure 1(b) are indistinguishable in black-and-white prints. Adjusting line shapes or patterns would improve accessibility.
2. Typographical Errors: Minor errors in lines 413 and 419 should be corrected for clarity.
Recommendation:
The paper makes a valuable contribution to the theoretical understanding of online recommendation systems and proposes a simple yet effective algorithm. Despite some limitations, its strengths outweigh its weaknesses, and the work is well-aligned with the scope of NeurIPS. I recommend the paper for acceptance, with minor revisions to address the noted issues.