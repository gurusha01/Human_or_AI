This paper presents a novel face verification method, DeepID2, which employs deep convolutional neural networks (CNNs) with dual objectives: face identification and verification. The method uses a landmark-based multi-scale approach to extract complementary features from different facial regions, achieving state-of-the-art performance on the LFW dataset with a 99.15% accuracy. The authors argue that combining identification and verification signals effectively increases inter-personal variations while reducing intra-personal variations, addressing a core challenge in face recognition.
Strengths:
1. Technical Quality: The paper is technically sound, with well-designed experiments that demonstrate the effectiveness of the proposed method. The dual-objective training strategy is convincingly shown to outperform single-objective approaches, and the results are supported by extensive quantitative evaluations.
2. State-of-the-Art Performance: Achieving 99.15% accuracy on LFW is a significant improvement over prior methods, reducing the error rate by 67% compared to the best previous deep learning result. This demonstrates the practical impact of the proposed approach.
3. Novelty and Contribution: While the method builds on prior work (e.g., DeepID), it introduces key innovations, such as the combination of identification and verification signals and the landmark-based multi-scale patch selection. These contributions are well-motivated and represent a meaningful advancement in face verification research.
4. Clarity: The paper is generally well-written and organized, providing sufficient details about the network architecture, loss functions, and experimental setup to allow reproducibility.
Weaknesses:
1. Comparison with Prior Work: While the paper builds on [18], the differences in training objectives and patch selection are not discussed in sufficient depth. A more detailed comparison would help clarify the novelty of the proposed approach.
2. Explanation of Training Margin: The margin parameter in the verification loss function is updated dynamically, but the rationale and impact of this design choice are not thoroughly explained. This could leave readers unclear about its significance.
3. Dataset Limitation: The evaluation is limited to LFW, which, while widely used, is not the most challenging dataset for face verification. Testing on a more difficult dataset, such as YouTube Faces, would strengthen the paper's claims of generalizability.
4. Inconsistent Presentation of Results: Some figures and tables lack consistent formatting, making it harder to interpret results at a glance. For example, the presentation of accuracy improvements across different configurations could be more streamlined.
Recommendation:
This paper is a strong candidate for acceptance due to its technical rigor, state-of-the-art performance, and meaningful contributions to face verification research. However, the authors should address the noted weaknesses to further strengthen the paper. Specifically, they should provide a more detailed comparison with [18], clarify the role of the training margin, and consider evaluating on a more challenging dataset. Additionally, improving the consistency of figures and tables would enhance readability.
Arguments for Acceptance:
- Significant improvement in face verification accuracy.
- Novel combination of identification and verification objectives.
- Well-designed experiments with clear technical contributions.
Arguments Against Acceptance:
- Limited evaluation on a single dataset.
- Insufficient discussion of differences with prior work.
- Lack of clarity on certain design choices (e.g., training margin).
Overall, the paper is a valuable contribution to the field and is recommended for acceptance with minor revisions.