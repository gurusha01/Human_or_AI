This paper addresses an important theoretical issue in cognitive science by proposing a framework to systematically evaluate the identifiability of Bayesian observer models. The authors focus on a long-standing challenge in Bayesian Decision Theory: the intrinsic degeneracy of Bayesian models, where multiple combinations of priors, likelihoods, and loss functions can produce indistinguishable behavioral data. The framework is applied to two behavioral studies—time interval estimation and motion perception—demonstrating its utility in identifying experimental designs that mitigate parameter degeneracy. This work has practical implications for improving experimental design and advancing our understanding of how internal representations can be reliably inferred from behavioral data.
Strengths:  
The paper tackles a critical issue in Bayesian modeling, offering a novel and systematic approach to assess identifiability. The framework is well-motivated and grounded in theoretical analysis, and its application to two distinct case studies demonstrates its versatility. The authors provide detailed mathematical formulations and computational techniques, which are essential for reproducibility. The results are insightful, particularly in showing how experimental design choices, such as fixing motor noise parameters or avoiding overly narrow loss functions, can significantly affect the reliability of inferred priors. The analysis of speed perception further validates prior empirical findings, adding robustness to the framework's claims.
Weaknesses:  
Despite its strengths, the paper has notable shortcomings. First, it overlooks significant prior work on model comparison in cognitive science, which limits the ability to contextualize its contributions. For instance, the authors could have engaged more deeply with existing methods for addressing model degeneracy, such as hierarchical Bayesian approaches or alternative identifiability metrics. Second, some assumptions in the framework, such as the parametric forms of priors and loss functions, appear arbitrary and lack sufficient justification or discussion. This raises concerns about the generalizability of the results to other experimental contexts. Additionally, the mathematical claims, while detailed, are occasionally unclear, and the figures suffer from ambiguous annotations, which may hinder comprehension for readers unfamiliar with the domain.
Pro and Con Arguments for Acceptance:  
Pros:  
- Addresses a critical theoretical issue with practical implications for experimental design.  
- Proposes a novel and systematic framework with clear computational methods.  
- Demonstrates versatility through applications to two distinct behavioral studies.  
- Provides valuable insights into the effects of experimental design on parameter identifiability.  
Cons:  
- Insufficient engagement with prior literature on model comparison and identifiability.  
- Some assumptions lack justification, potentially limiting generalizability.  
- Minor clarity issues in mathematical exposition and figure annotations.  
Conclusion:  
Overall, this paper is a well-written and significant contribution to the field of Bayesian modeling in cognitive science. However, it would benefit from better integration with prior work and a more thorough justification of its assumptions. I recommend acceptance with minor revisions to address these concerns.