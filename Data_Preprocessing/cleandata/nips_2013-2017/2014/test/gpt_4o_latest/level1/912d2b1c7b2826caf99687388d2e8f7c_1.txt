The paper addresses the problem of structured low-rank matrix recovery using nuclear norm regularization, a topic of significant interest in machine learning, control theory, and signal processing. The authors propose a novel reformulation of the optimization problem that avoids computationally expensive operations such as full singular value decomposition (SVD) and augmented Lagrangian techniques. Instead, they adapt the Generalized Conditional Gradient (GCG) method to solve the problem efficiently, achieving a per-iteration complexity of \(O(MN)\), which is substantially lower than existing methods. The paper demonstrates the effectiveness of the proposed approach through experiments on two applications: stochastic system realization (SSR) and spectral compressed sensing (SCS), showing significant improvements in computational efficiency and scalability.
Strengths:
1. Technical Contribution: The reformulation of the structured rank minimization problem and the adaptation of the GCG method are well-motivated and innovative. The authors achieve a significant reduction in computational complexity compared to state-of-the-art methods, which is a notable advancement for large-scale problems.
2. Empirical Validation: The experimental results convincingly demonstrate the practical benefits of the proposed method. The authors show that their approach not only outperforms competitors in terms of running time but also effectively recovers low-rank solutions in real-world applications.
3. Clarity of Presentation: The paper is well-organized, with a clear explanation of the problem formulation, algorithmic details, and theoretical guarantees. The convergence analysis is rigorous, and the empirical results are presented with sufficient detail to support the claims.
4. Broader Applicability: The method's applicability to diverse problems, such as SSR and SCS, highlights its versatility and potential impact on various domains.
Weaknesses:
1. Novelty of GCG Adaptation: While the adaptation of GCG is effective, the novelty of this contribution could be questioned, as GCG has been applied to related problems in prior work (e.g., Zhang et al. [27]). The paper could benefit from a more detailed discussion of how this adaptation specifically advances the state of the art.
2. Limited Comparisons: The experimental comparisons focus primarily on first-order methods from Fazel et al. [11]. Including additional baselines, such as recent nonconvex approaches or other scalable methods, would strengthen the empirical evaluation.
3. Penalty Parameter: The use of a penalty parameter to handle linear constraints raises concerns about sensitivity and tuning. While the authors argue that this trade-off is worthwhile, more discussion or experiments on the robustness of the method to different parameter settings would be valuable.
4. Reproducibility: Although the paper provides a detailed algorithmic description, the absence of code or pseudo-code for key subroutines, such as the Lanczos algorithm for leading singular vector computation, may hinder reproducibility.
Arguments for Acceptance:
- The paper addresses a challenging and important problem with a novel and computationally efficient approach.
- The theoretical and empirical results convincingly demonstrate the advantages of the proposed method.
- The work has broad applicability and potential impact on multiple fields.
Arguments Against Acceptance:
- The novelty of the GCG adaptation could be more explicitly highlighted.
- The experimental evaluation could include a wider range of baselines and robustness analyses.
Recommendation:
Overall, this paper makes a strong contribution to the field of structured low-rank matrix recovery. While there are minor areas for improvement, the strengths of the work outweigh the weaknesses. I recommend acceptance, with suggestions to address the aforementioned concerns in the final version.