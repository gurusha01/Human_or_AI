Obtaining fast rates of convergence has been a very dynamic field of research these past years, and most of the contributions have been made in the case of bounded loss functions. This paper addresses unbounded loss functions and still derives fast learning rates, at the (mild) price of a multi-scale Bernstein's condition and the existence of the $r$-th moment of the envelope function (upper bound of $\ell\circ \cdot$ where $\ell is the loss function$). The main result (Theorem 3.2) states a sharp oracle inequality holding with high probability, where the rate of convergence is $n^{-\beta}$ and $\beta$ can be made arbitrarily close (from above) to 1 (through $r$: the more moments of the envelope exist, the closer to 1). Section 3.4 is helpful in assessing that the multi-scale Bernstein's condition hold for a particular learning setting. Theorem 4.1 presents an application to this scheme to quantization: the ERM achieves a $\mathcal{O}(n^{-\beta})$ rate where $\beta$ may be arbitrarily close to 1. The paper is very pleasant to read and contains stunning contributions. I was impressed by the technical virtuosity and the very dense set of results and ideas contained in just eight pages. The introduction clearly states the paper's ambitions, even for non-expert readers. The main contributions are clearly stated and supported by sound proofs. I believe this work would have an impact on several researchers communities. In my opinion, this is a fine piece of work. Minor point: - Lines 444, 458, 460, 462, 481: please correct to proper citations, where all the authors are credited (no "et al.")