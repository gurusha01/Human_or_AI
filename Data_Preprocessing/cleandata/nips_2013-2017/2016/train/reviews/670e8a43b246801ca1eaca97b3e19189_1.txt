The paper presents an alternative prior for Bayesian non-parametric clustering. The prior is a better fit for applications where the size of data in each cluster doesn't grow linearly with the number of data points (i.e. rich gets richer assumption as in DP and related priors is no longer valid). The authors explicitly modeled the distribution of cluster sizes in the new process and provided two incarnations of the process using different forms of distributions over cluster sizes. They gave a Gibbs-sampling algorithm as well as a split-merge algorithm in the appendix. Comparisons were given to DP and PYP over various datasets. The authors addressed an important problem in BNP clustering and gave an interesting prior. However, the paper have the following weaknesses: 1- As the authors mentioned in line 64, [13] had a take on the same problem by defining a uniform prior rather than the rich gets richer prior implicit in DP and PYP. They showed that their prior produces larger number of clusters than DP. Unfortunately, the authors didn't compare with [13] nor discussed in any details, beyond a passing mention in line 64, how their work relates and differs from [13] in terms of the properties of the resulting prior. 2- The authors didn't discuss in details what are the implications of sacrificing consistency to achieve the micro-clustering property and how this compared to sacrificing exchangeability as in [13]? 3- The experimental results are not conclusive. Are any of the improvements statistically significant? I don't see a radical dominating performance across all measures of the new processes over exciting ones. 4- Writing is a bit hard to follow even for someone familiar with the area. Lots of symbols! Could use some work and simplifications.