This paper applies the Richardson-Romberg (RR) extrapolation to stochastic gradient Langevin dynamics in order to reduce the bias introduced from the gradient estimation noise. The resulting SGRRLD has an asymptotically lower bias and MSE than SGLD. The experiment with synthetic Linear Gaussian Model shows the advantage of the new algorithm over SGLD. Experiments on the MovieLens data show a slight improvement on the test RMSE but the results are arguable. Richardson-Romberg (RR) extrapolation was shown to improve the convergence rate of Monte Carlo estimates on SDEs in the literature. This paper applies this technique to SG-MCMC algorithms and proves that under certain conditions the convergence rate of SGRRLD is faster than SGLD with the same step size at the price of running two parallel Markov chains. The algorithm description is clear and it is quite easy to implement the proposed algorithm. The synthetic experiments show the clear advantage of SGRRLD in reducing the bias in that particular problem. It would be very nice to see more real data experiments to show that a simple modification to SGLD will reduce the bias significantly. I have not checked the proof details of Theorem 1&2, but I'm curious that what condition is required for U to satisfy both theorems? Can U be multi-modal? Intuitively when the gradient noises are not correlated, the two chains will become uncorrelated quickly even if the Gaussian noises are correlated. How would the combination of the two chains reduces the order of the error. When run in real data experiments, do the authors observe the correlation between the two chains? My concern about the experiment setting and the real data experiment is that the authors argue that the computation time is about the same as SGLD with the parallelisation. However, we can also run SGLD with multiple parallel chains within the same time. If we compare the estimation from 2 chains of SLGD with the SGRRLD, can we still observe the same improvement in RMSE? Another problem is that in the real data experiment, we compare SGRRLD with a step size gamma and gamma/2 against SGLD with a step size gamma. I think we should also compare with SGLD with the step size gamma/2 that has a lower bias (and run 2 chains in parallel). Also, more real data experiments should be carried out.