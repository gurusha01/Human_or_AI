The authors propose an extension of LTSM which allows for continuous time data to be processed by the LTSM which otherwise---as other RNNs---is restricted to discrete time data. The approach is succesful and gives good results for several data sets. The paper is clear and well written. The results are impressive  I do not think that the computational complexity will increase very much but this is not clear from the paper. Perhaps a comment on the time consumed, for instance reported as epochs/s?  The accuracy is very high even for the first Epoch. Is there any prior information going into the training?  Could you provide better intuition for what the gates do and why they work?  Are the nodes with different time-gates independent? If so, are you not training separate networks? Why is this then different from using several normal networks with the input data lagged?