This paper proposes an unsupervised adaptation technique using residual connects to make the target classifier equal a sum of the source classifier with a residual function. This is distinct from recent deep adaptation methods which learn a joint source and target model. This paper also proposes using the kernel MMD for aligning the representations of the two domains, just as done in the related DAN and DDC methods. The idea of learning a residual difference to produce a target classifier is novel, simple, and interesting. The paper is well written and the method is well explained. The main issue stems from the fact that there are 3 components to the approach, the entropy loss on the final target scores, the MMD loss for domain invariance, and the residual connection. From the experiments it appears that the entropy loss offers the most benefit, followed by MMD, and finally by the residual connection. The MMD loss is not novel and the entropy loss is not as well explained and the residual connection. The method appears useful, it's simply unclear if the novel portions of the approach are actually contributing much to the overall system.