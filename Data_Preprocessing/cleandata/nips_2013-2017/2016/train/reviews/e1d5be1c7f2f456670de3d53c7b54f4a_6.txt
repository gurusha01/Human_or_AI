This paper tries to reduce contextual semibandits to supervised learning, so that powerful supervised learning methods can be leveraged in this partial-feedback setting. The authors claimed that the policies used to select arm in contextual semibandits is a large but constrained class. Such a class enables us to learn an expressive policy, but introduce a computational challenge of finding a good policy without direct enumeration. This paper build on the supervised learning literature, including logistic regression and SVMs for linear classifier and boosting for tree ensembles. They access the policy class exclusively through a supervised learning algorithm, viewed as oracle. The oracle-based algorithm for contextual semibandits problems proposed in this paper is quite novel (as far as I know) and interesting. Both theoretical regret bound and empirical evaluation support their claims.