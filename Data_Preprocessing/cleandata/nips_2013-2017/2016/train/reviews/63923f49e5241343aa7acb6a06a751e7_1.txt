The paper appears to be the first to give fast learning rates for learning in unbounded domains with heavy tailed loss functions, under conditions introduced. For one of these conditions (multi-scale Bernstein) the authors also discuss how to verify it in practice. The other condition (polynomial entropy bounds on the hypothesis class) is less clear and the discussion section in the end suggests that extensions might be possible. In the case of bounded loss the new result recovers state of the art results of (Mehta & Williamson 2014). The proof uses new results of (Lederer et al 2014) to bound the suprema of empirical unbounded processes. As an application, k-means clustering is analysed in the setting of heavy tailed data distribution. This paper appears to be sound and useful. The only question I have is whether the authors could elaborate a bit on how restrictive or not is the polynomial entropy boundedness condition and, if there are indications to "expect" that the result would extend beyond this condition?