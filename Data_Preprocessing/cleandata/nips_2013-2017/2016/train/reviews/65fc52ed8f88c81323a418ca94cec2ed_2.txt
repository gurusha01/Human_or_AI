This paper presents an approach for unsupervised learning of similarities between exemplars. The paper addresses the problem of selecting relevant positive examples and negative examples for CNN-based similarity training. The underlying approach has two steps. First, an optimization problem is solved to extract samples with mutually consistent relations. Then, a ConvNet learns a single representation for all the samples. This procedure is repeated -- the authors alternatively train the CNN and recompute cliques/batches using similarities inferred from the last iteration. Results are shown on sports-related action datasets as well as a traditional PASCAL image classification task. Overall, the paper does a good job introducing an iterative algorithm for exemplar-based similarity learning which uses CNNs. The proposed algorithm overcomes some of the key problems when working with exemplar "single-positive" methods. Pros -Algorithm does well compared to baselines Cons -The computational complexity of the "mutually consistent relations" algorithm is not discussed. -It is not clear whether the algorithm can be improved by selecting better mutually consistent cliques, or doing better CNN learning. -Figures 1 and 4 are not clear.