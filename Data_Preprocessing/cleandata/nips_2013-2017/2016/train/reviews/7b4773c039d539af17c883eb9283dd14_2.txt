The paper provides a new sampling algorithm for planning in MDPs. The planning algorithm returns an estimate of the value function corresponding to the starting node of a loop-free MDP whose generative model is available to the planner (that is, a random next step can be sampled from any state). The sample complexity of the algorithm is analyzed theoretically. These results show achieve and/or improve previous results for MDPs with finite branching factors, and are also applicable when the number of possible next states are countably infinite. The paper considers an interesting and important problem. The results can be interpreted as a natural combination of the planning algorithm of Busoniou and Munos (2012) with the sampling method of Kearns et al (1999). However, the paper introduces a few more tricks to make this idea work (e.g., balances confidence intervals and uncertainties at different parts of the planning tree). The presentation is quite nice and the authors try to give the intuition behind the choices in designing the algorithm. The clarity could be improved by noting that the MAX part of the algorithm is in fact action elimination for best arm identification (can't you use some of the existing results instead of reproving everything from scratch?). I would be also happy to see a more detailed discussion about the parameter choices kl/(1-\eta)^2 and \eta max(Ul\epsilon). Also, please mention at the introduction of the algorithm that the semantics will be explained later (or change the order of discussion). On the negative side, the complexity measures are similarly hard to interpret as in previous results, although this might be inevitable. In line 45 it is mentioned that a planning tree is considered only for simplicity, and the algorithm can be extended to general MDPs with loops with merging states. I cannot see how you'd manage to actually propagate the sampling results in this case. In earlier algorithms, when you compute the optimal policy, this leads to significant complications (computationally), and I have failed to see why these would not apply here. So please either include such an explanation or remove the corresponding remark. Infinite N: note that this is countably infinite. Also, would it be possible to reduce the infinite N case to the finite one by showing that one can actually neglect successor states with sufficiently low probability (relative to epsilon) as those states will never be sampled and they have marginal contribution to the value function. Is the presented complexity measure dH superior to what would follow this way? Minor: - l. 59: Mention that you want to obtain an epsilon_-optimal policy. - There are several typos in the paper (e.g., choosing the correct article). - p. 3, footnote: define delta - l. 423: output->outputs