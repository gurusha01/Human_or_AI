This paper studies efficient memory usage for training RNNs. A dynamic programming solution is proposed for optimal memory allocation when training RNNs, allowing RNN training to handle long sequences with limited memory and at relatively low computational cost. The dynamic programming formulation is a solid step forward on top of Chen et al's fixed square root of t as well as the fixed recursive schedule. Being able to formulate the allocation problem as a dynamic programming problem also makes it clear that the optimal allocation can be found efficiently. Overall I think this is a nice and solid contribution. The distinction between hidden states and internal states is a little confusing. The results of this two cases also only differ by a constant factor, I wonder if it will be clearer to move some of the material to the appendix. On the other hand, I found the theoretical analysis in the appendix to be interesting. The only thing that is more obviously missing is the application of the proposed methods on real problems. It will be good to see if the ability to train on longer sequences help improve RNN performance, and see if there are any practical issues that occur beyond the theoretical analysis. A few minor problems: - This paper used the wrong format, it should use the template for submissions - At the beginning of section 3, it is said to discuss two cases, when memory is scarce and when memory is somewhat limited. However the second case was not discussed, or I somehow missed it? The authors never made the distinction between "scarce" and "somewhat limited" clear.