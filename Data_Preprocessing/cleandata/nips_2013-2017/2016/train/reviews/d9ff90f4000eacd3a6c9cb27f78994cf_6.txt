The authors propose a theoretical approach to measuring the capacity of a family of unitary matrices. They show that previous work using a simple family of unitary matrices to parameterize a unitary recurrent neural network has less capacity than the full unitary group. They apply an existing approach for gradient descent on the Stiefel manifold to optimize over the full unitary group. In synthetic and real data experiments, they confirm the superiority of this approach. Surprisingly, they also find that it is more efficient computationally. All-around good paper and well-written. One of the main contributions of the paper is a novel concept for evaluating the capacity of a family of unitary matrices. They use this approach to demonstrate that the previous family of unitary matrices limited the representational capacity of the neural network. Can the authors explain why a simple counting argument is not also valid? As the authors explain, the previous family of unitary matrices was parameterized by 7n real parameters, whereas U(N) is parameterized by n^2 real parameters. This seems to suggest an even lower bound for when the capacity of the previous family of unitary matrices will not cover the entire unitary group. The authors could strengthen the paper by conducting further experiments (for example, replicating some of the experiments from the original unitary evolution recurrent neural network paper like the permuted mnist experiments).