The paper combines two concepts that gained significant interest in theoretical neuroscience: information bottleneck (IB) and sparse coding. As such, in Reviewer's opinion, it has a potential of making a big impact on the field of neural coding. The paper is technically sound, proposing a number of algorithms: a EM-IB type of algorithm assuming sparse approximate prior p(encoding variable), and a kernel extension to the algorithm, which allows to deal with more complex, non-linear relationships between observables. It analyses a number of interesting problems. Perhaps, the writeup would benefit from underlining its neuroscientific/neural coding aspect (i.e. by relating results also to those obtained by a standard sparse coding approach). Thank you for the very interesting read. I enjoyed the comprehensive description of all the concepts and methods and, as stated above, I hope this research will make a big impact on theoretical neuroscience. I have a few questions rather than comments, and they are mostly to satisfy curiosity. 1. Would you be in a position to hypothesize, why sparse IB filters in Fig. 1C are curved? From your description I understood the stimuli were oriented bars, rather than curved arcs? 2. The horizontal bias in orientation representation - was it observed only with a strong bottleneck? Would the effect go away with a softer constraint on coding? To what extent did sparsity contribute to that result? In fact, there is a large body of work in neuroscience concerned with an asymmetry of orientation representation in V1, the famous "oblique effect" - which looks like an ideal setup for your experiment. I believe you can contribute with an interesting functional hypothesis of how the effect comes about in the brain of highly visual animals. This would probably even be accepted as a separate publication in a more neuroscience-oriented venue. Good luck! The paper is very well written. A few minor typos in lines: 90 (decide between mu or 0), 93 (typo in Xi variable), 95 (row rather than a column?), 175 (features presented on...), 195, 222 (asymmetric), 239 (Fig. 3F-G), 256 (neural) and Equation 1 (X and Y swapped in the first line). Please, double check the X-axis label in Fig. 1F - shouldn't it read "units"? You may consider mentioning the phi(x) [line 146 and following] is a row vector, I got slightly confused by notations such as phi(x) phi^T(x), which I understand should represent dot-products.