This paper proposes a new formulation for robust optimization that combines the maximization over policies and minimizations over transition models into a single expression. The new objective jointly considers performance of the proposed policy and performance of the baseline policy under a shared (minimized) model. The formulation allows the policy to improve even with significant uncertainties in the transition probabilities. The original formulation of robust optimization evaluates the baseline policy under the most optimistic model and the proposed policy under the most pessimistic model. For some domains this is a very punishing formulation because the most pessimistic model may never have an expectation as great as the most optimistic model-- regardless of the number of samples collected to build the model. By considering the baseline policy and the proposed policy jointly, this formulation does not need to wait until the proposed policy provably improves on the baseline policy's optimistic performance. I do not have much experience with robust optimization, so I cannot evaluate this work in the larger context of this subfield, but I find the reformulation to be convincing. My only concern is with the likely additional cost of optimizing to this formulation. Since the authors prove the formulation is NP-hard, their algorithms focus on promising approximations. nitpick: I could be missing something, but I think the assumption that transition probabilities are known for actions consistent with baseline policy is not realistic in the energy market example. This sounds like the action may be controlling the price? I am interested in learning more about the details here.