This work's main contribution is to utilize the triangular Cholesky factorization technique which could get rid of the square root in the standard CMA-ES, which could save the computation cost when calculating the inverse of matrices. The author presents an approach that comes with a theoretical justification to illustrate that it does not deteriorate the algorithm's performance. The proposed method reduces the runtime complexity of the algorithm with no significant change in the number of objective function evaluations. This paper is a valuable implementation of Cholesky factorization method for CMA-ES. Can the author further explain theoretically why the 'numerically more stable' computation could be achieved? It seems that The Cholesky-CMA-ES needs the same amount of objective function evaluations as the standard CMA-ES, and it lessen the wall-clock time and this increases with the search space dimensionality. Could the author consider combining the low-dimensional approximation [Loshchilov, 2015] with the existing framework because in most of practical cases such as training neural networks in direct policy search, the high-dimensionality of the problems should be a non-neglected concern?