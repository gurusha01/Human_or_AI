This paper proposes a new method of manifold learning which directly minimizes the deviation from isometry. The method is iteratively optimized by the projected gradient descent. There are some comments as below: In algorithm 1, how to set d and s in practice? Is there a systematic way to select s once d is given? In line 25, please define the function poly. line 27: An embedding ... : please check the sentence line 71: W{ij} --> W{kl} In (1), D = W1 --> D = diag(W1), likewise, tilde(D) = diag(tilde(W) 1). line 77: give -- > gives In swiss roll and curved half sphere example (Fig. 2), the qualitative performance of HLLE and Isomap seems better. However, the numerical performance using (10) is favorable for the proposed RR. I want to see how different each of the two loss terms in (10) for different algorithms. The computational complexities of each algorithm are better be compared.