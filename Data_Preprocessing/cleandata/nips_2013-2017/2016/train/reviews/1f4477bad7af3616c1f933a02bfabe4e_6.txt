The paper proposes a method to train -under certain assumptions- a specific type of feed-forward neural networks. The authors prove optimal convergence and demonstrate that their method can be applied on a selection of "real world" problems. The problem under investigation seems interesting to me and any theoretical advance in this direction is appreciated. But the paper falls a bit short in convincing that the proposed class of neural networks is useful in practice. In particular, if the authors raise the issue of the expressiveness of their restricted model (and they do so twice), then I would recommend adding some thoughts about what can be done and what is out of reach for their approach. Moreover, concurrent approaches should be discussed and contrasted. The experimental results do not clarify the limitations of applicability of their model either. When reading the experimental results, I was surprised that the authors only compare their approach to some SVM and ignore other methods, both other training methods for some neural networks and other algorithmic paradigms. Also, I would have expected some information about the computational resources demanded by the three algorithms. The introduction is well written, subsequently the presentation has some room for improvement. In particular, Section 2 does not read fluently. There are some typos, I have collected a few below. Some specific remarks: While the definition of the loss function is straight-forward, the function $\Phi$ lacks motivation: the role of the epsilon term was explained in the rebuttal, I think this should be added to the paper as well. Theorem 1 should be explained informally before being stated. The statement itself is hard to parse. Below Thm 1: The authors explained in the rebuttal that the very general statement that "the nonlinear spectral method [...] converges quickly typically in a few (less than 10) iterations to the global maximum", given immediately after Theorem 1, stems from their experimental observation. This should be clarified. 60: polyomial 67: one CAN model. 67: p1 and p2 are not introduced. 67: R_{++} is not introduced, which is unfortunate since there are several other variables whose definition points to that one. Thanks for clarifying this in the rebuttal, I had not seen this notation before.