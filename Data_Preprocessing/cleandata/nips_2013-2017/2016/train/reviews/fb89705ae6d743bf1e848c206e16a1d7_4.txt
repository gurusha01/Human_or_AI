Copula is a canonical method to describe dependency structure of discrete and continuous random variables by separating it from description of marginal distributions. While there are parametric copulas for multivariate random variables such as Frank or Gaussian copulas, these models may be limit. Here the author(s) proposed a method for constructing a joint model by iteratively combining bivariate copula models. Sampling method from the model and fitting procedure were proposed based on known procedures. The author(s) verified their model to simulated mixture signals of count and continuous data. They then applied their method to simulated LFP and spike count data using a virtual electrode recording toolbox, and demonstrated that mutual information between neural activity and stimulus conditions is significantly influenced by the dependency modeling. Recently several authors started to apply copula to model mixture signals of count and continuous data for neuroscience data. This manuscript provides a practical method that is scalable to analysis of larger number of neurons and LFPs, by iteratively applying pairwise analyses. Although the descriptions are complicated, the underlying idea is straightforward, thus was easy to grasp. It may be helpful if the author(s) could provide an intuitive picture of the tree structure described at lines 105-109. Below I describe questions that arose by reading this manuscript. I hope that these questions help the author(s) to extend their manuscript.  This method is based on pairwise analysis, thus likely to neglect higher-order dependency among signals. If so, then how much do we miss the higher-order depndency? If this is difficult to assess, it would be better if author(s) could comment on this issue in the manuscript.  Gaussian copula is probably the easiest model to construct multivariate dependency. Thus it would be nicer if the authors could compare performance of the vine copula model with a Gaussian copula model as these share the nature of pairwise analysis. * The final result on the mutual information (MI) shows reduction of MI by constraining the dependency among the signals. Does this mean that count and LFP signals are redundantly code the two stimulus conditions? It is recommended that the author(s) extend implications of this result.