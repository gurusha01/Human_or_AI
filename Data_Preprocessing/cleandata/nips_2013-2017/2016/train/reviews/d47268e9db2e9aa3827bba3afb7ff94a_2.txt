The paper rigorously studies a question: what kind of advantages can we expect from quantum computing in machine learning? This is a difficult question to ask, as in many learning algorithms we either have a clear idea of their computational complexity or their statistical complexity, but seldom both. The authors focus on the well-understood perceptron to study the limits of quantum computers in machine learning. The scheme uses and integer discretization the usual floating-point representation and assumes a quantum random access memory. The ideas pivot on a Grover-type search. The paper is meticulously written and it reads well. Little prior knowledge in the basics of quantum mechanics is sufficient to follow the argument. The classical weight update scheme is clearly simplistic, but the authors provide ample references for other algorithms, and this simple algorithm allows for a clean and straightforward comparison with the quantum case. Grover's search in machine learning is certainly not a ground-breaking idea, but investigating the bounds in a rigorous way has been lacking. The only flaw I can point out is the lack of references to other works on quantum perceptrons. Most notably, Lewenstein (1994) investigated quantum perceptrons from the perspective of statistical learning theory, which is the closest in spirit to the present work. M. Lewenstein (1994). Quantum Perceptrons, Journal of Modern Optics, 41:12, 2491-2501, DOI: 10.1080/09500349414552331.