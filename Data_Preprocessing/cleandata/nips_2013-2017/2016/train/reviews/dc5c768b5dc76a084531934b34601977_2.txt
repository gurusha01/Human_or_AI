This paper takes a stab at providing a foundation to analyze the churn of ML models: e.g., how much one model trained as an improvement to another changes the predictions of the model. The more changes, the more difficult to evaluate in practice. The authors show a simple method to reduce churn by regularizing towards past model's predictions, and provide a theoretical analysis of this approach. I really like this paper because it is easy to read, very thought provoking, and potentially very useful in practice. Major strengths of this paper: + Thorough, theoretical treatment of a problem that is super relevant to any practitioner of machine learning. + The experiments are thorough, and the P_win analysis is very nice. I really appreciate the thought that the authors put into making this more theoretical work appealing in a very practical way. + The connection to dropout, and the use of the Markov chain as away to get a robust model, is very interesting. + The gains in some cases are very big in the datasets used -- significantly improving churn while not affecting or improving accuracy. Major weaknesses: - Unfortunately, one major take-away here isn't particularly inspiring: e.g. there's a trade-off between churn and accuracy. - Also, the thought of having to train 30-40 models to burn in in order to test this approach isn't particularly appealing. Another interesting direction for dealing with churn could be unlabelled data, or applying via constraints: e.g. if we are willing to accep X% churn, and have access to unlabeled target data, what's the best way to use that to improve the stability of our model?