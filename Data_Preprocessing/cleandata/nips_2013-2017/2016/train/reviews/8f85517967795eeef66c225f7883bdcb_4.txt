The authors develop methods for approximate marginal inference and partition function estimation in an interesting and useful class of 'cooperative graphical models' where an extra submodular cost function on edges significantly extends pairwise MRFs in ways that can be helpful e.g. for image segmentation. Earlier work considered MAP inference for a subclass of these models but here marginal inference is tackled by cleverly combining polyhedral results with earlier work on variational inference. The paper is interesting, clear and well written with good motivation, background and examples. Novel upper bounds (convex) and lower bounds are derived for log Z, then a good range of existing inference methods are used appropriately to estimate these bounds, including Frank-Wolfe, PGD, TRW, BP, mean field and perturb-and-MAP methods. These are evaluated empirically and initial conclusions and guidance are drawn. For the empirical results on small models, how was exact inference performed - I presume brute force? The larger example from computer vision is helpful and demonstrates the promise of this approach. Lines 216-223: Nice idea to use Bethe here 224: nice again but don't we again need both conditions from just above, (i) and (ii) for this? Minor points: In Abstract, perhaps clarify: efficient inference techniques -> methods for approximate inference (clarifying approximate and also perhaps efficient should not strictly be used since eg BP does not have guaranteed runtime) Footnote 1: could this be elaborated in the Appendix Line 114: for clarity, perhaps something like "with an eye toward the bounds of Sec 3, we write a model using g instead of f, as..." Equation after line 29: typo mu-> tau 146: an entropy -> a concave entropy 236: solved exactly -> solved exactly or upper bounded