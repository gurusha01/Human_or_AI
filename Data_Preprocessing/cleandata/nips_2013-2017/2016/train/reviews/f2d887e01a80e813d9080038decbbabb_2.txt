The problem is estimating the risk of a classifier or a regression function using unlabeled data only. This original problem has been proposed in the prior work (Donmez, 2010). In the present paper the main assumption is that there are at least three "views" of each object, and these views are conditionally independent given the labels. Under some additional assumptions, certain performance guarantees are derived. My main concern is that the main contribution/improvement with respect to (Donmez, 2010) is not made really clear. In particular, (Donmez, 2010) also introduces conditional independence (section 2.2 Collaborative Estimation of the Risks: Conditionally Independent Predictors) where the conditional independence is that of predictors rather than "views." In the paper, predictors also are decomposed view-wise, thus their predictions are also conditionally independent. Thus, the assumption appears stronger than the corresponding assumption from (Donmez, 2010). Is cond. independence of views (rather than predictors' outputs) actually needed? In any case, what is the precise improvement w.r.t. (Donmez, 2010)? Perhaps the authors can clarify this in the rebuttal. I admit that the problem is rather unusual so I may be not understanding something. (The fact that the problem is unusual I consider rather an advantage.) The HMM setting is somewhat misleading: it requires m i.i.d. time series, in order for the i.i.d. assumption to hold. Usually in HMMs one tries to make inference based on just one time series. UPDATE: The novelty aspect, which was my main criticism, is more clear to me now (mainly from reading the rest of the reviews), so I lift this objection.