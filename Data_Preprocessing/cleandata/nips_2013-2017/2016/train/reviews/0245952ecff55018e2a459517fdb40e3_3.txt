This paper proposes a loss function for directed generative models with conditional variables. The method is an extension of generative moment matching networks, which uses an unconditional loss function based on the maximum mean discrepancy criterion. This approach leverages the work on conditional kernel mean embeddings to produce the loss function, and the results are demonstrated on a variety of generative tasks including classification, generating handwitten digits and faces, and distilling knowledge in Bayesian models. This is my second time reviewing this paper. The issues the reviewers had last time were minor: why the authors used a low-dimensional space and whether this could scale to a higher-dimensional latent space, the utility of this model compared to others, and other miscellaneous clarifying issues. Looking at the text, these seem to have been answered directly. With respect to Remark 1, it's unclear to me how to map from Equation (2) onto the weighted MMD form. What is the dot notation you're using here? Is it matrix multiplication or the Hadamard product? I would like to see this part given a bit more detail so that the mapping is more obvious. Also the choice of C I think is a bit unfortunate since you're already using C to define the conditional embedding. Theorems 1 and 2 refer to other papers, however Theorem 3 has no reference. A reference should be given to a paper containing a proof, or a proof must be given. The empirical results are decent. In previous reviews it was pointed out that using this model for supervised learning is perhaps not a great application, but the authors stated that it was to highlight the versatility of the model, which I think is fine. The distilled Bayesian inference application is interesting, but it's only used on one dataset with one model so it's unclear whether this will be useful in other cases. I feel like this approach would gain the most traction in pure generative modeling. The experiments in this case are comparable to those of the original GMM paper. The datasets used involve digits and faces, which I think is sufficient to demonstrate that the idea works. In terms of whether others will adopt this method, there would need to be compelling results on more difficult datasets, e.g., CIFAR-10 or LSUN.