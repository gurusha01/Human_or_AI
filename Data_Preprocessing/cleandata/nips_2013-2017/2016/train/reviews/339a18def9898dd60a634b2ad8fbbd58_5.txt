The paper models digital crowdsourcing in an information theoretic framework to provide lower bounds on the needed number of queries per task to achieve a given probability of error. The workers are modeled as parallel independent channels. The type of channels considered are symmetric discrete memoryless channels (MSC) to model errors done by workers and spammer-hammer channel model SHC(q) to model the case when a worker is a spammer with probability 1-q. The code is assumed to be nonadaptive. Two cases are considered for analysis: the case when the crowdsourcer, who decides the value of each task after collecting the results from the workers, knows the skill level of all of the workers and when it do not know anything about them. In both cases the taskmaster, who distributes the tasks to the workers, is assumed to not know anything about the workers skills, so every worker is assigned the same number of tasks. Finally, a necessary condition on the minimum needed rate- number of queries per task- k-ary incidence coding, where the worker is shown k items and asked if they belong to similar or different breeds, with SHC(q) worker pool was provided. Well organized and well written paper. There was no experiments or simulations to show how far current used schemes are from the limits, for example in AMT. I think section 2.4 can be shortened and 3.1 is not necessary or can be shortened. Instead, proof sketches to the theorems are more important. It seems novel, there is no analysis of the crowdsourcing problem from an information theoretic point of view before as far as I know and claimed by the paper. It seems very useful where designers of such crowdsourcing projects can know the minimum rate needed to accomplish a task with a given probability of error and it can help in pricing such projects. I did not read the appendix so I cannot claim anything about the proof.