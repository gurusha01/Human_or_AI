This paper studies the support recovery guarantess of the variants of the relaxed basis pursuit algorithm. The loss studied here is l1 loss and infinity loss instead of the traditional l2 loss. This work extends the existing theory for l2 loss case. The main theorem gives guarantess for support recovery under a specific small noise level setting. The main contribution of this paper is to give detailed support recovery guarantees for l1 and infinity loss variant of relaxed basis pursuit. This completes the theorectal analysis of this problem in these specific cases. The paper explains the main problem setup, main results and experiments very clearly. There is a minor typo like - line 62 "explicitely" Here are some main weak points of the paper. - The use of l1 loss and infinity loss is motivated by different noise models. However, in simulations it is not clear which noise model is used. It would be interesting to see how three methods perform differently under different noise models. Simulations basically show l2 loss is superior for support recovery, if no practically interesting cases are provided, why are the theoretical support recovery guarantees interesting? - Theorem 1 only applies for a small noise setting. It does not provide insights when the noise level is larger than what is assumed to be. Like it is discussed in line 215, it could that the Theorem 1 only applies to the case where no nosie is allowed. Could the authors elaborate more on large nose settings, either in theory or in simulations? - Most important information about the numerical experiments is given, however the noise level is not specified in any experiments.