Extending the traditional encoder-decoder framework for end-to-end learning, this paper proposes adding a reviewer module in the middle for visual caption generation. Experimental results show that reviewer module does improve the performance of image captioning and source code captioning over the traditional attentive encoder-decoder framework. The additional reviewer module with multiple-step attention over hidden units captures global information across several attentions, and also has a discriminative loss to guide the overall learning process. The idea of using a multi-step reviewer module is very interesting. Overall, the paper is well written. The attentive mechanism has two variants, input reviewer and output reviewer. The authors should explain the difference and their usage under different settings in details in the method section. The multi-step attention is very similar to the multi-hop attention used in memory networks. It is known that the final performance is highly dependent on different steps. The authors should explain how increasing steps of reviewing affects the results.