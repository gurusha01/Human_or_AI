This paper presents a method to estimate the test error of a model from unlabeled data, on distributions that are different from the distribution of the training set. The approach is based on the method of moments and the assumption that the feature space is divided in 3 conditionally independent subspaces conditionally to the output (3-views assumption); but no assumption is made on the optimal predictor or the parametric form of the distribution. The method extends to structured output settings such as HMMs. The paper is well written and I did not find any flaws in the proofs. My main concern is about the 3-views assumption and how realistic it could be? The assumption is stronger than the one of co-training which was proposed for multi-view learning and in some papers the assumption is discussed to be unrealistic for mono-view learning. I would suggest to have a discussion on whenever the main assumption can be relaxed or a least a discussion about how to deal the problem where it does not hold in many general cases.