This paper studies the problem of designing safe algorithms for reinforcement learning, where safe is defined with respect to a given baseline. The paper proposes a new notion of safety, where we seek the maximin improvement over a given baseline policy. The paper presents a number of results related to this concept, and an approximate algorithm. The paper gives a new perspective on the question of safe RL algorithms. The development is sometimes hard to follow, and it would have been nice to review existing notions of safety before delving into the novel idea. Having whole algorithms relegated to the appendix doesn't seem right to me. Issues/questions -- Line 104: Where is that definition of safety from? In particular, Thomas et al.'s "High Confidence Policy Improvement" provides a high-probability, value-based definition. The paper should clarify if/why there are multiple definitions, and why we prefer one over the other. -- Theorem 3: Why is a multiplicative bound from the right notion? Why not an additive bound (which wouldn't produce the same conclusion)? -- Proposition 7: Can you bound the approximation error when your assumption does not hold? In particular, Remark 1: can Algorithm 1 be arbitrarily worse than the exact solution? -- In the proof of Theorem 5. Can you explain the passage on line 392 from rho(piS, xi) to rho(pi^, xi)? It doesn't seem obvious to me, because pi^ is the optimal policy for P^, not for any xi. -- Proof of NP-hardness: the proof is hard to follow. Can you explain why some states (e.g. l13) are missing at the bottom of Figure 6? Also, I believe the statement needs to be formulated more carefully, and isn't correct as-is. The uncertainty set needs to be described in terms of its independent factors. I.e., if Xi is provided as one big set to the algorithm, then the minimization is trivially polynomial in the exponentially-sized Xi. Minor issues -- P^ seems superfluous. The MDP is already defined as using P. Why not use P instead of P^*? -- Def. 2: are we looking for a maximal zeta or a max-achieving pi? -- Line 118: "standard approach" sounds definitive and grates on me, especially since the paper at that point had not clearly reviewed what existing safe methods there are. -- Line 160: Your state occupancy measures are wrt p0, and are discounted -- that should be clarified. -- Theorem 8 and Lemma 11: There's a bit of slop in the use of the e, epi vectors. These need a bit of guesswork. It would be good to define the two vectors carefully.