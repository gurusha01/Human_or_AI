This paper proposes an effective memory allocation strategy to save GPU memory consumption for back propagation through time algorithm. The basic idea is using dynamic programming to find an optimal memory usage policy to balances the tradeoff between memorization and recomputation. Empirical result shows that under a fixed computational cost for forward propagation the proposed method achieves about half the memory usage compared with a previous method. Limited memory size of modern GPUs is a bottleneck to train very deep neural network. In order to alleviate this problem, this paper proposes an effective memory allocation strategy to save GPU memory consumption for back propagation through time algorithm. Theoretical analysis and bounds are well presented. The main drawbacks are the experiment part. I believe that if the paper could provide more evidence about its potential influence in real applications, it will be a very interesting paper. The detailed comments are as follows, -- There is few experiments on large-scale dataset or real applications. Without those empirical evidence, it is still not very clear how is the speedup or memory usage reduction of the proposed method comparing with other methods. -- The experiment result is not very significant since there is almost no speedup for very long sequences with a feasible memory consumption. -- The idea of dynamic programming adopted in this paper is a little incremental compared with Chen's divide-and-conquer algorithm. -- Besides memory cost, there are other factors limit the efficient training of very deep neural networks, such as convergence speed and computational cost in each iteration. The help of saving a small part of memory consumption is very limited in training deep neural networks, unless the saving is significant. It will be very helpful if we could consume orders of magnitude less memory. -- Minor: In page 7, "as expensive than a orward operation" --> "as expensive than a forward operation". Many typos in supplementary materials.