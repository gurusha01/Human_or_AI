This paper proposed a memory-efficient backpropagation through time by using dynamic programming, besides they provided an analytical upper bound for their strategy. Comparing to Chen's algorithm, their proposed BPTT-MSM can fit within almost arbitrary constant memory constraints which is the main advantage. As we known, memory consumption is a bottleneck in training complex recurrent neural networks on very long sequences. This paper proposed a memory-efficient backpropagation through time by using dynamic programming. However, compared to Chen's work, the strategies of this paper are more complex and Chen has tested on specific tasks using mxnet. I wonder if you could provide some results on specific rnn networks like seq2seq learning.