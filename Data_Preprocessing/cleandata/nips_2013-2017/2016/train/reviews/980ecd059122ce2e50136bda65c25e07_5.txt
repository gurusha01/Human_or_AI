The paper suggests to use linear programing in order to find adversarial examples for ReLu networks and defines measures of robustness. The paper also distinguishes the method that generates the adversarial examples from the method that measures robustness. Given the current interest in robustness properties of deep neural networks, this is definitely an interesting topic to investigate. The paper is well written and easy to follow. The results are convincing and I think that researchers from the deep learning community would benefit from reading this paper. However, I have two main points of criticism: First, while using linear programing to find adversarial examples is appealing, the approach presented in the paper relies on linear properties of ReLu networks and therefore hampers its usage. Second, the methods proposed in this paper seems to be superior over previous approaches at identifying adversarial examples, they do not improve the performance on the test set significantly. The authors also fail to demonstrate the superiority of their method in other data sets beside Mnist. Smaller remarks: I find the formalization of the linear constraints a bit exhausting. It is clear that at a given point x only one of the disjunction constrains is needed. I therefore don't see the point in introducing disjunctions only to later disregard them.