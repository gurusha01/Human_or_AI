This paper introduces an end-to-end differentiable memory access scheme that has the representational power of an original NTM, but is much more efficient with training wiht very large memory. This paper introduces a lot of original concepts which seem to have technical brilliance. The problem it attempts to solve is well motivated and well attacked. The impact of scaling memory systems for neural networks is large, and this paper introduces the problem and solution in a clear, concise, and well-explained manner.