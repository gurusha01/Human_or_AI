The paper proposes an approach to domain adaptation of deep neural networks based the following. 1) on multi kernel maximum mean discrepancy to enhance the similarity of the features between the target domain and the source domain 2) using the entropy of the prediction to adapt the classifier to the target domain. 3) the main contribution: the classifier of the source domain is a residual function of the classifier of the target domain. Overall, the technique appears to work well, and there is a big comparison with related work. I think the paper is interesting, and could become a very good paper if the experimental evaluation is improved. The main issue I have with the paper is that it does not properly isolate/evaluate the contribution of the residual function. It is not clear to me whether this residual block is actually needed. For example, I think the residual block can be replaced by simple L2 regularisation to keep the source and target classifier similar. Figure 2 also fails to convince me. I cannot see a qualitative difference between the DAN and the RTN predictions. Additionally. I found the mixing of H and F (what is residual and what is the original function) confusing at first. It would be better to stick with one notation and keep this consistent.