This paper presented a practical solution with performance guarantees to the problem of dimensionality reduction for very large scale sparse matrices, which uses a weighted subset of the data, and is independent of both the size and dimensionality of the data. Furthermore, an efficient algorithm for computing such a reduction, with provable bounds on size and running time. Also, a system that implements this dimensionality reduction algorithm and an application of the system to compute latent semantic analysis (LSA) of the entire English Wikipedia. It is an interesting work. Currently there are lots of algorithms for large-scale data, and the authors should discuss with such work. The writing of this paper is hard to understand. The paper needs more language proof. There are a lot of typos. Also it is better to denote the meaning of symbols, e.g. || in equation (2)-(i,ii). Equation (3) is hard to understand, please clarify more. The distance between A and S is the same to manifold distance [R1]. The authors should cite this work. [R1] Wang, Ruiping, et al. "Manifold-manifold distance with application to face recognition based on image set." CVPR, 2008 The format of reference should be consistent. Please check carefully. I think the paper has novelty but the language parts should be improved more.