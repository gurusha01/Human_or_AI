The authors propose a latent representation of voxelized volumes suitable both for generative and discriminative purposes. This representation is also linked to cropped 2D images. The system is based on Generative Adversarial Nets (GANs, Goodfellow et al. 2014), where the generative net is replaced by an VAE encoder, as in Larsen et al. 2016. The present manuscript focuses on 3D volume data, as opposed to 2D images from those two publications. The method shows qualitative and quantitative experiments related to 3D object generation, 3D object classification and 3D reconstruction from RGB images, with good results compared to the state of the art. The present paper shows a nice application of the system presented in Larsen 2016 to 3D volumetric data. Previous work (well analyzed in the manuscript) on volumetric data focuses on combining existing parts, creating latent spaces by exploiting class labels or simple losses in voxel space. The authors use the research on VAE and GAN (Larsen 2016) on this type of data, adapting the convolutional layers to volumetric ones, to improve the performance of the state-of-the-art in this type of data. The experiments showcase three potential interesting uses: object generation, 3D object classification, and 3D objects from RGB images. The analysis of the latent representation in section 5 is also interesting. On the negative side, there's basically no technical novelty in this paper, since it's an application of an existing system (Larsen 2016) to volumetric data by changing the convolutional layers to volumetric convolutional ones. Although the paper is rather clear (in part due to its large technical overlap with existing work), there is a couple of details that could improve the clarity of the paper, namely: - In the object classification experiment in 4.2, the authors use the learned representation as features for classification, but what classifier is used? Is it the same for all algorithms? - Since the authors emphasize the probabilistic nature of the latent space, I think it would be useful to report how likely the interpolations in figure 6 are. Specifically, I'm wondering about how likely interpolations with broken components as arms or legs in chairs are. - The idea of analysing the effect of changing some dimensions in the latent representation, or analysing the neuron activation depending on the volume input is good, but the papers show too few results. A more through analysis shown in a video would be interesting. Overall, I think this paper brings good existing ideas from images to volumetric data, which pushes the state of the art in that field. However, the limited technical novelty reduce the potential impact of the paper.