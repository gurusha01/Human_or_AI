The paper proposes a new version of a stochastic gradient algorithm combined with Bayesian modeling, for optimizing a multivariate objective function over a finite domain. The novel part of the algorithm is that in every iteration it identifies a number of points on which to compute the objective and this computation can be parallelized. The problem is to identify the sampling points in some optimal sense. For this purpose the authors adopt the framework of Knowledge Gradient, which estimates the expected improvement in the objective value if one more sampling point is used and based on that make a decision on whether and which sampling point to use. This approach is generalized here so that the decision is made on multiple sampling points in batch. Since this problem is computationally intractable, the authors develop an algorithm based on Monte Carlo and Infinitesimal Perturbation Analysis to estimate the relevant gradients so as to maximize the information gain over the set of candidate sampling sets. The algorithm is applied on several test problems and is shown to either outperform or seriously compete with other approaches in the literature, mainly those based on Confidence Bounds. The paper is well written and potentially useful for practical applications. I am not convinced that the level of novelty is very high, since the authors expand a previously studied approach (KG) to a batch setting. This requires a more sophisticated method for optimizing the criterion over a set of multiple points. The main novelty of the paper in my opinion lies in the estimation of the q-KG gradient based on an IPA approach, which is also rather standard. I have one rather specific comments/suggestion: In equation (3.1), since x^(1:n) is a finite sequence of vectors, it is not clear how mu(x^(1:n)) and K(x(1:n),x(1:n)) are defined, since mu and K are functions of (one or two) vectors and not sequences.