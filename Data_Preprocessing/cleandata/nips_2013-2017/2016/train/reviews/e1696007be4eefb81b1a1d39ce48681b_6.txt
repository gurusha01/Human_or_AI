This paper proposes an efficient algorithm to solve GLMs in large-scale problems under certain random designs. It can attain cubic convergence after an approximate OLS estimator is found, with only O(n) per-iteration computation. Theoretical analysis gives convergence rate of the estimation error and numerical experiments demonstrate the results. An old idea of relating GLM coefficient to OLS coefficient is applied to modern large-scale settings, assuming the OLS estimator can be obtained accurately with far less computation. The method is novel. It also generalizes the theoretical results to non-Gaussian design based zero-bias transformation. Typo: cubic convergence - Do you mean Halley's method? I have one question regarding the subsampling step in obtaining OLS estimator. One alternative could be do this step at the very beginning, and then either compute the MLE directly, or follow the similar procedure proposed here. How would that compare to the current results? In general, this paper is very well written and has many interesting results and implications.