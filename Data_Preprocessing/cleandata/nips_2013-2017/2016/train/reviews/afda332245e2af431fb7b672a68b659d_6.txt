The paper describes the use of intrinsic motivation for exploration in reinforcement learning. The measure of uncertainty used here is a new quantity called pseudo-count. It is able to work on large state spaces which is also shown in the experiment section with several hard games. The authors also show tight relations to other intrinsic motivation measures such as Bayesian information gain. It would benefit the paper to include more connections to the cited reference "Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning" as they also consider mutual information or channel capacity to be some form of path-counting. Technical quality: Good experiments with reasonably complex environments. Novelty/originality: Novel form of measuring uncertainty through counts. Relations to similar methods incomplete (c.f. section A in "Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning"). Potential impact or usefulness: Useful since it works with large state spaces. Clarity and presentation: Clear structure.