This paper discusses how to measure robustness of a neural net. The authors proposed a point-wise robustness metric, which is defined as the smallest perturbation (in \ell{nifty} norm) that the prediction changes. Based on this metric, they further define two metrics, one is the probability (of the input) that the point wise robustness is below a threshold, and the other one is the conditional expected value of the point wise robustness when it is below a threshold. Using ReLU activation function, computing the robustness can be challenging. The authors propose a tractable convex relaxation that obtains an upper bound. Based on their proposed metric, the authors presented ways to improve robustness of neural nets, and demonstrated the superiority over existing schemes. This paper discusses how to measure robustness of a neural net. The authors proposed a point-wise robustness metric, which is defined as the smallest perturbation (in \ell{nifty} norm) that the prediction changes. Based on this metric, they further define two metrics, one is the probability (of the input) that the point wise robustness is below a threshold, and the other one is the conditional expected value of the point wise robustness when it is below a threshold. Using ReLU activation function, computing the robustness can be challenging. The authors propose a tractable convex relaxation that obtains an upper bound. Based on their proposed metric, the authors presented ways to improve robustness of neural nets, and demonstrated the superiority over existing schemes. I find this paper a piece of interesting contribution toward understanding neural networks. While the concept proposed is not exactly ground breaking, working out all the details does require non trivial effort, which leads to solid contribution to a very important and trendy topic. As such, I think it would benefit the community to have this paper in NIPS. Some more detailed comments: 1. The point wise robustness concept appears closely related to the concept of "margin". I wonder whether the author can comment on this connection. 2. The concept of adversarial severity is less intuitive. Consider the following scenario: suppose we have improved the robustness of the network such that all points whose original point wise robustness is below \epsilon' is now reduced to \epsilon (\epsilon' > \epsilon). However, the adversarial severity for the more robust network is larger (implying being less robust), because of the condition expectation used. To address this, I propose to look at E[\rho \mathbb{1}(\rho\leq \epsilon)]. 3. L170: "when when" 4. I personally feel it may be more natural to have the subsection about the rounding error in the experiment section. 5. The authors mentioned that the proposed method does not improve robustness of NiN much, is there any intuitive explanation, even hypothetically?