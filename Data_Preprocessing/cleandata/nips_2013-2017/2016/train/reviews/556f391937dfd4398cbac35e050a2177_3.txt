This paper makes 2 major changes to the deep embedding pipeline. (1) The proposed PDDM leverages the information of absolute feature position to learn a similarity metric adaptive to local feature structure. (2) The proposed double-header hinge loss explicitly utilizes hard quadruplet mining to discriminate the target similarity distributions. Experiments show that the proposed method lead to faster convergence, better feature embedding and generalization ability. (1) The paper is well motivated. A global euclidean metric could be suboptimal in a heterogeneous space, which can mislead the hard sample mining and consequently deep embedding learning. Inspired by previous work [Xiong 2012], this paper proposes to leverage the feature position information to learn a locally adaptive similarity metric, which can be used to select genuinely hard samples and guide the deep embedding learning. Although not significantly novel, this sounds reasonable and worth exploring to me. (2) The paper is well presented. The network is well designed to incorporate additional feature position information. The loss function is well designed to explicitly require a hard quadruple mining process. Technical details and hyper-parameters are provided for repeatability. The experiment results are promising compared to previous methods where no feature position information is used.