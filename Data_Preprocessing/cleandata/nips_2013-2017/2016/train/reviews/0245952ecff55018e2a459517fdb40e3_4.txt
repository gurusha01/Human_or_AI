This paper builds upon the deep generative modeling approach "Generative Moment-Matching Networks" and derives an extension that allows for conditional generation. (This si done by deriving a kernel embedding of the moments defining the conditional distribution in such a way that they can be optimized using the same machinery as the unconditional version.) The proposed model is demonstrated with reasonably competitive performance on predictive modeling, contextual generation, and the distillation of the predictions from a Bayesian model. The paper appears to be technically sound and the proposals are well presented. (However, I did not check all the equations in full detail.) In terms of novelty, while the idea of making a conditional extension to the generative moment matching framework is quite natural, the mechanism and derivation of the empirical estimator was not obvious (at least to me). And so in this case, the paper seems to have novelty and usefulness. The derived framework itself should be quite easy to apply, as shown in Algorithm 1, consequently this paper will likely be useful and of relevance to people who are interested in using deep models for generative purposes or to distill more elaborate statistical processes. The paper was well written, clear, and easy to read, and the provided appendix usefully provides more complete information regarding the details of the methods used and for the experiments.