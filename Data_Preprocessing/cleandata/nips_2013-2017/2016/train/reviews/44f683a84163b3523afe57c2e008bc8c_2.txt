The paper proposes a generative adversarial networks (GAN) framework for 3D object generation, which is called the Volumetric Adversarial Networks (VAN). In order to adapt the GAN framework for the 3D object generation task, 3D volumetric convolutional architecture is used for the the generator and discriminator. The paper also combines the VAN network with a variational autoencoder for the purpose of synthesizing 3D shape from 2D query image, which is termed as VAE-VAN. A set of experiment results were presented for evaluating the proposed method, which include 1) visual comparison of the generated 3D shape with a prior work, 2) shape classification performance using the unsupervised feature extracted from the discriminator network with several prior works 3) visualization of the generated 3D objects from color images using the VAE-VAN framework, and 4) quantitative comparison of the generated 3D objects from color images using the VAE-VAN framework with several works. The paper also shows the shape arithmetic operation enabled by the VAN and visualizes the neurons in the discriminator. In terms of novelty, the paper is in many ways a straight forward extension of the GAN and DCGAN works to the 3D object generation task by replacing the 2D image generation and discrimination networks with 3D volumetric generation and discrimination networks. The major contribution of the paper is empirically showing that several nice properties of the GAN and DCGAN for the 2D image generation task also exhibit for the 3D object generation task. The properties include the capability of generating novel objects and the strength of the discriminator network as a feature extractor for the classification task. In terms of potential impact, the paper shows that the unsupervised features from the discriminator network are more discriminative than the other unsupervisedly learned features but are only as discriminative as the state-of-the-art algorithms that train their feature extractors supervisedly. As training a classification layer for classifying the unsupervisedly learned features extracted from the discriminator network, the labels of the samples have to be used. This does not reduce the number of samples required for achieving a target performance. It is hence unclear the advantage of the proposed unsupervised feature learning approach. It would be more convincing if the proposed method can achieve comparable or better performance with a fewer number of labeled examples using the proposed unsupervised features. The paper is easy to follow. I do not have difficulty in understanding the paper.