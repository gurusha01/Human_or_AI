The paper proposes a novel supervised metric, Supervised Word Mover's Distance (S-WMD), which builds upon the Word Mover's Distance (WMD) by incorporating supervision to improve document classification. The authors address the limitation of WMD being entirely unsupervised by introducing a method to learn an affine transformation of the word embedding space and a word-importance weight vector. This is achieved by minimizing a stochastic leave-one-out nearest neighbor classification error. To overcome the computational inefficiency of directly optimizing WMD, the authors employ a relaxed version of the optimal transport problem using the Sinkhorn distance, enabling efficient gradient computation. The paper demonstrates the superiority of S-WMD over 26 competitive baselines across eight real-world text classification tasks, achieving state-of-the-art results in most cases.
Strengths:
1. Quality: The paper is technically sound, with a well-motivated problem and a clear methodology. The use of the Sinkhorn distance to approximate WMD gradients is a clever and practical solution to the computational challenges of optimizing WMD.
2. Clarity: The paper is well-organized, with detailed explanations of the methodology, including mathematical formulations and pseudo-code for the proposed algorithm. The inclusion of initialization strategies and batch gradient descent further enhances reproducibility.
3. Originality: The work is novel in its approach to incorporating supervision into WMD by learning both a linear transformation of word embeddings and word-specific importance weights. This combination of supervised metric learning with optimal transport is a significant contribution.
4. Significance: The results demonstrate the practical utility of S-WMD, with consistent improvements over a wide range of datasets and baselines. The method's efficiency and scalability make it a valuable tool for text classification tasks.
Weaknesses:
1. Initialization Sensitivity: The performance of S-WMD appears to depend heavily on the initialization of the metric, as noted in the experiments. Poor initialization can lead to suboptimal results, as seen in certain datasets like CLASSIC.
2. Dataset-Specific Performance: While S-WMD outperforms baselines on most datasets, it underperforms on datasets with longer documents (e.g., BBCSPORT and OHSUMED). This suggests that the method may not generalize as well to all types of text data.
3. Limited Discussion on Hyperparameter Sensitivity: The paper does not provide an in-depth analysis of the sensitivity of S-WMD to hyperparameters such as Î» in the Sinkhorn distance or the batch size in gradient descent.
Arguments for Acceptance:
- The paper addresses a significant limitation of WMD and provides a well-justified, efficient solution.
- The experimental results are compelling, with S-WMD achieving state-of-the-art performance on most datasets.
- The methodology is clearly presented and reproducible, with code made publicly available.
Arguments Against Acceptance:
- The method's reliance on good initialization and its variable performance across datasets could limit its applicability.
- The paper could benefit from a more detailed exploration of hyperparameter tuning and its impact on performance.
Recommendation:
Overall, this paper makes a strong contribution to the field of document distance metrics and supervised metric learning. The proposed S-WMD is both innovative and practical, with demonstrated effectiveness across diverse datasets. I recommend acceptance, with minor revisions to address the initialization sensitivity and hyperparameter analysis.