Review of the Paper
This paper addresses the problem of contextual semibandits, which is a generalization of bandit learning where the learner selects composite actions (e.g., lists of items) and receives semibandit feedback (e.g., individual item feedback). The authors propose two novel reductions of the problem to supervised learning, enabling the use of powerful supervised learning oracles. The first reduction, VCEE, applies to the setting where the linear mapping from feedback to reward is known, achieving a near-optimal regret bound and outperforming state-of-the-art approaches in experiments. The second reduction, EELS, tackles the previously unstudied setting where the mapping is unknown, achieving sublinear regret with a computationally efficient algorithm. The paper provides theoretical guarantees for both algorithms and demonstrates their empirical effectiveness on real-world learning-to-rank datasets.
The paper builds on prior work in contextual bandits and semibandits, such as the oracle-based approach of Agarwal et al. [1] and the LinUCB algorithm [19]. While previous work has focused on either non-contextual settings or parametric approaches, this paper extends the scope by introducing oracle-based methods for semibandits with both known and unknown mappings. The authors also provide a comprehensive comparison with existing methods, highlighting the advantages of their approach.
Strengths:
1. Technical Soundness: The paper is technically rigorous, with clear regret bounds and proofs. The theoretical results are well-supported by empirical evaluations.
2. Novelty: The reduction of contextual semibandits to supervised learning is innovative, particularly the EELS algorithm, which addresses the unexplored setting of unknown mappings.
3. Empirical Validation: The experiments on large-scale datasets convincingly demonstrate the advantages of VCEE over baseline methods, including LinUCB and Îµ-greedy approaches.
4. Generality: The use of supervised learning oracles makes the approach agnostic to the policy representation, allowing it to work with a variety of policy classes (e.g., linear models, tree ensembles).
Weaknesses:
1. Clarity: While the theoretical contributions are significant, the paper is dense and could benefit from better organization and clearer exposition, particularly in the technical sections (e.g., the derivation of regret bounds).
2. Limited Evaluation of EELS: The empirical evaluation focuses solely on VCEE, leaving the performance of EELS untested. This is a missed opportunity to validate the algorithm in practical scenarios.
3. Dependence on Oracle Efficiency: The approach relies heavily on the efficiency of the supervised learning oracle, which may not always be practical for large or complex policy classes.
4. Suboptimal T-dependence for EELS: While EELS achieves sublinear regret, its T-dependence is weaker than state-of-the-art results for known mappings, leaving room for improvement.
Arguments for Acceptance:
- The paper makes a significant theoretical contribution by introducing novel reductions and achieving strong regret bounds.
- The empirical results convincingly demonstrate the practical utility of VCEE.
- The work addresses a relevant and challenging problem in machine learning, with applications in recommendation systems and personalized medicine.
Arguments Against Acceptance:
- The lack of empirical evaluation for EELS limits the completeness of the paper.
- The clarity of presentation could be improved to make the results more accessible to a broader audience.
- The suboptimal T-dependence for EELS suggests that further refinement is needed.
Recommendation: Accept with minor revisions. The paper makes a strong contribution to the field of contextual semibandits, but the authors should improve the clarity of the exposition and include empirical results for EELS in a future iteration.