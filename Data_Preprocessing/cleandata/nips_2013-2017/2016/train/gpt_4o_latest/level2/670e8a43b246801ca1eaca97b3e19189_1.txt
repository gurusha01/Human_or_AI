This paper introduces the concept of the microclustering property and proposes a new class of Bayesian clustering models, termed Kolchin Partition (KP) models, to address the limitations of traditional infinitely exchangeable clustering models. The authors argue that existing models, such as finite mixture models, Dirichlet process (DP) mixtures, and Pitman–Yor process (PYP) mixtures, assume cluster sizes grow linearly with the dataset size, which is inappropriate for applications like entity resolution. By defining the microclustering property and sacrificing projectivity (rather than finite exchangeability), the proposed KP models ensure that cluster sizes grow sublinearly with the dataset size. Two specific KP models, the NBNB (negative binomial–negative binomial) and NBD (negative binomial–Dirichlet) models, are introduced, and their performance is evaluated on synthetic and real-world entity resolution datasets.
Strengths:
1. Novelty: The paper presents a novel and well-motivated concept—the microclustering property—which addresses a critical gap in clustering applications like entity resolution. The introduction of KP models is a significant innovation over existing approaches.
2. Theoretical Rigor: The paper provides a solid theoretical foundation for the microclustering property and demonstrates how KP models satisfy this property. The derivations and proofs (e.g., in appendices) are thorough and technically sound.
3. Practical Relevance: The application of KP models to entity resolution is well-justified, and the experiments demonstrate their utility in scenarios where traditional clustering models fail.
4. Empirical Validation: The authors compare KP models to DP and PYP models across multiple datasets, showing that KP models generally outperform their counterparts in recovering true cluster statistics and handling datasets with small cluster sizes.
Weaknesses:
1. Limited Scope of Experiments: While the experiments demonstrate the advantages of KP models, the datasets are relatively small in scale. It would be valuable to evaluate the scalability of KP models on larger datasets, especially given the computational challenges noted for the reseating algorithm.
2. Performance on Noisy Data: The models perform poorly on the Syria2000 and SyriaSizes datasets, which are noisy and sparse. While the authors acknowledge this limitation, further discussion on how KP models could be adapted or improved for such scenarios would strengthen the paper.
3. Clarity of Presentation: The paper is dense and assumes a high level of familiarity with Bayesian clustering and partition-based models. Some sections, particularly the derivations of the NBNB and NBD models, could benefit from clearer explanations or additional diagrams to aid understanding.
4. Comparison to Other Approaches: The paper focuses on comparing KP models to DP and PYP models but does not consider alternative clustering approaches (e.g., non-Bayesian methods) that might also address the microclustering problem.
Pro and Con Arguments for Acceptance:
Pro: The paper introduces a novel concept (microclustering) and a flexible class of models (KP models) that address a real-world limitation in clustering. The theoretical contributions are significant, and the empirical results demonstrate the practical utility of the proposed models.
Con: The paper's presentation is dense, and the experimental evaluation could be expanded to include larger datasets and alternative methods. Additionally, the models struggle with noisy datasets, raising questions about their robustness.
Recommendation:
Overall, this paper makes a strong contribution to the field of Bayesian clustering and is well-suited for the NIPS audience. While there are areas for improvement, the novelty, theoretical rigor, and practical relevance of the work outweigh its weaknesses. I recommend acceptance with minor revisions, particularly to improve clarity and expand the discussion of limitations.