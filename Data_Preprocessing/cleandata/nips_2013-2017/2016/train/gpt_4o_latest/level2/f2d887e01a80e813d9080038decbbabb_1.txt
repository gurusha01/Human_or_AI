This paper addresses the challenging problem of unsupervised risk estimation, proposing a novel framework that estimates a model's test error from unlabeled data under distributional shifts. The authors leverage conditional independence assumptions and the method of moments to estimate the risk without requiring the test distribution to be close to the training distribution or assuming a parametric family. The framework extends to structured output settings, such as conditional random fields, and supports gradient-based unsupervised learning. 
Strengths:
1. Novelty and Originality: The paper introduces a significant innovation in unsupervised risk estimation by relaxing restrictive assumptions like covariate shift and parametric model specification. The use of the method of moments to exploit conditional independence is particularly novel, extending prior work in latent-variable models to more complex and continuous loss functions.
2. Technical Soundness: Theoretical results, including Theorem 1, are rigorously presented and supported by clear mathematical derivations. The sample complexity analysis is thorough, and the authors provide insights into the role of key parameters such as the rank of risk matrices and class probabilities.
3. Practical Utility: The proposed method has broad applicability, encompassing a wide family of loss functions and structured prediction tasks. The ability to perform unsupervised domain adaptation and learning with minimal labeled data is highly relevant for real-world scenarios.
4. Empirical Validation: The experiments on a modified MNIST dataset demonstrate the effectiveness of the proposed approach in both risk estimation and unsupervised domain adaptation. The results are compelling, showing robustness to significant train-test distribution shifts.
5. Clarity and Organization: The paper is well-structured, with clear explanations of the framework, theoretical results, and extensions. The inclusion of illustrative examples (e.g., logistic regression, neural networks) aids understanding.
Weaknesses:
1. Assumption Limitations: The reliance on the three-view conditional independence assumption is a significant limitation. While the authors acknowledge this and propose potential extensions, the assumption may not hold in many real-world datasets, limiting the generalizability of the approach.
2. Empirical Scope: The experiments are restricted to a synthetic modification of MNIST. Testing the method on more diverse and naturally occurring datasets would strengthen the empirical claims and demonstrate broader applicability.
3. Computational Complexity: While the authors discuss the scalability of their algorithm, tensor decomposition and moment estimation for high-dimensional data may still pose practical challenges. A more detailed discussion of runtime and memory requirements would be beneficial.
4. Seed Model Dependency: The framework requires a seed model for unsupervised learning, which may not always be available or easy to obtain in practice. The paper could explore alternative strategies to mitigate this dependency.
Recommendation:
This paper makes a strong theoretical and practical contribution to the field of unsupervised learning and domain adaptation. Despite the limitations of the three-view assumption and the need for broader empirical validation, the novelty and rigor of the proposed approach are commendable. I recommend acceptance, provided the authors address the empirical scope and computational concerns in the final version.
Arguments Pro Acceptance:
- Novel and theoretically sound framework for unsupervised risk estimation.
- Broad applicability to various loss functions and structured prediction tasks.
- Empirical results demonstrate robustness to train-test shifts.
Arguments Against Acceptance:
- Limited empirical evaluation on real-world datasets.
- Strong reliance on the three-view assumption, which may not generalize well.
Overall, this paper advances the state of the art in unsupervised learning and provides a foundation for future research in risk estimation under weak assumptions.