This paper addresses the problem of learning in the Limited Attribute Observation (LAO) setting, where algorithms can only access a restricted number of attributes per example. The authors present novel information-theoretic lower bounds for regression (with absolute and squared loss) and classification (with hinge loss), demonstrating fundamental limits on the precision achievable in this setting. Complementing these theoretical results, the paper introduces a general-purpose algorithm that achieves near-optimal precision in regression and classification tasks with missing data.
Strengths:
1. Novel Contributions: The paper makes significant theoretical contributions by establishing the first lower bounds for regression with absolute loss and hinge loss classification under the LAO model. These results fill gaps in prior work, such as Hazan and Koren (2016), and extend our understanding of the inherent limitations of learning with restricted attribute access.
2. Rigorous Theoretical Analysis: The proofs are mathematically rigorous and well-structured. The authors leverage subgradient analysis and information-theoretic arguments to establish tight lower bounds for regression and exponential lower bounds for classification.
3. General-Purpose Algorithm: The proposed algorithm is a practical addition, offering a method to achieve bounded error in the LAO setting. The analysis of its performance, particularly the dependence on the number of observed attributes \(k\) and the dimensionality \(d\), is thorough and aligns with the theoretical bounds.
4. Relevance and Impact: The results have broad implications for real-world applications, such as medical diagnosis, where data collection is costly or invasive. The findings also extend to the related setting of learning with missing data, further enhancing their significance.
Weaknesses:
1. Limited Experimental Validation: While the theoretical results are compelling, the paper lacks empirical validation of the proposed algorithm. Demonstrating its performance on synthetic or real-world datasets would strengthen the practical impact of the work.
2. Exponential Gap for Classification: The exponential lower bound for hinge loss classification leaves a substantial gap between the lower and upper bounds. While this is acknowledged as future work, it limits the completeness of the theoretical contributions.
3. Clarity of Presentation: The paper is dense with technical details, which may hinder accessibility for a broader audience. Simplifying some proofs or providing more intuitive explanations could improve clarity.
4. Comparison to Related Work: While the paper references prior work, a more detailed comparison of the proposed algorithm's performance against existing methods (e.g., AERR) would provide better context for its contributions.
Arguments for Acceptance:
- The paper provides strong theoretical advancements in the LAO setting, addressing open questions and extending prior work.
- The proposed algorithm is a meaningful contribution that complements the theoretical results and has potential practical applications.
- The work is relevant to the NIPS community, particularly in the areas of learning with missing or incomplete data.
Arguments Against Acceptance:
- The lack of experimental results limits the practical validation of the proposed algorithm.
- The exponential gap for hinge loss classification leaves room for further refinement of the theoretical results.
Recommendation:
I recommend acceptance with minor revisions. The paper makes substantial theoretical contributions and proposes a promising algorithm, but it would benefit from experimental validation and improved clarity. Addressing these points in a future revision would significantly enhance the paper's impact.