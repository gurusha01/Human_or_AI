The paper presents a novel method, Bounding Divergences with REverse Annealing (BREAD), to evaluate the accuracy of Markov chain Monte Carlo (MCMC)-based posterior inference algorithms. The authors extend the bidirectional Monte Carlo (BDMC) framework to bound the symmetrized KL divergence (Jeffreys divergence) between approximate samples and the true posterior distribution. The method is integrated into probabilistic programming languages WebPPL and Stan, and validated on various models and datasets. The paper also proposes a protocol for using BREAD to evaluate inference quality on real-world data and demonstrates its utility in guiding model representation choices and debugging probabilistic programming implementations.
Strengths:
1. Novelty and Significance: The paper addresses a critical challenge in probabilistic inferenceâ€”quantitatively evaluating the quality of approximate posterior samples. By extending BDMC to bound Jeffreys divergence, the authors provide a rigorous and practical tool for assessing inference accuracy, which is particularly valuable for black-box probabilistic programming systems.
2. Technical Rigor: The derivation of bounds on Jeffreys divergence is mathematically sound, and the authors validate the tightness of these bounds on toy distributions. The use of simulated data to rigorously evaluate inference algorithms is a notable contribution.
3. Practical Integration: The integration of BREAD into WebPPL and Stan demonstrates the method's applicability to real-world probabilistic programming frameworks. The experiments highlight its potential to guide model representation choices and uncover implementation bugs, showcasing its practical utility.
4. Comprehensive Validation: The paper validates BREAD across multiple dimensions, including consistency between real and simulated data, robustness to approximate hyperparameter sampling, and its ability to provide actionable insights into model representation tradeoffs.
Weaknesses:
1. Scope of Applicability: While BREAD is rigorous for simulated data, its reliance on exact posterior samples limits its direct applicability to real-world datasets. The proposed protocol for real-world data evaluation is heuristic and may not generalize across all scenarios.
2. Computational Overhead: The method involves running both forward and reverse annealed importance sampling (AIS) chains, which can be computationally expensive, particularly for large-scale models or datasets.
3. Limited Comparison to Related Work: Although the paper discusses related methods like convergence diagnostics and subjective divergence, it does not provide empirical comparisons to these approaches, leaving the relative advantages of BREAD somewhat unclear.
4. Clarity and Accessibility: The paper is dense and assumes significant familiarity with MCMC, AIS, and probabilistic programming. While technically sound, the presentation could be improved to make the contributions more accessible to a broader audience.
Recommendation:
I recommend acceptance of this paper, as it provides a significant and well-validated contribution to the evaluation of MCMC-based inference algorithms. The method is novel, rigorous, and practically useful, particularly for probabilistic programming languages. However, the authors should consider addressing the computational overhead and providing clearer guidance on applying BREAD to real-world datasets in the final version. Additionally, a more detailed comparison to related methods would strengthen the paper's positioning within the broader literature. 
Pro and Con Arguments:
Pros:
- Rigorous method for evaluating inference quality.
- Practical integration into widely used probabilistic programming languages.
- Demonstrated utility in guiding model design and debugging.
Cons:
- Limited applicability to real-world datasets without exact posterior samples.
- Computationally expensive.
- Dense presentation that may hinder accessibility.