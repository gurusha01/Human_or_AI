Review
This paper introduces SPALS, a novel sampling-based alternating least squares (ALS) method for low-rank tensor CANDECOMP/PARAFAC (CP) decomposition. The key contribution lies in leveraging statistical leverage score bounds of the Khatri-Rao product (KRP) matrix to enable efficient sampling, leading to sublinear per-iteration computation time. By connecting sampling-based regression techniques with low-rank tensor factorization, the authors propose an algorithm that achieves state-of-the-art computational efficiency while maintaining provable approximation guarantees. The work builds on established results in randomized numerical linear algebra, integrating them into tensor analytics in a technically sound manner.
The strengths of the paper include its technical rigor and practical relevance. The proposed method is well-motivated, addressing the computational bottlenecks of ALS for large-scale tensor decomposition. The theoretical results, particularly Theorems 3.2 and 3.3, provide insightful bounds on leverage scores for KRPs, enabling efficient sampling. Empirical evaluations on both synthetic and real-world datasets, such as the Amazon review tensor, demonstrate significant speedups over existing methods, with competitive approximation accuracy. The algorithm's ability to handle large sparse tensors efficiently is a notable advancement, making it highly relevant for modern big data applications.
However, the paper has several weaknesses. While the integration of leverage score sampling into tensor decomposition is novel, the contribution is incremental, primarily refining existing randomized ALS techniques. Theorems 3.2 and 3.3, though insightful, are relatively straightforward extensions of known results. Additionally, the phrase "The estimation is tight" (line 174) is misleading and should clarify that tightness is up to a constant factor \( R \). Clarity issues are prevalent throughout the manuscript, with numerous typos, grammatical errors, and awkward phrasing detracting from readability. For example, the table between lines 295 and 296 is not explicitly defined, and the term "sketch" in (a) lacks immediate clarity regarding its reference to prior work [37]. These issues hinder the accessibility of the paper to a broader audience.
Arguments for Acceptance:
1. The paper addresses a significant computational challenge in tensor decomposition, with clear practical implications.
2. The proposed method demonstrates strong theoretical guarantees and empirical performance.
3. The integration of leverage score sampling into ALS is a meaningful contribution to the field.
Arguments Against Acceptance:
1. The contribution is incremental, primarily refining existing techniques rather than introducing fundamentally new concepts.
2. Clarity issues, including typos and vague phrasing, reduce the paper's overall quality and accessibility.
3. Some theoretical results, while useful, lack depth and novelty.
Recommendation:
I recommend acceptance with minor revisions. While the contribution is incremental, the paper provides a valuable improvement to tensor decomposition methods, with strong empirical results and practical relevance. The authors should address the clarity issues, correct typos, and refine the presentation to enhance the paper's accessibility.