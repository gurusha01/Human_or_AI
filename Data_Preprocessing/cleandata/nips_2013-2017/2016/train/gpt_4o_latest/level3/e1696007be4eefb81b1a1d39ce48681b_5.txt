This paper addresses the computational challenges of parameter estimation in generalized linear models (GLMs) when the number of observations \( n \) far exceeds the number of predictors \( p \) (\( n \gg p \)). The authors propose a novel algorithm, the Scaled Least Squares (SLS) estimator, which leverages the approximate proportionality between GLM coefficients and ordinary least squares (OLS) coefficients. This relationship, while known in specific contexts, is extended here to general random design GLMs with non-Gaussian predictors. The paper provides theoretical guarantees for the algorithm, demonstrates its computational efficiency, and validates its performance through extensive experiments on synthetic and real-world datasets.
The paper is well-written, logically structured, and technically sound. The theoretical derivations appear correct, and the authors provide rigorous proofs to support their claims. The proposed SLS algorithm is particularly noteworthy for its computational efficiency, achieving up to cubic convergence rates with a per-iteration cost of \( O(n) \), which is significantly cheaper than traditional batch optimization methods by at least a factor of \( O(p) \). The experimental results convincingly demonstrate that SLS achieves comparable accuracy to the maximum likelihood estimator (MLE) while requiring substantially less computational time, especially in the large-scale regime (\( n \gg p \)).
Strengths:
1. Quality: The paper provides a strong theoretical foundation for the proposed method, including error bounds and convergence guarantees. The experiments are thorough and demonstrate the practical utility of the algorithm.
2. Clarity: The paper is clearly written and well-organized, with sufficient detail to allow reproduction of the results. The inclusion of both theoretical and empirical analyses strengthens its impact.
3. Originality: While the proportionality relationship between GLM and OLS coefficients has been noted in specific cases, the paper extends this idea to a broader class of GLMs and demonstrates its computational implications. This represents a novel contribution.
4. Significance: The proposed method addresses a critical bottleneck in large-scale GLM estimation, offering a practical alternative to computationally expensive MLE methods. This has significant implications for both research and applied domains.
Weaknesses:
1. The paper could benefit from a more detailed discussion of potential limitations, such as the impact of highly correlated predictors or scenarios where regularization is essential.
2. While the experiments are comprehensive, additional comparisons with state-of-the-art methods beyond the ones included (e.g., more recent advances in stochastic optimization) could further strengthen the empirical evaluation.
Arguments for Acceptance:
- The paper provides a novel and computationally efficient solution to a well-known problem in large-scale GLM estimation.
- The theoretical contributions are rigorous and well-supported by empirical evidence.
- The proposed method has practical significance, with potential applications in a wide range of fields.
Arguments Against Acceptance:
- The paper does not extensively address potential limitations or edge cases where the proposed method might underperform.
- Comparisons with additional state-of-the-art methods could enhance the evaluation.
Overall, this paper makes a solid contribution to the field and aligns well with the scope of the conference. I recommend it for acceptance.