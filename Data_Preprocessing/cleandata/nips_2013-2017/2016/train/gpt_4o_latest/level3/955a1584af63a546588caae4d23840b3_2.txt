This paper addresses the problem of learning in the Limited Attribute Observation (LAO) model, where algorithms are restricted to observing a fixed number of attributes per example. The authors provide novel theoretical contributions, including tightened lower bounds for regression and classification tasks, and propose an algorithm that achieves precision limits close to these bounds for regression. The work builds on prior research in the LAO setting, such as that by Ben-David and Dichterman (1998) and Hazan and Koren (2012), while resolving open questions about the limits of achievable precision for certain loss functions.
Strengths:  
The paper is technically sound and provides significant theoretical advancements. The derived lower bounds for regression with absolute loss and classification with hinge loss are novel and non-trivial. The authors complement these results with a general-purpose algorithm that achieves precision bounds up to a polynomial factor in dimensionality for regression, demonstrating the practical relevance of their theoretical findings. The manuscript is well-written, with clear exposition of the problem, rigorous proofs, and a logical flow of ideas. The results for regression are particularly impactful, as they close gaps in prior work and provide a near-complete characterization of achievable precision in the LAO model. The paper also addresses an important and practical problem, with potential applications in fields like medical diagnosis, where data collection is often constrained.
Weaknesses:  
The classification results are less compelling compared to regression. While the lower bounds for hinge loss are novel, there is an exponential gap between these bounds and the precision limits of the proposed algorithm. This gap weakens the practical applicability of the classification results and leaves room for improvement. Additionally, Theorem 5, which establishes the lower bound for hinge loss, is presented with insufficient commentary. Its weaker results compared to Theorems 1 and 3 are not adequately discussed, leaving the reader with unanswered questions about its implications and limitations. The authors should clarify this in the main paper to ensure a balanced presentation of their contributions.
Pro/Con Arguments for Acceptance:  
- Pro: Novel and rigorous theoretical contributions for regression and classification in the LAO model.  
- Pro: Resolves open questions in regression with absolute loss and provides a complementary algorithm.  
- Pro: Well-written and organized, with clear exposition of proofs and results.  
- Con: Exponential gap in classification results limits practical impact.  
- Con: Insufficient discussion of Theorem 5 and its weaker nature.
Recommendation:  
I recommend acceptance of this paper, as it makes a strong theoretical contribution to the field and resolves important open questions in the LAO model. However, I strongly encourage the authors to expand the discussion of Theorem 5 in the main paper, addressing its limitations and contextualizing its weaker results compared to other theorems. Additionally, future work should aim to bridge the exponential gap in classification results to enhance their practical relevance.