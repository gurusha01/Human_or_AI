This paper presents a novel information-theoretic framework for modeling digital crowdsourcing, focusing on deriving lower bounds for the number of queries required per task to achieve a given error probability. Workers are modeled as noisy channels, specifically symmetric discrete memoryless channels (MSC) and spammer-hammer channels (SHC(q)), and the analysis considers both cases where workers' skill levels are known and unknown to the crowdsourcer. The taskmaster assigns tasks uniformly without prior knowledge of worker skills, and the paper provides a necessary condition for the minimum query rate for k-ary incidence coding in SHC(q) worker pools. The results are positioned as practical tools for designing and pricing crowdsourcing projects by determining minimum query rates for desired error probabilities.
Strengths:  
The paper introduces a fresh perspective by applying an information-theoretic framework to crowdsourcing, a domain that has not been extensively analyzed from this angle. This originality is a significant contribution, as it provides fundamental insights into the trade-offs between query budgets and task fidelity. The theoretical results are well-motivated and offer practical implications for optimizing crowdsourcing systems, particularly in determining query rates and pricing strategies. The paper is well-written and organized, making it accessible to readers with a background in information theory and crowdsourcing. The inclusion of k-ary incidence coding as a query scheme is a thoughtful addition, and the analysis of its performance under SHC(q) worker models is compelling.
Weaknesses:  
The paper lacks experimental validation or simulations to compare the proposed theoretical bounds with existing schemes, such as those used on platforms like Amazon Mechanical Turk (AMT). This omission limits the ability to assess the practical applicability of the results. While the theoretical framework is robust, the absence of empirical evidence leaves questions about its real-world performance unanswered. Additionally, Sections 2.4 and 3.1 are overly detailed and could be shortened or replaced with proof sketches to improve readability and focus. The reviewer did not evaluate the appendix, so the rigor of the proofs cannot be commented on.
Pro and Con Arguments for Acceptance:  
- Pro: The paper provides a novel and theoretically sound framework for analyzing crowdsourcing, offering valuable insights into query budget-fidelity trade-offs. It is well-written and addresses a practical problem with significant implications for designing efficient crowdsourcing systems.  
- Con: The lack of experimental validation is a notable drawback, as it prevents a direct comparison with existing methods. Some sections are overly verbose, which could hinder readability for a broader audience.
Recommendation:  
The paper is a strong theoretical contribution to the field of crowdsourcing and information theory. However, its lack of empirical validation is a limitation. If accepted, the authors should be encouraged to include simulations or experiments in future work to strengthen the practical relevance of their results. Overall, I recommend acceptance with minor revisions to improve clarity and address the lack of empirical comparisons.