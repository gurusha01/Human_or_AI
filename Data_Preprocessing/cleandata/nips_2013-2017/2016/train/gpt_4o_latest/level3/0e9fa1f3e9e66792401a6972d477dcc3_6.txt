The paper explores the application of the bidirectional Monte Carlo (BDMC) method to evaluate MCMC-based posterior inference algorithms, focusing on bounding the symmetrized KL divergence (Jeffreys divergence) between approximate and true posterior distributions. The authors integrate their method, Bounding Divergences with Reverse Annealing (BREAD), into two probabilistic programming languages, WebPPL and Stan, and validate it on several models and datasets. While the work demonstrates the utility of BREAD in diagnosing inference quality, comparing model representations, and even debugging probabilistic programming implementations, it primarily applies existing techniques rather than introducing novel methodologies.
Strengths
The paper provides a clear and thorough explanation of BDMC and its extension to evaluate posterior inference quality. The integration of BREAD into WebPPL and Stan demonstrates its practical utility, and the experimental results validate its effectiveness in bounding Jeffreys divergence and diagnosing inference quality on both simulated and real-world data. The authors also highlight a valuable use case by comparing collapsed and uncollapsed model representations in probabilistic programming languages, offering insights into trade-offs between computational efficiency and convergence speed. Furthermore, the debugging example underscores the potential of BREAD as a tool for identifying implementation errors, which is particularly relevant given the growing number of probabilistic programming frameworks.
Weaknesses
The primary limitation of this work is its lack of originality. The paper largely builds on previously published results on BDMC [GGA15] and applies them to existing probabilistic programming languages without introducing significant new theoretical contributions. While the integration of BREAD into WebPPL and Stan is useful, it does not advance the state of the art in a meaningful way. Additionally, the paper's focus on implementation and validation makes it more suitable for an MCMC-focused workshop than a general AI conference like NeurIPS, where originality and broader significance are emphasized. The related work section could also be improved by providing a more comprehensive comparison to alternative methods for evaluating MCMC inference quality.
Pro and Con Arguments for Acceptance
Pros:
- Clear and well-written exposition of BDMC and its application.
- Practical integration into widely used probabilistic programming languages.
- Demonstrates utility in debugging and model representation analysis.
- Rigorous experimental validation on diverse models and datasets.
Cons:
- Lacks originality; primarily applies known techniques without significant innovation.
- Limited significance for the broader AI community; the work is more relevant to MCMC specialists.
- Better suited for a specialized workshop rather than a general AI conference.
Recommendation
While the paper is technically sound and provides practical insights, its lack of originality and narrow focus make it less suitable for NeurIPS. I recommend rejection for this venue but encourage submission to an MCMC-focused workshop where the work would be more appropriately appreciated.