The paper proposes a novel unsupervised domain adaptation technique, Residual Transfer Network (RTN), which introduces residual connections to model the target classifier as a sum of the source classifier and a residual function. This approach differs from recent deep adaptation methods by explicitly relaxing the shared-classifier assumption and avoiding the need to jointly learn source and target models. Instead, it bridges the source and target classifiers through residual layers, enabling adaptation in a more flexible and interpretable manner. The method also incorporates Maximum Mean Discrepancy (MMD) for feature alignment, similar to prior methods like DAN and DDC, while introducing entropy minimization to refine classifier adaptation.
Strengths:  
The paper presents a novel and simple idea of leveraging residual connections for classifier adaptation, which is both theoretically sound and practically relevant. The residual learning framework is well-motivated, drawing inspiration from deep residual networks, and effectively addresses the classifier mismatch problemâ€”a limitation of many prior domain adaptation methods. The integration of residual connections, entropy loss, and MMD loss into a unified framework is compelling, and the method is shown to outperform state-of-the-art approaches on standard benchmarks. The paper is well-written, with clear explanations of the methodology and experimental setup, making it accessible to readers. Additionally, the ablation studies provide valuable insights into the contributions of individual components, particularly highlighting the importance of entropy minimization and residual connections.
Weaknesses:  
While the residual connection is novel, the MMD loss component is not, as it has been extensively used in prior work. The entropy loss, though impactful in experiments, is not as thoroughly explained as the residual connection, leaving some ambiguity about its precise role in the adaptation process. Furthermore, the contribution of the residual connection to the overall performance improvement, relative to the other components, is not entirely clear. The experimental results, while promising, rely heavily on standard benchmarks, and the paper could benefit from additional real-world applications or more diverse datasets to better demonstrate the generalizability of the approach.
Pro and Con Arguments for Acceptance:  
Pro:  
1. Novel and well-motivated use of residual connections for classifier adaptation.  
2. Clear and well-structured presentation of the methodology.  
3. Strong empirical results, outperforming state-of-the-art methods.  
4. Comprehensive ablation studies that validate the importance of individual components.  
Con:  
1. Limited novelty in the use of MMD loss.  
2. Insufficient explanation of entropy loss and its role in the framework.  
3. Lack of clarity on the relative contribution of the residual connection to overall performance.  
4. Experiments are confined to standard benchmarks, with limited exploration of real-world scenarios.  
Recommendation:  
Overall, the paper makes a meaningful contribution to the field of domain adaptation by addressing a key limitation of prior methods and introducing a novel residual learning framework. Despite some minor weaknesses, the strengths outweigh the limitations, and the work is likely to inspire further research in this area. I recommend acceptance with minor revisions to clarify the entropy loss and better contextualize the contributions of the residual connection.