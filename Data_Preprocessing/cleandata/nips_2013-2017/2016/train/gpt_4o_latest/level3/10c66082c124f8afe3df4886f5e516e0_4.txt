The paper introduces a supervised extension of the Word Mover's Distance (WMD), termed Supervised Word Mover's Distance (S-WMD), which incorporates supervision into the document distance metric by learning a linear transformation of word embeddings and reweighting word distributions. The authors aim to improve the WMD metric for text classification tasks by aligning document distances with semantic labels. The proposed method leverages an efficient approximation of the WMD gradient using entropy-regularized optimal transport, enabling scalable training. Experimental results on eight datasets demonstrate that S-WMD outperforms numerous baselines, including unsupervised WMD and other supervised metric learning methods.
Strengths:
1. Clarity and Writing: The paper is well-written and organized, with a clear explanation of the methodology and a thorough review of related work. The inclusion of mathematical derivations and pseudo-code enhances reproducibility.
2. Experimental Validation: The authors evaluate S-WMD on diverse datasets, providing robust evidence of its effectiveness. The results consistently show superior performance compared to 26 baselines, highlighting the practical utility of the method.
3. Efficiency: The use of entropy-regularized optimal transport and batch gradient descent significantly reduces computational overhead, making the approach scalable for real-world applications.
4. Visualization: The t-SNE visualizations and word importance analysis provide intuitive insights into the model's behavior, enhancing interpretability.
Weaknesses:
1. Motivation for Reweighting: The rationale for reweighting word distributions is insufficiently justified. Altering word importance could distort the original semantic meaning of documents, and the authors do not provide a theoretical or empirical basis for this design choice.
2. Incremental Contribution: While the supervised extension of WMD is novel, the contribution feels incremental. The method builds on existing concepts like WMD, linear metric learning, and entropy-regularized transport, without introducing fundamentally new ideas.
3. Handling New Documents: The paper does not address how the reweighting factor is determined for unseen documents, which is critical for practical deployment.
4. Ambiguity in Terminology: The term "semantic difference" in the abstract is vague and conflates document labels with semantic meaning. A clearer definition is necessary to avoid confusion.
Arguments for Acceptance:
- The paper provides a well-executed supervised extension to a widely-used unsupervised metric, demonstrating significant performance gains.
- The methodology is computationally efficient and applicable to a variety of text classification tasks.
- The experimental results are comprehensive and compelling.
Arguments Against Acceptance:
- The contribution is incremental and lacks groundbreaking innovation.
- Key design choices, such as reweighting word distributions, are not adequately justified.
- The paper does not address critical practical concerns, such as handling unseen documents.
Recommendation:
The paper is a strong submission overall, but its incremental nature and lack of clarity in certain aspects warrant revisions. If the authors address the concerns regarding reweighting motivation, unseen document handling, and terminology, the paper would be a valuable contribution to the field. I recommend conditional acceptance pending these improvements.