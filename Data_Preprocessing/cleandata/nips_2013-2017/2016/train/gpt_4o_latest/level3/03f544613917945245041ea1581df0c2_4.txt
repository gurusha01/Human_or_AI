The paper introduces Stochastic Gradient Richardson-Romberg Langevin Dynamics (SGRRLD), a novel SG-MCMC algorithm leveraging Richardson-Romberg (RR) extrapolation to improve convergence rates in terms of bias and mean squared error (MSE). By running two parallel chains with different step sizes, SGRRLD aims to reduce bias while maintaining reasonable variance. The authors provide rigorous theoretical analysis, demonstrating that SGRRLD achieves higher convergence rates than traditional SG-MCMC methods, including SGLD, and supports these claims with synthetic and real-world experiments.
Strengths:
1. Theoretical Contributions: The paper offers a solid theoretical foundation, including asymptotic consistency, a central limit theorem, and non-asymptotic bounds for bias and MSE. The derivation of convergence rates (e.g., \(O(K^{-4/5})\)) is a significant improvement over existing methods like SGLD (\(O(K^{-2/3})\)).
2. Practical Implementation: The proposed scheme is straightforward to implement, requiring minimal modifications to existing SG-MCMC frameworks. Its compatibility with parallel and distributed architectures is a notable advantage.
3. Experimental Validation: The experiments, particularly on synthetic data and large-scale matrix factorization, convincingly demonstrate the practical benefits of SGRRLD. The results show reduced bias and MSE compared to SGLD, with significant computational efficiency gains.
4. Generality: The method is applicable to a wide range of SG-MCMC algorithms, as shown by its extension to SGHMC.
Weaknesses:
1. Convergence Rate Derivations: While the theoretical results are robust, the derivation of specific convergence rates (e.g., for \(\alpha = 0.2\) and \(\alpha = 1/3\)) lacks clarity. The observed discrepancies in Figure 3, where the best convergence is for \(\alpha = 0.2\) instead of the stated \(\alpha = 1/3\), raise questions about the accuracy of these claims.
2. Experimental Fairness: The matrix factorization experiments may not provide a fair comparison. SGLD's runtime should be adjusted by a factor of 2/3 to account for SGRRLD's computational overhead from running two chains.
3. Fluctuations in Results: The optimal curve in Figure 3 fluctuates significantly, potentially misaligning with the theoretical rate for \(\alpha = 0.2\). This warrants further clarification.
4. Unexplained Assumptions: The paper does not adequately explain why the term \(1/K\gamma\) does not dominate for SGLD when the step size is small, particularly in Figure 2.
5. Minor Issues: Undefined symbols (\(RR\), \(\Gamma_K\)), unclear smoothness assumptions for \(f\), and incorrect figure references detract from the paper's clarity. Formatting improvements, such as bolding vectors, would enhance readability.
Arguments for Acceptance:
- The paper addresses a critical limitation of SG-MCMC methods (bias) with a novel and theoretically sound approach.
- The proposed method is practical, easy to implement, and compatible with parallel architectures.
- Experimental results demonstrate clear advantages over existing methods.
Arguments Against Acceptance:
- Concerns about the fairness of experimental comparisons and the clarity of theoretical derivations need to be addressed.
- Minor but numerous presentation issues reduce the paper's overall polish.
Recommendation:
Accept with minor revisions. The paper makes a significant contribution to the field of SG-MCMC, but the authors should clarify the derivation of convergence rates, address experimental fairness concerns, and improve the paper's clarity and presentation.