This paper introduces Conditional Generative Moment-Matching Networks (CGMMN), which extend the Generative Moment-Matching Networks (GMMN) framework to model conditional distributions using the Conditional Maximum Mean Discrepancy (CMMD) criterion. By leveraging reproducing kernel Hilbert space (RKHS) embeddings, the authors propose a novel approach to learning conditional distributions in a deep generative model. The paper demonstrates the utility of CGMMN across diverse tasks, including predictive modeling, contextual generation, and Bayesian dark knowledge distillation.
Strengths:
1. Novelty and Extension of GMMNs: The paper makes a significant contribution by extending GMMNs to conditional settings, addressing a gap in the literature. The use of CMMD to measure differences between conditional distributions is a theoretically sound and innovative approach.
2. Wide Applicability: The authors evaluate CGMMN on a variety of tasks, showcasing its flexibility. The inclusion of Bayesian dark knowledge distillation is particularly interesting and highlights the model's potential for practical applications.
3. Theoretical Foundation: The paper provides a rigorous theoretical framework, including detailed derivations of CMMD and its connections to MMD. This strengthens the credibility of the proposed method.
4. Experimental Results: The empirical evaluation on datasets such as MNIST, SVHN, and Yale Face demonstrates competitive performance in predictive and generative tasks. The inclusion of qualitative results, such as generated images, adds value.
Weaknesses:
1. Clarity Issues: The paper assumes centered data in RKHS (i.e., $\muX$ and $\muY$ are zero), which is unconventional. This assumption is not adequately justified, and its implications for gradient computation and experiments remain unclear. The missing term related to $\muX$ and $\muY$ in the definition of $\hat{C}_{Y|X}$ also requires clarification.
2. Performance Gap: While CGMMN shows competitive results, its predictive performance lags behind state-of-the-art methods like CMMVA in certain tasks. This raises questions about its practical utility in scenarios where predictive accuracy is critical.
3. Lack of Comparisons: The paper does not compare CGMMN with other conditional generative models, such as Conditional GANs or Conditional Variational Autoencoders. This omission makes it difficult to assess CGMMN's generative performance relative to existing methods.
4. Minor Typos: The manuscript contains minor typographical errors, such as "Frobeniu norm" and "an universal." While these do not detract from the core contributions, they affect the overall polish of the paper.
Recommendation:
After the author rebuttal, the key concerns regarding the missing terms and assumptions in RKHS were addressed, improving the clarity of the method. However, the lack of comparisons with other conditional generative methods remains a limitation. Overall, the paper presents a novel and technically sound contribution with broad applicability, though its practical impact is somewhat diminished by the performance gap and limited comparisons.
Arguments for Acceptance:
- The paper introduces a novel extension of GMMNs to conditional settings, which is a meaningful contribution.
- The theoretical framework is well-developed and supported by empirical results.
- CGMMN demonstrates flexibility across diverse tasks.
Arguments Against Acceptance:
- The predictive performance is not state-of-the-art, and the generative performance lacks sufficient benchmarking.
- Certain assumptions and missing terms in the theoretical framework were initially unclear, though these were addressed in the rebuttal.
Final Score: 7/10 (Accept with minor revisions)  
The paper is a valuable addition to the field, but future work should focus on improving predictive performance and providing more comprehensive comparisons with other conditional generative methods.