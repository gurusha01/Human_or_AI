The paper presents a novel supervised extension of the Word Mover's Distance (WMD), termed Supervised Word Mover's Distance (S-WMD), for metric learning in textual documents. By introducing two learning components—a linear transformation matrix \( A \) and word importance weights \( w \)—the authors aim to adapt the WMD metric to better reflect semantic similarities in labeled datasets. The proposed method is evaluated across eight real-world text classification tasks, demonstrating consistent improvements over 26 competitive baselines.
Strengths:
1. Novelty and Contribution: The paper effectively bridges the gap between unsupervised WMD and supervised metric learning, leveraging supervision to improve document classification. The introduction of word importance weights \( w \) alongside a linear transformation \( A \) is a meaningful innovation that adds flexibility to the metric.
2. Efficiency: The authors address the computational challenges of WMD by using the Sinkhorn distance for efficient gradient computation, making the method scalable to larger datasets.
3. Comprehensive Evaluation: The method is tested on a diverse set of datasets and compared against a wide range of baselines, including unsupervised and supervised methods. The results show that S-WMD achieves state-of-the-art performance on most datasets.
4. Practical Insights: The visualization of learned word importance weights and t-SNE embeddings provides intuitive insights into the model's behavior and its ability to cluster semantically similar documents.
Weaknesses:
1. Clarity of Key Equations: The intuition behind Equation (5) and the contribution of each component (\( A \) and \( w \)) to the observed improvements could be better clarified. While the paper provides mathematical details, a clearer explanation of how these components interact to improve classification would enhance accessibility.
2. Comparative Context: Although the method is evaluated against numerous baselines, comparisons with simpler classifiers (e.g., logistic regression or SVMs) are missing. This would provide additional context for assessing the practical benefits of S-WMD.
3. Ambiguities in Tables: Table 3 lacks sufficient detail on training times, and Table 2 uses unclear terminology. Additionally, the choice of the kNN parameter \( k \) is not explained, which could impact reproducibility.
4. Conceptual Similarity Claims: The paper claims that S-WMD captures conceptual similarity better than WMD, but this assertion would benefit from more rigorous justification or examples.
Suggestions for Improvement:
- Provide a more intuitive explanation of Equation (5) and its components.
- Include comparisons with simpler supervised classifiers to contextualize the performance gains.
- Clarify the missing details in Tables 2 and 3, and provide justification for the choice of \( k \) in kNN.
- Expand on the differences in \( \lambda \) values used in Equation (2) and their impact on performance.
Recommendation:
The paper makes a significant contribution to supervised metric learning for text documents and demonstrates strong empirical results. However, the clarity of certain key components and the inclusion of simpler baselines could strengthen its impact. I recommend acceptance with minor revisions to address the issues of clarity and comparative context.