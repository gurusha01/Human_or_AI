Review of the Paper
Summary:
This paper introduces the "low approximate regret" property, a relaxation of the standard no-regret property in online learning algorithms, which allows for a small multiplicative approximation factor of regret. This relaxation leads to faster convergence to approximate optimality in repeated games, particularly in smooth games, while relying only on realized or bandit feedback rather than expected feedback. The authors demonstrate that this property is satisfied by a broad class of algorithms, including Hedge and its variants, and propose a new bandit algorithm with improved performance. The paper extends existing results by improving convergence rates, broadening the scope of algorithms and settings, and addressing dynamic population games. However, the paper has significant overlap with prior works and raises concerns about the clarity and overstatement of its claims.
Strengths:
1. Innovative Relaxation: The introduction of the low approximate regret property is a novel and well-leveraged idea that allows for faster convergence while maintaining price of anarchy guarantees in smooth games. This relaxation is both theoretically interesting and practically relevant.
2. Broader Applicability: The results apply to a wider class of algorithms (e.g., Hedge and its variants) and settings, including dynamic population games and bandit feedback scenarios, making the contributions more general than prior work.
3. Improved Convergence: The paper achieves faster convergence rates (e.g., \(O(n/T)\)) compared to previous work, with only a minor loss in approximation quality.
4. Technical Contributions: The additive-to-multiplicative error term trick is a clever analytical tool that strengthens the theoretical results.
5. Practical Insights: The paper highlights the limitations of expectation feedback in real-world scenarios and provides a new bandit algorithm with improved dependence on the number of actions.
Weaknesses:
1. Overlap with Prior Work: The technical contributions have significant overlap with prior works, particularly Syrgkanis et al. (2015) and Lykouris et al. (2016). While the extensions are meaningful, the novelty is somewhat diminished.
2. Clarity and Overselling: The language of the paper oversells the results, particularly the claims of "fast convergence" in games. The relaxation of convergence notions (e.g., time-averages instead of actual behavior) and equilibrium targets detracts from the core contributions and may confuse readers.
3. Practical Implications: Despite general claims, the practical implications for specific game classes (e.g., two-player or 2x2 games) remain unclear. The paper could benefit from more concrete examples or simulations to support its claims.
4. Complexity of New Algorithm: While the new bandit algorithm is theoretically interesting, its practical advantages over existing methods like GREEN or SCRiBLe are not convincingly demonstrated.
5. Interpretation Stretch: The paper stretches interpretations of convergence and equilibrium, which may detract from the technical rigor and focus.
Arguments for Acceptance:
- The low approximate regret property is a novel and impactful relaxation that broadens the applicability of regret minimization algorithms in repeated games.
- The paper provides meaningful improvements in convergence rates and feedback requirements, addressing practical challenges in game-theoretic learning.
- The theoretical contributions, particularly the additive-to-multiplicative error term trick, are innovative and could inspire future research.
Arguments Against Acceptance:
- The overlap with prior work reduces the novelty of the contributions, making the paper less compelling for an oral presentation.
- The overselling of results and lack of clarity in certain claims may mislead readers and detract from the paper's overall quality.
- The practical implications of the results are not well-demonstrated, particularly for specific game classes or real-world scenarios.
Recommendation:
While the paper has notable strengths, including its innovative relaxation and improved convergence results, the significant overlap with prior work and issues with clarity and practical implications temper enthusiasm. I recommend acceptance as a poster, provided the authors address the clarity issues and better contextualize their contributions relative to prior work.