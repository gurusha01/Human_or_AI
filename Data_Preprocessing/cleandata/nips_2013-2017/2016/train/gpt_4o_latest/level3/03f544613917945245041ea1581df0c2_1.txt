This paper introduces Stochastic Gradient Richardson-Romberg Langevin Dynamics (SGRRLD), a novel approach that applies Richardson-Romberg extrapolation (RRE) to Stochastic Gradient Langevin Dynamics (SGLD) for scalable Bayesian inference. The authors aim to reduce the bias inherent in SG-MCMC methods while maintaining reasonable variance, a significant challenge in "big-data MCMC" applications. By running two SGLD chains with different step sizes in parallel and leveraging RRE, the proposed method achieves higher rates of convergence, theoretically matching the accuracy of methods based on higher-order integrators. The paper bridges the gap between MCMC and stochastic differential equation (SDE) literature, offering insights that benefit both fields.
The paper is technically sound, with rigorous theoretical analysis demonstrating that SGRRLD is asymptotically consistent, satisfies a central limit theorem, and achieves improved rates for bias and mean squared error (MSE). The authors provide non-asymptotic bounds for these metrics, showing that SGRRLD outperforms SGLD in both finite-time and asymptotic regimes. Numerical experiments on synthetic and real-world datasets further validate these claims. The method shows significant improvements in toy examples and consistent, albeit modest, gains in large-scale applications like matrix factorization for movie recommendation tasks. Importantly, the authors exploit the parallelizable nature of SGRRLD, which enhances its computational efficiency.
Strengths of the paper include its clear writing, thorough theoretical grounding, and practical relevance. The proposed method is computationally convenient and likely to be adopted by practitioners, especially in scenarios where reducing bias without incurring excessive computational cost is critical. The experiments are well-designed and align with the theoretical findings, adding credibility to the results.
However, the paper has some minor issues. The interpretation of Figure 1a could be clarified, as it is not immediately intuitive. Additionally, the counter-intuitive behavior of bias in Figure 2a warrants further discussion to ensure readers fully understand the observed trends. While the method is a valuable contribution, it is unlikely to revolutionize current practices, as the improvements in large-scale applications are incremental rather than transformative.
Arguments for Acceptance:
1. The paper addresses an important problem in SG-MCMC methods and provides a novel, theoretically sound solution.
2. It bridges two significant fields (MCMC and SDEs), advancing the state of the art.
3. The method is practical, computationally efficient, and supported by strong experimental results.
4. The writing is clear, and the theoretical contributions are well-explained.
Arguments Against Acceptance:
1. The practical gains in large-scale applications, while consistent, are modest and may not justify widespread adoption.
2. Minor clarity issues in figures and discussions could hinder accessibility for some readers.
In conclusion, this paper makes a meaningful contribution to the field of scalable Bayesian inference and is well-suited for presentation at the conference. While it may not be groundbreaking, its theoretical rigor and practical utility make it a strong candidate for acceptance.