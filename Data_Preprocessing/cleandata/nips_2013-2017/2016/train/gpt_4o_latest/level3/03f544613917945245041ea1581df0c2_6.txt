The paper introduces Stochastic Gradient Richardson-Romberg Langevin Dynamics (SGRRLD), a novel SG-MCMC algorithm leveraging Richardson-Romberg (RR) extrapolation to improve convergence rates. By running two parallel chains with different step sizes and correlated Gaussian noise, the method aims to reduce the bias inherent in SG-MCMC algorithms like SGLD while maintaining reasonable variance. The authors provide rigorous theoretical analysis, including asymptotic and non-asymptotic convergence properties, and validate their claims through synthetic Gaussian model experiments and a large-scale matrix factorization task.
Strengths:
1. Theoretical Contribution: The paper provides a solid theoretical foundation for SGRRLD, demonstrating its asymptotic consistency, central limit theorem satisfaction, and improved convergence rates. The bounds on bias and mean squared error (MSE) are well-articulated and supported by mathematical rigor.
2. Empirical Validation: The synthetic experiments convincingly show SGRRLD's superiority over SGLD in terms of bias and MSE reduction. The large-scale matrix factorization experiments further highlight its practical utility, with significant efficiency gains in terms of wall-clock time.
3. Generality and Scalability: The proposed method is adaptable to other SG-MCMC algorithms (e.g., SGHMC) and is well-suited for parallel and distributed architectures, which is a notable advantage for large-scale applications.
4. Contextualization: The paper situates its contributions within the broader SG-MCMC literature, referencing related work on higher-order integrators and numerical acceleration techniques.
Weaknesses:
1. Incremental Novelty: While the application of RR extrapolation to SG-MCMC is novel, the idea of using numerical integrators and extrapolation methods has been explored in prior work. The contribution may be perceived as incremental rather than groundbreaking.
2. Practical Limitations: The method's reliance on two parallel chains introduces communication overhead, which is not addressed in the paper. This could limit its applicability in resource-constrained environments.
3. Experimental Fairness: The experimental comparisons between SGRRLD and SGLD raise concerns about fairness. It is unclear how computational resources are allocated between the two chains of SGRRLD and whether comparisons with two independent SGLD chains would yield similar results.
4. Clarity Issues: Minor redundancies, such as the repeated mention of the "Unadjusted Langevin Algorithm (ULA)" on lines 25 and 70, detract from the paper's overall clarity.
Suggestions for Improvement:
1. Address the communication costs between parallel chains and discuss potential strategies to mitigate them.
2. Clarify how computational resources are split between the two chains of SGRRLD and explore comparisons with two independent SGLD chains.
3. Streamline the manuscript by removing redundant statements and improving the clarity of certain sections.
Recommendation:
The paper makes a valid contribution to the SG-MCMC literature by introducing a theoretically sound and empirically validated method for improving convergence rates. However, the incremental novelty and practical limitations temper its impact. I recommend acceptance with minor revisions, provided the authors address the concerns regarding experimental fairness and communication costs.