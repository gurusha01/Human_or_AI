The paper proposes a novel method, Supervised Word Mover's Distance (S-WMD), to enhance the Word Mover's Distance (WMD) by incorporating supervision through a learned Mahalanobis distance and reweighting of word histogram coefficients. This approach addresses a key limitation of WMD, which is its unsupervised nature, by introducing task-specific adaptations for improved document classification. The authors provide gradients for an NCA-inspired loss function and demonstrate the efficacy of their method through extensive experiments on eight datasets, outperforming 26 competitive baselines.
Strengths:
The proposed method is conceptually straightforward yet non-trivial, combining the strengths of optimal transport theory with supervised metric learning. The use of entropy-regularized transport for computational efficiency is well-motivated, and the experimental results are compelling, showing consistent improvements over both unsupervised and supervised baselines. The paper is well-structured, with clear explanations of the methodology, and the inclusion of fast gradient approximations makes the approach practical for large-scale datasets. The visualization of learned word weights and t-SNE embeddings further highlights the interpretability of the method.
Weaknesses:
While the method is effective, there are areas where the paper could be improved. First, the distinction between regularized and non-regularized formulations is not sufficiently explored, leaving questions about the trade-offs between computational efficiency and approximation accuracy. The mathematical notation, particularly in the gradient derivations, could be more rigorous to aid reproducibility. Additionally, the paper would benefit from an algorithmic box summarizing the steps of S-WMD for clarity. The use of squared Euclidean distance in the cost matrix is inconsistent with the Euclidean metric used elsewhere, and a generalization to p-Wasserstein distances would improve the method's flexibility. The reweighting approach, while effective, is not novel and has been previously applied in text classification, which the authors fail to acknowledge adequately. Furthermore, the paper lacks experimental insights into the importance of the weight vector \( w \), leaving its role somewhat underexplored. Finally, the related work section does not sufficiently emphasize differences from prior methods, such as entropy regularization for scalability or continuous cost parameterization.
Recommendation:
Pros for acceptance: The paper introduces a practical and effective supervised extension to WMD, achieving state-of-the-art results on multiple datasets. Its simplicity and strong experimental validation make it a valuable contribution to the field of metric learning and document classification.
Cons for acceptance: The limited novelty of the reweighting approach, inconsistencies in metric usage, and insufficient exploration of certain aspects (e.g., weight vector \( w \), related work distinctions) detract from the overall contribution.
Final Decision:
I recommend acceptance with minor revisions. Addressing the noted weaknesses, particularly the inconsistencies in metric usage and the inclusion of an algorithmic box, would significantly strengthen the paper.