The paper presents a novel approach to augmenting recurrent neural networks (RNNs) by introducing a recurrent weight matrix with fast synaptic weight dynamics, serving as a non-selective short-term memory. This mechanism uses a simple update rule with exponential decay to store temporary memories of the recent past, avoiding the need to store explicit copies of neural activity patterns. The authors demonstrate the utility of this method across a range of tasks, including key-value associative retrieval, sequential MNIST, MultiPIE facial expression recognition, and a reinforcement learning (RL) task, showing its effectiveness in scenarios that do not require selective memory.
Strengths:  
The paper is well-written and clearly describes the proposed method, including its biological motivation and mathematical formulation. The experiments are extensive and demonstrate the advantages of fast weights over standard RNNs and LSTMs, particularly in memory-constrained scenarios. The integration of layer normalization to stabilize training and enhance performance is a thoughtful addition. The results are compelling, showing faster convergence and improved accuracy in key-value retrieval and visual attention tasks. The reinforcement learning experiments further highlight the potential of fast weights in partially observable environments, making the contribution relevant to both supervised and RL domains.
Weaknesses and Concerns:  
1. Biological Plausibility: While the authors emphasize the biological motivation, the implementation of the inner loop and its sensitivity to the number of iterations raise questions about its feasibility in real neural systems. Further discussion or justification is needed.  
2. Missing Reference: The reference to the Appendix in Line 136 is unclear or missing, which detracts from the clarity of the experimental setup.  
3. Sequence Lengths: The performance of the network with varying sequence lengths in the key-value task is not discussed, leaving a gap in understanding the method's robustness.  
4. Selective Memory Tasks: The paper does not adequately explore the limitations of the proposed non-selective memory in tasks requiring selective storage. A comparison with LSTMs or other selective memory mechanisms would strengthen the analysis.  
5. Comparison with Related Work: The paper does not compare its method with Facebook's key-value memory networks, which might be better suited for some of the tested scenarios. This omission weakens the originality and contextualization of the work.  
6. Terminological Confusion: Lines 114/115 confuse mini-batches with sequences, which could mislead readers.  
7. Code Availability: The availability of code is not mentioned, which limits reproducibility.  
8. Cache Implementation: The concept of "popping" results from the cache is unclear. It is not specified whether this is manually implemented or learned by the network.
Pro and Con Arguments for Acceptance:  
Pros:  
- Novel and biologically inspired approach to augmenting RNNs.  
- Demonstrated improvements in memory-constrained tasks.  
- Clear and thorough experimental evaluation across diverse tasks.  
Cons:  
- Limited exploration of selective memory tasks and comparison with related methods.  
- Questions about biological plausibility and implementation details.  
- Missing references and unclear terminology in some parts of the manuscript.  
Recommendation:  
While the paper makes a valuable contribution to the field by introducing a novel memory mechanism, the concerns outlined above need to be addressed. I recommend acceptance conditional on revisions that clarify the missing reference, improve comparisons with related work, and address the limitations of non-selective memory in selective memory tasks.