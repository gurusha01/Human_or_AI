This paper presents a rigorous theoretical analysis of \(\ell1\)-norm minimization under \(\ell\alpha\)-norm data fidelity constraints, specifically addressing the challenging cases of non-smooth losses (\(\ell1\) and \(\ell\infty\)). The authors derive support recovery guarantees and provide sharp conditions for stability and instability of the support in the presence of noise. While the proofs focus on the special cases of \(\ell1\) and \(\ell\infty\), the insights are extended numerically to general \(\ell\alpha\) constraints (\(\alpha \geq 1\)). This work is a significant extension of the well-studied \(\ell2\)-norm case and provides a novel perspective on non-smooth loss functions, which are critical for handling sparse and uniform noise models.
Strengths:
1. Theoretical Contribution: The paper addresses a gap in the literature by providing support stability guarantees for non-smooth \(\ell1\) and \(\ell\infty\) losses, which are less explored compared to the smooth \(\ell_2\) case. The results are theoretically sound and well-supported by detailed proofs.
2. Novelty: The extension of support recovery theory to non-smooth loss functions is novel and relevant, particularly for applications like compressed sensing and robust regression.
3. Presentation Quality: The paper is exceptionally well-written and organized. Figures, particularly Figure 2, provide valuable intuition about the behavior of \(\ell_\alpha\)-norm constraints. The inclusion of numerical experiments further strengthens the paper by validating theoretical findings.
4. Practical Insights: The identification of an "extended support" in cases of instability is a useful contribution, offering a nuanced understanding of support recovery under non-smooth constraints.
Weaknesses:
1. Numerical Experiments: While the numerical experiments are insightful, they lack discussion on how the choice of \(x_0\) (e.g., equal nonzero absolute values) influences the results. This could provide additional clarity on the robustness of the findings.
2. Figure Suggestion: The reviewer suggests augmenting Figure 2 by plotting \(1/\alpha\) against \(k\) to explore potential symmetry around \(\alpha = 2\). This could reveal deeper insights into the behavior of \(\ell_\alpha\)-norm constraints.
3. Minor Typos and Formatting: The paper contains minor typographical and formatting issues, such as inconsistent boldface and figure caption spacing, which should be addressed for improved readability.
Arguments for Acceptance:
- The paper provides a substantial theoretical contribution to the field of sparse recovery and compressed sensing, addressing a challenging and underexplored problem.
- The results are novel, well-supported, and have potential applications in robust regression and signal processing.
- The presentation quality and clarity are excellent, making the paper accessible to a broad audience.
Arguments Against Acceptance:
- The numerical experiments, while useful, could be expanded to address the impact of specific parameter choices, such as the structure of \(x_0\).
- Minor presentation issues, though not critical, detract slightly from the overall polish of the paper.
Recommendation:
I recommend accepting this paper with minor revisions. The theoretical contributions are significant, and the paper is well-aligned with the conference's focus on advancing the state of the art in machine learning and optimization. Addressing the suggested improvements to the numerical experiments and figures would further enhance the paper's impact.