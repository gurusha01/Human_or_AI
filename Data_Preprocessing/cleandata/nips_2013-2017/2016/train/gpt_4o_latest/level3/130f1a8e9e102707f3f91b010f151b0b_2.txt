This paper presents an extension to the Sparse Online Dictionary Learning (SODL) framework by incorporating a Sobolev (Laplacian) prior to encourage spatial contiguity in dictionary atoms, with a focus on neuroimaging data. The proposed Smooth-SODL method aims to extract structured, sparse, and interpretable components from brain images, addressing the limitations of prior approaches that either lacked spatial regularization or relied on computationally expensive methods. The authors demonstrate the scalability of their method to large datasets and compare its performance against standard SODL and Canonical ICA (CanICA) on task fMRI data from the Human Connectome Project (HCP).
Strengths:
1. Algorithmic Contribution: The introduction of a Laplacian penalty to enforce spatial smoothness is a notable and original contribution, extending the SODL framework in a principled way. This innovation is particularly relevant for neuroimaging, where spatially contiguous regions are critical for interpretability.
2. Scalability: The method retains the computational efficiency of SODL, making it suitable for large-scale neuroimaging datasets, a significant advantage over existing spatially regularized methods.
3. Potential Impact: The proposed method has broad applicability beyond neuroimaging, including tasks like image segmentation and regional sensing, making it a valuable tool for the community.
4. Rebuttal Improvements: The authors addressed key concerns during the rebuttal phase, providing additional results that clarified the technical quality and empirical performance of their method.
Weaknesses:
1. Empirical Evaluation: While the method shows promise, the empirical advantage of the Sobolev prior over alternatives like SODL and CanICA is not consistently demonstrated. For instance, the claim of "more structured" results is not convincingly substantiated in Figure 2, where visual comparisons lack clarity due to inconsistent slice presentation.
2. Presentation Issues: The manuscript suffers from numerous typos, unclear matrix notations, and inconsistent equations, which hinder comprehension. Figures 2 and 3 are particularly problematic, with missing legends and insufficient explanation of the PCA baseline and predictions.
3. Limited Quantitative Metrics: The evaluation relies heavily on qualitative assessments and a limited set of quantitative metrics (e.g., explained variance, stability, and R² scores). A more comprehensive analysis, including statistical significance tests, would strengthen the claims.
4. Hyperparameter Sensitivity: The method's performance is highly sensitive to hyperparameters (e.g., γ, τ), and the tuning process is not well-documented, making reproducibility challenging.
Arguments for Acceptance:
- The paper introduces a novel and computationally efficient approach to structured dictionary learning, which is a significant contribution to the field.
- The method has potential for wide applicability and addresses a critical need for interpretable neuroimaging decompositions.
- The rebuttal phase demonstrated the authors' responsiveness and improved the technical clarity of the work.
Arguments Against Acceptance:
- The empirical results do not consistently demonstrate the superiority of the proposed method, and key claims are not well-supported.
- The manuscript's presentation issues significantly detract from its clarity and accessibility.
- The evaluation lacks depth, with limited metrics and insufficient exploration of the method's limitations.
Recommendation:
I recommend weak acceptance. While the paper makes a valuable algorithmic contribution, the empirical evaluation and presentation require significant improvement. If accepted, the authors should address the presentation issues and provide more robust empirical evidence in the final version.