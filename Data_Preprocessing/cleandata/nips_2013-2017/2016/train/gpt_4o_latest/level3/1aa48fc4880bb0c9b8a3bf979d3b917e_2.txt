This paper addresses the problem of minimizing convex-concave saddle-point problems by extending stochastic variance reduction methods (e.g., SVRG, SAGA). The authors provide a convergence analysis for their proposed methods, demonstrating linear convergence rates. They also show that the methods can be accelerated using an extension of the catalyst framework, which improves performance over existing batch and stochastic algorithms. Notably, the paper extends the applicability of these methods to monotone operators, broadening their utility beyond saddle-point problems. Numerical experiments are included to validate the theoretical findings, though the scope of these experiments is somewhat limited.
Strengths:
1. Theoretical Contributions: The paper provides the first convergence analysis for variance reduction methods applied to saddle-point problems. This is a significant theoretical advancement, as it extends the utility of these methods to a broader class of problems, including variational inequalities.
2. Acceleration via Catalyst Framework: The incorporation of the catalyst framework is well-motivated and leads to a provable improvement in convergence rates. This is an important contribution, as it demonstrates that the proposed methods are not only theoretically sound but also practically efficient.
3. Extension to Monotone Operators: The generalization to monotone operators is a notable strength, as it highlights the versatility of the proposed methods and their potential applicability in other domains, such as game theory and variational inequalities.
4. Clarity of Analysis: The theoretical analysis is rigorous and well-structured, making it accessible to readers familiar with optimization and monotone operator theory.
Weaknesses:
1. Strong Convexity Assumption: The reliance on strong convexity-concavity assumptions for both the primal and dual problems is a significant limitation. This assumption is overly restrictive and excludes many practical problems where such conditions do not hold. Relaxing this assumption would greatly enhance the paper's impact.
2. Limited Numerical Experiments: While the numerical results support the theoretical claims, the experiments are limited in scope. More diverse datasets and problem settings, including real-world applications, would strengthen the empirical validation.
3. Comparison with Related Work: Although the paper references prior work, it could provide a more detailed comparison with existing methods, particularly in terms of practical performance on benchmark problems. This would help contextualize the contributions more effectively.
4. Practical Implementation Details: The paper lacks a detailed discussion of implementation challenges, such as memory requirements for SAGA or the computational cost of non-uniform sampling. Addressing these aspects would make the work more accessible to practitioners.
Recommendation:
I recommend acceptance with minor revisions. The paper makes significant theoretical contributions to the field of optimization and variance reduction methods for saddle-point problems. However, addressing the strong convexity-concavity assumption and expanding the numerical experiments would substantially improve the paper. Additionally, a more detailed discussion of practical implementation and comparisons with related work would enhance its overall impact.
Arguments for Acceptance:
- Novel theoretical contributions, including the first convergence analysis for variance reduction methods in this context.
- Demonstrated acceleration via the catalyst framework, which is both theoretically and practically significant.
- Extension to monotone operators, broadening the scope of applicability.
Arguments Against Acceptance:
- Overly restrictive assumptions on strong convexity-concavity.
- Limited empirical validation and lack of diverse numerical examples.
In conclusion, the paper advances the state of the art in optimization for saddle-point problems and has the potential to inspire further research in this area. However, addressing the noted weaknesses would make its contributions more robust and impactful.