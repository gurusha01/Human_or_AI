Review of the Paper
This paper tackles the supervised PageRank problem by proposing two novel optimization methods: a gradient-based approach and a gradient-free approach. Both methods are designed to handle non-convex loss minimization, leveraging inexact oracle information to estimate stationary distributions and their derivatives. The authors provide theoretical guarantees for convergence rates and demonstrate the superiority of their methods over state-of-the-art approaches in ranking quality. The paper is technically sound and contributes to the field of optimization for graph-based learning tasks, but there are areas for improvement in clarity and experimental evaluation.
Strengths:
1. Technical Contributions: The paper builds on the foundational work of Nesterov and Nemirovski to develop optimization methods that avoid the computational overhead of large matrix operations. The gradient-based method guarantees convergence without requiring convexity, while the gradient-free method ensures a decrease in the loss function. Both methods provide theoretical convergence rate estimates, which is a significant improvement over existing approaches.
2. Practical Relevance: The proposed methods outperform the state-of-the-art in ranking quality, as demonstrated in experiments on a real-world dataset. The ability to avoid exact calculations of the objective function while maintaining strong theoretical guarantees makes these methods highly applicable to large-scale problems.
3. Theoretical Rigor: The paper includes detailed proofs and analyses, ensuring that the claims are well-supported. The investigation into the trade-off between lower-level accuracy and computational complexity is particularly noteworthy.
4. Novelty: The combination of random gradient-free and gradient-based optimization methods with inexact oracle concepts is innovative and expands the toolbox for solving constrained non-convex optimization problems.
Weaknesses:
1. Clarity: The excessive use of symbols and delayed definitions (e.g., $N$) make the paper difficult to follow, especially for readers unfamiliar with the topic. A symbol table would significantly improve readability.
2. Experimental Evaluation: While the methods are evaluated on a real-world dataset, the focus on the loss function rather than ranking quality in the experimental comparison is a limitation. Ranking quality is the ultimate goal, and a more direct evaluation would strengthen the results.
3. Dataset Accessibility: The dataset used for experiments is not publicly available, which limits the reproducibility of the results and the ability of other researchers to benchmark against the proposed methods.
4. Comparison with Reference Work: A direct comparison with the generalized reference work (ref: 17) is missing. This would provide a more comprehensive evaluation of the proposed methods' performance.
Arguments for Acceptance:
- The paper addresses a challenging and important problem in graph-based learning.
- It introduces novel methods with strong theoretical guarantees and practical relevance.
- The methods outperform existing approaches in experiments, demonstrating their effectiveness.
Arguments Against Acceptance:
- The clarity of the presentation is suboptimal, which may hinder understanding and adoption.
- The experimental evaluation could be more robust, particularly with a focus on ranking quality and comparisons with key reference works.
- The lack of publicly available datasets limits reproducibility.
Recommendations:
- Include a symbol table and define key terms earlier in the paper to improve clarity.
- Expand the experimental section to include direct evaluations of ranking quality and comparisons with ref: 17.
- Consider releasing a synthetic dataset or a subset of the data to enhance reproducibility.
Conclusion:
This paper makes a significant contribution to the field of optimization for supervised PageRank and related problems. While there are some weaknesses in clarity and experimental evaluation, the strengths outweigh these issues. I recommend acceptance, provided the authors address the clarity issues and strengthen the experimental section in the final version.