Review
This paper extends the theoretical framework of sparse support recovery to non-smooth regression losses, specifically focusing on the `1 and `∞ norms. The authors provide rigorous mathematical guarantees for support stability under small noise, generalizing results previously established for the smooth `2 loss. The main contribution lies in deriving sharp conditions for support recovery with non-smooth loss functions, introducing the concept of an "extended support" to handle cases of instability. Theoretical results are supported by numerical experiments in a compressed sensing setting, offering insights into the practical implications of using `1 and `∞ losses for sparse regression.
Strengths:
1. Novelty and Originality: The paper addresses a significant gap in the literature by extending support recovery guarantees to non-smooth loss functions. This is a meaningful contribution, as `1 and `∞ losses are widely used in practice but lack rigorous theoretical backing.
2. Mathematical Rigor: The paper demonstrates strong theoretical grounding, with detailed proofs and well-defined conditions for stability and instability. The introduction of minimum norm certificates and extended support is a notable advancement.
3. Practical Insights: By contrasting `1 and `∞ losses, the paper provides valuable insights into their behavior under different noise models (`1 for sparse noise and `∞ for uniform noise). This is particularly relevant for practitioners in compressed sensing and robust regression.
4. Numerical Validation: The numerical experiments effectively illustrate the theoretical findings, highlighting the varying degrees of support stability across different loss functions.
Weaknesses:
1. Clarity and Readability: The paper is dense and challenging to follow, particularly for readers unfamiliar with the topic. Key concepts, such as dual certificates, extended support, and Lagrange multipliers, are introduced with insufficient intuition or geometric interpretation. For instance, the roles of `vβ` and `pβ` in the regression problem could benefit from visual or intuitive explanations.
2. Lack of Diagrams: The absence of diagrams is a significant drawback. Illustrations of the regression problem in 1D/2D, the polyhedral nature of the constraints, and the behavior of `1 and `∞ losses would greatly enhance understanding.
3. Transitions and Notation: The transitions between general dual pairs (`α, β`), polyhedral losses, and specific cases (`1, `∞) are abrupt and lack clarity. Additionally, notations are often introduced after their use, making the paper difficult to parse on a first read.
4. Connection to Prior Work: While the paper references prior work, the connections to foundational results (e.g., Tibshirani's Lasso) are not explicitly drawn. This makes it harder to contextualize the contributions within the broader literature.
5. Minor Issues: There are occasional unclear symbols and grammatical errors, which detract from the overall presentation.
Suggestions for Improvement:
1. Include diagrams to illustrate key concepts, such as the regression constraints, extended support, and the behavior of different loss functions.
2. Reorganize the introduction of notations and provide quick intuitions for terms like `vβ`, `pβ`, and Lagrange multipliers.
3. Clarify transitions between general and specific cases, and explicitly link the results to prior work to better situate the contributions.
4. Add a section summarizing the practical implications of the results, particularly for practitioners in compressed sensing and robust regression.
5. Address minor grammatical issues and unclear symbols for improved readability.
Arguments for Acceptance:
- The paper makes a novel and rigorous contribution to the theory of sparse support recovery with non-smooth losses.
- The results are significant and have practical implications for regression problems under non-Gaussian noise models.
- The numerical experiments are well-executed and validate the theoretical findings.
Arguments Against Acceptance:
- The paper's readability is poor, with dense mathematical exposition and insufficient intuition or visualization.
- Key connections to prior work are not adequately emphasized, limiting the accessibility of the contributions.
- The lack of diagrams and clear transitions makes the paper difficult to follow, even for experts.
Recommendation:
Borderline Accept. While the paper's contributions are significant and well-founded, its clarity and presentation need substantial improvement. If the authors address the readability issues and include visual aids, the paper would be a strong candidate for acceptance.