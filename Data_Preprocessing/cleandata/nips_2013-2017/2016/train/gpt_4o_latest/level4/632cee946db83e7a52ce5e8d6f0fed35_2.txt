The paper establishes a connection (referred to as a "duality") between boosting and SVMs and leverages this relationship to propose a novel boosting-based method for dimensionality reduction. I found the proposed dimensionality-reduction technique to be reasonable, relatively efficient, and effective based on the experimental results presented. The "duality" with SVMs is somewhat intriguing. However, the approach ultimately relies solely on boosting, rather than incorporating an alternating scheme between boosting and SVMs. As a result, the practical utility of this connection is somewhat limited. The paper's presentation is adequate, though certain mathematical formulations could benefit from greater precision. The paper does not provide theoretical guarantees, such as generalization bounds or convergence proofs, which could strengthen its contributions. Some theoretical insights might be feasible; for example, see Allwein et al. ("Reducing multiclass to binary..."). The alternating approach mentioned in this paper bears some resemblance to (though is distinct from) the method proposed by Schapire ("Using output codes to boost multiclass learning problems"). A comparison between the two approaches could be insightful.
Additional comments:  
- Line 67: The phrase "tend to produce sub-optimal..." should be supported with references or evidence.  
- Equation (1): The approximate equality holds only if uniform convergence bounds can be established. Additionally, clarify what the expectation is taken over. The summation on the right-hand side should also be scaled by a factor of 1/n.  
- Line 94: Consider omitting the subscripts in the definition of M(xi, zi) and elsewhere, simplifying the notation to M(x, z).  
- Lines 91 and following: This section would benefit from more precise mathematical exposition.  
- Line 95: Shouldn't the classifier output map to {1, 2} instead of {-1, +1}?  
- Line 97: It seems the intended meaning is that each y^z is in R^d, but the current wording implies the entire set is in R^d.  
- Equation (7): Why is there a shift from zi to ci? Clarify the notation.  
- Algorithm 2: Is {\cal Y} intended to be a set or a tuple? It seems it should be a tuple, and it does not appear to be an element of R^d. Additionally, Algorithm 2 references equation (14), which does not seem to exist in the paper.  
- Equation (11): Should y^l be corrected to y^1?  
- Line 246: There does not appear to be a figure 3b corresponding to the description provided.