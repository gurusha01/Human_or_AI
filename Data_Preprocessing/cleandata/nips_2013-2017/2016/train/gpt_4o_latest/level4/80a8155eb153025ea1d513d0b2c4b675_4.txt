This paper investigates the statistical properties of the "robust k-means clustering" method, focusing specifically on its robustness as measured by the finite sample breakdown point and its consistency. The authors employ variational analysis techniques to explore the functional characteristics of the robust k-means (RKM) objective. In particular, the study examines the "breakdown point" of a family of robust k-means objectives with varying regularization terms (denoted as f_lambda). The primary finding, presented in Theorem 1, is that this family of k-means objectives lacks robustness in the presence of even as few as two outliers. This result highlights that "robust" k-means objectives are not robust for general datasets. However, the authors clarify that when the dataset exhibits a clusterable structure, the objective demonstrates robustness to outliers. Additionally, they establish the consistency of the objective.
Technical quality: One key point I want to emphasize is that the experimental section appears somewhat disconnected from the theoretical focus of the paper. While the paper primarily aims to analyze the properties of the robust k-means objective, the experiments instead compare two different robust clustering methods. One method is based on a heuristic (coordinate descent) that locally optimizes the robust k-means objective, while the other method does not seem to be tied to any specific objective, as far as I understand. 
Novelty/Originality: The novelty of this work lies in its application of optimization techniques to analyze the properties of the robust k-means objective. This approach provides a fresh perspective on the theoretical understanding of clustering objectives.
Potential impact & Usefulness: The findings are significant because they reveal that, in general, robust k-means is not robust to outliers, and achieving robustness requires datasets with a clusterable structure. This insight aligns with recent research emphasizing the importance of clusterability in clustering methods. Furthermore, the introduction of variational analysis as a tool to study clustering objectives could inspire future research aimed at understanding clustering methods through this lens.
Clarity and presentation: The interpretability of the results could be improved. For example, in Section 3.3, the connection between Corollary 2 and the conclusion at the end of the section is unclear. Additionally, the contribution of this paper to the discussion in this section is ambiguous: Is the issue already addressed in [2], or does this paper provide new insights into the robustness of k-means objectives under a clusterable structure? More broadly, it would be helpful if the authors could better situate their work within the context of related research.