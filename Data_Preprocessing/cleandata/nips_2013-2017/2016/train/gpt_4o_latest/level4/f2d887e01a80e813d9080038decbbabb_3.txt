This paper introduces a method for estimating the test error of a model using unlabeled data, even when the data distribution differs from that of the training set. The proposed approach leverages the method of moments and assumes that the feature space is partitioned into three conditionally independent subspaces given the output (the 3-views assumption), without imposing any constraints on the optimal predictor or the parametric form of the distribution. The method is further extended to structured output scenarios, such as Hidden Markov Models (HMMs). The paper is well-written, and I did not identify any issues in the provided proofs. My primary concern lies with the 3-views assumption and its practical feasibility. This assumption is stricter than the one used in co-training, which was originally proposed for multi-view learning, and some prior works have argued that it may be unrealistic in mono-view learning contexts. I recommend including a discussion on whether the main assumption can be relaxed or, at the very least, addressing how to handle situations where the assumption does not hold in a wide range of practical cases.