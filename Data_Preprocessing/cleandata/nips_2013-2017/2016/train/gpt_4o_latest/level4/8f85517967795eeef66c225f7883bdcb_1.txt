This paper presents an intriguing approach to deriving upper and lower bounds for Markov random field (MRF) models that incorporate an additional submodular energy term, which is not factored. The method leverages two established techniques: (1) constructing upper and lower linear bounds for the submodular function \( f(.) \), effectively transforming \( f(.) \) into additional low-order factor terms, and (2) applying standard variational upper and lower bounds to the resulting MRF. Together, these techniques yield upper and lower bounds for the partition function of the original MRF. 
While the approach is interesting, it is somewhat unclear how practically useful the resulting bounds are. In the experimental results, the authors primarily focus on reporting the pseudomarginals derived from the upper bound, rather than demonstrating specific applications of the partition function bounds. It seems plausible that the upper bounds might be particularly beneficial in parameter learning tasks, and it would be helpful if the authors could provide commentary on this point. 
The paper establishes strong connections to existing work, which are well-articulated and clearly presented. On a technical note, I recommend replacing the marginal polytope representation of TRW in Equation (3) with a decomposition-based formulation, such as the dual form of Equation (3). Examples include a combination of spanning trees (Jancsary & Matz, AISTATS 2011) or dual decomposition methods (Ping et al., NIPS 2015). This substitution could offer several advantages: it would transform the saddle-point, double-loop optimization into a single joint minimization problem, simplify the weight update process, and likely accelerate the overall computation, as the current approach appears to be bottlenecked by running TRWBP in the inner loop.