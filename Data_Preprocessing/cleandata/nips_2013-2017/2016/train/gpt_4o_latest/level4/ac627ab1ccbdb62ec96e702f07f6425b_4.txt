This paper introduces an unsupervised adaptation technique leveraging residual connections to construct the target classifier as the sum of the source classifier and a residual function. This approach differs from recent deep adaptation methods, which focus on learning a unified model for both source and target domains. Additionally, the paper employs the kernel MMD to align representations across domains, similar to the strategies used in related methods like DAN and DDC. The concept of learning a residual difference to derive the target classifier is innovative, straightforward, and intriguing. The paper is well-written, and the proposed method is clearly articulated. However, the primary concern lies in the three components of the approach: the entropy loss applied to the final target scores, the MMD loss for domain alignment, and the residual connection. Experimental results suggest that the entropy loss provides the most significant contribution, followed by the MMD loss and, lastly, the residual connection. While the MMD loss is not novel, the entropy loss is less thoroughly explained compared to the residual connection. Although the method appears promising, it remains uncertain whether the novel aspects of the approach substantially enhance the overall system's performance.