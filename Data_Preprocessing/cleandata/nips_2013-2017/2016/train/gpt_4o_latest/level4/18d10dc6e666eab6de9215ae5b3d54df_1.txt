This paper focuses on batch-sequential Bayesian Optimization, introducing a batch-sequential adaptation of the Knowledge Gradient (KG) criterion. After providing background on related work and Gaussian processes, the authors define the parallel (q-KG) criterion. The computation of this criterion is described in detail, following the methodology of the standard KG criterion. The paper also presents several numerical experiments, demonstrating that q-KG outperforms certain state-of-the-art batch-sequential Bayesian Optimization algorithms. Overall, this is an excellent paper, and I believe it has significant merits that warrant its acceptance at NIPS. The societal impact of parallelizing Bayesian optimization algorithms is substantial. 
However, I have a minor critique: the paper does not analyze speed-ups achieved by transitioning from sequential to batch-sequential optimization. Additionally, a few statements in the literature review are slightly imprecise. For example, the idea of integrating Expected Improvement (EI) with respect to posterior distributions was already discussed in "Kriging is well-suited to parallelize optimization" (along with the Constant Liar approach), while Chevalier et al. notably introduced CL-mix in [2]. Furthermore, q-EI maximization using the natural gradient is explored in "Differentiating the multipoint Expected Improvement for optimal batch design." 
Finally, I have the following comments and questions:  
- Is the set A compact, and is the function f continuous?  
- Why is A restricted to being a Latin Hypercube Sampling (LHS) design at the initial stage?  
- In Algorithm 1, how is hyperparameter re-estimation (or Bayesian updating) handled?  
- In Section 5.2, is g defined as a maximum or a minimum?  
- Regarding Section 5.2 again, the smoothness of g does not seem immediately evident.  
- Similarly, the derivative of the Cholesky factor may not be straightforward.  
- I assume the Mat√©rn kernel is 5/2, not 2/5?  
- For Figure 1 and the corresponding experiments, was it possible to fit the same Gaussian Processes (GPs) using different software tools?