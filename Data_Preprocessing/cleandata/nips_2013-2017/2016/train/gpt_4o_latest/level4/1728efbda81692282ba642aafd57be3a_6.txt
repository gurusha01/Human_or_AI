The authors of this paper present a spectral analysis of the Koopman operator within reproducing kernel Hilbert spaces (RKHS) and propose an algorithm to perform this analysis using measurement data from dynamical systems. The Koopman operator, a concept originating in fluid dynamics, is suggested by the authors to have potential relevance to machine learning. The paper demonstrates the proposed algorithm and analysis on two simple dynamical systems: a damped linear 1D system and a chaotic map. Additionally, the authors apply their method to real-world locomotion data, comparing its performance against standard dynamic mode decomposition (DMD), PCA, and kernel PCA, though the results are somewhat ambiguous. 
The work represents an interesting extension of dynamic mode decomposition, aligning with prior efforts to "kernelize" techniques involving linear operators (e.g., kernel PCA, kernel ICA, kernel independence tests, Gaussian process bandits, etc.). While the authors provide experimental results, these are primarily limited to artificial problems. The paper is generally well-written and has educational value, particularly for readers unfamiliar with fluid dynamics concepts. I appreciate efforts to introduce machine learning researchers to techniques from other fields, and this work appears to explore a decomposition method for functions mapping \( M \to M \) in the context of deterministic dynamical systems. However, I am not aware of such setups being widely used in machine learning, where stochastic components (e.g., noise or innovations) are typically incorporated into dynamical systems. That said, I may be overlooking relevant applications.
To make the work more compelling for the machine learning audience, the authors should provide stronger justification for the practical utility of their approach. What are the potential use cases for this method? Can it compete, even partially, with state-of-the-art techniques in relevant domains? For instance, robotics is a field where learning and inference in dynamical systems are critical and extensively studied. What advantages would Koopman analysis offer to researchers in robotics, or in any other domain the authors might consider? 
While the theoretical derivations are well-executed, they are not particularly surprising to someone familiar with kernel PCA, kernel ICA, or related follow-up work on kernel independence tests or the "kernel Bayes rule." The use of a linear operator in RKHS to derive algorithms involving eigendecomposition of finite-dimensional matrices is a well-established approach. 
A few specific points of clarification and improvement: It is unclear whether the modal decomposition algorithm requires explicit representation in the feature space. If this is the case, it represents a limitation compared to kernel PCA, and the authors should explicitly highlight this. Additionally, it would be helpful if the authors demonstrated the performance of standard dynamic mode decomposition on the toy examples and the Henon map to better illustrate the differences in these simple setups.