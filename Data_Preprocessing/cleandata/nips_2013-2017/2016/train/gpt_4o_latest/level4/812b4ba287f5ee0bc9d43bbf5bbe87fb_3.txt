The authors introduce a reinforcement learning method aimed at accelerating the search for object scales and locations. Their approach employs a tree-structured search mechanism that adjusts the search window by scaling (down) or translating it at each step. This design is partially inspired by visual attention models. The proposed method enhances the efficiency and quality of proposal generation, achieving state-of-the-art results with reduced computational overhead when integrated with standard object detectors. The paper presents a concise yet intriguing idea that is clearly articulated and thoroughly analyzed. I appreciate the adoption of a formalized visual attention model for proposal generation, as opposed to relying on brute-force dense CNN-based classification. Additionally, the use of deep Q-learning for optimization is compelling. Overall, this work is likely to be of interest to the NIPS audience.