This paper addresses unsupervised domain adaptation, emphasizing the presence of a source-target classifier mismatch in addition to the marginal distribution discrepancy between source and target domains. The classifier mismatch is modeled as a perturbation function (following the approach in [25,26]), which is learned using a novel deep residual network that simultaneously incorporates feature learning and feature adaptation to mitigate the marginal distribution shift. The paper innovatively builds upon the deep network that won the ILSVRC challenge in 2015, repurposing it for domain adaptation. The description of how the residual block is integrated into the CNN architecture and utilized to estimate the perturbation function for the target classifier is both clear and represents a noteworthy contribution. Furthermore, to the best of my knowledge, the entropy minimization principle [28] has not been previously incorporated into a domain adaptation network, and the MK-MMD employed here is a novel variant compared to its use in [5]. Experimentally, the results presented are quite compelling, though additional evaluations on more challenging testbeds could strengthen the findings. It would also be helpful to clarify the basis on which figures 2-c and 2-d are deemed superior to 2-a and 2-b; perhaps providing the average class-to-class distance could better substantiate the claimed improvement, as the figure is not entirely self-explanatory.