The paper introduces an enhancement to widely-used encoder-decoder frameworks, such as those employed in image captioning. Specifically, it proposes the integration of an intermediate "reviewer" module that generates a set of fact vectors, which can, for instance, encapsulate the key concepts in an image. These fact vectors are subsequently fed into the decoder model alongside the hidden representation. Notably, the fact vectors can also be supervised during the training phase.  
Strengths:  
- The paper presents an intriguing idea of incorporating additional supervision into the encoder-decoder learning paradigm.  
- Experimental results are provided for two tasks and datasets, with both demonstrating improvements over ablation baselines.  
- The approach is shown to generalize standard encoder-decoder methods.  
Weaknesses:  
1. For the captioning experiment, the paper evaluates its approach on a non-official test or dev set. However, final results should be benchmarked on the official COCO leaderboard using the blind test set: https://competitions.codalab.org/competitions/3221results. For example, methods like [5, 17], which have won this challenge, have been assessed on the blind challenge set. Additionally, several other approaches have been proposed since then, showing significant improvements (as seen on the leaderboard). The paper should at least compare against methods with corresponding publications.  
2. A human evaluation for caption generation would strengthen the results, as automatic evaluation metrics can sometimes be misleading.  
3. Section 4.2 lacks clarity on how supervision is incorporated in the source code captioning experiment.  
While the work is compelling, addressing at least weaknesses 1 and 3 is necessary for acceptance.  
Post Author Response:  
The authors have committed to including results addressing point 1 in the final version. Regarding point 3, it would be helpful if they explicitly clarified this in Section 4.2. I also encourage the authors to incorporate the additional results they shared during the rebuttal, such as T_r, as these provide valuable insights into the proposed approach. My concerns, along with those of the other reviewers as far as I can tell, have been largely addressed. Therefore, I recommend accepting the paper.