This paper introduces a novel tree-based reinforcement learning method for sequentially proposing object bounding boxes within a deep Q-learning network framework. Empirical results demonstrate competitive performance in region proposal metrics (recall @ nboxes, recall @ IoU) and state-of-the-art object detection results (mAP) on the PASCAL07 test set. The paper presents an interesting application of reinforcement learning to object proposal generation. However, one observation from the recall plots (Figure 5e and 5f) is that the authors did not evaluate performance beyond 1500 proposals. This omission makes it challenging to directly compare the recall performance of the proposed method with other baseline proposal techniques at higher numbers of proposals. For instance, baselines like Selective Search, Edge Boxes, and BING achieve recall values close to 1.0 at approximately 4000 boxes with an IoU threshold of 0.5. In contrast, the proposed method appears to saturate relatively early (based on visual extrapolation), suggesting it may not maintain high recall beyond the evaluated 1500 proposals. Regardless of the current results, the paper would be scientifically stronger if the authors extended their evaluation to include recall performance beyond 1500 proposals.