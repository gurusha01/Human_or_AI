The paper explores the application of intrinsic motivation for exploration in reinforcement learning, introducing a novel uncertainty measure termed pseudo-count. This measure demonstrates effectiveness in large state spaces, as evidenced by experiments conducted on several challenging games. The authors also establish strong connections to other intrinsic motivation measures, such as Bayesian information gain. However, the paper would benefit from deeper engagement with the cited work "Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning," which also interprets mutual information or channel capacity as a form of path-counting. Technical quality: The experiments are well-executed and involve reasonably complex environments. Novelty/originality: The paper presents a novel approach to measuring uncertainty using counts. However, the discussion of relationships to similar methods is incomplete (see section A of "Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning"). Potential impact or usefulness: The approach is promising and practical, particularly due to its applicability to large state spaces. Clarity and presentation: The paper is well-structured and clearly presented.