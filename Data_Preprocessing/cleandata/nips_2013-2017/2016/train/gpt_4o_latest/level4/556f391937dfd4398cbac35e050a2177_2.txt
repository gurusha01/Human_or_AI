This paper introduces a novel approach for local similarity-aware embedding using a deep neural network. The key contributions of the paper include the ability to select hard samples during training to accelerate convergence and enhance performance, the introduction of a new objective function termed double-header hinge loss to capture local structures in the data, the incorporation of absolute position information to handle heterogeneous feature distributions, and the use of quadruplets within mini-batches for an efficient sampling procedure. The proposed method is demonstrated to outperform existing approaches in image retrieval and transfer learning tasks.
Major comments:  
1. While the paper asserts that the proposed method offers both performance and speed advantages, it does not provide any runtime analysis or measurements.  
2. The architecture depicted in Fig. 2 requires further elaboration. For instance, the CNN module in Fig. 2(a) should be explicitly defined.  
3. Additional clarification regarding Fig. 3 would be beneficial. Specifically, the differences among contrastive embedding, triplet embedding, and lifted structured embedding should be explained, along with an analysis of their respective strengths and weaknesses compared to the proposed method.  
4. The paper lacks details on the optimization of the objective function, such as the gradient computation process.  
5. An analysis of how performance varies with different mini-batch sizes is missing.  
6. The paper does not address potential issues related to parameter initialization or specify how parameters were initialized in the experiments.  
7. Including the standard deviation of the results in Table 1 would help assess the statistical significance of the reported outcomes.  
The paper would benefit from more detailed explanations of the technical aspects, such as optimization procedures, implementation details, and network architecture, to ensure reproducibility by other researchers. Additionally, the results section should substantiate each claim made in the paper, particularly those related to speed improvements.