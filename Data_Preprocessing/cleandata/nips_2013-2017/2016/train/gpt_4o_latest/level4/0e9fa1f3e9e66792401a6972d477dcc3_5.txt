The authors address the problem of evaluating the reliability of MCMC outputs and comparing the efficiency of different MCMC schemes. They propose to achieve this by leveraging the upper and lower stochastic bounds on the log marginal likelihood provided by the Bidirectional Monte Carlo (BMC) procedure. The central idea is to select, among available MCMC schemes, the one that yields the tightest BMC stochastic bounds for a given computational effort. A key challenge, however, is that BMC requires an exact sample from the target distribution to produce a valid stochastic upper bound. To address this, the authors propose a set of heuristics. Specifically, in the context of Bayesian posterior sampling, they suggest performing diagnostics on the posterior generated from synthetic data rather than the actual data, exploiting the fact that it is easier to generate high-quality approximate samples for such synthetic posteriors. The proposed methodology is then tested on a series of examples.
The idea of using stochastic lower bounds from Bidirectional Monte Carlo to assess MCMC convergence is intriguing. Although the methodology appears to be tailored to AIS and SMC sampler schemes and focuses exclusively on diagnostics based on the marginal likelihood, it still holds potential value as a theoretically motivated approach to MCMC diagnostics. However, the implementation suffers from several limitations that, in my view, reduce the appeal of the proposed methodology. These limitations stem from the heuristic approach used to circumvent the requirement for exact samples in Bidirectional Monte Carlo. I outline three main concerns below:
1. The authors assume prior knowledge of a hyperparameter value, \(\eta_{\text{real}}\), that is representative of the entire posterior, potentially derived from a previously run MCMC. This assumption is problematic because it presupposes that the earlier algorithm has already converged (essentially the original problem of interest) and that the posterior can be adequately summarized by a single value. Both assumptions are strong and lack general justification.
2. The methodology assumes that the posterior induced by synthetic data generated from \(\eta_{\text{real}}\) exhibits similar MCMC convergence properties to the original posterior. This assumption is again unjustified and could be particularly problematic in scenarios involving model misspecifications. The approach appears to sidestep the original difficulty posed by Bidirectional Monte Carlo by shifting the focus to diagnostics on a different posterior.
3. The authors adopt an optimistic stance that starting from \(\eta_{\text{real}}\) enables the MCMC algorithm to quickly generate an almost exact sample from the posterior. While this might hold in some cases, it is not guaranteed and remains an unsubstantiated assumption.
As a result, the proposed methodology appears to rest on several assumptions that are closely tied to the very problem it aims to address—namely, the convergence properties of the original MCMC algorithm. While I appreciate that Section 5.1 provides simple examples where these issues do not seem to affect the conclusions, the limited scope of these examples is insufficient to demonstrate that the identified issues will not become critical in more complex scenarios.
The authors critique existing convergence diagnostic tools for their potential failures in multimodal cases or when a limited set of summary statistics is insufficiently expressive (lines 203–205). However, they should clarify why their method is better suited to such scenarios and provide supporting evidence. More broadly, it would be beneficial to include simulations comparing their method with commonly used diagnostic tools (e.g., those described in Section 4) to highlight cases where their approach yields more reliable diagnostics.