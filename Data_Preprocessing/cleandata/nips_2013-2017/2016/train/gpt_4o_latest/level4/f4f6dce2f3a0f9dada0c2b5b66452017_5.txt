Recently, randomized sampling and sketching methods have gained significant attention for addressing large-scale overdetermined least squares regression problems. This paper introduces a leverage scores-based sampling approach tailored for the alternating least squares (ALS) minimization problems that arise as intermediate steps in computing low-rank tensor CANDECOMP/PARAFAC (CP) decomposition. Tensor CP decomposition involves expressing a tensor as a sum of rank-1 tensors, where these rank-1 tensors are represented by low-rank factor matrices. The ALS approach is commonly used to compute these factor matrices, requiring the solution of least squares (LS) problems involving the tensor matricization and the Khatri-Rao product (KRP) of the other factor matrices. The paper proposes leveraging scores-based sampling of the matricization and the KRP before solving the LS regression problem. 
The primary contribution of the paper, in my opinion, lies in the computation of leverage scores for the rows of the KRPs. To address the computational expense of directly calculating these leverage scores, the authors propose an upper bound approximation, which is shown to be the product of the leverage scores of the constituent matrices. Experimental results are presented to demonstrate the speedup achieved by the proposed algorithm. Overall, the paper introduces a fast method for estimating the ALS steps encountered during tensor CP decomposition using leverage scores sampling. The experimental results showcasing the computational speedup are compelling. However, I have several concerns and suggestions, detailed below.
Concerns and Suggestions Regarding the Theory:
1. Justification for Leverage Scores-Based Sampling: The paper does not adequately justify why leverage scores-based sampling is preferred over other randomized sampling or sketching methods that do not require leverage scores computation. For instance, methods such as those based on subsampled randomized Hadamard transforms (SRHT) (Drineas et al., 2011, reference [15]) or those discussed in Woodruff's (2014) monograph exhibit sampling complexities of \(m = \Theta(R \log(n)/\epsilon^2)\), which appear to be better than the proposed method's complexity of \(m = \Theta(R^2 \log(n)/\epsilon^2)\) as stated in Theorem 4.1. The advantages of the proposed method over these alternatives should be explicitly discussed.
   
2. Derivation of Sampling Complexity in Theorem 4.1: The sampling complexity \(m = \Theta(R^2 \log(n)/\epsilon^2)\) in Theorem 4.1 is stated without a clear derivation or proof. Neither the main paper nor the Appendix provides sufficient details to substantiate this result. A rigorous proof or explanation is necessary.
3. Clarification of Matrices in Lemma E.2 and Corollary E.3: The matrices \(C\) and \(D\) in Lemma E.2 and Corollary E.3 are not defined. Based on my understanding, \(C = AS^T\) and \(D = SB\), where \(S\) is the sampling matrix. This should be explicitly stated in the paper for clarity.
4. Connection Between Lemma E.1 and Theorem 4.1: The equivalence of the quantity \(\rho(x_B)\) in Lemma E.1 and \(\|\mathcal{T} - [A,B,C]\|^2\) in Theorem 4.1 is unclear. The paper should provide a detailed explanation or proof to establish this connection.
5. Runtime Complexity of Each Iteration: The runtime of each iteration of the proposed algorithm is claimed to be \(\tilde{O}(nR^3)\). However, the paper does not provide any details or derivations to support this claim. A thorough explanation of this runtime complexity is necessary.
Concerns Regarding Style and Presentation:
6. Inconsistent Notation: The notation used throughout the paper is inconsistent. For instance:
   - Both \(r\) and \(R\) are used to denote the size of the factor matrices (e.g., lines 124, 181, 210, 268 use \(r\), while elsewhere \(R\) is used).
   - The size of the design matrix \(X\) is denoted by \(R\) in some places, but \(p\) is used in line 121. This inconsistency should be addressed.
7. Definition of \(\tilde{O}\) Complexity: The paper uses the \(\tilde{O}\) notation for time complexity but does not define it. Since this notation may not be familiar to all readers, it should be explained.
8. Incomplete or Missing Statements: Several statements in the paper are incomplete or unclear:
   - Line 46: "of be" is incomplete.
   - Line 164: "i-th of" is missing context.
   - Line 165: Something is missing in the sentence.
   - Line 444 (Lemma E.1): \(U\) is not defined.
   - Lemma E.2 and E.3: \(C\) and \(D\) are not defined.
9. Minor Typos: The paper contains several minor typographical errors:
   - Line 5: "the the" should be corrected.
   - Line 52: "SPASL" should be clarified or corrected.
   - Line 108: "a challenging tasks" should be "a challenging task."
   - Line 185: "an rank" should be "a rank."
   - Line 202: "second term is spare, and the the" should be revised for clarity.
In summary, while the paper presents an interesting approach to accelerating ALS for tensor CP decomposition using leverage scores-based sampling, it requires significant improvements in theoretical justification, clarity of proofs, and consistency in presentation. Addressing these concerns will enhance the paper's overall quality and impact.