This paper proposes a novel objective function for restricted Boltzmann machines by replacing the KL divergence with a smoothed Wasserstein distance, yielding a generative model well-suited for tasks where the use of a metric is critical. The authors provide theoretical proof for the gradient derivation of the new objective function, conduct quantitative comparisons to analyze the properties of the smoothed Wasserstein distance, and demonstrate its utility through applications in data completion and denoising. Overall, the paper is well-written, with clear language and a coherent logical structure. It presents solid theoretical foundations, well-designed experiments, and promising application scenarios. The concept is clearly explained, and the motivation is convincingly articulatedâ€”specifically, that KL divergence is insufficient as a metric for problems where performance is evaluated in terms of distance. However, the experimental comparisons are limited to kernel density estimation, standard RBM, and Wasserstein RBM, with the first two relying on non-metric measures. Including results based on Euclidean distance and Hamming distance would make the comparisons more comprehensive and insightful.