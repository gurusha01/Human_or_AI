The paper introduces a novel sequence-to-sequence architecture that incorporates an encoder and a decoder, as is standard, but uniquely integrates a "reviewer" module between them. This module performs a fixed number of attentive iterations over the input representations, aiming to provide a more comprehensive representation of the input sequence. Additionally, the process can be enhanced by introducing an intermediate loss, such as a bag-of-words loss over the target sequence, to guide the reviewer module. The authors conduct experiments on two distinct tasks—image captioning and code captioning—and compare their approach to other state-of-the-art methods. However, a few recently proposed related approaches should be considered. Specifically, I recall: - Order Matters:..., by Vinyals et al., ICLR 2016, which introduces a "Process" module between the encoder and decoder that appears to share similarities with the "Attentive Input Reviewer" version in this paper. - Adaptive Computation..., by Graves, ArXiv 2016, which seems to have parallels with the Decoder module in this work.
I appreciate the concept of "discriminative supervision," which allows the reuse of supervision in a novel way (e.g., bag-of-words supervision). However, I would like to better understand its significance. In the experiments, the \(\lambda\) factor that balances this loss with the standard loss is fixed, leaving its impact unclear. Additionally, the experiments on COCO do not acknowledge that the MSCOCO website lists more recent results, which outperform those reported in the paper across nearly all metrics. Another experiment I would have liked to see is an analysis of the importance of \(Tr\), which is set to 8 in the COCO experiment. How does performance change if \(Tr\) is varied (e.g., lower or higher values)? Could this lead to potential overfitting? Regarding the image captioning model using VGG, it would be helpful to clarify which layer of VGG was used for input attention. Lastly, I would have appreciated a discussion comparing the "attentive input reviewer" and "attentive output reviewer," including guidance on when to use each and how they perform relative to one another.
========
After reading the authors' response, I find that all my concerns have been addressed. I believe the updated paper merits acceptance.