To address the bias in SG-MCMC, the authors introduce a novel approach termed stochastic gradient Richardson-Romberg MCMC (SG-RR-MCMC). This method leverages Richardson-Romberg extrapolation, a standard technique for SDEs. Specifically, SG-RR-MCMC operates by running two chains in parallel without communication. Theoretical analysis demonstrates that SG-RR-MCMC is asymptotically consistent, and empirical results further support its effectiveness. The proposed idea is both interesting and shown to be effective based on the empirical findings. It can be interpreted as a straightforward combination of Richardson-Romberg extrapolation and SGLD. The efficiency of the method is theoretically validated by offering an improved convergence rate, although this could also be achieved using a high-order integrator (unfortunately, the authors did not include experimental comparisons with such integrators). However, there are inconsistencies in the statements regarding the step size, as noted earlier. Additionally, Algorithm 1 (in the supplementary material) does not align with Equation (5).