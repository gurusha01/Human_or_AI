This paper aims to reduce contextual semibandits to a supervised learning framework, enabling the use of powerful supervised learning techniques in a partial-feedback setting. The authors assert that the policy class used for arm selection in contextual semibandits is large yet constrained. While this class allows for the learning of expressive policies, it also introduces the computational challenge of identifying a good policy without resorting to direct enumeration. The work builds on established supervised learning methods, such as logistic regression and SVMs for linear classifiers, as well as boosting for tree ensembles. The policy class is accessed solely through a supervised learning algorithm, treated as an oracle. The oracle-based algorithm proposed for contextual semibandits in this paper appears to be novel (to the best of my knowledge) and compelling. Both the theoretical regret bounds and the empirical evaluations presented in the paper substantiate the authors' claims.