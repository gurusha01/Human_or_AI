This paper introduces an efficient memory allocation strategy aimed at reducing GPU memory consumption during the backpropagation through time algorithm. The core concept involves leveraging dynamic programming to derive an optimal memory usage policy that effectively balances the tradeoff between memorization and recomputation. Empirical results demonstrate that, given a fixed computational cost for forward propagation, the proposed method achieves approximately half the memory usage compared to a prior approach. The limited memory capacity of modern GPUs remains a significant bottleneck in training very deep neural networks. To address this challenge, the paper presents a well-structured theoretical analysis and bounds. However, the experimental section has notable shortcomings. I believe that providing more evidence of the method's potential impact on real-world applications would enhance the paper's appeal. Detailed comments are as follows:
-- There are limited experiments conducted on large-scale datasets or real-world applications. Without such empirical evidence, it remains unclear how the proposed method's speedup or memory reduction compares to other approaches.  
-- The experimental results lack significance, as there is little to no speedup observed for very long sequences under feasible memory consumption conditions.  
-- The use of dynamic programming in this paper represents a somewhat incremental improvement over Chen's divide-and-conquer algorithm.  
-- Beyond memory cost, other factors, such as convergence speed and computational cost per iteration, also constrain the efficient training of very deep neural networks. Reducing memory consumption by a small margin has limited utility unless the reduction is substantial. Achieving orders-of-magnitude memory savings would be far more impactful.  
-- Minor: On page 7, the phrase "as expensive than a orward operation" should be corrected to "as expensive as a forward operation." Additionally, there are numerous typos in the supplementary materials.