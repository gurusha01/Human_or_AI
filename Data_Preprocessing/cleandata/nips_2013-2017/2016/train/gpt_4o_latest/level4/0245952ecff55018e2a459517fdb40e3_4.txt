This paper extends the deep generative modeling framework "Generative Moment-Matching Networks" by introducing a conditional generation mechanism. (This is achieved by deriving a kernel embedding of the moments that define the conditional distribution, enabling optimization using the same methodology as the unconditional version.) The proposed model demonstrates reasonably competitive performance across tasks such as predictive modeling, contextual generation, and distilling predictions from a Bayesian model. The paper appears to be technically sound, and the proposed methods are presented clearly. (However, I did not verify all the equations in exhaustive detail.) Regarding novelty, while extending the generative moment-matching framework to the conditional setting seems like a natural progression, the derivation of the empirical estimator and the underlying mechanism were not immediately obvious (at least to me). Thus, the paper appears to offer both novelty and practical utility. The derived framework, as outlined in Algorithm 1, seems straightforward to implement, making this work likely to be of interest and relevance to researchers focused on deep generative models or the distillation of complex statistical processes. The paper is well-written, clear, and easy to follow, with the appendix providing valuable additional details on the methods and experiments.