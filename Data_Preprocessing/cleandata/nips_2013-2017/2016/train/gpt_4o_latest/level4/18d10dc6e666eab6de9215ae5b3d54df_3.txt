The paper introduces a novel variant of a stochastic gradient algorithm integrated with Bayesian modeling, aimed at optimizing a multivariate objective function over a finite domain. The key innovation of the algorithm lies in its ability to identify multiple points for objective computation during each iteration, enabling parallelization of this process. The challenge addressed is the optimal selection of sampling points. To tackle this, the authors employ the Knowledge Gradient (KG) framework, which evaluates the expected improvement in the objective value when an additional sampling point is utilized, guiding the decision on whether and which point to sample. The proposed approach extends this framework to make decisions for multiple sampling points in a batch setting. Given the computational intractability of this problem, the authors propose an algorithm leveraging Monte Carlo methods and Infinitesimal Perturbation Analysis (IPA) to estimate the gradients necessary for maximizing information gain across candidate sampling sets. The algorithm is tested on various benchmark problems and demonstrates competitive or superior performance compared to existing methods in the literature, particularly those based on Confidence Bounds. The paper is well-written and has potential practical relevance. However, I am not fully convinced of the paper's level of novelty, as it primarily extends an existing approach (KG) to batch settings, which necessitates a more advanced optimization method for the criterion over multiple points. In my view, the main contribution lies in the estimation of the q-KG gradient using the IPA approach, which, while effective, is relatively standard. I have one specific comment/suggestion: In equation (3.1), since x^(1:n) represents a finite sequence of vectors, it is unclear how mu(x^(1:n)) and K(x^(1:n), x^(1:n)) are defined, as mu and K are functions of individual vectors (or pairs of vectors) rather than sequences.