The authors present an extension of LSTM that enables the processing of continuous-time data, addressing the limitation of LSTM and other RNNs, which are typically constrained to discrete-time data. The proposed method is effective and demonstrates strong performance across multiple datasets. The paper is well-written, clear, and the results are impressive.  
* I do not anticipate a significant increase in computational complexity; however, this is not explicitly addressed in the paper. Could the authors provide a comment on the time consumption, perhaps in terms of epochs per second?  
* The accuracy is remarkably high even from the first epoch. Is there any prior information incorporated into the training process?  
* Could the authors offer a more intuitive explanation of the gates, including their roles and why they function as intended?  
* Are the nodes with different time-gates independent? If so, does this imply that separate networks are being trained? How does this approach differ from using multiple standard networks with lagged input data?