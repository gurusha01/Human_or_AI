This paper attempts to establish a foundation for analyzing the churn of machine learning models, specifically examining how much the predictions of a model trained as an improvement over another differ from its predecessor. Greater churn poses challenges for practical evaluation. The authors propose a straightforward method to mitigate churn by regularizing towards the predictions of prior models and provide a theoretical analysis of this approach. I find this paper highly commendable due to its clarity, thought-provoking nature, and significant practical applicability.
Major strengths:
+ The paper offers a rigorous theoretical treatment of a problem that is highly relevant to machine learning practitioners.
+ The experimental results are comprehensive, and the P_win analysis is particularly noteworthy. I appreciate the effort the authors invested in making this theoretical work accessible and appealing to practitioners.
+ The connection to dropout and the use of a Markov chain as a means to achieve a robust model are both compelling and innovative.
+ The results demonstrate substantial improvements in some datasets, significantly reducing churn without compromising—and in some cases even improving—accuracy.
Major weaknesses:
- One key conclusion of the paper is somewhat underwhelming: there is an inherent trade-off between churn and accuracy.
- Additionally, the need to train 30-40 models to achieve burn-in for testing this approach is a significant practical drawback. 
An interesting future direction for addressing churn could involve leveraging unlabeled data or incorporating constraints. For instance, if we are willing to tolerate X% churn and have access to unlabeled target data, what strategies could be employed to enhance model stability under these conditions?