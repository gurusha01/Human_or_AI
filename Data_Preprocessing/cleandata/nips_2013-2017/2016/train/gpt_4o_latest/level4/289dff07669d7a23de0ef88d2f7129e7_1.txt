CMA-ES is widely recognized as the state-of-the-art stochastic (randomized) algorithm for derivative-free optimization. It integrates various learning mechanisms to adapt the parameters of a multivariate normal sampling distribution, which can also be interpreted as adapting an underlying metric. This paper introduces a novel variant for updating the covariance matrix using triangular Cholesky factors. Compared to previous approaches, this method offers significant advantages, including a substantial reduction in both the computational complexity of the update and the memory required to store the algorithm's state parameters. The proposed method undergoes rigorous numerical evaluation, demonstrating that it maintains the performance of the standard CMA-ES in terms of the number of function evaluations needed to achieve a target, while significantly reducing the algorithm's wall-clock time, particularly in high-dimensional settings. I believe this paper represents a highly valuable contribution to the field of optimization. This new variant of CMA-ES has the potential to become the default choice for medium- to large-scale problems due to its clear benefits: reduced memory requirements, lower computational complexity, and the automatic computation of the covariance matrix's eigenvalues. The paper is well-written, and the proposed approach is thoroughly evaluated. It is gratifying to see this contribution presented at NIPS, given that CMA-ES is deeply connected to machine learning, information geometry, and its applications in reinforcement learning and supervised learning. 
Minor comments: Please clarify how you ensure that the different implementations used in the experiments are comparable in terms of CPU performance (e.g., are they implemented in the same programming language, and if so, which one?). Additionally, when discussing Figure 2, the statement "the higher the dimensionality, the more pronounced the differences" does not seem to hold for the Cigar and Discus functions in dimension 256. Providing an explanation for this observation would be beneficial.