This paper introduces the use of bidirectional Monte Carlo (BDMC) to estimate the J-S divergence between an MCMC sampler and its target distribution, with a focus on debugging and assessing MCMC implementations in probabilistic programming languages (PPLs). I find the idea of employing BDMC to identify sampler convergence issues compelling—this approach appears potentially valuable, as current MCMC diagnostics have notable limitations. Two particularly relevant prior works are [1,2], which also evaluate MCMC samplers by applying them to data generated from the prior distribution.  
Section 3.1: I struggled to follow the derivation in this section. For instance, the function q(.) is introduced before being properly defined. Based on the context, it seems to represent the marginal distribution of the AIS sampler after T steps, but this should be explicitly clarified. While the supplementary material provides some additional clarity, the main text should be self-contained, and readers should not be required to consult the supplement to grasp the core ideas. More broadly, it would be helpful to include a concise, step-by-step explanation of how to implement the proposed method—currently, readers must infer this from scattered details.  
Minor comments: The distinction between z and θ as separate unobserved variables feels unnecessary in this general setting, as they always appear together. It might simplify the presentation to consolidate them into a single variable. Additionally, on line 165, there is a missing closing parenthesis.  
[1] Geweke, J. (2004). Getting it right: Joint distribution tests of posterior simulators. Journal of the American Statistical Association, 99(467), 799–804. http://doi.org/10.1198/016214504000001132  
[2] Cook, S. R., Gelman, A., & Rubin, D. B. (2012). Validation of software for Bayesian models using posterior quantiles. Journal of Computational and Graphical Statistics, 15(3), 675–692. http://doi.org/10.1198/106186006X136976