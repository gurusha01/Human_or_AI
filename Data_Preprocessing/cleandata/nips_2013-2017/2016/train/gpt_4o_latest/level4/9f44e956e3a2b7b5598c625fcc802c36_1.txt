This paper introduces a novel recurrent neural network (RNN) architecture incorporating "fast weights," which are parameters that evolve on a timescale intermediate between the rapid fluctuations of hidden activity patterns and the slower weight updates driven by gradient descent. These fast weights are updated automatically using a Hebbian learning rule, effectively embedding an associative memory within the dynamics of the RNN. Experimental results demonstrate that this approach can quickly learn a variety of (primarily visual) tasks, outperforming both standard LSTMs and LSTMs augmented with external memory in terms of learning speed and, in many cases, achieving lower error rates as well.
Major Comments:  
This paper presents an interesting concept: a weight matrix that is architecturally constrained to follow a specific learning rule and updates itself dynamically during processing. This general framework has the potential to inspire numerous future variants. The performance on the tasks presented is robust, making the proposed technique a valuable contribution to the field of machine learning. However, the claim in the conclusion that the primary contribution is to computational neuroscience and cognitive science is not substantiated by the evidence provided. The paper does not engage with experimental data from neuroscience or psychology, nor does it adequately address the broader computational neuroscience or cognitive science literature (e.g., Buonomano and Maass, 2009; or the extensive body of work on neural networks and recursive processing in human linguistic abilities, such as Prince and Smolensky, 1997).  
While the proposed method could plausibly contribute to understanding how (quasi)recursive computations might be implemented in the brain—a highly valuable goal—significant additional work is required to support this claim. If the authors intend to argue that fast weights enable recursive, compositional processing, a task explicitly designed to highlight this capability would provide a more compelling demonstration. For example, applying the method to natural language processing tasks would strengthen the paper, but to address cognitive science concerns, the results would need to go beyond improved performance. They should replicate human-like error patterns, such as those observed in complex "garden path" sentences. As it stands, the paper is firmly situated within the engineering tradition, where success is measured by improved performance on benchmark tasks.  
From a cognitive perspective, the paper's claims about multi-scale object representations are not entirely convincing. Humans do not obtain multi-scale views of objects and their parts by "zooming in" with their eyes; this process is mediated by attention. Additionally, the paper's presentation of the models used in each experiment is somewhat difficult to follow. The figures illustrating different architecture variants are subtly distinct (e.g., in Fig. 1, "sustained" transitions are marked with red arrows, while in Fig. 2, "integration" transitions are also marked with red arrows). The concept of an "integration transition" is not clearly defined, which adds to the confusion.
Minor Comments:  
- Table 3: Clarify whether the reported metric is classification accuracy.  
- The details of the reinforcement learning agent and the MNIST experiments are sparse and should be expanded.  
- The paper references an "appendix," but no appendix was included in the submission materials. Providing this could significantly enhance the reproducibility of the results. Additionally, some details currently omitted could be incorporated into the main text.  
- Cite the "asynchronous advantage actor-critic method."