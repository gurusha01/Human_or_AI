Stochastic Gradient MCMC (SG-MCMC) methods offer a straightforward approach for performing Bayesian posterior inference on large datasets and have garnered significant attention from the research community in recent years. However, a notable limitation of these methods is their asymptotic bias, meaning they do not converge exactly to the posterior distribution. This paper demonstrates that the bias can be mitigated using a technique known as Richardson-Romberg extrapolation. The core idea is quite intuitive: Two SG-MCMC chains are executed in parallel, with Chain 2 having half the step size of Chain 1. Additionally, Chain 2 is run for twice as many steps as Chain 1. The Gaussian noise injected into the chains is correlated, following the formula alphak = (beta{2k-1} + beta{2k})/sqrt(2), where alphak and beta_k represent the Gaussian noise injected at time step k in Chains 1 and 2, respectively. To estimate the expectation of a function f with respect to the target distribution, the estimate from Chain 1 is subtracted from the estimate obtained using Chain 2. This approach is shown to reduce the bias to O(gamma^2), compared to the O(gamma) bias observed when using either Chain 1 or Chain 2 alone (where gamma denotes the step size). The authors also establish a similar reduction in the mean squared error (MSE) of the estimates. 
I appreciate that the method is both simple to understand and easy to implement (as summarized above), requiring no significant modifications to the underlying SG-MCMC algorithm. Furthermore, the approach appears to be broadly applicable to a wide range of SG-MCMC algorithms, making it potentially very impactful for the Stochastic Gradient MCMC community.
Novelty: While Richardson-Romberg extrapolation is a well-established technique in numerical analysis, it is not widely recognized within the machine learning or stochastic gradient MCMC communities.
Clarity: The paper is well-written, and the presentation is clear.
Comments/Questions:
- Can this technique be directly applied to all SG-MCMC methods? If not, are there specific conditions beyond the requirement that the SG-MCMC algorithm satisfies the bound in Section 2.2: pi_gamma(f) = pi(f) + C * gamma + O(gamma^2)?
- Is it possible to extend this method to other approximate MCMC schemes that are not based on stochastic gradients, such as sub-sampling-based Metropolis-Hastings tests? How about Distributed SGLD?
- Since one chain must run for twice as long as the other, there is a significant amount of wasted computation where the chain with the larger step size remains idle. Could this be addressed by using three chains—one with a step size of gamma and two with step sizes of gamma/2—running all chains for the same number of steps? Would this modification increase the variance of the estimate?
- Is there a way to generalize this method to incorporate more than two step sizes?
- The chains require correlated noise injection, but I found the discussion on the effect of correlation between mini-batches unclear. Is the variance minimized when the same mini-batch is used for the k^th iteration of Chain 1 and the 2k-1^th and 2k^th iterations of Chain 2? Or is the impact of this correlation negligible?
- Regarding the matrix factorization experiment (Figure 5), I recommend running the experiment until convergence and including a comparison to SGD. While the current plot demonstrates that the proposed method outperforms SGLD, it would be more compelling to show that the method excels in scenarios where Bayesian approaches are advantageous (i.e., where it outperforms SGD). Bayesian matrix factorization is not commonly used in practice, so providing additional quantitative results could help persuade practitioners to adopt this method. Including an SGD baseline would also contextualize the final errors of SGRRLD and SGLD.
- Although the method is straightforward and clearly explained, including an algorithm box would make the paper more accessible to a broader audience. Many practitioners may not engage with the theoretical sections, so presenting pseudo-code early in the paper would enable readers less familiar with this domain to implement the method without needing to fully grasp the more technical details.