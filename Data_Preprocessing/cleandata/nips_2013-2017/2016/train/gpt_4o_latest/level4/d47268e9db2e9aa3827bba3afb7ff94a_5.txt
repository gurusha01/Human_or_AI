The authors present a perceptron model learning strategy leveraging quantum computing, which achieves notable training speedups. Beyond the specific contribution to the perceptron model, the authors demonstrate that re-envisioning learning strategies through the lens of quantum computing can yield better outcomes compared to directly adapting traditional learning methods to a quantum framework.
Major corrections:
- My primary concern pertains to the assumption that training observations have unit norm. The core contribution of this work lies in the training speedup achieved via quantum computing. However, Theorems 1, 2, and 3, along with Lemma 2, rely on the premise that input vectors have unit length. From a machine learning perspective, this is a significant assumption and is only valid under per-observation normalization schemes. For example, in a one-dimensional context, this approach restricts observations to just two values (-1 and 1). Does this assumption impact your conclusions? Would the same results hold in alternative scenarios?
- The explanation of the encoding process in lines 133-134 requires clarification. The final representation [0,0,0,0,0,1] was not clear to me.
- Certain phrases are ambiguous (e.g., lines 115-116, "while-but"). Please review grammar and sentence structure.
Minor corrections:
- Line 83: "algorthm" → "algorithm."
- Line 95: "quatum" → "quantum."