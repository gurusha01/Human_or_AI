The authors build upon generative moment-matching networks (GMMNs) by focusing on matching conditional distributions rather than joint distributions. The central concept involves embedding conditional distributions into a reproducing kernel Hilbert space, a method introduced by Song et al. in 2009. The proposed algorithm, CGMMN, is empirically tested on multiple real-world datasets. In the definition of $\hat{C}{Y|X}$ (Line90), the term associated with $\muX$ and $\muY$ (specifically, their estimators) is omitted. Moreover, the assumption that $\muX$ and $\muY$ are zeroes, implying that the data is pre-centered in the RKHS, is unconventional. Given that $\hat{C}{Y|X}$ is a critical component of CGMMN, it is important for the authors to clarify this missing term and explain how it is handled in gradient computation and practical experiments. While the proposed approach is innovative and well-conceived, the experimental results are somewhat underwhelming. Regarding predictive performance, CGMMN exhibits higher error rates compared to the state-of-the-art algorithm CMMVA on both datasets. For generative performance, the lack of comparisons between CGMMN and other conditional generative methods (e.g., conditional generative adversarial networks) makes it unclear whether the proposed algorithm produces superior samples. Additionally, the paper contains several typographical errors, such as "Frobeniu norm" (Line48), "an universal" (Line65), and "which the" (Line238). -----Update after the author rebuttal----- The authors have adequately addressed all my concerns. I will revise my scores accordingly.