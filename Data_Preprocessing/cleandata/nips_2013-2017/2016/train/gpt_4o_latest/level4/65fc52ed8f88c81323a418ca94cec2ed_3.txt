This paper introduces an unsupervised learning approach for deep networks that involves classifying samples into a predefined set of cliques. The authors propose an optimization procedure to partition samples into batches that respect known similarity and dissimilarity relationships between clique samples, while excluding pairs with unknown relationships. The method is iteratively refined, starting with HOG-LDA similarity in the first iteration, to improve the learned similarity network. The results are evaluated through nearest-neighbor classification using the learned similarity across several datasets. The paper is well-written and technically robust, particularly in the formulation of the optimization problem in Section 2.3. The consolidation of transitivity relationships into batches presents an intriguing perspective on similarity learning. However, apart from Section 2.3, the overall method appears somewhat ad hoc. There seems to be no compelling reason why batch assignments could not be performed directly on individual samples instead of cliques, aside from potential computational efficiency. Framing the method in terms of individual samples first, and then introducing cliques as an engineering solution to reduce problem complexity, could provide a more solid justification for the approach. 
The paper begins with the premise that initial similarities are unreliable, implying that most of them should not be assigned labels (training signals). It would be more compelling to explicitly relate the optimization objective to this premise, potentially framing it as an approximation of the broader problem. The paper's overall presentation is strong, but Section 2.2 is overly concise, which hampers reproducibility. Additionally, it lacks supporting references for key concepts (e.g., "complete-linkage clustering"). The experiments are generally sufficient, particularly the use of learned similarities for nearest-neighbor classification in challenging tasks. The comparisons with ground-truth nearest neighbors and supervised methods are especially insightful, as they contextualize the unsupervised learning results. However, the experimental analysis could be improved by breaking down the contributions of different components in the pipeline. For instance, training a classifier directly on cliques (as suggested in line 141, "Forcing them into different classes ...") would help isolate the impact of clique clustering on the final results. Another valuable baseline would involve training a simple two-stream network end-to-end on the same data. Since the authors argue that these alternative approaches would incorporate incorrect relationships, it is important to empirically demonstrate how the proposed method avoids this issue.
Finally, the visualization of merged RGB images as evidence of meaningful similarities is debatable. High pixel-level similarity does not necessarily imply semantic similarity, and it is conceivable that clustering based solely on RGB values could yield similar visualizations. To strengthen this analysis, the authors could compute objective metrics, such as cluster purity, to validate and complement the qualitative results.