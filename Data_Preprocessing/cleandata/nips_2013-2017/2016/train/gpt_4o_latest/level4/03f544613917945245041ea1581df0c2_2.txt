This paper employs the Richardson-Romberg (RR) extrapolation technique to stochastic gradient Langevin dynamics (SGLD) to mitigate the bias caused by gradient estimation noise. The resulting method, SGRRLD, demonstrates asymptotically lower bias and mean squared error (MSE) compared to SGLD. A synthetic experiment using a Linear Gaussian Model highlights the superiority of the proposed algorithm over SGLD. On the other hand, experiments conducted on the MovieLens dataset reveal a slight improvement in test RMSE, though the results are debatable. RR extrapolation has previously been shown in the literature to enhance the convergence rate of Monte Carlo estimates for stochastic differential equations (SDEs). This paper extends this technique to stochastic gradient Markov chain Monte Carlo (SG-MCMC) methods and provides theoretical proof that, under specific conditions, SGRRLD achieves a faster convergence rate than SGLD with the same step size, albeit at the cost of running two parallel Markov chains. The algorithm is clearly described and straightforward to implement. The synthetic experiments convincingly demonstrate the ability of SGRRLD to reduce bias in the tested scenario. However, it would be beneficial to include more real-world data experiments to substantiate the claim that this simple modification to SGLD significantly reduces bias.
While I have not verified the proof details of Theorems 1 and 2, I am curious about the conditions required for the potential function \( U \) to satisfy both theorems. Can \( U \) be multi-modal? Intuitively, if the gradient noise is uncorrelated, the two chains should quickly become independent, even if the Gaussian noise is correlated. How, then, does combining the two chains reduce the error order? Additionally, in real data experiments, do the authors observe any correlation between the two chains? 
A concern regarding the experimental setup and real-world data experiments is the authors' claim that the computational cost of SGRRLD is comparable to SGLD due to parallelization. However, SGLD could also be run with multiple parallel chains within the same time budget. If we compare the estimates from two parallel SGLD chains with those from SGRRLD, would the latter still exhibit the same RMSE improvement? Another issue arises in the real data experiments, where SGRRLD with step sizes \( \gamma \) and \( \gamma/2 \) is compared against SGLD with step size \( \gamma \). A fairer comparison would involve SGLD with step size \( \gamma/2 \), which has lower bias, and running two parallel chains. Finally, more real-world data experiments would strengthen the empirical validation of the proposed method.