The paper proposes the use of linear programming to identify adversarial examples for ReLU networks and introduces measures to evaluate robustness. It also clearly separates the method for generating adversarial examples from the method for assessing robustness. Considering the current focus on robustness in deep neural networks, this is undoubtedly a relevant and important topic for exploration. The paper is well-written, clear, and easy to understand. The results presented are compelling, and I believe that this work would be of interest to researchers in the deep learning community. 
However, I have two primary concerns: First, while the use of linear programming to find adversarial examples is an attractive idea, the method relies heavily on the linear characteristics of ReLU networks, which limits its broader applicability. Second, although the proposed methods outperform prior approaches in identifying adversarial examples, they do not lead to significant improvements in test set performance. Additionally, the authors do not provide evidence of their method's superiority on datasets beyond MNIST. 
Minor comments: I find the formalization of the linear constraints somewhat cumbersome. It is evident that at a given point \( x \), only one of the disjunction constraints is required. As such, introducing disjunctions only to later disregard them seems unnecessary.