This paper addresses the domain adaptation problem under the assumption that the labels of data in the target domain are unknown. To tackle this challenge, the proposed approach alternates between transduction and adaptation. Experimental results validate the effectiveness of the proposed method. However, I have several concerns regarding this work. First, with respect to the Structured Consistency term, it only enforces instances with different labels to exhibit low similarity. This could inadvertently lead to instances with the same label also having low similarity, which is undesirable for target domain classification. How does the proposed method mitigate this issue? Second, regarding the hyper-parameter settings, the lambda parameter in Equation 1 likely has a significant impact on the performance of the proposed approach. Please provide an analysis of the performance of the method under varying values of lambda. Additionally, please evaluate the effect of alpha. Third, since the proposed method alternates between transduction and adaptation, how many iterations are typically required? It appears that for each iteration, the DNNs need to be trained. If there are N iterations, this would necessitate training the DNN N times, which could make the entire framework computationally expensive. Please report the training time for the proposed method as well as for other baseline methods.