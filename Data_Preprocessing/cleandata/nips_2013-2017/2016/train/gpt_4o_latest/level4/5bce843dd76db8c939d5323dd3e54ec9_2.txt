This paper presents the Phased LSTM, a novel architecture designed to handle irregularly sampled data by incorporating a new time gate. The authors evaluate PLSTMs on four datasets, demonstrating improvements over standard LSTMs. Notably, for the N-MNIST and Lip Reading datasets, the method achieves performance surpassing the state-of-the-art. Overall, this is a strong paper. The proposed cell structure introduces a meaningful degree of novelty, and its effectiveness is well-validated. Considering the widespread use of time series data and the need to learn representations from irregularly sampled inputs, this approach has the potential for significant impact. The paper is well-written, and its presentation is clear. Minor questions/comments: How many samples were used to train the models in the frequency discrimination task, and how does accuracy vary with additional data? Can Phased LSTMs be stacked to further enhance performance? In Figure 4, please ensure the same color is used for Phased LSTM across both plots. Additionally, including a diagram of the deep learning architectures used in the experiments would be helpful. If space constraints prevent this, an appendix or extended version could provide this information.