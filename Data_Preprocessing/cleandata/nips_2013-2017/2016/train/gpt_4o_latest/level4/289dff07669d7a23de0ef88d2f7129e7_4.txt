The primary contribution of this work lies in leveraging the triangular Cholesky factorization technique to eliminate the square root operation in the standard CMA-ES, thereby reducing the computational cost associated with matrix inversion. The author introduces an approach supported by theoretical justification, demonstrating that it does not compromise the algorithm's performance. The proposed method decreases the runtime complexity of the algorithm without significantly affecting the number of objective function evaluations. This paper represents a valuable application of the Cholesky factorization method within the context of CMA-ES. However, could the author provide a more detailed theoretical explanation of how the approach achieves 'numerically more stable' computation? Additionally, while the Cholesky-CMA-ES appears to require the same number of objective function evaluations as the standard CMA-ES, it reduces wall-clock time, with the improvement becoming more pronounced as the dimensionality of the search space increases. Could the author explore the possibility of integrating the low-dimensional approximation [Loshchilov, 2015] into the current framework? This consideration is particularly relevant for practical scenarios, such as training neural networks in direct policy search, where the high dimensionality of the problems is a critical factor.