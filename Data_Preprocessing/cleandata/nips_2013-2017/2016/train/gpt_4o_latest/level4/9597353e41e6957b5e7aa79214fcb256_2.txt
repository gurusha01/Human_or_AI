This paper makes a valuable contribution to the semi-supervised clustering literature, presenting a compelling model, particularly from a learning theory perspective. The authors propose and analyze a novel clustering framework. In this setup, the algorithm not only receives a clustering instance and a distance function but can also issue "same cluster" queries to an oracle, which determines whether two data points belong to the same cluster. This model is innovative because previous approaches typically utilized either a distance function or a query oracle, but not both simultaneously. This dual access enables intriguing results within a "semi-supervised" clustering paradigm.
The paper's primary contribution is the introduction of a margin property, characterized by a parameter that effectively makes the clustering instance easier (or equivalently, strengthens the assumption). For k-means clustering, the authors identify a sharp threshold for this parameter. The proposed algorithm is relatively straightforward, consisting of a sampling phase followed by a binary search phase. Based on the relationship between this margin property, center proximity, and the careful adaptation of lower bounds, the paper establishes that there exist regimes where the problem is NP-hard without queries but becomes tractable under the additional assumption.
One potential concern with this model is that the instances where the margin property is most advantageous compared to the unsupervised case might also be the instances where it is most challenging for the user to determine their desired clustering outcome. Despite this limitation, I appreciate the direction this model takes and the learning theory insights it contributes to the field.