This paper explores the application of Richardson-Romberg extrapolation (RRE) to contemporary "big-data MCMC" techniques, with a particular emphasis on Stochastic Gradient Langevin Dynamics (SGLD). RRE, a well-established numerical integration method, has recently been effectively applied to numerical stochastic differential equations (SDEs). One of the notable contributions of this work is its effort to bridge the gap between the MCMC and SDE literatures, which could prove valuable for researchers in both areas. The authors propose a novel SGLD-RRE method, derive theoretical results regarding the convergence of this algorithm (including scenarios where SGLD-RRE outperforms standard SGLD), and present numerical experiments. Their results demonstrate significant improvements in toy problems and consistent, albeit modest, gains in large-scale settings. Overall, the paper is well-executed and clearly presented. 
As mentioned, this is a strong paper that establishes meaningful connections between two relatively distinct fields, offers interesting theoretical insights, and demonstrates the practical utility of the proposed algorithm. The writing is clear, the technical content appears sound, and the method itself represents a straightforward yet computationally efficient adaptation of RRE to SGLD. While this approach is unlikely to transform current practices, it is likely to find adoption among practitioners due to its practicality. 
Minor comments: In Fig. 1a, the depiction is somewhat misleadingâ€”it does not represent the empirically estimated posterior distribution but rather a Gaussian constructed using the empirical posterior mean and variance. This distinction should be clarified to avoid confusion for less experienced readers. Additionally, for Fig. 2a, it would be helpful to include a brief explanation of why the bias does not necessarily decrease as the step size is reduced, as this behavior might seem counterintuitive.