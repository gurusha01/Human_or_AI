This paper investigates the geometrical properties of a nonconvex objective in the context of completing a PSD matrix. The central result (Theorem 2.3) establishes that all data points \( x \) satisfying \( \nabla f(x) = 0 \) and \( \text{Hessian}(x) \geq -\tau I \) are global minima. This implies: (i) all such \( x \) are local minima and globally optimal, and (ii) all saddle points exhibit \( \text{Hessian}(x) < -\tau I \). Subsequent analysis reveals that \( \tau \leq 0.1p \), indicating that a higher sampling probability results in saddle points with larger negative curvature. This aligns with prior characterizations of functions possessing only strictly escapable saddle points, which ensures that certain optimization algorithms, such as cubic regularization, trust region methods, and SGD, can converge to global optima. 
To establish the main theorem, the authors focus on eliminating critical points that exhibit (1) high coherence with the standard basis (e.g., Lemma 3.7) and (2) significant negative curvature (e.g., Lemma 3.8) from the set of local minima. They then demonstrate that (3) the remaining critical points must necessarily be global optima (e.g., Lemma 3.10). This conclusion relies on showing that such points satisfy Lemma 3.3, which is ultimately derived via Lemma 3.6 and culminates in Lemma C.1.
* Part 2) Regarding Lemma 3.8, I interpret the authors' intent to be that data points satisfying both first- and second-order optimality conditions must have an \( \ell_2 \)-norm of at least \( \frac{1}{8} \), which is unattainable for data points where \( \text{Hessian}(x) < -0.1p I \). If this interpretation is correct, I recommend rephrasing Lemma 3.8 to enhance clarity. If not, the authors should clarify how such points are excluded.
* Part 3) The chain of reasoning in (3) feels somewhat lengthy. To improve readability, I suggest condensing this section. Additionally, Lemma C.1 is crucial for concluding that \( x \) satisfying Lemma 3.3 can only represent equivalent solutions (e.g., \( z \) and \( -z \) in the rank-1 case). It would be beneficial to include Lemma C.1 in the main text because (a) it is a critical step in the argument, and (b) Lemma C.1 introduces an upper bound on \( \epsilon \), which is a function of \( p \) in Lemma 3.3, allowing readers to better understand how \( p \) scales.
Other minor points:
1) In Theorem 3.2, the authors state \( \tau < -0.1p \), but \( \tau \) is defined as positive in Definition 2.2. Based on the context (e.g., Lemma 3.4), I believe the authors intended \( \tau \leq 0.1p \).
2) In Figure 1, the bound for the \( \ell\infty \)-norm should be \( 40u / \sqrt{d} \). Additionally, the figure is somewhat confusing; the \( \ell2 \)-ball represents the entire ellipsoid, not just a single circle.
In conclusion, this is a strong paper with significant contributions, but its presentation could be improved. The proof structure could benefit from clearer outlining, and the connections between technical definitions, intuitions, and prior work should be better articulated for readers less familiar with the field.