The authors investigate the robustness and consistency of the Robust k-means (RKM) objective. Within the framework of the universal breakdown point, they demonstrate that RKM is, in fact, not robust. Specifically, the universal breakdown point of RKM is 2/n for the unbiased proximal map and 1/n for the biased one. This implies that as few as two outliers can cause some centers to break down (i.e., move arbitrarily far). However, the authors counterbalance this finding by proving that RKM exhibits robustness on well-clustered data, provided the data satisfies the (\rho1, \rho2)-balanced property introduced by Ben-David and Haghtalab (ICML'14). Additionally, they establish that the consistency property of standard k-means continues to hold for the more general RKM. 
The paper is well-written, and the problem is clearly motivated. While the results are not groundbreaking, they are likely to be of interest to a subset of the clustering research community. The experiments are solid, though I did not focus heavily on them, as the paper's primary contribution lies in its theoretical insights. The exploration of robust clustering methods, particularly k-means variants that account for outliers, holds significant potential for impact. I recommend accepting the paper. 
Minor issues:  
- Line 23: Replace "when measured" with "when measured according."