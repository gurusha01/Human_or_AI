The paper introduces an alternative prior for Bayesian non-parametric (BNP) clustering, tailored for scenarios where the size of data in each cluster does not scale linearly with the total number of data points (i.e., the "rich-get-richer" assumption inherent in the Dirichlet Process (DP) and related priors is relaxed). The authors explicitly model the distribution of cluster sizes in their proposed process and present two variations of the process based on different distributions over cluster sizes. They also provide a Gibbs-sampling algorithm and a split-merge algorithm (detailed in the appendix). Comparisons are made to the DP and Pitman-Yor Process (PYP) across various datasets. The paper addresses a significant challenge in BNP clustering and proposes an intriguing prior. However, the work has the following shortcomings: 
1. As noted by the authors in line 64, [13] also tackled the same problem by introducing a uniform prior instead of the "rich-get-richer" prior implicit in the DP and PYP, demonstrating that their approach yields a larger number of clusters than the DP. Unfortunately, the authors neither compare their method to [13] nor provide a detailed discussion—beyond the brief mention in line 64—of how their approach relates to and differs from [13] in terms of the properties of the resulting prior.  
2. The authors do not thoroughly discuss the trade-offs involved in sacrificing consistency to achieve the micro-clustering property, nor do they compare this trade-off to the sacrifice of exchangeability made in [13].  
3. The experimental results lack conclusiveness. Are the reported improvements statistically significant? The new processes do not appear to exhibit consistently superior performance across all metrics compared to existing methods.  
4. The writing is somewhat difficult to follow, even for readers familiar with the field. The paper contains an abundance of symbols, which could benefit from simplification and improved clarity.