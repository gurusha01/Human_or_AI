This paper introduces an intriguing approximation aimed at making the information bottleneck method feasible for high-dimensional scenarios, which is effectively demonstrated through experimental examples. Additionally, since this approach relies on scalar products, the authors propose a nonlinear extension using kernels. Unlike other kernel-based feature extraction methods, the proposed kernel-information-bottleneck technique offers the unique advantage of producing an intermediate representation where features can be visualized. I believe this successful integration of the simplified information bottleneck and its kernel-based generalization makes the work deserving of publication at NIPS! Following a compelling presentation of the proposed simplification of the information bottleneck and its nonlinear kernel extension, the authors raise an interesting point in their discussion: unlike other feature extraction methods, which typically depend solely on the statistics of the input signal "x," the information-bottleneck features also incorporate the relevant signal "y." It would be valuable to explore practical examples of this relationship: how do the sparse features (e.g., Gabor-like edge detectors in natural images) differ when the signals retaining information are tied to a specific class of images (e.g., faces)? Could this be linked to the top-down adaptation mechanisms in early vision processes?