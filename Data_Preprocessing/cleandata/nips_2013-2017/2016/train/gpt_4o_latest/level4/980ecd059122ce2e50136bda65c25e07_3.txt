This paper explores methods to evaluate the robustness of neural networks. The authors introduce a point-wise robustness metric, defined as the smallest perturbation (in \(\ell_{nifty}\) norm) required to alter the network's prediction. Building on this, they propose two additional metrics: the first measures the probability that the point-wise robustness of an input falls below a given threshold, and the second calculates the conditional expected value of the point-wise robustness for inputs below the same threshold. Given the challenges in computing robustness with ReLU activation functions, the authors propose a tractable convex relaxation to derive an upper bound. Using their proposed metrics, they also present strategies to enhance neural network robustness and showcase their superiority over existing approaches.
I find this paper to be a meaningful contribution to the understanding of neural network robustness. While the proposed concept is not entirely groundbreaking, the authors have undertaken a non-trivial effort to work out the details, resulting in a solid contribution to a highly relevant and timely topic. Therefore, I believe this paper would be a valuable addition to NIPS. Below are some more detailed comments:
1. The point-wise robustness concept seems closely related to the notion of "margin." It would be helpful if the authors could elaborate on this connection.
2. The concept of adversarial severity is less intuitive. For instance, consider a scenario where the robustness of a network is improved such that all points with an original point-wise robustness below \(\epsilon'\) are now increased to \(\epsilon\) (\(\epsilon' > \epsilon\)). However, the adversarial severity for the more robust network appears larger (suggesting reduced robustness) due to the conditional expectation used. To address this, I suggest considering \(E[\rho \mathbb{1}(\rho \leq \epsilon)]\) instead.
3. Line 170: There is a repeated "when when."
4. It might feel more natural to move the subsection on rounding error to the experimental section.
5. The authors note that their method does not significantly improve the robustness of NiN. Is there an intuitive explanation for this, even if hypothetical?