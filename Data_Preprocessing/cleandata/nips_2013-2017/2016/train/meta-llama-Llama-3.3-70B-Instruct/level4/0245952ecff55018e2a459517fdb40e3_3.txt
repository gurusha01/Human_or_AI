This manuscript presents a novel loss function designed for directed generative models that incorporate conditional variables, building upon the foundation of generative moment matching networks. The approach utilizes an unconditional loss function rooted in the maximum mean discrepancy criterion and extends it by leveraging conditional kernel mean embeddings to formulate the loss function. The efficacy of this method is demonstrated across a range of generative tasks, including classification, generation of handwritten digits and faces, and knowledge distillation in Bayesian models. As this is my second review of the paper, I note that the authors have addressed the minor concerns raised in the initial review, such as the choice of a low-dimensional space, scalability to higher-dimensional latent spaces, and the model's utility compared to existing alternatives. However, I require clarification on Remark 1, specifically the mapping from Equation (2) to the weighted MMD form, and the notation used, which could refer to either matrix multiplication or the Hadamard product. Additional detail would enhance the clarity of this mapping. Furthermore, the use of the symbol "C" is potentially confusing, as it is also employed to define the conditional embedding. Theorems 1 and 2 are referenced from other works, but Theorem 3 lacks a citation or proof, which should be provided for completeness. The empirical results presented are satisfactory, although the application of this model to supervised learning, as previously discussed, may not be its strongest suit. The demonstration of its versatility is appreciated, nonetheless. The application to distilled Bayesian inference is intriguing but limited in scope, as it is only applied to a single dataset and model, leaving its broader utility uncertain. I believe this approach holds the most promise in the realm of pure generative modeling, where the experiments are comparable to those in the original GMM paper, using datasets of digits and faces to adequately demonstrate the concept's feasibility. For this method to gain widespread adoption, however, compelling results on more challenging datasets, such as CIFAR-10 or LSUN, would be necessary.