This manuscript presents a novel approach to parameter inference, where the objective is to estimate the posterior distribution of parameters, p(theta|x), given a set of observed variables x and underlying parameters theta. The problem is formulated under the assumption that sampling from the conditional distribution p(x|theta) is feasible, albeit without an explicit form. A prior distribution, p(theta), is also assumed to be available. Traditional methods for addressing this problem typically involve approximating p(x=x0|theta) with p(||x-x0|| < epsilon|theta) and employing sampling techniques, such as Markov Chain Monte Carlo (MCMC). However, these methods only provide an accurate approximation as epsilon approaches zero, which coincides with a significant increase in computational complexity. In contrast, the proposed method involves training a neural network to directly learn the posterior distribution p(theta|x), normalized by a known ratio of pt(theta) to p(theta). The network outputs parameters for a mixture of Gaussians. Training data are generated by sampling from a distribution pt(theta), passing the samples through a sampler to obtain corresponding x values, and then training the network to predict p(x|theta) from the input theta. The choice of pt(theta) is crucial for convergence speed, and a refinement method is proposed, which iteratively updates pt(theta) using the current model, starting from the prior p(theta). Experimental results on multiple datasets demonstrate the effectiveness and improved convergence of the proposed method compared to MCMC and simple rejection methods. The paper is well-structured, and the methodology appears sound. Although related works are discussed, it would be beneficial to include direct comparisons with these methods on at least one problem, and it is unconventional that these discussions appear towards the end of the paper rather than in the introduction.