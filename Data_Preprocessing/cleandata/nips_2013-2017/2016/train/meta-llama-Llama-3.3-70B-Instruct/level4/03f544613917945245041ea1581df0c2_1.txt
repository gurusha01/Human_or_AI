This manuscript explores the application of Richardson-Romberg extrapolation (RRE) to contemporary "big-data MCMC" techniques, with a particular emphasis on Stochastic Gradient Langevin Dynamics (SGLD). As a well-established tool in numerical integration, RRE has recently demonstrated promising applications in numerical stochastic differential equations (SDEs), and a notable aspect of this work is its ability to bridge the gap between the MCMC and SDE literatures, potentially benefiting both fields. The authors propose a novel SGLD-RRE method, derive theoretical convergence results for this algorithm (including scenarios where SGLD-RRE outperforms standard SGLD), and present numerical experiments. The results show significant improvements in toy examples and consistent, albeit modest, enhancements in large-scale scenarios. Overall, the paper is well-structured and clearly written, offering an interesting intersection of two distinct areas, compelling theoretical insights, and strong empirical performance of the proposed algorithm. The methodology represents a relatively straightforward application of RRE to SGLD, which is computationally efficient. While the approach is not expected to revolutionize current practices, it is likely to be adopted by practitioners. Some minor suggestions for improvement include clarifying Fig 1a to indicate that it depicts a Gaussian distribution with empirical posterior mean and variance, rather than the empirical estimated posterior distribution itself, to avoid potential confusion. Additionally, Fig 2a would benefit from a brief discussion explaining why the bias does not necessarily decrease with diminishing stepsize, as this may seem counterintuitive to some readers.