This manuscript explores the robustness of neural networks, introducing a point-wise robustness metric that quantifies the smallest perturbation, measured in $\ell_{nifty}$ norm, required to alter the prediction. From this foundation, the authors derive two additional metrics: the probability that the point-wise robustness falls below a specified threshold and the conditional expected value of the point-wise robustness when it is below this threshold. However, computing robustness with ReLU activation functions poses challenges, which the authors address by proposing a tractable convex relaxation to obtain an upper bound. Building on their metric, they outline strategies to enhance neural network robustness and demonstrate superiority over existing methods. 
The paper offers an interesting contribution to the understanding of neural networks. Although the proposed concept may not be entirely novel, the detailed development and analysis represent a non-trivial effort, contributing significantly to a critical and trendy topic. Therefore, I believe its inclusion in NIPS would benefit the community.
Several detailed comments are worth noting:
1. The concept of point-wise robustness appears to have a close relationship with the notion of "margin." It would be enlightening if the authors could elaborate on this connection.
2. The concept of adversarial severity seems less intuitive, particularly in scenarios where improving network robustness could paradoxically increase adversarial severity due to the conditional expectation used. An alternative approach could involve examining $E[\rho \mathbb{1}(\rho\leq \epsilon)]$.
3. A minor error, "when when," is noted at L170.
4. It might be more logical to relocate the subsection on rounding errors to the experiments section for better flow.
5. The authors mention that their proposed method does not significantly improve the robustness of NiN, and it would be helpful to have an intuitive, even hypothetical, explanation for this observation.