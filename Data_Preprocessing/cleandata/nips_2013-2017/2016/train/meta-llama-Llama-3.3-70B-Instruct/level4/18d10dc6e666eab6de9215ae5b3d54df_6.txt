This study presents a methodology for parallel Batch Bayesian Optimization, which involves computing an optimal batch of configurations for evaluation using the knowledge gradient (q-KG) as a utility measure. The authors propose an infinitesimal perturbation analysis-based method to efficiently maximize the acquisition function. Through three experiments, they demonstrate that q-KG is competitive with existing parallel Bayesian optimization methods in noise-free problems and outperforms them in problems with observation noise. While the concept of parallel hyperparameter optimization for efficient multi-core environment utilization is appealing, certain aspects of the work remain unclear, and the experimental results are not entirely convincing.
Regarding technical quality, the paper utilizes common artificial benchmark functions to demonstrate the superiority of the proposed method and also presents results for optimizing a CNN and logistic regression on Cifar10/MNIST. However, it would be beneficial to include an experiment showing wall-clock time or an analysis of the gains from using this parallel method compared to simple random search or sequential optimization. Additionally, the choice of q = 4 for all experiments is not justified. 
In terms of novelty and originality, the paper proposes using the knowledge gradient as an acquisition function and infinitesimal perturbation analysis to maximize q-KG. Although both methods are not new, the combination is notable. The paper references "Parallel Bayesian global optimization of expensive functions," which uses IPA to select a batch of configurations using expected improvement, but the current work's approach is distinct.
The impact and usefulness of parallel hyperparameter tuning methods are significant, with applications in machine learning, computer vision, biology, and robotics. 
The technical details and background section are well-described, and the experiment section contains necessary information for comprehending the comparisons. However, some questions arise: 
1. Have the authors compared their method to Wang et al. (2015), and if so, how does it differ from "parallel EI in MOE"? 
2. How scalable is the method, and what are the potential gains from increasing the number of parallel runs beyond 4? 
3. Is it possible to extend the method to run asynchronously, similar to Spearmint? 
4. How does the method compare to random search or simple sequential Bayesian optimization in terms of wall-clock time, and what is the overhead for computing a new batch? 
5. What does "iterations" represent in the plots, and does the x-axis include the initial design?
Minor comments include: 
* A potential missing term in equation (4.1)
* Grammatical errors, such as "achieve" instead of "achieves"
* Incorrect reference formatting, such as parenthetical references
* The incorrect attribution of the introduction of infinitesimal perturbation analysis to Wang et al. (2015).