This manuscript proposes a novel approach for estimating test error from unlabeled data, applicable to distributions that diverge from the training set distribution. The methodology leverages the method of moments, coupled with the assumption that the feature space can be segmented into three conditionally independent subspaces relative to the output, referred to as the 3-views assumption. Notably, this approach does not impose assumptions on the optimal predictor or the parametric form of the distribution, and it can be extended to structured output scenarios, such as Hidden Markov Models (HMMs). The paper is well-structured, and the proofs appear to be sound. However, my primary concern revolves around the realism and applicability of the 3-views assumption. This assumption is more stringent than that underlying co-training, which was introduced for multi-view learning, and has been debated in the literature as potentially unrealistic, especially in the context of mono-view learning. I recommend that the authors provide a discussion on whether this central assumption can be relaxed or, at the very least, offer insights into how to address scenarios where this assumption may not hold, which could be a common occurrence in more general cases.