This manuscript presents a pioneering work by deriving fast learning rates for unbounded domains with heavy-tailed loss functions, subject to specified conditions. Notably, the authors provide a methodology to verify one of these conditions, known as the multi-scale Bernstein condition, in practical scenarios. However, the other condition, which imposes polynomial entropy bounds on the hypothesis class, remains less transparent, and the discussion hints at potential avenues for extension. In the context of bounded loss, the novel result aligns with the state-of-the-art findings of Mehta and Williamson (2014). The proof leverages recent developments by Lederer et al (2014) to establish bounds on the suprema of empirical unbounded processes. Furthermore, the paper demonstrates an application to k-means clustering under heavy-tailed data distributions. The manuscript appears to be technically sound and contributes meaningfully to the field. Nevertheless, a point of clarification would be beneficial: could the authors provide further insight into the restrictiveness of the polynomial entropy boundedness condition and whether there are indications that the results might be generalizable beyond this condition?