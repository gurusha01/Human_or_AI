Here is a paraphrased version of the review:
The paper presents a novel approach to solving large-scale overdetermined least squares regression problems, specifically in the context of low-rank tensor CANDECOMP/PARAFAC (CP) decomposition. The authors propose a leverage scores-based sampling method for the alternating least squares minimization problems that arise during the computation of tensor CP decomposition. This involves representing the tensor as a sum of rank-1 tensors, which can be further represented as low-rank factor matrices. The low-rank factor matrices are computed using the Alternating Least Squares (ALS) approach, which requires solving least squares problems with the tensor matricization and the Khatri-Rao product (KRP) of the remaining factor matrices. The paper introduces a leverage scores-based sampling of the matricization and the KRP prior to solving the least squares regression problem. A key contribution of the paper is the computation of leverage scores for the rows of the KRP, which is achieved by replacing the exact leverage scores with an upper bound, shown to be the product of the scores of the constituting matrices. Experimental results demonstrate the speedup of the proposed algorithm.
However, several concerns and questions arise. Theoretically, it is unclear why leverage-based sampling is preferred over other randomized sampling or sketching approaches that do not require leverage scores computation. The paper's Theorem 4.1 states that the number of samples required is m = Θ(R^2 log n / ε^2), which appears to be worse than other randomized sampling methods, such as those proposed in references [15] (Drineas et al., 2011) and (Woodruff, 2014). The advantages of the proposed method over other sampling methods need to be discussed.
Furthermore, the derivation of the sample complexity in Theorem 4.1 is not provided, and the proof is missing. Additionally, the matrices C and D in Lemma E.2 and Corollary E.3 are not defined, and their connection to sampling is unclear. The equivalence between the quantity ρ(x_B) in Lemma E.1 and the expression in Theorem 4.1 is also not established. The claimed runtime of each iteration of the algorithm, Õ(nR^3), lacks detailed explanation.
In terms of style and presentation, the notation is inconsistent, with both 'r' and 'R' used to denote the size of the factor matrices. The size of the design matrix X is also inconsistently represented. The use of Õ time complexity is not explicitly defined, which may not be familiar to all readers. Several statements are incomplete or missing, including lines 46, 164, 165, and 444. Minor typos are also present throughout the paper.
Overall, while the paper proposes a fast method for estimating the alternating least squares that appear during the computation of tensor CP decomposition, several concerns and questions need to be addressed to improve the clarity and rigor of the presentation.