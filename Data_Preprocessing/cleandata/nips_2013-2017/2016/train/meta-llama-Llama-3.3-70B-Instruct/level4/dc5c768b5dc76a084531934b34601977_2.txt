This manuscript attempts to establish a framework for analyzing the churn of machine learning models, specifically examining the extent to which a new model, developed as an improvement over a previous one, alters the predictions of the original model. As the degree of change increases, so does the difficulty of evaluating the model in practical scenarios. The authors propose a straightforward method to mitigate churn by regularizing the predictions towards those of past models and provide a theoretical justification for this approach. The paper's clarity, thought-provoking nature, and potential practical utility are notable strengths. Key advantages of this paper include: 
+ A comprehensive and theoretically sound treatment of a highly relevant problem in machine learning practice.
+ The experiments are rigorous, and the P_win analysis is particularly noteworthy. The authors' effort to make this theoretical work appealing from a practical standpoint is appreciated.
+ The connection to dropout and the utilization of Markov chains to achieve a robust model are intriguing aspects.
+ The approach yields substantial gains in certain cases, significantly reducing churn without compromising accuracy. 
However, there are also significant weaknesses:
- A major conclusion, namely the trade-off between churn and accuracy, is not particularly novel or inspiring.
- The requirement to train numerous models (30-40) to initialize the approach is impractical and unappealing. 
An alternative direction for addressing churn could involve leveraging unlabelled data or applying constraints, such as determining the optimal method to utilize unlabeled target data to enhance model stability when a specific level of churn (e.g., X%) is acceptable.