This paper presents an exploration strategy in reinforcement learning, leveraging intrinsic motivation. A novel uncertainty metric, termed pseudo-count, is introduced, which demonstrates effectiveness in navigating large state spaces, as evidenced by experimental results on challenging games. The authors establish a connection between this approach and other intrinsic motivation measures, such as Bayesian information gain. However, further discussion on the relationship with existing work, particularly "Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning", which explores mutual information and channel capacity in the context of path-counting, would enhance the paper. The technical quality is supported by well-designed experiments in complex environments. The novelty of this work lies in its innovative approach to uncertainty measurement through counting methods. Nevertheless, the connections to similar techniques, as seen in section A of the aforementioned reference, are not fully explored. The potential impact of this research is significant, given its ability to handle large state spaces, making it a useful contribution. The paper's structure and presentation are clear and well-organized.