The paper explores a crowdsourcing framework where a taskmaster breaks down a complex task, such as an inference problem, into smaller tasks that are then assigned to a crowd of workers. The crowdsourcer subsequently collects and processes the information provided by these workers to complete the inference task. This setup accommodates workers with varying skill levels and potential unreliability in reporting their findings. The primary objective is to achieve a certain level of fidelity or quality in the final outcome, despite the presence of incorrect information from some workers. To accomplish this, the taskmaster must carefully design the small tasks or queries allocated to the workers. The total number of queries presented to the workers is defined as the budget of the crowdsourcing system. The paper investigates the fundamental trade-off between the budget and fidelity, which is achieved by mapping the crowdsourcing system to the problem of joint source channel coding in information theory. By treating the taskmaster as a transmitter and the crowdsourcer as a receiver/decoder, and considering the unreliable links from workers to the crowdsourcer as a communication channel, the authors derive a lower bound on the budget required for a desirable fidelity level. This bound is independent of the specific query design schemes used by the taskmaster and the algorithms employed by the crowdsourcer to process worker information. The authors then examine the performance of a specific scheme, k-ary incidence coding, and compare it to the obtained information theoretic lower bound for a particular channel model. The parallel drawn between the rate-distortion framework and the crowdsourcing system with unreliable workers is noteworthy, and this work may inspire further research into applying information theoretic tools to crowdsourcing frameworks. However, the reviewer questions the realism of the models presented, as they seem to simplify the complexities of real-world crowdsourcing systems to fit the point-to-point communication problem, allowing for the direct application of existing information theory results. The authors are encouraged to address the following concerns: 1) The merging of worker reliability and skill level into a single channel model, and the assumption that the taskmaster allocates the same number of queries to all workers regardless of skill level, may not accurately reflect real-world scenarios where workers have varying skill levels and ratings. 2) The realism of the channel models in capturing worker unreliability, particularly in cases where workers may intentionally degrade fidelity in an adversarial manner, is uncertain. The explanation of numerical results, specifically the labeling of curves in Fig. 2, could be improved, and the $k=1$ case requires clarification. Additionally, the assumption of knowledge about $P(B(X))$ should have been stated earlier in the paper. Minor corrections include the swapping of figure references in page 4, line 135, and the inconsistent use of 'Theorem', 'Lemma', and 'Corollary' without accompanying numbers, which could be replaced with lowercase equivalents for consistency.