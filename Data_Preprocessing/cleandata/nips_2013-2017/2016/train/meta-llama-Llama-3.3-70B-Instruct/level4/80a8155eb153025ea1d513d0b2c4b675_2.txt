The authors investigate the robustness and consistency of the Robust k-means (RKM) objective, leveraging the universal breakdown point framework to demonstrate its lack of robustness. Specifically, they find that the universal breakdown point for RKM with an unbiased proximal map is 2/n, and 1/n for the biased version, indicating that even a small number of outliers (as few as 2) can significantly disrupt the placement of cluster centers. However, the authors also show that RKM exhibits robustness on well-structured data, as defined by the concept of (\rho1, \rho2)-balanced datasets introduced by Ben-David and Haghtalab (ICML'14). Furthermore, they establish that the consistency property of traditional k-means remains applicable to the more general RKM framework. The paper is well-organized and clearly motivated, with results that, although not groundbreaking, are likely to be of interest to researchers in the clustering community. While the experimental section is thorough, the primary contribution of this work lies in its theoretical foundations, which is where the authors' efforts shine. The examination of robust clustering variants, including k-means, has significant potential for impact, particularly in scenarios involving outliers. Overall, I recommend accepting this paper, noting that minor revisions, such as correcting typos (e.g., Line 23, where the term "measured" is used), would further enhance its quality.