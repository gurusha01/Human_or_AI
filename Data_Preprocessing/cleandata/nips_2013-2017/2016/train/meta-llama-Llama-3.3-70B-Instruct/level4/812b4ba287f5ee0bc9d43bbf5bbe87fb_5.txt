This paper proposes a tree-structured reinforcement learning (Tree-RL) approach to capture the interdependency among objects by sequentially searching for object candidates, starting with an entire image and discovering multiple objects through a tree-structured traversing scheme. At each tree node, the agent takes simultaneous scaling and local translation actions, navigating multiple near-optimal search paths learned via the deep Q-learning framework. The experimental section is designed to evaluate three key aspects: a comparison between tree search and single path search, a comparison with several object proposal algorithms, and an assessment of object detection frameworks with and without the proposed object proposals.
However, as a preprocessing step, object proposal algorithms require time efficiency, and while several algorithms (as seen in Figure 5) report their runtime, this paper lacks time measurement or complexity analysis, despite claiming computational efficiency. A comparison with other algorithms in terms of time efficiency would be beneficial. 
Furthermore, Figure 6 could be enhanced with more qualitative results, as the current examples primarily feature images with two main objects. Including qualitative comparisons with other object proposal algorithms for cases with one main object or more than two objects would provide a more comprehensive evaluation.
The justification for the specific tree structure used seems unclear. Questions arise regarding the choice of translation and scaling actions for the left and right child nodes, and whether alternative variations were considered. Additionally, introducing randomization in node splitting or exploring other strategies could potentially improve generalization.
The technical contribution of this paper appears marginal compared to existing work, such as [18]. Except for the tree-structured search section, the definition of actions, states, rewards, and the optimization method using deep Q-learning closely resembles [18] and [22]. A key difference, as noted by the authors, is that [18] repeats the process multiple times for object detection, whereas this paper runs the process sequentially once. This distinction could be more clearly demonstrated through experiments focusing on time efficiency and providing more qualitative and quantitative results.