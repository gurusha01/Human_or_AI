This manuscript introduces approaches designed to mitigate prediction churn, which refers to changes in the predictor, without compromising the potential accuracy gains that such changes could bring. Following a clear motivation of the problem, the authors propose two stabilization operators that can be integrated with a Markov Chain Monte Carlo (MCMC) chain. This chain iteratively perturbs the training sets, aiming to simulate the changes that occur in practice as more data is collected and new features are introduced. The paper provides theoretical support for the proposed method, albeit in a limited context, along with experimental results on real datasets. The presentation is clear, and the problem is well-motivated. The proposed stabilization operators are logical but introduce two additional hyperparameters that require tuning. For the method to be effective, the MCMC chain should accurately reflect real-world changes, such as the increase in available training examples and features over time. However, the proposed chain maintains these numbers at a constant level over time, which significantly impacts its potential effectiveness.