This manuscript proposes a novel objective function for restricted Boltzmann machines, wherein the KL divergence is substituted with a smoothed Wasserstein distance, yielding a generative model tailored for applications where metric-based evaluation is crucial. The authors provide a theoretical foundation for deriving the gradient of this new objective function, as well as quantitative analyses and comparisons to elucidate the characteristics of the smoothed Wasserstein distance. Furthermore, the paper demonstrates the efficacy of this objective function through its application in data completion and denoising tasks. Overall, the manuscript is well-structured, with clear language and logical coherence, offering robust theoretical support, meticulously designed experiments, and promising potential applications. The presentation of the central idea is straightforward, and the motivation for replacing KL divergence with a distance-based metric, due to its limitations in problems where performance is assessed in terms of distance, is convincingly argued. Nevertheless, the comparative analysis of results is limited to kernel density estimation, standard RBM, and Wasserstein RBM, all of which, except for the latter, rely on non-distance metrics. To further strengthen the manuscript, it would be beneficial to include comparative results using Euclidean distance and Hamming distance, providing a more comprehensive evaluation of the proposed objective function's performance.