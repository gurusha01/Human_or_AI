This paper presents a novel approach to enhancing the convergence of the Stochastic Gradient Markov Chain Monte Carlo (SG-MCMC) algorithm by utilizing the Richardson-Romberg extrapolation, a numerical sequence acceleration method. The proposed technique involves running two SG-MCMC chains in parallel with different step sizes and correlated Gaussian noise injection. The authors provide a comprehensive analysis of both asymptotic and non-asymptotic convergence properties. Experimental results on a synthetic Gaussian model validate the theoretical bounds, while large-scale matrix factorization experiments on real data demonstrate the practical applicability of the proposed algorithm, outperforming the standard Stochastic Gradient Langevin Dynamics (SGLD). Overall, the paper is well-structured and presents a valuable contribution to the field of SG-MCMC methods, effectively contextualizing the proposed technique within the existing literature. However, two primary concerns arise: (1) the novelty of the paper may be limited, as the impact of numerical integrators on SG-MCMC has been previously explored in [10], and the application of Richardson-Romberg extrapolation for approximating invariant distributions has been discussed in [23]. (2) the practical utility of the algorithm may be restricted, and the experimental comparison may be incomplete. The parallel implementation of the SG-MCMC algorithm requires communication between the two chains at each step, but the authors seem to overlook the associated communication cost. It would be beneficial to acknowledge this aspect. Furthermore, the allocation of computing resources for the SGRRLD and SGLD algorithms in the experiments is unclear. For instance, is the single SGLD chain implemented using the same resources as the two SGRRLD chains? If not, this may not be a fair comparison from a practical standpoint. If yes, then it is essential to clarify how the resources are divided between the two SGRRLD chains. Given that the computational cost of SG-MCMC is primarily attributed to stochastic gradient calculations, it is puzzling how the partial resource utilization in SGRRLD for gradient computation at each chain could lead to reduced wall-clock time compared to the full resource utilization in SGLD. Additional details on the implementation setup would be appreciated. Alternatively, it would be interesting to compare the results with those obtained by running two embarrassingly parallel SGLD chains without communication. Minor comments include the redundant mention of "Unadjusted Langevin Algorithm (ULA)" on lines 25 and 70.