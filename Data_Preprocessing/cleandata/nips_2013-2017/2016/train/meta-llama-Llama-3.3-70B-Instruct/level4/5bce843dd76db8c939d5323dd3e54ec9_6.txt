The authors present a novel extension of Long Short-Term Memory (LSTM) networks, enabling the processing of continuous-time data, which is a significant limitation of traditional LSTMs and other Recurrent Neural Networks (RNNs) that are confined to discrete-time data. The proposed approach yields promising results across multiple datasets. The paper is well-organized and clearly written, with notable results. However, it would be beneficial to include an analysis of the computational complexity, potentially by reporting the time consumed in terms of epochs per second, to provide a clearer understanding of the method's efficiency. Furthermore, the high accuracy achieved, even in the initial epoch, raises questions about the potential incorporation of prior knowledge into the training process. Additional insight into the functionality and effectiveness of the gates would be valuable, as well as clarification on the independence of nodes with different time gates and how this approach differs from training separate networks with lagged input data, or utilizing multiple conventional networks.