This paper presents a novel approach to optimizing memory allocation for the back propagation through time algorithm, leveraging dynamic programming to strike a balance between memorization and recomputation. The empirical results demonstrate that, under a fixed computational cost for forward propagation, the proposed method reduces memory usage by approximately half compared to a previous approach. The limited memory capacity of modern GPUs poses a significant challenge to training deep neural networks, and this paper addresses this issue by introducing an effective memory allocation strategy. The theoretical analysis and bounds are well-presented, providing a solid foundation for the proposed method. However, the experimental section has some limitations. To further enhance the paper's impact, it would be beneficial to provide more evidence of its potential influence in real-world applications. The detailed comments are as follows: 
- The paper lacks experiments on large-scale datasets or real-world applications, which makes it unclear how the proposed method compares to others in terms of speedup or memory usage reduction. 
- The experimental results are not particularly significant, as there is minimal speedup for very long sequences with feasible memory consumption. 
- The dynamic programming approach adopted in this paper can be seen as an incremental improvement over Chen's divide-and-conquer algorithm. 
- While saving memory is crucial, other factors such as convergence speed and computational cost per iteration also limit the efficient training of deep neural networks. Unless the memory savings are substantial, the benefits of the proposed method may be limited. Achieving orders of magnitude less memory consumption would be more impactful. 
- Minor errors include a typo on page 7, where "as expensive than a orward operation" should be corrected to "as expensive as a forward operation," and multiple typos in the supplementary materials.