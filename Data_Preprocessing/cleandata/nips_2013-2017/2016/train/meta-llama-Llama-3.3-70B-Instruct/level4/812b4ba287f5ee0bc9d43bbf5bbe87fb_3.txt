The authors present a reinforcement learning-based method to accelerate the search for object scales and locations, utilizing a tree-structured search scheme that iteratively scales or translates the search window. This approach draws inspiration from visual attention models, resulting in an efficient proposal generation process that achieves state-of-the-art performance at a lower computational cost when combined with conventional object detectors. The paper introduces a concise yet intriguing concept, which is clearly presented and thoroughly analyzed. The use of a formal visual attention model representation in proposal generation, as opposed to relying on brute force dense CNN-based classification, is a notable aspect. Additionally, the application of deep Q-learning optimization is an interesting element. Overall, this research is likely to be of interest to the NIPS audience, offering a unique perspective on object detection.