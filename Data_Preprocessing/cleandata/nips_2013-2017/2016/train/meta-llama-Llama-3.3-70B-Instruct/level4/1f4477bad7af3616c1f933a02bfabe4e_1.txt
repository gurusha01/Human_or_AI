This manuscript explores a specific type of neural network, demonstrating that it possesses a single stationary point. The authors propose an efficient method that converges to this unique fixed-point, which corresponds to the global minimum of the cost function. The paper tackles an intriguing problem, showcasing that a complex model with carefully selected constraints can exhibit only one stationary point. Beyond convexity and its generalizations, such as geodesic convexity, the typical approach to proving the uniqueness of a stationary point involves fixed-point theory, which is the methodology employed in this study. By constructing a contractive map, the authors establish that its fixed-point is the unique minimizer of the cost function. However, a limitation of the proposed method is its reliance on the boundedness of the spectral radius of a non-trivial matrix for convergence proof, as acknowledged by the authors, which restricted their experiments to networks with a smaller number of hidden units. Additionally, the method requires tuning numerous parameters, making its application somewhat counterintuitive, and for each parameter choice, the spectral condition must be verified. In the experimental section, the authors evaluated approximately 150,000 different parameter combinations and selected the best performer based on cross-validation accuracy. Nonetheless, their approach outperformed linear SVM on only 2 out of 7 datasets, which raises questions about the true capabilities of the investigated neural network.