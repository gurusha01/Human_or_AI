This manuscript presents a novel approach to backpropagation through time, leveraging dynamic programming to achieve memory efficiency, and derives an analytical upper bound for this methodology. A key benefit of the proposed BPTT-MSM algorithm is its ability to operate within stringent, virtually arbitrary memory constraints, surpassing Chen's algorithm in this regard. Given that memory usage is a significant obstacle in training complex recurrent neural networks, particularly on lengthy sequences, this contribution is noteworthy. The authors' dynamic programming-based backpropagation through time offers a memory-efficient solution. However, their strategy is more intricate compared to Chen's, which was tested on specific tasks utilizing mxnet. To further substantiate the efficacy of their approach, it would be beneficial to see results applied to specific RNN architectures, such as those employed in sequence-to-sequence learning.