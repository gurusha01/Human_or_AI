This paper examines the problem of selecting a limited number of rows and their corresponding reweightings to approximate the sum of squared distances from the original point set to any k-dimensional affine space. The authors demonstrate that O(k^2/eps^2) rows can be chosen deterministically, with the base case established for k = 0, utilizing a method that appears to derandomize Chebyshev's inequality. However, the paper contains critical errors regarding previous work, notably misattributing results to [8] instead of the correct reference, Cohen et al.'s "Dimensionality Reduction for k-Means Clustering and Low Rank Approximation". This mistake leads to an incorrect comparison, as the Cohen et al. paper achieves a stronger result of O(k/eps^2) rescaled columns deterministically for the same problem, contradicting the authors' claim of being the first to achieve an (k,eps)-coreset of size independent of n and d. Furthermore, the authors incorrectly state that [8,7] minimize the 2-norm, and fail to compare their work to Theorem 8 in http://arxiv.org/pdf/1511.07263v1.pdf. The comparison to [7] is also unclear, as it is uncertain whether [7] could not be made deterministic for rank-k approximation using similar techniques. Despite these negative points, the paper's deterministic sampling without BSS is a notable aspect, which, as shown in the experiments, could be more practical than BSS, albeit with a worse k^2/eps^2 bound. The deterministic argument without BSS is the most interesting part of the paper, and, with a proper comparison to previous work and a focus on the practical aspect, the paper can be considered for acceptance.