This paper introduces an object proposal algorithm that leverages reinforcement learning, formulated as a Markov Decision Process (MDP), and a novel tree-structured search approach. This method enables the discovery of multiple objects in a single pass through two distinct actions: translation and scale search. When combined with detection procedures, the proposed algorithm demonstrates not only an improvement in the object proposal task but also effectiveness in object detection. The core concept of utilizing a tree-structured search with multiple policies for single-pass discovery of multiple objects is ingenious, intuitive, and logical. The approach is both technically sound and innovative, although the foundational MDP model, which includes 13 actions, appears to build upon and extend previous work. The experimental setup effectively proves the efficacy of the proposed method. However, it would be beneficial to see the results of detection cases using either VGG or ResNet as a baseline in comparison to the proposed algorithm. Additionally, while the authors suggest their object proposal method leads to better detection performance than state-of-the-art approaches, the reported mean Average Precision (mAP) of approximately 76% is somewhat lower than the best detection performances currently reported in the literature. Overall, the paper is well-written and has the potential to make an impact.