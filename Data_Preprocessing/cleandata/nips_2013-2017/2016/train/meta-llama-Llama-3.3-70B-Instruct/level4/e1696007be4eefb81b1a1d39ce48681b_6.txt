This manuscript presents an efficient algorithm for solving Generalized Linear Models (GLMs) in large-scale problems under specific random designs, achieving cubic convergence once an approximate Ordinary Least Squares (OLS) estimator is obtained, with a computational cost of only O(n) per iteration. Theoretical analysis provides the convergence rate of the estimation error, which is supported by numerical experiments. By leveraging the established relationship between GLM coefficients and OLS coefficients, this work adapts an existing concept to modern large-scale settings, assuming that an accurate OLS estimator can be computed with significantly reduced computational effort. The proposed method is innovative and extends theoretical results to non-Gaussian designs using zero-bias transformation. A minor clarification is needed: is the reference to cubic convergence intended to invoke Halley's method? A question arises regarding the subsampling step for obtaining the OLS estimator: would an alternative approach, where this step is performed initially followed by either direct computation of the Maximum Likelihood Estimator (MLE) or a similar procedure to the one proposed, yield comparable results? Overall, the paper is exceptionally well-written, offering numerous intriguing findings and implications.