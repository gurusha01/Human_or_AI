This manuscript presents a batch-based extension of the Knowledge Gradient (KG) method, utilizing a Monte-Carlo simulation-based gradient estimation technique to identify an optimal set of design points. Experimental results indicate that the proposed approach surpasses other batch Bayesian optimization (BO) techniques. 
Several key aspects require clarification or expansion:
1. Given that batch KG is not a novel concept introduced by this paper, it is essential to delineate the specific contributions of this work in relation to existing literature, such as references [1] and [2]. The novelty appears to lie in the gradient estimation method for optimal batch determination. Therefore, a comparative analysis, either through experimental results or mathematical validation, with previous batch KG methodologies is necessary to assess the efficiency and effectiveness of the proposed method.
2. Section 5.2 is pivotal to the manuscript and warrants more detailed explanation to facilitate a comprehensive understanding of the methodology.
3. The comparison involving the Expected Improvement (EI) criterion in a noisy setting may be misleading, as EI typically assumes noise-free observations. It is crucial to specify whether a noise-considering variant of EI was employed. If the standard EI was used, the discussion in Section 6.2 should acknowledge the limitation of EI in handling noisy data.
4. The abbreviation "IPA" is reintroduced in line 162, which may cause confusion and should be addressed for clarity.
References:
[1] Yingfei Wang, Kristofer G. Reyes, Keith A. Brown, Chad A. Mirkin, and Warren B. Powell. 2015. Nested-Batch-Mode Learning and Stochastic Optimization with An Application to Sequential MultiStage Testing in Materials Science. SIAM J. Sci. Comput. 37, 3 (January 2015), B361â€“B381. DOI:http://dx.doi.org/10.1137/140971117
[2] http://castlelab.princeton.edu/theses/Peng%20-%20Senior%20Thesis%20-%20May032010.pdf