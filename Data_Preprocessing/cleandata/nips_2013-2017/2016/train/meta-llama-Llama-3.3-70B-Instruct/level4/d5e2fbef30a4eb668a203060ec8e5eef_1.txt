This manuscript introduces a novel feature selection algorithm, CMICOT, which accounts for high-order dependencies among features (up to order t, where t > 3) using Mutual Information (MI) to quantify these dependencies. To mitigate the issues of limited data and increased computational cost associated with accurately estimating mutual information, CMICOT employs a greedy approach utilizing binary representatives for each feature. The algorithm's performance is evaluated against state-of-the-art feature selection algorithms and interaction-aware Sequential Forward Selection (SFS)-based filters. Results from 10 public datasets demonstrate that CMICOT generally outperforms other feature selection algorithms in terms of classification accuracy when using kNN or AdaBoost as classifiers. The development of a feature selection algorithm that efficiently handles high-order interactions among features is a compelling and open problem in the field, making this paper appealing. However, several concerns regarding computational cost and experimental setup need clarification for consideration of acceptance.
A primary concern is the justification and analysis of the binary representatives procedure outlined in Section 3.3, which significantly impacts the paper's acceptability. The theoretical basis for this procedure is not convincing, as it relies on the intuition that binary representatives of different features interact better on average than those of the same feature, without providing supporting references or examples. Furthermore, the comparison of computational costs between the algorithm with and without binary representations is flawed, as it considers the same values for t and s, which does not account for the differing levels of information. The claimed reduction in computational cost due to binary representatives is also questionable, as while computing mutual information is less costly with binary variables, the cardinalities of the sets involved in the algorithm increase, potentially offsetting this gain.
The computational cost of the proposed method, stated as O(i^2) for an "optimal" interaction-aware MI-based feature selection, is comparable to RelaxMRMR, raising questions about reasonable values for t and s. Clarification is needed on this point, as well as on lines 183-191, which are not clear. The description of the particular case t=s in Algorithm 1, without providing a generic algorithm, is puzzling and requires explanation. Additionally, the first sentence of Proposition 3 in Appendix A.4 needs clarification, as it is crucial for the proposition's correctness.
The sentence on lines 249-250 regarding the estimation of mutual information and the BR technique is unclear and seems to overlook the potential impact of problem-dependent factors. The experimental setup poses another critical issue, as it is unclear whether the results in Figure 1 are based on a validation/test set or the training set, and whether 10-fold cross-validation was applied to obtain these results. This ambiguity must be resolved.
The paper's omission of discussion on the poor performance of the proposed method with the NBC classifier, despite results being provided in the appendices, is notable. The appendices contain relevant comparisons between feature selection methods that are not adequately represented in the main manuscript. It is surprising that CMIM, rather than an interaction-aware FS method, is identified as the strongest competitor, which warrants explanation. Empirical comparisons between CMICOT with and without binary representatives, in terms of both classification accuracy and computational cost, would be insightful, as would comparisons with other feature selection methods regarding computational cost to clearly demonstrate the proposed method's advantages.
Minor comments include the potential mistake of referring to SBS-based filters instead of SFS-based filters on line 27, the need for clarification on lines 144-145, missing axes labels in Figure 1, and the necessity of specifying the statistical test used in Table 1.