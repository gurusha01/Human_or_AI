This manuscript addresses the challenge of generating 3D objects by proposing a methodology that utilizes a generative deep network trained with an adversarial signal from a discriminative deep network. While Generative Adversarial Networks (GANs) have demonstrated exceptional performance in generating 2D images, this work extends their application to 3D object synthesis. Furthermore, the authors introduce an extension of VAE-GANs to 3D, termed VAE-VAN, which incorporates an additional encoder network to encode 2D images into latent representations, allowing the generative network to reconstruct 3D object models from these representations. Experimental results indicate that the proposed models can synthesize 3D objects of superior quality compared to the current state-of-the-art, both qualitatively and quantitatively. 
In essence, this work builds upon well-established techniques from 2D image generation and adapts them for 3D object generation. The use of adversarial training and VAE-GANs is not novel, as these concepts have been previously explored by the community. The contribution of this paper lies in successfully extending these techniques to 3D synthesis, a non-trivial task. Although the novelty may not be significant, the work is aligned with the interests of the NIPS community and represents a step in the right direction.
However, several clarifications are needed from the authors. The experimental details regarding 3D object classification and single-image 3D reconstruction require further explanation. Specifically, it is unclear which discriminator is used for extracting representations for classification (as mentioned in Line 172 and Line 193), and whether separate VANs are trained for different experiments or if a single model is used. Additionally, the type of classifiers employed for decision-making (e.g., nearest neighbor, multi-class) should be specified. Similar questions arise regarding the experiments in Sec 4.3, including the number of VAE-VANs trained on the IKEA dataset and how these models are tested on novel test images.
Moreover, a deeper analysis of the discriminator's neurons and their responses is necessary. Figure 8 suggests that multiple neurons are activated by the same object part, with neurons corresponding to the top-right and bottom-left both responding to the left sides of chairs. To facilitate reproducibility and clarity, more experimental details and insights into these aspects are required.