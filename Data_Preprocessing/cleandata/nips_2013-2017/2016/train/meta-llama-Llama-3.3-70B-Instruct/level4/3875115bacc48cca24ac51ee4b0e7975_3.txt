The paper explores the existence of local modes in the log-likelihood of Gaussian mixture models, focusing on the simplest possible mixture model with isotropic Gaussian components and known scale, and a well-specified model. The authors demonstrate that local modes exist even with infinite data, and these modes can be arbitrarily bad in terms of log-likelihood differences between local and global optima. They concentrate on specific configurations where mixture centers are divided among well-spaced clusters, showing that random initialization leads to the EM algorithm missing the global optima almost certainly as the number of components increases.
The paper is well-written, albeit with occasional typos. However, I have two primary concerns regarding the practical relevance of the paper. Firstly, Theorem 1 indicates that the log-likelihood has local modes even with infinite data, existing under specific center configurations. My concern is the likelihood of these configurations occurring in practice. I would be more confident in the paper's practical relevance if the authors made assumptions about the distribution of centers and demonstrated that "bad" configurations become more likely as the number of components or dimensionality increases. Theorem 2 is purported to address these concerns, but I am unsure if it adequately does so. A clear statement on the likelihood of "bad" configurations under certain assumptions would be beneficial.
Secondly, Theorem 2 involves the initialization of the EM algorithm, where centers are initialized by randomly sampling the mixture. Under specific center configurations, the EM algorithm often fails to converge to the global optimum with this initialization. However, considering a scenario with data generated from three Gaussians, two close and one far apart, it seems unusual to initialize EM with centers where there are fewer data points, especially when clusters are well-separated. I question the practical relevance of random initialization when data is clearly clustered.
Additionally, I have several minor points and questions. The example on lines 74-81 is unclear in its purpose, particularly in relation to Sresbro's conjecture. The requirements on lines 233-235 are partially unclear, specifically why requirement (1) is necessary. The proof that EM is unlikely to converge to a saddlepoint is practically important, but its significance in relation to converging to a local optimum is unclear. Minor typographical and formatting corrections are also suggested throughout the paper.