This manuscript presents the Phased LSTM, a novel architecture designed to address irregularly sampled data by incorporating a time gate. The authors evaluate the Phased LSTM on four datasets, demonstrating its superiority over traditional LSTMs and achieving state-of-the-art performance on the N-MNIST and Lip Reading datasets. Overall, the paper appears to be of high quality, offering a sufficient level of innovation in its cell structure and successfully validating its effectiveness. Given the ubiquity of time series data and the need to learn representations from irregularly sampled data, this technique has the potential for significant impact. The paper is well-written, and the presentation is clear. Some minor inquiries and suggestions include: What was the sample size used to train the models in the frequency discrimination task, and how does accuracy vary with increasing data? Could stacking Phased LSTMs lead to further performance enhancements? In Figure 4, it would be beneficial to use a consistent color scheme for the Phased LSTM across both plots. Including a visual representation of the deep learning architectures used in the experiments would be helpful; if space is limited, this could be provided in an appendix or supplementary material.