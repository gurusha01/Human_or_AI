This paper presents two novel optimization techniques for addressing the supervised PageRank problem, distinguishing itself from existing approaches by introducing a gradient-based method that guarantees a theoretical convergence rate and achieves a specified accuracy. Additionally, a gradient-free method is proposed, which ensures a decrease in the loss function value. A key advantage of these methods is that they do not require the exact value of the objective function and provide an estimated convergence rate, outperforming state-of-the-art methods in terms of ranking quality. The hyperparameters utilized in both methods are thoroughly documented. Although the datasets employed are not publicly available, their descriptions are sufficiently detailed, making it feasible to replicate the results. The authors propose two two-level optimization methods, specifically gradient-based (GBN) and gradient-free (GFN), grounded in the work of Nesterov and Nemirovski (reference 17), to tackle the supervised PageRank problem. The lower and upper-level optimizations are based on this foundational work. Notably, the proposed method eliminates the need for an exact objective function value and offers a proven estimate of the convergence rate for a given accuracy, thereby avoiding the computation of large matrices while maintaining satisfactory results. The methodology is extensively explained from Section 2 to Section 5, with proofs included in the supplementary material. However, the inclusion of a symbol table would greatly enhance readability, as the multitude of symbols in the equations can be confusing. For instance, the symbol $N$ is introduced in Line 139 and Equation 3.1 without immediate clarification of its meaning (number of steps) until Line 193. Furthermore, the experimental section primarily compares the authors' work with GBP in terms of the loss function, rather than ranking quality. Given that this work generalizes reference 17, a direct comparison would be beneficial to assess whether the performance has indeed improved.