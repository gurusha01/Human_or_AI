This paper presents a novel stochastic gradient algorithm integrated with Bayesian modeling for optimizing multivariate objective functions within a finite domain. A key innovation of the algorithm is its ability to identify and parallelize the computation of objective functions at multiple points in each iteration. The challenge lies in optimally selecting these sampling points, which the authors address by employing the Knowledge Gradient framework. This approach estimates the expected improvement in objective value with the addition of a sampling point, informing decisions on whether and where to sample. The authors extend this methodology to facilitate batch decisions on multiple sampling points simultaneously. Due to the computational complexity of this problem, they develop an algorithm leveraging Monte Carlo methods and Infinitesimal Perturbation Analysis to estimate gradients that maximize information gain across candidate sampling sets. The algorithm's efficacy is demonstrated through its application to various test problems, where it either surpasses or closely competes with existing Confidence Bounds-based approaches. The paper is well-structured and holds potential for practical applications. However, the novelty of the work seems somewhat limited, as it builds upon the previously explored Knowledge Gradient approach, now adapted for batch settings. This adaptation necessitates a more complex optimization method for multiple points, which, while useful, does not radically depart from established techniques. The primary innovation, in my view, lies in the estimation of the q-KG gradient using an IPA approach, a method that, although valuable, is fairly standard. One specific technical concern arises in equation (3.1), where the definition of mu(x^(1:n)) and K(x^(1:n),x^(1:n)) is unclear due to mu and K being defined for vectors (or pairs of vectors), not sequences like x^(1:n).