This manuscript explores the application of Richardson-Romberg (RR) extrapolation to stochastic gradient Langevin dynamics (SGLD) to mitigate the bias stemming from gradient estimation noise, yielding the stochastic gradient Richardson-Romberg Langevin dynamics (SGRRLD) algorithm. Theoretical analysis indicates that SGRRLD achieves an asymptotically lower bias and mean squared error (MSE) compared to SGLD. Experimental results on a synthetic linear Gaussian model demonstrate the superiority of SGRRLD over SGLD. However, experiments conducted on the MovieLens dataset show only a marginal improvement in test root mean squared error (RMSE), with results being somewhat debatable. The RR extrapolation technique has been previously shown to enhance the convergence rate of Monte Carlo estimates for stochastic differential equations (SDEs). This work applies this method to stochastic gradient Markov chain Monte Carlo (SG-MCMC) algorithms, proving that under specific conditions, SGRRLD converges faster than SGLD with the same step size, albeit at the cost of running two parallel Markov chains. The algorithm is well-described and straightforward to implement. Synthetic experiments clearly illustrate the bias reduction capabilities of SGRRLD in the context of the linear Gaussian model. Further experiments using real data would be beneficial to demonstrate the significant bias reduction achievable through this simple modification of SGLD. Although the proof details of Theorems 1 and 2 were not thoroughly examined, it is intriguing to consider the conditions required for U to satisfy both theorems, including whether U can be multi-modal. Intuitively, when gradient noises are uncorrelated, the two chains should become uncorrelated rapidly, even if the Gaussian noises are correlated, raising questions about how combining the chains reduces the error order. In real-data experiments, the authors should investigate whether correlation between the two chains is observed. Concerns regarding the experimental setup and real-data experiments include the comparison of computational time, where the authors argue that SGRRLD's time is comparable to SGLD's when parallelized. However, running multiple SGLD chains in parallel within the same time frame could yield similar improvements. Therefore, comparing the estimates from two SGLD chains with SGRRLD would be insightful to determine if the observed improvement in RMSE persists. Additionally, in the real-data experiment, comparing SGRRLD with step sizes gamma and gamma/2 against SGLD with step size gamma may not be comprehensive; a comparison with SGLD using a step size of gamma/2, which has lower bias and is run in parallel, would provide a more thorough evaluation. Ultimately, conducting more real-data experiments is essential to solidify the findings.