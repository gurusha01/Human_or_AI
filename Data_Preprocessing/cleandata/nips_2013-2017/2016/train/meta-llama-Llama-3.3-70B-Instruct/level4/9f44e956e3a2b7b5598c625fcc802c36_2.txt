This manuscript presents a novel approach to utilizing an additional recurrent weight matrix with rapid synaptic weight dynamics as a non-selective short-term memory mechanism. The proposed update rule for the fast weights incorporates exponential decay, providing a straightforward and efficient means of information storage. Experimental evaluations across various tasks, including key-value paradigms, sequential MNIST, MultiPIE, and a reinforcement learning task, demonstrate the effectiveness of the proposed memory in sequence tasks that do not necessitate selective memory forms. Following the authors' rebuttal, which addressed my initial concerns, and with the suggested revisions, I am pleased to recommend this paper for acceptance.
The paper is well-structured, and the methodology is clearly described, with comprehensive experiments that support the claims made. However, several questions arose during my review, which I outline below:
1. The biological plausibility of this short-term memory type is argued, but implementing the inner loop, as described in equation (2), poses challenges in a biological context. This is due to the requirement for caching Wh(t) during the update of the new hidden state and the potential for the new state to converge over many iterations. Could the authors provide speculation on the underlying biological mechanisms in real neural networks and discuss the sensitivity of this mechanism to the number of iterations?
2. The reference to the Appendix on line 136 could not be found; it would be beneficial to clarify or correct this.
3. In the key-value task, it would be informative to analyze how the network's performance evolves with the sequence length, providing insight into the memory's capabilities under varying conditions.
4. Given the non-selective nature of the memory, it is anticipated that performance would be reduced in tasks requiring the network to selectively store certain inputs while disregarding others. While the RL task shares some similarities, selectivity is inherently induced by the task structure. Are there scenarios where LSTMs outperform this short-term memory approach, highlighting the trade-offs between these methods?
5. A comparison with Facebook's key-value memory would be valuable, as the scenarios tested seem more suited to this type of memory than to LSTMs.
6. There appears to be confusion between mini-batches and sequences in lines 114 and 115, which could be clarified for better understanding.
7. Will the code for this network be made available online, or are there plans to release it in the future?
8. The description in lines 209-211 mentions integrating results with partial results at a higher level by "popping" the previously cached result. Could the authors elaborate on what "popping" entails in this context? Is it a manually implemented process, or is it expected that the network will learn to "pop" the cache itself? If the latter, how does the network learn to selectively remove information from the memory without eliminating additional relevant information stored in the hidden unit activity?