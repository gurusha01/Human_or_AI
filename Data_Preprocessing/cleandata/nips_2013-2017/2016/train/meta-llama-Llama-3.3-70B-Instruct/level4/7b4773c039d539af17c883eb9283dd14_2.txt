This paper presents a novel sampling algorithm for planning in Markov Decision Processes (MDPs), providing an estimate of the value function for the starting node of a loop-free MDP with a known generative model. The algorithm's sample complexity is theoretically analyzed, yielding results that improve upon or match previous findings for MDPs with finite branching factors and are also applicable to cases with countably infinite possible next states. The problem addressed is both interesting and important, and the results can be seen as a natural extension of the planning algorithm by Busoniou and Munos (2012) combined with the sampling method of Kearns et al (1999), incorporating additional techniques to balance confidence intervals and uncertainties across the planning tree. The presentation is clear, and the authors provide intuition behind the algorithm's design choices. However, clarity could be enhanced by explicitly stating that the MAX part of the algorithm essentially performs action elimination for best arm identification, potentially leveraging existing results rather than rederiving them. Further discussion on the parameter choices, such as $kl/(1-\eta)^2$ and $\eta \max(Ul\epsilon)$, would be beneficial. It would also be helpful to mention that the algorithm's semantics will be explained later or to rearrange the discussion order. A drawback is that the complexity measures, similar to previous results, are challenging to interpret, which might be unavoidable. The mention of extending the algorithm to general MDPs with loops and merging states in line 45 is intriguing, but it is unclear how the sampling results would be propagated in such cases, given the computational complications observed in earlier algorithms. Either an explanation for this or the removal of the remark would be necessary. Regarding the case of infinite N, it is noted that this refers to countably infinite scenarios. A potential approach could involve reducing the infinite N case to the finite one by demonstrating that successor states with sufficiently low probabilities (relative to epsilon) can be neglected, as they would not be sampled and contribute marginally to the value function. It is worth questioning whether the presented complexity measure $d_H$ is superior to what would be obtained through this method. Minor suggestions include specifying the goal of obtaining an epsilon-optimal policy (line 59), correcting several typos, defining delta in the footnote on page 3, and changing "output" to "outputs" on line 423.