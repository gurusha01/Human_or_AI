This manuscript presents an innovative extension to conventional encoder-decoder frameworks, such as those utilized in image captioning tasks. The core concept involves integrating an intermediate "reviewer" module that predicts a set of fact vectors, which can represent key concepts within an image. These fact vectors, along with a hidden representation, are then fed into the decoder model. Notably, the fact vectors can be supervised during the training phase, adding an extra layer of guidance. The strengths of this paper include its novel approach to incorporating additional supervision into the encoder-decoder learning process, comprehensive experimental evaluations across two tasks and datasets that demonstrate improvements over baseline models, and the generalizability of the approach beyond standard encoder-decoder models. 
However, several weaknesses were identified. Firstly, the comparison to related work in the captioning experiment was conducted on a non-official test or development set, rather than the official COCO leaderboard's blind test set. This is a critical omission, as several state-of-the-art methods, such as those presented in [5,17], have been evaluated and ranked on this leaderboard, and more recent approaches have achieved significant improvements. Secondly, relying solely on automatic evaluation metrics for caption generation may be misleading; a human evaluation would provide more convincing evidence of the model's performance. Lastly, the method by which supervision is incorporated into the source code caption experiment in Section 4.2 is not clearly explained.
Following the author's response, which addressed some of these concerns by promising to include official leaderboard results and clarifying the supervision method for the source code caption experiment, the major issues have been adequately addressed. The inclusion of additional results, such as T_r, as mentioned in the rebuttal, would further enhance the manuscript by offering deeper insights into the approach. Given that the concerns raised by myself and other reviewers have been largely mitigated, I recommend accepting this paper.