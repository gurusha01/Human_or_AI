This manuscript presents a novel sequence-to-sequence framework, comprising an encoder, a decoder, and an additional "reviewer" module that performs multiple attentive iterations to enhance input sequence representation. The process can be further refined through intermediate losses, such as a bag-of-words loss over the target sequence. Experimental evaluations are conducted on image and code captioning tasks, with comparisons to state-of-the-art approaches. However, recent related works, including "Order Matters: Sequence to sequence for sets" by Vinyals et al (ICLR 2016) and "Adaptive Computation Time for Recurrent Neural Networks" by Graves (ArXiv 2016), should be considered. The "Order Matters" paper introduces a "Process" module similar to the proposed "Attentive Input Reviewer", while the "Adaptive Computation" paper bears similarities to the Decoder module. The concept of "discriminative supervision" is intriguing, allowing for the reuse of supervision in different ways, but its importance is unclear due to the fixed lambda factor in the experiments. The COCO experiments do not account for more recent results on the MSCOCO website, which show improved performance on most metrics. Further experiments investigating the importance of T_r, set to 8 in the COCO experiment, would be valuable, including potential overfitting when this value is changed. Additionally, clarification on the input attention in the VGG-based image captioning model would be beneficial, specifically which VGG layer was used. A comparison between the attentive input reviewer and attentive output reviewer, including discussion on their applicability and differences, would also be informative. Following the author's response, which addressed all concerns, I believe the revised manuscript is worthy of acceptance.