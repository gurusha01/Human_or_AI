The authors present a quantum computing-based approach to learning perceptron models, yielding substantial improvements in training efficiency. Notably, their work demonstrates the potential benefits of re-examining traditional learning strategies through the lens of quantum computing, rather than simply adapting conventional methods to a quantum framework. Major concerns include:  A key assumption underlying the main contribution - that training observations have unit norm - warrants scrutiny. Theorems 1, 2, and 3, as well as Lemma 2, rely on input vectors having unit length, which may only be valid for per-observation normalization schemes. This assumption may limit the applicability of the approach, particularly in scenarios where input vectors have varying lengths. For instance, in a one-dimensional setting, this would restrict observations to only two possible values (-1 and 1). It is essential to investigate whether this assumption affects the conclusions and to explore the results in more diverse scenarios.  The encoding explanation provided in lines 133-134 requires clarification, as the final representation [0,0,0,0,0,1] is unclear. * Certain phrases, such as those in lines 115-116 (while-but), lack clarity and should be revised for better understanding. Additionally, a thorough review of grammar and spelling is necessary. Minor corrections include: Line 83: "algorthm" should be spelled as "algorithm". Line 95: "quatum" should be corrected to "quantum".