The authors introduce two novel metrics to evaluate the robustness of neural networks, leveraging an approximation algorithm to assess a previously established robustness criterion by Szegedy et al. Experimental evaluations are conducted on the MNIST and CIFAR-10 datasets to assess the efficacy of the proposed methods, with the authors also discussing how their approach can enhance neural network robustness. This method is grounded in the concept of the nearest adversarial example, defined by the Linfinity distance, and introduces new metrics based on the proportion of examples within a specified distance and their average distance. While these metrics appear reasonable, the complete cumulative distribution function (CDF) of adversarial distances provides more comprehensive insights, which the authors helpfully include in their experimental results. A key assumption of the proposed approach is the linearity of the space, which may not be fully justified, as neural networks may exhibit approximate linearity over a broader region than where they are analytically linear. Nonetheless, the ability to identify numerous adversarial examples not detected by previous baselines is a significant finding, suggesting that despite the restrictive assumption of linearity, the method offers valuable insights into network vulnerabilities. The results on CIFAR-10, although largely negative, are informative: after fine-tuning for accuracy, the robust network exhibits a 10% increase in errors and remains susceptible to manipulation on approximately 60% of examples through the alteration of an average of 4 pixels, representing an increase from 3 pixels. Several minor issues require attention: the use of numeric citations could be improved by incorporating author names into the text; the paper's title and abstract suggest a universally applicable approach, yet the method is specifically tailored for ReLUs, warranting a revised title or abstract; the introduction needs revision to provide clearer background information on the choice of Linf norm for robustness and to define key terms like rho before they are referenced, as the current structure necessitates readers to consult external references to fully understand the content. Additionally, a typo ("when when" should be "when") should be corrected.