This paper presents two fundamental results on the population likelihood function of Gaussian mixture models with M ≥ 3 components. The first result shows that the population likelihood function has bad local maxima, even in the special case of equally-weighted mixtures of well-separated and spherical Gaussians. The second result demonstrates that the EM algorithm, as well as its first-order variant, with random initialization, converges to a bad critical point with high probability.
The paper is well-written and clearly organized, making it easy to follow the authors' arguments. The introduction provides a thorough background on Gaussian mixture models and the EM algorithm, and the problem setup is clearly defined. The main results are presented in Section 3, and the proofs are provided in the appendix.
The first result, Theorem 1, is a negative answer to the open question of Srebro [2007], which conjectured that any local maximum of the likelihood function is a global maximum in the limit of infinite samples. The authors construct a GMM with M = 3 well-separated Gaussians, whose population log-likelihood function contains local maxima with arbitrarily bad log-likelihood values. This result has significant implications for the convergence of local search algorithms, such as EM, which cannot guarantee global convergence even on well-separated mixtures of Gaussians.
The second result, Theorem 2, shows that the EM algorithm, with random initialization, converges to a bad critical point with high probability. The authors demonstrate that the probability of success for the EM algorithm is exponentially small as a function of M, which means that the algorithm must be executed at least eΩ(M) times to guarantee recovering a global maximum with at least constant probability.
The paper also provides results on the first-order EM algorithm, which is shown to converge to a bad critical point with high probability, similar to the EM algorithm. Additionally, the authors demonstrate that the first-order EM algorithm cannot converge to strict saddle points, which suggests that the sub-optimal points to which the algorithm frequently converges are bad local maxima.
The strengths of the paper include its clear presentation, rigorous proofs, and significant implications for the convergence of local search algorithms. The results have important consequences for the practice of using EM-style algorithms with random initialization schemes, highlighting the need for careful initialization and the potential for failure even on seemingly benign problem instances.
However, there are some potential weaknesses and areas for improvement. One potential criticism is that the results are limited to the population setting, and it is unclear how they generalize to finite sample sizes. Additionally, the authors' construction of the GMM with bad local maxima relies on a specific choice of parameters, and it is unclear whether this construction is representative of more general cases.
Overall, the paper makes a significant contribution to the understanding of Gaussian mixture models and the EM algorithm, and its results have important implications for practice. The authors' use of clear and concise language, combined with rigorous proofs, makes the paper accessible to a wide range of readers.
Arguments for acceptance:
* The paper presents significant and original results on the population likelihood function of Gaussian mixture models.
* The authors provide rigorous proofs and clear explanations of their results.
* The paper has important implications for the practice of using EM-style algorithms with random initialization schemes.
Arguments against acceptance:
* The results are limited to the population setting, and it is unclear how they generalize to finite sample sizes.
* The authors' construction of the GMM with bad local maxima relies on a specific choice of parameters, and it is unclear whether this construction is representative of more general cases.
Recommendations for improvement:
* The authors could provide more discussion on the generality of their results and how they might be extended to finite sample sizes.
* The authors could consider providing more examples or simulations to illustrate the practical implications of their results.
* The authors could provide more context on the related work and how their results compare to existing literature on Gaussian mixture models and the EM algorithm.