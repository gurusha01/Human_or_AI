This paper proposes a novel approach to studying fast learning rates for heavy-tailed losses in the context of clustering problems. The authors introduce two new conditions, the multi-scale Bernstein's condition and the integrability of the envelope function, which enable the derivation of fast learning rates for unbounded losses. The paper provides a thorough analysis of the conditions and their implications, and demonstrates the applicability of the approach to k-means clustering with heavy-tailed source distributions.
The strengths of the paper include its originality, technical soundness, and clarity of presentation. The authors provide a clear and concise introduction to the problem, and the mathematical framework is well-developed and easy to follow. The proofs are rigorous and well-organized, and the authors provide a detailed analysis of the conditions and their implications.
However, there are some weaknesses in the paper. The writing and notation are sometimes unclear and needlessly complicated, with minor grammatical errors and sections that are hard to read. The algorithm uses an interesting application of binary search, but the choice of estimator for the cluster centre could result in false negatives or false positives, which is not acknowledged by the authors. Additionally, the description of the algorithm is confusing and inconsistent, with differences between the description on page 4 and the actual algorithm on page 5.
The authors claim that the algorithm is guaranteed to run successfully when the gamma condition is met, but the reviewer is not convinced based on the written proof. The proof of lemma 5 assumes a probabilistic bound that is only proven in lemma 6, and the overall result in Theorem 7 is with probability 1-\delta, which is weaker than the claimed "guaranteed success". The paper needs editing and more details explaining the results, particularly in section 4.1, and the lemmas 5 and 6 need to be reordered and expanded on.
In terms of originality, the paper introduces a new fast-rate assumption, the multi-scale Bernstein's condition, which is a significant contribution to the field. The approach is novel and has the potential to be applied to a wide range of problems. The paper also provides a clear path to verify the assumption in practice, which is a significant advantage.
The significance of the paper lies in its ability to provide fast learning rates for heavy-tailed losses, which is an important problem in machine learning. The paper demonstrates the applicability of the approach to k-means clustering, which is a widely used algorithm in practice. The results have the potential to be used in a variety of applications, including image and speech recognition, natural language processing, and recommender systems.
Overall, the paper is well-written and provides a significant contribution to the field. However, it needs some editing and clarification to make it more readable and convincing. The reviewer recommends acceptance of the paper, but with some revisions to address the weaknesses mentioned above.
Arguments pro acceptance:
* The paper introduces a novel approach to studying fast learning rates for heavy-tailed losses.
* The approach is technically sound and well-developed.
* The paper provides a clear and concise introduction to the problem.
* The results have the potential to be used in a variety of applications.
Arguments con acceptance:
* The writing and notation are sometimes unclear and needlessly complicated.
* The algorithm uses an interesting application of binary search, but the choice of estimator for the cluster centre could result in false negatives or false positives.
* The description of the algorithm is confusing and inconsistent.
* The proof of lemma 5 assumes a probabilistic bound that is only proven in lemma 6.
* The overall result in Theorem 7 is with probability 1-\delta, which is weaker than the claimed "guaranteed success".