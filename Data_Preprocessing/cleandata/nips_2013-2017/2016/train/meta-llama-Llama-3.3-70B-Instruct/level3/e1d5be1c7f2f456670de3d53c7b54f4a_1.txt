This paper presents a significant contribution to the field of online decision making, specifically in the context of contextual semibandits. The authors extend the semi-bandit problem to a contextual setting, where the learner has access to a supervised learning oracle and aims to achieve a sqrt{T} regret bound. The proposed algorithm, VCEE, achieves a near-optimal regret bound of ˜O(pKLT logN) in the known weight setting, outperforming existing approaches. The paper also introduces a new algorithm, EELS, for the unknown weight setting, which achieves a regret bound of ˜O(T^{2/3}(K logN)^{1/3}).
The paper is well-written, and the authors provide a clear and detailed explanation of the problem, the algorithms, and the analysis. The experimental evaluation of VCEE on two large-scale learning-to-rank datasets demonstrates its effectiveness in practice, outperforming existing baselines. The comparison to other applicable bounds in Table 1 provides a clear understanding of the paper's contribution to the field.
The strengths of the paper include:
* The extension of the semi-bandit problem to a contextual setting, which has important applications in online content recommendation and other domains.
* The proposal of two algorithms, VCEE and EELS, which achieve state-of-the-art regret bounds in their respective settings.
* The thorough experimental evaluation of VCEE, which demonstrates its effectiveness in practice.
* The clear and detailed analysis of the algorithms, which provides a deep understanding of the paper's contributions.
The weaknesses of the paper include:
* The assumption of a linear relationship between the semibandit feedback and the reward, which may not always hold in practice.
* The requirement of a supervised learning oracle, which may not be available in all settings.
* The computational complexity of the algorithms, which may be a concern in large-scale applications.
Overall, the paper presents a significant contribution to the field of online decision making, and the proposed algorithms have the potential to be widely applicable in practice. The paper is well-written, and the authors provide a clear and detailed explanation of the problem, the algorithms, and the analysis.
Arguments for acceptance:
* The paper presents a significant contribution to the field of online decision making.
* The proposed algorithms achieve state-of-the-art regret bounds in their respective settings.
* The experimental evaluation demonstrates the effectiveness of VCEE in practice.
* The paper is well-written, and the authors provide a clear and detailed explanation of the problem, the algorithms, and the analysis.
Arguments against acceptance:
* The assumption of a linear relationship between the semibandit feedback and the reward may not always hold in practice.
* The requirement of a supervised learning oracle may not be available in all settings.
* The computational complexity of the algorithms may be a concern in large-scale applications.
However, the strengths of the paper outweigh its weaknesses, and I recommend acceptance.