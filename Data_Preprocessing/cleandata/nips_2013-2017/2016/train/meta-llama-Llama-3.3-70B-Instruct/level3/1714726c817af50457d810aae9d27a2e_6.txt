This paper presents a novel approach to fast learning rates for heavy-tailed losses in the context of empirical risk minimization. The authors introduce the multi-scale Bernstein's condition, a generalization of the standard Bernstein's condition, which enables the derivation of fast learning rates for unbounded losses. The paper provides a clear and well-structured framework for analyzing fast learning rates, including a localization-based result and a fast-rate inequality.
The strengths of the paper include its technical soundness, clarity, and originality. The authors provide a thorough analysis of the multi-scale Bernstein's condition and its implications for fast learning rates. The paper also includes a detailed discussion of the relation to previous work and a clear explanation of the assumptions and conditions required for the results to hold.
However, there are some weaknesses and areas for improvement. The paper assumes that the hypothesis class has an integrable envelope, which may be a strong condition in some cases. Additionally, the paper focuses on independent and identically distributed observations, which may not be realistic in all scenarios. The authors also mention that the condition of polynomial entropy bounds could be explored in future work.
The practical significance of the work is not entirely clear, as the experiments are carried out in a limited setup, and the scalability of the method to higher dimensions is unknown. The presentation of the results could be improved, with suggestions including the use of dotted lines or colors to show the trajectory of the primal variable in figures.
Overall, the paper makes a significant contribution to the field of machine learning, providing a new perspective on fast learning rates for heavy-tailed losses. The results are well-supported by theoretical analysis and experimental evidence, and the paper is well-written and easy to follow.
Arguments pro acceptance:
* The paper presents a novel and original approach to fast learning rates for heavy-tailed losses.
* The authors provide a clear and well-structured framework for analyzing fast learning rates.
* The paper includes a detailed discussion of the relation to previous work and a clear explanation of the assumptions and conditions required for the results to hold.
* The results are well-supported by theoretical analysis and experimental evidence.
Arguments con acceptance:
* The paper assumes that the hypothesis class has an integrable envelope, which may be a strong condition in some cases.
* The paper focuses on independent and identically distributed observations, which may not be realistic in all scenarios.
* The practical significance of the work is not entirely clear, as the experiments are carried out in a limited setup, and the scalability of the method to higher dimensions is unknown.
* The presentation of the results could be improved, with suggestions including the use of dotted lines or colors to show the trajectory of the primal variable in figures.