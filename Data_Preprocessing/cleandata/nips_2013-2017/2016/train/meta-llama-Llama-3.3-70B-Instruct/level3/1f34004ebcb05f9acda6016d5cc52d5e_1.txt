This paper proposes two novel optimization methods for learning parameters of a graph-based ranking model, specifically the Supervised PageRank model. The first method is a gradient-free approach that adapts existing random gradient-free methods to constrained optimization problems with calculable precision. The second method is a gradient-based approach that develops an inexact oracle for non-convex optimization problems and proves its convergence to the stationary point of the problem.
The paper's main contribution is the adaptation of existing approaches to constrained optimization problems with calculable precision, which is a significant improvement over previous methods. The authors provide a thorough analysis of the convergence rates and complexity bounds for both methods, making them more reliable and efficient.
The experimental results demonstrate the effectiveness of the proposed methods, outperforming the state-of-the-art gradient-based method on a web page ranking problem. The gradient-free method, in particular, shows significant improvements over the state-of-the-art algorithms on all test sets.
However, the paper raises some concerns about being an adaptation of previously proposed methods, which may limit its originality. Additionally, the presentation of the optimization problem in a more general context would better place the contribution within the state-of-the-art.
Strengths:
* The paper proposes two novel optimization methods for learning parameters of a graph-based ranking model.
* The methods are thoroughly analyzed, and their convergence rates and complexity bounds are provided.
* The experimental results demonstrate the effectiveness of the proposed methods.
Weaknesses:
* The paper may be seen as an adaptation of previously proposed methods, which may limit its originality.
* The presentation of the optimization problem in a more general context would better place the contribution within the state-of-the-art.
Arguments pro acceptance:
* The paper proposes novel optimization methods that improve upon existing approaches.
* The methods are thoroughly analyzed, and their convergence rates and complexity bounds are provided.
* The experimental results demonstrate the effectiveness of the proposed methods.
Arguments con acceptance:
* The paper may be seen as an adaptation of previously proposed methods, which may limit its originality.
* The presentation of the optimization problem in a more general context would better place the contribution within the state-of-the-art.
Overall, the paper is well-written, and the proposed methods are thoroughly analyzed. The experimental results demonstrate the effectiveness of the proposed methods, making it a strong candidate for acceptance. However, the authors should consider addressing the concerns about originality and providing a more general context for the optimization problem. 
Quality: 8/10
Clarity: 9/10
Originality: 7/10
Significance: 8/10
Recommendation: Accept with minor revisions. The authors should consider addressing the concerns about originality and providing a more general context for the optimization problem. Additionally, the authors should provide a conclusion to the paper to summarize the main contributions and implications of the work.