This paper proposes a novel approach to measuring the robustness of neural networks by introducing a point-wise robustness metric. The metric is defined as the smallest perturbation that changes the prediction of the network. The authors also propose two statistics, adversarial frequency and adversarial severity, to measure the robustness of a network. The paper demonstrates the effectiveness of the proposed approach by evaluating the robustness of several neural networks, including LeNet and NiN, on the MNIST and CIFAR-10 datasets.
The paper is well-written, and the authors provide a clear and concise explanation of their approach. The proposed metric and statistics are well-motivated, and the experimental results demonstrate the effectiveness of the approach. The paper also provides a thorough review of related work, which helps to contextualize the contributions of the paper.
One of the strengths of the paper is its ability to provide a more accurate estimate of the robustness of a network compared to existing approaches. The authors demonstrate that their approach can identify more adversarial examples than existing methods, which is an important contribution to the field.
However, there are some limitations to the paper. The concept of adversarial severity is less intuitive than adversarial frequency, and it may not accurately reflect the robustness of a network in certain scenarios. Additionally, the paper does not provide a clear explanation of why the proposed approach is more effective than existing methods.
The paper also has some minor errors, such as repeated words and potentially misplaced subsections. Furthermore, the authors' proposed method does not significantly improve the robustness of certain networks, such as NiN, and an intuitive explanation for this is needed.
In terms of the conference guidelines, the paper meets the criteria for quality, clarity, originality, and significance. The paper is technically sound, well-written, and provides a novel contribution to the field. The authors also provide a thorough review of related work and demonstrate the effectiveness of their approach through experiments.
Overall, I would recommend accepting this paper to the conference. The paper provides a significant contribution to the field of neural network robustness, and the authors demonstrate the effectiveness of their approach through thorough experiments. While there are some limitations to the paper, they do not detract from the overall quality and significance of the contribution.
Arguments for acceptance:
* The paper provides a novel approach to measuring the robustness of neural networks.
* The proposed metric and statistics are well-motivated and effective.
* The paper demonstrates the effectiveness of the approach through thorough experiments.
* The paper provides a thorough review of related work.
Arguments against acceptance:
* The concept of adversarial severity is less intuitive than adversarial frequency.
* The paper does not provide a clear explanation of why the proposed approach is more effective than existing methods.
* The paper has some minor errors, such as repeated words and potentially misplaced subsections.
* The authors' proposed method does not significantly improve the robustness of certain networks, such as NiN.