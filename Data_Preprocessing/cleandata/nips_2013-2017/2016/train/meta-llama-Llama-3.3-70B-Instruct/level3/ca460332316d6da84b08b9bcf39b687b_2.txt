This paper proposes a novel approach to manifold learning, which aims to create embeddings with low distortion. The authors introduce a new loss function, called Riemannian Relaxation (RR), that measures the deviation of the embedding from isometry. The loss function is based on the push-forward Riemannian metric associated with the embedding, and it is optimized using a projected gradient descent algorithm.
The paper is well-written and well-organized, with a clear and novel problem formalization that compares meaningfully with existing work in the field. The authors provide a thorough analysis of the properties of the loss function and the optimization algorithm, and they demonstrate the effectiveness of their approach through a series of experiments on various real-world datasets.
The strengths of the paper include:
* The introduction of a new and natural way to measure the distortion from isometry of an embedding, which is based on the push-forward Riemannian metric.
* The development of a novel optimization algorithm, called Riemannian Relaxation, that can efficiently optimize the loss function.
* The demonstration of the effectiveness of the approach through a series of experiments on various real-world datasets, including a large-scale dataset of galaxy spectra.
The weaknesses of the paper include:
* The loss function is not convex, which can make the optimization algorithm sensitive to the initial conditions.
* The algorithm requires the specification of several hyperparameters, including the intrinsic dimension and the embedding dimension, which can be difficult to choose in practice.
* The computational complexity of the algorithm can be high, especially for large datasets.
Overall, the paper makes a significant contribution to the field of manifold learning, and it has the potential to be widely used in practice. The authors demonstrate the effectiveness of their approach through a series of experiments, and they provide a thorough analysis of the properties of the loss function and the optimization algorithm.
Arguments for acceptance:
* The paper introduces a novel and natural way to measure the distortion from isometry of an embedding.
* The authors develop a novel optimization algorithm that can efficiently optimize the loss function.
* The paper demonstrates the effectiveness of the approach through a series of experiments on various real-world datasets.
Arguments against acceptance:
* The loss function is not convex, which can make the optimization algorithm sensitive to the initial conditions.
* The algorithm requires the specification of several hyperparameters, which can be difficult to choose in practice.
* The computational complexity of the algorithm can be high, especially for large datasets.
However, the strengths of the paper outweigh its weaknesses, and I believe that it should be accepted for publication. The authors demonstrate the effectiveness of their approach through a series of experiments, and they provide a thorough analysis of the properties of the loss function and the optimization algorithm. The paper makes a significant contribution to the field of manifold learning, and it has the potential to be widely used in practice.