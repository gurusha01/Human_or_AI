This paper proposes a novel algorithm, called Scaled Least Squares (SLS), for estimating the coefficients of generalized linear models (GLMs) in the large-scale setting where the number of observations is much larger than the number of predictors. The algorithm is based on an approximate proportionality relationship between the GLM coefficients and the ordinary least squares (OLS) coefficients, which is established theoretically and demonstrated experimentally.
The paper is well-written and organized, and the authors provide a clear and concise introduction to the problem and their approach. The theoretical results, including Theorem 1, provide a solid foundation for the algorithm and its applicability to non-Gaussian designs. The experimental results demonstrate the efficiency and accuracy of the SLS algorithm compared to other optimization algorithms for finding the maximum likelihood estimator (MLE).
One of the strengths of the paper is its ability to provide a simple and efficient solution to a complex problem. The SLS algorithm has a low per-iteration cost of O(n) and can achieve quadratic or cubic convergence rates, making it suitable for large-scale problems. The paper also provides a thorough analysis of the algorithm's performance and compares it to other existing methods.
However, there are some areas that could be improved. The paper could benefit from additional plots, such as time vs accuracy, to further illustrate the trade-offs between the proposed method and existing algorithms. Additionally, the theoretical results, including Theorem 1, require further clarification and tightening to ensure consistency with special cases, such as Gaussian covariates.
The paper also lacks clarity on the choice of |S| in experiments, with inconsistent notation and undefined parameters, such as Î»_min, which need to be addressed for better understanding. Furthermore, the paper could provide more discussion on the implications of the proportionality relationship between GLM and OLS coefficients, and how it can be used in other contexts, such as support vector machines.
In terms of originality, the paper proposes a novel algorithm and provides new theoretical insights into the relationship between GLM and OLS coefficients. The paper also demonstrates the effectiveness of the SLS algorithm in various experiments, which is a significant contribution to the field.
Overall, the paper is well-written, and the authors provide a clear and concise introduction to the problem and their approach. The theoretical results and experimental demonstrations provide a solid foundation for the algorithm, and the paper has the potential to make a significant impact in the field of large-scale optimization.
Arguments pro acceptance:
* The paper proposes a novel algorithm that is simple and efficient, making it suitable for large-scale problems.
* The theoretical results provide a solid foundation for the algorithm and its applicability to non-Gaussian designs.
* The experimental results demonstrate the efficiency and accuracy of the SLS algorithm compared to other optimization algorithms.
* The paper has the potential to make a significant impact in the field of large-scale optimization.
Arguments con acceptance:
* The paper could benefit from additional plots to further illustrate the trade-offs between the proposed method and existing algorithms.
* The theoretical results require further clarification and tightening to ensure consistency with special cases.
* The paper lacks clarity on the choice of |S| in experiments, with inconsistent notation and undefined parameters.
* The paper could provide more discussion on the implications of the proportionality relationship between GLM and OLS coefficients.