This paper proposes a convex relaxation of a bi-level training objective for two-layer networks with a structured hidden middle layer. The authors apply this approach to transliteration and image inpainting tasks, demonstrating its effectiveness. The paper's main contribution is the derivation of a convex formulation that captures latent structure and estimates model parameters jointly and optimally.
The paper is well-motivated, and the authors provide a clear overview of the background and related work. The technical development is sound, and the experiments demonstrate the promise of the method. However, there are some areas that require improvement. The paper makes several assumptions, adjustments, and approximations, which can make it difficult to understand the resulting algorithm's behavior and impact on model learning. Additionally, the use of a bi-level objective and SDP relaxation raises questions about their effects on model fidelity and optimization.
The experiments show positive results, but they lack detailed comparisons to non-structured methods and convexified CRF-AE, making it hard to assess the importance of structure and the method's usefulness. Furthermore, the paper could benefit from more discussion on the implications of the convex relaxation and its potential limitations.
In terms of quality, the paper is technically sound, but the claims could be better supported by theoretical analysis or experimental results. The paper is well-organized, but some sections could be improved for clarity. The originality of the paper is high, as it proposes a novel approach to convexifying bi-level objectives. The significance of the paper is also high, as it has the potential to impact the field of machine learning, particularly in areas where structured prediction is crucial.
Overall, I would recommend accepting this paper, but with revisions to address the aforementioned concerns. The authors should provide more discussion on the implications of the convex relaxation, compare their method to other approaches, and clarify some of the technical developments.
Arguments pro acceptance:
* The paper proposes a novel approach to convexifying bi-level objectives, which is a significant contribution to the field.
* The experiments demonstrate the effectiveness of the method on two tasks, showing its potential for real-world applications.
* The paper is well-motivated, and the authors provide a clear overview of the background and related work.
Arguments con acceptance:
* The paper makes several assumptions, adjustments, and approximations, which can make it difficult to understand the resulting algorithm's behavior and impact on model learning.
* The use of a bi-level objective and SDP relaxation raises questions about their effects on model fidelity and optimization.
* The experiments lack detailed comparisons to other approaches, making it hard to assess the importance of structure and the method's usefulness.