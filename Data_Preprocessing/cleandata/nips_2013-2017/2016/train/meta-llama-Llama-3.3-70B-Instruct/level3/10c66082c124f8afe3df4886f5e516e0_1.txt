This paper proposes a novel approach to domain adaptation in deep networks, which enables end-to-end learning of adaptive classifiers and transferable features. The approach, called Residual Transfer Network (RTN), relaxes the shared-classifier assumption made by previous methods and assumes that the source and target classifiers differ by a small residual function. The RTN model integrates deep feature learning, feature adaptation, and classifier adaptation in a unified framework, which can be trained by standard back-propagation.
The paper is well-written and provides a clear overview of the proposed approach, including the motivation, methodology, and experimental evaluation. The authors provide a thorough review of related work and highlight the differences between their approach and existing methods. The experimental evaluation is comprehensive, with results on several benchmark datasets, including Office-31 and Office-Caltech.
The strengths of the paper include:
* The proposed RTN approach is novel and addresses a key limitation of existing domain adaptation methods, which assume that the source and target classifiers are identical.
* The approach is scalable and can be implemented using standard deep learning packages.
* The experimental evaluation is thorough and demonstrates the effectiveness of the RTN approach on several benchmark datasets.
However, there are some weaknesses and limitations:
* The paper assumes that the source and target classifiers differ by a small residual function, which may not always be the case in practice.
* The approach requires careful tuning of hyperparameters, including the tradeoff parameters for the tensor MMD penalty and entropy penalty.
* The paper does not provide a detailed analysis of the computational complexity of the RTN approach, which may be important for large-scale applications.
Overall, the paper makes a significant contribution to the field of domain adaptation and provides a novel approach that addresses a key limitation of existing methods. The results are promising, and the approach has the potential to be applied to a wide range of applications.
Arguments for acceptance:
* The paper proposes a novel approach to domain adaptation that addresses a key limitation of existing methods.
* The approach is scalable and can be implemented using standard deep learning packages.
* The experimental evaluation is thorough and demonstrates the effectiveness of the RTN approach on several benchmark datasets.
Arguments against acceptance:
* The paper assumes that the source and target classifiers differ by a small residual function, which may not always be the case in practice.
* The approach requires careful tuning of hyperparameters, which may be time-consuming and require significant expertise.
* The paper does not provide a detailed analysis of the computational complexity of the RTN approach, which may be important for large-scale applications.
Recommendation: Accept, with minor revisions to address the limitations and weaknesses mentioned above.