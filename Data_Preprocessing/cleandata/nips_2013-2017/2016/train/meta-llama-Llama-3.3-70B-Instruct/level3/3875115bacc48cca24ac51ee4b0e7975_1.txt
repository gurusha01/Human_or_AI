This paper presents two fundamental results on the population likelihood function of Gaussian mixture models with M ≥ 3 components. The first result shows that the population likelihood function has bad local maxima even in the special case of equally-weighted mixtures of well-separated and spherical Gaussians. The second result shows that the EM algorithm with random initialization will converge to bad critical points with probability at least 1− e−Ω(M). 
The paper's results, although coherent, are not surprising and follow expected lines, particularly when the clusters are separated by a large distance, making the problem similar to k-means clustering. A comparison with k-means clustering and Lloyd's heuristic would be useful to contrast the results and provide a more comprehensive understanding of the EM algorithm's limitations.
The strengths of the paper include its thorough analysis of the EM algorithm and its variants, as well as its clear presentation of the results. The paper also provides a detailed proof of the theorems, which is helpful for understanding the underlying mathematics. However, the paper's weaknesses include its limited scope, as it only considers Gaussian mixture models with M ≥ 3 components, and its lack of comparison with other clustering algorithms.
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis. The paper is also well-organized, and the writing is clear. However, the paper could benefit from a more detailed discussion of the implications of the results and their potential applications.
In terms of originality, the paper presents new results on the population likelihood function of Gaussian mixture models, which is a significant contribution to the field. However, the paper's approach is not entirely new, as it builds on existing work on the EM algorithm and its variants.
In terms of significance, the paper's results have important implications for the use of the EM algorithm in practice, particularly in the context of clustering and density estimation. The paper's findings suggest that careful initialization is required for the EM algorithm to converge to a good solution, even in large-sample settings.
Arguments for acceptance:
* The paper presents new and significant results on the population likelihood function of Gaussian mixture models.
* The paper provides a thorough analysis of the EM algorithm and its variants.
* The paper's results have important implications for the use of the EM algorithm in practice.
Arguments against acceptance:
* The paper's scope is limited to Gaussian mixture models with M ≥ 3 components.
* The paper lacks a comparison with other clustering algorithms, such as k-means clustering and Lloyd's heuristic.
* The paper's results are not surprising, given the existing literature on the EM algorithm and its variants.
Overall, I would recommend accepting the paper, as it presents significant and original results on the population likelihood function of Gaussian mixture models. However, I would suggest that the authors consider addressing the limitations of the paper, such as its limited scope and lack of comparison with other clustering algorithms, in future work.