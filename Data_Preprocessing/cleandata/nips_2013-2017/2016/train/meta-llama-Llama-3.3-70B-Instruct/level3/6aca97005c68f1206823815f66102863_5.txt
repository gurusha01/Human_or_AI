This paper proposes a novel extension of the encoder-decoder framework, called the review network, which enhances the existing encoder-decoder model by performing multiple review steps with attention on the encoder hidden states. The review network outputs a set of thought vectors that capture the global properties of the input, which are then used by the decoder to generate the output. The authors demonstrate the effectiveness of the review network on two tasks: image captioning and source code captioning, achieving state-of-the-art performance on the MSCOCO benchmark dataset.
The paper is well-written and easy to follow, with clear explanations of the proposed architecture and its components. The authors provide a thorough analysis of the review network's performance, including ablation studies and comparisons to existing encoder-decoder models. The use of attention mechanisms and the introduction of thought vectors are interesting contributions to the field of sequence-to-sequence learning.
However, there are some concerns regarding the novelty of the proposed approach. The review network seems to be an extension of existing encoder-decoder models, and the authors could have done a better job of highlighting the key differences and advantages of their approach. Additionally, the paper could benefit from a more detailed discussion of the trade-offs between the number of review steps and the computational cost.
The experimental results are impressive, but it would be useful to see more analysis of the thought vectors and how they contribute to the overall performance of the model. The authors provide some visualizations of the attention weights, but a more detailed examination of the thought vectors and their relationship to the input and output sequences would be helpful.
In terms of the conference guidelines, the paper meets the criteria for quality, clarity, and significance. The authors provide a clear and well-organized presentation of their work, and the results are significant and relevant to the field of sequence-to-sequence learning. However, the paper could benefit from a more detailed discussion of the related work and the novelty of the proposed approach.
Overall, I would recommend accepting this paper, but with some revisions to address the concerns mentioned above. The authors should provide a more detailed discussion of the related work, highlight the key differences and advantages of their approach, and provide more analysis of the thought vectors and their contribution to the overall performance of the model.
Arguments for acceptance:
* The paper proposes a novel extension of the encoder-decoder framework that achieves state-of-the-art performance on the MSCOCO benchmark dataset.
* The authors provide a clear and well-organized presentation of their work, with a thorough analysis of the review network's performance.
* The use of attention mechanisms and the introduction of thought vectors are interesting contributions to the field of sequence-to-sequence learning.
Arguments against acceptance:
* The paper could benefit from a more detailed discussion of the related work and the novelty of the proposed approach.
* The authors could have done a better job of highlighting the key differences and advantages of their approach.
* The paper could benefit from more analysis of the thought vectors and their contribution to the overall performance of the model.