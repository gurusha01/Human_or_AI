This paper proposes a novel extension to the encoder-decoder framework, called the review network, which aims to improve performance in image and source code captioning tasks. The review network performs multiple review steps with attention on the encoder hidden states, outputting a set of thought vectors that capture global information in the input. The authors demonstrate that their model outperforms conventional attentive encoder-decoders and is competitive with state-of-the-art models on image captioning tasks.
The paper is well-written and clearly explains the proposed architecture and its components. The authors provide a thorough analysis of the model's performance on two different tasks, image captioning and source code captioning, and demonstrate its effectiveness in improving over baseline models. The use of attention mechanisms and discriminative supervision is well-motivated and contributes to the model's performance.
One of the strengths of the paper is its ability to provide a generic framework that can be applied to various tasks, making it a valuable contribution to the field. The authors also provide a detailed comparison with existing models and demonstrate the effectiveness of their approach.
However, there are some limitations to the paper. The authors do not provide a clear analysis of the impact of the review network on the model's performance, making it difficult to understand the extent of the benefit. Additionally, the comparison with attentive encoder-decoders with more layers is not thoroughly explored, which could provide further insights into the model's performance.
Some potential areas for improvement include exploring the use of different attention mechanisms, such as self-attention or hierarchical attention, and investigating the application of the review network to other tasks, such as machine translation or text summarization. Furthermore, the authors could provide more detailed analysis of the thought vectors and their role in the model's performance.
Overall, the paper presents a novel and effective approach to improving the encoder-decoder framework, and its contributions have the potential to impact the field of natural language processing and computer vision.
Arguments pro acceptance:
* The paper proposes a novel and effective approach to improving the encoder-decoder framework.
* The model outperforms conventional attentive encoder-decoders and is competitive with state-of-the-art models on image captioning tasks.
* The paper provides a thorough analysis of the model's performance on two different tasks.
* The use of attention mechanisms and discriminative supervision is well-motivated and contributes to the model's performance.
Arguments con acceptance:
* The paper does not provide a clear analysis of the impact of the review network on the model's performance.
* The comparison with attentive encoder-decoders with more layers is not thoroughly explored.
* The paper could benefit from more detailed analysis of the thought vectors and their role in the model's performance.
* The application of the review network to other tasks is not explored.