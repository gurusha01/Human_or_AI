This paper introduces a new concept, the "low approximate regret property", which relaxes the standard no-regret property in online algorithms. The authors show that this property is satisfied by many learning algorithms and provides price of anarchy guarantees in (\lambda-\mu) smooth games with a smaller error term after a smaller number of periods of play. The results only require realized feedback or bandit feedback, without needing the expectation over actions of other players.
The paper's technical contributions are significant, and the authors provide a thorough analysis of the properties of the low approximate regret property. However, the paper's language is sometimes seen as overselling the results, particularly in claims about fast convergence to equilibria in games, which may not be entirely accurate. Additionally, the relaxation of convergence and target states notions allows (\lambda-\mu) smoothness results to carry over, but stretching the interpretation of convergence and equilibrium may detract from the technical points.
The paper has technical overlap with previous works SAL15 and LST16, which reduces enthusiasm for an oral level presentation. Nevertheless, the paper's results are important and provide new insights into the behavior of online algorithms in smooth games. The authors' use of realized feedback or bandit feedback is a significant contribution, as it allows for more practical applications of the low approximate regret property.
The paper's practical implications for specific classes of games, such as two-player games or 2x2 games, are unclear and require further exploration. However, the authors' results provide a foundation for future research in this area.
In terms of quality, the paper is technically sound, and the authors provide a thorough analysis of the properties of the low approximate regret property. The paper is well-organized, and the authors provide sufficient information for the expert reader to reproduce the results. The paper's originality is significant, as it introduces a new concept and provides new insights into the behavior of online algorithms in smooth games. The paper's significance is also high, as it provides a foundation for future research in this area.
Overall, I would recommend accepting this paper for publication, but with some revisions to address the concerns mentioned above. The authors should tone down their language and provide more accurate claims about the results, and they should also provide more discussion on the practical implications of their results for specific classes of games.
Arguments pro acceptance:
* The paper introduces a new concept, the "low approximate regret property", which relaxes the standard no-regret property in online algorithms.
* The authors provide a thorough analysis of the properties of the low approximate regret property.
* The paper's results are important and provide new insights into the behavior of online algorithms in smooth games.
* The authors' use of realized feedback or bandit feedback is a significant contribution, as it allows for more practical applications of the low approximate regret property.
Arguments con acceptance:
* The paper's language is sometimes seen as overselling the results, particularly in claims about fast convergence to equilibria in games, which may not be entirely accurate.
* The relaxation of convergence and target states notions allows (\lambda-\mu) smoothness results to carry over, but stretching the interpretation of convergence and equilibrium may detract from the technical points.
* The paper has technical overlap with previous works SAL15 and LST16, which reduces enthusiasm for an oral level presentation.
* The paper's practical implications for specific classes of games, such as two-player games or 2x2 games, are unclear and require further exploration.