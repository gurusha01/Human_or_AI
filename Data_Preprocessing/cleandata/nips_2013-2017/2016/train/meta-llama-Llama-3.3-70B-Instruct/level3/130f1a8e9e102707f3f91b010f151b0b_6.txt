This paper presents a significant contribution to the understanding of Gaussian mixture models (GMMs) and the behavior of the Expectation-Maximization (EM) algorithm in estimating their parameters. The authors provide two fundamental results: (1) the existence of bad local maxima in the population likelihood function of GMMs, even in the case of equally-weighted, well-separated, and spherical Gaussians, and (2) the EM algorithm, with random initialization, converges to a bad critical point with high probability.
The paper is well-organized, and the introduction provides a clear overview of the background and motivation for the research. The authors demonstrate a thorough understanding of the existing literature and provide a clear explanation of the limitations of previous work. The technical sections are well-written, and the proofs are rigorous and well-explained.
The first result, which shows the existence of bad local maxima, is a significant contribution to the field. The authors provide a simple example of a mixture of three spherical Gaussians, which demonstrates that the population log-likelihood function can have local maxima that are arbitrarily worse than the global maximum. This result has important implications for the use of local search algorithms, such as EM, in estimating GMM parameters.
The second result, which shows that the EM algorithm converges to a bad critical point with high probability, is also significant. The authors provide a detailed analysis of the EM algorithm and demonstrate that, with random initialization, it is likely to converge to a suboptimal solution. This result highlights the importance of careful initialization in using the EM algorithm and suggests that alternative initialization schemes, such as those based on pilot estimators, may be necessary to ensure convergence to a good solution.
The paper also provides some interesting insights into the behavior of the first-order EM algorithm, which is a variant of the EM algorithm that uses gradient ascent updates. The authors show that this algorithm also converges to a bad critical point with high probability and provide some evidence that the problem of convergence to suboptimal fixed points is due to the existence of bad local maxima, rather than saddle points.
In terms of the conference guidelines, this paper meets all the criteria for a good scientific paper. The paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The paper is clearly written, and the organization is logical and easy to follow. The authors provide a thorough discussion of the related work and demonstrate a clear understanding of the contributions of the paper.
The originality of the paper is high, as it provides new insights into the behavior of GMMs and the EM algorithm. The significance of the paper is also high, as it has important implications for the use of local search algorithms in estimating GMM parameters.
Overall, I would recommend accepting this paper for publication. The paper makes a significant contribution to the field, and the results are well-supported by theoretical analysis and experimental results. The paper is well-written, and the authors demonstrate a clear understanding of the background and motivation for the research.
Arguments pro acceptance:
* The paper provides a significant contribution to the understanding of GMMs and the behavior of the EM algorithm.
* The results are well-supported by theoretical analysis and experimental results.
* The paper is well-written, and the authors demonstrate a clear understanding of the background and motivation for the research.
* The originality and significance of the paper are high.
Arguments con acceptance:
* None.