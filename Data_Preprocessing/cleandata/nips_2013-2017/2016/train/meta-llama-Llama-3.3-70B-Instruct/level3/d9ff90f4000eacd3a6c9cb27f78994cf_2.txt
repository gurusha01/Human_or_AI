This paper introduces a novel approach to estimating the coefficients of generalized linear models (GLMs) in the large-scale setting where the number of observations is much larger than the number of predictors. The authors propose an algorithm, called Scaled Least Squares (SLS), which achieves the same accuracy as the maximum likelihood estimator (MLE) but with a significantly reduced computational cost.
The paper is well-written, and the authors provide a clear and concise introduction to the problem and their approach. The technical sections are also well-organized, and the authors provide a thorough analysis of the theoretical properties of their algorithm. The experimental results demonstrate the effectiveness of the SLS algorithm in comparison to other optimization algorithms for finding the MLE.
One of the strengths of the paper is its ability to provide a simple and efficient solution to a complex problem. The authors show that the GLM coefficients are approximately proportional to the corresponding ordinary least squares (OLS) coefficients, which allows them to design an algorithm that is computationally efficient and achieves the same accuracy as the MLE.
However, there are some weaknesses in the paper. The experimental portion of the paper has some issues, including the use of different optimization methods and the lack of consideration of confounding factors. Additionally, the introduction of Stiefel manifolds in the paper seems unnecessary, as only the square matrix case is considered, which is equivalent to unitary matrices.
In terms of quality, the paper is technically sound, and the authors provide a thorough analysis of the theoretical properties of their algorithm. The claims are well-supported by theoretical analysis and experimental results. The paper is also well-organized, and the authors provide a clear and concise introduction to the problem and their approach.
In terms of clarity, the paper is well-written, and the authors provide a clear and concise introduction to the problem and their approach. The technical sections are also well-organized, and the authors provide a thorough analysis of the theoretical properties of their algorithm.
In terms of originality, the paper proposes a novel approach to estimating the coefficients of GLMs in the large-scale setting. The authors show that the GLM coefficients are approximately proportional to the corresponding OLS coefficients, which allows them to design an algorithm that is computationally efficient and achieves the same accuracy as the MLE.
In terms of significance, the paper addresses a difficult problem in a better way than previous research. The authors provide a simple and efficient solution to a complex problem, which has the potential to impact a wide range of applications in machine learning and statistics.
Arguments for acceptance:
* The paper proposes a novel approach to estimating the coefficients of GLMs in the large-scale setting.
* The authors provide a thorough analysis of the theoretical properties of their algorithm.
* The experimental results demonstrate the effectiveness of the SLS algorithm in comparison to other optimization algorithms for finding the MLE.
* The paper addresses a difficult problem in a better way than previous research.
Arguments against acceptance:
* The experimental portion of the paper has some issues, including the use of different optimization methods and the lack of consideration of confounding factors.
* The introduction of Stiefel manifolds in the paper seems unnecessary, as only the square matrix case is considered, which is equivalent to unitary matrices.
Overall, I would recommend accepting this paper, as it proposes a novel approach to estimating the coefficients of GLMs in the large-scale setting and provides a thorough analysis of the theoretical properties of the algorithm. However, the authors should address the issues in the experimental portion of the paper and consider revising the introduction to remove unnecessary material.