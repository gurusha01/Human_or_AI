This paper presents a global analysis of the Expectation Maximization (EM) algorithm for estimating parameters of Gaussian mixture models with known covariance and mixing proportions. The authors prove the convergence of the EM algorithm to the global maximum of the likelihood function for specific models, including a mixture of two Gaussians. The paper provides a detailed analysis of the Population EM algorithm, which is an idealized version of the EM algorithm that assumes an infinite sample size.
The main contribution of the paper is the characterization of the stationary points and dynamics of the EM algorithm for the considered models. The authors show that the EM algorithm can converge to the global maximum of the likelihood function, but also to local maxima or saddle points. The paper also establishes the consistency of the Sample-based EM algorithm, which is the actual EM algorithm used in practice.
The strengths of the paper include its rigorous mathematical analysis and the provision of a clear and detailed explanation of the results. The authors also discuss the implications of their results for the understanding of the EM algorithm and its behavior in practice.
However, the paper has some weaknesses. The main selling point of the paper is unclear, and the presentation could be improved to make the results more accessible to a broader audience. The models considered in the paper are relatively simple, and it is unclear how the results generalize to more complex models. Additionally, the proof techniques used in the paper are not novel or interesting enough to generalize to other models, and are buried in a long technical supplement without intuitive explanation.
The choice of models as a test case for the EM algorithm is also questionable, as they have a simple likelihood function with only two local maxima, making convergence to the global maximum seem inevitable. Furthermore, the models discussed in the paper can be easily estimated using methods like MOM or MOM plus a one-step estimator, making the need for the EM algorithm unclear.
In terms of the conference guidelines, the paper meets the criteria for quality, as it is technically sound and provides a complete piece of work. However, the paper could be improved in terms of clarity, as the presentation is sometimes dense and difficult to follow. The paper is also not particularly original, as it builds on existing work on the EM algorithm, but it does provide a useful contribution to the understanding of the algorithm's behavior.
Overall, I would recommend accepting the paper, but with revisions to improve the presentation and clarify the main contributions and implications of the results. The authors should also consider adding more discussion on the practical importance of their results and their potential applications.
Arguments pro acceptance:
* The paper provides a rigorous mathematical analysis of the EM algorithm for Gaussian mixture models.
* The authors establish the consistency of the Sample-based EM algorithm, which is an important result for practice.
* The paper provides a clear and detailed explanation of the results, making it accessible to experts in the field.
Arguments con acceptance:
* The main selling point of the paper is unclear, and the presentation could be improved.
* The models considered in the paper are relatively simple, and it is unclear how the results generalize to more complex models.
* The proof techniques used in the paper are not novel or interesting enough to generalize to other models.
* The choice of models as a test case for the EM algorithm is questionable, as they have a simple likelihood function with only two local maxima.