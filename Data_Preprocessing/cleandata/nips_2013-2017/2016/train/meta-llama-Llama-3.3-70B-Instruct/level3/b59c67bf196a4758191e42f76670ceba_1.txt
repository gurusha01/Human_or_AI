This paper presents a theoretical analysis of the robustness and consistency properties of a variation of the classical quadratic k-means algorithm, called robust k-means (RKM). The authors provide a detailed description of the optimality conditions for the associated minimization problem and show that RKM shares the computational simplicity of quadratic k-means, making it a "computationally cheap" candidate for robust nearest neighbor clustering.
The paper's main strengths include its thorough analysis of the breakdown properties of RKM, which shows that the algorithm is not robust against any type of contamination and any type of datasets, regardless of the form of the proximal map used. However, the authors also demonstrate that if the attention is restricted to "well-structured" datasets, then the algorithm exhibits some desirable noise robustness properties.
The paper's weaknesses include the lack of discussion on the convergence of the alternating optimization procedure used in RKM, as well as the sensitivity of the algorithm's performance to the value of certain parameters. Additionally, the experiments are only conducted on a fully transductive setup, which may not be practical in real-world scenarios.
In terms of originality, the paper's contribution is significant, as it provides a novel analysis of the robustness and consistency properties of RKM. The authors also relate RKM to trimmed k-means, another robust variant of k-means, and show that both algorithms perform similarly in practice.
The paper's significance is also notable, as it addresses a difficult problem in a better way than previous research. The authors' analysis provides valuable insights into the properties of RKM and its potential applications in real-world scenarios.
Overall, I would recommend accepting this paper, as it makes a significant contribution to the field of machine learning and provides a thorough analysis of the robustness and consistency properties of RKM. However, I would suggest that the authors address the weaknesses mentioned above, such as discussing the convergence of the alternating optimization procedure and conducting experiments on a more practical setup.
Arguments for acceptance:
* The paper provides a thorough analysis of the breakdown properties of RKM.
* The authors demonstrate that RKM exhibits desirable noise robustness properties on "well-structured" datasets.
* The paper relates RKM to trimmed k-means and shows that both algorithms perform similarly in practice.
* The authors' analysis provides valuable insights into the properties of RKM and its potential applications.
Arguments against acceptance:
* The paper lacks discussion on the convergence of the alternating optimization procedure used in RKM.
* The algorithm's performance may be sensitive to the value of certain parameters.
* The experiments are only conducted on a fully transductive setup, which may not be practical in real-world scenarios.