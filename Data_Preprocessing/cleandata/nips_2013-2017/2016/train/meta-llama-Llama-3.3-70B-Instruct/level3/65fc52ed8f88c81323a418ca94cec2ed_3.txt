This paper proposes an unsupervised learning method for deep networks based on classifying samples into pre-defined cliques using an optimization procedure to partition samples into batches. The method iterates to refine the learned similarity network, starting with HOG-LDA similarity, and demonstrates results through nearest-neighbor classification on various datasets. The paper is technically sound, especially in Section 2.3, where the optimization problem is formulated to select batches of mutually consistent cliques.
The strengths of the paper include its ability to handle unreliable initial similarities and approximate the full problem through an iterative process. The experiments are adequate, and the results show competitive performance compared to state-of-the-art approaches. The paper also provides a good presentation, making it easy to follow and understand.
However, there are some weaknesses to the paper. The method as a whole feels ad-hoc, and there is a lack of justification for using cliques instead of individual samples. The optimization objective could be more explicitly related to the goal of handling unreliable initial similarities and approximating the full problem. Section 2.2 is too terse and lacks supporting references, making reproducibility suffer. Additionally, the experiments could be improved with a better breakdown of the relative contributions of the pipeline's aspects and additional baselines, such as training a classifier on cliques or a simple two-stream network.
The results could be further validated with objective measures, such as cluster purity, to complement the visualizations and demonstrate the meaningfulness of the learned similarities. The paper could also benefit from a more detailed analysis of the learned similarities and their relationship to the underlying data.
In terms of the conference guidelines, the paper meets the criteria for quality, clarity, and significance. The paper is well-written, and the authors provide enough information for the expert reader to reproduce the results. The approach is novel and differs from previous contributions, and the related work is adequately referenced.
Arguments pro acceptance:
* The paper proposes a novel approach for unsupervised learning of similarities between large numbers of exemplars using CNNs.
* The method demonstrates competitive performance compared to state-of-the-art approaches.
* The paper provides a good presentation and is easy to follow and understand.
Arguments con acceptance:
* The method feels ad-hoc, and there is a lack of justification for using cliques instead of individual samples.
* The optimization objective could be more explicitly related to the goal of handling unreliable initial similarities and approximating the full problem.
* The experiments could be improved with additional baselines and a better breakdown of the relative contributions of the pipeline's aspects.
Overall, I would recommend accepting the paper, but with revisions to address the weaknesses mentioned above. The authors should provide more justification for using cliques, improve the optimization objective, and add more experiments and analysis to validate the results.