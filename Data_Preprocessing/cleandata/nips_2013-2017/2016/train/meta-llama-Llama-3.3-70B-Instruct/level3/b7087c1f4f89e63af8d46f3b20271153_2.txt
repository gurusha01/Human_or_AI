This paper proposes a novel approach for unsupervised learning of similarities between large numbers of exemplars using Convolutional Neural Networks (CNNs). The authors address the challenges of single positive exemplar setup, imbalance between exemplar and negatives, and inconsistent labels within SGD batches by formulating an optimization problem that yields SGD batches of compact, mutually dissimilar cliques of samples. The approach is evaluated on three different datasets, including Olympic Sports, Leeds Sports, and PASCAL VOC 2007, and demonstrates competitive performance compared to state-of-the-art methods.
The paper's key strengths include its ability to learn fine-grained similarity structures, particularly crucial for detailed posture analysis, and its potential to reduce computation time by leveraging the relationship information between compact cliques. The approach is also shown to be invariant to changes in appearance, as long as the shape is similar, which is a desirable property for unsupervised learning.
However, there are some weaknesses and areas for improvement. The proof of the optimization problem contains an error, specifically in replacing a vector with a matrix in Theorem 2, which needs to be corrected. Additionally, the algorithm's running time can be improved, and providing more intuition on this would be beneficial. The paper's organization is clear, but there are typos and inconsistencies in notation, such as the use of || || to denote both operator norm and vector l_2 norm, which need to be corrected for clarity.
Arguments pro acceptance include:
* The paper proposes a novel and effective approach for unsupervised learning of similarities between large numbers of exemplars using CNNs.
* The approach demonstrates competitive performance compared to state-of-the-art methods on multiple datasets.
* The paper provides a clear and well-organized presentation of the approach and its evaluation.
Arguments con acceptance include:
* The proof of the optimization problem contains an error, which needs to be corrected.
* The algorithm's running time can be improved, and more intuition on this would be beneficial.
* There are typos and inconsistencies in notation, which need to be corrected for clarity.
Overall, the paper makes a significant contribution to the field of unsupervised learning and CNNs, and with some revisions to address the weaknesses and areas for improvement, it has the potential to be a strong paper. 
Quality: 8/10
The paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. However, the error in the proof of the optimization problem needs to be corrected.
Clarity: 8/10
The paper is clearly written, and the organization is well-structured. However, there are typos and inconsistencies in notation, which need to be corrected for clarity.
Originality: 9/10
The paper proposes a novel approach for unsupervised learning of similarities between large numbers of exemplars using CNNs, which is a significant contribution to the field.
Significance: 9/10
The paper demonstrates competitive performance compared to state-of-the-art methods on multiple datasets, and the approach has the potential to reduce computation time and learn fine-grained similarity structures.