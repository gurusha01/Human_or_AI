This paper proposes a new notion of safety in reinforcement learning, which seeks to maximize the minimax improvement over a given baseline policy. The authors present related results and an approximate algorithm to achieve this goal. 
The paper's main contribution is the introduction of the Product Cut model for multi-way graph partitioning, which relies on a multiplicative cut-based objective. The authors provide a detailed investigation of the mathematical properties of this objective and an effective algorithm for its optimization. The proposed model has strong mathematical underpinnings, and the corresponding algorithm achieves state-of-the-art performance on benchmark data sets.
The development of the concept is sometimes hard to follow, and it would be beneficial to review existing notions of safety before introducing the novel idea. The paper's definition of safety is also questionable, and clarification is needed on why this definition is preferred over others, such as the high-probability, value-based definition.
The use of a multiplicative bound in Theorem 3 is also questionable, and it is unclear why an additive bound was not used instead. Furthermore, the proof of Theorem 5 is unclear, and additional explanation is needed to understand the passage from rho(pi_S, xi) to rho(pi^*, xi).
The proof of NP-hardness is also hard to follow, and clarification is needed on the statement and the description of the uncertainty set. Minor issues include the use of P^* instead of P, the definition of Def. 2, and the lack of clarity in the use of certain vectors and notation.
Despite these issues, the paper has several strengths. The proposed algorithm is simple and effective, and the experimental results demonstrate its state-of-the-art performance on various data sets. The paper also provides a detailed analysis of the stability properties of the Product Cut and Normalized Cut objectives, which is a significant contribution to the field.
In conclusion, while the paper has some weaknesses, its strengths make it a valuable contribution to the field of reinforcement learning and graph partitioning. With some revisions to address the issues mentioned above, the paper has the potential to be a high-quality publication.
Arguments pro acceptance:
- The paper proposes a new and interesting notion of safety in reinforcement learning.
- The proposed algorithm is simple and effective, and the experimental results demonstrate its state-of-the-art performance.
- The paper provides a detailed analysis of the stability properties of the Product Cut and Normalized Cut objectives.
Arguments con acceptance:
- The development of the concept is sometimes hard to follow, and additional review of existing notions of safety is needed.
- The paper's definition of safety is questionable, and clarification is needed on why this definition is preferred over others.
- The use of a multiplicative bound in Theorem 3 is questionable, and the proof of Theorem 5 is unclear.
- The proof of NP-hardness is hard to follow, and minor issues with notation and definitions need to be addressed.