This paper presents a significant contribution to the field of probabilistic inference, particularly in the context of Markov chain Monte Carlo (MCMC) methods. The authors extend the bidirectional Monte Carlo (BDMC) technique to evaluate MCMC-based posterior inference algorithms, providing a rigorous method for bounding the symmetrized KL divergence between the true posterior distribution and the distribution of approximate samples.
The paper is well-written, and the authors provide a clear and concise explanation of the methodology, including the derivation of the bias of the stochastic lower bound and the upper bound on the Jeffreys divergence. The integration of the method into popular platforms such as WebPPL and Stan is a notable contribution, making it accessible to a broader audience.
The experiments demonstrate the effectiveness of the method in evaluating the accuracy of posterior inference in realistic settings. The validation of the method on simulated data and its application to real-world datasets show promising results, and the authors provide a thorough discussion of the potential limitations and challenges.
The paper tackles a current and significant problem in the field, and the idea is interesting and worthy of consideration. The authors provide a rigorous and general procedure for monitoring the quality of posterior inference, which can be useful for non-expert users of probabilistic programming languages.
The strengths of the paper include:
* The method is technically sound, and the claims are well-supported by theoretical analysis and experimental results.
* The integration of the method into popular platforms makes it a notable contribution.
* The paper tackles a significant problem in the field, and the idea is interesting and worthy of consideration.
The weaknesses of the paper include:
* The method is limited to certain algorithms, such as AIS or SMC, and may not be applicable to other MCMC methods.
* The protocol for using BDMC to evaluate the accuracy of approximate inference on real-world datasets may not always yield representative results.
Overall, I recommend accepting the paper due to its overall quality and relevance to the field. The paper provides a significant contribution to the field of probabilistic inference, and the methodology has the potential to be widely adopted. The authors demonstrate a clear understanding of the problem and provide a rigorous and well-supported solution. 
Arguments pro acceptance:
* The paper presents a significant contribution to the field of probabilistic inference.
* The methodology is technically sound, and the claims are well-supported by theoretical analysis and experimental results.
* The integration of the method into popular platforms makes it a notable contribution.
* The paper tackles a significant problem in the field, and the idea is interesting and worthy of consideration.
Arguments con acceptance:
* The method is limited to certain algorithms, such as AIS or SMC, and may not be applicable to other MCMC methods.
* The protocol for using BDMC to evaluate the accuracy of approximate inference on real-world datasets may not always yield representative results.