This paper proposes Conditional Generative Moment-Matching Networks (CGMMN), a novel approach to learn conditional distributions using a conditional maximum mean discrepancy (CMMD) criterion. The authors extend the capability of Generative Moment-Matching Networks (GMMN) to address a wide range of application problems, including predictive modeling, contextual generation, and Bayesian dark knowledge.
The paper is well-organized, and the authors provide a clear motivation for their work, discussing the limitations of existing approaches and the benefits of their proposed method. The technical presentation is sound, with a thorough explanation of the CMMD criterion and the CGMMN architecture. The authors also provide a detailed analysis of the relationship between CMMD and MMD, highlighting the advantages of their approach.
The experimental evaluation is comprehensive, covering various tasks and datasets, including MNIST, SVHN, and Yale Face. The results demonstrate that CGMMN is competitive with state-of-the-art methods, including Variational Auto-encoders (VA) and Max-Margin Deep Generative Models (MMVA). The authors also show that CGMMN can be used for Bayesian dark knowledge distillation, achieving comparable performance to the original Bayesian model.
However, there are some limitations to the paper. The evaluation of the proposed method is lacking in some aspects, with aggregated performance results making it unclear how and why CGMMN outperforms other methods. Additionally, the presentation of results, including Figure 1, is unclear, with missing information such as a y-axis to interpret relative performance gaps.
Overall, the paper presents a significant contribution to the field of deep generative models, and the proposed CGMMN approach has the potential to improve the state-of-the-art in various applications. However, the authors should address the limitations mentioned above to strengthen their claims and provide a more comprehensive evaluation of their method.
Arguments For Acceptance:
1. The paper proposes a novel approach to learn conditional distributions using a conditional maximum mean discrepancy criterion.
2. The authors provide a thorough analysis of the relationship between CMMD and MMD, highlighting the advantages of their approach.
3. The experimental evaluation is comprehensive, covering various tasks and datasets.
4. The results demonstrate that CGMMN is competitive with state-of-the-art methods.
Arguments Against Acceptance:
1. The evaluation of the proposed method is lacking in some aspects, with aggregated performance results making it unclear how and why CGMMN outperforms other methods.
2. The presentation of results, including Figure 1, is unclear, with missing information such as a y-axis to interpret relative performance gaps.
3. The authors should provide more detailed comparisons with other methods, including ablation studies and sensitivity analysis.
Quality: 8/10
Clarity: 8/10
Originality: 9/10
Significance: 9/10
Recommendation: Accept with minor revisions to address the limitations mentioned above.