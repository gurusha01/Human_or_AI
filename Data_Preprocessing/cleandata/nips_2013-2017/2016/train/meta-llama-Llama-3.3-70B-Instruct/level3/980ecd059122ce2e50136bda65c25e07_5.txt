This paper proposes a novel approach to measuring the robustness of neural networks by formulating it as a linear programming problem. The authors define two statistics, adversarial frequency and adversarial severity, to quantify the robustness of a neural network. They also develop an algorithm, ALP, to approximate the pointwise robustness of a neural network, which is shown to be more accurate than existing algorithms.
The paper is well-written and easy to follow, with convincing results that could benefit researchers from the deep learning community. The proposed method is superior in identifying adversarial examples, and the authors demonstrate its effectiveness on the MNIST and CIFAR-10 datasets.
However, there are some limitations to the approach. The method relies on the linear properties of ReLU networks, which may limit its applicability to other types of neural networks. Additionally, the proposed method does not significantly improve performance on the test set, and the demonstration of superiority is limited to the MNIST dataset.
The formalization of linear constraints is also overly complex, introducing disjunctions that are later disregarded, making it exhausting and unnecessary. Furthermore, the algorithm's performance on larger datasets, such as CIFAR-10, is not impressive, with the fine-tuned neural net still being very prone to adversarial examples.
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The paper is also well-organized, and the authors provide enough information for the expert reader to reproduce the results.
The originality of the paper lies in its novel approach to formulating robustness as a linear programming problem and the development of the ALP algorithm. The paper also provides a thorough analysis of the related work and clearly explains how the proposed method differs from previous contributions.
The significance of the paper is that it provides a new perspective on measuring the robustness of neural networks and demonstrates the importance of using impartial measures to compare robustness. The paper also highlights the need for more research on improving the robustness of neural networks, particularly on larger datasets.
Overall, the paper is a good scientific contribution to the field, and the results are important for the development of more robust neural networks. However, the limitations of the approach and the need for further research on larger datasets should be acknowledged.
Arguments pro acceptance:
* The paper proposes a novel approach to measuring the robustness of neural networks.
* The authors develop an algorithm, ALP, which is shown to be more accurate than existing algorithms.
* The paper provides a thorough analysis of the related work and clearly explains how the proposed method differs from previous contributions.
* The results are important for the development of more robust neural networks.
Arguments con acceptance:
* The method relies on the linear properties of ReLU networks, which may limit its applicability to other types of neural networks.
* The proposed method does not significantly improve performance on the test set.
* The demonstration of superiority is limited to the MNIST dataset.
* The formalization of linear constraints is overly complex and introduces disjunctions that are later disregarded.
* The algorithm's performance on larger datasets, such as CIFAR-10, is not impressive.