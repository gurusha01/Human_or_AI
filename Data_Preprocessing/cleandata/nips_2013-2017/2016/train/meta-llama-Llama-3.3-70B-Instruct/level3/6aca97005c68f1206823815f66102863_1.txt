This paper proposes a novel extension of the encoder-decoder framework, called the review network, which enhances the existing encoder-decoder model by performing multiple review steps with attention on the encoder hidden states. The review network outputs a set of thought vectors that capture the global properties of the input, providing a more compact and abstractive representation. The authors demonstrate the effectiveness of the review network on two tasks: image captioning and source code captioning, achieving state-of-the-art performance on the MSCOCO benchmark dataset.
The paper is well-written and easy to understand, with a sufficient level of technical detail. The approach is novel and different from previous work, such as encoder-decoders with variational inference. The authors build upon previous work, using the key idea of proposition 1 to choose the proposal prior and estimate the posterior approximation. The paper also includes other moderate but useful contributions, such as the extension of MDN to SVI.
The strengths of the paper include its ability to improve over conventional encoder-decoders, its effectiveness in learning useful representations, and its ability to incorporate discriminative supervision in an end-to-end manner. The authors also provide a good mix of simple examples and larger datasets, effectively disentangling the effect of selecting the proposal distribution from the posterior estimation.
However, the paper lacks a firm theoretical underpinning, relying on asymptotic motivation provided by Proposition 1. Additionally, the metric used to evaluate performance could be improved, with CPU time potentially being a more relevant measure than effective sample size.
Arguments for acceptance include:
* The paper proposes a novel and effective extension of the encoder-decoder framework
* The approach is well-motivated and builds upon previous work
* The experimental results demonstrate the effectiveness of the review network on two tasks
* The paper is well-written and easy to understand
Arguments against acceptance include:
* The paper lacks a firm theoretical underpinning
* The metric used to evaluate performance could be improved
* The paper may not be significantly different from previous work in terms of its core ideas
Overall, I believe that the paper is a good scientific contribution to the field, and its strengths outweigh its weaknesses. I recommend acceptance, with the suggestion that the authors provide more theoretical justification and consider alternative evaluation metrics.