This paper proposes a novel approach to learning conditional distributions using a conditional generative moment-matching network (CGMMN). The method extends the capability of generative moment-matching networks (GMMN) to address a wide range of application problems, including predictive modeling, contextual generation, and Bayesian dark knowledge. The authors introduce a conditional maximum mean discrepancy (CMMD) criterion, which measures the difference between the kernel mean embedding of an empirical conditional distribution and that of the generative model.
The paper is well-organized, and the authors provide a clear explanation of the proposed method, including the mathematical formulation and the learning algorithm. The experimental results demonstrate the competitive performance of CGMMN in various tasks, including predictive modeling, data generation, and Bayesian dark knowledge.
The strengths of the paper include:
* The proposal of a novel approach to learning conditional distributions using CMMD, which is a significant extension of the GMMN framework.
* The provision of a clear and concise explanation of the mathematical formulation and the learning algorithm.
* The demonstration of competitive performance in various tasks, including predictive modeling, data generation, and Bayesian dark knowledge.
However, there are some weaknesses and areas for improvement:
* The paper lacks intensity and depth of analysis in the experimental results. More empirical experiments and comparisons with other state-of-the-art methods would strengthen the paper.
* The methodology presented is incremental, building upon existing ideas rather than introducing groundbreaking novelty.
* The notation clarity could be improved to avoid misunderstandings, and some related work is missing from the discussion.
* The paper could benefit from a more detailed discussion of the theoretical aspects, such as the submodularity of the CMMD objective.
To enhance the paper, I recommend the following:
* Rewrite the paper with improved notation clarity to avoid misunderstandings.
* Add more intensive experiments and comparisons with other state-of-the-art methods to demonstrate the effectiveness of the proposed approach.
* Explore the theoretical aspects of the CMMD objective, such as submodularity, to provide a deeper understanding of the method.
* Discuss related work more comprehensively to provide a clearer context for the proposed approach.
Overall, the paper presents a significant contribution to the field of deep generative models, and with some revisions, it has the potential to be a strong paper. 
Arguments pro acceptance:
* The paper proposes a novel approach to learning conditional distributions using CMMD.
* The experimental results demonstrate competitive performance in various tasks.
* The paper provides a clear explanation of the proposed method, including the mathematical formulation and the learning algorithm.
Arguments con acceptance:
* The paper lacks intensity and depth of analysis in the experimental results.
* The methodology presented is incremental, building upon existing ideas rather than introducing groundbreaking novelty.
* The notation clarity could be improved to avoid misunderstandings, and some related work is missing from the discussion.