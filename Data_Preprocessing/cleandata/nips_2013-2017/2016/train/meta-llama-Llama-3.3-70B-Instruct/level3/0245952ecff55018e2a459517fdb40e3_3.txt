This paper proposes a novel approach to learning Supervised PageRank models, which can account for features of nodes and edges in a graph. The authors develop two optimization methods, a gradient-free and a gradient-based method, to solve the non-convex loss-minimization problem. The gradient-free method is based on a random gradient-free optimization framework with inexact oracle, while the gradient-based method uses an adaptive projected gradient algorithm with inexact first-order oracle.
The paper is well-structured and easy to follow, with clear explanations of the proposed methods and their theoretical guarantees. The authors provide a thorough analysis of the convergence rates and complexity bounds for both methods. The experimental results demonstrate the effectiveness of the proposed methods on a web page ranking problem, outperforming the state-of-the-art gradient-based method.
The strengths of the paper include:
* The proposal of two novel optimization methods for learning Supervised PageRank models, which can handle non-convex loss functions and inexact oracles.
* The provision of theoretical guarantees for the convergence rates and complexity bounds of both methods.
* The demonstration of the effectiveness of the proposed methods on a real-world web page ranking problem.
However, there are some weaknesses and areas for improvement:
* The paper could benefit from more detailed comparisons with other existing methods for learning Supervised PageRank models.
* The experimental results are limited to a single dataset, and it would be useful to see results on other datasets to demonstrate the robustness of the proposed methods.
* Some of the notation and terminology used in the paper may be unfamiliar to readers without a strong background in optimization and graph theory.
Overall, the paper makes a significant contribution to the field of graph-based learning and optimization, and the proposed methods have the potential to be widely applicable in various domains.
Arguments pro acceptance:
* The paper proposes novel and effective optimization methods for learning Supervised PageRank models.
* The theoretical guarantees provided for the convergence rates and complexity bounds of the proposed methods are rigorous and well-established.
* The experimental results demonstrate the effectiveness of the proposed methods on a real-world problem.
Arguments con acceptance:
* The paper could benefit from more detailed comparisons with other existing methods.
* The experimental results are limited to a single dataset.
* Some of the notation and terminology used in the paper may be unfamiliar to readers without a strong background in optimization and graph theory.
Rating: 8/10
Recommendation: Accept with minor revisions to address the areas for improvement mentioned above.