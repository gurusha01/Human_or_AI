This paper presents a novel approach to unsupervised risk estimation, which is a crucial problem in machine learning. The authors propose a method that relies on conditional independence structure and makes no parametric assumptions about the true distribution. The approach is based on the method of moments and can be applied to a large family of losses, including the log and exponential losses. The paper also extends the framework to conditional random fields and provides a gradient-based learning algorithm.
The paper makes multiple contributions, including an extension to counting-based exploration and a modification to DQN, with impressive empirical results, particularly in solving Montezuma's Revenge. The formulation of pseudo-count seems novel, and the Montezuma's Revenge experiment demonstrates the method's effectiveness, making it a good paper that should be accepted.
However, I have some concerns about the claimed relationship between pseudo-count and information gain, which seems technically and philosophically different from the usual concept of information gain in intrinsic motivation literature. The paper questions the connection between the paper's definition of information gain and intrinsic motivation, and whether it truly unifies count-based exploration and intrinsic motivation.
Additionally, I wonder if pseudo-count has distinctive advantages over PG, or if they are more or less interchangeable, given that PG performs competitively without extra tweaking. The paper provides a good discussion on the strengths and weaknesses of the approach, and the authors are careful and honest about evaluating both the strengths and weaknesses of the work.
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The paper is clearly written, well-organized, and provides enough information for the expert reader to reproduce the results. The approach is novel, and the paper provides a unique combination of familiar techniques.
The significance of the paper lies in its ability to estimate the risk of a model on a novel distribution without any labeled data, which is an important problem in machine learning. The paper provides a principled way to handle lack of supervision and under-specification, and the results have implications for building reliable machine learning systems.
Overall, I would recommend accepting this paper, as it makes significant contributions to the field of machine learning, and the approach has the potential to be widely applicable. The paper is well-written, and the authors provide a clear and concise presentation of the results.
Arguments pro acceptance:
* The paper presents a novel approach to unsupervised risk estimation.
* The approach is based on conditional independence structure and makes no parametric assumptions about the true distribution.
* The paper provides impressive empirical results, particularly in solving Montezuma's Revenge.
* The approach has the potential to be widely applicable.
Arguments con acceptance:
* The claimed relationship between pseudo-count and information gain seems technically and philosophically different from the usual concept of information gain in intrinsic motivation literature.
* The paper questions the connection between the paper's definition of information gain and intrinsic motivation, and whether it truly unifies count-based exploration and intrinsic motivation.
* The paper does not provide a clear comparison with other methods, such as PG.