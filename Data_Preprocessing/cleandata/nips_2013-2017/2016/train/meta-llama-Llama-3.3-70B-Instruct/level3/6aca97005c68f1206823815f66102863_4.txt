This paper proposes a novel extension of the encoder-decoder framework, called the review network, which aims to improve the traditional encoder-decoder models by incorporating multiple review steps with attention on the encoder hidden states. The review network outputs a set of thought vectors that summarize the global information in the input, which are then used as input to the decoder. The paper presents a thorough evaluation of the review network on two tasks: image captioning and source code captioning, demonstrating consistent improvement over conventional encoder-decoders.
The paper is well-written, and the authors provide a clear explanation of the review network architecture and its components. The experimental results are thorough and well-presented, with a detailed comparison to baseline models and state-of-the-art systems. The paper also provides a good discussion of related work and the differences between the review network and other architectures.
One of the strengths of the paper is its ability to provide a generic and flexible framework that can be applied to various tasks, including image captioning and source code captioning. The review network is also shown to be more expressive than traditional encoder-decoders, which is a significant advantage. The paper also provides a good analysis of the thought vectors and their role in capturing global information, which is an interesting aspect of the review network.
However, there are some weaknesses in the paper. One of the limitations is the lack of direct comparison to other related methods, such as memory networks and attention-based models. While the paper provides a good discussion of related work, it would be beneficial to include a more thorough comparison to these methods. Additionally, the paper could benefit from a more detailed analysis of the review network's performance on different tasks and datasets.
In terms of the conference guidelines, the paper meets the criteria for quality, clarity, and originality. The paper is technically sound, and the claims are well-supported by experimental results. The paper is also well-organized and easy to follow, with a clear explanation of the review network architecture and its components. The paper presents a novel and original contribution to the field, and the review network has the potential to be applied to various tasks and domains.
Arguments pro acceptance:
* The paper presents a novel and original contribution to the field
* The review network is shown to be more expressive than traditional encoder-decoders
* The paper provides a thorough evaluation of the review network on two tasks
* The paper is well-written and easy to follow
Arguments con acceptance:
* The paper lacks a direct comparison to other related methods
* The paper could benefit from a more detailed analysis of the review network's performance on different tasks and datasets
* The paper may not be suitable for a general audience, as it assumes a strong background in deep learning and natural language processing.