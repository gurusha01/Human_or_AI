This paper proposes a novel approach to estimating the coefficients of generalized linear models (GLMs) in the large-scale setting where the number of observations is much larger than the number of predictors. The authors leverage an identity that relates GLM coefficients to ordinary least squares (OLS) coefficients, which can be estimated more efficiently. The proposed Scaled Least Squares (SLS) estimator achieves the same accuracy as the maximum likelihood estimator (MLE) with a significantly reduced computational cost.
The paper is well-written, and the introduction provides a clear motivation for the problem and the proposed approach. The authors provide a thorough review of related work and highlight the key novelties of their contribution. The technical sections are well-organized, and the proofs of the main results are provided in the supplementary material.
The strengths of the paper include:
* The proposed SLS estimator is computationally efficient and achieves the same accuracy as the MLE.
* The authors provide a rigorous analysis of the estimator's performance, including bounds on the estimation error.
* The paper highlights the potential for significant computational savings in large-scale problems.
However, there are some weaknesses and areas for improvement:
* The comparison to other optimization algorithms is not comprehensive, and it would be beneficial to include more baselines.
* The experimental evaluation could be more extensive, including more datasets and scenarios.
* Some of the notation and terminology may be unfamiliar to non-experts, and additional explanations or references would be helpful.
In terms of the conference guidelines, the paper addresses the key criteria:
* Quality: The paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results.
* Clarity: The paper is well-written, and the organization is clear. However, some notation and terminology may require additional explanation.
* Originality: The paper proposes a novel approach to estimating GLM coefficients, and the authors highlight the key novelties of their contribution.
* Significance: The paper addresses a significant problem in large-scale optimization and provides a computationally efficient solution.
Overall, I recommend accepting this paper, as it makes a significant contribution to the field of large-scale optimization and provides a novel approach to estimating GLM coefficients. However, I suggest that the authors address the weaknesses and areas for improvement mentioned above to further strengthen the paper.
Arguments pro acceptance:
* The paper proposes a novel and computationally efficient approach to estimating GLM coefficients.
* The authors provide a rigorous analysis of the estimator's performance, including bounds on the estimation error.
* The paper highlights the potential for significant computational savings in large-scale problems.
Arguments con acceptance:
* The comparison to other optimization algorithms is not comprehensive.
* The experimental evaluation could be more extensive.
* Some notation and terminology may be unfamiliar to non-experts.