This paper proposes a novel approach for unsupervised learning of similarities between large numbers of exemplars using convolutional neural networks (CNNs). The authors address the challenges of single positive exemplar setup, imbalance between exemplar and negatives, and inconsistent labels within stochastic gradient descent (SGD) batches. They formulate an optimization problem to select batches of compact, mutually dissimilar cliques of samples, which enables CNN training for exemplar-based learning.
The paper is well-written, and the motivation is clear. The authors provide a thorough review of related work and clearly explain the limitations of existing approaches. The proposed method is demonstrated on three different datasets, including Olympic Sports, Leeds Sports, and PASCAL VOC 2007, and shows competitive performance compared to state-of-the-art approaches.
The strengths of the paper include:
* The proposal of a novel approach for unsupervised learning of similarities using CNNs, which addresses the challenges of single positive exemplar setup and imbalance between exemplar and negatives.
* The formulation of an optimization problem to select batches of compact, mutually dissimilar cliques of samples, which enables CNN training for exemplar-based learning.
* The demonstration of the approach on three different datasets, including Olympic Sports, Leeds Sports, and PASCAL VOC 2007, and the comparison with state-of-the-art approaches.
The weaknesses of the paper include:
* The optimization problem is not convex, and the authors use a relaxation technique to solve it, which may not always converge to the global optimum.
* The approach requires a large number of parameters to be tuned, including the number of batches, the size of each batch, and the regularization parameters.
* The authors do not provide a thorough analysis of the computational complexity of the approach, which may be a limitation for large-scale datasets.
Overall, the paper is well-written, and the proposed approach is novel and interesting. The experimental results demonstrate the effectiveness of the approach, and the comparison with state-of-the-art approaches is thorough. However, the optimization problem and the computational complexity of the approach need to be further analyzed and improved.
Arguments pro acceptance:
* The paper proposes a novel approach for unsupervised learning of similarities using CNNs, which addresses the challenges of single positive exemplar setup and imbalance between exemplar and negatives.
* The approach demonstrates competitive performance compared to state-of-the-art approaches on three different datasets.
* The paper is well-written, and the motivation is clear.
Arguments con acceptance:
* The optimization problem is not convex, and the authors use a relaxation technique to solve it, which may not always converge to the global optimum.
* The approach requires a large number of parameters to be tuned, including the number of batches, the size of each batch, and the regularization parameters.
* The authors do not provide a thorough analysis of the computational complexity of the approach, which may be a limitation for large-scale datasets.