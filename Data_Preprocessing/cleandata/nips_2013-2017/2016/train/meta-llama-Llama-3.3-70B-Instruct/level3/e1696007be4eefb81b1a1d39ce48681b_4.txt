This paper proposes a novel approach to efficiently estimate the coefficients of Generalized Linear Models (GLMs) in large-scale settings. The authors exploit the fact that GLM coefficients are approximately proportional to the corresponding Ordinary Least Squares (OLS) coefficients when predictors are normally distributed. They design an algorithm, called Scaled Least Squares (SLS), which estimates the OLS coefficients and then finds the proportionality constant using a univariate root-finding method.
The paper is well-written, especially in the first three sections, which provide a clear introduction to the problem and the proposed approach. However, the second half of the paper seems a bit hurried and lacks clarity on some points, such as the requirement of a canonical link. The authors provide theoretical guarantees for their algorithm and demonstrate its performance through extensive numerical studies on large-scale real and synthetic datasets.
The proposed approach has potential, but some results, such as the performance of the SLS method in Figure 1, are puzzling and require further explanation. The introduction of extra variance when estimating the constant c is not fully addressed, and the use of sub-sampling in the experiments makes the results harder to interpret. The comparison with other methods, such as Iteratively Reweighted Least Squares (IRLS), is incomplete, and the initialization of MLE algorithms is not fully discussed, which raises questions about the fairness of the comparison.
The experimental setup and results are not fully clear, with questions about the number of runs, convergence of methods, and presentation of results, such as the cramming of Figure 2 and the lack of explanation for Corollary 1. Some minor points, such as the equivalence of logistic regression and Fisher's discriminant analysis, and the definition of lambda_min, require clarification or correction.
In terms of quality, the paper is technically sound, but the claims could be better supported by theoretical analysis or experimental results. The authors are careful about evaluating the strengths and weaknesses of their work, but some points, such as the computational benefits of the SLS method, could be more thoroughly discussed. The paper is well-organized, but some sections, such as Section 6, could be improved for better clarity.
The originality of the paper lies in its novel approach to estimating GLM coefficients, which has potential applications in large-scale machine learning and statistics problems. The paper provides a unique perspective on the relationship between GLM and OLS coefficients, and the proposed algorithm could be useful in practice. However, the paper could benefit from more thorough discussions of related work and the implications of the proposed approach.
The significance of the paper lies in its potential to improve the efficiency of GLM estimation in large-scale settings. The proposed approach could be useful in a variety of applications, such as logistic regression, Poisson regression, and linear regression. However, the paper could benefit from more thorough evaluations of the proposed approach and its comparison to other methods.
Overall, I would recommend accepting this paper, but with revisions to address the clarity and completeness of the presentation, as well as the fairness of the comparison to other methods. The authors should provide more thorough discussions of the theoretical guarantees, experimental setup, and results, as well as the implications of the proposed approach.
Arguments pro acceptance:
* The paper proposes a novel approach to estimating GLM coefficients, which has potential applications in large-scale machine learning and statistics problems.
* The proposed algorithm is computationally efficient and has potential benefits in practice.
* The paper provides a unique perspective on the relationship between GLM and OLS coefficients.
Arguments con acceptance:
* The paper lacks clarity on some points, such as the requirement of a canonical link and the introduction of extra variance when estimating the constant c.
* The comparison with other methods is incomplete, and the initialization of MLE algorithms is not fully discussed.
* The experimental setup and results are not fully clear, with questions about the number of runs, convergence of methods, and presentation of results.