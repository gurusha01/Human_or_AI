This paper presents a novel approach to modeling and analyzing crowdsourcing systems using information theory. The authors propose a framework that views crowdsourcing as a human-in-the-loop computation problem, where a taskmaster breaks down a project into small tasks and assigns them to workers with imperfect skill levels. The paper provides a thorough analysis of the fundamental performance limits of crowdsourcing, including the tradeoff between budget and fidelity.
The paper's main contribution is the development of a joint source-channel coding scheme that represents the query scheme and inference in crowdsourcing. The authors derive information-theoretic bounds on the minimum number of queries per item required to achieve a certain level of fidelity, considering both unknown and known worker skill levels. They also introduce a new query scheme, k-ary incidence coding, and analyze its performance using a spammer-hammer worker pool model.
The paper is well-organized and clearly written, with a good balance of theoretical analysis and numerical results. The authors provide a thorough review of related work and clearly explain the significance of their contributions. The use of information theory to analyze crowdsourcing systems is a novel and interesting approach, and the paper provides valuable insights into the fundamental limits of crowdsourcing.
However, the paper could be improved in several ways. Firstly, the technical nature of the paper may make it difficult for non-experts to understand, and the authors could provide more high-level intuition and explanations to make the paper more accessible. Secondly, the paper could benefit from a clearer conclusion that summarizes the key takeaways and implications of the results. Finally, the authors could discuss related work on robust economic incentives for workers and mechanism design for crowdsourcing in more detail, as these topics are closely related to the paper's contributions.
In terms of minor errors and areas of confusion, there are a few instances where the notation and terminology could be clarified. For example, the distinction between the terms "worker" and "channel" could be made clearer, and some of the sentences could be rephrased for better clarity.
Overall, the paper is a valuable contribution to the field of crowdsourcing and information theory, and the authors' work has the potential to inform the design of more efficient and effective crowdsourcing systems. With some revisions to address the areas mentioned above, the paper could be even stronger and more impactful.
Arguments for acceptance:
* The paper presents a novel and interesting approach to modeling and analyzing crowdsourcing systems using information theory.
* The authors provide a thorough analysis of the fundamental performance limits of crowdsourcing, including the tradeoff between budget and fidelity.
* The paper introduces a new query scheme, k-ary incidence coding, and analyzes its performance using a spammer-hammer worker pool model.
* The authors provide a thorough review of related work and clearly explain the significance of their contributions.
Arguments against acceptance:
* The paper may be difficult for non-experts to understand due to its technical nature.
* The paper could benefit from a clearer conclusion that summarizes the key takeaways and implications of the results.
* The authors could discuss related work on robust economic incentives for workers and mechanism design for crowdsourcing in more detail.