This paper proposes a novel approach to unitary recurrent neural networks (uRNNs) by optimizing the recurrence matrix over all unitary matrices, leading to significantly improved performance over uRNNs that use a restricted-capacity recurrence matrix. The authors provide a theoretical argument to determine if a unitary parameterization has restricted capacity and show that a recently proposed unitary parameterization has restricted capacity for hidden state dimension greater than 7. They also propose a method for stochastic gradient descent for training the unitary recurrence matrix, which constrains the gradient to lie on the differentiable manifold of unitary matrices.
The paper is well-written and clearly explains the background and motivation of the research. The authors provide a thorough analysis of the limitations of restricted-capacity parameterizations and demonstrate the effectiveness of their proposed approach through experiments on synthetic and natural data. The results show that full-capacity uRNNs outperform restricted-capacity uRNNs and LSTMs on various tasks, including system identification, long-term memorization, and speech prediction.
The strengths of the paper include its clear and concise writing style, thorough analysis of the limitations of restricted-capacity parameterizations, and impressive experimental results. The authors also provide a detailed explanation of their proposed method for optimizing full-capacity unitary matrices, which is easy to follow and understand.
One potential weakness of the paper is the lack of comparison to non-RKHS Koopman spectral analysis in simulations. The authors could have included a comparison to other methods to further demonstrate the effectiveness of their approach. Additionally, the authors could have explored the choice of kernels and its potential impact on the results, which could be done through simulations or discussions.
Overall, the paper is well-structured and easy to follow, and the authors provide a clear and concise explanation of their research. The results are impressive, and the paper makes a significant contribution to the field of unitary recurrent neural networks.
Arguments pro acceptance:
* The paper proposes a novel approach to unitary recurrent neural networks that leads to significantly improved performance over existing methods.
* The authors provide a thorough analysis of the limitations of restricted-capacity parameterizations and demonstrate the effectiveness of their proposed approach through experiments on synthetic and natural data.
* The paper is well-written and clearly explains the background and motivation of the research.
Arguments con acceptance:
* The paper lacks a comparison to non-RKHS Koopman spectral analysis in simulations, which could have further demonstrated the effectiveness of the approach.
* The authors could have explored the choice of kernels and its potential impact on the results, which could be done through simulations or discussions.
Quality: 9/10
Clarity: 9/10
Originality: 8/10
Significance: 9/10
Overall, I would recommend accepting this paper for publication, as it makes a significant contribution to the field of unitary recurrent neural networks and demonstrates impressive experimental results. However, the authors could have included a comparison to other methods and explored the choice of kernels to further strengthen their research.