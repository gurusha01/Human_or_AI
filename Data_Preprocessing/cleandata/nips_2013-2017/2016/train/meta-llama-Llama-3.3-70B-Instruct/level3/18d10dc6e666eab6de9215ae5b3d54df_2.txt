This paper proposes a novel parallel Bayesian optimization algorithm, the parallel knowledge gradient method, which computes Bayes-optimal batches and outperforms existing Bayesian optimization approaches. The writing style is clear and easy to follow, making the paper a pleasure to read. The proposed parallel Bayesian optimization approach is elegant and an important subject for practical hyperparameter optimization.
The theoretical aspect of the paper is strong, providing a solid foundation for the proposed algorithm. However, the experiments are somewhat disappointing due to issues such as the use of test set error as an optimization criterion, which is a suboptimal score-function for hyperparameter tuning. Additionally, the benchmark used in the paper is limited, using only two datasets and a single machine learning task, which is not sufficient to be truly convincing. A more comprehensive evaluation using varied benchmarks, such as HPOlib, would be beneficial.
One of the key assumptions in the paper is that of independent normally distributed errors, which may not always be realistic, especially in hyperparameter optimization where measurement errors can represent differences between generalization performance and empirical estimates. This assumption may limit the applicability of the proposed algorithm in certain scenarios.
Despite these limitations, the paper makes a valuable contribution to the field of machine learning, and the proposed algorithm has the potential to be highly effective in practice. The use of infinitesimal perturbation analysis to optimize the acquisition function is a notable aspect of the paper, allowing for efficient computation of the gradient of the parallel knowledge gradient factor.
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The authors are careful and honest about evaluating both the strengths and weaknesses of the work. The paper is clearly written, well-organized, and provides enough information for the expert reader to reproduce the results.
The originality of the paper lies in the proposal of a novel parallel Bayesian optimization algorithm, which is a novel combination of familiar techniques. The related work is adequately referenced, and the paper provides a clear understanding of how it differs from previous contributions.
The significance of the paper is evident, as it addresses a difficult problem in a better way than previous research. The results are important, and other people, both practitioners and researchers, are likely to use these ideas or build on them. The paper advances the state of the art in a demonstrable way, providing a unique theoretical and pragmatic approach to parallel Bayesian optimization.
Overall, I would recommend accepting this paper, but with the suggestion that the authors address the limitations mentioned above, particularly with regards to the benchmark and the assumption of independent normally distributed errors. 
Arguments pro acceptance:
- The paper proposes a novel and elegant parallel Bayesian optimization algorithm.
- The theoretical aspect of the paper is strong, providing a solid foundation for the proposed algorithm.
- The paper makes a valuable contribution to the field of machine learning.
- The results are important, and other people are likely to use these ideas or build on them.
Arguments con acceptance:
- The experiments are limited, using only two datasets and a single machine learning task.
- The assumption of independent normally distributed errors may not always be realistic.
- The use of test set error as an optimization criterion is suboptimal.
- A more comprehensive evaluation using varied benchmarks would be beneficial.