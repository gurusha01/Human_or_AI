This paper presents a novel approach to unsupervised learning of similarities between large numbers of exemplars using Convolutional Neural Networks (CNNs). The authors address the challenges of single positive exemplar setup, imbalance between exemplar and negatives, and inconsistent labels within SGD batches. The proposed method formulates an optimization problem to extract batches of samples with mutually consistent relations, which are then used to train a CNN. The approach is evaluated on three different datasets, including Olympic Sports, Leeds Sports, and PASCAL VOC 2007, and demonstrates competitive performance compared to state-of-the-art methods.
The paper is well-structured and clearly introduces the problem setup, providing intuition and interpretation of all analysis. The technical proofs, including Theorem 1 and Theorem 2, are sound and provide a solid foundation for the proposed approach. The key idea of Theorem 2 is clever and shows novelty and originality. The results have potential impact on both theory and practice, including inspiring study of local optima structure of related clustering tasks and providing insights in designing new algorithms.
The strengths of the paper include:
* Novel approach to unsupervised learning of similarities using CNNs
* Well-structured and clear presentation
* Sound technical proofs
* Competitive performance on benchmark datasets
* Potential impact on both theory and practice
The weaknesses of the paper include:
* Limited analysis of the optimization problem and its solution
* No comparison with other optimization methods
* Limited discussion of the computational cost and scalability of the approach
Overall, the paper is well-written and presents a significant contribution to the field of unsupervised learning. The approach is novel and has potential impact on both theory and practice. However, some limitations and areas for future work are identified, including further analysis of the optimization problem and its solution, comparison with other optimization methods, and discussion of computational cost and scalability.
Arguments pro acceptance:
* Novel approach to unsupervised learning of similarities using CNNs
* Competitive performance on benchmark datasets
* Potential impact on both theory and practice
* Well-structured and clear presentation
Arguments con acceptance:
* Limited analysis of the optimization problem and its solution
* No comparison with other optimization methods
* Limited discussion of the computational cost and scalability of the approach
Recommendation: Accept with minor revisions to address the limitations and areas for future work identified above.