This paper proposes a novel batch Bayesian optimization algorithm, the parallel knowledge gradient method (q-KG), which is derived from a decision-theoretical perspective. The authors demonstrate that q-KG outperforms or is competitive with state-of-the-art benchmark algorithms on several synthetic functions and in tuning practical machine learning algorithms, especially in the presence of noisy function evaluations.
The paper is well-written and clearly organized, making it easy to follow. The authors provide a thorough review of related work and clearly explain the motivation and contributions of their research. The technical content is sound, and the authors provide a detailed description of the q-KG algorithm and its implementation.
One of the strengths of the paper is its ability to handle noisy function evaluations, which is a common challenge in real-world optimization problems. The authors demonstrate that q-KG performs well in both noise-free and noisy settings, and its performance advantage over benchmark algorithms is even larger in the noisy setting.
However, there are some areas that could be improved. For example, the paper could benefit from a more detailed comparison with other batch Bayesian optimization algorithms, such as those mentioned in the related work section. Additionally, the authors could provide more insight into the computational complexity of the q-KG algorithm and its scalability to high-dimensional problems.
In terms of the conference guidelines, the paper meets the criteria for quality, clarity, and originality. The authors provide a clear and concise abstract, and the introduction effectively motivates the research and provides a clear overview of the paper's contents. The paper is well-organized, and the technical content is sound. The authors also provide a thorough review of related work and clearly explain the contributions of their research.
Overall, I would recommend accepting this paper for publication. The research is novel and significant, and the paper is well-written and clearly organized. With some minor revisions to address the areas mentioned above, the paper has the potential to make a valuable contribution to the field of Bayesian optimization.
Arguments pro acceptance:
* The paper proposes a novel batch Bayesian optimization algorithm that outperforms or is competitive with state-of-the-art benchmark algorithms.
* The authors demonstrate the effectiveness of the q-KG algorithm in both noise-free and noisy settings.
* The paper is well-written and clearly organized, making it easy to follow.
* The authors provide a thorough review of related work and clearly explain the contributions of their research.
Arguments con acceptance:
* The paper could benefit from a more detailed comparison with other batch Bayesian optimization algorithms.
* The authors could provide more insight into the computational complexity of the q-KG algorithm and its scalability to high-dimensional problems.
* Some minor revisions are needed to address the areas mentioned above.