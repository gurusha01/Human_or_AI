This paper presents Conditional Generative Moment-Matching Networks (CGMMN), a novel framework for learning conditional distributions using a conditional maximum mean discrepancy (CMMD) criterion. The authors extend the capability of Generative Moment-Matching Networks (GMMN) to address a wide range of application problems, including predictive modeling, contextual generation, and Bayesian dark knowledge.
The paper is well-written, and the authors provide a clear and concise introduction to the background and motivation of the work. The technical sections are also well-organized, and the authors provide a thorough explanation of the CMMD criterion and the CGMMN architecture.
The strengths of the paper include:
* The authors propose a novel and flexible framework for learning conditional distributions, which can be applied to various tasks.
* The CMMD criterion is well-motivated and provides a simple and efficient way to learn the conditional distribution.
* The authors provide a thorough evaluation of the proposed method on various tasks, including predictive modeling, contextual generation, and Bayesian dark knowledge.
* The results demonstrate competitive performance of CGMMN compared to state-of-the-art methods.
The weaknesses of the paper include:
* The paper assumes a significant amount of background knowledge in deep learning and kernel methods, which may make it difficult for non-experts to follow.
* The authors could provide more intuition and explanation for the choice of the CMMD criterion and the CGMMN architecture.
* Some of the experimental results, such as the generation of images, could be improved with more detailed analysis and evaluation.
Overall, the paper is well-written, and the authors provide a significant contribution to the field of deep learning and conditional modeling. The proposed CGMMN framework has the potential to be applied to various tasks and provides a flexible and efficient way to learn conditional distributions.
Arguments for acceptance:
* The paper proposes a novel and flexible framework for learning conditional distributions.
* The CMMD criterion is well-motivated and provides a simple and efficient way to learn the conditional distribution.
* The authors provide a thorough evaluation of the proposed method on various tasks.
* The results demonstrate competitive performance of CGMMN compared to state-of-the-art methods.
Arguments against acceptance:
* The paper assumes a significant amount of background knowledge in deep learning and kernel methods.
* The authors could provide more intuition and explanation for the choice of the CMMD criterion and the CGMMN architecture.
* Some of the experimental results could be improved with more detailed analysis and evaluation.
Rating: 8/10
Recommendation: Accept with minor revisions. The authors should provide more intuition and explanation for the choice of the CMMD criterion and the CGMMN architecture and improve some of the experimental results with more detailed analysis and evaluation.