This paper introduces a new family of discrete probabilistic models, called cooperative graphical models, which capture variable interactions more expressively than traditional graphical models. The authors propose efficient inference techniques for these models by exploiting their submodular structure and combining it with variational inference methods. The paper provides a thorough overview of related work, including maximum-a-posteriori (MAP) estimation, variational inference, and log-supermodular models.
The authors derive convex upper bounds on the partition function using a linearization of the model, which leads to a convex optimization problem over the base polytope of a submodular function. They propose two algorithms for solving this problem: Frank-Wolfe and projected gradient descent (PGD). The paper also discusses the smoothness of the optimization problem and provides conditions under which the problem is smooth.
In addition to upper bounds, the authors develop lower bounds on the partition function using a submodular minimization problem. They propose a block-coordinate ascent method to optimize the lower bound and show that it can be solved efficiently using existing algorithms.
The paper presents experimental results on synthetic and real-world data, demonstrating the efficacy and scalability of the proposed inference schemes. The results show that the methods optimizing the fully convex upper bound yield good marginal probabilities and log-partition function estimates, while the lower bounds work well for settings with small pairwise strength.
The strengths of the paper include:
* Introduction of a new family of probabilistic models that capture rich variable interactions
* Development of efficient inference techniques that exploit the submodular structure of the models
* Provision of convex upper bounds and submodular lower bounds on the partition function
* Experimental evaluation on synthetic and real-world data demonstrating the efficacy and scalability of the proposed methods
The weaknesses of the paper include:
* The paper assumes submodularity of the function f, which may not always be the case in practice
* The optimization problem for the upper bound may not be smooth in all cases, which can affect the convergence of the algorithms
* The paper does not provide a detailed comparison with existing inference methods for graphical models
Overall, the paper presents a significant contribution to the field of probabilistic graphical models and variational inference. The proposed methods have the potential to be applied to a wide range of problems, including computer vision, natural language processing, and recommender systems.
Arguments pro acceptance:
* The paper introduces a new family of probabilistic models that capture rich variable interactions
* The proposed inference techniques are efficient and scalable
* The experimental results demonstrate the efficacy of the proposed methods
Arguments con acceptance:
* The paper assumes submodularity of the function f, which may not always be the case in practice
* The optimization problem for the upper bound may not be smooth in all cases
* The paper does not provide a detailed comparison with existing inference methods for graphical models
Recommendation: Accept, with minor revisions to address the weaknesses mentioned above.