This paper presents a comprehensive study of linear regression and classification in the limited attribute observation (LAO) setting, where the learning algorithm can only access a limited number of attributes per example. The authors provide the first lower bounds on the precision attainable by any algorithm for several variants of regression, including linear regression with absolute loss and squared loss, as well as classification with hinge loss.
The paper is well-written, and the authors provide a clear and concise introduction to the LAO setting and the problems they aim to address. The technical contributions of the paper are significant, and the authors provide a thorough analysis of the lower bounds they establish. The proofs of the main results are detailed and well-explained, making it easy to follow the authors' reasoning.
One of the strengths of the paper is its ability to provide a unified framework for analyzing the LAO setting, which allows the authors to derive lower bounds for various loss functions and settings. The authors also provide a general-purpose algorithm for regression and classification with missing data, which complements their lower bounds and provides a means of achieving error up to a certain precision limit.
The paper is well-organized, and the authors provide a clear overview of the main results and contributions in the introduction. The technical sections are well-structured, and the authors provide a detailed analysis of the lower bounds and the algorithm they propose.
In terms of originality, the paper presents several new results, including the first lower bounds for regression with absolute loss and classification with hinge loss in the LAO setting. The authors also provide a new algorithm for regression and classification with missing data, which improves upon existing results.
The significance of the paper lies in its ability to provide a comprehensive understanding of the LAO setting and the limits of learning in this setting. The authors' results have implications for a wide range of applications, including medical diagnosis, where the number of attributes that can be observed is often limited.
Overall, I would recommend accepting this paper for publication. The paper presents significant technical contributions, and the authors provide a clear and well-written exposition of their results. The paper is well-organized, and the authors provide a thorough analysis of the lower bounds and the algorithm they propose.
Arguments for acceptance:
* The paper presents significant technical contributions, including the first lower bounds for regression with absolute loss and classification with hinge loss in the LAO setting.
* The authors provide a unified framework for analyzing the LAO setting, which allows them to derive lower bounds for various loss functions and settings.
* The paper is well-written, and the authors provide a clear and concise introduction to the LAO setting and the problems they aim to address.
* The authors provide a general-purpose algorithm for regression and classification with missing data, which complements their lower bounds and provides a means of achieving error up to a certain precision limit.
Arguments against acceptance:
* The paper assumes a limited number of attributes per example, which may not be realistic in all applications.
* The authors' results are primarily theoretical, and it is unclear how they will be applied in practice.
* The paper does not provide an extensive experimental evaluation of the proposed algorithm, which may limit its impact on the field.