This paper proposes a method for constructing and summarizing confidence sets for the unknown true cluster tree, which is a highly-interpretable summary of a density function representing the hierarchy of its high-density clusters. The authors introduce a partial ordering on cluster trees to prune statistically insignificant features, resulting in interpretable and parsimonious cluster trees. 
The paper lacks clarity and organization, with some sections and discussions being limited or unrelated to the main contribution. For instance, the title of the paper is misleading, as it promises hypothesis testing discussions that are not actually presented. The paper requires improvements in presentation, such as adding labels to figures and clarifying the meaning of certain terms like "feature". 
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. However, the paper lacks innovation and significance, particularly in terms of comparing its results to existing methods and demonstrating practical applications. The experimental section fails to validate some of the key contributions, such as the convergence rate independent of dimension.
The paper's strengths include its novel approach to statistical inference for cluster trees and its potential applications in various fields. The authors provide a clear definition of the cluster tree and its properties, and they propose a method for constructing confidence sets using the bootstrap. The paper also includes some interesting examples and simulations that demonstrate the effectiveness of the proposed method.
However, the paper's weaknesses outweigh its strengths. The lack of clarity and organization, combined with the misleading title and limited presentation, make it difficult to follow and understand the paper. Additionally, the paper's lack of innovation and significance, as well as its failure to validate some of its key contributions, raise concerns about its overall quality and impact.
Arguments pro acceptance:
* The paper proposes a novel approach to statistical inference for cluster trees.
* The authors provide a clear definition of the cluster tree and its properties.
* The paper includes some interesting examples and simulations that demonstrate the effectiveness of the proposed method.
Arguments con acceptance:
* The paper lacks clarity and organization.
* The title is misleading, and the presentation is limited.
* The paper lacks innovation and significance.
* The experimental section fails to validate some of the key contributions.
* The paper requires significant improvements in terms of quality, clarity, and presentation.
Overall, while the paper has some interesting ideas and contributions, its limitations and weaknesses outweigh its strengths, and it requires significant revisions before it can be considered for acceptance.