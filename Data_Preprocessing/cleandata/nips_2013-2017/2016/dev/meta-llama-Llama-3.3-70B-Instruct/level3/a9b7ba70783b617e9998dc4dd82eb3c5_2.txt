This paper proposes a novel approach to statistical inference for cluster trees, which are used to represent the hierarchy of high-density clusters in a density function. The authors introduce a bootstrap-based confidence set for the cluster tree associated with an unknown density function, using a metric defined on cluster trees to govern the shape of the confidence set. The paper provides methods for obtaining informative representatives in the confidence set that retain statistically significant features of the cluster tree.
The strengths of the paper include its ability to provide a statistically principled way to prune the cluster tree, removing statistically insignificant features while maintaining statistical guarantees. The authors also demonstrate the effectiveness of their approach on a variety of synthetic examples and a real-world dataset.
However, there are some weaknesses and areas for improvement. The relationship between nonparametric inference for density functions and constructing a confidence set for the cluster tree is not entirely clear, and it is unclear whether addressing the latter problem directly is justified. Additionally, the choice of metric $d_{\infty}$ for forming the confidence set seems arbitrary, and further justification for its use beyond the scope of the paper would be helpful.
The paper is well-written and clearly organized, making it easy to follow and understand. The authors provide a thorough review of related work and clearly explain the contributions of their paper. The experimental results are also well-presented and demonstrate the effectiveness of the proposed approach.
In terms of the criteria for evaluation, the paper scores well on clarity, originality, and significance. The paper is clearly written and well-organized, making it easy to understand and follow. The approach proposed in the paper is novel and addresses an important problem in statistical inference for cluster trees. The results are also significant, as they provide a statistically principled way to prune cluster trees and remove statistically insignificant features.
However, the paper could be improved in terms of quality. While the authors provide a thorough review of related work, there are some areas where the paper could be more rigorous and detailed. For example, the proof of Lemma 2 is omitted, and the authors could provide more detail on the computational complexity of the proposed approach.
Overall, I would recommend accepting this paper, as it provides a novel and significant contribution to the field of statistical inference for cluster trees. However, the authors should address the areas for improvement mentioned above to strengthen the paper.
Arguments pro acceptance:
* The paper proposes a novel approach to statistical inference for cluster trees
* The approach is statistically principled and provides a way to prune cluster trees and remove statistically insignificant features
* The paper is well-written and clearly organized
* The experimental results demonstrate the effectiveness of the proposed approach
Arguments con acceptance:
* The relationship between nonparametric inference for density functions and constructing a confidence set for the cluster tree is not entirely clear
* The choice of metric $d_{\infty}$ for forming the confidence set seems arbitrary
* The paper could be improved in terms of quality, with more detail and rigor in certain areas.