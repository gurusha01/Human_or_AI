This paper proposes a novel approach to monocular depth estimation by training a neural network to predict distributions of local coefficients of the scene depth map in an overcomplete representation. The network outputs parameterized distributions for each coefficient, allowing it to effectively characterize the ambiguity in its predictions. The authors then employ an efficient globalization procedure to find the single consistent depth map that best agrees with the set of local distributions.
The paper is well-written and clearly organized, making it easy to follow the authors' line of reasoning. The proposed approach is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The authors provide a thorough evaluation of their method on the NYU v2 depth dataset, demonstrating its effectiveness in estimating scene depth from a single image.
One of the strengths of the paper is its ability to handle the ambiguity in local coefficient predictions by using a distributional output space. This allows the network to express confidence about some coefficients and ambiguity about others, which is particularly useful in regions with limited depth cues. The authors also provide a detailed analysis of the contribution of different components of their overcomplete representation, which helps to understand the importance of each component in the final estimation accuracy.
However, one potential weakness of the paper is the complexity of the proposed approach, which may make it challenging to implement and optimize in practice. The authors use a cascade of seven convolution layers and a separate path that extracts a single feature vector from the entire image, which may require significant computational resources. Additionally, the globalization procedure involves an alternating minimization algorithm, which may require careful tuning of hyperparameters to achieve good performance.
In terms of originality, the paper proposes a novel approach to monocular depth estimation that differs from previous methods. The use of a distributional output space and an overcomplete representation of the scene depth map is a unique aspect of the proposed approach. The authors also provide a thorough review of related work, which helps to situate their contribution in the context of existing research.
The significance of the paper lies in its ability to provide accurate estimates of scene depth from a single image, which has numerous applications in computer vision, robotics, and graphics. The proposed approach has the potential to be used in a variety of settings, such as stereo reconstruction, active and passive depth sensing, and motion estimation. The authors also provide a pre-trained network model and source code, which makes it easier for others to build upon their work.
Overall, I would recommend accepting this paper for publication, as it presents a novel and effective approach to monocular depth estimation. The paper is well-written, technically sound, and provides a thorough evaluation of the proposed method. The authors also provide a detailed analysis of the contribution of different components of their overcomplete representation, which helps to understand the importance of each component in the final estimation accuracy.
Arguments pro acceptance:
* The paper proposes a novel approach to monocular depth estimation that differs from previous methods.
* The proposed approach is technically sound and provides accurate estimates of scene depth from a single image.
* The authors provide a thorough evaluation of their method on the NYU v2 depth dataset.
* The paper is well-written and clearly organized, making it easy to follow the authors' line of reasoning.
Arguments con acceptance:
* The complexity of the proposed approach may make it challenging to implement and optimize in practice.
* The globalization procedure involves an alternating minimization algorithm, which may require careful tuning of hyperparameters to achieve good performance.