This paper proposes a novel dual-learning mechanism for neural machine translation, which enables the system to learn from unlabeled data through a dual-learning game. The approach is based on the observation that any machine translation task has a dual task, and the primal and dual tasks can form a closed loop, generating informative feedback signals to train the translation models. The proposed method, called dual-NMT, uses two agents to represent the models for the primal and dual tasks, and asks them to teach each other through a reinforcement learning process.
The paper is well-written, easy to read, and provides a clear explanation of the proposed method. The authors also provide a comprehensive review of the related work and a detailed description of the experimental setup. The results show that dual-NMT outperforms the baseline algorithms in all settings, and achieves comparable translation accuracy as vanilla NMT using 100% bilingual data for the Frâ†’En task, even with only 10% bilingual data.
The strengths of the paper include:
* The proposed dual-learning mechanism is novel and interesting, and has the potential to significantly reduce the requirement on parallel bilingual data.
* The paper provides a clear and detailed explanation of the proposed method, and the experimental setup is well-designed.
* The results are impressive, and demonstrate the effectiveness of the proposed method.
The weaknesses of the paper include:
* The paper could benefit from a more detailed analysis of the results, and a discussion of the potential limitations of the proposed method.
* The authors could also provide more insights into the dual-learning mechanism, and how it can be applied to other tasks beyond machine translation.
Overall, the paper is a strong contribution to the field of neural machine translation, and has the potential to make a significant impact. The proposed dual-learning mechanism is novel and interesting, and the results demonstrate its effectiveness. With some minor revisions to address the weaknesses, the paper could be even stronger.
Arguments pro acceptance:
* The paper proposes a novel and interesting approach to neural machine translation.
* The results are impressive, and demonstrate the effectiveness of the proposed method.
* The paper is well-written, easy to read, and provides a clear explanation of the proposed method.
Arguments con acceptance:
* The paper could benefit from a more detailed analysis of the results.
* The authors could provide more insights into the dual-learning mechanism, and how it can be applied to other tasks beyond machine translation.
* The paper may not be suitable for readers who are not familiar with neural machine translation and reinforcement learning. 
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The paper is also well-organized, and provides enough information for the expert reader to reproduce the results. The originality of the paper is high, as the proposed dual-learning mechanism is novel and interesting. The significance of the paper is also high, as it has the potential to make a significant impact on the field of neural machine translation. 
In comparison to other papers, such as "Dynamic Memory Networks for Visual and Textual Question Answering" published in ICML 2016, the proposed method in this paper is more focused on the task of neural machine translation, and provides a more detailed analysis of the results. However, the paper could benefit from a more detailed comparison with other related work, and a discussion of the potential limitations of the proposed method. 
Overall, I would recommend accepting the paper, as it is a strong contribution to the field of neural machine translation, and has the potential to make a significant impact. With some minor revisions to address the weaknesses, the paper could be even stronger.