This paper presents a method for statistical inference on cluster trees, which are used to visualize and summarize the hierarchical structure of high-density clusters in a dataset. The authors propose a confidence set for the unknown true cluster tree and develop methods for visualizing the trees contained in this confidence set. The paper makes several contributions, including the introduction of a partial ordering on cluster trees, the development of a pruning scheme to simplify the empirical tree, and the application of the method to synthetic and real datasets.
The paper is well-written and clearly organized, with a good balance between technical details and intuitive explanations. The authors provide a thorough review of related work and clearly explain the advantages and limitations of their approach. The experimental results are impressive, demonstrating the effectiveness of the method in identifying significant features in the data.
However, there are some areas where the paper could be improved. One limitation of the method is that it relies on a fixed bandwidth for the kernel density estimator, which may not be optimal for all datasets. The authors acknowledge this limitation and suggest that a more targeted bandwidth selection method could be developed in future work. Additionally, the paper could benefit from a more detailed comparison with other methods for statistical inference on cluster trees, such as those based on phylogenetic trees.
In terms of the conference guidelines, the paper meets the criteria for quality, clarity, originality, and significance. The paper is technically sound, with a clear and well-organized presentation of the methodology and results. The authors provide a thorough review of related work and clearly explain the advantages and limitations of their approach. The paper presents a novel combination of familiar techniques, including the use of kernel density estimation and bootstrap sampling. The results are significant, demonstrating the effectiveness of the method in identifying significant features in the data.
Arguments pro acceptance:
* The paper presents a novel and effective method for statistical inference on cluster trees.
* The method is well-motivated and clearly explained, with a good balance between technical details and intuitive explanations.
* The experimental results are impressive, demonstrating the effectiveness of the method in identifying significant features in the data.
* The paper meets the criteria for quality, clarity, originality, and significance.
Arguments con acceptance:
* The method relies on a fixed bandwidth for the kernel density estimator, which may not be optimal for all datasets.
* The paper could benefit from a more detailed comparison with other methods for statistical inference on cluster trees.
* The method may not be applicable to very large datasets, due to the computational complexity of the bootstrap sampling procedure.
Overall, I recommend accepting the paper, as it presents a novel and effective method for statistical inference on cluster trees, with impressive experimental results and a clear and well-organized presentation. However, the authors should be encouraged to address the limitations of the method and provide a more detailed comparison with other approaches in future work.