This paper proposes a novel approach to multimodal learning, called Multimodal Residual Networks (MRN), which extends the idea of deep residual learning to visual question-answering tasks. The authors argue that their model effectively learns the joint representation of vision and language information, outperforming state-of-the-art methods on the Visual QA dataset. 
The paper is well-structured and clearly written, making it easy to follow the authors' line of reasoning. The introduction provides a good background on the importance of visual question-answering tasks and the limitations of existing methods. The related work section provides a thorough overview of deep residual learning and attentional models, which is helpful in understanding the context of the proposed approach.
The technical contributions of the paper are significant, and the authors provide a detailed explanation of their model, including the architecture, the joint residual function, and the visualization method. The experimental results are impressive, with the proposed model achieving state-of-the-art results on both Open-Ended and Multiple-Choice tasks.
However, there are some areas that need improvement. The paper lacks motivation in using tensor networks for defining the feature map, which is not clearly explained. The use of tensor networks leads to difficulties in the optimization process, and the authors should explore the kernel trick to alleviate computational complexity. Additionally, the proposed classification model has issues with label indexing and placement, making it unsuitable for multiclass classification.
The experiments have several issues, including missing details such as data size and number of classes, and lack of comparison with state-of-the-art classification methods. The authors used quadratic loss for its ease of computation, but should also compare with other loss functions used in the experiments.
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The paper is a complete piece of work, and the authors are careful about evaluating both the strengths and weaknesses of the work.
The clarity of the paper is good, and the organization is well-structured. The paper adequately informs the reader, and the writing is clear and concise. The originality of the paper is high, and the approach is novel and significant. The paper provides a unique combination of familiar techniques, and the related work is adequately referenced.
The significance of the paper is high, and the results are important. The paper addresses a difficult problem in a better way than previous research, and it advances the state of the art in a demonstrable way. The paper provides unique data, unique conclusions on existing data, or a unique theoretical or pragmatic approach.
Overall, I would recommend accepting this paper, but with some revisions to address the issues mentioned above. The paper has the potential to make a significant contribution to the field of multimodal learning, and with some improvements, it can be even stronger.
Arguments pro acceptance:
- The paper proposes a novel approach to multimodal learning, which is significant and original.
- The experimental results are impressive, with the proposed model achieving state-of-the-art results on both Open-Ended and Multiple-Choice tasks.
- The paper is well-structured and clearly written, making it easy to follow the authors' line of reasoning.
Arguments con acceptance:
- The paper lacks motivation in using tensor networks for defining the feature map.
- The use of tensor networks leads to difficulties in the optimization process.
- The proposed classification model has issues with label indexing and placement, making it unsuitable for multiclass classification.
- The experiments have several issues, including missing details and lack of comparison with state-of-the-art classification methods.