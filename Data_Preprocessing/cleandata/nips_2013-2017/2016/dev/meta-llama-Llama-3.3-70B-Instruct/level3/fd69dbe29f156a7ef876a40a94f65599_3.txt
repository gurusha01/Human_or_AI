This paper proposes a novel neural model for visual question answering (VQA) that iteratively updates the question representation by selecting relevant image regions and transforms both image and question features into a shared latent space. The model uses a VGG model to encode input images, extracts features from candidate regions, and employs a GRU to embed word vectors and represent the question. The final answer is generated through a softmax layer.
The paper is well-written and clearly explains the proposed model, its components, and the experimental results. The authors provide a thorough analysis of the results, including ablation studies and comparisons with state-of-the-art models. The model is evaluated on two challenging VQA datasets, COCO-QA and VQA, and shows improved performance compared to existing models.
The strengths of the paper include the novel approach to VQA, the use of attention mechanisms to focus on relevant image regions, and the thorough experimental evaluation. The model's ability to update the question representation and infer over a set of image regions is a significant contribution to the field.
However, there are some weaknesses and areas for improvement. The paper could benefit from a more detailed description of the baseline models and a comparison of different question representation pooling mechanisms. Additionally, the authors could provide more explanations for using a single layer in the MLP and a thorough analysis of the results.
The significance of the study lies in its ability to modify an existing text question answering model to address the VQA problem, opening a new area of research for QA/VQA. The paper demonstrates the effectiveness of applying a text QA model to the VQA task and provides a new perspective on the problem.
Arguments for acceptance:
* The paper proposes a novel and effective approach to VQA.
* The model shows improved performance compared to state-of-the-art models on two challenging datasets.
* The paper provides a thorough analysis of the results and ablation studies.
* The study is significant and opens a new area of research for QA/VQA.
Arguments against acceptance:
* The paper could benefit from a more detailed description of the baseline models.
* The authors could provide more explanations for using a single layer in the MLP.
* The paper could be improved by including a more thorough analysis of the results.
Overall, I recommend accepting the paper as it presents a novel and effective approach to VQA, provides a thorough analysis of the results, and demonstrates the significance of the study. However, the authors should address the weaknesses and areas for improvement mentioned above to further strengthen the paper.