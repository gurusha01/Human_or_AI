This paper proposes a new approach to stochastic gradient descent (SGD) and its variant, stochastic variance reduced gradient (SVRG), by incorporating the Barzilai-Borwein (BB) method to automatically compute step sizes. The authors provide a thorough analysis of the proposed methods, including a linear convergence result for SVRG-BB, and demonstrate their effectiveness through numerical experiments.
The paper is well-written and easy to follow, with clear explanations of the proposed methods and their theoretical justifications. The authors also provide a nice comparison with existing methods, including SGD and SVRG with fixed step sizes, and demonstrate the superiority of their approach.
One of the main strengths of the paper is the proposal of a theoretically-justified adaptive step-size strategy, which is a significant advantage over existing methods. The authors also provide a nice way to bound the step-size for the BB method, which is an important contribution.
However, there are some weaknesses in the paper. The quadratic dependence on problem constants is inferior to existing results, which may limit the applicability of the proposed methods. Additionally, the paper lacks an empirical comparison with existing heuristics for tuning the step-size, such as SAG line-search and MISO line-search, which would be useful to further demonstrate the effectiveness of the proposed approach.
The paper has improved significantly with the removal of misleading statements and the addition of extra references and discussion. The authors have also addressed a severe restriction on the condition number, which is an important contribution.
Overall, the paper is a significant contribution to the field of stochastic optimization, and the proposed methods have the potential to be widely used in practice. The authors have demonstrated the effectiveness of their approach through numerical experiments, and the theoretical justifications provided are sound.
Arguments pro acceptance:
* The paper proposes a new and theoretically-justified adaptive step-size strategy, which is a significant advantage over existing methods.
* The authors provide a thorough analysis of the proposed methods, including a linear convergence result for SVRG-BB.
* The numerical experiments demonstrate the effectiveness of the proposed methods and their superiority over existing methods.
Arguments con acceptance:
* The quadratic dependence on problem constants is inferior to existing results, which may limit the applicability of the proposed methods.
* The paper lacks an empirical comparison with existing heuristics for tuning the step-size, such as SAG line-search and MISO line-search.
* The paper still has some grammar issues, which need to be addressed before publication.
Overall, I would recommend accepting the paper, as the strengths outweigh the weaknesses, and the proposed methods have the potential to be widely used in practice. However, the authors should address the grammar issues and consider adding an empirical comparison with existing heuristics for tuning the step-size to further demonstrate the effectiveness of their approach.