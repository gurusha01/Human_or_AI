This paper proposes a neural network-based reasoning model for visual question answering (VQA) that updates the question representation iteratively by inferring image information. The model uses object proposals to obtain candidate image regions and employs an attention mechanism to determine the relevance between the question and each image region. The results show that the model achieves state-of-the-art performance on the COCO-QA dataset and comparable results on the VQA dataset.
The paper is well-written and easy to follow, with clear explanations of the model architecture and experimental results. The use of object proposals and attention mechanisms is a novel approach to VQA, and the results demonstrate the effectiveness of this approach. The model's ability to focus on image regions highly related to the question is also visually demonstrated through attention masks.
However, I have some concerns about the paper. Firstly, the model's performance on ambiguous questions is not fully convincing. The example questions and figures provided, such as Figure 3, are not intuitive and raise questions about the model's performance on such questions. Secondly, the paper lacks a discussion on the pros and cons of the proposed model compared to other state-of-the-art methods, particularly on the VQA experiments. This makes it difficult to understand the strengths and weaknesses of the model.
In terms of quality, the paper is technically sound, and the claims are well-supported by experimental results. The model is a complete piece of work, and the authors are careful about evaluating both the strengths and weaknesses of the work. However, the paper could benefit from a more detailed analysis of the results and a discussion on the limitations of the model.
The originality of the paper is high, as it proposes a novel approach to VQA using object proposals and attention mechanisms. The paper is well-organized, and the writing is clear and concise. The significance of the paper is also high, as it achieves state-of-the-art performance on a challenging dataset and demonstrates the effectiveness of the proposed approach.
Overall, I would recommend accepting this paper, but with some revisions to address the concerns mentioned above. The authors should provide more analysis and discussion on the results, particularly on ambiguous questions, and compare the proposed model with other state-of-the-art methods.
Arguments for acceptance:
* The paper proposes a novel approach to VQA using object proposals and attention mechanisms.
* The model achieves state-of-the-art performance on the COCO-QA dataset and comparable results on the VQA dataset.
* The paper is well-written and easy to follow, with clear explanations of the model architecture and experimental results.
Arguments against acceptance:
* The model's performance on ambiguous questions is not fully convincing.
* The paper lacks a discussion on the pros and cons of the proposed model compared to other state-of-the-art methods.
* The paper could benefit from a more detailed analysis of the results and a discussion on the limitations of the model.