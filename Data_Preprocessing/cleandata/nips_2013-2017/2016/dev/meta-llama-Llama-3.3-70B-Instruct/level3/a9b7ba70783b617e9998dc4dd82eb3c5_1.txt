This paper proposes a method for statistical inference on cluster trees, which are used to represent the hierarchy of high-density clusters in a density function. The authors introduce a partial ordering on cluster trees and use it to prune statistically insignificant features from the empirical cluster tree, resulting in a more interpretable and parsimonious representation of the data.
The paper is well-written and clearly explains the concepts and methods used. The authors provide a thorough review of related work and demonstrate the effectiveness of their approach on several synthetic examples and a real dataset. The use of a partial ordering to prune the cluster tree is a novel and useful contribution to the field.
However, there are some concerns with the paper. The main result, Theorem 3, lacks a dependency on the parameter B, which is used to define the confidence set. This makes it difficult to understand the significance of the result and how it relates to the rest of the paper. Additionally, the authors claim that their method overcomes the curse of dimensionality, but this is not entirely clear. The choice of bandwidth h is arbitrary, and it is not clear how this affects the results.
Furthermore, the authors introduce the metric dMM, but then proceed to argue that it is not suitable for statistical inference. It is not clear why this metric is introduced in the first place, and it would be better to remove all mentions of it from the paper.
In terms of quality, the paper is technically sound, but there are some areas where the claims are not well-supported by theoretical analysis or experimental results. The paper is well-organized and clearly written, but there are some areas where the notation and terminology could be improved.
In terms of originality, the paper proposes a novel approach to statistical inference on cluster trees, and the use of a partial ordering to prune the cluster tree is a new contribution to the field. However, the paper builds on existing work in the area, and it is not entirely clear how the approach differs from previous contributions.
In terms of significance, the paper addresses an important problem in the field of clustering, and the results have the potential to be useful in practice. However, the paper could be improved by providing more context and motivation for the problem, and by discussing the potential applications and implications of the results more clearly.
Overall, I would recommend accepting this paper, but with some revisions to address the concerns mentioned above. The paper has the potential to make a significant contribution to the field, but it needs to be improved in terms of clarity, technical soundness, and significance.
Arguments for acceptance:
* The paper proposes a novel approach to statistical inference on cluster trees
* The use of a partial ordering to prune the cluster tree is a new contribution to the field
* The paper is well-written and clearly explains the concepts and methods used
* The results have the potential to be useful in practice
Arguments against acceptance:
* The main result, Theorem 3, lacks a dependency on the parameter B
* The choice of bandwidth h is arbitrary, and it is not clear how this affects the results
* The paper introduces the metric dMM, but then proceeds to argue that it is not suitable for statistical inference
* The paper could be improved by providing more context and motivation for the problem, and by discussing the potential applications and implications of the results more clearly.