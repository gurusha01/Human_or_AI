This paper proposes an automatic step size scheme using the Barzilai-Borwein (BB) method for Stochastic Gradient Descent (SGD) and Stochastic Variance Reduced Gradient (SVRG) methods. The authors provide a linear convergence analysis for SVRG-BB and SVRG-I, which is a significant contribution. However, the paper lacks a convergence analysis for SGD-BB, which is a major shortcoming. The authors compare SVRG-BB and SGD-BB to existing methods and find that the BB step sizes have a comparable rate of convergence to the best-tuned step size for both SVRG and SGD.
The paper is well-organized, and the authors provide a clear introduction to the BB method and its application to SVRG and SGD. The numerical experiments demonstrate the efficacy of the proposed methods, but they are limited to binary classification models and do not compare SGD-BB to other automatic step size methods.
The convergence analysis for SVRG-BB is simple but interesting, although the application of a BB step size on SVRG is not a significant contribution due to SVRG's true gradient calculations. The paper requires more work, including a convergence rate proof for SGD-BB and more extensive experiments to fully demonstrate its effectiveness.
Some minor comments include typos, potential improvements to bounds, and questions about the sensitivity of SGD-BB to certain parameters and the initial slowdown in SVRG-BB. Overall, the paper has some strengths, including the proposal of a new step size scheme and the provision of linear convergence analysis for SVRG-BB and SVRG-I. However, the lack of convergence analysis for SGD-BB and limited numerical experiments are significant weaknesses.
Arguments for acceptance:
* The paper proposes a new step size scheme using the BB method for SGD and SVRG.
* The authors provide a linear convergence analysis for SVRG-BB and SVRG-I.
* The numerical experiments demonstrate the efficacy of the proposed methods.
Arguments against acceptance:
* The paper lacks a convergence analysis for SGD-BB.
* The numerical experiments are limited to binary classification models and do not compare SGD-BB to other automatic step size methods.
* The application of a BB step size on SVRG is not a significant contribution due to SVRG's true gradient calculations.
Overall, I would recommend that the authors address the weaknesses of the paper, including providing a convergence analysis for SGD-BB and conducting more extensive numerical experiments, before considering it for acceptance.