This paper explores the problem of learning decision thresholds in the drift-diffusion model of perceptual decision making. The authors introduce a reward function that averages over many trials to Wald's cost function, which defines decision optimality. They propose two distinct methods to learn the decision thresholds: a REINFORCE method derived from Williams' REINFORCE algorithm for training neural networks, and a Bayesian optimization method that fits a Gaussian process to the reward function.
The paper is well-written and clearly explains the background and methods used. The authors provide a thorough discussion of the results, including comparisons with experimental data from animal learning studies. The paper makes a significant contribution to the field by providing a novel approach to learning decision thresholds and demonstrating the effectiveness of the proposed methods.
The strengths of the paper include:
* The introduction of a new reward function that averages over many trials to Wald's cost function, which provides a clear and well-defined objective for learning decision thresholds.
* The proposal of two distinct methods for learning decision thresholds, which provides a comprehensive approach to addressing the problem.
* The thorough evaluation of the methods, including comparisons with experimental data from animal learning studies.
* The clear and concise writing style, which makes the paper easy to follow and understand.
The weaknesses of the paper include:
* The computational cost of the Bayesian optimization method, which may limit its applicability in practice.
* The variability of the threshold estimates in the Bayesian optimization method, which may affect the accuracy of the results.
* The lack of a clear comparison between the REINFORCE method and other existing methods for learning decision thresholds.
Overall, the paper is a significant contribution to the field and provides a novel approach to learning decision thresholds. The strengths of the paper outweigh the weaknesses, and the authors provide a clear and concise presentation of the results.
Arguments for acceptance:
* The paper introduces a new and well-defined objective for learning decision thresholds.
* The proposed methods are thoroughly evaluated and compared with experimental data from animal learning studies.
* The paper makes a significant contribution to the field and provides a novel approach to learning decision thresholds.
Arguments against acceptance:
* The computational cost of the Bayesian optimization method may limit its applicability in practice.
* The variability of the threshold estimates in the Bayesian optimization method may affect the accuracy of the results.
* The lack of a clear comparison between the REINFORCE method and other existing methods for learning decision thresholds may limit the impact of the paper.
Quality: 8/10
Clarity: 9/10
Originality: 8/10
Significance: 8/10
Overall, I would recommend accepting the paper with minor revisions to address the weaknesses mentioned above.