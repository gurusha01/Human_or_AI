This paper proposes a novel approach to visual question-answering tasks by extending the concept of deep residual learning to multimodal inputs. The authors introduce Multimodal Residual Networks (MRN), which effectively learn joint representations from vision and language information using element-wise multiplication and residual mappings. The paper is well-organized and clearly written, making a significant contribution to the field of machine learning.
The strengths of the paper include its ability to achieve state-of-the-art results on the Visual QA dataset for both Open-Ended and Multiple-Choice tasks. The authors also propose a novel method to visualize the attention effect of joint residual mappings, which provides a unique insight into the model's decision-making process. The use of element-wise multiplication as an implicit attention mechanism is an innovative approach that differs from traditional attentional models.
However, there are some weaknesses to the paper. The experiment section is limited, with only the Visual QA dataset being used for evaluation. The authors do not provide a comparison with other state-of-the-art learning algorithms and feature selection methods, which makes it difficult to assess the true effectiveness of MRN. Additionally, the paper could benefit from a more detailed analysis of the results, including an exploration of the model's performance on different types of questions and images.
Arguments for acceptance:
* The paper proposes a novel and innovative approach to visual question-answering tasks
* The authors achieve state-of-the-art results on the Visual QA dataset
* The paper provides a unique insight into the model's decision-making process through the visualization of attention effects
Arguments against acceptance:
* The experiment section is limited and lacks comparison with other state-of-the-art methods
* The paper could benefit from a more detailed analysis of the results
* The model's performance on different types of questions and images is not thoroughly explored
Overall, the paper makes a significant contribution to the field of machine learning and has the potential to be a valuable addition to the conference program. However, the authors should address the limitations of the experiment section and provide a more detailed analysis of the results to strengthen the paper. 
Quality: 8/10
The paper is technically sound, and the claims are well-supported by experimental results. However, the experiment section is limited, and the authors could provide more detailed analysis and comparison with other state-of-the-art methods.
Clarity: 9/10
The paper is well-organized and clearly written, making it easy to follow and understand. The authors provide a clear explanation of the proposed approach and the experimental results.
Originality: 9/10
The paper proposes a novel approach to visual question-answering tasks, and the use of element-wise multiplication as an implicit attention mechanism is an innovative idea.
Significance: 8.5/10
The paper makes a significant contribution to the field of machine learning, and the proposed approach has the potential to be a valuable addition to the conference program. However, the authors should address the limitations of the experiment section to strengthen the paper.