This paper proposes a framework for learning decision thresholds in the drift-diffusion model of perceptual decision making. The authors introduce two methods for optimizing the decision thresholds: a REINFORCE method derived from Williams' REINFORCE algorithm for training neural networks, and a Bayesian optimization method that fits a Gaussian process to the reward function. Both methods converge to near-optimal decision thresholds, but the REINFORCE method is more computationally efficient and produces more accurate estimates.
The paper is well-motivated, and the problem of learning decision thresholds is clearly explained. The authors provide a thorough background on the drift-diffusion model and the sequential probability ratio test, which is helpful for understanding the context of the problem. The proposed methods are well-described, and the results are clearly presented.
However, the paper is dense and difficult to read, which may make it challenging for non-experts to follow. The authors could improve the clarity of the paper by providing more intuitive explanations of the methods and results, and by adding more visual aids to help illustrate the key concepts.
The originality of the paper is high, as it proposes two new methods for learning decision thresholds in the drift-diffusion model. The authors demonstrate the effectiveness of these methods through simulations and comparisons with experimental data. The significance of the paper is also high, as it addresses a important problem in perceptual decision making and provides new insights into the mechanisms of reward-driven learning.
The quality of the paper is good, with well-supported claims and a clear presentation of the results. The authors are careful to evaluate the strengths and weaknesses of their methods, and they provide a thorough discussion of the implications of their findings.
Some potential weaknesses of the paper include the complexity of the methods, which may make it challenging for readers to implement them in practice. Additionally, the authors could provide more detailed comparisons with existing methods for learning decision thresholds, to help readers understand the advantages and disadvantages of their approach.
Overall, I would recommend accepting this paper, as it makes a significant contribution to the field of perceptual decision making and provides new insights into the mechanisms of reward-driven learning. However, I would suggest that the authors revise the paper to improve its clarity and readability, and to provide more detailed comparisons with existing methods.
Arguments pro acceptance:
* The paper proposes two new methods for learning decision thresholds in the drift-diffusion model, which is a significant contribution to the field.
* The authors demonstrate the effectiveness of these methods through simulations and comparisons with experimental data.
* The paper provides new insights into the mechanisms of reward-driven learning, which is an important problem in perceptual decision making.
Arguments con acceptance:
* The paper is dense and difficult to read, which may make it challenging for non-experts to follow.
* The methods proposed in the paper may be complex and challenging to implement in practice.
* The authors could provide more detailed comparisons with existing methods for learning decision thresholds, to help readers understand the advantages and disadvantages of their approach.