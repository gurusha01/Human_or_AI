This paper proposes a novel approach to learning decision thresholds in the drift-diffusion model of perceptual decision making. The authors introduce two distinct methods, REINFORCE and Bayesian optimization, to optimize the decision thresholds based on single-trial rewards derived from Wald's trial-averaged cost function. The paper presents promising experimental results, demonstrating that both methods can converge to near-optimal decision thresholds.
The strengths of the paper include its novel approach to learning decision thresholds, its ability to handle highly stochastic rewards, and its comparison to experimental data from animal learning studies. The REINFORCE method, in particular, shows a good fit to the acquisition curve of animal learning, suggesting that it may be a plausible model of reward-driven learning during perceptual decision making.
However, there are also several weaknesses and concerns. The paper lacks a formal definition of diffusion, a core concept in the paper, and omits a citation to previous work on the topic. The authors' emphasis on generalizing convolutions may not be applicable to edge or vertex prediction settings, and the absence of edge experiments is notable, despite the claim of a unified architecture for vertex, edge, and graph prediction.
Furthermore, the comparison to baseline models, such as logistic regression and CRF, is criticized for not using comparable features, and the review suggests training a shallow model on the same signal. The paper also lacks a comparison to other neural-network-based models, such as node2vec, and omits citations to relevant previous work.
In terms of the conference guidelines, the paper's quality is lower than other related work, such as LINE, DeepWalk, and node2vec, leading to a strong argument for rejection. The paper's lack of clarity, organization, and attention to detail also raises concerns. While the paper presents some promising results, its overall quality and contribution to the field are not sufficient to warrant acceptance.
Arguments for rejection include:
* Lack of formal definition of diffusion
* Omission of citation to previous work
* Limited applicability of generalizing convolutions
* Absence of edge experiments
* Inadequate comparison to baseline models
* Lack of comparison to other neural-network-based models
* Lower quality compared to other related work
Overall, while the paper presents some interesting ideas and results, its weaknesses and limitations outweigh its strengths, leading to a recommendation for rejection.