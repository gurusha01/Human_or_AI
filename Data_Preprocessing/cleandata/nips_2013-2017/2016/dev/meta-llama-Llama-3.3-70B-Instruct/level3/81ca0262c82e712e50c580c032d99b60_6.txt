This paper proposes a novel approach to visual question answering (VQA) by iteratively updating the question representation through interactions with image regions. The model, called QRU, consists of four main components: image understanding, question encoding, reasoning, and answering layers. The authors introduce a sub-modularity index to measure the closeness of a function to being sub-modular, which is a natural and novel contribution. The paper explores causal subset selection using directed information and formulates two tasks to study sub-modularity properties.
The strengths of this paper include its ability to learn the causal structure of the data, which is a relevant and interesting use case. The authors also provide a clear and well-organized presentation of their model, making it easy to follow and understand. The experimental results demonstrate the effectiveness of the proposed model, achieving state-of-the-art performance on two challenging VQA datasets, COCO-QA and VQA.
One of the weaknesses of this paper is that it does not provide a thorough analysis of the sub-modularity index and its relationship to the VQA task. Additionally, the authors could have provided more insights into the reasoning layer and how it contributes to the overall performance of the model. Furthermore, the paper could benefit from a more detailed comparison with other state-of-the-art models, highlighting the advantages and disadvantages of the proposed approach.
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The authors are careful and honest about evaluating both the strengths and weaknesses of their work. The paper is clearly written, well-organized, and provides enough information for an expert reader to reproduce the results.
The originality of this paper lies in its novel approach to VQA, which combines the strengths of neural reasoners and attention mechanisms. The authors provide a unique perspective on the VQA task, highlighting the importance of updating the question representation through interactions with image regions. The paper is significantly different from previous contributions, and the authors adequately reference related work.
The significance of this paper lies in its potential to advance the state of the art in VQA. The proposed model provides a new and effective way to approach the VQA task, and the experimental results demonstrate its effectiveness. The paper also provides insights into the importance of updating the question representation and inferring over image regions, which could be useful for other researchers working on VQA and related tasks.
Arguments pro acceptance:
* The paper proposes a novel and effective approach to VQA.
* The experimental results demonstrate the effectiveness of the proposed model.
* The paper provides a clear and well-organized presentation of the model.
* The authors provide insights into the importance of updating the question representation and inferring over image regions.
Arguments con acceptance:
* The paper could benefit from a more thorough analysis of the sub-modularity index and its relationship to the VQA task.
* The authors could have provided more insights into the reasoning layer and its contribution to the overall performance of the model.
* The paper could benefit from a more detailed comparison with other state-of-the-art models.