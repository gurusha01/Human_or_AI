This paper proposes a novel approach to automatically compute step sizes for stochastic gradient descent (SGD) and its variant, stochastic variance reduced gradient (SVRG), using the Barzilai-Borwein (BB) method. The resulting algorithms, SGD-BB and SVRG-BB, are shown to have comparable or even better performance than SGD and SVRG with best-tuned step sizes.
The paper is well-written and provides a clear overview of the proposed methods, including their motivations, algorithms, and theoretical analysis. The authors also provide extensive numerical experiments to demonstrate the efficacy of their methods.
The strengths of the paper include:
* The proposal of a novel approach to automatically compute step sizes for SGD and SVRG, which can be useful in practice where tuning step sizes can be time-consuming.
* The provision of theoretical analysis, including the proof of linear convergence of SVRG-BB for strongly convex objective functions.
* The extensive numerical experiments, which demonstrate the competitiveness of the proposed methods with existing state-of-the-art methods.
The weaknesses of the paper include:
* The paper assumes that the objective function is strongly convex, which may not always be the case in practice.
* The paper does not provide a thorough comparison with other existing methods for automatically computing step sizes, such as AdaGrad and line search techniques.
* The paper could benefit from more discussion on the choice of hyperparameters, such as the update frequency m and the weighting parameter Î² in SGD-BB.
Arguments pro acceptance:
* The paper proposes a novel and useful approach to automatically compute step sizes for SGD and SVRG.
* The paper provides a clear and well-written presentation of the proposed methods and their theoretical analysis.
* The numerical experiments demonstrate the competitiveness of the proposed methods with existing state-of-the-art methods.
Arguments con acceptance:
* The paper assumes strong convexity of the objective function, which may not always be the case in practice.
* The paper could benefit from more comparison with other existing methods for automatically computing step sizes.
* The paper could benefit from more discussion on the choice of hyperparameters.
Overall, I believe that the paper is well-written and provides a useful contribution to the field of stochastic optimization. With some revisions to address the weaknesses mentioned above, I would recommend accepting the paper.