This paper addresses the problem of statistical inference for cluster trees, which are used to represent the hierarchy of high-density clusters in a density function. The authors propose methods to construct and summarize confidence sets for the unknown true cluster tree, and introduce a partial ordering on cluster trees to prune statistically insignificant features. The paper makes several contributions, including the study of various metrics on trees, the construction of confidence sets using the bootstrap, and the application of these methods to synthetic and real datasets.
The paper is well-written and clearly organized, with a good balance between technical details and intuitive explanations. The authors provide a thorough review of related work and clearly motivate the need for statistical inference in clustering. The proposed methods are rigorously developed and evaluated, and the experiments demonstrate the effectiveness of the approach.
The strengths of the paper include:
* The authors tackle an important problem in clustering, which is the lack of methods for statistical inference.
* The proposed methods are rigorously developed and evaluated, and the experiments demonstrate the effectiveness of the approach.
* The paper provides a thorough review of related work and clearly motivates the need for statistical inference in clustering.
The weaknesses of the paper include:
* The paper assumes that the density function is estimated using a kernel density estimator, which may not be the best choice for all datasets.
* The authors do not provide a clear guideline for choosing the bandwidth, which is an important parameter in the kernel density estimator.
* The paper does not address the issue of computational complexity, which may be a concern for large datasets.
Arguments pro acceptance:
* The paper tackles an important problem in clustering and provides a rigorous and effective solution.
* The proposed methods are well-motivated and clearly explained, and the experiments demonstrate the effectiveness of the approach.
* The paper provides a thorough review of related work and clearly motivates the need for statistical inference in clustering.
Arguments con acceptance:
* The paper assumes that the density function is estimated using a kernel density estimator, which may not be the best choice for all datasets.
* The authors do not provide a clear guideline for choosing the bandwidth, which is an important parameter in the kernel density estimator.
* The paper does not address the issue of computational complexity, which may be a concern for large datasets.
Overall, I believe that the paper makes a significant contribution to the field of clustering and statistical inference, and I recommend acceptance. However, I suggest that the authors address the weaknesses mentioned above, such as providing a clear guideline for choosing the bandwidth and addressing the issue of computational complexity. 
Quality: 8/10
The paper is technically sound, and the proposed methods are rigorously developed and evaluated. However, the authors could provide more details on the choice of bandwidth and computational complexity.
Clarity: 9/10
The paper is well-written and clearly organized, with a good balance between technical details and intuitive explanations.
Originality: 8/10
The paper proposes new methods for statistical inference in clustering, but the idea of using confidence sets and bootstrap is not new.
Significance: 9/10
The paper tackles an important problem in clustering and provides a rigorous and effective solution, which has the potential to impact the field of clustering and statistical inference.