This manuscript introduces a novel architectural paradigm, referred to as Matryoshka Networks (MatNets), which integrates the strengths of DRAW-like models and Ladder Networks to facilitate the learning of hierarchically deep generative models that jointly optimize inference and generation. The authors demonstrate the quantitative efficacy of MatNets through experiments on the MNIST, Omniglot, and CIFAR10 datasets. The proposed framework presents an intriguing approach to learning deep generative models, with notable results in image imputation tasks. Nevertheless, the inclusion of classification results, encompassing supervised, semi-supervised, and unsupervised settings on benchmark datasets such as MNIST and CIFAR10, would substantially enhance the convincingness of the paper. The manuscript is well-structured and clearly written, with lucid explanations, derivations, and claims that are readily comprehensible.