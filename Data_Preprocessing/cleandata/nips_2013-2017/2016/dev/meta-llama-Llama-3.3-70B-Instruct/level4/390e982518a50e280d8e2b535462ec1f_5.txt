This paper introduces a novel neural network architecture for classification tasks on generic graphs, building upon the concept of Convolutional Neural Networks (CNNs). The proposed model incorporates graph diffusion through a multi-hop architecture, effectively leveraging both node attributes and graph structure during training. While the model demonstrates superior performance to several simple baselines on average, its scalability appears to be a concern. The idea of integrating graph diffusion into neural networks is both intriguing and innovative, and the authors have done a commendable job of motivating the problem. However, there are several aspects of the work that could be improved upon. 
In terms of scalability, two concerns arise: firstly, the authors propose three separate models for node, graph, and edge classification, yet fail to report empirical performance for edge classification, potentially due to scalability issues stemming from the large parameter size for medium-scale graphs, as indicated by equation (6). Secondly, including the runtime of the current experiments would provide valuable insight. 
Regarding the experimental settings, two issues are noted: firstly, the comparison between the proposed model and baselines seems unfair, as the baselines (l1-logistic, l2-logistic, KED, KLED) primarily rely on graph structures, whereas the proposed model utilizes both node features and graph structures, making it unclear whether the performance gain is attributed to the model design or the additional information. To address this, the performance of a purely structural version of the proposed model (as described in equations 101-104) should be reported for a more meaningful comparison. 
Furthermore, section 5 mentions recent neural architectures for graph-based learning that extend CNN to irregular graph domains, yet none of these models are included as baselines for empirical comparison. Without strong baselines, it is challenging to determine whether the proposed model achieves state-of-the-art performance. 
Lastly, the relationship between the proposed model and CNN is unclear, as it is not evident how the proposed model can be viewed as an extension of CNN, given that it does not explicitly generalize the convolution operator over a 2D grid, unlike existing works (Bruna et al., 2013; Henaff et al., 2015). It is not obvious how the proposed model would subsume CNN as a special case, which raises questions about the claim that the proposed model is an extension of CNN. 
References:
Bruna, J., et al. (2013). Spectral networks and locally connected networks on graphs. arXiv preprint arXiv:1312.6203.
Henaff, M., Bruna, J., & LeCun, Y. (2015). Deep convolutional networks on graph-structured data. arXiv preprint arXiv:1506.05163.