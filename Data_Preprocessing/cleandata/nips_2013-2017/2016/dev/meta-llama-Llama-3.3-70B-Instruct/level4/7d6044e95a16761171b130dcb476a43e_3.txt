This manuscript introduces a unified framework for modeling and inference, leveraging the strengths of probabilistic graphical models (PGMs) and the flexibility of neural networks. By integrating variational autoencoder concepts with graphical models, the authors propose the structured variational autoencoder (SVAE) approach, which represents structured probability distributions and learns nonlinear data manifolds. A key challenge in hybrid models is the difficulty of inference, which the authors address by learning recognition networks that output conjugate graphical model potentials, enabling the use of tractable graphical model inference algorithms. The paper outlines an algorithm for inference in the SVAE model and demonstrates its application to both synthetic and real-world datasets. The SVAE model is evaluated on a synthetic dataset, where it accurately predicts the trajectory of a bouncing dot, and on real-world depth video recordings of mouse behavior, where it effectively predicts future frames. Furthermore, the authors apply a latent switching linear dynamical system (SLDS) SVAE model to learn discrete states corresponding to natural behavioral units. The combination of PGMs and deep learning is a rapidly evolving and promising research area, and this paper contributes to the existing literature by presenting a model that can account for discrete latent variables, offering potential applications in behavior representation modeling. The paper is well-organized, and the writing is clear, although the technical aspects are dense. Algorithm 1 in Section 4 is challenging to follow due to undefined symbols. A strength of the paper is its general approach, but this may make it difficult to apply the algorithm to new models. The authors could benefit from including a detailed description of the algorithm applied to the examples in Figure 3 in the appendix. A major criticism is the lack of comparison to existing baselines, except for the simple example in Figure 1. While the advantages of "structured" representations are acknowledged, a comparison to baseline methods would be beneficial. For instance, in Figure 5, it is difficult to assess the model's performance without a baseline for comparison. Section 6.3 and Figure 6 require more detailed explanation, as the identification of discrete latent behavioral states by the SLDS model is a significant contribution. Without further clarification, it is unclear what the results represent, such as the semantic meaning of the 30 discrete states mentioned in Section 6.3, and why only two states are shown in Figure 6.