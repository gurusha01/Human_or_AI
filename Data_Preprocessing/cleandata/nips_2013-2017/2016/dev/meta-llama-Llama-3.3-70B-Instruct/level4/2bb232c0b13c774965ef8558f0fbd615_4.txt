This study proposes an adaptation to the collapse layer of conventional MD-LSTMS for handwriting recognition, as initially presented in [18], and shares similarities with [6] in its character-level decoding approach per time step. The key modification involves replacing global average pooling with weighted average pooling (equation 2), where the weights are dynamically learned through a recurrent attention layer (MD-LSTM) that incorporates both previous weights and the encoded feature vector. The use of CTC loss enables direct computation of transcription loss without requiring character or line-level alignment, and the attention mechanism can be viewed as a form of "soft" line segmentation. The authors provide a comparative analysis with other methods, including [6], demonstrating superior or comparable performance. In my interpretation, the primary distinction between this work and [6] lies in the decoding of an entire line at each time step, as opposed to a single character, resulting in enhanced speeds and performance. However, I remain uncertain about the extent of technical innovation presented, and I would appreciate clarification in the rebuttal to potentially revise my assessment. Additionally, visualizing attention mechanisms when the input image contains more lines than the algorithm's specified time steps could provide valuable insights, particularly given the method's reported robustness in such scenarios.