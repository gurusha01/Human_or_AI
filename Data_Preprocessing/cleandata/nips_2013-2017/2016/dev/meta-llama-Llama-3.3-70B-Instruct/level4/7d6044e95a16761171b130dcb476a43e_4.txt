This paper proposes a novel approach to extending variational autoencoders (VAEs) to structured graphical models with non-linear observation models, leveraging the VAE framework to predict potential functions for facilitating inference on complex latent representations. The core concept presented is sound, and upon examination, the claims regarding bounds and other technical aspects appear to hold true. However, the current manuscript suffers from clarity issues, making it challenging to follow. Notably, the primary objective, L_{SVAE}, is introduced only in the supplementary material, and crucial proofs are dispersed throughout, indicating a need for improved exposition. Enhancing the algorithm description and expanding explanations in the appendix, potentially relocating figures like Figure 6 to make room for additional clarifications, could significantly improve readability. While the experimental results serve as a proof of concept, they fall short of demonstrating the model's full potential by only being applied to toy data, mouse depth data, and comparisons limited to synthetic spiral data. It is hoped that the authors can showcase their model's capabilities on more complex and recognized tasks if the paper is accepted. Additionally, minor corrections are needed, such as addressing the constant terms in the posterior in Appendix equation (28) and correcting the subscript in line 86 to reflect the accurate representation according to Figure 2.