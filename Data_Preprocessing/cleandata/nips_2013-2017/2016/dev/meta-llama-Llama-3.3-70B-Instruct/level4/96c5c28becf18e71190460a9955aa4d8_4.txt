The authors explore the estimation of thresholds in a drift diffusion model using two established algorithms, REINFORCE and Bayesian optimization. It is unclear why the asymptotic values in Figures 2D and 3D exhibit discrepancies, particularly given that the Bayes risk is expected to have a unique minimum. Notably, previous research, such as the works by J Drugowitsch et al (J Neurosci, 2012), S Deneve (Frontiers, 2012), and Huang et al (NIPS, 2012), has demonstrated that optimal thresholds are time-dependent. A significant limitation of the current study is the lack of connection to empirical neural and behavioral data. Furthermore, the implementation of REINFORCE can be enhanced by utilizing a reinforcement comparison for the reinforcement baseline, rather than a zero baseline, which would serve to decrease the variance of the gradient estimate.