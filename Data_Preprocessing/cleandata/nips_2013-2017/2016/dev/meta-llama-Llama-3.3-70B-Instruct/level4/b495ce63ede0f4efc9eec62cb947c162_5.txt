This manuscript introduces a innovative framework for establishing visual component correspondence between objects within the same category across different images. The proposed fully convolutional architecture leverages a contrastive loss function, facilitating efficient computation reuse throughout the convolutional layers, and incorporates a modified spatial transformer module, enabling adaptive transformation of input patches. These novel components are essential for the model's efficiency and effectiveness. The paper is well-structured and clearly explained. The adoption of a fully convolutional architecture is well-founded, as it significantly enhances training efficiency compared to triplet loss and contrastive loss approaches. The employment of hard negative mining is also crucial in deep metric learning. However, there are minor typographical errors on lines 49 and in the caption of Figure 2. The authors frequently refer to "semantic correspondence," although the model actually learns to extract abstract visual features shared across multiple instances of the same object part, rather than acquiring semantic meaning. The term "geometric correspondence" would be more accurate. The experimental results are qualitatively underwhelming, as evident in Figure 7, where the HN-ST model fails to establish correspondences for the dog, boat, and bus, highlighting its inability to learn semantic correspondences, particularly given the disparate visual perspectives between query and test samples.