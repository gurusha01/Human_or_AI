This manuscript presents a novel approach to visual question answering by iteratively refining the question representation to enhance its ability to discern the actual image content. This concept is intriguing and draws parallels with the 20 questions game, where uncertainty is progressively reduced through iterative refinement. Building upon the neural reasoner concept [21], the authors adapt this idea to the domain of visual images. The proposed neural network architecture leverages pre-trained networks, including CNNs for image processing and GRUs for text analysis, which are further enhanced by a dedicated "reasoning" layer, culminating in a softmax layer that yields the final answer. The model's performance is evaluated on challenging real-world datasets, yielding promising results. The paper is well-structured, complemented by qualitative results and quantitative evaluations, with implementation details providing valuable insights into hyperparameter tuning, such as learning rates. To further enhance the paper's clarity, illustrating limitations and failure cases through additional figures, potentially complementing Figure 5, would offer guidance for future research directions. Specifically, visualizing ambiguities in text parsing or category confusion could provide deeper insights. Although the method is experimentally validated, the convergence of the "question update" iterations remains unclear, and there is a potential risk of oscillation between conflicting image content interpretations. The authors' commentary on this aspect would be beneficial, addressing why such iterations should converge rather than oscillate.