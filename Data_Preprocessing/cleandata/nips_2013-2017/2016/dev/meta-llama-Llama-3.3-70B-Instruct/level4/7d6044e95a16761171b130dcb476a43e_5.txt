The authors propose a methodology that integrates nonlinear likelihoods from neural networks with structured latent variables, leveraging existing techniques such as stochastic variational inference, message passing, and backpropagation via the reparameterization trick. To enhance optimization efficiency, the approach utilizes conjugate exponential families and natural gradients where applicable. The paper is well-structured and clearly written, featuring informative examples and a thorough discussion of related work. The authors deserve credit for acknowledging and succinctly describing recent studies that employ a similar approach, as referenced in Section 5. However, it would be beneficial to include a brief mention of Belanger and McCallum's ICML 2016 work on Structured Prediction Energy Networks. The provided examples effectively demonstrate the scalability of the method, and the accompanying videos are a welcome addition. To further strengthen the paper, it would be helpful to elucidate the key strengths of the novel contributions presented. A primary concern is whether the combination of these pre-existing tools constitutes a sufficiently innovative contribution for this conference, although this concern is not paramount and is acknowledged from a non-expert perspective.