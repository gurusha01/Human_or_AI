The authors introduce the MatNet, a novel hierarchical generative model that integrates recent advancements from various architectures, including DRAW-type models, Ladder Networks, and residual nets. This model achieves state-of-the-art performance in terms of negative log-likelihood (NLL) on several datasets, such as MNIST, Omniglot, and CIFAR 10, and demonstrates impressive qualitative inpainting results on datasets like CelebA and LSUN. 
From a technical standpoint, the experimental section is commendable for its clarity and the straightforward, reproducible protocol it follows. The comparisons with current state-of-the-art methods, including very recent ones like Pixel RNN, are thorough. However, a side-by-side comparison of qualitative results with other methods would have been beneficial, yet this was not provided, even in the supplementary materials.
In terms of novelty, the authors build upon recent successes in the field, making notable advancements, such as utilizing a Gaussian Mixture Model (GMM) as a prior over $z_0$ instead of relying on a single Gaussian prior. 
The clarity of the presentation could be improved, particularly with Figure 1, which lacks the quality and clarity expected. Furthermore, the distinction between the content of the supplementary material and the main paper submission is not well-defined, aside from the additional images included in the supplementary material.