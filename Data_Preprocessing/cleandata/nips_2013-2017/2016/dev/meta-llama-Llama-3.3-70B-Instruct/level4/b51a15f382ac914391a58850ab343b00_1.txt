The authors address the stochastic combinatorial partial monitoring problem, where an unknown vector theta is generated from a fixed distribution at each round, and the operator selects an arm from a potentially infinite set, receiving a reward that is a known function of the arm and theta. However, instead of receiving the reward or the full vector theta as feedback, the operator receives a linear transformation of theta that depends on the chosen arm and aims to minimize regret. The authors propose two algorithms based on the Phased Exploration and Greedy Exploitation strategy, which involves alternating between exploration and exploitation phases of fixed lengths, with one version incorporating an initial estimation of the gap. They provide analyses for both algorithms, establishing problem-dependent and problem-independent regret bounds that match the complexity of previous work over T but are distinct in being independent of the number of arms and not requiring a unique optimal arm for the problem-independent bound. An application to online ranking is also demonstrated. The paper is well-structured and clear, with notable ideas including the use of the PEGE framework to eliminate dependency on the number of arms and the allocation of samples for gap estimation to improve the problem-dependent regret bound. I recommend accepting this paper. However, I have several questions for the authors: 
1. The paper does not discuss lower bounds for regret. Are such bounds known for the stochastic CPM problem, and if so, how do they compare to the bounds presented?
2. The choice of the global observable set is not elaborated upon. Is there a method for making a strategic choice of the global observable set sigma to minimize \beta_\sigma? 
After considering the rebuttal, my assessment remains unchanged.