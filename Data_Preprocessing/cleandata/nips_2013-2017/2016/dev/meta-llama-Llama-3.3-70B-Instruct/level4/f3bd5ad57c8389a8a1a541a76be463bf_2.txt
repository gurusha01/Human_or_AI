This manuscript presents a novel approach for estimating depth from single images by training a neural network to predict distributional parameters of the depth map's derivatives. Unlike end-to-end CNN methods that directly regress depth, this approach involves a two-stage process: first, predicting the distributional parameters of the zeroth, first, and second-order derivatives for each pixel, and then applying a globalization step to 'harmonize' these distributions and estimate the depth map that maximizes their likelihoods. The proposed method is evaluated on the NYU v2 depth dataset, outperforming competing approaches trained solely on this dataset, although it falls slightly short of methods that utilize additional supervision, such as pretrained VGG networks or semantic segmentation outcomes. The paper is technically sound, and the use of CNNs to regress distributional parameters for depth estimation is a notable contribution, distinct from related work like Chakrabarti et al. (CVPR 2015). However, upon examining Figure 3, it is apparent that the estimated coefficients exhibit numerous low-confidence regions, likely due to the independent application of the network to local image regions. Consequently, the final depth map accuracy heavily relies on the globalization procedure, which is applied as a separate, final stage. This strategy may be at a disadvantage compared to approaches like Eigen and Fergus (ICCV 2015), where multiple tasks, including depth and normal prediction and semantic labeling, are addressed simultaneously by a single network architecture. It would be beneficial for the authors to explore the possibility of integrating local estimation and global harmonization into a single network. Furthermore, I would appreciate additional commentary from the authors on the errors depicted in Figure 3, particularly the vertical high-frequency stripes, as the smooth elliptical shapes can be attributed to the Gaussian Mixture Models (GMMs), but the origin of these stripes is unclear.