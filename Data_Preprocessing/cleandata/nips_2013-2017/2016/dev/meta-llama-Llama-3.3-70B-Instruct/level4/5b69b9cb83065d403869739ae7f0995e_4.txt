This manuscript proposes a novel formulation of machine translation as a bidirectional reinforcement learning task, leveraging RNN translation models and two unaligned corpora. The approach aims to optimize a linear combination of two loss functions: one derived directly from the language corpora and the other assessing the consistency of the reconstructed message, thereby facilitating communication. This innovative framework enables translation without requiring aligned parallel corpora, potentially unlocking new avenues for research in adjacent fields. The originality of this concept is a significant strength. However, further clarification on the selection of the weighting factor $\alpha$, which balances the two losses, would be beneficial. Specifically, the rationale behind choosing $\alpha = 0.01$ warrants explanation: was this value chosen due to the inherently higher magnitude of the communication loss, or did the consistency of communication have a more pronounced impact, leading to this particular selection?