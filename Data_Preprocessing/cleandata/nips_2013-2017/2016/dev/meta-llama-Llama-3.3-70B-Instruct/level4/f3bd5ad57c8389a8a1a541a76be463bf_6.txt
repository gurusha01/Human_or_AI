This manuscript presents a novel approach to monocular depth estimation, wherein the algorithm predicts filter-bank response coefficients of the depth map rather than directly estimating the depth map itself. The proposed method involves predicting the filter response distribution and subsequently recovering the depth through a global energy minimization step. Technically, the approach appears sound, and the underlying concept of capturing high-level statistics is reasonable. The novelty of the method is also apparent. However, several concerns arise regarding the justification and choice of the proposed method. 
The idea bears some resemblance to recent studies that incorporate loss functions over high-order statistics for various low-level vision tasks, including flow, monocular depth recovery, and image generation, as seen in works such as "DisparityNet" by Mayer et al. (2016), "Image Generation with Perceptual Loss" by Ridgeway et al. (2015), "DeePSiM loss" by Dosovitskiy et al. (2015), and "Depth Estimation" by Eigen et al. (2015). These methods utilize loss functions that capture high-level statistics, often referred to as perceptual loss, through handcrafted or learnable filter map responses. 
Given this context, a baseline comparison seems necessary to convince readers of the proposed method's merits. Specifically, instead of fitting filter-bank responses followed by an energy minimization stage for depth recovery, an alternative approach could involve fitting the depth using a loss function based on the coefficient similarity between filter responses from ground truth depth and predicted depth. This scheme would capture high-order statistics through handcrafted filters without requiring time-consuming alternating inference in prediction. It is unclear why the proposed method is favored over such an approach, and experimental evidence supporting its importance is lacking. 
The author emphasizes the significance of fitting the coefficients of filter-bank responses but fails to demonstrate this importance through experiments. Questions remain as to whether this approach yields visually more appealing results, better preserves 3D geometry, or if modeling uncertainty leads to more diverse predictions. The comparison study in section 4.2 does not provide clear insights into the method's advantages, suggesting that its impact may be less significant than other factors such as pretraining a VGG model on ImageNet or incorporating semantic labeling loss. 
Furthermore, the foundation for directly fitting high-order depth map statistics rather than 3D geometry space is not well-established, and the choice of a series of handcrafted Gaussian filters lacks clear justification. An alternative approach could involve incorporating the inference stage of equation 6 into the network and learning the filters in an end-to-end manner, allowing the objective of reconstructing depth to be directly utilized. There is also a concern that indirect regression might compromise performance in terms of RMSE, as the model is not optimized to minimize this loss. 
In its current state, the paper is on the borderline, and a rebuttal addressing these concerns is necessary to fully evaluate its contribution.