The paper addresses the challenging problem of causal subset selection using Directed Information (DI) as a measure of prediction causality. It introduces two key tasks—causal sensor placement and causal covariate selection—and formulates them as cardinality-constrained DI maximization problems. The authors demonstrate that while the first problem is submodular but not monotonic, the second is "nearly" submodular. To address these challenges, the paper proposes a novel metric, the Submodularity Index (SmI), to quantify the degree of submodularity for general set functions. Theoretical results are supported by experiments on synthetic and real-world datasets, with applications to causal structure learning.
Strengths:
1. Novel Contributions: The introduction of the Submodularity Index (SmI) is a significant theoretical advancement. It extends the applicability of greedy algorithms to non-monotonic and approximately submodular functions, broadening their utility in subset selection problems.
2. Theoretical Rigor: The paper provides detailed submodularity analysis for the two objectives and derives performance guarantees for greedy algorithms as a function of SmI. This is a valuable contribution to the field of combinatorial optimization.
3. Practical Relevance: The application of the proposed methods to causal structure learning demonstrates their practical utility. The experiments on synthetic and real-world datasets (e.g., stock market data) reinforce the applicability of the approach.
4. Experimental Validation: The experiments are well-designed and validate the theoretical findings. The results show that the proposed methods achieve near-optimal solutions efficiently, even for non-submodular objectives.
Weaknesses:
1. Clarity: While the paper is technically sound, some sections, particularly the theoretical derivations (e.g., SmI definition and bounds), are dense and may be challenging for readers unfamiliar with submodularity. Improved explanations or visual aids could enhance accessibility.
2. Limited Discussion of Limitations: The paper does not explicitly discuss the limitations of the proposed approach, such as potential computational challenges in estimating SmI for large-scale problems or the reliance on DI as the causality measure.
3. Comparative Analysis: While the paper mentions related work, it lacks a thorough empirical comparison with alternative methods for subset selection or causal structure learning. This would strengthen the case for the proposed approach.
4. Scalability: The experiments are limited to datasets with up to 35 processes. It is unclear how the method scales to much larger datasets, which are common in real-world applications.
Recommendation:
I recommend acceptance of this paper, as it makes a significant theoretical and practical contribution to causal subset selection and greedy optimization. However, the authors should consider improving the clarity of the theoretical sections and providing a more detailed discussion of limitations and scalability in the final version.
Pro and Con Arguments:
Pros:
- Novel and impactful contributions (SmI and its application to non-monotonic functions).
- Strong theoretical foundation with performance guarantees.
- Practical relevance demonstrated through experiments and applications.
Cons:
- Dense theoretical sections may hinder accessibility.
- Limited discussion of limitations and scalability.
- Lack of empirical comparison with alternative methods.
In summary, this paper advances the state of the art in subset selection and causal analysis, making it a valuable addition to the conference.