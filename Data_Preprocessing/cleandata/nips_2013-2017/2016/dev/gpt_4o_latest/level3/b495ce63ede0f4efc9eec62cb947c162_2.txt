The paper presents a novel deep learning framework, the Universal Correspondence Network (UCN), for learning dense correspondences in natural image pairs, addressing both geometric and semantic correspondence. Unlike prior CNN-based approaches that rely on surrogate patch similarity objectives, UCN employs deep metric learning to directly optimize a feature space for correspondence tasks. Key contributions include a correspondence contrastive loss for efficient training and testing, a convolutional spatial transformer for patch normalization, and a K-nearest neighbor (K-NN) layer for efficient correspondence search. The framework demonstrates state-of-the-art performance across multiple datasets, including KITTI, PASCAL, and CUB-2011, and is recommended for an oral presentation at NIPS.
Strengths:
1. Technical Innovation: The paper introduces several novel components, such as the correspondence contrastive loss and convolutional spatial transformer, which significantly enhance the efficiency and accuracy of correspondence estimation. These innovations address limitations in prior methods, such as inefficiencies in patch-based approaches and the lack of invariance to transformations.
2. State-of-the-Art Results: The framework achieves impressive performance on diverse datasets, demonstrating its generalizability across rigid and non-rigid bodies as well as intra-class variations. The results are particularly strong for semantic correspondence tasks, where the convolutional spatial transformer proves highly effective.
3. Efficiency: The fully convolutional architecture and the O(n) computational complexity for testing make the framework scalable and practical for real-world applications.
4. Clarity and Organization: The paper is well-written, with a clear explanation of the methodology, experiments, and results. The inclusion of ablation studies to evaluate individual components (e.g., hard negative mining and spatial transformer) strengthens the experimental rigor.
Weaknesses:
1. Computational Complexity: While the authors claim O(n) complexity for testing, the computational efficiency compared to related works (e.g., Siamese networks) is not fully clarified. A more detailed analysis or empirical comparison of runtime would strengthen the argument.
2. Occlusion Handling: The paper does not explicitly address how the framework handles occlusions, which are common in real-world correspondence tasks. A discussion or additional experiments on this aspect would improve the paper's completeness.
3. Loss Function for Missing Correspondences: It is unclear whether the proposed correspondence contrastive loss adequately handles cases where no correspondence exists. This could be a limitation in scenarios with significant occlusions or background clutter.
4. Missing Citation: The paper overlooks a relevant reference on dense correspondence via 3D-guided cycle consistency (CVPR 2016). Including this citation and discussing its relationship to the proposed work would provide a more comprehensive context.
Recommendation:
The paper makes significant contributions to the field of visual correspondence and addresses a challenging problem with innovative solutions. Its strong experimental results and practical efficiency make it a valuable addition to the NIPS conference. However, the authors should address the concerns regarding computational complexity, occlusion handling, and missing citations in the final version. Overall, I recommend acceptance with minor revisions. 
Pro Acceptance:
- Novel contributions (e.g., correspondence contrastive loss, spatial transformer).
- State-of-the-art results across multiple datasets.
- Efficient and scalable framework.
Con Acceptance:
- Lack of clarity on computational complexity.
- Limited discussion on occlusion handling and missing correspondences.
- Missing relevant citation.