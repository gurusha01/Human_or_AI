Review of the Paper
This paper addresses the problem of partial monitoring in stochastic combinatorial settings with linear feedback, building upon the CPM model introduced by Lin et al. [1]. It proposes two algorithms, PEGE and PEGE2, which aim to overcome some limitations of the Global Confidence Bound (GCB) algorithm from [1]. The authors claim improvements in regret bounds and practical applicability, particularly in scenarios with large or infinite action spaces for the learner.
Strengths:
1. Novel Contributions: The paper introduces the PEGE framework, which uses phased exploration with greedy exploitation, and PEGE2, which combines gap estimation with PEGE. These approaches provide regret bounds that are independent of the learner's action set size, a significant improvement over GCB.
2. Practical Advantages: PEGE eliminates the need for a second-best solution oracle and avoids the uniqueness constraint on the optimal solution, making it more practical for real-world applications.
3. Theoretical Insights: The regret bounds achieved by PEGE and PEGE2 are theoretically sound. The distribution-independent regret of \(O(T^{2/3} \sqrt{\log T})\) and the distribution-dependent regret of \(O(\log^2 T)\) for PEGE are noteworthy. PEGE2 matches GCB's \(O(\log T)\) regret while maintaining independence from the action set size.
4. Application to Online Ranking: The paper demonstrates how the proposed algorithms can be applied to online ranking problems with feedback at the top, extending the CPM model to practical settings.
5. Clarity in Assumptions: The paper clearly outlines its assumptions (e.g., Lipschitz continuity, global observability) and provides detailed theoretical analysis to support its claims.
Weaknesses:
1. Parameter Tuning: The distribution-dependent bounds for PEGE require careful tuning of the parameter \(h\), which can lead to exponential dependence on \(h\) if improperly set. PEGE2 attempts to address this but introduces new challenges, such as reliance on the time horizon \(T\) and weaker guarantees in some cases.
2. Computational Complexity: Both PEGE and PEGE2 require solving linear optimization problems at every step, which may limit their practical scalability, especially in high-dimensional or large-scale settings.
3. Incomplete Resolution of Issues: While PEGE2 removes dependence on the action set size, it still requires a unique optimal action for achieving \(O(\log T)\) regret. This assumption may not hold in many practical scenarios, as noted in the online ranking example.
4. Clarity and Presentation: The paper could benefit from a more formal algorithmic presentation of its protocols. For instance, Algorithm 1 lacks clarity in the role of \(\sigma\), and the remark in lines 176-180 is ambiguous. Additionally, there are typos (e.g., line 177, line 304) and an incomplete citation (line 317).
5. Comparison with Prior Work: While the paper compares its results to GCB, the discussion of related work in online ranking is unclear. The introduction of \(\delta\) (set to \(1/T\)) also seems unnecessary and adds to the confusion.
Arguments for Acceptance:
- The paper makes a significant theoretical contribution by achieving regret bounds independent of the learner's action set size.
- It addresses practical limitations of GCB, such as the need for a second-best oracle and the uniqueness constraint.
- The application to online ranking demonstrates the potential for real-world impact.
Arguments Against Acceptance:
- The practical utility of the algorithms is limited by their computational complexity and reliance on parameter tuning.
- PEGE2's solution to the \(h\)-tuning issue is unsatisfactory, and its regret guarantees are weaker in some cases.
- The paper's presentation has several clarity issues, and the comparison to related work is incomplete.
Recommendation:
While the paper provides valuable theoretical insights and addresses important limitations of prior work, its practical applicability and clarity could be improved. I recommend acceptance with minor revisions, focusing on improving the clarity of the algorithms, addressing computational concerns, and providing a more thorough comparison to related work.