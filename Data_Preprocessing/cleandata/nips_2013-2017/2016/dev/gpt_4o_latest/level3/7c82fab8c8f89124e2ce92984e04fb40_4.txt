This paper addresses the problem of selective inference in the context of linear models with group sparsity, a topic of growing importance in modern statistical modeling. The authors propose novel tools for constructing confidence intervals and p-values for selected groups of variables, extending existing methods for sparse regression to the group-sparse setting. The key technical contribution is the "truncated projection lemma," which characterizes the distribution of the magnitude of a projection conditioned on selection events. This result enables inference for a variety of group-sparse selection methods, including the group lasso, iterative hard thresholding (IHT), and forward stepwise regression. The paper demonstrates these methods on both simulated and real-world health data, showcasing their practical utility.
Strengths:
1. Theoretical Significance: The paper provides non-trivial theoretical results that generalize prior work on selective inference for sparse models (e.g., Lee et al., 2016) to the group-sparse setting. The "truncated projection lemma" is a key innovation that addresses the challenge of non-independence between the length and direction of projections in the group-sparse case.
2. Practical Relevance: The proposed methods are applicable to widely used group-sparse algorithms, such as the group lasso and IHT. This broad applicability enhances the paper's potential impact on both theoretical and applied research.
3. Experimental Validation: The experimental results, particularly the empirical coverage of confidence intervals and the analysis of California health data, are promising and demonstrate the practical utility of the proposed methods.
4. Clarity and Organization: The paper is well-written and logically structured. The authors provide clear explanations of their methods, including detailed derivations and pseudo-code for implementation.
Weaknesses:
1. Limited Comparison to Prior Work: While the paper builds on foundational work in selective inference, it could provide a more comprehensive comparison to existing methods, particularly in terms of computational efficiency and practical limitations.
2. Numerical Approximation for Group Lasso: The reliance on numerical approximations for the group lasso may limit the method's scalability and precision. A more detailed discussion of the computational trade-offs and potential limitations would strengthen the paper.
3. Scope of Experiments: While the experiments are informative, they are somewhat limited in scope. Additional benchmarks against alternative methods or larger-scale real-world datasets could provide a more robust evaluation of the proposed techniques.
Pro and Con Arguments for Acceptance:
Pro:
- The paper makes a significant theoretical contribution to selective inference for group-sparse models.
- The methods are broadly applicable and address practical challenges in statistical modeling.
- The experimental results are promising and demonstrate the utility of the proposed tools.
Con:
- The reliance on numerical approximations for the group lasso introduces potential limitations.
- The experimental evaluation, while promising, could be more comprehensive.
Recommendation:
Overall, this paper represents a meaningful contribution to the field of selective inference and group-sparse modeling. While there are some areas for improvement, particularly in experimental scope and computational considerations, the theoretical advancements and practical relevance justify its acceptance. I recommend acceptance with minor revisions to address the noted weaknesses.