The paper presents a novel neural network model for visual question answering (VQA) that iteratively updates the question representation by interacting with relevant image regions. The approach builds on the neural reasoner framework, adapting it to the VQA domain by incorporating object proposals and attention mechanisms. The model uses a VGG-based image encoder and a GRU-based question encoder, transforming both into a shared latent space for reasoning. The reasoning process involves multilayer perceptrons (MLPs) and attention-based weighted pooling, with the final answer generated via a softmax layer. The model achieves state-of-the-art results on the COCO-QA dataset and competitive performance on the VQA dataset.
Strengths:
1. Technical Contribution: The iterative updating of question representations through image-question interactions is a meaningful advancement. The integration of object proposals and attention mechanisms enhances the model's ability to focus on relevant image regions, improving reasoning and answer accuracy.
2. Performance: The model outperforms state-of-the-art methods on COCO-QA and shows strong results on VQA, particularly in categories like "Color" and "Location." This demonstrates the effectiveness of the proposed approach.
3. Clarity: The paper is well-written and provides detailed descriptions of the model architecture, training process, and evaluation metrics. The qualitative analysis, including attention visualizations, effectively illustrates the model's reasoning capabilities.
4. Novelty: The adaptation of the neural reasoner to VQA, particularly the use of object proposals as "facts," is innovative and opens new research directions for integrating text-based QA models into multimodal tasks.
5. Ablation Studies: The experiments comparing pooling mechanisms and the inclusion of global image features and spatial coordinates provide valuable insights into the model's design choices.
Weaknesses:
1. Baseline Comparisons: While the paper compares its results with state-of-the-art methods, it lacks a detailed explanation of these baselines. Including brief descriptions of competing models would help contextualize the contributions.
2. Pooling Mechanisms: The paper highlights the importance of weighted pooling but does not explore alternative pooling strategies in depth. A more comprehensive comparison could strengthen the contribution.
3. Single MLP Layer: The use of a single MLP layer in the reasoning process is not well-justified. Exploring deeper MLP architectures or explaining this design choice would improve the paper.
4. Figure 3 Clarifications: The third example in Figure 3 is ambiguous, and additional explanation would enhance the reader's understanding of the qualitative results.
5. Counting Limitation: The model struggles with counting tasks, as acknowledged by the authors. While this is a challenging problem, a discussion of potential solutions or future directions would be beneficial.
Recommendation:
The paper is a strong candidate for acceptance due to its technical novelty, strong empirical results, and clear presentation. However, addressing the weaknesses—particularly the lack of baseline descriptions and the justification for certain design choices—would further solidify its contributions. The work is well within the scope of the conference and provides a significant step forward in VQA research.
Pro Arguments:
- Novel adaptation of neural reasoner for VQA.
- Strong empirical performance on challenging datasets.
- Clear and detailed presentation.
Con Arguments:
- Limited discussion of baseline models.
- Lack of exploration of alternative pooling mechanisms.
- Ambiguities in qualitative examples and design justifications.
Overall, the paper is a valuable contribution to the field and merits acceptance with minor revisions.