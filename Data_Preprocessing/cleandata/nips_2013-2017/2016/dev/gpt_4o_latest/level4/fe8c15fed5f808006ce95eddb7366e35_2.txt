The paper introduces a hierarchical model for trajectory planning, applied specifically to predicting basketball player trajectories. The model is structured around two policy networks: a "micro-planner," which computes a distribution over actions \(a{\text{micro}} \sim \pi(s; \theta{\text{micro}})\), and a "macro-planner," which computes a distribution over "goals" \(\pi(s; \theta{\text{macro}})\). A "goal" \(g\) represents a sub-region of the court (at a coarser granularity than \(s\)) that the player aims to reach. A "transfer function" \(m\) maps \(g\) to an attention mask \(mg\) (defined in the action space), which is then applied via pointwise multiplication (Hadamard product) to the action distribution \(a_{\text{micro}}\). The training process involves optimizing the micro- and macro-planners independently (via cross-entropy loss) while freezing the other components, using ground truth micro-action labels for supervision. The experimental evaluation includes a visual analysis of the generated trajectories by human observers and a prediction accuracy benchmark across various model ablations. Overall, the paper is well-written, and the proposed use of an attention mechanism to define sub-goals is an interesting and promising idea. However, the paper has several technical limitations that, in its current form, make it unsuitable for acceptance at NIPS. 
Limitations:
- The title is misleading. The term "memory networks" is not appropriate, as the only form of memory in the model comes from the GRUs. A more suitable title would be "Recurrent and Hierarchical Trajectory Planning Using ConvNets."
- The authors employ a multi-stage training approach, where the micro-planner, macro-planner, and attention mechanism are trained separately with the other components frozen. This approach is not compared to end-to-end training, where the final prediction \(m_g(a)\) is backpropagated through the entire model, including the attention mechanism, micro-planner, and macro-planner. Both training strategies should be benchmarked for a fair comparison.
- The choice of a discrete 17x17 action space is not well-justified. A continuous 2D space or polar coordinates (either continuous or discretized) would likely simplify training. Using mean squared error in a continuous space (especially with polar coordinates) could extract more information per training sample, as small errors in direction or magnitude would not be penalized as heavily as they are in the current setup, where errors are treated equally regardless of their nature.
- In the experiments, the prediction task assumes that all other players stop moving (page 7, line 209, and supplementary material). This assumption raises concerns about how much of an advantage this provides to "random" baselines and other simpler methods, making it difficult to draw robust conclusions from the results.
- Table 2 is missing key baselines, such as "random" and "keep moving in the same direction." Furthermore, the results in Table 2 suggest that training the attention mechanism does not consistently improve performance, which warrants further investigation.
Unclear Points:
- On page 5, lines 164-165 mention "we sub-sampled every 4 frames," while line 175 states "sub-sampling at 4Hz." Since 25Hz / 4 equals 6.25Hz, there is an inconsistency. Please clarify which is correct.
- Specify that "frames" in Section 5 (e.g., page 7, line 208) refer to frames after sub-sampling.
- Rephrase the term "95% statistically significant" for better clarity and accuracy.