The authors address the problem of learning the thresholds of a drift diffusion model and employ two well-established algorithms, REINFORCE and Bayesian optimization, to achieve this. A key question arises regarding the differing asymptotic values observed in Fig. 2D and 3D, particularly given that the Bayes risk is expected to have a unique minimum. The study of optimal thresholds is not novel and has previously been shown to exhibit time-dependence, as demonstrated in works such as J Drugowitsch et al. (J Neurosci, 2012), S Deneve (Frontiers, 2012), and Huang et al. (NIPS, 2012). The manuscript also lacks connections to relevant neural and behavioral data. Additionally, the REINFORCE algorithm could be enhanced by incorporating reinforcement comparison for the baseline, rather than using zero, to reduce the variance in the gradient estimate.