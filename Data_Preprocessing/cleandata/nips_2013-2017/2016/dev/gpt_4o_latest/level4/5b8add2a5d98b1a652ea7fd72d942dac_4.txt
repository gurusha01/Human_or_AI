The problem of recovering a vector from quadratic measurements (commonly referred to as phase retrieval) is explored in this paper. The authors adopt the now-standard approach of formulating a (non-convex) optimization problem, which is then solved using a gradient-descent-like algorithm with an appropriate initialization. However, the paper introduces significant modifications to both the initialization and the gradient-descent process: 1) Similar to prior work, the initialization is derived as an eigenvector of a matrix. However, the matrix proposed in this paper differs substantially from those used in existing methods. The resulting improvement in sample complexity due to this modification is convincingly demonstrated through numerical experiments (Figs. 3 and 4). 2) The refinement step following initialization involves a gradient-descent-like method, but with the exclusion of a few undesirable data points at each iteration. The novelty here lies in the fact that both the objective function and the truncation rule are newly introduced. The enhanced sample complexity resulting from this refinement is illustrated in Fig. 1. The overall benefits of the proposed method in terms of sample complexity are summarized in Fig. 5. However, the computational complexity does not show significant improvement compared to existing approaches.
1) Figure 1 compares the performance of various algorithms, all of which employ the truncated spectral initialization. In this comparison, the success rate of TWF is noticeably lower than that of TGGF. It would be intriguing to investigate the impact of replacing the initialization in TWF with the new initialization proposed in this paper. Would the success rate of TWF remain inferior to TGGF? If not, this would suggest that the improvement of TGGF is primarily due to the enhanced initialization. Conversely, if the success rate of TWF remains lower, it would strengthen the contributions of this paper by providing evidence that the improvement stems from the second stage of the algorithm. 2) The TWF paper also includes experiments with structured sensing vectors (e.g., coded diffraction patterns). How does TGGF perform when the sensing vectors are structured rather than random? 3) While the empirical results in the noisy case are excellent, the paper does not provide theoretical guarantees for the noisy case. This omission is not a critical issue, as the empirical results for both the noiseless and noisy cases, along with the theoretical results for the noiseless case, are already strong. 4) For the noisy case, the measurement model is assumed to be |ai^Tx + etai| rather than |ai^Tx|^2 + etai, as considered in some earlier works. Additionally, eta_i is assumed to follow a Gaussian distribution rather than a Poisson or arbitrary distribution. Since the paper does not provide theoretical results for the noisy case, it would be valuable to include numerical experiments for the case of Poisson noise, which is a relevant model for imaging applications. 5) Is the improvement of TGGF over TWF limited to sample complexity? For instance, with n=1000 and m=8000, how does the convergence rate of TGGF compare to that of TWF?