The paper is well-written and presents intriguing ideas, framing machine translation as a communication game between two parties, each fluent only in their respective language. The following points were identified: 
1. The theoretical foundation of the method appears underdeveloped. It would be beneficial to include more theoretical analysis or discussion to strengthen the approach.  
2. Several key details are missing. For instance, what specific one-way translation model is employed, and how are its architecture and parameters determined? Additionally, what precise model is used to evaluate the quality of pseudo-translations? Such details are crucial for clarity and reproducibility.  
3. In Algorithm 1, the scheduling alternates between A-to-B and B-to-A translations on a sentence-by-sentence basis. How effective is this scheduling strategy, and could it be improved? For example, when sampling a sentence from B, one might prioritize sentences that overlap with the pseudo-translation of the previous sentence from A.  
4. The experimental results are somewhat underwhelming. Given that the method targets monolingual translation, it could be applied to much larger datasets. However, the authors have limited their experiments to conventional small datasets. Why not train on larger corpora, such as the entirety of English and French Wikipedia?  
5. Another compelling question is how the method compares to training on parallel data. For instance, how much parallel data could the proposed method save while achieving comparable performance to fully parallel data training?