This paper introduces a novel class of architectures called Matryoshka Networks (MatNets), which integrate the strengths of DRAW-like models and Ladder Networks to develop hierarchically deep generative models with jointly-trained inference and generation. The authors demonstrate the quantitative performance of MatNets on datasets such as MNIST, Omniglot, and CIFAR10. The proposed framework presents an intriguing approach to learning deep generative models. The paper also showcases impressive results in imputing missing regions of images. Nonetheless, the inclusion of classification results (whether supervised, semi-supervised, or unsupervised) on standard benchmarks like MNIST and CIFAR10 would strengthen the paper's contributions. Overall, the paper is well-written, with its claims, explanations, and derivations presented in a clear and comprehensible manner.