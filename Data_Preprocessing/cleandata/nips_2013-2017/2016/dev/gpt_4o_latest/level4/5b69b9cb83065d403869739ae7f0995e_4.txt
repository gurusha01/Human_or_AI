This paper frames machine translation as a bidirectional reinforcement learning problem, utilizing RNN-based translation models and two corpora (which do not need to be aligned). The goal is to minimize a linear combination of two losses: 1) one derived directly from the language corpora and 2) another based on the consistency of the recovered message (communication). This represents a novel approach that enables translation without requiring aligned parallel corpora. I believe this idea has the potential to inspire new directions in other research areas as well, highlighting its innovative contribution. However, I would like to see additional analysis regarding the choice of $\alpha$, the weighting factor for the two losses. For instance, why was $\alpha$ set to 0.01? Was this due to the communication loss being inherently stronger, or does communication consistency have a greater overall impact?