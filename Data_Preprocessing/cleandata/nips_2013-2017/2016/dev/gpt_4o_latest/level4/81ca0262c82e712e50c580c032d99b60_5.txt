The paper tackles the challenge of identifying subsets of causal sources by proposing a novel metric to quantify the degree of submodularity. To enable the application of greedy algorithms to this class of problems, the authors introduce the submodularity index (SmI), a measure that facilitates the derivation of bounds for a random greedy algorithm as a function of the SmI. In doing so, the work extends the well-established framework of submodular function maximization. Leveraging these findings, the authors explore two problems: source detection and causal covariate selection (where one set of covariates is the complement of the other) using the information-theoretic measure directed information (DI). The first problem is shown to exhibit submodularity without monotonicity, while the second is demonstrated to be nearly submodular (as characterized by the SmI). The theoretical contributions are validated using datasets generated via Murphy's Bayes net toolbox for dynamic Bayesian networks (DBNs), which reveal the underlying causal structure. 
The paper addresses multiple fundamental and pertinent topics, offering potentially intriguing results for each. However, the broad scope of the work diminishes its overall impact, resulting in a lack of coherence in the contributions. The SmI concept introduced in Sec. 4, particularly the implications of Theorem 3, holds relevance for a wide range of NP-hard problems. Nevertheless, the authors confine their application of SmI to causality analysis. While causality analysis is undoubtedly an important field, the paper provides insufficient exploration of the fundamental properties of SmI before delving into this specific application. As a result, the paper appears to prioritize the causal subset selection component, which detracts from the depth of the broader theoretical contributions. 
The lack of focus leads to challenges in comprehension, especially given the limited material presented in the main body of the paper. The first five pages discuss foundational results on the optimization of (nearly) submodular set functions, but the proofs are relegated to supplementary material. These proofs are critical to the paper's results and should be given more prominence. Condensing the analysis of the causal subset selection component could create space for this, as it seems infeasible to adequately cover both topics within the constraints of a single conference paper.
Minor Comments/Questions:
- Consider exploring transfer entropy as an alternative measure of predictability, as similar results for the SmI might be achievable. Note that DI was originally associated with feedback structure (per Massey). Reference [2] provides a useful discussion on when transfer entropy may be preferable to DI.
- Sec. 2 requires citations for directed information and causally conditioned entropy.
- Line 6: Do you substantiate the idea or quantify it?
- Line 8: "the random" → "a random" or "we propose a random."
- Line 9: "guarantee" → "guarantees."
- Line 50: SmI is first mentioned here but is not expanded until later (lines 135–136).
- Line 70: "a a."
- Line 140: "several effort has" → "several efforts have."
- Line 143: "existing works" → "existing work."
- Line 151: "indexes" → "indices."
- Line 120: "detour" should likely be "digression."
- Line 229: Should SmD be SmI?
- A definition of monotonicity might be helpful (at least in the supplementary material).
- References use inconsistent formatting, with some conferences listed as acronyms and others spelled out. Journals also alternate between abbreviations and full titles.
- Line 286: Clarify the conditions under which the maximum DI identifies the underlying graph structure. Does this apply only to fully observed DBNs?
- Line 286: "can be reduces" → "can be reduced."
- Line 305: "an novel."
- Line 313: "gaussian" → "Gaussian."
- Line 331: "dc" → "DC."
- Line 340: "The Bayes"; inconsistent use of "et al."; "matlab" → "MATLAB."
- Line 350: Add periods after abbreviations, e.g., "Comput" → "Comput."
- (Supplementary Material) Lemma 5: "definition (??)" likely refers to Definition 2.
References:
[1] A. Krause, D. Golovin. Submodular Function Maximization. Tractability: Practical Approaches to Hard Problems 3.19 (2012): 8.  
[2] M. Wibral, R. Vicente, and J. T. Lizier. Directed Information Measures in Neuroscience. Heidelberg: Springer, 2014.