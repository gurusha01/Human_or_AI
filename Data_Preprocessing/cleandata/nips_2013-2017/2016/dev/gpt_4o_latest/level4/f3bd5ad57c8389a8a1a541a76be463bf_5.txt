This paper introduces a neural network system designed to estimate depth from monocular images. The proposed approach employs a cascaded two-stage system. Initially, the system generates distributions for various depth derivatives of different orders across multiple scales and orientations. Subsequently, these local distributions are integrated within a globalization framework. While the paper is clearly presented and demonstrates strong results overall, it lacks sufficient novel contributions. As such, this submission does not meet the standard for acceptance at NIPS. 
1. The proposed system bears significant resemblance to the methods of Eigen et al. and Liu et al. It is unclear whether the observed qualitative and quantitative improvements stem from the differences in neural network architecture or the proposed algorithm itself. A more equitable comparison between the proposed algorithm and Eigen et al. under identical neural network settings is warranted. 
2. Experimental fairness is a concern. Liu et al.'s approach is based on super-pixels, whereas the current work employs a sliding window approach. Consequently, it would be appropriate to include an additional baseline that applies a CRF on top of the proposed local neural networks. The authors should either justify the exclusion of this baseline or provide new experimental results addressing this in the rebuttal.
3. The motivation for the proposed algorithm is not sufficiently clear. Specifically, it is unclear why the two-stage cascaded architecture resolves the ambiguity in predictions, as stated in line 42.
4. The submission omits several relevant references in the field of semantic segmentation. While these works do not directly address depth estimation, many of them involve architectures similar to the one proposed in this paper. The authors are strongly encouraged to update their submission to include these related works.