The paper introduces the application of matrix product states (MPS) decomposition, a tensor network technique, to address a general multiclass supervised classification problem. While the paper is well-written, it presumes a certain level of familiarity with MPS and tensor networksâ€”concepts that are widely utilized in quantum physics but may not be as familiar to the broader machine learning community. The proposed approach builds upon prior work (references [3] and [4]), with its contributions being incremental and somewhat similar in nature to these earlier studies. The primary contributions of the paper can be summarized as follows: a) It introduces a tensor-inspired encoding (kernel) that can be applied to any classification problem where the input data is represented as fixed-length vectors. b) It employs gradient descent to optimize the MPS representation for the classification task, in contrast to [4], where the MPS representation is first selected in an unsupervised manner and subsequently used in a separate step for classification by applying a standard classification algorithm to the transformed data.
1) The paper assumes prior knowledge of tensor networks and MPS, which, while common in quantum physics, may not be as accessible to the NIPS audience. In my view, the paper would benefit significantly from a more thorough introduction to these concepts, building them up from the basics. While space constraints in a NIPS paper make this challenging, it is essential for enhancing the paper's readability.  
2) Including the dimensions of vectors and matrices throughout the paper would greatly improve clarity and comprehension.  
3) On line 153, the paper mentions the use of a zig-zag ordering, but Figure 8 does not appear to depict such a pattern. Is this a typographical error, or was the wrong figure included? Please clarify.  
4) The differences between this work and [3] and [4] should be elaborated upon earlier in the paper. For readers with limited or no experience with tensor networks, this additional context would be helpful in understanding the contributions of the current work.  
5) The connection to neural networks, which is briefly mentioned at the end of the paper, is highly informative for this audience. Expanding on this discussion would strengthen the paper.  
6) Could you provide more details on the initialization process? How sensitive is the proposed method to local minima, and how was this issue addressed?  
7) It would be beneficial to specify the tools or libraries used for performing singular value decomposition (SVD).