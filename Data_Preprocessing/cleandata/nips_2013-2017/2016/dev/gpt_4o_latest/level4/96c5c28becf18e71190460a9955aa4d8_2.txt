The drift-diffusion model (DDM) is a widely used framework for modeling outcomes in two-alternative forced choice experiments in psychophysics. In its simplest form, it comprises a stochastic process representing evidence accumulation, which progresses until it reaches either an upper or lower threshold, corresponding to the two possible choices. This paper addresses the challenge of determining optimal thresholds for the DDM. Previous research suggests that thresholds are set to maximize the reward rate, but the underlying mechanisms remain unclear. In essence, the paper posits that thresholds are selected by solving a meta-optimality problem aimed at minimizing the "Bayes risk"â€”a convex objective function derived from a loss function that is linear in the expected decision time and the probabilities of type I and II errors. The resulting meta-optimization problem is framed as a continuous-armed bandit problem. Two strategies for solving this problem are explored: one based on the REINFORCE algorithm and another leveraging Bayesian optimization with a custom acquisition function. These approaches are empirically compared.
Pros:
- The paper tackles an intriguing and important question. Understanding how DDM thresholds are determined could have significant implications for psychophysics.
- The manuscript is well-written, with sound mathematical formulations and clearly presented empirical results.
Cons:
- There are conceptual challenges in addressing the issue of "optimally setting the parameters of optimal choice." Why is it self-evident that this problem can be resolved through meta-reasoning? This fundamental question is not addressed.
- The manuscript contains several typographical errors in the mathematical expressions. For example, equation (4) inconsistently uses both \( t \) and \( T \).
- Certain design choices lack justification. For instance, what specific loss function was used to define the Bayes risk? Why is the bandit strategy formulated as a linear combination of binary units? Additionally, isn't the exponential scaling of coefficients \( s_j \) essentially a form of a-ary coding?
- In my opinion, the paper's primary limitation is that its findings are neither particularly novel nor sufficiently impactful. From a machine learning perspective, the proposed models are relatively straightforward and therefore less compelling. From a psychophysics standpoint, the relevance of the models is difficult to assess without a thorough comparison to empirical data from human or animal decision-making experiments.
Overall, while the paper demonstrates potential, it currently feels underdeveloped and premature for publication.