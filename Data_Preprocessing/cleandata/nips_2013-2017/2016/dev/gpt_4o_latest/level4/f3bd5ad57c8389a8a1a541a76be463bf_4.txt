The proposed method employs ConvNets to predict local depth outputs and subsequently applies a globalization step to achieve a globally consistent depth estimation. Specifically, the authors utilize a ConvNet to predict weights for a set of coefficients, which are modeled as a mixture of Univariate Gaussians. These coefficients are directly linked to the depth through a convolution operation with a set of kernels, where the kernels are derived from the derivatives of a Gaussian. The optimization process alternates between the coefficients and the depth: fixing the predicted depth to optimize the coefficients, and then fixing the coefficients to optimize the depth, iteratively. 
- The approach does not rely on any assumptions about the local outputs, unlike other similar local-global methods such as Chakrabarti et al. [2], which impose a planarity assumption.
Clarity:  
+ The structure of the paper is well-organized.  
+ The explanations are clear and written in simple language, making the content easy to understand.  
Novelty:  
+ The use of ConvNets for local output prediction is a novel aspect of the work.  
- However, the overarching concept of making local predictions and reconciling them to produce a consistent global estimation is not new. This idea has been explored in several previous works, including Chakrabarti et al. [2]. As a result, the level of novelty is limited, particularly when considering the standards of a conference like NIPS.  
Experiments and Test:  
- The results on the NYU v2 dataset are not superior to state-of-the-art methods; they are merely comparable.  
Impact:  
+ The application of ConvNets in this domain (globalization of local outputs) could gain attention due to this work, potentially inspiring other researchers to explore similar ideas in different problem settings.