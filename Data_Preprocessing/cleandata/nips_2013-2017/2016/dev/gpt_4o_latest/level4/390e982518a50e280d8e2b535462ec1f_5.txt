The paper introduces a novel neural network model designed for classification tasks on generic graphs, extending the concept of convolutional neural networks (CNNs). The proposed model explicitly incorporates graph diffusion through a multi-hop architecture and effectively utilizes both node attributes and graph structure during training. While the model demonstrates superior average performance compared to several simple baselines, it appears to face challenges with scalability. The integration of graph diffusion into neural networks is both an interesting and innovative idea. Additionally, the authors provide a strong motivation for the problem. However, there are several areas where the work could be improved:
Scalability:  
1. The authors present three distinct models for node, graph, and edge classification. However, no empirical results for edge classification are provided. This omission raises the question of whether scalability issues are the cause, as edge classification could lead to a significantly large parameter size even for medium-scale graphs (as suggested by Equation (6)).  
2. Including runtime metrics for the current experiments would provide valuable insights into the model's scalability.  
Experimental Settings:  
1. The experimental comparisons appear to lack fairness. While DCNN leverages both node features and graph structures, at least four of the five baselines (l1-logistic, l2-logistic, KED, KLED) rely solely on graph structures as input. This discrepancy makes it unclear whether DCNN's performance improvements stem from superior model design or the additional side information. To ensure a more meaningful comparison, the performance of a purely structural DCNN (e.g., 101-104) should also be reported.  
2. Section 5 references several recent neural architectures for graph-based learning that extend CNNs to irregular graph domains. However, none of these models are included as baselines for empirical comparison. Without benchmarking against strong baselines, it is difficult to assess whether DCNN achieves state-of-the-art performance or is even competitive.  
Relationship to CNN:  
Unlike prior works that explicitly generalize the convolution operator over 2D grids [1,2], it is unclear whether the proposed DCNN can be regarded as an extension of CNNs, as claimed by the authors. Specifically, it is not evident how DCNN would subsume CNN as a special case.  
[1] Bruna, Joan, et al. "Spectral networks and locally connected networks on graphs." arXiv preprint arXiv:1312.6203 (2013).  
[2] Henaff, Mikael, Joan Bruna, and Yann LeCun. "Deep convolutional networks on graph-structured data." arXiv preprint arXiv:1506.05163 (2015).