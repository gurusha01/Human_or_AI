This paper introduces a method for visual question answering by iteratively refining the representation of the question to better distinguish the relevant content in the image. The approach is quite intriguing and reminiscent of the "20 Questions" game, where uncertainty is progressively reduced. The idea builds upon the neural reasoner [21] framework, now adapted for visual imagery. The proposed neural network model leverages certain pre-trained networks (a CNN for image features and a GRU for text processing), which are further enhanced by a "reasoning" layer. A softmax layer is employed to produce the final answer. The model is tested on challenging real-world datasets and demonstrates strong performance. The paper is well-written, providing both qualitative and quantitative results to support the proposed method. Additionally, the implementation details, such as adjustments to learning rates, are clearly described. To further enhance the paper's clarity and utility, it would be beneficial to include figures illustrating the method's limitations and failure cases. For instance, Figure 5 could be complemented with another figure highlighting specific shortcomings, such as ambiguities in text parsing or confusion between image categories, to guide future research. While the experimental evaluation is thorough, the convergence of the "question update" iterations remains unclear. It is conceivable that the updates might oscillate between conflicting interpretations of the image content. It would be valuable for the authors to address this potential issue and provide insights into such scenarios.