This paper introduces a deep learning framework designed to establish dense correspondences between pairs of natural images. The proposed framework learns the correspondence map directly from data, enabling its application to both geometric correspondences (e.g., appearance variations due to pose changes) and semantic correspondences (e.g., matching body regions across different bird species). The primary contributions over prior methods include the introduction of a correspondence contrastive loss for effective training, a convolutional spatial transformer for local patch normalization, and a K-nearest neighbor (KNN) layer for efficient correspondence search between feature vectors extracted from the two images. The paper is well-written, and experiments are conducted on multiple relevant datasets, achieving state-of-the-art results. While there are a few aspects that warrant further investigation, the paper provides sufficient contributions to merit consideration for an oral presentation at NIPS.  
Comments:  
[1] Clarification on O(n) vs O(n²) argument (forward passes): The claim regarding O(n²) forward passes in related works pertains to image patches, whereas the O(n) forward passes in this paper refer to the entire image. However, the KNN layer in the proposed method still performs O(mn) comparisons. In related works, feature extraction for patches requires only a single forward pass, and the decision layers (typically the last 2–3 layers) can be applied to all pairs. While the proposed framework is likely more computationally efficient in practice due to its fully convolutional nature and implicit bookkeeping, it is unclear how the computational complexity is fundamentally improved.  
[2] Occlusions: The paper should discuss how the proposed framework addresses occlusions. Specifically, how does the loss function ensure that, for certain points, no correspondence is assigned when the corresponding point in the second image is occluded? During testing, the current evaluation metric (PCK curves) penalizes only for mis-registrations, and occlusions appear to be handled implicitly by selecting an appropriate threshold. A more explicit discussion on this limitation would strengthen the paper.  
[3] References: The authors should consider citing the relevant work "Learning Dense Correspondence via 3D-guided Cycle Consistency" (CVPR 2016), which is available on arXiv.