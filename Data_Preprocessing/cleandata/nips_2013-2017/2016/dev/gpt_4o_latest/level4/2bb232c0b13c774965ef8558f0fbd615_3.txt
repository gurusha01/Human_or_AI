This paper tackles the challenge of end-to-end paragraph-level handwriting recognition. Traditional methods approach this problem in two stages: line segmentation followed by line recognition. In contrast, this work integrates these two stages into a unified framework using an attention-based model. Experimental results demonstrate that the proposed method surpasses the performance of conventional two-step approaches, even when the latter utilize ground-truth line segmentation. Furthermore, the proposed approach achieves competitive results compared to state-of-the-art line-level methods on the Rimes and IAM datasets, despite not relying on the sophisticated pre-processing techniques employed by previous methods. 
For decades, state-of-the-art handwriting recognition has adhered to the two-step paradigm, with research efforts primarily focused on improving the individual components. While end-to-end, line-segmentation-free systems have long been desired, they have remained a challenging goal. Recent advancements in deep learning, however, have made such systems feasible. This work aligns with these developments, proposing a unified approach that leverages an attention-based model. The attention mechanism inherently performs line segmentation within the model, offering a natural and intuitive formulation. The experimental results convincingly demonstrate the effectiveness of this approach. 
Given the current trajectory of related research fields, the application of attention-based models to end-to-end paragraph-level handwriting recognition is a logical progression. To the best of my knowledge, this is the first work to successfully implement such a system. The paper is well-written and easy to follow. 
Comments: The paper would benefit from additional explanation regarding why the attention-based model outperforms line-based models that utilize ground-truth line segmentation. Additionally, reporting computational time would provide valuable insights.