The authors present a novel analysis of SVRG, enabling the use of "Option I" (selecting the final iterate of the inner iteration), which aligns with practical implementations. Additionally, they propose employing a scaled version of the Barzilai-Borwein method to determine the step-size for SVRG, and they heuristically argue that this approach could also benefit classic stochastic gradient methods. Their experimental results demonstrate that this adaptive step-size performs competitively with fixed step-sizes. I have updated my score based on the new experiments described in the author response. I previously reviewed this paper for ICML, and I have included relevant excerpts from that review below. However, I will first address the changes and areas that remain unaddressed since the prior review round:
1. The authors have removed most of the misleading statements and added additional references and discussions, which significantly improve the paper.
2. One reviewer previously noted that the quadratic dependence on certain problem constants is weaker than existing results. While I am willing to accept this trade-off because the automatic step-size is a substantial advantage, the paper should explicitly highlight that the theoretical bound is less tight. (This reviewer also remarked that achieving a "bad" rate under Option I is straightforward to establish. However, I agree with the authors that this contribution is novel.)
3. The paper still lacks an empirical comparison with existing heuristics commonly used for step-size tuning. While the SAG line-search is now mentioned in the introduction (and it is worth noting that this approach often outperforms the "best tuned step-size" by increasing the step-size as the solution is approached), there is no experimental comparison provided. Furthermore, the MISO line-search heuristic remains entirely unaddressed. This omission is puzzling: if the proposed method outperforms these existing approaches, including such comparisons would only strengthen the paper. Even if the proposed method achieves similar performance, it would still enhance the paper by demonstrating a theoretically-justified alternative to existing methods. Omitting these comparisons not only constitutes incomplete scholarship but also risks creating the impression that there is something to conceal. (To clarify, I am not suggesting there is anything to hide, but rather emphasizing that including these comparisons has only positive implications for the paper.)
4. A prior reviewer highlighted a severe restriction on the condition number in the earlier submission, which has now been addressed.
---
Comments from the previous review:
Summary:  
The authors provide a new analysis of SVRG, enabling the use of "Option I" (selecting the final iterate of the inner iteration), which is consistent with practical usage. They also propose a scaled version of the Barzilai-Borwein method to determine the step-size for SVRG, and they heuristically suggest that this approach could be beneficial for classic stochastic gradient methods as well. Their experiments indicate that this adaptive step-size is competitive with fixed step-sizes.
Clarity:  
The paper is well-written and easy to follow, though there are still numerous grammatical issues.
Significance:  
While several heuristic adaptive step-size strategies exist in the literature, this is the first method with theoretical justification. It still depends on constants that are generally unknown, but it represents progress toward black-box stochastic gradient methods.
Details:  
Beyond the SVRG/SG contributions, the authors present a useful approach for bounding the step-size in the Barzilai-Borwein method. While BB typically achieves much faster rates than constant step-sizes, the theory and experiments in the SVRG setting only show that it performs as well as the best fixed step-size (which is promising, though not superior to the best step-size).  
The paper would be significantly stronger if it included comparisons with two existing strategies commonly used in practice:  
1. The line-search method of Le Roux et al., which adjusts an estimate of the Lipschitz constant.  
2. The line-search method of Mairal, which empirically determines the optimal step-size.  
That said, I do not expect the proposed method to outperform both of these existing approaches (as these older methods lack theoretical guarantees). However, providing such comparisons would still enhance the paper by situating the proposed method within the broader context of existing techniques.