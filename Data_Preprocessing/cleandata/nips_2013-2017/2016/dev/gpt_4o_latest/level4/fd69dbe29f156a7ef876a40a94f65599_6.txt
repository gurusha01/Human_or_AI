This paper introduces a framework for visual question answering that combines a deep convolutional neural network with a gated recurrent unit. The model is designed to iteratively refine the question representation to generate answers. Rather than processing the entire input image, the approach leverages object proposals to extract multiple candidate regions, focusing on those most relevant to the given question. The paper is well-written and straightforward to understand. The use of region proposals, inspired by object detection techniques, appears to be a reasonable strategy for enhancing the performance of visual question answering. 
However, I have the following questions:  
1. The paper asserts that the proposed model can iteratively update the question representation. However, based on Figures 1 and 3, it seems that the question is updated only once. Is the number of iterations equivalent to the number of reasoning layers? Could incorporating a recurrent network within the reasoning layer allow for recursive updates to the question representation and potentially yield better accuracy?  
2. In Table 3, the proposed method outperforms many prior approaches but performs slightly worse than FDA[11] and DMN+[30]. Could the authors provide an explanation for this result on the VQA dataset?