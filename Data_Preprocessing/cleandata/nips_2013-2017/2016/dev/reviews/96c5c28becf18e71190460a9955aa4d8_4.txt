The authors consider learning the thresholds of a drift diffusion model and apply two well known algorithms, REINFORCE and Bayesian optimization to do so. Why do the asymptotic values in Fig.2D and 3D differ, in particular if the Bayes risk has a unique minimum? Optimal thresholds have been considered before and have been found to be time-dependent, e.g. J Drugowitsch et al J Neurosci 2012, S Deneve Frontiers 2012 and Huang et al NIPS 2012. Missing links to actual neural and behavioral data. REINFORCE can obviously be improved using reinforcement comparison for the reinforcement baseline instead of zero, in order to reduce the variance of the gradient estimate.