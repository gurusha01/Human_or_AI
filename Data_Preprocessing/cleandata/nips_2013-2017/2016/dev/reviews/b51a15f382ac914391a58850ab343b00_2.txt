The paper looks at the combinatorial version of partial monitoring games in stochastic settings. Two algorithms are developed based on forced exploration instead of confidence bounds. The first algorithm matches the state of the art distribution-free regret bound with a simpler oracle. The second matches the state of the art distribution-dependent regret bound. Both regret bounds depend on the size of a certain covering of the action set, not on its cardinality. After rebuttal addendum: ------------------------------------ Rev1: Line 249-253: The algorithm for "online ranking with top-1 feedback" was developed for the adversarial setting by the corresponding authors, specifically for the problem of ranking. What we show is that the problem setting can be subsumed in our general CPM setting, and thus, the specific "online ranking" problem can be solved even in stochastic setting, by the algorithm we have given for the general CPM problem. I find this response very confusing, especially the 'even' bit. So let me clarify: the stochastic adversary is less powerful than the oblivious adversary. I agree that you can deduce results for the stochastic instance of the ranking problem. But the existing algorithm was able to deal with oblivious adversaries too, and you are not as far as I can tell. Viewed in this light, this is a limitation of your current approach. I am still interested to know what possible additional benefit (there might be such) you get in return for making the stochastic iid assumption. This would be a matter of comparing bounds in terms of their dependency on the problem parameters. This was a minor comment that I am confident the authors can address. Original: ------------------------------------ This paper addresses an interesting and important problem on the current edge of online learning theory, and improves the dependence on certain relevant parameters (oracle requirement, dependence on action set). It discusses related work in detail, and points out how it relates to existing approaches. I would be happy to see this at NIPS. That said, please do have your manuscript proof-read for English grammatical and style issues. Especially focus on the use of articles 'the/a', plural, and where to place commas. Here are some minor remarks: line 117: S(x) should be S(\thetap^*) line 118: \bar r is used before it is defined in Assumption 1, line 121. line 241. This would be an excellent place for commenting on the possibility of getting all the benefits of the various algorithms combined. What would be required to/currently prevents us from getting an anytime, argmax-oracle algorithm? lines 249-253: It seems that an algorithm for the non-stochastic (i.e. oblivious adversary) case is strictly more powerful/useful than a distribution independent stochastic algorithm. What is the advantage of your stochastic method? Do we get any improved dependencies on the problem parameters from your method? line 305: expectation misses \mathbb