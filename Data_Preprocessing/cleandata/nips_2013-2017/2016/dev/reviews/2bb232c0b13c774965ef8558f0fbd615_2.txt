The paper provides a useful approach to jointly segmenting and transcribing handwritten paragraphs to text. The authors use MDLSTMs to learn 1) the encoding of the input and 2) an attention network that effectively segments each line of text. A Bidirectional-LSTM decoder is trained to output the text corresponding to the concatenation of the encoded sequences. A CTC loss is minimized over the entire paragraph. The paper is a useful progression of previous work extending beyond models that need line segmentation. The model has real-world applicability. Some feedback on how the paper could have been stronger: It would have been useful to have a baseline with just using Convolutional or Affine [5] layers since these would be much simpler to train compared to using MDLSTMs. The complexity of the model will increase if another level of MDLSTMs with CTCs are used to find the paragraph boundaries. While the authors do find improvements over their own baseline and improved performance on the Rimes benchmark, the performance on the IAM benchmark was not an improvement over previous results.