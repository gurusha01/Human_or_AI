This paper proposes a framework based on a deep convolutional neural network and a gated recurrent unit for visual question answering. The proposed model learns to answer questions by iteratively updating question representation. Instead of using the entire input image, they use object proposal to obtain multiple candidate regions and focus on image regions which are highly related to the questions. This paper is well written and easy to follow. The idea to use region proposal is borrowed from object detection, but sounds reasonable to improve the performance of visual question answering. My questions here: 1. This paper claims that the proposed model can iteratively update the questions. But it seems that the questions are only updated once (Figure 1 and 3). Is the number of iterations the same as the number of reasoning layers? Can you use a recurrent network in the reasoning layer to recursively update the question representation and achieve better accuracy? 2. In table 3, the proposed method outperforms many previous methods but is slightly worse than FDA[11] and DMN+[30]. Any explanation to this result on the VQA dataset?