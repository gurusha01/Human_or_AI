Given a single RGB image, the proposed approach tries to estimate its depth image exploiting visual cues. The idea is to let a neural network predict a distribution for high order derivatives of the depth for each patch. These retrieved parametrized distributions (GMMs) are used in a global optimization step to construct the depth map itself. While the paper is well structured and easy to follow until Section 3.1, there are some open questions on the technical side and the motivation behind the proposed steps. motivation ------------ The authors give no reason for chaining these multiple steps despite their experimental results. Why is a specific intermediate GMM representation needed instead of letting a neural network do what it is good for: learning good intermediate representations? Especially fixing the derivative filters of the first network seems an unnecessary restriction. Why not learning them? The approach has also some similarity to using VLAD/FisherVector features as inputs or the more recently proposed NetVLAD neural network architecture. So what is the difference of the presented approach to the ones mentioned? At least, if there is a distribution representation of intermediate values, I would have expected to see some kind of variance estimate of the depth map. Is this possible? That would be a great plus and good motivation for the intermediate distribution representation. technical points ----------------- - L. 123, what about the other clusters? Did the authors use some standard techniques like splitting highly populated clusters to fill negligible clusters? How many clusters are effectively used? All 64? - How does the number of clusters effect the results? - L. 116, isn't this just linear regression, because everything is fixed but \hat{p}. This seems to be more or less just a normalization step. What happens if one directly uses w_i? - L. 129, why this architecture? - What is the entire runtime during the inference phase, because the first part seems to process patches only? - There are no visual comparisons to any other method. It is hard to judge in which parts the algorithm is more robust than others. - L. 227, it is a no-go to let a reader look up used notations by referring to other papers. - The paper doesn't discuss any failure cases. Are there some failure cases the authors are aware of? ----------------- Thanks for addressing all raised questions in the rebuttal. After reading the authors' rebuttal, I uprated my voting.