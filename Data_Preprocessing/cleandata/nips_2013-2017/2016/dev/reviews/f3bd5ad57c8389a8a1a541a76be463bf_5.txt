This paper presents a neural network system that estimates depth from monocular images. The proposed depth estimation system is a cascaded two-stage system. First, the system generates distributions for values of various depth derivatives of different orders, at multiple scales and orientations. Then the system combines these local distributions within a globalization framework. This paper has a clear presentation and strong results in general, however, this submission does not provide sufficient novel ideas. This paper is not strong enough to be a NIPS paper. 1. The proposed system is very similar to Eigen et al and Liu et al. From the qualitative and quantitative improvements, it is not clear whether the improvements are from the different neural network architecture or the proposed algorithm. I would expect to a more fair comparison between the proposed algorithm and Eigen et al. in the same neural networks settings. 2. Fairness in experiments. Liu et al. is based on super-pixels, while this work is based on sliding window approach. Therefore, I would expect to see another baseline, applying CRF on top of the proposed local neural networks. Authors are encouraged to either provide justification of not using this baseline or provide new experiments in the rebuttal. 3. The proposed algorithm is not very well motivated. I am not sure why the two-stage cascaded architecture clears the ambiguity in the predictions in line 42. 4. There are quite a lot of related references in semantic segmentation are missing in this submission. Although they are not directly doing depth estimation, most of them have involved similar architecture like this paper. Authors are strongly encouraged to update with these relevant works.