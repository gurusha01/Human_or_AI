The authors describe a method for training deep, generative models that allow for more information flow and more effective training. They present the Matryoshka network which bears resemblance to LapGANs and ResNets and comprises of a top-down network, a bottom-up network, and a set of merge modules. Merge modules compare the top-down states with the bottom-up module states, choosing a perturbation to minimize reconstruction error. - While the details for specific sections are generally sufficient (such as good use of equations to clarify computations), there is room for improvement in the clarity and flow across different sections and subsections. - Section 2.2 and end of section 2.1 needs to connect the sampling/inference/distributions with the network components in a clearer manner. For example, x (in section 2.2) is never defined to be anything other than a random variable (until line 132, where it is vaguely defined as unknown or known data). How does this variable x relate to the network? - How are the latent variables z initialized? What kind of impact does this initialization have? - Is there a typo on line 71? It says that conv(h, w) is a convolution of the input x with kernel w, but says nothing about h. And, x isn't an input into the conv function. - The qualitative results are quite impressive. - The quantitative results show that the proposed model works better than previous methods, though it is much more complex. - Before diving into the details of individual components of the network, it would be helpful to provide a brief explanation on where the inputs and outputs of the network (and how they are used) are clearly defined. It would be even more helpful if the inputs and outputs of each component of the network (top-down, bottom-up, merge modules) are defined prior to explaining the mechanisms. - I would like to see more analysis on the qualitative results in addition to explanations about quantitative results. - Can you provide more measurements besides NLL? How about reconstruction error? - It would be great to see some qualitative comparisons with previous methods.