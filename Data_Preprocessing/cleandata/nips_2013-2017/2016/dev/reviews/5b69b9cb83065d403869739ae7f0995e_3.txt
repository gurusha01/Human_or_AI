The paper describes a way of jointly training a pair of machine translation systems using monolingual data. This is described as a kind of communication game, but it seems like a variation on the idea of autoencoders (broadly construed). Essentially, we have models of p(X|Y) and p(Y|X) and we train them jointly on independent samples from X (or Y) and we learn to predict a sample X from itself using p(X|Y)p(Y|X). (Hence Y can be seen as a "representation" of X; again, this is construing the autoencoder idea quite broadly). The technical ideas here are relatively simple but it is a neat idea that may actually be quite useful. The experiments suggest that this is a promising direction, although they seem preliminary; there are many natural questions left unanswered. The technical ideas are simple enough to understand, to the point where I felt their explanation was actually rather belabored: the basic idea is repeated in the abstract, on p. 2 (line 47) and p. 3 (line 124). Rather than repeatedly explain this simple idea, I think the paper would have been stronger if it included a more thorough empirical explanation, i.e. showing learning curves, the effects of initializing with various amounts of data, and an analysis of the results: in what respects do systems trained this way improve? It obviously can't be in vocabulary (since the vocabulary of these systems is capped at 30K words). Is it word choice, word order, or something else?