The proposed approach uses ConvNets to predict local depth outputs and applies a globalization to predict a globally consistent depth prediction. The authors use a ConvNet to predict weights for a set coefficients, which are represented via a mixture of Univariate Gaussians. These coefficients are directly related to the depth via a convolution operation with set of kernels. The kernels here are derivatives of a Gaussian. Optimization for the coefficients and depth is done in an alternate fashion: fixing the predicted depth they optimize for the coefficients, then fixing the coefficients they optimize for the depth, and so on. - The approach makes no assumptions about local outputs. Other similar local-global methods like, Chakrabarti et. al [2] impose planarity assumption. Clarity: + The paper structure is good. + Explanations are presented in a simple language. It was understandable. Novelty: + They idea of using ConvNets for local output prediction is new. - The basic idea of making local prediction and harmonising local outputs to get a consistent global estimation is not new. The same idea is used in several papers, including in Chakrabarti et. al. [2]. Therefore, novelty, is quite limited, especially for NIPS standard. Experiments and Test: - The results in the NYU v2 Dataset are NOT superior to state-of the art methods. They are only comparable. Impact: + The idea of using ConvNets in the area (Globalisation of local outputs) could come to light because of this work. This might help other authors experiment the idea to other problems too.