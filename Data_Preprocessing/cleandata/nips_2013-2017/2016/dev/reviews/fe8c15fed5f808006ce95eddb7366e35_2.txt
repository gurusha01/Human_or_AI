The paper presents a hierarchical model for trajectories planning. The authors applied it to basketball (player) trajectory prediction. The gist of the model is to have two policy networks, one called "micro-planner" that computes a distribution on actions a{micro} ~ \pi(s; \theta{micro}), and one called "macro-planner" that computes a distribution on "goals" \pi(s; \theta{macro}). A "goal" g is a sub-region of the court (coarser grain than s) that the player wants to go to. There is then a "transfer function" m that maps g to an attention mask mg (in the space of actions) that is pointwise multiplied (Hadamard product) with the distribution on actions (a{micro}). Both the micro- and macro-planners are trained (through cross-entropy loss) with the other parts frozen, with the labeling being ground truth micro-action labels. The experiments include a visual analysis by humans of the trajectory generated by the planner, and a prediction accuracy benchmark of the different ablations of the model. This is overall a nice paper, quite easy to read, built on an interesting idea of using an attention mechanism to specify sub-goals, but I think that it has a too many technical limitations for inclusion in NIPS as is. Limitations: - The title feels inappropriate, there is no memory as in "memory networks", the only form of memory in the model comes from the GRUs. (Recurrent and) Hierarchical Trajectory Planning Using ConvNets would be OK. - The multi-stage learning, in which the authors train the micro-planner, macro-planner, and attention mechanism individually "freezing the other parts of the network", vs. end-to-end training with the final prediction mg(a), back-propagating both through the attention, the micro-planner and macro-planner. Both training methods should at least be benchmarked. - Using a discrete 17x17 action space vs. using a continuous 2D space, or (in particular) continuous or discretized (r, \theta) polar coordinates is not justified in the article. It seems to me that it makes the training harder than it should. A mean square error on a continuous space (even more so with two components on polar coordinates) would extract more information per training sample as a slight error in direction and/or intensity is not the same as going the opposite direction (which is the case for the current loss). - In the experiments, prediction is limited as all the other players stop moving (page 7 line 209, or watch the supplementary material). I wonder how much of an edge this gives to "random" and some other baselines. This is a concern as it makes it harder to draw conclusions from the experiments. - Table 2. lacks some baselines like "random" and "keep moving in the same direction". The results in table 2 seem to show that training the attention mechanism is not always beneficial... Unclear: - page 5 lines 164-165: "we sub-sampled every 4 frames" vs. line 175 "while sub-sampling at 4Hz". 25Hz / 4 = 6.25 Hz. One or the other, I get the idea, but please specify. - precise that "frames" in section 5 (e.g. page 7 line 208) refer to frames after subsampling. - Phrase "95% statistically significant" better.