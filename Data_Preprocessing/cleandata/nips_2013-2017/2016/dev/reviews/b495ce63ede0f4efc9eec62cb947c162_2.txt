This paper presents a deep learning framework to obtain dense correspondences between a pair of natural images. The framework learns the correspondence map from the data and hence can be applied to both geometric (e.g. appearance change due to pose) as well as semantic correspondence (e.g. body regions across different birds). The key contribution compared to previous approaches include correspondence contrastive loss for efficient training, convolutional spatial transformer for local patch normalization as well as K-nearest neighbor layer for efficient correspondence search between feature vectors from 2 images. Paper is well written and experiments are performed on several relevant datasets with state-of-art results. While there are a few details that can be investigate further, this paper does contain sufficient material to be considered for an oral presentation at NIPS. Comments: [1] Clarification on O(n) vs O(n^2) argument (forward passes)? The O(n^2) forward passes in the related papers are over image patches vs O(n) forward in this paper is over the image. Note the KNN layer in this paper also does O(mn) comparisons. Even in the related works, the features can be computed only once for every patch (forward pass) and the decision layers (last 2-3 layers) can be applied for all pairs. While the proposed framework would be computationally more efficient) in practice) with implicitly better book keeping and fully convolutional nature, I fail to understand how it has better computational complexity. [2] [Occlusions] Paper should include a discussion on how this framework handles occlusions. How the existing loss addresses that for certain point there should be no correspondence in the image (since the corresponding point in the second image is occluded)? During testing, the current metric (PCK curves) only penalizes for mis-registrations and hence occlusion is hope to addressed by choosing the right threshold. [3] References: Relevant reference (available on arxiv). Learning Dense Correspondence via 3D-guided Cycle Consistency. CVPR 2016.