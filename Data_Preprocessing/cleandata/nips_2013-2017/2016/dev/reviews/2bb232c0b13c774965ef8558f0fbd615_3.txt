This paper addresses the problem of end-to-end handwriting recognition at paragraph-level. Conventional approaches consist of two steps: Line segmentation and line recognition. This work unifies the two steps using an attention-based model. The experimental results show that the proposed approach outperforms the conventional two-step approaches even if the conventional approaches use the ground-truth line segmentation. It also shows that the proposed approach provides good results compared to state-of-the-art line-level methods reported on Rimes and IAM datasets even though the proposed approach does not use sophisticated pre-processing methods which were used in the previous methods. The state-of-the-art handwriting recognition has been taking the two-step approach for decades and researchers have been focusing on improving the individual components. End-to-end line-segmentation-free algorithms have been desired but it has been a challenging problem. However, recent advances in deep learning have opened the door to build such systems. This work comes in the context. This work proposes to unify the two steps by using an attention-based model. The attention mechanism is used to do the line segmentation implicitly in the model. The formulation is very natural and makes sense. The experimental results show the effectiveness of the approach. Given the current trends of the related areas, applying attention-based models to the end-to-end paragraph-level handwriting recognition is something expected to be done. As far as I know, this is the first work which actually does it. The paper is well written and easy to understand. Comments: It needs some explanation about why the attention-based model is better than the line-based model with the ground-truth line segmentation. Reporting computational time will be valuable.