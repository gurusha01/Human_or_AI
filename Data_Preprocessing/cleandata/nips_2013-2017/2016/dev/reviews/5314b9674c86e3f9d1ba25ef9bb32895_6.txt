This paper develops an efficient algorithm for classifying images. The authors demonstrate how to adapt the tensor networks optimization algorithms to supervised learning tasks by using matrix product states. The authors first map the very large vectors X into a higher dimensional space via a feature map Φ(x), and then use a decision function f(x)=W×Φ(x) to classify these vectors. Because the feature vector Φ(x) and the weight vector W can be exponentially large or even infinite, the authors proposed a new approach which is different from kernel trick (reference 9). This approach uses a tensor network to approximate the optimal weight vector W (Eq.5) , by extracting information hidden within trained model and exploiting the structure of W, a "sweeping" optimization algorithm is developed (Eq.7) to minimize a quadratic cost function defining the classification task. This paper develops an efficient algorithm for classifying images. The authors demonstrate how to adapt the tensor networks optimization algorithms to supervised learning tasks by using matrix product states. The authors first map the very large vectors X into a higher dimensional space via a feature map Φ(x), and then use a decision function f(x)=W×Φ(x) to classify these vectors. Because the feature vector Φ(x) and the weight vector W can be exponentially large or even infinite, the authors proposed a new approach which is different from kernel trick (reference 9). This approach uses a tensor network to approximate the optimal weight vector W (Eq.5) , by extracting information hidden within trained model and exploiting the structure of W, a "sweeping" optimization algorithm is developed (Eq.7) to minimize a quadratic cost function defining the classification task. Overall, I think this paper is well organized and clearly written; the proposed approach is novel and makes an important contribution to the field of machine learning. It is nice to build a connection between tensor networks and feature selection. However, one major problem of this paper is the experiment part. To demonstrate the effectiveness of the proposed approach, the authors uses one single dataset, i.e., MINST, and achieves less than 1% test set classification error. It would be better if the authors can apply the proposed approach to other widely used dataset in this field and show the results. More importantly, there is a lack of comparison with state-of-the-art learning algorithms and feature selection methods, making it difficult to judge the performance of the proposed approach. I hope the authors can clarify these questions in the rebuttal process. Overall, my opinion for this paper is weak accept.