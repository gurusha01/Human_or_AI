This paper tackle the common problem resulted from CNN training, CNN structure is redundancy in terms of filters, channels, depth, and even filter shapes. In order these redundancy, this paper proposes a structured sparsity learning method to directly learn a compressed structure of CNN by group lasso regularization. The group strategy involves grouping based on channel-wise, filter-wise, shape-wise, and even depth-wise. Experimental results show a notable speed up comparing with the baseline CNN model. The details of the training method is not very clear. The authors seem simply give the optimization objective, and do not discuss the parameter settings. Why the model is trained from weights initialized by the baseline,not from scratch? So it is more likely belong to a fine tune method. The authors discuss different regularization methods by grouping channels, filters, or shape of filters, I wonder if these methods can be combined for further speed up? Or the optimization is the main challenge. Another issue is that, recent CNN structure often adopt filters with size 3 times 3, e.g., VGG-16, ResNet, what is the meaning of shape regularization since it is already highly local.