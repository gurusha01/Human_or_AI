This paper studies the task of energy disaggregation load minotoring. The authors formulated the problem as an integer quadratic programming optimization problem, and then apply standard SDP relaxation and randomized rounding. The theory part of this paper is a bit incremental. My main concern is on the experimental study of this paper: (1) Since the real dataset (REDD) used in this paper is the same as that in Kolter&Johnson (KJ), I took a quick look at the experiments in KJ. It seems that the precision/recall in KJ is much higher (average 87.2%/60.3% over 7 appliances), even higher than the proposed algorithm of this paper (in Table 1). This looks a bit strange to me, or, one of the two results must have issues. (2) There is no comparison on the running time in the experimental study. I feel this comparison is necessary since, as mentioned in the introduction, the goal of this paper is to "develop a scalable, computationally efficient method" I actually don't know how large is the tested dataset, and thus I don't know why solving SDP directly is infeasible here. About related work (second paragraph of intro), there are quite a few paper mentioned in the introduction that are published after 2012 (e.g., Zhong et. al. 2014). It will help to explain why KJ is the state-of-the-art? Minors: -- Line 75, what is the meaning of I{} s{t,i} = s? -- Title of Sec. 6. Why say "Synthetic Data Set"?