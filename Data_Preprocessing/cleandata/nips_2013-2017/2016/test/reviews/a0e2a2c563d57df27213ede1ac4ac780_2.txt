This paper suggests that the sparse and diverse features learned by RRSVM also predicts visual saliency. Experiments were designed to show the correctness of this hypothesis. This paper suggests the sparse and diverse features learned by RRSVM for classification also predicts visual saliency. This idea is interesting and worth in-depth investigation. The paper is well organized and well written. The main drawback is that the authors have not provide significant enough evidence to show the proposed method is better than the simple center bias model. Providing following experiments and comparison could made the paper on a more solid foundation. 1. Use the shuffled AUC (sAUC) criterion [R1, R2] for performance comparison, which is designed for handling center bias. 2. Comparisons with the methods in [R3, R4] could provide stronger evidence. 3. Another way to improve the criterion is to compare the positions of selected regions directly with the eye fixation points with the metric introduced in [R5]. [R1] L. Zhang, M. H. Tong, T. K. Marks, H. Shan, and G. W. Cottrell, "SUN: A Bayesian framework for saliency using natural statistics," J. Vis., vol. 8, no. 7, pp. 1–20, Dec. 2008. [R2] B. W. Tatler, "The central fixation bias in scene viewing: Selecting an optimal viewing position independently of motor biases and image feature distributions," J. Vis., vol. 7, no. 14, pp. 1–17, 2007. [R3] A. Garcia-Diaz, V. Leborán, X. R. Fdez-Vidal, and X. M. Pardo, "On the relationship between optical variability, visual saliency, and eye fixations: A computational approach," J. Vis., vol. 12, no. 6, pp. 1–22, 2012. [R4] C. Xia, F. Qi, G. Shi, "Bottom-up Visual Saliency Estimation with Deep Autoencoder-based Sparse Reconstruction," IEEE Trans. Neural Networks and Learning Systems, 27(6): 1227–1240, June 2016. [R5] A. Borji, H. R. Tavakoli, D. N. Sihite, and L. Itti, "Analysis of scores, datasets, and models in visual saliency prediction," in Proc. 14th IEEE Int. Conf. Comput. Vis., Sydney, VIC, Australia, Dec. 2013, pp. 921–928.