This paper proposes a novel sequence-to-sequence model architecture that processes fixed-size blocks of inputs and generates outputs block-by-block, making it suitable for online tasks like speech recognition. The authors demonstrate that their online model performs comparably to the best-reported offline sequence-to-sequence model on the TIMIT core test set, achieving a phone error rate of 19.8%. 
The paper's strengths include its ability to perform well on online tasks, which is a significant advantage over traditional offline models. Additionally, the model's performance is comparable to state-of-the-art offline models, making it a viable option for real-time applications. However, the paper lacks implementation-specific details, such as the computation of bidirectional features and the value of M used in the experiments, which makes it difficult to reproduce the results.
One potential area of improvement is the exploration of the model's performance as a function of utterance length, which could provide valuable insights into its limitations and potential applications. Furthermore, the results could be improved by using better regularization techniques, acoustic features, and speaker-dependent transforms, as shown in previous studies.
The similarity between the proposed model's alignments and GMM-HMM alignments is an interesting finding, but its significance and impact on the final phone error rate are unclear. The paper could benefit from a more in-depth analysis of this similarity and its implications for the model's performance.
In terms of quality, the paper is technically sound, and the claims are well-supported by experimental results. However, the lack of implementation-specific details and the omission of certain experiments, such as the analysis of utterance length, detract from the paper's overall quality. The paper is well-organized and clearly written, making it easy to follow and understand.
The originality of the paper lies in its proposal of a new sequence-to-sequence model architecture for online tasks, which is a novel combination of familiar techniques. The paper adequately references related work and provides a clear explanation of how the proposed model differs from previous contributions.
The significance of the paper lies in its potential to improve the state of the art in speech recognition, particularly in online tasks. The results demonstrate that the proposed model is a viable option for real-time applications, and the analysis provides valuable insights into its strengths and limitations.
Arguments for acceptance include:
* The paper proposes a novel sequence-to-sequence model architecture for online tasks, which is a significant contribution to the field.
* The model performs comparably to state-of-the-art offline models, making it a viable option for real-time applications.
* The paper provides a clear explanation of the model's architecture and its advantages over traditional offline models.
Arguments against acceptance include:
* The paper lacks implementation-specific details, making it difficult to reproduce the results.
* The analysis of the model's performance as a function of utterance length is omitted, which could provide valuable insights into its limitations and potential applications.
* The significance and impact of the similarity between the proposed model's alignments and GMM-HMM alignments are unclear and require further analysis.
Overall, the paper is well-written, and the proposed model is a significant contribution to the field. However, the lack of implementation-specific details and the omission of certain experiments detract from the paper's overall quality. With some revisions to address these issues, the paper has the potential to be a strong contribution to the field. 
Minor edits are suggested to correct typos, formatting, and notation inconsistencies throughout the paper. Additionally, the authors may consider adding more details about the experimental setup and the hyperparameters used in the experiments to make the results more reproducible.