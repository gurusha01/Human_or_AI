This paper proposes a novel framework for long-range predictions in videos by predicting motion, differing from standard approaches that reconstruct frames explicitly from internal model states. The authors introduce a class of video prediction models that directly use appearance information from previous frames to construct pixel predictions, allowing for conditional input integration. The proposed method uses a deep network to output convolutional filters or affine transformation matrices applied to the current input frame.
The paper is well-motivated and written, with a clear explanation of the proposed approach and its advantages over existing methods. The authors provide a thorough analysis of the limitations of their approach, including the potential for blurry predictions of non-rigid objects. The use of reconstruction loss in pixel space may be a limitation, and alternative losses like GAN-type losses could potentially improve results.
The approach of producing predictions in pixel space is questioned, and predicting compact codes for next frames could be more reasonable and efficient. However, the authors argue that their method is better able to predict future video sequences for multiple steps, even involving objects not seen at training time.
The paper makes a significant contribution to the field of video prediction, with a novel approach that explicitly models pixel motion. The authors provide a thorough evaluation of their method, including comparisons to prior state-of-the-art methods, and demonstrate its effectiveness on a range of datasets, including a new robotic pushing dataset.
The strengths of the paper include its novel approach, thorough evaluation, and clear writing. The weaknesses include the potential for blurry predictions and the use of reconstruction loss in pixel space. However, the authors provide a clear discussion of these limitations and potential future directions for improvement.
Overall, I would argue in favor of accepting this paper, as it makes a significant contribution to the field of video prediction and provides a thorough evaluation of its approach. The paper is well-written and clearly explains the proposed method and its advantages over existing approaches.
Arguments pro acceptance:
* Novel approach to video prediction that explicitly models pixel motion
* Thorough evaluation, including comparisons to prior state-of-the-art methods
* Clear writing and explanation of the proposed method
* Significant contribution to the field of video prediction
Arguments con acceptance:
* Potential for blurry predictions of non-rigid objects
* Use of reconstruction loss in pixel space may be a limitation
* Approach of producing predictions in pixel space may not be the most efficient or reasonable approach.