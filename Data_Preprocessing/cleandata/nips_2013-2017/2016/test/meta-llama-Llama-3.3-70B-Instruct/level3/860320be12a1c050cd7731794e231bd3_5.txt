This paper presents a novel approach to learning Bayesian networks optimally, subject to ancestral constraints. The authors propose a search space for structure learning with non-decomposable scores, called the EC tree, and employ an oracle that optimizes decomposable scores. The paper provides a sound and complete method for pruning the EC tree based on ancestral constraints and shows how the employed oracle can be empowered by passing it decomposable constraints inferred from the non-decomposable ancestral constraints.
The strengths of the paper include its ability to handle non-decomposable constraints, which is a significant challenge in learning Bayesian networks. The authors provide a comprehensive evaluation of their approach, comparing it to ILP-based systems and demonstrating its efficiency and scalability. The paper also highlights the impact of background knowledge on the quality of the learned network, showing that a relatively small number of ancestral constraints can have a significant impact on the accuracy of the learned model.
However, the paper has some weaknesses. The writing is dense and difficult to follow, with excessive use of symbols and definitions. The authors could improve the clarity and readability of the paper by providing more intuitive explanations and using plain language. Additionally, the paper raises some questions about the performance variance and model comparisons, such as the close performance of different models and inconsistent results.
To improve the paper, the authors could consider the following suggestions:
* Remove unnecessary symbols and definitions to improve clarity and readability.
* Use plain language to explain complex concepts and provide more intuitive explanations.
* Summarize important symbols and definitions in a table to help readers quickly understand the notation.
* Address the questions raised about performance variance and model comparisons, such as providing more detailed analysis and discussion of the results.
Overall, the paper presents a significant contribution to the field of Bayesian network learning and provides a novel approach to handling non-decomposable constraints. With some revisions to improve clarity and readability, the paper has the potential to be a strong contribution to the field.
Arguments pro acceptance:
* The paper presents a novel approach to learning Bayesian networks optimally, subject to ancestral constraints.
* The authors provide a comprehensive evaluation of their approach, comparing it to ILP-based systems and demonstrating its efficiency and scalability.
* The paper highlights the impact of background knowledge on the quality of the learned network, showing that a relatively small number of ancestral constraints can have a significant impact on the accuracy of the learned model.
Arguments con acceptance:
* The writing is dense and difficult to follow, with excessive use of symbols and definitions.
* The paper raises some questions about the performance variance and model comparisons, such as the close performance of different models and inconsistent results.
* The authors could improve the clarity and readability of the paper by providing more intuitive explanations and using plain language.