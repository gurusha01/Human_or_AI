This paper proposes a novel approach to studying the dynamic regret of multi-armed bandit and experts problems in non-stationary stochastic environments. The authors introduce a new parameter Λ, which measures the total statistical variance of the loss distributions over time, and investigate its impact on the regret bounds. The paper provides a comprehensive analysis of the tradeoff between Λ and other parameters, including Γ (the number of times the distributions change) and V (the total drift of the distributions).
The paper's main strengths lie in its thorough theoretical analysis and the provision of matching upper and lower bounds for the regret. The authors propose several algorithms, including a parameter-dependent bandit algorithm and a full-information algorithm, which achieve near-optimal regret bounds. The paper also presents a parameter-free full-information algorithm, which is a significant contribution to the field.
However, the paper's write-up is convoluted and requires multiple reads to understand, with some notation and assumptions needing clarification. Additionally, the feature selection experiments are less impressive due to the comparison with a random feature selection method, which is not a strong baseline.
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The authors are careful and honest about evaluating both the strengths and weaknesses of their work.
The originality of the paper lies in its novel approach to studying dynamic regret and the introduction of the new parameter Λ. The paper provides a unique combination of familiar techniques, and the authors adequately reference related work.
The significance of the paper is evident in its potential to advance the state of the art in online learning and decision-making. The results have important implications for practitioners and researchers, and the paper provides a valuable contribution to the field.
Arguments for acceptance:
* The paper provides a comprehensive and thorough analysis of the dynamic regret in non-stationary stochastic environments.
* The introduction of the new parameter Λ and the investigation of its impact on the regret bounds is a significant contribution to the field.
* The paper presents matching upper and lower bounds for the regret, which is a rare and valuable achievement.
* The authors propose several algorithms, including a parameter-free full-information algorithm, which is a significant contribution to the field.
Arguments against acceptance:
* The paper's write-up is convoluted and requires multiple reads to understand.
* The feature selection experiments are less impressive due to the comparison with a random feature selection method.
* Some notation and assumptions need clarification.
Overall, I recommend accepting this paper due to its significant contributions to the field, thorough analysis, and well-supported claims. However, the authors should be encouraged to revise the paper to improve its clarity and address the minor issues mentioned above.