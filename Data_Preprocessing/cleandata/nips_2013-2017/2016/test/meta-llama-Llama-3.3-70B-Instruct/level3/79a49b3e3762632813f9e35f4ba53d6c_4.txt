This paper presents a Bayesian classification routine for estimating positive-only labels from noisy and high-dimensional data. The approach builds upon previous work in the field, addressing the limitations of existing algorithms that often perform poorly on real-world data. The authors propose two practical classification algorithms that model noise in positive labels and utilize univariate transforms based on discriminative classifiers. Theoretically, the approach is sound, providing important properties such as preservation of class prior, which enables estimation in the univariate space and avoids kernel density estimation for high-dimensional data.
The paper's strengths lie in its robustness to noise and effectiveness for high-dimensional data, with both theoretical justification and some empirical evidence. The authors are commended for presenting a balanced view of their results, showcasing both dominant and non-dominant performances. The proposed technique performs well in some cases, winning 19 out of 36 times and being significant 12 of those times. However, it is also significantly beaten 11 times, highlighting the need for further improvement.
A major weakness of the paper is the lack of practical assessment on how the algorithm scales up with large datasets, including computation time and susceptibility to the curse of dimensionality. This is a critical issue that requires more detailed analysis, as the approach may not be ideal for large data. Despite this limitation, the paper contributes to the state of the art in robust classification algorithms for positive-unlabeled data, providing a novel combination of familiar techniques.
In terms of quality, the paper is technically sound, with well-supported claims and careful evaluation of both strengths and weaknesses. The writing is clear, and the organization is good, making it easy to follow. The originality of the approach is evident, with a novel combination of techniques and adequate referencing of related work. The significance of the results is also notable, as the paper addresses a difficult problem in a better way than previous research, providing a unique theoretical and pragmatic approach. Overall, the paper is a good scientific contribution to the field, and with further work on scalability, it has the potential to make a significant impact. 
Arguments pro acceptance: 
- The paper presents a novel and theoretically sound approach to robust classification for positive-unlabeled data.
- The authors provide a balanced view of their results, showcasing both strengths and weaknesses.
- The approach is effective for high-dimensional data and robust to noise.
Arguments con acceptance: 
- The paper lacks a practical assessment of the algorithm's scalability with large datasets.
- The approach may not be ideal for large data, which could limit its applicability.
- The performance is inconsistent in certain comparisons, which requires further improvement.