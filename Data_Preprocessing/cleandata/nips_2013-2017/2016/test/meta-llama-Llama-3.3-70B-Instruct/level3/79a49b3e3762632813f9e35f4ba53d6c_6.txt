This paper presents a classification algorithm for estimating posterior distributions from positive-unlabeled data, with a focus on robustness to noise in the positive labels and effectiveness for high-dimensional data. The authors build on previous work to develop two practical classification algorithms that explicitly model the noise in the positive labels and utilize univariate transforms built on discriminative classifiers. The paper provides both nonparametric and parametric approaches, and the authors prove that the univariate transforms preserve the class prior, enabling estimation in the univariate space and avoiding kernel density estimation for high-dimensional data.
The paper is well-written and easy to follow, with a clear explanation of the technical results. The authors provide a solid foundation for their work, and the theoretical development is sound. However, upon closer inspection, it becomes apparent that the paper is a minor extension of a previous work by the same authors, with overlapping theoretical results and a similar algorithmic contribution. This raises concerns about the originality and significance of the paper.
The simulations presented in the paper use standard UCI datasets with added noise, rather than real-world datasets that could strengthen the paper's motivations and applications. This limitation may not provide a comprehensive evaluation of the algorithm's performance in real-world scenarios. Furthermore, the paper's lack of new and interesting material may not warrant publication in a top conference like NIPS, in my personal opinion.
To improve the paper, I suggest adding figures to clarify the technical results, obtaining more theoretical results for the AlphaMax-N algorithm, and making the code available for others to use. Additionally, the authors could consider using real-world datasets to demonstrate the algorithm's effectiveness in practical scenarios. Overall, while the paper is technically sound and well-written, its limited originality and significance may not make it a strong candidate for publication in NIPS.
Arguments pro acceptance:
* The paper is well-written and easy to follow
* The theoretical development is sound
* The authors provide a solid foundation for their work
Arguments con acceptance:
* The paper is a minor extension of a previous work by the same authors
* The simulations use standard UCI datasets with added noise, rather than real-world datasets
* The paper's lack of new and interesting material may not warrant publication in a top conference like NIPS.