The authors propose a novel semi-supervised approach that leverages the intrinsic consistency of the data to guide the learning process of a machine. Unlike conventional learning methods, which solely focus on the discrepancy between the desired and actual outputs, this work also exploits the property that, in classification tasks, the output should remain consistent despite variations in the inputs and the learning machine itself. In essence, the machine's ultimate objective is to identify the invariances that maximize recognition accuracy. The paper is well-structured and clearly explained, with a core concept that is both intuitive and innovative, capitalizing on previously underutilized information in the data. This enables the authors to achieve remarkable results using limited labeled datasets and large unlabeled ones. This research contributes to the growing understanding of machine learning as a process of discovering invariances, as highlighted in the "Deep Symmetry Networks" paper by Gens and Domingos. Minor suggestion: 1. Consider providing a clear definition for the index i in equation (1) to enhance clarity.