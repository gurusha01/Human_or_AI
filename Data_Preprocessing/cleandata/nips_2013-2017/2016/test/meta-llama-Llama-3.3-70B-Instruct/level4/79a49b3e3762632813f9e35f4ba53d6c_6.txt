This paper proposes methods for estimating the parameters $\alpha$ and $\beta$ in a mixture model, where two distributions are combined with different mixing coefficients: $\mu = \alpha \mu1 + (1-\alpha) \mu0$ and $\nu = \beta \mu1 + (1-\beta) \mu0$. The application of interest is PU-learning, where $\mu1$ represents the density of positive samples, $\mu0$ represents the density of negative samples, $\mu$ is the density of unlabeled samples, and $\nu$ is the density of positive-labeled samples with a $1-\beta$ probability of error. The authors present both nonparametric and parametric approaches, which are evaluated through simulations. 
The strengths of this paper include addressing an important problem and providing a solution, as well as being well-written and solid in its presentation. However, a major concern is that this work appears to be a relatively minor extension of a previous paper by the same authors, [1]. Specifically, the theoretical results show significant overlap, and the primary algorithmic contribution, AlphaMax-N, is a minor variation of the AlphaMax algorithm from [1]. Additionally, the parametric algorithm MSGMM-T is not competitive in most cases, and the simulations utilize the same UCI datasets with added noise. 
To clarify the novelty of this work, it would be beneficial for the authors to explicitly identify which components are new and which are closely related to or reformulations of results from [1]. Furthermore, while the paper discusses various real-world motivations, such as Facebook likes and learning certain protein interactions, it does not utilize a relevant dataset in the simulations, instead relying on standard UCI datasets. If this problem indeed has numerous important applications, it should be feasible to obtain a suitable dataset, which would strengthen the paper.
In my opinion, this is a decent paper, but it lacks sufficient new and interesting material to warrant publication in a top conference like NIPS. Some suggestions for improvement include: 
1. Enhancing the clarity of Section 3 by adding figures that illustrate mixtures of simple distributions, making the technical results more intuitive and accessible. 
2. Deriving additional theoretical results for the AlphaMax-N algorithm, such as analyzing how the error in estimating the mixing proportions decreases as the sample size increases, potentially under certain strong conditions. 
3. Making the code available for others to use, promoting reproducibility and further research. 
Overall, while this paper has some merits, its lack of significant new contributions and limited evaluation with real-world datasets are notable drawbacks.