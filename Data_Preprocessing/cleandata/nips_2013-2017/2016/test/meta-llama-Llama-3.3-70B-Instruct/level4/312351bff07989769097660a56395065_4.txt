This manuscript presents an online sequence-to-sequence framework that generates output incrementally while processing input sequence blocks, leveraging a conventional sequence-to-sequence model with additional state retention from preceding blocks. The sequence alignment is approximated using a dynamic programming approach with a greedy local search heuristic. The authors provide experimental results on phone recognition using the TIMIT dataset. The proposed incremental transducer represents a logical extension of traditional sequence-to-sequence models, and the experimental results on TIMIT suggest its effective optimizability. It is likely that this model, or its future variants, will have numerous applications in data stream processing. One minor suggestion for improvement: the presentation of data in the two tables in section 4.2, each with only two rows, appears somewhat simplistic; a more effective visualization method may be warranted. Additionally, it is noted that the first column of table 2 is empty, which could be revised for better clarity.