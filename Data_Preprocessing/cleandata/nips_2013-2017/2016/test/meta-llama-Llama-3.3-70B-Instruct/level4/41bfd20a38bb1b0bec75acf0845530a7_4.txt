This paper addresses the prevalent issue of redundancy in CNN architectures, specifically in terms of filters, channels, depth, and filter shapes. To mitigate this redundancy, the authors propose a structured sparsity learning approach, utilizing group lasso regularization to directly learn a compressed CNN structure. The grouping strategy encompasses various dimensions, including channel-wise, filter-wise, shape-wise, and depth-wise. The experimental results demonstrate a significant speedup compared to the baseline CNN model. However, the training methodology lacks clarity, with the authors only providing the optimization objective without discussing parameter settings. It is unclear why the model is initialized with weights from the baseline rather than being trained from scratch, which suggests that this approach may be more akin to fine-tuning. The discussion of different regularization methods, including channel, filter, and shape-based grouping, raises questions about the potential for combining these methods to achieve further speedups, and whether optimization is the primary challenge. Furthermore, given the widespread adoption of 3x3 filters in modern CNN architectures, such as VGG-16 and ResNet, the relevance of shape regularization in these highly localized contexts is questionable.