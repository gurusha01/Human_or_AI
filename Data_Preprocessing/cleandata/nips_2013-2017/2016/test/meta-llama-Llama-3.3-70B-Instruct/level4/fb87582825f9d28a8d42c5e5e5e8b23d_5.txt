The authors explore the application of recurrent neural networks to learn optimal update strategies in first-order optimization, effectively replacing traditional hand-designed strategies like steepest descent with outputs from recurrent networks. Their approach utilizes one LSTM per coordinate, with two variants that yield negligible improvements in experimental results compared to the basic model, which incorporates global averaging of certain LSTM cells and a read/write mechanism to an external memory. Through three case studies, they demonstrate the network's ability to outperform select first-order strategies, such as ADAM, and exhibit limited generalization to similar problem classes. The benchmarks employed include optimizing unregularized linear least-squares, fitting a neural network to the MNIST dataset, and solving optimization problems in artistic style transfer, which combines two distinct images. Conceptually, the paper's idea is intriguing, straightforward, and ripe with possibilities, making it a strong candidate for the NIPS conference. However, from a practical standpoint, the current implementation is challenging to justify due to significant drawbacks. First-order optimization algorithms boast two primary advantages: broad applicability to (sub)differentiable problems and low implementation costs once gradients are known. In contrast, the proposed approach sacrifices these benefits, requiring retraining for even minor problem changes, incurring substantial training costs, and potentially significant memory and time overhead from executing multiple LSTM networks. This raises questions about the rationale for choosing a simple first-order procedure over second-order techniques when considerable computational resources are available. The method shows promise, particularly for scenarios involving repeated solutions to the same optimization problem, potentially leading to interesting applications beyond machine learning. Notably, the experiment involving neural network training is, in this reviewer's opinion, the least convincing of the three presented.