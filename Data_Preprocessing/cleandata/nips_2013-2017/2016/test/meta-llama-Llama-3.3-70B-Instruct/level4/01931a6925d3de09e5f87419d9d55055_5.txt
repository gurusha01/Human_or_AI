Summary: This paper introduces a locally adaptive normal distribution that utilizes a geodesic manifold traversal distance, which is learned from the data, replacing the traditional Mahalanobis distance in Gaussian distributions. An extension to a mixture of these distributions is also presented. The method's performance is assessed using both synthetic and real-world EEG measurement datasets. 
Major comments: The concept of employing a geodesic distance, akin to Isomaps, is intriguing. However, the paper suffers from clarity issues. Notably, the definition of the inverse of the metric tensor in Equation (7) appears arbitrary, and the authors should provide a clearer rationale for using a Gaussian kernel for weighting local covariances in a weighted sum. Furthermore, there seems to be a discrepancy between the definition of the local covariance matrix in Equation (7) and its later MAP estimation in Equation (11), which requires clarification on whether these refer to the same entity. The experimental evaluations are somewhat lacking, but a significant concern lies in the method's scalability and computational efficiency. Specifically, the computational complexity and running time in comparison to standard Expectation-Maximization (EM) algorithms need to be addressed. In essence, while the paper offers an interesting theoretical contribution, its practical applicability may be limited.
Minor comments: In Algorithm 1, lines 4 and 5 should be corrected to reflect \( \nabla \) instead of \( d \).