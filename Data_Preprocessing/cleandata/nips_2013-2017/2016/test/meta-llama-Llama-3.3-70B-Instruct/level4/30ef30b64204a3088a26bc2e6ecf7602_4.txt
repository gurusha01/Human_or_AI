This paper revolves around the concept that a robust model should yield consistent predictions under various random transformations of the data or perturbations of the model itself, given any training sample. The authors introduce a novel unsupervised loss function, termed transformation or stability loss, designed to minimize the sum of squared differences between predictions obtained from multiple passes of the same sample through the model. This loss function is combined with another unsupervised loss, the mutual-exclusivity loss, and the authors demonstrate through several experiments that semi-supervised training, utilizing these unsupervised losses alongside a supervised loss, leads to improved model performance when labeled data is scarce. The efficacy of this approach is showcased on a range of datasets including MNIST, CIFAR10, CIFAR100, SVHN, NORB, and ILSVRC. The paper presents a logical and straightforward methodology for leveraging unlabeled data in the training of deep convolutional networks, achieving notable results on benchmark datasets, including state-of-the-art performance on CIFAR10 and CIFAR100. However, the significant gap between their results on ImageNet and the current state-of-the-art raises questions about the applicability of this method in settings with abundant training data, or if its benefits are confined to scenarios with limited labeled data. The paper's clarity and readability are commendable, although some aspects require clarification. Specifically, in Section 4.2 regarding SVHN, the experimental setup involving sparse convolutional networks is unclear. The description mentions creating five sets of labeled data and randomly selecting a different 1% subset of training samples for each set. It is ambiguous whether this 1% subset is used as labeled examples while the remainder serves as unlabeled examples, and if the results in Table 2 are averaged across these sets. Furthermore, the inconsistent application of data augmentation throughout the experiments warrants explanation.