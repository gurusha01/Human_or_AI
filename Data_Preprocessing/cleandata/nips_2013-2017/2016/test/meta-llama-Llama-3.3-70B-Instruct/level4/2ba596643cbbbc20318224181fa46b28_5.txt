This manuscript presents a variation of the traditional stochastic K-armed bandit problem, where low-cost approximations for each arm are accessible. The authors conceptualize this as a multi-fidelity bandit problem and derive theoretical regret bounds. To illustrate the impact of multi-fidelity, simulation experiments are conducted. The paper's presentation is clear and concise. The simulation results effectively demonstrate the efficacy of the multi-fidelity bandit approach. Furthermore, the authors provide comprehensive theoretical analysis of the lower bound for the proposed method, thereby establishing its theoretical superiority.