This paper explores unsupervised learning for predicting outcomes from physical interactions, focusing on motion prediction of pixels rather than their actual values. It builds upon convolutional LSTM and introduces three predictive models: DNA, CDNA, and STP. These are evaluated on a large-scale physical interaction dataset and the Human3.6M dataset, with quantitative comparisons to existing methods [14,17]. 
The clarity of the paper is commendable, with clear and well-organized discussions of relevant literature. However, the presentation could be enhanced by including visualizations of the DNA and STP architectures, in addition to the CDNA architecture, potentially in Figure 1 or the supplementary materials. The supplementary materials provide valuable insights with video results and masks.
The method presented achieves state-of-the-art results, although the predicted frames exhibit blur artifacts and lack detail. Notably, the masks appear to lack temporal coherence, raising questions about the dependency between frame predictions and the potential for improvement by imposing temporal consistency. Furthermore, treating the collection of motion transformations as a backward optical flow field and introducing priors to encourage spatial smoothness could be a fruitful direction for future work.
In conclusion, the paper is well-written, presents solid results, and offers a novel approach to predicting future frames from physical interactions. Its contributions are significant and beneficial to the scientific community, making it a valuable addition to the field.