The authors introduce a novel sequence-to-sequence model architecture that utilizes fixed-size input blocks, processed by an encoder RNN, to generate outputs block-by-block through a transducer RNN. The transducer RNN receives inputs from the encoder RNN and maintains its state across blocks via recurrent connections, making it suitable for online tasks such as speech recognition, which requires incremental predictions as data becomes available. This paper is well-written, and the concept of employing a blocked transducer is innovative. The proposed online model achieves comparable performance (19.8% PER) to the best-reported offline sequence-to-sequence model (17.6% PER) on the TIMIT core test set, without relying on extensively trained models. Given that this model is designed to address attention issues affecting long utterances in sequence-to-sequence models, it would be intriguing to investigate how the proposed model's performance varies with utterance length. To accommodate this experiment, the additional toy task could be omitted without disrupting the narrative flow. A few implementation-specific details are missing, which would be beneficial for readers to know: 
* In the comparison model (with a PER of 18.7%) using a bidirectional encoder, were bidirectional features computed after the end of an input block or the entire utterance? The latter would imply that the model is no longer offline, and this should be clarified in the write-up.
* What value of M was used in the experiments? (M appears in the DP algorithm used to compute alignments during training.) What beam search width was used during inference? As the authors mention, the results reported in Table 2 could be improved by employing better regularization techniques. Another potential approach to enhance model performance is using better acoustic features, such as speaker-dependent transforms, as demonstrated by Lu et al., "Segmental Recurrent Neural Networks for End-to-end Speech Recognition", Interspeech 2016, which achieved significant PER improvements on TIMIT. When the authors state that the proposed model's alignments are similar to GMM-HMM alignments, do they mean this in terms of per-frame phone error rates? Although the models benefited from using GMM-HMM alignments, as evidenced by the final PER numbers (19.8% vs 20.8%), it is unclear what this can be attributed to if the alignments were very similar. Some minor edits are suggested: 
— pg.3, correct the typo in "compute the probability of 1 compute" 
— pg.4, change "is in computed in" to "is computed in" 
— pg.8, correct "showed that is can" to "showed that it can" 
— use a single operator for argmax, rather than "arg max", in Eqn 12 
— use \mathrm for the softmax function in Eqn 8.