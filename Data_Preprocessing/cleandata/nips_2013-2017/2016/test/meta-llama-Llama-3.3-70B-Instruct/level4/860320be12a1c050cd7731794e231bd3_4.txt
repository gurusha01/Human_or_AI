This paper presents a trio of complexity measures tailored for recurrent neural networks, comprising recurrent depth, feedforward depth, and recurrent skip coefficients. The authors conduct an empirical evaluation of these measures through experiments on a range of applications, including parsing, language modeling, program modeling, and image modeling. In my opinion, the paper offers a valuable assessment of how these complexity measures impact performance in various tasks, yielding insights that are highly relevant and beneficial to the research community.