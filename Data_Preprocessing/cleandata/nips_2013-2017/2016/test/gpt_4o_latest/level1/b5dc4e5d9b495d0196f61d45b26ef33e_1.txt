The paper presents a novel Homotopy Smoothing (HOPS) algorithm for solving a class of structured non-smooth optimization problems. The authors address problems composed of a non-smooth term with explicit max-structure and a smooth or simple non-smooth term with easy-to-compute proximal mappings. The key contribution is the reduction of iteration complexity from the best-known \(O(1/\epsilon)\) to \(\tilde{O}(1/\epsilon^{1-\theta})\), where \(\theta \in (0, 1]\) captures the local sharpness of the objective function. By employing a homotopy strategy, HOPS gradually reduces the smoothing parameter in stages, leveraging warm-start techniques to achieve faster convergence. The paper rigorously analyzes the algorithm's theoretical guarantees and demonstrates its linear convergence for several well-known non-smooth problems, such as empirical risk minimization and cone programming. Experimental results further validate the algorithm's superior performance compared to Nesterov's smoothing and primal-dual methods.
Strengths
1. Technical Novelty: The introduction of a homotopy strategy to reduce the smoothing parameter in stages is a significant innovation. This approach improves upon existing methods by achieving a lower iteration complexity under mild local error bound conditions.
2. Theoretical Rigor: The paper provides a thorough theoretical analysis, including proofs of convergence and iteration complexity. The connection to local error bounds and the Kurdyka-≈Åojasiewicz property is well-established and broadens the applicability of the method.
3. Practical Relevance: The algorithm is applicable to a wide range of problems in machine learning, statistics, and optimization, such as hinge loss minimization and image denoising. This demonstrates the method's versatility.
4. Experimental Validation: The experiments convincingly show that HOPS and its primal-dual variant (PD-HOPS) outperform state-of-the-art methods in terms of both iteration count and runtime, especially for small \(\epsilon\).
Weaknesses
1. Clarity: While the paper is technically sound, some sections, particularly the theoretical analysis, are dense and could benefit from clearer explanations or visual aids to improve accessibility for a broader audience.
2. Comparison Scope: The experimental evaluation, though thorough, could include a broader range of baselines, such as more recent primal-dual or homotopy-based methods, to strengthen the empirical claims.
3. Practical Implementation: The dependence of the algorithm on parameters like the local sharpness constant \(\theta\) and the unknown constant \(c\) may limit its practical applicability. While the authors propose PD-HOPS to address this, further discussion on parameter tuning would be helpful.
Arguments for Acceptance
- The paper introduces a novel and theoretically grounded algorithm that advances the state of the art in non-smooth optimization.
- The method is broadly applicable and demonstrates strong empirical performance across diverse tasks.
- The theoretical contributions, particularly the improved iteration complexity and connection to local error bounds, are significant and relevant to the NIPS community.
Arguments Against Acceptance
- The paper's presentation could be improved to make the technical content more accessible.
- The experimental evaluation, while strong, could include more baselines for a comprehensive comparison.
Recommendation
I recommend acceptance of this paper. It makes a substantial contribution to the field of optimization by introducing a novel algorithm with both theoretical and practical significance. Minor revisions to improve clarity and expand experimental comparisons would further strengthen the paper.