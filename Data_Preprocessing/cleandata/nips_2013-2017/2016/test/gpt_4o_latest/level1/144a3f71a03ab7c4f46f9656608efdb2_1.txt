The paper addresses the problem of learning Bayesian networks (BNs) optimally under ancestral constraints, which are non-decomposable and thus challenging for traditional structure learning approaches that rely on decomposable scores. The authors build upon the framework introduced by Chen et al. (2015, 2016) for optimal structure learning with non-decomposable scores and propose a novel method to incorporate ancestral constraints. Their approach involves inferring decomposable constraints from ancestral ones, enabling the use of oracles designed for decomposable scores. Empirical results demonstrate that the proposed method is orders-of-magnitude more efficient than existing frameworks, such as those based on integer linear programming (ILP).
Strengths
1. Technical Contribution: The paper makes a significant contribution by addressing a critical limitation in existing BN structure learning methods. The proposed technique of projecting non-decomposable ancestral constraints into decomposable ones is both novel and impactful.
2. Empirical Validation: The authors provide thorough empirical evaluations, comparing their approach to ILP-based methods and demonstrating substantial efficiency gains. The experiments are well-designed, varying key parameters like dataset size, number of variables, and proportion of constraints, which adds robustness to the findings.
3. Scalability: The method scales well to problems with up to 20 variables, which is comparable to state-of-the-art approaches for Bayesian network learning. The easy-hard-easy trend observed in the experiments is insightful and aligns with theoretical expectations.
4. Practical Significance: The results highlight the utility of incorporating background knowledge (ancestral constraints) in improving learning efficiency and accuracy, which is valuable for real-world applications where data collection can be expensive.
Weaknesses
1. Clarity: While the paper is technically sound, it is dense and challenging to follow in parts. The detailed theoretical discussions, particularly around projecting constraints and the MaxSAT formulation, could benefit from additional examples or visual aids to improve accessibility.
2. Comparison to Related Work: Although the authors compare their method to ILP-based approaches, the discussion of alternative methods (e.g., constraint-based approaches like PC or greedy search methods) is limited. This omission leaves some questions about the broader applicability of the proposed method.
3. Generality: The method is tailored to ancestral constraints, but it is unclear how well it generalizes to other types of non-decomposable constraints. A discussion on this aspect would strengthen the paper's contribution.
Arguments for Acceptance
- The paper addresses a well-motivated and challenging problem in Bayesian network learning.
- The proposed method is both novel and technically sound, with significant empirical improvements over existing approaches.
- The work has practical implications for improving learning efficiency and accuracy in real-world scenarios.
Arguments Against Acceptance
- The paper's clarity could be improved, particularly for readers less familiar with the technical details of Bayesian network learning.
- The evaluation could include a broader comparison to other learning paradigms, such as heuristic-based methods or constraint-based approaches.
Recommendation
Overall, this paper represents a strong contribution to the field of Bayesian network learning and is well-suited for presentation at NeurIPS. While some aspects of clarity and scope could be improved, the technical novelty and empirical results outweigh these concerns. I recommend acceptance, with minor revisions to improve readability and contextualization.