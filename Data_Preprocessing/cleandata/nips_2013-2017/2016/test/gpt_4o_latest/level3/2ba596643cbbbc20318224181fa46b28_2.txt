This paper introduces a novel multi-armed bandit (MAB) setting where each arm can be played at multiple fidelities, with higher fidelities offering more accurate but costlier outcomes. The authors define a new cost-regret metric that combines the cost of playing an arm with the pseudo-regret, making the problem particularly relevant for real-world applications like online advertising and algorithm selection. The proposed MF-UCB algorithm builds on the classical UCB framework, adapting it to the multi-fidelity setting. The authors provide theoretical guarantees, including upper and lower bounds on cumulative pseudo-regret, and demonstrate the algorithm's near-optimality under certain conditions.
Strengths:
1. Novelty and Theoretical Contribution: The paper presents a new formalism for multi-fidelity bandits, addressing a practical and underexplored problem in the MAB literature. The theoretical analysis is rigorous, with well-crafted proofs and interesting theorems that provide valuable insights into the behavior of MF-UCB.
2. Algorithm Design: MF-UCB is a thoughtful extension of UCB, leveraging lower fidelities to eliminate suboptimal arms efficiently and reserving higher fidelities for promising candidates. This approach is intuitive and aligns well with the cost-regret objective.
3. Comparison with UCB: The paper demonstrates that MF-UCB achieves better regret than naive UCB strategies by effectively utilizing the multi-fidelity structure, especially when the number of arms is large and the set of near-optimal arms is small.
4. Empirical Validation: Simulations on synthetic problems corroborate the theoretical results, showing that MF-UCB outperforms UCB in terms of both regret and computational efficiency.
Weaknesses:
1. Clarity in Supplementary Materials: While the main paper is well-written, the supplementary materials suffer from numerous typos, missing terms, and incorrect symbols. These issues detract from the overall readability and could hinder reproducibility.
2. Proof Issues: Minor errors in the supplementary proofs, such as missing terms and inconsistent notation, need to be addressed to improve clarity and rigor.
3. Practical Applicability: The practicality of MF-UCB is somewhat unclear, particularly in scenarios where fidelity estimation (\(\zeta\)) is inaccurate. A discussion on how to handle such inaccuracies would strengthen the paper.
4. Constants in Analysis: The use of "up-to-a-multiplicative-constant" signs can be misleading, as hidden parameters (e.g., \(\rho\)) significantly influence the results. A more explicit treatment of these constants would enhance transparency.
Arguments for Acceptance:
- The paper addresses a novel and practical problem, making a significant theoretical contribution to the MAB literature.
- The proposed MF-UCB algorithm is well-designed and supported by rigorous analysis and empirical evidence.
- The work is relevant to real-world applications, such as online advertising and algorithm selection, where multi-fidelity evaluations are common.
Arguments Against Acceptance:
- The supplementary materials require substantial revision to fix typos and improve clarity.
- The paper lacks a detailed discussion of the practical limitations of MF-UCB, such as inaccurate fidelity estimates or scalability to large-scale problems.
Overall Assessment:
This paper makes a significant and interesting contribution to the field of multi-armed bandits by introducing a novel multi-fidelity setting and proposing an effective algorithm with strong theoretical guarantees. Despite minor issues in the supplementary materials and some gaps in practical applicability, the work is of high quality and relevance. I recommend acceptance, provided the authors address the identified weaknesses, particularly the clarity and correctness of the supplementary proofs and a discussion of practical limitations.