The paper addresses the novel problem of incorporating ancestral constraints into optimal Bayesian network learning, proposing a method that translates these non-decomposable constraints into decomposable ordering constraints using a MaxSAT solver. The authors demonstrate how this approach integrates ancestral constraints into the EC tree search space, enabling efficient pruning and leveraging inferred decomposable constraints to empower the oracle used in the search. Empirical results show significant improvements in efficiency compared to ILP-based methods like Gobnilp, particularly as the problem scales.
Strengths:
1. Core Contribution: The paper introduces a novel framework for handling ancestral constraints in Bayesian network learning, a problem that has not been extensively studied. By translating non-decomposable constraints into decomposable ones, the method bridges a gap in existing approaches, which are typically limited to decomposable scores.
2. Algorithmic Innovation: The use of a MaxSAT solver to infer ordering constraints from ancestral constraints is a creative and technically sound solution. The approach ensures that all implied constraints are explicit, enhancing the efficiency of the search process.
3. Empirical Performance: The proposed method outperforms Gobnilp by orders of magnitude in most scenarios, showcasing its computational efficiency. The results highlight the practical benefits of leveraging inferred constraints to reduce the search space.
4. Clarity: The paper is well-organized and provides a clear explanation of the technical details, including theorems and empirical evaluation. The inclusion of detailed experiments adds credibility to the claims.
Weaknesses:
1. Artificial Problem Setting: While the problem is novel, the setting appears somewhat contrived. In real-world applications, causal discovery algorithms might be more suitable for incorporating background knowledge, limiting the practical relevance of the proposed approach.
2. Sparse Constraints: The paper acknowledges that ancestral constraints are typically sparse in practice, which may not significantly reduce the search space. This limits the broader impact of the method.
3. Theoretical Concerns: The rules for translating constraints, such as acyclicity rules, appear incomplete or inconsistent in certain cases. This raises questions about the general applicability of the method.
4. Alternative Benchmarks: The comparison with Gobnilp, while favorable, is less meaningful since Gobnilp is not specifically designed for this problem. A comparison with a greedy algorithm like GES under oracle input would provide a more relevant benchmark.
5. Practical Assumptions: The method assumes extensive knowledge of ancestral constraints, which may not be realistic in many real-world scenarios.
Arguments for Acceptance:
- The paper presents a novel and technically sound solution to a previously unexplored problem.
- The empirical results demonstrate significant computational improvements over existing methods.
- The approach is of interest to a niche audience focused on Bayesian network learning and constraint-based optimization.
Arguments Against Acceptance:
- The problem setting is artificial, and the practical impact is limited due to the sparsity of ancestral constraints and the assumptions made.
- The theoretical framework for translating constraints could benefit from further refinement and validation.
- The comparison with Gobnilp is not entirely fair, and alternative benchmarks are needed to substantiate the claims.
Recommendation:
While the paper offers a novel contribution and demonstrates strong empirical performance, its limited practical impact and theoretical concerns suggest that it may be better suited for a specialized venue rather than a broader AI conference like NIPS. With additional work on addressing the theoretical and practical limitations, the paper could make a more compelling case for acceptance.