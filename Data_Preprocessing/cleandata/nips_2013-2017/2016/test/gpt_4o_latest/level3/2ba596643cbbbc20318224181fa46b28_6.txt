This paper introduces a novel multi-fidelity extension to the classical K-armed bandit problem, where each arm can be evaluated at different fidelity levels, with higher fidelities providing more accurate reward estimates but incurring greater costs. The proposed Multi-Fidelity Upper Confidence Bound (MF-UCB) algorithm strategically leverages lower-cost fidelities to eliminate suboptimal arms and reserves higher-cost fidelities for promising arms. This approach is particularly relevant for applications like online advertising, where short-term approximations can reduce costs while identifying optimal choices.
The paper makes several key contributions. First, it formalizes the multi-fidelity bandit problem, introducing a cost-weighted regret definition that accounts for fidelity-specific costs. Second, it proposes the MF-UCB algorithm, which adapts classical UCB strategies to the multi-fidelity setting. Theoretical analysis demonstrates that MF-UCB achieves better regret bounds compared to naive UCB strategies, particularly when the number of arms is large and the subset of near-optimal arms is small. Third, the authors provide a regret lower bound, showing that MF-UCB is near-optimal under certain conditions. Empirical results on synthetic datasets corroborate the theoretical findings, demonstrating that MF-UCB outperforms standard UCB in terms of regret.
The paper is technically sound, with rigorous theoretical analysis and clear algorithmic design. However, there are notable limitations. The assumption of prior knowledge of fidelity deviations (denoted as $\varepsilon^{(m)}$ or $\zeta(m)$) is a significant drawback, as it may not be practical in real-world applications like online advertising. Relaxing this assumption could make the approach more broadly applicable. Additionally, while the paper provides a strong theoretical foundation, the empirical evaluation is limited to synthetic datasets, leaving open questions about performance in real-world scenarios.
The paper is well-written and organized, with clear explanations of the problem setting, algorithm, and theoretical results. However, several minor issues, including typos, inconsistent notations, and equation errors (e.g., lines 326, 343, 345, 384, 407, 431, 440, 450), should be addressed to improve clarity.
Strengths:
1. Novel problem formulation and algorithmic approach.
2. Rigorous theoretical analysis with regret bounds and lower bounds.
3. Practical relevance to cost-sensitive applications like online advertising.
Weaknesses:
1. Assumption of known fidelity deviations limits practical applicability.
2. Limited empirical validation on real-world datasets.
3. Minor issues with notation and consistency.
Recommendation: Accept with minor revisions. The paper makes a significant contribution to the field of multi-armed bandits by addressing a novel and practical problem setting. However, addressing the assumption of known fidelity deviations and expanding empirical evaluations would strengthen the work further.