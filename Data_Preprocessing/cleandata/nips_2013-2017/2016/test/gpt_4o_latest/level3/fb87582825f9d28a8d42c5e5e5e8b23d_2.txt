Review
This paper presents a novel approach to designing optimization algorithms by framing the problem as a learning task, leveraging Long Short-Term Memory (LSTM) networks to learn gradient-based optimization procedures. The authors demonstrate that their learned optimizers outperform standard hand-designed methods like SGD, RMSprop, and ADAM on tasks such as quadratic functions, neural network training, and neural art generation. The paper's primary contribution lies in its explicit bias toward gradient-based learning algorithms and its demonstration of generalization across tasks with similar structures.
Strengths:
1. Novelty and Significance: The paper introduces a compelling idea of using LSTMs to learn optimization algorithms, which could inspire further research in meta-learning and optimization. The explicit bias toward gradient-based learning algorithms is a significant departure from prior work, which lacked such focus.
2. Experimental Results: The experiments are thorough and demonstrate the effectiveness of the proposed method across a variety of tasks, including quadratic functions, MNIST, CIFAR-10, and neural art. The results show strong generalization to unseen tasks, architectures, and data distributions.
3. Potential Impact: The approach has the potential to rekindle interest in gradient-based meta-learning and could lead to new advances in optimization for deep learning and beyond.
4. Clarity of Experiments: The experimental setup is well-documented, and the comparisons with baseline optimizers are clear and fair.
Weaknesses:
1. Conflation of Meta-Learning and Transfer Learning: The introduction conflates meta-learning and transfer learning, which could confuse readers. While the authors attempt to cast transfer learning as generalization in a meta-learning framework, this distinction should be clarified to avoid misinterpretation.
2. Insufficient Historical Context: The paper does not adequately acknowledge foundational meta-learning work, such as Schmidhuber's 1987 and 1993 research, which introduced general learning algorithms capable of modifying their own behavior. Similarly, Hochreiter's 2001 meta-LSTM work, which demonstrated faster learning than standard gradient descent, deserves a more direct comparison, especially given the similarity of the quadratic function experiments.
3. Reinforcement Learning Comparisons: The comparison to reinforcement learning overlooks earlier, more general systems like Schmidhuber's Success-Story Algorithm (SSA). Including this would provide a more comprehensive evaluation of the proposed approach.
4. LSTM Variant Clarification: The authors use a two-layer LSTM for coordinate-wise updates but do not clarify whether they used the original LSTM architecture or later variants with forget gates. This detail is critical for reproducibility and understanding the results.
5. Limited Discussion of Limitations: While the experiments are impressive, the paper does not sufficiently discuss the limitations of the approach, such as its reliance on task similarity for generalization or potential scalability issues for more complex optimization problems.
Arguments for Acceptance:
- The paper introduces a novel and impactful idea that advances the state of the art in meta-learning and optimization.
- The experimental results are compelling and demonstrate the practical utility of the proposed method.
- The explicit gradient-based bias is an innovative contribution that distinguishes this work from prior research.
Arguments Against Acceptance:
- The conflation of meta-learning and transfer learning in the introduction could mislead readers unfamiliar with the distinctions.
- The lack of direct comparisons to foundational meta-learning work, such as Schmidhuber's and Hochreiter's contributions, weakens the historical positioning of the paper.
- Some methodological details, such as the LSTM variant used, are insufficiently clarified, which could hinder reproducibility.
Recommendation:
The paper is a strong candidate for acceptance, provided the authors address the identified weaknesses. Specifically, they should clarify the distinction between meta-learning and transfer learning, provide direct comparisons to foundational work, and include more methodological details. These revisions would strengthen the paper's contribution and ensure its impact on the field.