The paper presents a novel algorithm, Homotopy Smoothing (HOPS), for solving composite non-smooth optimization problems with a max-structured term \( f \) and a proximal-friendly term \( g \). By leveraging a homotopy strategy with progressively decreasing smoothing parameters, HOPS achieves improved iteration complexity compared to existing methods. Specifically, under the \(\theta\)-Local Error Bound (LEB) condition, the method achieves an iteration complexity of \( O(\epsilon^{\theta-1}) \), with linear convergence for \(\theta = 1\) and \( 1/t^2 \) rates for \(\theta = 0.5\). The algorithm builds on Nesterov's smoothing technique but introduces a stage-wise smoothing parameter reduction, which is both theoretically justified and practically effective.
Strengths:
1. Technical Quality: The theoretical contributions are rigorous and well-supported. The paper establishes clear iteration complexity results under the LEB condition, demonstrating significant improvements over existing methods like Nesterov's smoothing and primal-dual methods.
2. Novelty: While gradual smoothing strategies have been explored before, the proposed homotopy approach and its analysis under the LEB condition are novel. The paper also generalizes prior work to a broader class of non-smooth problems.
3. Significance: The results have strong implications for applications in machine learning (e.g., SVMs with hinge loss), image processing, and cone programming. The connection to the Kurdyka-≈Åojasiewicz (KL) property and the demonstration of faster rates for non-smooth problems are valuable contributions.
4. Experimental Validation: The experiments convincingly demonstrate the practical advantages of HOPS and its primal-dual variant (PD-HOPS) over state-of-the-art methods. The results align well with the theoretical claims.
Weaknesses:
1. Clarity: The sketch of Theorem 5 is insufficiently detailed, making it difficult for readers to fully grasp the proof's intuition. Additionally, a typo on line 231 should be corrected.
2. Practical Concerns: While the theoretical results are strong, the paper does not sufficiently address the computational complexity of HOPS for large-scale empirical risk minimization (ERM) problems. The choice of smoothing parameters and their practical tuning could also be elaborated further.
3. Scope of Experiments: The experimental setup, though diverse, could benefit from additional benchmarks on larger datasets or real-world applications to better demonstrate scalability and robustness.
Arguments for Acceptance:
- The paper addresses an important problem in non-smooth optimization and provides a novel, theoretically sound solution.
- The results advance the state-of-the-art in iteration complexity for a broad class of problems.
- The experimental results are promising and validate the theoretical claims.
Arguments Against Acceptance:
- The clarity of some theoretical sections, particularly Theorem 5, needs improvement.
- Practical concerns, such as computational overhead and parameter tuning, are not fully addressed.
Recommendation:
Overall, this paper makes a significant contribution to the field of optimization and is well-suited for the conference. While minor issues in clarity and practical considerations exist, they do not detract from the paper's overall quality and impact. I recommend acceptance with minor revisions to address the clarity issues and practical concerns.