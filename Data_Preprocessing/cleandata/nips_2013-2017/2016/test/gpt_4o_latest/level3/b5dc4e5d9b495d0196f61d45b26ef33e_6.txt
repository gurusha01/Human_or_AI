The paper proposes a novel optimization algorithm, Homotopy Smoothing (HOPS), for solving structured non-smooth optimization problems. The authors claim that HOPS achieves an improved iteration complexity of \( O(1/\epsilon^{1-\theta} \log(1/\epsilon)) \), where \( \theta \in (0, 1] \) reflects the local sharpness of the objective function. The algorithm builds on Nesterov's smoothing technique but introduces a homotopy strategy to gradually decrease the smoothing parameter, leveraging warm-starts to improve efficiency. The paper also extends the analysis to a primal-dual variant (PD-HOPS) and demonstrates the algorithm's effectiveness through experiments on tasks such as linear classification, image denoising, and matrix decomposition.
Strengths:
1. Theoretical Contribution: The authors provide a rigorous theoretical analysis of HOPS, establishing its improved iteration complexity under the local error bound (LEB) condition. This is a meaningful contribution as it generalizes existing results and offers a framework for a broader class of non-smooth problems.
2. Practical Relevance: The paper demonstrates the applicability of HOPS to real-world problems in machine learning, image processing, and optimization, showcasing its versatility.
3. Experimental Validation: The experiments convincingly show that HOPS and PD-HOPS outperform state-of-the-art methods like Nesterov's smoothing and primal-dual algorithms, particularly for high-accuracy solutions.
4. Clarity of Algorithm Design: The homotopy strategy is well-motivated, and the paper provides clear explanations of how it improves upon fixed-parameter smoothing methods.
Weaknesses:
1. Originality: While the homotopy smoothing approach is novel, many of the results are either straightforward generalizations of prior work or directly borrow from existing analyses. For instance, the result on Line 237 of Page 7 is identical to Zhang et al. (2012) for locally strongly convex optimization, and the KL condition on Line 243 is equivalent to the widely studied Polyak-≈Åojasiewicz (PL) condition.
2. Significance Justification: The authors claim that HOPS achieves the lowest iteration complexity for the considered problem class, but the practical significance of this improvement is not thoroughly justified. It would be helpful to include more concrete examples or scenarios where this improvement has a substantial impact.
3. Relation to Prior Work: The paper could better contextualize its contributions relative to existing methods. For example, while the authors highlight differences between HOPS and Nesterov's smoothing, they do not sufficiently discuss the novelty of their local error bound condition compared to related work.
4. Clarity of Writing: Although the paper is generally well-organized, some sections (e.g., the discussion of the KL property) are overly dense and could benefit from simplification for better accessibility.
Recommendation:
While the paper provides a solid theoretical framework and demonstrates empirical improvements, its contributions are somewhat incremental, and the novelty is limited by reliance on known techniques. To strengthen the paper, the authors should provide more compelling justifications for the significance of their results and clarify their contributions relative to prior work. Additionally, simplifying some technical sections would enhance readability. Overall, I recommend conditional acceptance pending revisions to address these concerns.
Arguments for Acceptance:
- Theoretical rigor and improved iteration complexity.
- Broad applicability to non-smooth optimization problems.
- Strong experimental results validating the algorithm's effectiveness.
Arguments Against Acceptance:
- Limited originality, with many results being extensions of prior work.
- Insufficient justification for the practical significance of the proposed improvements.
- Some sections lack clarity and accessibility for a broader audience.