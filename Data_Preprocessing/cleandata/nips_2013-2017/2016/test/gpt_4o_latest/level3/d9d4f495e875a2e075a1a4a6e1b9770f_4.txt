This paper presents a novel approach to action-conditioned video prediction by proposing three unsupervised methods—Dynamic Neural Advection (DNA), Convolutional DNA (CDNA), and Spatial Transformer Predictors (STP)—that focus on modeling object motion without explicitly learning optical flow. The integration of LSTMs, dynamic neural advection, and spatial transformers into a deep network architecture is a notable contribution. The authors evaluate their methods on a newly introduced robot-object manipulation dataset and the Human3.6M dataset, demonstrating superior quantitative performance compared to prior state-of-the-art approaches.
Strengths:
1. Technical Contribution: The paper introduces a unique framework for video prediction that explicitly models pixel motion, enabling generalization to unseen objects. This is a significant step forward in unsupervised learning for physical interaction.
2. Evaluation: The experiments are thorough, with evaluations on both a novel robotic dataset and a widely-used human motion dataset. The results convincingly show the superiority of the proposed methods over existing baselines.
3. Clarity and Writing: The paper is well-written and organized, making the methodology and findings accessible to readers.
4. Dataset Contribution: The introduction of a large-scale robot-object interaction dataset is a valuable resource for the community and enhances the paper's significance.
5. Interpretability: The CDNA and STP models naturally produce interpretable internal representations, such as object-centric motion predictions and background masks.
Weaknesses:
1. Blurry Predictions: Despite strong quantitative results, the predicted frames become blurry after one second, raising concerns about the practical utility of the method for long-term predictions. This limitation is acknowledged but not sufficiently addressed.
2. Novelty: While the use of LSTMs for video prediction is effective, it is not novel. The paper does not explore whether additional LSTM layers or alternative memory mechanisms like Neural Turing Machines (NTMs) could improve performance.
3. Dynamic Neural Advection (DNA) Component: The role and parametrization of the DNA component remain unclear. A more detailed mathematical explanation would improve understanding and reproducibility.
4. Supplementary Materials: The lack of access to videos, appendices, and supplementary materials limits the ability to fully assess the qualitative aspects of the approach.
5. Modeling Assumptions: The paper would benefit from a deeper discussion of the modeling assumptions and architectural choices, particularly regarding the trade-offs between DNA, CDNA, and STP.
Pro and Con Arguments for Acceptance:
Pro: The paper addresses an important problem in video prediction, proposes a novel motion-focused approach, and provides a valuable dataset. The results are strong, and the models are interpretable.  
Con: The blurry predictions and lack of novelty in using LSTMs raise questions about the practical impact. Additionally, the unclear parametrization of DNA and limited supplementary materials hinder reproducibility.
Recommendation:
Overall, this paper makes a meaningful contribution to the field of unsupervised video prediction and interactive learning. While there are some weaknesses, particularly regarding clarity and long-term prediction quality, the strengths outweigh the limitations. I recommend acceptance, provided the authors address the issues of blurry predictions and clarify the DNA component in the final version.