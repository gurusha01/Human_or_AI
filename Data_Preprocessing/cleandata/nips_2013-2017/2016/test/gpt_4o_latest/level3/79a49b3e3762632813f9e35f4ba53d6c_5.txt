The paper addresses the problem of estimating class prior probabilities from positive and unlabeled (PU) data in the presence of label noise, a challenging and relevant issue in machine learning. The authors propose a novel algorithm that models distributions as mixtures and learns parameters using Gaussian Mixture Models (GMMs) or AlphaMax, with theoretical guarantees for identifiability. The paper also introduces univariate transforms to handle high-dimensional data, avoiding kernel density estimation, which is a significant improvement over existing methods. Experimental results demonstrate that the proposed models outperform competing approaches across various datasets, showcasing their practical utility.
Strengths:
The paper is well-structured and clearly written, with a logical progression from problem formulation to theoretical development, algorithm design, and experimental validation. The inclusion of theoretical guarantees for identifiability is commendable and adds rigor to the work. The authors also provide extensive experimental results, which strengthen the empirical validity of their approach. The use of univariate transforms to address high-dimensionality is particularly innovative and addresses a common limitation in PU learning methods. Additionally, the authors' clarification on dimensionality reduction during the review process reflects their responsiveness and willingness to improve the paper.
Weaknesses:
Despite its technical contributions, the paper lacks a compelling justification for the importance and practical impact of the problem. While PU learning is a well-known challenge, the authors do not provide clear real-world applications or scenarios where their method would be impactful. This omission limits the perceived significance of the work. Furthermore, the identifiability condition required by the theoretical framework is overly strong and unlikely to hold in real-world scenarios, which undermines the practical applicability of the proposed method. While the authors address dimensionality reduction, the reliance on density estimation still limits the method's scalability to very high-dimensional datasets.
Arguments for Acceptance:
- The paper provides a novel and technically sound approach to PU learning with label noise.
- Theoretical guarantees and extensive experiments demonstrate the validity of the method.
- The use of univariate transforms is an innovative contribution to handling high-dimensional data.
Arguments for Rejection:
- The practical impact and real-world applicability of the method are not well-justified.
- The strong identifiability condition limits the generalizability of the theoretical results.
- The method's reliance on density estimation, despite dimensionality reduction, may hinder scalability.
Final Recommendation:
While the paper makes notable technical contributions, the lack of clear real-world applications and the strong theoretical assumptions reduce its overall impact. I lean towards rejection but remain open to reconsideration if the authors can provide stronger justifications for the practical significance of their work.