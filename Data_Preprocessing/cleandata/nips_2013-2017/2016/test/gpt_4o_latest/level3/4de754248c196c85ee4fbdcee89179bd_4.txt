This paper presents a method for energy disaggregation using semidefinite programming (SDP) relaxation and randomized rounding, applied to additive factorial hidden Markov models (FHMMs). The authors propose a scalable algorithm leveraging the Alternating Direction Method of Multipliers (ADMM) to address the computational challenges of SDP, followed by randomized rounding for approximate integer solutions. They claim superior performance over state-of-the-art methods, particularly Kolter and Jaakkola (KJ, 2012), on both synthetic and real-world datasets.
Strengths:
1. Problem Relevance: Energy disaggregation is a critical problem in energy efficiency, with potential societal and environmental benefits. The focus on scalability and computational efficiency aligns well with practical deployment needs.
2. Methodological Innovation: The combination of SDP relaxation with ADMM and randomized rounding is a novel approach to tackling the computational challenges of FHMM inference. The use of Moreau-Yosida regularization in ADMM is a notable contribution.
3. Synthetic and Real-World Evaluation: The authors demonstrate their method on both synthetic data and the widely used REDD dataset, providing a comprehensive evaluation.
4. Significant Recall Improvements: The method achieves competitive recall compared to KJ while improving precision by 50%, addressing a key limitation of prior work.
Weaknesses:
1. Incremental Theoretical Contribution: While the methodological combination is novel, the theoretical advances are incremental. SDP relaxation and randomized rounding are well-established techniques, and their application here does not introduce fundamentally new insights.
2. Experimental Concerns: The precision and recall metrics for KJ reported in Table 1 are lower than those in the original KJ paper, raising concerns about the validity of the experimental setup or implementation.
3. Scalability Claims: The lack of a direct runtime comparison with KJ undermines the claim of computational efficiency. While the authors acknowledge that their implementation is slower, they attribute this to the use of Matlab, which is unconvincing without further evidence.
4. Dataset Size and SDP Infeasibility: The paper does not clearly justify why directly solving the SDP is infeasible, nor does it specify the dataset size in sufficient detail to contextualize the scalability claims.
5. Related Work Gaps: The related work section does not adequately justify why KJ is considered the state-of-the-art benchmark, especially given the existence of newer methods like deep learning-based approaches (e.g., Kelly & Knottenbelt, 2015).
6. Clarity Issues: Notation in Line 75 is unclear, and the section title "Synthetic Data Set" is ambiguous. These minor issues detract from the paper's readability.
Recommendation:
While the paper addresses an important problem and proposes a method with promising results, the incremental theoretical contribution, concerns about experimental validity, and lack of runtime comparisons weaken its impact. I recommend major revisions before acceptance. The authors should:
1. Provide a direct runtime comparison with KJ and other baselines.
2. Clarify experimental discrepancies and dataset details.
3. Expand the related work section to include and compare against more recent methods.
4. Address clarity issues in the manuscript.
Arguments for Acceptance:
- Addresses a relevant and impactful problem.
- Proposes a novel combination of established techniques.
- Demonstrates improved precision and recall over KJ.
Arguments Against Acceptance:
- Incremental theoretical contribution.
- Experimental concerns and lack of runtime comparisons.
- Insufficient justification for benchmark choices and scalability claims.