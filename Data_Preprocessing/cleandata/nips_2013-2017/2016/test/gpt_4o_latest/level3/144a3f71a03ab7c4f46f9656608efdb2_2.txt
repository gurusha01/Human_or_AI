The paper introduces a novel method for learning Bayesian networks optimally under ancestral constraints, leveraging a framework that integrates non-decomposable constraints into structure learning. The authors build on prior work by Chen et al. (2015, 2016) and propose an enhancement to the EC tree search space, enabling the incorporation of ancestral constraints by inferring decomposable constraints to empower the heuristic. The approach is empirically shown to be significantly more efficient than integer linear programming (ILP)-based methods, such as GOBNILP, achieving orders-of-magnitude improvements in runtime.
Strengths:
1. Originality and Contribution: The paper addresses a critical limitation in Bayesian network structure learning by enabling the use of non-decomposable ancestral constraints. This is a meaningful contribution, as ancestral constraints are practically relevant for encoding causal relationships.
2. Efficiency: The proposed method demonstrates substantial efficiency gains over ILP-based approaches, as evidenced by the empirical results.
3. Technical Soundness: The theoretical framework appears robust, with sound and complete pruning methods for the EC tree and a well-defined approach for projecting non-decomposable constraints into decomposable ones.
4. Scalability: The method scales to problems with up to 20 variables, which is comparable to state-of-the-art methods for Bayesian network learning.
Weaknesses:
1. Clarity of Experimental Results: The presentation of experimental results is somewhat unclear. For instance, Table 1 compares (EC + new work) to (GOB + new work'), but the interpretation of Table 3 is ambiguous. The trends in Table 3, such as the easy-hard-easy pattern, are not sufficiently explained.
2. Missing Baseline Comparisons: While the paper compares (EC + new work) to GOBNILP, it does not explicitly compare (EC + new work) to EC alone. Such a comparison would help isolate the contribution of the proposed enhancements.
3. Interpretability of Results: The structural Hamming distance (∆) results are reported but not thoroughly analyzed. The implications of ∆ values, particularly when p = 1, are not well-discussed.
4. Clarity of Writing: While the technical content is strong, the paper could benefit from better organization and clearer explanations, particularly in the experimental section. For example, the impact of projected constraints on ILP is only briefly mentioned and could be elaborated further.
Arguments for Acceptance:
- The paper addresses a significant problem in Bayesian network learning and proposes a novel, efficient solution.
- The theoretical contributions, including pruning methods and constraint projection, are sound and well-motivated.
- The empirical results demonstrate clear efficiency advantages over ILP-based methods.
Arguments Against Acceptance:
- The experimental results are not presented as clearly as they could be, making it challenging to fully evaluate the impact of the proposed method.
- The lack of a direct comparison between (EC + new work) and EC alone limits the ability to assess the incremental benefit of the new contributions.
Recommendation:
The paper makes a solid technical contribution and addresses an important problem, but it requires revisions to improve the clarity of experimental results and provide additional comparisons. I recommend acceptance with minor revisions, contingent on addressing the above concerns.