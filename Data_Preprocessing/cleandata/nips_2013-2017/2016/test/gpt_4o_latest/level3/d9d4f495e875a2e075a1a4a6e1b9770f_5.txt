This paper presents a novel approach to predicting motion from physical interactions in an unsupervised manner by focusing on pixel motion rather than pixel values. The authors propose three predictive models—Dynamic Neural Advection (DNA), Convolutional Dynamic Neural Advection (CDNA), and Spatial Transformer Predictors (STP)—all built on convolutional LSTM architectures. These models are evaluated on a newly introduced large-scale robotic interaction dataset and the Human3.6M dataset, demonstrating strong performance compared to prior methods. The paper also introduces a significant contribution to the field in the form of a large dataset of 59,000 robot-object interactions, which is made publicly available.
Strengths:
The paper is technically sound and well-written, with a clear exposition of the problem, methodology, and related work. The proposed models are innovative, particularly in their focus on pixel motion, which allows for generalization to unseen objects and reduces reliance on object appearance. The introduction of the robotic pushing dataset is a valuable contribution, as it provides a rich resource for future research in physical interaction prediction. The experiments are thorough, with both quantitative and qualitative evaluations, and the results demonstrate significant improvements over prior methods. The inclusion of supplementary materials, such as video results and masks, enhances the reproducibility and interpretability of the work.
Weaknesses:
While the results are strong, the models exhibit some limitations, including blur artifacts, missing details, and a lack of temporal coherence in the predicted masks. These issues are particularly evident in long-term predictions. The paper would benefit from visualizing all three architectures (DNA, CDNA, and STP) rather than only CDNA, as this would provide a more comprehensive understanding of the differences between the models. Additionally, the authors could explore imposing priors on motion transformations to encourage spatial smoothness, which might mitigate some of the observed artifacts. The reliance on mean-squared error as the loss function may also contribute to the blur, and alternative loss functions could be considered.
Pro and Con Arguments for Acceptance:
- Pro: The paper addresses a significant and challenging problem in video prediction and physical interaction modeling. The proposed methods are novel and achieve state-of-the-art results. The introduction of a new dataset is a substantial contribution to the field.
- Con: The models suffer from some qualitative limitations, such as blur and temporal incoherence, and the paper could improve in terms of architectural visualization and exploration of alternative loss functions.
Conclusion:
Overall, this paper makes meaningful contributions to the field of unsupervised learning for physical interaction prediction. Despite some limitations, the strengths of the methodology, results, and dataset outweigh the weaknesses. I recommend acceptance, with minor revisions to address the visualization of all architectures and further discussion on mitigating blur artifacts.