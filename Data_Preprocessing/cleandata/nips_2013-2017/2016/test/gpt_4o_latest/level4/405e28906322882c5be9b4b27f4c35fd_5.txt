The paper establishes enhanced lower and upper bounds on regret in both the bandit and full information settings. These bounds are expressed in terms of four parameters:  the number \(\Gamma\), representing the frequency of changes in the optimal arm,  the cumulative variation \(V\) in the mean reward across consecutive rounds,  the sum \(\Lambda\) of the reward variances over all rounds, which is a novel consideration in this context,  and the time horizon \(T\). Prior work primarily combined \(T\) with either \(\Gamma\) or \(V\), and those results can be recovered from this paper's findings as a special case under worst-case assumptions. The paper is well-motivated, clearly written, and provides detailed explanations. While the derived bounds are unlikely to represent the definitive characterization of regret (as the parameters may not fully capture all relevant aspects of problem complexity), they offer meaningful extensions to existing results and contribute to a deeper understanding of the subject. A limitation is that many of the proposed algorithms assume prior knowledge of certain parameters, which is somewhat impractical. Nonetheless, the paper introduces sufficient novel insights to make it a valuable contribution to the field. 
- Line 192: Including the remark "m_t is determined below" could slightly enhance readability.  
- Lines 186-187: Do you select a random arm using the distribution \(p_t\)?  
- Line 205: Is \(\eta{t,k}\) correct here? Should it instead be \(\eta{t-1,k}\)?  
- Lines 304-309: The index \(i\) is already used to denote the optimal arm. Consider using a different symbol here.  
- Lines 318-320: Does \(\sqrt{VT} \leq \sqrt[3]{\Lambda VT}\), when substituted into Theorem 4.1, directly establish the theorem's claim? Is the explanation in the sentence between lines 318 and 320 strictly necessary?  
- Table 1 in Appendix A is excellent and highly informative. However, it could be even more useful if it highlighted which upper bounds rely on algorithms that require prior knowledge of the parameters.  
- A general question: The regret in this paper is analyzed relative to the best dynamic learner. How would the regret compare against the best fixed arm? Could these parameters also lead to improvements in classical regret bounds?