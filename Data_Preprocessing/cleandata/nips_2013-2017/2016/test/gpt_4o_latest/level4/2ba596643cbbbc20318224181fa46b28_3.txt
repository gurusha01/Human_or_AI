The paper presents a "multi-fidelity" extension of the multi-armed bandit problem, where there are K arms, each playable at M different "fidelity" levels. Lower fidelity incurs reduced cost but introduces potentially greater bias in estimating an arm's reward. Specifically, pulling an arm at fidelity level m generates a sample from a distribution whose expected value deviates from the arm's true expected reward by an amount bounded by the fidelity level. The authors analyze a natural UCB-based algorithm tailored for this problem, adjusting the confidence interval width to account for the bias introduced by low-fidelity sampling. The analysis culminates in theorems that provide regret bounds, though these bounds are complex and difficult to interpret. The paper argues that this regret bound is often significantly better than the one achieved by always playing at the highest fidelity and applying the standard UCB algorithm. A short section near the end includes simulation results to support this claim.
Initially, I questioned the decision to model lower fidelity as introducing more bias rather than more variance, as the latter also seems like a plausible interpretation of "low fidelity." However, the motivating examples provided in the paper, such as algorithm selection for machine learning problems, largely convinced me that modeling low fidelity as increased bias is reasonable. That said, I remain unconvinced by one particular exampleâ€”the claim that displaying an ad for a shorter duration yields a biased estimate of its effectiveness over longer intervals. Additionally, in the machine learning algorithm selection example, it is unclear why minimizing regret would be the primary objective for an algorithm designer in that context. Overall, while the connection between the proposed model and the motivating applications feels tenuous, it is not weak enough to be a critical flaw.
The primary contribution of the paper appears to be the formulation of the multi-fidelity multi-armed bandit problem itself. The algorithm is a fairly standard application of the "optimism in the face of uncertainty" principle. As noted earlier, the regret bounds are difficult to interpret, which is a drawback. The simulation results on synthetic problems are also challenging to evaluate: while Appendix C provides details on the parameter values used, it does not justify these choices. In many simulations, the regret of MF-UCB improves over UCB by a factor of 3 to 4. However, it is unclear whether this performance improvement is representative of typical behavior in practice or if it results from specific parameter choices (e.g., values of \(\zeta^{(m)}\)).