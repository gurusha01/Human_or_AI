This paper addresses a variation of the classical stochastic K-armed bandit problem, incorporating the availability of inexpensive approximations for each arm. The authors define this problem within the framework of a multi-fidelity bandit problem. Theoretical regret bounds are derived and presented. Simulations are conducted to illustrate the impact of the multi-fidelity approach. The presentation is clear and comprehensible. The simulations effectively showcase the performance of the multi-fidelity bandit method. Additionally, the paper provides adequate theoretical analysis on the lower bounds of the proposed method, highlighting its theoretical advantages.