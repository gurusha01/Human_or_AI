This paper addresses the constrained optimization problem of learning Bayesian networks from local scores under ancestral constraints. The search process employs a branch-and-bound strategy, where nodes in the search tree correspond to CPDAGs. The transition from one CPDAG (CPDAG1) to another (CPDAG2) is achieved by (approximately) selecting a parent set for a Bayesian network variable that is not yet a node in CPDAG1. The authors implement sensible symmetry-breaking techniques. The search algorithm follows an A* framework, utilizing the URLearning system to provide a heuristic (details of which are not included in this paper but are available in prior work). Ancestral constraints enable some pruning of the search tree, with Lemma 3 (presented in the supplementary material) serving as the central result. While I believe Lemma 3 to be correct, I find the proof unclear. Specifically, the statement "By the EC tree edge generation rules, G_k also contains edge Z -> W" requires further elaboration.
Additionally, the paper discusses "implied constraints," which are standardly referred to as such but are labeled "projected constraints" here. A set of ancestral constraints can imply edge constraints that facilitate pruning. The authors also infer constraints on permissible topological orderings, referred to as "ordering constraints." However, the methodology for deriving these constraints is insufficiently explained. For instance, the statement "we can infer Y < Z from Z not an ancestor of Y" is problematic due to the ambiguity of the word "can." There exist DAGs where Z is not an ancestor of Y, yet Y < Z is a consistent ordering (e.g., a graph with vertices Z and Y but no edges). The authors likely intend to convey that if "Z is not an ancestor of Y," one can choose to impose the constraint Y < Z. The goal is to infer as many consistent ordering constraints as possible (beyond those strictly entailed), and the authors employ a MAXSAT approach to achieve this. They are careful not to infer excessive constraints.
The experimental evaluation varies the number of variables, data points, and ancestral constraints. The proposed system is compared to the GOBNILP system, with results showing that the current approach significantly outperforms GOBNILP in terms of speed. The authors note that GOBNILP typically underperforms compared to A* methods when there is no limit on parent set cardinality. Since the experiments here impose no such limit, it is unclear whether GOBNILP's poor performance arises from its general difficulty handling large parent sets or its specific challenges with ancestral constraints. Furthermore, the encoding of ancestral constraints (detailed in the supplementary material) is based on a MAXSAT encoding from [Cussens, 2008], rather than the ILP encoding described in Section 3.1.1 of [Cussens, 2010]. The MAXSAT encoding used here is suboptimal for an ILP system. A more efficient approach would involve introducing A(X, Y) binary variables alongside the I(Z, U) variables while omitting the (cubic number of) E(X, Y, Z) variables. The necessary constraints would include transitivity constraints on the A(X, Y) variables and the following linkage between A and I variables:  
A(X, Y) ≥ ∑_{U: X ∈ U} I(Y, U).  
This formulation ensures that if X is a parent of Y, then X is also an ancestor of Y. It offers a tighter linear relaxation and would likely yield better performance. This approach aligns with Section 3.1.1 of [Cussens, 2010], which assumes a total ordering on variables but would require one constraint to be dropped since "ancestor" represents a partial, not total, order. 
I am confident that even with a well-designed ILP formulation for ancestral constraints, the proposed system would outperform GOBNILP. However, the paper is weakened by comparing the proposed method to a suboptimal encoding rather than a more robust one. It would also be valuable to compare the current approach to that of van Beek and Hoffmann, as their method often outperforms GOBNILP. Adapting their method to accommodate ancestral constraints should not be overly challenging. Notably, the paper by van Beek and Hoffmann is not cited by the authors.  
References:  
[Cussens, 2010] James Cussens. "Maximum likelihood pedigree reconstruction using integer programming." WCB'10.  
[van Beek and Hoffmann, 2015] Peter van Beek and Hella-Franziska Hoffmann. "Machine learning of Bayesian networks using constraint programming." Proceedings of CP 2015, Cork, Ireland, August 2015.