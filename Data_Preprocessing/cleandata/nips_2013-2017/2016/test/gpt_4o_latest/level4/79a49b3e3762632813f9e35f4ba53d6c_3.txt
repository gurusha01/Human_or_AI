The paper presents a novel method to estimate class priors in a positive and unlabeled learning scenario. The authors address the issue of false (known) positives, a prevalent but often overlooked challenge in existing literature. To mitigate the curse of dimensionality, the proposed method first maps the data to a single dimension using a non-traditional classifier before performing density estimation. Experimental benchmarks demonstrate the effectiveness of the approach. The manuscript is generally well-written and easy to comprehend. While the proofs are intricate and notation-heavy, the authors' effort to summarize the practical implications of each proof significantly enhances the readability and coherence of the text. The insights provided by Theorems 1 and 2 are particularly valuable. However, I have a few comments on the current manuscript:  
- The authors claim that this is the first method to address noisy positive and unlabeled data (lines 57-58 and 312-314). However, prior work explicitly addressing this variant of positive and unlabeled learning exists [1]. While it is understandable that some prior work might be overlooked, the broader context of learning from noisy positives and unlabeled data can also be framed within the domain of learning with label noise (e.g., noisy positives versus noisy negatives), for which numerous methods are available (see [2] for a review). Therefore, I disagree with the assertion that this is the first method to tackle this specific problem.  
- What happens if the non-traditional classifier performs poorly (e.g., due to overfitting, underfitting, or trivial predictions)? How exactly is the non-traditional classifier used to transform the data into a single dimension? For instance, is this done within a cross-validation framework? Furthermore, how are the hyperparameters of the non-traditional classifier optimized, and which score function is recommended for this purpose? The manuscript would benefit from a more detailed explanation of the practical aspects of employing the non-traditional classifier.  
- The inclusion of regression datasets in the benchmark appears unnecessary and somewhat out of place. I recommend replacing these datasets with other classification problems to better align with the proposed method's focus.  
[1] M. Claesen, F. De Smet, J. Suykens, B. De Moor, A robust ensemble approach to learn from positive and unlabeled data using SVM base models, Neurocomputing (2015) 73-84. http://dx.doi.org/10.1016/j.neucom.2014.10.081  
[2] B. Frenay, M. Verleysen, Classification in the presence of label noise: a survey, IEEE Trans. Neural Netw. Learn. Syst. 25 (May (5)) (2014) 845â€“869. http://dx.doi.org/10.1109/TNNLS.2013.2292894, ISSN 2162-237X.