This paper investigates the use of structured sparsity (group lasso) to reduce the size of convolutional neural networks in a manner that is more structured and thus better suited for vectorized computation on GPUs compared to the recently explored l1 regularization by Han et al. I consider this to be a significant contribution. The experimental results are promising, and I find the approach to depth regularization particularly intriguing. Overall, this is a well-executed paper with a solid set of experimental findings. Enhancing the efficiency of DNNs is a fundamental challenge in deep learning. Moreover, sparsification offers additional benefits, such as improved regularization and enhanced interpretability. However, the level of novelty is somewhat limited, as structured sparsity is already a well-established concept.