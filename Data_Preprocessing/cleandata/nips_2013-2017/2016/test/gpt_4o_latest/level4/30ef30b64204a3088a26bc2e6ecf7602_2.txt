In this paper, the authors explore semi-supervised learning using convolutional neural networks. They introduce an unsupervised loss function designed to minimize the discrepancy between predictions obtained from multiple passes of the same training sample through a deep network. The proposed approach is tested on several image recognition tasks, and experimental results are presented. Overall, the study is engaging, and the authors effectively set up and report results across multiple benchmark image recognition datasets. However, the technical contribution of the paper can be summarized as introducing a straightforward method to reduce prediction variability for the same training example caused by factors such as randomization, dropout, max-pooling, etc. A significant portion of the effort appears to have been devoted to conducting experiments to illustrate the impact of this modification to the loss function. One aspect remains unclear â€” how was the new loss function optimized in practice? Did the authors replicate training samples within each mini-batch and store predictions from previous iterations to optimize the transformation function? Additionally, what implications does this have on the network's training speed and convergence? Finally, the reported accuracies for the proposed method on the ImageNet ILSVRC task are notably lower than those achieved by current state-of-the-art approaches.