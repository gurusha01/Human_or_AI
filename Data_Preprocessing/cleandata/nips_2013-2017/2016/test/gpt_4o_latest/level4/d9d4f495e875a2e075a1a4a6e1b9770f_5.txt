The paper focuses on learning to predict outcomes of physical interactions in an unsupervised manner. The core idea is to forecast pixel motion rather than directly predicting pixel values. Building on convolutional LSTM, the authors propose three predictive models—DNA, CDNA, and STP—to achieve this objective. These approaches are evaluated on a newly introduced large-scale physical interaction dataset as well as the Human3.6M dataset. Quantitative comparisons with [14,17] are provided.  
Clarity of exposition:  
- The paper is well-written and easy to follow.  
- The literature review is thorough, clear, and well-structured.  
- While the CDNA architecture is illustrated, the other two architectures are only described in the text. It would be helpful to visualize these architectures in Figure 1 or include them in the supplementary material.  
- The supplementary site includes video results and corresponding masks.  
Method:  
The proposed method demonstrates strong performance compared to other state-of-the-art techniques. However, the predicted frames exhibit blur artifacts and lack fine details. For instance:  
- The masks appear to lack temporal coherence. It raises the question of whether the prediction for the next frame depends on the current frame.  
- The motion transformation collection \( M \) can be interpreted as a backward optical flow field. Introducing priors, such as penalizing large gradients in the flow fields, could promote spatial smoothness.  
In conclusion, this is a well-written paper with robust results. The proposed methods introduce a novel approach to predicting future frames from physical interactions and make valuable contributions to the field.