The central premise of this paper is that a robust model should produce consistent predictions for any given training sample, regardless of random transformations applied to the data or perturbations introduced to the model. To achieve this, the authors propose an unsupervised loss function termed the transformation/stability loss, which explicitly minimizes the sum of squared differences between predictions generated from multiple passes of the same sample through the model. This loss is combined with another unsupervised loss function, the mutual-exclusivity loss, and the authors demonstrate through various experiments that incorporating these unsupervised losses alongside a supervised loss function enables the training of superior models in semi-supervised settings where labeled data is scarce. The proposed approach is evaluated on several datasets, including MNIST, CIFAR10, CIFAR100, SVHN, NORB, and ILSVRC. 
The paper introduces a clear and intuitive method for leveraging unlabeled data in training deep convolutional networks. The authors report impressive results on benchmark datasets, achieving state-of-the-art performance on CIFAR10 and CIFAR100. However, their performance on ImageNet falls significantly short of the current state-of-the-art, raising questions about the applicability of their approach in scenarios where labeled data is plentiful, as opposed to its apparent strength in settings with limited labeled data. The paper is generally well-written and easy to understand. Below are some specific suggestions for improvement: 
- At the bottom of page 5 in Section 4.2 (SVHN), the description of the experiment involving sparse convolutional networks is somewhat unclear. The text states, "we create five sets of labeled data" and that "for each set, we randomly pick a different 1% subset of training samples." Does this imply that the 1% subset is used as labeled training data while the remaining samples are treated as unlabeled data? Additionally, are the results reported in Table 2 averaged across these five sets? 
- Why is data augmentation applied in some experiments but omitted in others?