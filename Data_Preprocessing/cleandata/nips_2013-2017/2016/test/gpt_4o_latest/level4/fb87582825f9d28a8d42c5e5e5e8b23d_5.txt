The authors explore the application of recurrent neural networks (RNNs) for learning optimal update strategies in the domain of first-order optimization. Specifically, they replace traditional hand-crafted update rules, such as steepest descent, with outputs generated by recurrent networks. Their approach employs one LSTM per coordinate, with two variations—global averaging of certain LSTM cells and a read/write mechanism to an external memory—that do not yield significant improvements over the basic version in their experiments. Through three examples, the authors demonstrate that their networks can outperform a few selected first-order optimization methods (e.g., ADAM) and exhibit limited generalization to similar problem classes. The benchmarks considered include: (i) optimization of unregularized linear least squares; (ii) training a neural network on the MNIST dataset; and (iii) solving optimization problems in the context of 'artistic style transfer,' which combines features of two images. 
Conceptually, the paper introduces a compelling and innovative idea. The approach is straightforward to grasp yet opens up numerous possibilities, making it, in my view, an excellent fit for the NIPS conference. However, from a practical standpoint, the current work has notable limitations. First-order optimization methods are widely used because they offer two key advantages: (i) applicability to nearly any (sub)differentiable problem, and (ii) low implementation cost once gradients are available. The proposed method forfeits both of these benefits, as the network must be retrained even for minor changes in the optimization problem (e.g., altering the activation function in a neural network). Furthermore, training the network is computationally expensive, and the memory and time overhead associated with running multiple LSTM networks can be substantial. Given these constraints, one might question the rationale for using a first-order approach when the computational resources required could instead support more sophisticated second-order techniques. 
The proposed method seems particularly promising for scenarios where the same optimization problem must be solved repeatedly, potentially thousands of times. In this context, the most intriguing applications may lie outside the traditional scope of machine learning. Indeed, the only experiment directly involving the training of a neural network is, in my opinion, the least compelling of the three presented.