This paper introduces a novel optimization method designed to replace traditional approaches like SGD and RMSProp, which rely on hand-crafted parameter update rules. The proposed method leverages an LSTM to learn the optimal parameter updates at each step, effectively substituting manually designed update rules with a learned alternative. When evaluated on tasks such as quadratic functions, MNIST, and Neural Art, the LSTM-based optimizer demonstrated superior performance compared to traditional optimizers. This represents an innovative optimization technique that transitions from fixed, hand-crafted update rules to a learnable framework. The learning curve achieved significantly better results than conventional methods. The paper is well-written, highly readable, and easy to follow. However, there are a few questions that the authors should address: 1. What is the computational cost of using the LSTM optimizer? It is evident that the LSTM optimizer is not a free lunch, as its update rule involves more complex computations compared to SGD (computing an LSTM versus a simple ax+y operation). How much slower does this make the training process? 2. In the results section, the authors reported loss values over iterations, but what about the final accuracy? 3. While the experiments include simple tasks like quadratic functions, MNIST, and Neural Art, how well does this method generalize to modern deep networks such as ResNet on large-scale datasets? Would training in such scenarios present significant challenges?