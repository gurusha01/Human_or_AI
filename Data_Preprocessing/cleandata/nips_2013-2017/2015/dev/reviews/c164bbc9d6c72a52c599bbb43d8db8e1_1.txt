The paper definitely contains some new contributions from a technical point of view. However, the main idea and the theoretical results are not mature enough. Indeed, Algorithm 1 can be viewed as a simple inexact variant of Guler's fast proximal method in [9], where the authors impose the condition (5). This approach has several limitations including the choice of \kappa, the solution of the subproblem in (5).
 The authors provide two convergence theorems for both the strongly convex case and the nonstrongly case. Unfortunately, the choice of the inner accuracy \epsilon_k depends on the optimal value F which is unknown. In addition, the method for solving (5) is elusive and its convergence guarantee is given by \tildle{O} notion, which does not precisely reflect the real number of iterations of the inner loop. Hence, the overall complexity may be worse than existing methods. In addition, the convergence guarantees in (7) and (11) remain depending on F(x^0) - F, which is different from existing methods.
As far as I observed, the authors fix kappa in Algorithm 1, but this is not a good idea since in the accelerated scheme, the error of the inexact oracle
accumulates. Indeed, the closer we are to the true solution the more exact solution of the subproblem we require. Hence, adaptively update kappa is crucial.
 Clearly, extending Algorithm 1 from noncomposite to composite form has in issues, especially when the regularizer does not have a low cost proximal operator. The inner loop requires such an operator at each iteration.
 Overall, even though the paper contains some new technical contributions, but they are not sufficiently strong. In addition, the convergence analysis has not done rigorously. I think to overcome this limitation, one can exploit the idea of sliding gradient/conditional gradient methods from G. Lan to characterize the convergence of Algorithm 1. This paper proposes a so-called catalyst algorithm for unconstrained convex optimization. In fact, this algorithm can be viewed as an inexact variant of fast proximal method introduced by Guler in [9]. The authors analyze the convergence of their algorithm for two cases: strongly convex and nonstrongly convex. Several extensions and modifications are mentioned but are not rigorously backed up. A few numerical experiments are given to show advantages of their method.