Summary: The authors propose adapting tools from the design and analysis of prediction markets to the problem of learning a good hypothesis when the training data is distributed amongst many parties.
The authors also propose modifications to guarantee differential privacy.
In more detail, the authors propose maintaining a current hypothesis, allowing participants to update this hypothesis (various "betting languages" for doing this are considered), and using a family of convex cost functions (parameterized by a domain element x) to charge/reward participants after the final hypothesis is applied to a test data point.
(The choice of the cost functions is dictated by the loss function.)
Differential privacy is added by adapting the state-of-the-art techniques in "continual observation" models (where one want privacy at each time step, without paying linearly in the number of time steps).
Quality: The stitching together of the various models and techniques is competently done.
The paper feels a bit weak on motivation.
The results have a "here's what we know how to do" flavor to them, as opposed to the more traditional "here's a well-motivated problem" and "here's our solution and why it's better than previous/obvious solutions" narrative.
Clarity: The writing quality is reasonably good.
Originality: None of the tools used are original.
Some of their combinations here appear original.
Significance: I find the results modestly significant. The authors propose adapting tools from the design and analysis of prediction markets to the problem of learning a good hypothesis when the training data is distributed amongst many parties.The authors also propose modifications to guarantee differential privacy.