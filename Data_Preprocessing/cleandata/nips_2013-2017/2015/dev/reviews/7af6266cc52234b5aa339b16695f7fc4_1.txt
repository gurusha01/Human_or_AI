The authors identify a strategy for compensating agents to disclose private and relevant data. The strategy draws on interesting ideas from the machine learning literature, including the use of the stochastic gradient descent algorithm to set the payment for the data. This allows effective compensation of agents while maintaining a limited budget. The authors also include mechanisms for preserving the privacy of agents, and identification of different "profit maximizing" strategies for agent to select given their confidence in their data. It appears that the substantive contribution is
in identifying a mechanism that compensates agents for their data while maintaing a bounded budget.
The usefulness of this family of algorithms hinges on timely, available correct information.
If "true samples" will arise only in the distant future, then section 2.3 is not viable (see below), section 2.1 does not seem to offer much advantage over traditional betting markets (modulo the generalizability to more complex prediction function).
Section 3 does not strike me as addressing a fundamentally serious problem: depending on the type of privacy one is concerned with, there seem to be simpler solutions to keep agent i from learning about agent j: (a) anonymized participation (b) anonymized relations between updates and agents (which agent made which trade is not available to other agents)
The really useful contribution here is a generalization of prediction markets to use sophisticated prediction tools, thus allowing for prediction markets to extend far beyond bets on single binary or scalar variables.
This is cool, but in practice it seems like it would offer little motivation for participation, unless the market happened to run along-side a constant stream of true samples, such that rewards could be evaluated quickly.
(If I won't know what my data is bidding on, how much credit it might get, and when the rewards will come, why should i play?)
Section 2.3 (offering to buy data) seems predicated on knowing the loss function of predictions, which means that the correct answers are known.
In that case, what's even the point of bidding on data?
If the answers are not known, then how does one come up with the marginal gain from a given data point?
Seems to be a pretty fundamental catch-22.
There are a few possible ways out of this, but they all seem to open the system up to being gamed: - Use past true samples to evaluate the worth of new training data.
However, then one can simply offer lots of training data to match known past samples, and reap the rewards by generating fake data to overfit past data. - Use some prediction divergence measure to evaluate the utility of new data (i.e., all data that changes my predictions is good).
This can obviously be gamed by generating crazy data to make predictions veer wildly offtrack.
 Thus, it seems that the only way to set up a cost function is in light of future true samples, and this seems to be a serious limitation insofar as the future is distant.
It absolutely precludes the kind of "selling" scheme in section 2.3 The authors propose a family of market algorithms that extend prediction markets by rewarding incremental improvements in prediction from contributed data.This is a really cool idea, however, the practical applications of this seem very limited because the market requires a known Loss function, so if the object of prediction is not known, then there is no way to set up accurate incentives.