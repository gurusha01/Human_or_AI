I had a couple of main comments/questions.
I would have liked to seen empirical evaluation of the approach on data from NIHL subjects (rather than on modified normal hearing data) for two main reasons. First, it would have been especially useful to see empirical justification for the NIHL mean function and the priors on the various hyper parameters which presumably are key to getting the method to perform sensibly e.g. so a NIHL notch is not explained by the SE fluctuations in a normal audiogram. Second, I have slight concerns about the robustness of the method and exposing it to real data would be a sensible test.
 Is model comparison is really the most sensible approach to diagnosis -- doesn't everyone have some degree of noise induced hearing loss and so shouldn't diagnosis correspond to identifying where on a spectrum the individual is? Would it then not be more sensible/sufficient to do inference in the NIHL model, define the mutual information gain in terms of the parameter 'd', and base diagnosis on the magnitude of this inferred parameter, rather than using a discrete mixture model?  I like the paper and vote of acceptance; the application of active learning approaches to automated audiometry is very sensible. The paper is well written, clear and the model choices and approximations well justified.