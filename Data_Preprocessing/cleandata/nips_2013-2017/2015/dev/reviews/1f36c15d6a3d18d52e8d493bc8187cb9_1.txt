This paper has results about tests like:
H0:
P is monotonone
 versus
 H1: P is no monotone
I like the paper.
The results are interesting. However, I have a few concerns:
1. The sample space you use is a discrete cube.
Why would anyone want
 to test for monotonicity over this space?
In practice, people use
 monotinicity tests for continuous random variables.
Can you cite
 any real data analysis problem where your setting is of scientific interest?
2. You dismiss the statistics literature as concentrating on the large
 sample regime.
This is a bit misleading: many of the tests can be
 made exact by simulating the null distribution. The use of asymptotics
 is often to get precise theoretical results about the power of the
 tests. By precise I mean limits, not bounds.
And there are
 statistics papers that do provide finite sample guarantees.
An
 example is:
 Dumbgen, Lutz, and Guenther Walther.
 "Multiscale inference about a density." The Annals of Statistics (2008): 1758-1785.
 At any rate, your references to the vast statistical literature on this topic
 is too sparse. You need to have more references to the statistical
 literature.
 3. Also, I am not convinced your test really is a finite sample test.
 Suppose I want to use your test and I want to make sure the type I
 error is less than alpha. (You take alpha = 1/3 but I assume you
 can change things to make alpha any user-specified level.) Your
 results say: there exists some N0 such that the type I error is
 less than alpha if the sample size N is larger than N, the type I
 error is less than alpha. The asymptotic statistics tests say: for
 large N the test has type I error close to alpha. I don't see any
 real difference. If I use your test with real data, I have no way
 of knowing if N is bigger than N0. We simply have to assume N is
 large enough. So it seems to me that, at a practical level the same
 as an asymptotic test.
  Interesting paper. But I am not convinced this problem actually comes up in practice. Also, the connections to statistics are dismissed too readily.