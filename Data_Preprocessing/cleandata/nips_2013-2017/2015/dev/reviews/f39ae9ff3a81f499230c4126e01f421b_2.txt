In order to model positive correlations in discrete data that cannot be handled by ordinary Multinomial distributions, in this paper authors propose a Poisson Markov random fields to directly model word correlations in text data. Specifically, because the number of words in a document is known for textual analysis, they show that the normalizing constant of Poisson MRF can be estimated efficiently, which enables the use of the proposed model in
combination with standard topic models like LDA.
While the assumption is simple and the associated inference is efficient, my concern about this paper is the scalability to ordinary texts. Authors used very small set of texts containing just a thousand or so of documents and thus the dimension of the lexicon is quite small. However, actual texts use a lexicon of over some tens of thousands of words, which will preclude the approach to directly modeling word correlations because the number of parameters in Poisson MRF scales in order O(L^2) with L equals the number of words in lexicon. In fact, ordinary texts do not obey the distribution they assume: the length of a document generally distributes according to a Gamma distribution or like, authors argue that it obeys a Poisson or Normal. When the parameter of a Poisson becomes large, its distribution is quite narrow which is by no means similar to actual distributions.
Therefore, if authors would like to argue that this model is useful,
experiments should be conducted not only the very small data of text data but other types of discrete data that have lower number of dimensions. I think this model is more useful for these domains other than for natural
languages. To model positive and negative word correlations, indirect construction using word embeddings might be much more suitable approach, and in fact pursued in the latest work in [1] at ACL 2015. The direct Poisson MRF approach would be persuasive only when compared with these more appropriate baselines.
[1] "Gaussian LDA for Topic Model with Word Embeddings",
 Rajarshi Das, Manzil Zaheer and Chris Dyer, ACL 2015. Poisson MRF for directly modeling word correlations, with efficient inference in the normalizing constant. Not scalable for real texts other than very small experiments in this paper.