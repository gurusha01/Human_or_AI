This paper presents a novel approach to active model selection, which is a crucial problem in machine learning, particularly in diagnostic settings where collecting additional data can be costly and time-consuming. The authors introduce a Bayesian active model selection (BAMS) framework that selects the next data point to query based on the mutual information between the observation and the model posterior. The key strength of this approach is that it does not require model retraining to evaluate candidate points, making it more feasible than previous approaches.
The paper is well-written, and the authors provide a clear and concise introduction to the problem of active model selection and its importance in diagnostic settings. The technical sections of the paper are also well-organized and easy to follow, with a clear explanation of the BAMS framework and its application to Gaussian process models.
One of the significant contributions of this paper is the development of an analytical approximation to the BAMS criterion, which can be used for automatically learning the model class of Gaussian processes with arbitrary observation likelihoods. This approximation is based on a Laplace approximation to the model evidence and hyperparameter posterior, and it allows for efficient computation of the mutual information between the observation and the model posterior.
The authors also demonstrate the effectiveness of their approach in a real-world application, namely, the diagnosis of noise-induced hearing loss (NIHL). They show that their method can diagnose NIHL with drastically fewer samples than existing approaches, and it is extremely fast, enabling diagnosis to be performed in real-time.
However, there are some limitations to the paper. For example, the authors' limitations to monotonic, log-concave, unimodal, and monotonic hazard rate distributions are unclear and require explanation. Additionally, the paper could benefit from a more detailed comparison with other state-of-the-art methods for active model selection.
Overall, the paper presents a significant contribution to the field of machine learning, and it has the potential to impact a wide range of applications, particularly in diagnostic settings. The strengths of the paper include its clear and concise introduction, well-organized technical sections, and significant contributions to the field. The weaknesses of the paper include the lack of clarity on the authors' limitations and the need for a more detailed comparison with other state-of-the-art methods.
Arguments for acceptance:
* The paper presents a novel approach to active model selection, which is a crucial problem in machine learning.
* The authors provide a clear and concise introduction to the problem and its importance in diagnostic settings.
* The technical sections of the paper are well-organized and easy to follow.
* The paper demonstrates the effectiveness of the approach in a real-world application.
* The approach has the potential to impact a wide range of applications, particularly in diagnostic settings.
Arguments against acceptance:
* The authors' limitations to monotonic, log-concave, unimodal, and monotonic hazard rate distributions are unclear and require explanation.
* The paper could benefit from a more detailed comparison with other state-of-the-art methods for active model selection.
* The paper may require additional experimental results to demonstrate the robustness of the approach.