The paper presents an algorithm that essentially replicates the one found in [9], integrating the extrapolation concept from Nesterov's acceleration scheme with the proximal point operator. Notably, while [9] relies on exact minimization at each iteration, which is impractical, the current paper conducts its analysis under more realistic assumptions of approximate minimization, a similarity it shares with [8]. Given that [8] has precedence in publication, the novelty of the current paper should be evaluated based on its unique contributions beyond the overlapping results with [8]. Although the appendix provides a detailed comparison of results between the current paper and [8], a comparative analysis of the methodologies would have been beneficial. One of the significant new findings in this paper is its ability to handle functions that are not strongly convex. However, upon inspection, the proof methods for both strongly convex and general convex cases appear to be similar, raising the question of whether the approach in [8] could be adapted to handle non-strongly convex functions without requiring new insights. 
Another key contribution is the acceleration and enhancement of Finito/MISO, with the modified algorithm bearing a resemblance to a variant of SDCA [24], albeit with distinct differences. The absence of a comparison with SDCA in the experimental results is a significant oversight. The paper offers an analysis of a generalized acceleration method for first-order optimization, leveraging Nesterov's extrapolation idea and the proximal point operator, but the lack of comparison with similar methods, such as SDCA, diminishes the comprehensiveness of the experimental validation.