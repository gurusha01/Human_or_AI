This paper explores the challenge of designing revenue-maximizing auctions based on samples from the user valuation distribution F. The authors establish an upper bound on the required number of samples to achieve an auction with performance close to that of an optimal auction. A crucial component of their approach is the introduction of a class of auctions, denoted as t-level auctions (Ct), where an increase in t leads to one of the auctions in Ct approximating the optimal auction. Notably, t-level functions are characterized by n*t free parameters, enabling the application of fundamental learning theoretic principles to derive an upper bound on the sample requirements for learning a suitable auction. Although the existence of such auctions may be intriguing to a game-theoretic audience, its appeal to the NIPS community is questionable. To generate more interest, the authors could strengthen their case by presenting faster algorithms or demonstrating the learnability of auctions for specific distribution classes (F) with significantly fewer samples or at an accelerated pace. Furthermore, investigating lower bounds on the sample requirements for learning near-optimal auctions would be valuable, particularly in comparison to the common learning problem scenario where sample complexity is near-logarithmic in the covering number. The paper's clarity is commendable, although additional motivational context would benefit readers unfamiliar with the auction theory literature. The primary contribution lies in the demonstration of a nested class of auctions (C1 ⊆ C2 ⊆ ...) where larger t values yield auctions that are nearly optimal. While this result is appreciated, the learning arguments, although straightforward, are existential and computationally demanding, making the overall contribution somewhat incremental. However, the paper's potential to introduce algorithmic game theory problems to the learning community within a learning framework could be a significant plus at NIPS.