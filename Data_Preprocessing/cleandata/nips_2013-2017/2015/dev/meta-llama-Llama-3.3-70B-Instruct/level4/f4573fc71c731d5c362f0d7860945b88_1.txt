The authors present a novel approach to collaborative filtering by integrating the underlying graph structure among users and items, addressing the challenge of sparse data. This methodology is distinct in its ability to simultaneously incorporate graph structure and handle sparse data, marking a significant advancement.
The proposed method is straightforward and well-explained, utilizing block-coordinate ascent to solve a convex problem at each iteration. A notable aspect is the use of conjugate-gradient methods to solve for low-rank factors, potentially avoiding the inefficiencies of slow matrix decompositions. However, it is unclear if this specific application of conjugate-gradient methods is a new contribution.
The authors establish a connection to the nuclear norm minimization work of Srebro and Salakhutdinov (2010), demonstrating that their approach is equivalent to using a weighted atomic norm. The weights in this norm are derived from the graph structure, enabling the authors to derive a consistency bound for recovering the true low-rank matrix. This bound is expressed in terms of a quantity, \alpha_^*, which empirical evidence suggests is substantially smaller for realistic matrices compared to the corresponding bound for matrix completion.
Empirical validation on three real datasets shows that the method outperforms standard matrix completion, achieving a given RMSE in significantly less time. The quality of the work is high, and the explanations are clear. While the originality of certain aspects, such as the application of conjugate-gradient methods within a coordinate-ascent scheme in collaborative filtering, is somewhat uncertain, this could represent a reasonably novel contribution if it indeed is the first such application.
Overall, this paper contributes substantially to the growing field of leveraging underlying structure among users and items for collaborative filtering. It offers both theoretical contributions, such as tighter consistency bounds, and practical advantages, including a method that is faster by orders of magnitude and demonstrates superior performance on real datasets. The paper is well-written, and its contributions are significant, making it a valuable addition to the field.