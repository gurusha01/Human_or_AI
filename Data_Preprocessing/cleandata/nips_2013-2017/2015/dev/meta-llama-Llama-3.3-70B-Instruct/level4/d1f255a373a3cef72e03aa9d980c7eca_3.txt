This paper demonstrates technical soundness, with the supplemental file providing detailed proofs and extensive experiments that support its claims. 
The discussion in Session 6 is noteworthy, particularly the argument that the F-measure, being an aggregate measure, renders the analysis of regret bounds in general online learning meaningless. 
However, in lines 196-197, it would be beneficial to provide the variance of $\hat{h}(\tau)$ with respect to the data distribution, as $\hat{h}(\tau)$ is an unbiased estimate of $h(\tau)$. Alternatively, discussing other estimated functions of $h(\tau)$ could enhance the analysis. 
Furthermore, lines 268-269 suggest that the noisy estimation of $h(.)$ is dependent on the labels, which raises the question of how the decomposition step mitigates this undesirable effect. 
At line 286, clarifying the assumptions required for the online learner would improve the paper's readability. 
In terms of clarity, the paper is well-written and organized, although minor issues persist. The overall idea is easy to follow, but corrections are needed, such as changing the second "-" sign in Eq.(5) to a "+" sign and addressing the error on the right-hand side of Eq.(1). 
Additionally, the notation "P" above the arrow in line 155 should be clarified before its use. Other minor errors, such as "positive a negative" instead of "positive and negative" in lines 65-66, should also be corrected. 
In the pseudo-code, line 7 would benefit from a note explaining that $at$ and $bt$ can be calculated using Eq.(9). Moreover, lines 251-252 require further explanation of the terms "$F_t$-measurable" and "filtration". 
Lastly, in line 296, "conference rate" likely should be "convergence rate". 
The paper's originality lies in its exploration of the online optimization problem for a non-decomposable metric, the F-score, a less explored area in the community. The idea presented is novel and contributes to the field. 
In terms of significance, the paper has the potential to spark further research interest in the online learning community, given the nice properties of the four fundamental quantities (true/false positive/negative rate) and the challenging open problems related to F-measure optimization. The proposed online algorithm for thresholding a given classifier to maximize the F-score, along with the proven convergence of the online F-scores to the optimal F-score and the extensive experimental verification, underscores the paper's significance and potential for future research.