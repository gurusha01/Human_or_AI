This paper presents some novel technical contributions, but its core concept and theoretical framework require further development. Specifically, Algorithm 1 can be seen as a simplified, inexact version of Guler's fast proximal method, as described in [9], with the added condition (5). However, this approach is limited by factors such as the selection of \kappa and the resolution of the subproblem in (5).
The authors provide convergence theorems for both strongly convex and non-strongly convex cases. Nonetheless, the choice of inner accuracy \epsilon_k is dependent on the optimal value F, which is unknown. Furthermore, the method for solving (5) lacks clarity, and its convergence guarantee is expressed using the \tildle{O} notation, which does not accurately reflect the actual number of iterations in the inner loop. As a result, the overall complexity may be inferior to existing methods. Additionally, the convergence guarantees in (7) and (11) rely on F(x^0) - F, differing from existing methods.
Upon examination, it appears that the authors fix \kappa in Algorithm 1, which is not ideal, as the error of the inexact oracle accumulates in the accelerated scheme. In fact, as the true solution is approached, a more exact solution to the subproblem is required, making adaptive updates of \kappa crucial.
Extending Algorithm 1 from non-composite to composite form poses significant challenges, particularly when the regularizer lacks a low-cost proximal operator. The inner loop necessitates such an operator at each iteration, which can be problematic.
While the paper offers some new technical insights, they are not sufficiently robust. Moreover, the convergence analysis lacks rigor. To address this limitation, incorporating the concept of sliding gradient/conditional gradient methods, as proposed by G. Lan, could provide a more comprehensive characterization of Algorithm 1's convergence. This algorithm can be viewed as an inexact variant of the fast proximal method introduced by Guler in [9]. The authors analyze its convergence for strongly convex and non-strongly convex cases, mentioning several extensions and modifications, although these are not thoroughly substantiated. A limited number of numerical experiments are presented to demonstrate the method's advantages.