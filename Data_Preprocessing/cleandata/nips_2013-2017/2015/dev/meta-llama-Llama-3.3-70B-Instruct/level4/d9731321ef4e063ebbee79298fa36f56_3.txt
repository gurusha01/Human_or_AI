I have several key observations and inquiries regarding the submission.
Firstly, I believe it would be beneficial to conduct an empirical assessment of the proposed approach utilizing data from individuals with noise-induced hearing loss (NIHL) rather than relying on modified data from subjects with normal hearing. This is crucial for two primary reasons: firstly, to provide empirical validation for the NIHL mean function and the priors assigned to the various hyperparameters, which are essential for the method's sensible performance, such as distinguishing a NIHL notch from standard errors in a normal audiogram; and secondly, to address my concerns regarding the method's robustness, which could be effectively tested by exposing it to real-world data.
Furthermore, I question whether model comparison is the most appropriate approach for diagnosis, given that noise-induced hearing loss exists on a spectrum and virtually everyone exhibits some degree of it. Wouldn't a more suitable diagnostic strategy involve identifying an individual's position on this spectrum? To this end, it might be more sensible and sufficient to perform inference within the NIHL model, define the mutual information gain in terms of the parameter 'd', and base diagnosis on the magnitude of this inferred parameter, rather than employing a discrete mixture model. Overall, I find the paper to be well-written, clear, and justified in its model choices and approximations, and I support its acceptance, as the application of active learning approaches to automated audiometry is a sensible and valuable contribution.