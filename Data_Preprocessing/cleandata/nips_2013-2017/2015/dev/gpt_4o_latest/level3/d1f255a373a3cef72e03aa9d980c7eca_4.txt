The paper addresses the problem of training classifiers to maximize the F-measure in an online setting, a challenging task due to the non-decomposability of the F-measure. While prior work has focused on batch settings, where optimal thresholds are tuned on validation sets, this paper introduces an online learning algorithm that adaptively determines the optimal threshold. The authors provide a formal analysis of the algorithm, proving its statistical consistency under certain assumptions, and validate its performance through comprehensive experiments.
Strengths:  
The paper is well-written and clearly organized, making it accessible to readers with a background in machine learning. The theoretical contributions are solid, with proofs of consistency and a detailed explanation of the algorithm's mechanics. The proposed method is innovative in its ability to operate in a purely online setting without requiring a hold-out validation set, which is a significant advantage in streaming data scenarios. The experimental section is thorough, covering multiple datasets and comparing the proposed method (OFO) with the widely used 2-stage F-measure maximization approach (2S). The results demonstrate that OFO performs competitively with 2S while offering the added benefit of being applicable in one-pass learning scenarios. The inclusion of an appendix with additional experiments and proofs further strengthens the paper's rigor.
Weaknesses:  
The primary concern is the paper's novelty. While the authors present a compelling algorithm, the reviewer lacks sufficient expertise in this specific area to confidently assess whether the approach is a significant departure from prior work. Additionally, while the discussion section briefly mentions related work on AUC maximization, it would benefit from a more detailed comparison with other non-decomposable metric optimization methods, particularly in online settings. This would help situate the contribution more clearly within the broader literature. Finally, there is a minor formatting issue on Line 454, where an extra space appears in the word "consistency."
Pro and Con Arguments for Acceptance:  
Pro:  
1. The paper addresses an important and challenging problem in online learning.  
2. The proposed algorithm is theoretically sound and empirically validated.  
3. The method's applicability to one-pass learning scenarios is a practical advantage.  
Con:  
1. The novelty of the contribution is unclear without deeper domain expertise.  
2. The discussion section could be expanded to include more comparisons with related work.  
Recommendation:  
I recommend accepting the paper, as it provides a well-rounded contribution combining theory, algorithms, and experiments. However, I encourage the authors to address the minor formatting issue and expand the discussion section to include comparisons with AUC maximization and other non-decomposable metric optimization methods.