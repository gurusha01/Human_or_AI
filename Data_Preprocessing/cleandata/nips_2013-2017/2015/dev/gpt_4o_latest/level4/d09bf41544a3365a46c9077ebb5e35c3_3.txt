This paper addresses the question of whether it is feasible to predict the temporal evolution of objects in a scene by analyzing video streams of that scene. For example, when observing a block move in a particular manner, we naturally form an expectation of its trajectory, presumably due to an intuitive physics model embedded in our cognitive system. This topic has been explored in recent literature, some of which the authors appropriately cite.
The paper's contribution lies in employing a deep learning tool to extract visual features, which is integrated with a Bayesian generative framework to model the dynamics of objects. The Bayesian formulation presented in Equation 1 is a standard representation of how physical parameters translate into visual features. The authors focus on observed velocity, obtained via a tracker, as the primary observable.
The key contribution, as I interpret it, is the application of these tools in an experiment demonstrating the system's ability to predict the scene's evolution based on partial video traces. The paper presents several variations of this experiment, showcasing the system's capability to perform both classification tasks (e.g., predicting discrete labels such as whether an object will or will not hit a specific point) and regression tasks (e.g., predicting continuous variables like the magnitude of motion).
However, beyond the use of LeNet to extract visual features, the broader argument does not appear particularly surprising. The approach essentially mirrors inverse problem-solving methods long employed in fields such as meteorology and the oil industry, where much more complex dynamics (e.g., fluid flow and viscosity estimation) are routinely modeled. Given this context, it is not entirely unexpected that Equation 1 could be used to estimate an object's mass.
The comparison to human perception is intriguing and represents a perspective not typically considered by statisticians working on inverse problems. However, this aspect is not explored in depth. The paper includes only superficial references to cognitive hypotheses without substantive claims or arguments. For instance, the statement on page 2 suggesting that a certain type of model would require an innate physics engine is a significant assumption, but the paragraph ends without further elaboration or discussion.
In conclusion, while the use of a deep learning tool to extract visual features is timely (albeit not presented as a novel contribution of this paper), I remain uncertain about the paper's originality and significance relative to prior work on this topic. The paper employs a generative model framework to infer physical properties of objects in a video dataset, demonstrating that useful predictions about scene evolution can be made. However, the generative model itself is a standard Bayesian formulation, and its integration with deep learning for prediction does not appear to offer substantial novelty. While the results are valid, their significance beyond existing work in the field remains unclear to this reviewer.