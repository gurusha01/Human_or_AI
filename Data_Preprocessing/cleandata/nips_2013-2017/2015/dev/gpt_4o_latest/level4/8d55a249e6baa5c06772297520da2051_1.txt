Review - Paraphrased Version:
Summary:  
This paper proposes a framework for learning complex structured output representations by extending variational auto-encoders (VAEs) to "conditional VAEs," which are conditioned on the input data \(x\).
Quality:  
The paper is generally well-written but could benefit from occasional improvements.  
Clarity:  
The core idea is clearly conveyed, though some details are lacking.  
Originality:  
While conditional VAEs appear to be a natural extension of standard VAEs, the topic is certainly worth exploring and discussing.  
Significance:  
The significance of the work could be enhanced through a more comprehensive evaluation, demonstrating results for various modifications.
Comments:  
- The term "generative" is typically used to describe models that learn distributions involving the input data. However, the proposed conditional variational auto-encoder approach does not generate data via \(p(x)\), which might confuse readers.  
- The paper discusses three possible methods for inference, i.e., estimating \(y\) given \(x\). Two of these methods are evaluated on toy data, but it remains unclear which method from Section 3.1 the authors recommend.  
- The authors mention a measurable gap (line 148) during or after training, quantified by the regularization term, where the proposal \(q(z|x,y)\) and the prior \(p(z|x)\) do not perfectly align. How large is this gap?  
- To address the gap, the authors propose introducing a Gaussian stochastic neural network that directly models the reconstruction term, thereby avoiding regularization via the KL divergence. They suggest a weighted combination of the conditional VAE (computing both regularization and reconstruction) and the new network (computing only reconstruction) as the cost function. However, this approach seems counter-intuitive. Intuitively, one would expect the regularization gap between the distributions to decrease if more weight were assigned to the regularization term rather than the reconstruction term. Could the authors provide an explanation? Additionally, how were the weighting parameter \(\alpha\) and its final value determined or cross-validated?  
- There is a substantial body of work on semantic image segmentation using CNNs. For fairness, the authors should consider citing a few more recent techniques.  
- More details about the noise injection into data \(x\) would be helpful for readers. What specific steps did the authors take?  
- Readers would also benefit from quantitative results regarding the modifications described in Section 3.3.2. For instance, how critical is the "latent-to-output" pathway? Furthermore, how much performance improvement was achieved by using the direct output prediction as input for the conditional prior network? Additionally, clarification is needed on whether the conditional prior network was trained using only the direct output prediction as input or both the data \(x\) and the prediction \(\tilde{y}\). While some modifications are explored in Table 3, a more detailed ablation study would be highly valuable.  
- Given that the conditional VAE involves multiple networks, it would be helpful to understand whether its improved performance is primarily due to the increased number of trainable parameters. Could the authors comment on this?  
- The abstract mentions efficiency, but there is no discussion of training and inference times. Could the authors provide details on this?  
---  
As noted by other reviewers, additional citations could improve the completeness of the paper. Extending variational autoencoders to conditional distributions is a valuable contribution. However, the paper could be strengthened by including the missing details and conducting a more thorough evaluation.