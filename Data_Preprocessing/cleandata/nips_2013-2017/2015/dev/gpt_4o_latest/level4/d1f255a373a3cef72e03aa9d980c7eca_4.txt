The paper addresses the challenge of training classifiers to maximize the F-measure in an online learning setting. The F-measure, defined as the ratio of two linear functions, is non-decomposable, making it fundamentally different from traditional loss functions. While most existing methods for optimizing the F-measure operate in the batch setting and rely on determining the optimal threshold of probabilistic classifiers using a validation set, this work introduces an online learning algorithm to identify the optimal threshold. The authors provide consistency proofs under various assumptions and support their approach with extensive experiments, including additional results in the appendix, to validate the method's performance.
Overall, the paper is well-written, and I appreciate the clear presentation of the proof for Theorem 3. The theoretical contributions appear robust, and the experimental results are reasonably persuasive.
This topic is outside my primary area of expertise, so I am less confident in assessing the novelty of the technical contributions relative to existing work on F-measure maximization. Nevertheless, I find the paper's balanced integration of theory, algorithm design, and experimental validation commendable.
Minor comments:
- In the Discussion section (Section 6), it would be beneficial to expand the comparisons with [9]. Additionally, there are two relevant papers on generalization performance in the context of AUC maximization in the online setting:
  1. Wang et al., Generalization bounds for online learning algorithms with pairwise loss functions, COLT 2012
  2. Kar et al., On the generalization ability of online learning algorithms for pairwise loss functions, ICML 2013
- Line 454: There is an extra space in "consistency."
In summary, this paper introduces an online learning algorithm for optimizing the F-measure, offering a well-rounded contribution that combines theoretical insights, algorithmic development, and experimental validation.