The paper addresses the problem of matrix completion in a scenario where the row and column variables are associated with graphs. The authors propose a scalable alternating least squares (ALS) algorithm. Additionally, they demonstrate that the regularizer in the optimization problem can be interpreted as a generalized form of the weighted nuclear norm and establish statistical consistency guarantees for the low-rank matrix estimators. Experimental results on a movie ratings dataset show that their method achieves the lowest RMSE compared to leading approaches. Moreover, their ALS algorithm is shown to scale significantly better—by orders of magnitude—than stochastic gradient descent (SGD).
a. The explanation of how the row and column graphs are constructed from the MovieLens dataset is insufficiently detailed in the paper; this requires clarification.
b. Sections 5 and 5.1 are challenging to comprehend. For instance, terms like "spikiness" are not defined, even though they are critical for understanding the main theoretical results and the comparison to standard matrix completion approaches.
c. Why is there no RMSE table for the three large datasets? From Figure 2, it is unclear whether the RMSE of GRALS is comparable to or worse than the other methods (though it is evident that GRALS scales better).  
The optimization framework presented in this paper—graph-structured matrix factorization with partial observations—appears to be novel and is likely to attract significant interest within the collaborative filtering community. The proposed solution is grounded in weighted norm minimization, akin to the work of Srebro and Salakhutdinov (2010). The authors convincingly demonstrate that their alternating least squares algorithm is far more efficient than SGD and outperforms leading methods that incorporate side information. However, I found the writing in critical sections to be difficult to follow, and I did not verify the proofs.