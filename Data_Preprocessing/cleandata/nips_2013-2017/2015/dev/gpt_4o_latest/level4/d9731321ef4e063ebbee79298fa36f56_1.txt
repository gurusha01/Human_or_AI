Summary
The authors present a novel approach for actively selecting the model that best aligns with a given dataset. Unlike active learning, which focuses on selecting the next data point to refine model hyperparameter estimates, this method identifies the next point to better differentiate between a set of candidate models. While similar techniques for active model selection exist, they typically require retraining each model for every new data point. The key advantage of the proposed method is that it only necessitates evaluating the predictive distributions of the models, eliminating the need for retraining.
The authors apply their method to the problem of detecting noise-induced hearing loss (NIHL). Traditional NIHL screening involves testing across a broad range of intensities and frequencies, which is time-intensive. The authors demonstrate that their method can significantly reduce the number of required tests, thereby lowering the cost of large-scale NIHL screenings.
Quality
The paper is technically sound, and the derivations appear reasonable, though they are not presented in detail. However, the work lacks theoretical justification or discussion, and the empirical evaluation is insufficient. The authors compare their active model selection approach only against a "traditional" active learning algorithm and a random baseline, using simulated data generated from their own model (which could introduce bias). Ideally, the method should also be tested on real-world data with genuine NIHL cases (rather than model-generated data) and compared against other active model selection techniques. Additionally, critical aspects such as defining the set of candidate points or models are not addressed.
Clarity
The paper is exceptionally well written, with a clear structure. The relevance and potential utility of the proposed method are effectively introduced, and the application to NIHL detection is particularly well explained. Overall, it is a pleasure to read.
Originality
As noted by the authors, active model selection is a less explored area compared to active learning. The proposed method builds on existing approaches (e.g., maximizing mutual information instead of expected cross-entropy) and leverages established approximations for its implementation. The application to NIHL detection is also novel and not extensively studied in the literature.
Significance
The method offers a notable complexity advantage over existing approaches, as it avoids the need to retrain models for each new candidate point. This improvement enables real-time application, which is crucial for certain use cases. Furthermore, the method significantly reduces the number of testing points required for NIHL screening, which could have a substantial impact on large-scale screening efforts by lowering costs.
Pros
* Clear and well-written paper  
* Novel method for active model selection that avoids retraining models  
* Demonstrates significant reductions in the number of samples required for an important and practical application  
Cons
* Lack of theoretical analysis or discussion of the proposed method  
* Limited empirical evaluation  
* No comparison with other active model selection techniques  
* Evaluation relies on simulated data generated from the authors' own model, potentially introducing bias  
* No discussion on how to define the set of candidate points or models  
The proposed active model selection method appears promising, and its application to NIHL detection is both practical and impactful. However, the evaluation is unconvincing, and the paper does not address critical issues such as the selection of candidate locations and models.