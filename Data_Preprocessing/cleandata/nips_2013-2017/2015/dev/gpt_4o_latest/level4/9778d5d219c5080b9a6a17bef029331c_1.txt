Quality:  
This paper presents an elegant and well-executed approach to a long-standing problem. The methodology is clearly articulated, with well-founded motivations and well-conducted experiments. The analysis is thorough (the rightmost columns of Figure 2 are particularly intriguing), but additional exploration of the relationship between the variance of estimators and the error at specific locations would strengthen the work. While a strong correlation between these factors might be expected, the figures suggest otherwise, which warrants further investigation.
Clarity:  
The paper is exceptionally well-written, easy to understand, and employs notation effectively. A few minor suggestions for improvement: consider using boldface characters for all vector properties (e.g., chromaticity, pixels) to better distinguish them from scalars. Additionally, some key equations are presented inlineâ€”those on lines 158, 216, and 237 would benefit from being displayed as standalone numbered equations or given clearer separation. Lastly, in line 308, "it's" should be corrected to "its."
Originality:  
The paper introduces an original approach to a well-established problem.
Significance:  
The problem addressed is a classic one that remains relevant to a significant portion of the vision community. While I am uncertain whether NIPS is the ideal venue for this work, its quality makes it a strong candidate. The paper proposes a method for achieving color constancy in images by learning the conditional chromaticity distribution based on pixel luminance. This is accomplished by modeling empirical histograms from a training set and globally optimizing these histograms using gradient descent on a cost function. Interestingly, luminance proves to be a highly informative predictor of illumination chromaticity (up to standard scaling constants) even when pixels are treated independently. The method is computationally efficient, and the results are both visually appealing and numerically impressive.