Review:
Quality:  
This paper is technically robust, with the supplemental file providing comprehensive proofs and a wide range of experimental results.  
The discussion in Section 6 is both engaging and insightful, particularly the argument that the F-measure, being an aggregate metric, renders it illogical to analyze regret bounds in the context of general online learning.  
- In lines 196-197, while $\hat{h}(\tau)$ is presented as an unbiased estimator of $h(\tau)$, what is its variance with respect to the data distribution? Alternatively, it would be beneficial to include discussions on other estimators of $h(\tau)$.  
- Additionally, in lines 268-269, it is mentioned that the noisy estimation of $h(.)$ is influenced by the labels. How does the decomposition step mitigate this undesirable effect?  
- In line 286, it would be helpful to explicitly state the assumptions required for the online learner.  
Clarity:  
The paper is well-written and logically structured, though there are a few minor issues.  
The main idea of the paper is straightforward and easy to comprehend.  
- For instance, the second "-" sign in Eq.(5) should be corrected to a "+" sign.  
- There appears to be an error in the far-right-hand side of Eq.(1).  
- In line 155, the meaning of "P" above the arrow should be clarified before its usage.  
- In lines 65-66, "positive a negative" should be revised to "positive and negative."  
- In line 7 of the pseudo-code, it would be helpful to include a note indicating that $at$ and $bt$ can be computed using Eq.(9).  
- In lines 251-252, further explanation of $F_t$-measurable and filtration would enhance clarity.  
- In line 296, "conference rate" seems to be a typo and should likely be "convergence rate."  
Originality:  
This paper addresses the online optimization problem for a non-decomposable metric, the F-score, which has been relatively underexplored in the research community. The reviewer finds the proposed idea to be novel.  
Significance:  
Given the valuable properties of the four fundamental quantities (true/false positive/negative rates), this paper lays a foundation for further exploration. Additionally, since the F-score function is neither convex nor concave and exhibits a decomposition property, it presents numerous challenging open problems for F-measure optimization. The reviewer believes this work has the potential to spark further research interest within the online learning community.  
In this paper, the authors propose an online algorithm to threshold a given classifier for the purpose of maximizing the F-measure. They also prove the convergence of the online F-scores generated by their algorithm to the optimal F-score. Extensive experiments are conducted to validate the convergence properties established in the theoretical analysis.