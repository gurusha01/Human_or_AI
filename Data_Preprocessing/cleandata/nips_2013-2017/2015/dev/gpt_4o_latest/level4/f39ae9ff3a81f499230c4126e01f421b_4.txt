This paper introduces a tractable extension of the Poisson MRF model, termed the Fixed-Length Poisson MRF (LPMRF), which is capable of modeling positive dependencies. The authors employ this model as the emission distribution for an admixture model akin to LDA, where each topic encodes additional information about pairwise dependencies (correlations) between word types. When applied to text data, the model demonstrates intriguing and competitive results, even with as few as three topics.
My main technical question concerns the boundary between modeling topics and modeling word dependencies. If we had a perfect model of word dependencies, would there still be a need for a mixture model over topics? Are the topics compensating for higher-order (e.g., ternary) dependencies that this particular word dependency model cannot easily capture? With a sufficiently large number of topics, the top words alone might suffice as results, as seen in LDA. The intuitive interpretation of word type dependencies could become more questionable if the model were applied with more topics. This is particularly relevant because each topic captures specific positive and negative dependencies, which may interact across topics in complex ways that are challenging to analyze or present intuitively.
A significant concern is the scalability of the proposed approach. How well does the method scale with increasing vocabulary size? As the number of topics grows, the memory requirements may become prohibitive. How many word types were included in your dataset? Why did you not test the model with a larger number of topics?
This paper makes a valuable modeling contribution by developing a fixed-length PMRF with distinct properties compared to the original PMRF distribution. However, its contribution to inference is relatively modest, as it relies on existing techniques that optimize a pseudo-likelihood. Why did you choose optimization over parameter sampling?
The paper references the Admixture of Poisson MRFs model multiple times but does not provide sufficient details. Please include a discussion of this in the related work section. Additionally, cite relevant collocation literature from linguistics and contrast your approach with it. While your model identifies long-range dependencies rather than sequential word relationships, the output appears similar, except that word order in the pairs is irrelevant.
In Section 3, you state that LDA "does not capture dependencies between words because there is only one word being drawn at a time." While this is true from a generative perspective, I would argue that, inferentially, allowing for a sufficient number of topics can capture many types of positive dependencies.
The proposed model achieves only marginal improvements over LDA in terms of perplexity. However, perplexity is widely regarded as a poor indicator of topic quality, and numerous existing topic models outperform LDA in terms of perplexity scores.
The negative dependencies presented in Table 1 are far less interpretable than the positive dependencies. Please provide further commentary on this observation.
Your model might find more compelling applications outside of topic modeling, such as in event count modeling for political science, where relationships are less well understood and the relationships themselves are of primary interest as objects of study.
Minor Comments
- Move Figure 1 to page 2. It is highly effective and deserves earlier placement. What value of \( L \) was used to generate these graphs?
- Standardize your model names and acronyms. For instance, what does CPMRF stand for in Equation 1?
- Specify the size of the dependency matrix used to generate Figure 3.
- In the caption for Figure 4, clarify that lower perplexity values are better.
- Increase the font size in all figures for better readability.
- Avoid using \( \theta \) and \( \Theta \) as distinct parameters. Similarly, refrain from using \( e \) both as the mathematical constant and as a vector of ones in your proof. These notations are confusing.
- Move the Monte Carlo sampling section before the Upper Bound section in 2.1 for better logical flow.
- On page 5, use bold font for "LPMRF" in the generative process to emphasize that this is the paper's main contribution.
- In Section 4, you mention optimizing the Dirichlet parameter \( \beta \). Did you mean \( \alpha \)?
In summary, this paper proposes a tractable extension of the Poisson MRF model that accommodates positive dependencies and uses this distribution as a topic-specific emission model incorporating positive and negative pairwise correlations between word types. While the paper is statistically interesting and makes incremental contributions to document topic modeling, its advances are relatively modest.