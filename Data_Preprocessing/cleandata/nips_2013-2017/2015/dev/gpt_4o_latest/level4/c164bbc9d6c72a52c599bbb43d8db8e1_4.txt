This paper builds upon Nesterov's initial acceleration technique for proximal point algorithms by addressing inexact solutions to subproblems. The authors introduce nontrivial modifications to existing analyses, enabling controlled inexactness and deriving the global convergence rate as a function of this inexactness.
The technical contributions are presented with clarity and high quality. To the best of my knowledge, the work is original and introduces a novel unified framework that enhances our understanding of accelerating first-order methods with inexact inner solvers.
While I found it somewhat disappointing that Theorem 3.3 requires the level of inexactness to decrease at a rapid rate as global iterations progress, this outcome is not unexpected.
Overall, this paper offers a unified framework and analysis for accelerating first-order optimization methods, carefully considering the inexactness in solving subproblems and demonstrating its impact on convergence rates. Although I did not verify all the proofs in detail, the theoretical results appear solid and provide valuable insights into these widely recognized acceleration techniques.