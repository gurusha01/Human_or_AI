I have a couple of primary comments and questions.
Firstly, I would have preferred to see an empirical evaluation of the proposed approach on data from NIHL subjects rather than on modified normal hearing data. This is important for two main reasons. One, it would provide empirical justification for the NIHL mean function and the priors on the various hyperparameters, which are presumably critical for ensuring the method performs as intendedâ€”for example, to prevent a NIHL notch from being incorrectly explained by SE fluctuations in a normal audiogram. Two, I have minor concerns regarding the robustness of the method, and testing it on real data would serve as a reasonable way to address these concerns.
Secondly, I wonder if model comparison is truly the most appropriate approach for diagnosis. Given that nearly everyone experiences some degree of noise-induced hearing loss, wouldn't it make more sense for diagnosis to involve determining where an individual falls on a spectrum? In that case, wouldn't it be more practical and sufficient to perform inference within the NIHL model, define the mutual information gain in terms of the parameter 'd,' and base the diagnosis on the magnitude of this inferred parameter, rather than relying on a discrete mixture model?
Overall, I find the paper to be well-executed and recommend acceptance. The application of active learning approaches to automated audiometry is highly appropriate. The paper is well-written, clear, and the model choices and approximations are well-justified.