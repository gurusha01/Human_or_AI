The paper addresses the problem of low-rank matrix completion with additional structural information encoded via graphs, a significant extension to traditional collaborative filtering approaches. The authors propose a novel framework, Graph Regularized Alternating Least Squares (GRALS), which incorporates graph-based structural information into matrix completion tasks. The paper demonstrates that this approach generalizes weighted nuclear norm formulations and provides statistical consistency guarantees. The proposed method is validated on synthetic and real-world datasets, showing significant scalability improvements—up to two orders of magnitude faster—over state-of-the-art stochastic gradient descent methods. The authors also provide theoretical insights, including a connection to generalized weighted nuclear norms and bounds on statistical consistency.
Strengths:
1. Technical Novelty: The paper introduces a scalable algorithm for graph-regularized matrix completion, which is a meaningful advancement over existing methods. The use of conjugate gradient-based alternating minimization is well-motivated and efficient.
2. Theoretical Contributions: The authors provide a rigorous theoretical foundation, including statistical consistency guarantees and a connection to generalized weighted nuclear norms. These contributions are valuable for understanding the method's robustness and applicability.
3. Scalability: The proposed GRALS algorithm demonstrates impressive scalability, handling datasets with over 55 million observations. This is a significant improvement over existing methods, making the approach practical for large-scale applications.
4. Empirical Validation: The experimental results are thorough, comparing GRALS against multiple baselines on both synthetic and real-world datasets. The results convincingly demonstrate the method's efficiency and comparable accuracy.
5. Clarity of Contributions: The paper clearly delineates its contributions, including algorithmic efficiency, theoretical guarantees, and empirical validation.
Weaknesses:
1. Limited Comparison to Non-Graph Methods: While the paper compares GRALS to graph-based methods, it would be useful to see a more detailed comparison to state-of-the-art non-graph-based matrix completion techniques to highlight the added value of graph regularization.
2. Graph Construction Details: The paper assumes the availability of graphs but does not extensively discuss how graph quality or construction methods impact performance. This could be a critical factor in real-world applications.
3. Practical Limitations: The method assumes that graph Laplacians are given or can be constructed efficiently. In some domains, constructing these graphs might be computationally expensive or infeasible.
4. Clarity in Theoretical Results: While the theoretical results are strong, the presentation is dense and may be challenging for readers unfamiliar with advanced optimization techniques. Simplifying or summarizing key takeaways could improve accessibility.
Arguments for Acceptance:
- The paper provides a novel and scalable solution to a well-studied problem, with strong theoretical and empirical support.
- The method is highly relevant to the NeurIPS audience, given its focus on efficient algorithms and theoretical guarantees.
- The scalability and practical applicability of the method make it a valuable contribution to the field.
Arguments Against Acceptance:
- The reliance on graph information may limit the method's applicability in domains where such information is unavailable or expensive to compute.
- The paper could improve in terms of clarity, particularly in the theoretical sections.
Recommendation:
I recommend acceptance of this paper. While there are minor weaknesses, the strengths in terms of novelty, scalability, and theoretical rigor outweigh them. The paper makes a significant contribution to the field of matrix completion and collaborative filtering, particularly in scenarios where graph-based structural information is available.