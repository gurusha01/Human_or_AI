This paper proposes a novel approach to analyzing differences between high-dimensional distributions, termed Principal Differences Analysis (PDA). The method operates by finding the projection that maximizes the Wasserstein divergence between the resulting univariate populations. The authors also introduce a sparse variant of the method, SPARDA, which identifies features responsible for the differences between distributions.
The paper is well-written, and the ideas are clearly presented. The authors provide a thorough review of related work and demonstrate the superiority of their approach over existing methods, such as sparse linear discriminant analysis and logistic lasso, in identifying relevant features. The experimental results are convincing, and the application of SPARDA to real-world data, including single-cell RNA-seq data, is impressive.
The strengths of the paper include its novelty, clarity, and thoroughness. The authors provide a detailed explanation of the methodology, including the optimization problem and the algorithms used to solve it. The paper also includes a comprehensive review of related work and a thorough evaluation of the method's performance.
However, there are some weaknesses to the paper. The authors could provide more insight into the theoretical properties of the SPARDA framework, particularly in the high-dimensional setting. Additionally, the paper could benefit from a more detailed analysis of the relationship between the layer width and the first-layer budget.
In terms of the conference guidelines, the paper meets the criteria for quality, clarity, and originality. The paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The paper is clearly written, and the ideas are well-organized and easy to follow. The approach is novel and differs from previous contributions, and the authors provide a thorough review of related work.
Arguments for acceptance:
* The paper proposes a novel approach to analyzing differences between high-dimensional distributions.
* The method is well-motivated, and the authors provide a thorough review of related work.
* The experimental results are convincing, and the application of SPARDA to real-world data is impressive.
* The paper is well-written, and the ideas are clearly presented.
Arguments against acceptance:
* The paper could benefit from more insight into the theoretical properties of the SPARDA framework, particularly in the high-dimensional setting.
* The analysis of the relationship between the layer width and the first-layer budget could be more detailed.
* The paper may not be suitable for a general audience, as it assumes a strong background in machine learning and statistics.
Overall, I recommend accepting the paper, as it makes a significant contribution to the field of machine learning and statistics. The paper's strengths outweigh its weaknesses, and the authors provide a thorough and well-written presentation of their ideas.