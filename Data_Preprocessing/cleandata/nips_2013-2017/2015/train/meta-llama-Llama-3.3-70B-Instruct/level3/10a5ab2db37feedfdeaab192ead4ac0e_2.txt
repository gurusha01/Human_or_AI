This paper proposes a novel approach to batch learning from logged bandit feedback (BLBF) by introducing a self-normalized risk estimator that avoids the propensity overfitting problem inherent in the conventional unbiased risk estimator. The authors demonstrate the effectiveness of their approach, called Norm-POEM, on several multi-label classification problems, showing that it consistently outperforms the conventional estimator.
The paper is well-written, clear, and original, with a thorough discussion of related work and a detailed explanation of the proposed method. The authors provide a rigorous theoretical analysis of the self-normalized risk estimator and demonstrate its advantages over the conventional estimator through extensive experiments.
The strengths of the paper include:
* A clear and concise introduction to the problem of BLBF and the limitations of the conventional unbiased risk estimator
* A thorough discussion of related work, including the Counterfactual Risk Minimization (CRM) principle and various counterfactual estimators
* A detailed explanation of the proposed self-normalized risk estimator and its advantages over the conventional estimator
* Extensive experiments demonstrating the effectiveness of Norm-POEM on several multi-label classification problems
The weaknesses of the paper include:
* The paper assumes a certain level of familiarity with BLBF and counterfactual estimation, which may make it difficult for non-experts to follow
* The experimental evaluation could be more comprehensive, including more datasets and comparison to other state-of-the-art methods
* The paper could benefit from a more detailed discussion of the computational efficiency of Norm-POEM and its potential applications in real-world scenarios
Overall, the paper makes a significant contribution to the field of BLBF and counterfactual estimation, and the proposed self-normalized risk estimator has the potential to improve the performance of BLBF algorithms in a wide range of applications.
Arguments for acceptance:
* The paper proposes a novel and effective approach to BLBF that addresses a significant limitation of the conventional unbiased risk estimator
* The paper provides a thorough theoretical analysis and extensive experimental evaluation of the proposed method
* The paper has the potential to impact a wide range of applications, including recommendation systems, advertising, and healthcare
Arguments against acceptance:
* The paper assumes a certain level of familiarity with BLBF and counterfactual estimation, which may limit its accessibility to non-experts
* The experimental evaluation could be more comprehensive, including more datasets and comparison to other state-of-the-art methods
* The paper could benefit from a more detailed discussion of the computational efficiency and potential applications of Norm-POEM.