This paper proposes a novel algorithm for sparse and low-rank tensor decomposition, which is a fundamental problem in machine learning and signal processing. The authors extend existing ideas on simultaneous diagonalization and low-rank and sparse matrix recovery to third-order non-symmetric tensors, providing a convincing mathematical framework for their approach.
The algorithm is based on a reduction of the tensor decomposition problem to sparse and low-rank matrix decomposition via tensor contraction. The authors use well-understood convex techniques to solve the reduced matrix sub-problem, which allows them to perform the full decomposition of the tensor. The paper provides theoretical guarantees for the algorithm, including conditions under which exact recovery is possible.
The strengths of the paper include its originality, clarity, and the fact that it addresses a difficult problem in a better way than previous research. The algorithm is computationally efficient and scalable, with a computational complexity of O(n^3), which is a significant improvement over existing methods. The paper also provides numerical experiments to validate the approach, demonstrating its effectiveness in recovering the low-rank and sparse components of a tensor.
However, there are some weaknesses to the paper. The evaluation of the proposed algorithm is limited to synthetic data, and it would be beneficial to include experiments on non-synthetic data to demonstrate the algorithm's robustness. Additionally, the use of multiple contractions and random projections is unclear and could affect the stability of diagonalization, particularly for non-symmetric tensors requiring three sets of eigenvectors.
Overall, the paper is well-written, and the authors provide a clear and concise explanation of their approach. The algorithm has the potential to be useful in a variety of applications, including machine learning, signal processing, and data analysis.
Arguments pro acceptance:
* The paper proposes a novel and original algorithm for sparse and low-rank tensor decomposition.
* The algorithm is computationally efficient and scalable, with a computational complexity of O(n^3).
* The paper provides theoretical guarantees for the algorithm, including conditions under which exact recovery is possible.
* The numerical experiments demonstrate the effectiveness of the algorithm in recovering the low-rank and sparse components of a tensor.
Arguments con acceptance:
* The evaluation of the proposed algorithm is limited to synthetic data.
* The use of multiple contractions and random projections is unclear and could affect the stability of diagonalization.
* The paper could benefit from more experiments, including those on non-synthetic data and illustrations of theoretical guarantees.
In conclusion, the paper is a significant contribution to the field of machine learning and signal processing, and its strengths outweigh its weaknesses. With some additional experiments and clarifications, the paper has the potential to be a valuable resource for researchers and practitioners in the field.