This paper presents a novel approach to generating natural language descriptions for image streams, extending the traditional single-image single-sentence framework to a sequence of images and sentences. The proposed coherent recurrent convolutional network (CRCN) architecture integrates convolutional neural networks, bidirectional recurrent neural networks, and a local coherence model to capture the semantic relationships between images and text. The authors demonstrate the effectiveness of their approach using large datasets of blog posts and user studies via Amazon Mechanical Turk.
The paper is well-structured, and the authors provide a clear explanation of their methodology and experimental setup. The use of real-world data and the comparison with state-of-the-art baselines strengthen the empirical evaluation. The CRCN architecture is a significant contribution, and the authors provide a detailed description of its components and how they are combined.
However, there are some areas that require improvement. The writing, particularly in Section 5, needs revision to clarify unclear sentences and grammar errors. Additionally, the comparison methods on the Glaucoma dataset are weak and should be improved by adding a comparison against a discrete-time HMM. The authors could also explore using mixtures of distributions for transition times instead of only exponential distributions.
The paper's strengths include its novel approach to image stream description, the use of real-world data, and the comprehensive experimental evaluation. The weaknesses include the need for improvement in the empirical evaluation and the writing clarity. Overall, the paper is worthy of publication, and with some revisions, it has the potential to make a significant contribution to the field.
Arguments pro acceptance:
* The paper presents a novel approach to image stream description, which is a significant extension of the traditional single-image single-sentence framework.
* The CRCN architecture is a substantial contribution, and the authors provide a detailed description of its components and how they are combined.
* The use of real-world data and the comparison with state-of-the-art baselines strengthen the empirical evaluation.
Arguments con acceptance:
* The writing, particularly in Section 5, needs revision to clarify unclear sentences and grammar errors.
* The comparison methods on the Glaucoma dataset are weak and should be improved by adding a comparison against a discrete-time HMM.
* The authors could explore using mixtures of distributions for transition times instead of only exponential distributions.
Quality: 8/10
The paper is technically sound, and the authors provide a clear explanation of their methodology and experimental setup. However, there are some areas that require improvement, such as the writing clarity and the comparison methods.
Clarity: 7/10
The paper is well-structured, but the writing, particularly in Section 5, needs revision to clarify unclear sentences and grammar errors.
Originality: 9/10
The paper presents a novel approach to image stream description, which is a significant extension of the traditional single-image single-sentence framework. The CRCN architecture is a substantial contribution.
Significance: 8/10
The paper has the potential to make a significant contribution to the field, particularly in the area of image stream description. The use of real-world data and the comparison with state-of-the-art baselines strengthen the empirical evaluation.