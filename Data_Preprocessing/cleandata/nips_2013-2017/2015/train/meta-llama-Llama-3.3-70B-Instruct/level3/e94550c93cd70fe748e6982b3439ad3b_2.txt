This paper proposes a novel approach to batch learning from logged bandit feedback (BLBF) by introducing a self-normalized risk estimator that avoids the propensity overfitting problem inherent in the conventional unbiased risk estimator. The authors demonstrate the effectiveness of their approach, called Norm-POEM, through extensive experiments on several multi-label classification problems.
The methodology and experiments presented in the paper are convincing, and the authors provide a thorough analysis of the propensity overfitting problem and its solution. However, I have some minor comments to improve the paper. Firstly, I suggest aggregating functions of parameters relevant for prediction instead of the full set of parameters for predictive inference. This could potentially improve the efficiency of the algorithm.
Additionally, I question the sensitivity of the results to the aggregation method used. Have the authors done experiments to investigate this? It would be interesting to see how different aggregation methods affect the performance of Norm-POEM. Furthermore, I inquire about the choice of aggregation method for positive semidefinite matrices and suggest alternative reparametrizations.
I also noticed a minor error in equation (3), where a missing integration is present. The authors should ensure that all equations are correctly formatted and free of errors.
Overall, the paper makes a significant contribution to the field of BLBF, and the experiments demonstrate the effectiveness of Norm-POEM in avoiding propensity overfitting. The authors' use of control variates to derive the self-normalized risk estimator is a clever solution to the problem, and the paper is well-written and easy to follow.
Arguments pro acceptance:
- The paper proposes a novel approach to BLBF that addresses the propensity overfitting problem.
- The experiments demonstrate the effectiveness of Norm-POEM in avoiding propensity overfitting.
- The paper is well-written and easy to follow.
Arguments con acceptance:
- The paper could benefit from additional experiments to investigate the sensitivity of the results to the aggregation method.
- The authors should ensure that all equations are correctly formatted and free of errors.
- The paper assumes a specific form of the hypothesis space, which may not be applicable to all BLBF problems. 
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The paper is also well-organized and clearly written, making it easy to understand for readers familiar with the field. The originality of the paper lies in its proposal of a novel approach to BLBF, and the significance of the results is demonstrated through extensive experiments. Overall, I recommend accepting the paper with minor revisions to address the comments mentioned above.