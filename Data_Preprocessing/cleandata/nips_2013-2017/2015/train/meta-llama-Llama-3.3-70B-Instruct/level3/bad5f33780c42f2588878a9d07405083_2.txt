This paper presents a significant contribution to the field of machine learning, addressing the crucial issue of overfitting in adaptive data analysis. The authors introduce two algorithms, Thresholdout and SparseValidate, which enable the reuse of a holdout set for validation while preventing overfitting. The paper's results are exciting, as they do not restrict the class of functions from which the analyst can select her checks, unlike standard uniform concentration inequalities for VC classes.
The paper's technical contributions are substantial, including the introduction of a new information-theoretic measure, approximate max-information, which unifies the generalization arguments that come from both differential privacy and description length. The authors demonstrate that approximate max-information has desirable properties, such as adaptive composition guarantees, making it amenable to reasoning about the generalization properties of adaptively applied sequences of algorithms.
The experiments presented in the paper are informative, illustrating the danger of reusing a standard holdout set and demonstrating the effectiveness of the proposed algorithms in preventing overfitting. However, the construction of a classifier that only uses weights +1 and -1 based on the signs of correlations may not be a plausible scenario in practice.
The paper's strengths include its well-written high-level discussion, clear presentation of the algorithms, and thorough analysis of the theoretical guarantees. However, the reviewer has significant concerns about Theorem 9, which may require a serious revision before the paper can be accepted. Specifically, the deterministic statement, in-probability statement, and the claim about the number of queries may not be entirely clear or useful to the analyst.
To strengthen the results, the reviewer suggests relaxing the bound on max-information and using Renyi divergence instead, which could lead to a more general and useful result. Additionally, the paper could benefit from addressing minor issues, such as typos and unclear sentences, to improve its overall clarity and readability.
Overall, the paper presents a valuable contribution to the field, and with revisions to address the concerns mentioned above, it has the potential to be a strong acceptance. The key arguments for and against acceptance are:
Arguments for acceptance:
* The paper presents a significant contribution to the field of machine learning, addressing a crucial issue in adaptive data analysis.
* The introduction of approximate max-information is a substantial technical contribution.
* The experiments are informative and demonstrate the effectiveness of the proposed algorithms.
Arguments against acceptance:
* Theorem 9 requires revision to address concerns about its clarity and usefulness.
* The construction of the classifier in the experiment may not be a plausible scenario in practice.
* Minor issues, such as typos and unclear sentences, need to be addressed to improve the paper's clarity and readability.