This paper presents a significant contribution to the field of risk-sensitive reinforcement learning by extending the policy gradient method to the whole class of coherent risk measures. The authors analyze risk-averse Markov decision processes with static and dynamic risk measures, providing a unified approach to risk-sensitive reinforcement learning that generalizes and extends previous results.
The paper is well-organized, well-written, and easy to follow, with correct results as far as I can tell. The authors provide a clear and concise introduction to the concept of coherent risk measures and their importance in finance and operations research. They also provide a thorough review of related work, highlighting the limitations of previous studies that focused on specific risk measures.
The main contribution of the paper is the development of new policy gradient style formulas that combine sampling with convex programming to estimate the gradient of both static and dynamic coherent risk measures. The authors demonstrate the utility of these formulas through several examples, including the conditional value-at-risk (CVaR) and mean-semideviation risk measures.
The paper also presents a numerical illustration of the approach, highlighting the importance of flexibility in designing risk criteria for selecting an appropriate risk-measure that suits both the user's risk preference and the problem-specific properties.
The strengths of the paper include:
* A clear and concise introduction to the concept of coherent risk measures and their importance in finance and operations research
* A thorough review of related work, highlighting the limitations of previous studies that focused on specific risk measures
* The development of new policy gradient style formulas that combine sampling with convex programming to estimate the gradient of both static and dynamic coherent risk measures
* A numerical illustration of the approach, highlighting the importance of flexibility in designing risk criteria
The weaknesses of the paper include:
* The paper assumes that the risk envelope is given in a canonical convex programming formulation, which may not always be the case in practice
* The paper does not provide a detailed analysis of the computational complexity of the proposed algorithms
* The paper does not provide a comparison with other risk-sensitive reinforcement learning methods
Overall, I believe that this paper makes a significant contribution to the field of risk-sensitive reinforcement learning and provides a useful framework for designing risk-sensitive policies. I recommend accepting this paper for publication.
Arguments pro acceptance:
* The paper presents a significant contribution to the field of risk-sensitive reinforcement learning
* The paper provides a clear and concise introduction to the concept of coherent risk measures and their importance in finance and operations research
* The paper demonstrates the utility of the proposed formulas through several examples
* The paper presents a numerical illustration of the approach, highlighting the importance of flexibility in designing risk criteria
Arguments con acceptance:
* The paper assumes that the risk envelope is given in a canonical convex programming formulation, which may not always be the case in practice
* The paper does not provide a detailed analysis of the computational complexity of the proposed algorithms
* The paper does not provide a comparison with other risk-sensitive reinforcement learning methods
Rating: 8/10
Confidence: 0.8
Recommendation: Accept with minor revisions. The authors should address the weaknesses of the paper by providing a more detailed analysis of the computational complexity of the proposed algorithms and comparing their approach with other risk-sensitive reinforcement learning methods. Additionally, the authors should consider providing more examples and illustrations to demonstrate the utility of the proposed formulas.