This paper discusses the problem of batch learning from logged bandit feedback (BLBF) and proposes a new estimator to address the issue of propensity overfitting. The authors identify a severe problem with the conventional counterfactual risk estimator used in BLBF, which can lead to degenerate risk estimates. They propose a self-normalized risk estimator that avoids this problem and provides a more robust estimate of the risk.
The paper is well-written and clearly explains the problem of propensity overfitting and the proposed solution. The authors provide a thorough analysis of the issue and demonstrate the effectiveness of their approach through experiments on several multi-label classification problems. The results show that the proposed Norm-POEM algorithm outperforms the conventional POEM algorithm and achieves better generalization performance.
One of the strengths of the paper is its clarity and organization. The authors provide a clear introduction to the problem of BLBF and the conventional estimator, and then carefully explain the proposed self-normalized estimator and its advantages. The experimental results are also well-presented and demonstrate the effectiveness of the proposed approach.
However, there are some areas where the paper could be improved. For example, the authors could provide more discussion on the relation between propensity overfitting and the large variance of weights. Additionally, the correctness of Equation (2) and the claim of unbiased counterfactual risk estimation in prior works could be further clarified.
Despite these minor issues, the paper makes a significant contribution to the field of BLBF and provides a new and effective approach to addressing the problem of propensity overfitting. The availability of code for the proposed algorithm is also a plus, making it easier for others to reproduce and build upon the results.
Overall, I would recommend accepting this paper due to its interesting ideas, clear presentation, and significant contribution to the field. The paper meets the criteria for quality, clarity, originality, and significance, and provides a valuable addition to the conference program.
Arguments pro acceptance:
* The paper proposes a new and effective approach to addressing the problem of propensity overfitting in BLBF.
* The authors provide a clear and thorough analysis of the issue and demonstrate the effectiveness of their approach through experiments.
* The paper is well-written and well-organized, making it easy to follow and understand.
* The availability of code for the proposed algorithm is a plus, making it easier for others to reproduce and build upon the results.
Arguments con acceptance:
* The paper could benefit from more discussion on the relation between propensity overfitting and the large variance of weights.
* The correctness of Equation (2) and the claim of unbiased counterfactual risk estimation in prior works could be further clarified.
* Some minor issues with notation and formatting could be improved.