This paper presents a novel approach to characterizing differences between high-dimensional distributions using linear projections, which is referred to as Principal Differences Analysis (PDA). The method operates by finding the projection that maximizes the Wasserstein divergence between the resulting univariate populations. The paper also introduces a sparse variant of the method, called SPARDA, to identify features responsible for the differences.
The paper is well-written, and the authors provide a clear and concise introduction to the problem and their approach. The technical sections are also well-organized, and the authors provide a detailed explanation of their algorithms and theoretical results. The experiments on synthetic and real data demonstrate the effectiveness of the proposed methods, and the results are impressive.
One of the strengths of the paper is its ability to handle high-dimensional data and identify meaningful differences between distributions. The authors also provide a thorough discussion of related work and demonstrate how their approach compares to existing methods. The use of the Wasserstein distance as a divergence measure is also a nice touch, as it provides a natural way to compare distributions.
The theoretical results provided in the paper are also impressive, and the authors demonstrate the consistency and sparsistency of their estimators under certain conditions. The proofs are relegated to the supplementary information, but the authors provide a clear outline of the main ideas and techniques used.
If I were to criticize the paper, I would say that the authors could provide more intuition about why their approach works and how it relates to other methods in the literature. Additionally, some of the technical sections could be made more accessible to readers who are not familiar with the specific techniques used.
In terms of the conference guidelines, I would say that the paper meets all the criteria. The paper is well-written, and the authors provide a clear and concise introduction to the problem and their approach. The technical sections are also well-organized, and the authors provide a detailed explanation of their algorithms and theoretical results. The experiments on synthetic and real data demonstrate the effectiveness of the proposed methods, and the results are impressive.
Here is a list of arguments for and against acceptance:
Arguments for acceptance:
* The paper presents a novel and effective approach to characterizing differences between high-dimensional distributions.
* The authors provide a clear and concise introduction to the problem and their approach.
* The technical sections are well-organized, and the authors provide a detailed explanation of their algorithms and theoretical results.
* The experiments on synthetic and real data demonstrate the effectiveness of the proposed methods, and the results are impressive.
Arguments against acceptance:
* The paper could provide more intuition about why the approach works and how it relates to other methods in the literature.
* Some of the technical sections could be made more accessible to readers who are not familiar with the specific techniques used.
* The authors could provide more discussion about the limitations of their approach and potential avenues for future research.
Overall, I would recommend accepting the paper, as it presents a novel and effective approach to characterizing differences between high-dimensional distributions, and the authors provide a clear and concise introduction to the problem and their approach. The technical sections are well-organized, and the authors provide a detailed explanation of their algorithms and theoretical results. The experiments on synthetic and real data demonstrate the effectiveness of the proposed methods, and the results are impressive.