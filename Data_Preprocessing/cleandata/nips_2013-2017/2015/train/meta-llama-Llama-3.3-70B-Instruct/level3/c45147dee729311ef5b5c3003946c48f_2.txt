This paper proposes a novel recurrent CNN architecture for multi-frame super resolution, combining feed-forward, recurrent, and conditional convolutional filters in a unique way. The technical quality of the paper is borderline, as it combines existing deep learning modules, but its novelty lies in its application to multi-frame super resolution. The authors propose a bidirectional recurrent convolutional network (BRCN) that efficiently models temporal dependency in video sequences, achieving state-of-the-art performance and orders of magnitude faster speed than other multi-frame SR methods.
The strengths of the paper include its ability to super resolve videos with complex motions, its low computational complexity, and its end-to-end framework that does not require pre- or post-processing. The experimental results demonstrate the effectiveness of the proposed model, with significant improvements over existing single-image and multi-frame SR methods.
However, there are several weaknesses and questions that need to be addressed. The model parameters, comparison with pre-trained SR-CNN, and clarification on certain experimental results are unclear and require further explanation. Additionally, the originality of the paper is incremental, building upon previous work, and its significance for the NIPS audience is debatable.
Arguments for acceptance include:
* The paper proposes a novel architecture for multi-frame super resolution
* The experimental results demonstrate significant improvements over existing methods
* The model is efficient and has low computational complexity
Arguments against acceptance include:
* The technical quality of the paper is borderline
* The originality of the paper is incremental
* The significance of the paper for the NIPS audience is debatable
* The model parameters and comparison with pre-trained SR-CNN are unclear
Overall, the paper has both strengths and weaknesses, and the authors need to address the questions and concerns raised to improve the quality and significance of the paper. With revisions to clarify the model parameters, comparison with pre-trained SR-CNN, and experimental results, the paper has the potential to be a strong contribution to the field of deep learning.