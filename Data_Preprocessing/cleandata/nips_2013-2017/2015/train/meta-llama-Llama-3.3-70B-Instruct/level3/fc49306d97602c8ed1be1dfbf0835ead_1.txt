This paper proposes a kernel-based method for cross-domain matching of bag-of-words data by representing data as a probability distribution over vectors in a shared latent space. The method captures the occurrence of different but semantically similar features in two distinct instances by estimating latent vectors using maximum mean discrepancy. The paper presents strong empirical results on several real-world datasets, including bilingual documents, document-tag matching, and image-tag matching.
The key strength of the paper is its ability to model complex dependencies between latent random variables across timesteps, which is essential for capturing the variability observed in highly structured sequential data such as natural speech. The proposed variational recurrent neural network (VRNN) model outperforms standard RNN models and other related sequential models on several speech datasets and a handwriting dataset.
However, the paper has some weaknesses. The technicality of the paper may need clarification in some areas, such as the experiment section and equation formulations. Additionally, the paper could benefit from more detailed explanations of the notations and formulations used. The idea presented in the paper has some similarity to existing work, but its application to cross-domain matching and treatment of data as probability distributions over latent space is interesting and has potential applications.
The paper is clearly written, and the authors provide a thorough background on sequence modeling with recurrent neural networks and variational autoencoders. The experimental evaluation is comprehensive, and the results demonstrate the effectiveness of the proposed VRNN model.
In terms of originality, the paper presents a novel combination of familiar techniques, and the application of the VRNN model to cross-domain matching is new. The related work is adequately referenced, and the authors provide a clear discussion of how their work differs from previous contributions.
The significance of the paper lies in its ability to address a difficult problem in a better way than previous research. The results demonstrate that the VRNN model can capture complex dependencies between latent random variables, which is essential for modeling highly structured sequential data. The paper provides a unique theoretical or pragmatic approach to sequence modeling, and the idea presented has potential applications in representation learning with hierarchical structures or generative models.
Overall, I would recommend accepting this paper, as it presents a significant contribution to the field of sequence modeling and cross-domain matching. The paper is well-written, and the results are comprehensive and well-supported by theoretical analysis and experimental evaluation.
Arguments pro acceptance:
* The paper presents a novel combination of familiar techniques and applies the VRNN model to cross-domain matching.
* The experimental evaluation is comprehensive, and the results demonstrate the effectiveness of the proposed VRNN model.
* The paper addresses a difficult problem in a better way than previous research and provides a unique theoretical or pragmatic approach to sequence modeling.
Arguments con acceptance:
* The technicality of the paper may need clarification in some areas.
* The paper could benefit from more detailed explanations of the notations and formulations used.
* The idea presented in the paper has some similarity to existing work.