This paper proposes a novel approach, Principal Differences Analysis (PDA), for analyzing differences between high-dimensional distributions. The method operates by finding the projection that maximizes the Wasserstein divergence between the resulting univariate populations. The authors also introduce a sparse variant of the method, SPARDA, to identify features responsible for the differences. The paper provides an efficient optimization procedure for the top-k loss function, enabling the algorithm to scale to large datasets.
The paper is well-written, and the authors provide a clear and concise explanation of the methodology and its applications. The experimental results demonstrate the effectiveness of the proposed approach in identifying differences between high-dimensional distributions, outperforming other methods such as sparse PCA, logistic regression, and linear discriminant analysis.
The strengths of the paper include:
* The proposal of a novel approach for analyzing differences between high-dimensional distributions, which is a common problem in many fields.
* The introduction of a sparse variant of the method, SPARDA, which can identify features responsible for the differences.
* The provision of an efficient optimization procedure for the top-k loss function, enabling the algorithm to scale to large datasets.
* The demonstration of the effectiveness of the proposed approach in identifying differences between high-dimensional distributions, outperforming other methods.
The weaknesses of the paper include:
* The paper assumes that the distributions are compactly supported, which may not be the case in many real-world applications.
* The paper does not provide a thorough analysis of the computational complexity of the proposed approach, which is an important consideration for large-scale datasets.
* The paper does not provide a clear explanation of how to choose the regularization parameter, which is an important hyperparameter in the proposed approach.
Overall, the paper is well-written, and the proposed approach is novel and effective. However, there are some limitations and areas for improvement, such as providing a more thorough analysis of the computational complexity and explaining how to choose the regularization parameter.
Arguments for acceptance:
* The paper proposes a novel approach for analyzing differences between high-dimensional distributions, which is a common problem in many fields.
* The experimental results demonstrate the effectiveness of the proposed approach in identifying differences between high-dimensional distributions, outperforming other methods.
* The paper provides a clear and concise explanation of the methodology and its applications.
Arguments against acceptance:
* The paper assumes that the distributions are compactly supported, which may not be the case in many real-world applications.
* The paper does not provide a thorough analysis of the computational complexity of the proposed approach, which is an important consideration for large-scale datasets.
* The paper does not provide a clear explanation of how to choose the regularization parameter, which is an important hyperparameter in the proposed approach.
Rating: 8/10
Recommendation: Accept with minor revisions. The authors should provide a more thorough analysis of the computational complexity of the proposed approach and explain how to choose the regularization parameter. Additionally, the authors should consider relaxing the assumption of compactly supported distributions to make the approach more applicable to real-world applications.