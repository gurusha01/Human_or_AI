This paper proposes a novel approach for retrieving a sequence of natural sentences for an image stream, extending both input and output dimensions to a sequence of images and a sequence of sentences. The authors design a multimodal architecture called coherent recurrent convolutional network (CRCN), which integrates convolutional neural networks, bidirectional recurrent neural networks, and an entity-based local coherence model. The approach directly learns from vast user-generated resources of blog posts as text-image parallel training data.
The paper is well-structured, and the authors provide a clear overview of the problem, related work, and their proposed approach. The experimental results demonstrate the superior performance of the proposed CRCN approach compared to other state-of-the-art alternatives, using both quantitative measures and user studies via Amazon Mechanical Turk.
However, there are some areas that need improvement. The writing is dense and could be improved for better readability and understanding. The paper spends too much space explaining prior art, taking up 4.5 pages, which could be condensed to provide more space for the authors' contributions. The results in Section 5.1 using simulated data may not effectively demonstrate the efficacy of the proposed scheme due to minimal noise and lack of comparison to other methods.
Additionally, the error metric "2-norm error" is not clearly defined, and its application to the state sequence is uncertain. The authors should clarify the contributions of references [8,9,10,12,13] in Section 2 to help readers better understand the topic. A recent relevant paper by V. Rao and Y. W. Teh on fast MCMC sampling for Markov jump processes should be cited and commented on to strengthen the paper's contributions and novelty.
The trade-off introduced by the discretized time interval and its exactness should be questioned, and the authors should consider applying the same discretization to CTMC to compare results. Overall, the paper has some strengths, such as the novelty of the proposed approach and the thorough experimental evaluation, but also some weaknesses, such as the dense writing and the lack of clarity in some sections.
Arguments pro acceptance:
* The paper proposes a novel approach for retrieving sentence sequences for an image stream.
* The experimental results demonstrate the superior performance of the proposed CRCN approach.
* The paper provides a clear overview of the problem, related work, and the proposed approach.
Arguments con acceptance:
* The writing is dense and could be improved for better readability and understanding.
* The paper spends too much space explaining prior art.
* The results in Section 5.1 using simulated data may not effectively demonstrate the efficacy of the proposed scheme.
* The error metric "2-norm error" is not clearly defined, and its application to the state sequence is uncertain. 
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. However, the paper could be improved by providing more clarity in some sections and condensing the prior art explanation. The originality of the paper is high, as it proposes a novel approach for retrieving sentence sequences for an image stream. The significance of the paper is also high, as it addresses a difficult problem in a better way than previous research and advances the state of the art in a demonstrable way. 
Overall, I would recommend accepting this paper with minor revisions to address the mentioned weaknesses. The authors should improve the writing clarity, condense the prior art explanation, and provide more clarity in some sections. Additionally, the authors should consider citing and commenting on relevant recent papers to strengthen the paper's contributions and novelty.