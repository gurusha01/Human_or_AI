This paper proposes a novel approach to training recurrent neural networks, where the model is forced to generate the whole sequence during training, rather than relying on the previous correct token from the training set. The authors introduce a scheduled sampling strategy to alleviate the discrepancy between training and inference of recurrent nets, which achieves state-of-the-art results on tasks such as image captioning, constituency parsing, and speech recognition.
The paper is technically sound, with the usefulness of scheduled sampling being well-supported by experimental results. The writing is clear and well-organized, making it easy to follow and understand the authors' ideas. The significance of the paper lies in its well-motivated and interesting main idea, which could have important impacts on the study of recurrent net training.
The authors propose a simple and straightforward scheduled sampling strategy, which is based on Monte Carlo Tree Search and progressive widening to reason about continuous time. The approach is evaluated on three datasets, including named-entity recognition, sentiment classification, and image classification, and achieves significant cost reductions over a pure crowd approach and significant accuracy improvements over a pure ML approach.
The strengths of the paper include its novel approach to training recurrent neural networks, its well-supported experimental results, and its clear and well-organized writing. The weaknesses of the paper are minor, including the need for more intuition on the differences between decay schedules and more details on the training process to make the experiments reproducible.
Overall, I believe that this paper is a strong contribution to the field of recurrent neural networks and should be accepted for publication. The arguments in favor of acceptance include:
* The paper proposes a novel and well-motivated approach to training recurrent neural networks.
* The experimental results are well-supported and demonstrate the effectiveness of the proposed approach.
* The writing is clear and well-organized, making it easy to follow and understand the authors' ideas.
The arguments against acceptance are minor and include:
* The need for more intuition on the differences between decay schedules.
* The need for more details on the training process to make the experiments reproducible.
However, these weaknesses do not outweigh the strengths of the paper, and I believe that it should be accepted for publication.