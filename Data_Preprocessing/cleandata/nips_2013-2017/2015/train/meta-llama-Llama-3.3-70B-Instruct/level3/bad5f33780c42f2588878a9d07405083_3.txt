This paper introduces the concept of approximate max-information to quantify the generalization properties of adaptive data analyses. The authors demonstrate that approximate max-information has useful properties, including low values for differentially private algorithms and algorithms with small cardinality range, and compositions of algorithms with low approximate max-information also have relatively low values. The paper provides interesting applications, including generalization of differentially private algorithms, managing holdout set reuse in machine learning, and multiple hypothesis testing on the same data.
The paper's main technical contribution is the introduction and analysis of approximate max-information, which unifies the generalization arguments that come from both differential privacy and description length. The authors prove that approximate max-information has several desirable properties, including adaptive composition guarantees, which makes it amenable to reasoning about the generalization properties of adaptively applied sequences of algorithms.
The paper also presents two algorithms, Thresholdout and SparseValidate, which enable validation of analyst's queries in the adaptive setting. Thresholdout is based on differential privacy and provides a simple and efficient way to validate queries, while SparseValidate is based on description length and provides a more general framework for validation.
The experiments demonstrate the effectiveness of the proposed algorithms in preventing overfitting to the holdout set. The results show that reusing a standard holdout set can lead to overfitting, while the proposed algorithms provide a valid estimate of classifier accuracy.
The paper has some technical issues, including errors in probability statements, undefined notation, and unclear statements, which need to be addressed. Additionally, the paper lacks comparison to earlier work on generalization from learning theory, such as Freund's work on self-bounding learning algorithms and Blum and Langford's work on micro-choice bounds.
Despite these issues, the paper provides a novel perspective on generalization and useful applications, and the reviewer suggests that the paper should be accepted. The post-rebuttal remarks clarify some points of confusion, and the reviewer reiterates the recommendation to accept the paper.
Arguments pro acceptance:
* The paper introduces a novel concept of approximate max-information, which has useful properties and unifies the generalization arguments from differential privacy and description length.
* The paper provides interesting applications, including generalization of differentially private algorithms, managing holdout set reuse in machine learning, and multiple hypothesis testing on the same data.
* The paper presents two algorithms, Thresholdout and SparseValidate, which enable validation of analyst's queries in the adaptive setting.
* The experiments demonstrate the effectiveness of the proposed algorithms in preventing overfitting to the holdout set.
Arguments con acceptance:
* The paper has some technical issues, including errors in probability statements, undefined notation, and unclear statements, which need to be addressed.
* The paper lacks comparison to earlier work on generalization from learning theory, such as Freund's work on self-bounding learning algorithms and Blum and Langford's work on micro-choice bounds.
* The paper could benefit from more explicit statements about the budget and union bound, and more discussion on the interplay between tau and n in Thresholdout.