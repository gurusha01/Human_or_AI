This paper presents a novel Bayesian optimization method, Infinite-Metric GP Optimization (IMGPO), which achieves an exponential convergence rate without the need for auxiliary optimization and δ-cover sampling. The algorithm combines the strengths of bound-based search methods and Gaussian Process (GP) optimization, leveraging the information encoded in the GP prior/posterior to reduce the degree of unknownness of the semi-metric.
The paper is well-written, and the authors provide a clear and detailed explanation of the algorithm and its theoretical analysis. The experimental results demonstrate the effectiveness of IMGPO in comparison to other state-of-the-art algorithms, including SOO, BaMSOO, GP-PI, and GP-EI.
However, I have some concerns regarding the optimization section, specifically the single iteration for alternating optimization between RPN and R-CNN. The authors assume optimal proposals from the first iterated RPN, which may not always be the case. Additionally, the application of a pixel-wise sliding window to the top layer of CNN may result in inaccurate bounding box locations due to the smaller scale of the top level compared to the input image.
Furthermore, I would like to seek clarification on the definition of $ha$ in lines 173 and 174 of the work. The notation is not clearly explained, and it is essential to understand the role of $ha$ in the algorithm.
The proposed algorithm is a two-stage object detection method using CNN, consisting of region proposal and fast R-CNN stages, achieving near real-time performance at 5fps. The authors claim that IMGPO outperforms other algorithms in general, but it is slower than SOO.
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The authors are careful and honest about evaluating both the strengths and weaknesses of the work. The paper is clearly written, well-organized, and adequately informs the reader.
The originality of the paper lies in the combination of bound-based search methods and GP optimization, which is a novel approach to Bayesian optimization. The authors provide a thorough analysis of the algorithm and its relationship to previous work, including the DIRECT algorithm and GP-UCB.
The significance of the paper is evident in its ability to achieve an exponential convergence rate without auxiliary optimization and δ-cover sampling. The results are important, and other researchers and practitioners are likely to use these ideas or build upon them. The paper addresses a difficult problem in a better way than previous research and advances the state of the art in a demonstrable way.
Overall, I would recommend accepting this paper, but I would like the authors to address the concerns mentioned above and provide further clarification on the definition of $h_a$.
Arguments pro acceptance:
* The paper presents a novel and effective Bayesian optimization method.
* The algorithm achieves an exponential convergence rate without auxiliary optimization and δ-cover sampling.
* The experimental results demonstrate the effectiveness of IMGPO in comparison to other state-of-the-art algorithms.
* The paper is well-written, and the authors provide a clear and detailed explanation of the algorithm and its theoretical analysis.
Arguments con acceptance:
* The optimization section requires further clarification, specifically the single iteration for alternating optimization between RPN and R-CNN.
* The application of a pixel-wise sliding window to the top layer of CNN may result in inaccurate bounding box locations.
* The definition of $h_a$ in lines 173 and 174 of the work requires further clarification.