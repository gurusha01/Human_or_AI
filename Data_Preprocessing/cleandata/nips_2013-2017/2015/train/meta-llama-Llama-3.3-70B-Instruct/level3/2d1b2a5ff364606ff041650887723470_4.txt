This paper presents a convex relaxation approach to learn the MultiNomial Logit (MNL) model from ordinal data, with applications in collaborative ranking and bundled choice modeling. The authors provide theoretical guarantees for the performance of their approach, including upper bounds on the estimation error and a lower bound on the minimax error rate.
The paper's main result, Theorem 2.1, assumes a normal distribution for the linear measurement vector, which may be a strict assumption that requires further explanation. Additionally, the choice of regularizer based on the set in which the true signal lies is not addressed in the paper, despite discussing convex regularizers.
The result showing equivalence between linear and nonlinear measurements depends on parameters characterizing the hardness of estimation, and the necessity of these dependencies is unclear. Furthermore, the paper lacks references to relevant studies, such as single index models and sufficient dimension reduction, which also investigate linear estimation under unknown link functions.
A recent paper by Yi et al. introduces a new algorithm for sparse recovery with unknown link functions and establishes the equivalence of high-dimensional linear estimation with linear and nonlinear link functions. This paper's contribution is significant, as it provides a polynomial-time inference algorithm with provable guarantees for learning the MNL model from ordinal data.
The paper's strengths include its clear writing, well-organized structure, and adequate information for the expert reader to reproduce the results. The authors also provide a detailed analysis of the performance guarantees, including upper bounds on the estimation error and a lower bound on the minimax error rate.
However, the paper's weaknesses include the lack of references to relevant studies and the unclear necessity of the dependencies in the result showing equivalence between linear and nonlinear measurements. Additionally, the assumption of a normal distribution for the linear measurement vector may be too strict and requires further explanation.
Arguments for acceptance:
* The paper presents a significant contribution to the field of personalized recommendation systems and revenue management.
* The authors provide a clear and well-organized presentation of their results.
* The paper includes a detailed analysis of the performance guarantees, including upper bounds on the estimation error and a lower bound on the minimax error rate.
Arguments against acceptance:
* The paper lacks references to relevant studies, such as single index models and sufficient dimension reduction.
* The assumption of a normal distribution for the linear measurement vector may be too strict and requires further explanation.
* The necessity of the dependencies in the result showing equivalence between linear and nonlinear measurements is unclear.
Overall, I recommend accepting this paper, as it presents a significant contribution to the field and provides a clear and well-organized presentation of the results. However, the authors should address the weaknesses mentioned above, including providing references to relevant studies and clarifying the assumption of a normal distribution for the linear measurement vector.