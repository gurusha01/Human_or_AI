This paper presents a novel approach to batch learning from logged bandit feedback (BLBF) by introducing a self-normalized risk estimator that avoids the propensity overfitting problem inherent in the conventional unbiased risk estimator. The proposed estimator is based on a multiplicative control variate, which leads to a more robust and equivariant risk estimate. The authors derive a new learning algorithm, Norm-POEM, using the CRM principle and the self-normalized estimator, and demonstrate its improved generalization performance on several multi-label classification problems.
The paper is well-written, and the authors provide a clear and thorough explanation of the problem, the proposed solution, and the experimental results. The theoretical analysis is sound, and the empirical evaluation is convincing. The authors also provide a detailed discussion of the related work and the significance of the proposed approach.
The strengths of the paper include:
* The identification of the propensity overfitting problem and its solution using a self-normalized risk estimator
* The derivation of a new learning algorithm, Norm-POEM, which demonstrates improved generalization performance
* The thorough experimental evaluation, which includes a comparison with the conventional unbiased risk estimator and a full-information CRF
The weaknesses of the paper include:
* The lack of a more detailed analysis of the computational efficiency of Norm-POEM, which is only briefly discussed
* The limited exploration of the hyper-parameter space, which may affect the performance of Norm-POEM
* The absence of a more detailed comparison with other BLBF algorithms, which would provide a more comprehensive understanding of the proposed approach
Overall, the paper presents a significant contribution to the field of BLBF and provides a promising solution to the propensity overfitting problem. The proposed approach has the potential to improve the performance of BLBF algorithms in a variety of applications, and the authors' experimental evaluation demonstrates its effectiveness.
Arguments for acceptance:
* The paper presents a novel and significant contribution to the field of BLBF
* The proposed approach has the potential to improve the performance of BLBF algorithms in a variety of applications
* The experimental evaluation is thorough and convincing
Arguments against acceptance:
* The paper may benefit from a more detailed analysis of the computational efficiency of Norm-POEM
* The exploration of the hyper-parameter space may be limited
* The comparison with other BLBF algorithms may be incomplete
Recommendation: Accept, with minor revisions to address the weaknesses mentioned above.