This paper introduces the Principal Differences Analysis (PDA) framework for analyzing differences between high-dimensional distributions. The method operates by finding the projection that maximizes the Wasserstein divergence between the resulting univariate populations. The paper is well-written and covers non-trivial material, with good experimental results to support its claims.
The PDA framework is an interesting approach to characterizing differences between populations, and the use of the Wasserstein distance as a divergence measure is a good choice. The authors provide a clear and concise explanation of the method, and the experimental results demonstrate its effectiveness in identifying differences between populations.
One potential area for improvement is in providing further motivation for the choice of loss function used in the paper. The authors could provide more discussion on why the Wasserstein distance is a good choice for this problem, and how it compares to other possible divergence measures.
The paper also contains a small typo on page 3, where the word "optimal" should be removed from the phrase "globally optimal leads to".
The experimental results are impressive, and demonstrate the effectiveness of the PDA framework in identifying differences between populations. The comparison to other methods, such as sparse PCA and logistic regression, is also useful in highlighting the strengths and weaknesses of the PDA approach.
Overall, this is a strong paper that makes a significant contribution to the field of statistical analysis. The PDA framework is a useful tool for characterizing differences between high-dimensional distributions, and the authors provide a clear and concise explanation of the method.
Arguments for acceptance:
* The paper introduces a novel and interesting approach to characterizing differences between populations.
* The experimental results demonstrate the effectiveness of the PDA framework in identifying differences between populations.
* The paper is well-written and easy to follow, with clear explanations of the method and its applications.
Arguments against acceptance:
* The paper could benefit from further discussion on the choice of loss function and its motivation.
* The typo on page 3 should be corrected.
* Some readers may find the paper to be slightly dense and technical, which could make it difficult to follow for those without a strong background in statistical analysis.