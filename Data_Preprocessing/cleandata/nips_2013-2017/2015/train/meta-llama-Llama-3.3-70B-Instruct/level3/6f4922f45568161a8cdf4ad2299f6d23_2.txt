This paper presents a novel Markov Chain Monte Carlo (MCMC) scheme for posterior sampling in Bayesian nonparametric mixture models with priors that belong to the general Poisson-Kingman class. The proposed hybrid sampler combines the strengths of conditional and marginal samplers, allowing for a more comprehensive representation of the random probability measure while reducing memory requirements.
The paper is well-written, and the experimental results demonstrate the efficacy of the proposed MCMC algorithm against existing marginal and conditional MCMC samplers. The authors provide a clear and detailed explanation of the methodology, including the generative process and the complete conditionals for the Gibbs sampler.
One of the key strengths of the paper is its ability to handle a wide range of Bayesian nonparametric priors, including the σ-Stable Poisson-Kingman class and the ´ logBeta-Poisson-Kingman processes. The authors also provide a thorough analysis of the performance of their hybrid sampler, including a comparison with existing approaches in terms of running time and effective sample size.
However, there are some limitations to the paper. The authors acknowledge that their approach may not be suitable for all values of σ, and that the use of a Metropolis-Hastings step may require further optimization to improve mixing. Additionally, the paper could benefit from a more detailed analysis of the theoretical properties of the proposed sampler, including its convergence rates and stationarity.
In terms of novelty, the paper presents an incremental improvement over existing methods, rather than a revolutionary new approach. However, the authors' contribution is still significant, as it provides a flexible and efficient tool for inference in a wide range of Bayesian nonparametric models.
Overall, I would recommend accepting this paper for publication, as it presents a well-written and well-researched contribution to the field of Bayesian nonparametrics. The paper's strengths, including its clear methodology and thorough experimental evaluation, outweigh its limitations, and it has the potential to be a useful resource for researchers in the field.
Arguments pro acceptance:
* The paper presents a novel and efficient MCMC scheme for posterior sampling in Bayesian nonparametric mixture models.
* The authors provide a clear and detailed explanation of the methodology, including the generative process and the complete conditionals for the Gibbs sampler.
* The experimental results demonstrate the efficacy of the proposed MCMC algorithm against existing marginal and conditional MCMC samplers.
* The paper has the potential to be a useful resource for researchers in the field of Bayesian nonparametrics.
Arguments con acceptance:
* The paper presents an incremental improvement over existing methods, rather than a revolutionary new approach.
* The authors acknowledge that their approach may not be suitable for all values of σ, and that the use of a Metropolis-Hastings step may require further optimization to improve mixing.
* The paper could benefit from a more detailed analysis of the theoretical properties of the proposed sampler, including its convergence rates and stationarity.