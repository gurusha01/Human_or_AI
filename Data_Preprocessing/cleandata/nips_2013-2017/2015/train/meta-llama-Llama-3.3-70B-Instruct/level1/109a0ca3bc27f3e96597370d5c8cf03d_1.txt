This paper proposes a novel recurrent convolutional encoder-decoder network for synthesizing novel views of 3D objects from a single image. The network is trained end-to-end on the task of rendering rotated objects starting from a single image, and is able to capture long-term dependencies along a sequence of transformations. The authors demonstrate the quality of the network's predictions on the Multi-PIE dataset for human faces and a dataset of 3D chair models, and show that the network is able to disentangle latent data factors without using object class labels.
The paper is well-written and clearly explains the proposed approach, including the network architecture and training procedure. The authors provide a thorough review of related work and demonstrate the effectiveness of their approach through a series of experiments. The results show that the proposed network is able to generate high-quality renderings of novel views of 3D objects, and that the network's performance improves with increasing trajectory length of training sequences.
The strengths of the paper include:
* The proposal of a novel recurrent convolutional encoder-decoder network for synthesizing novel views of 3D objects
* The demonstration of the network's effectiveness on two datasets, including human faces and 3D chair models
* The ability of the network to disentangle latent data factors without using object class labels
* The thorough review of related work and clear explanation of the proposed approach
The weaknesses of the paper include:
* The limited scope of the proposed approach, which is currently only able to handle rotation transformations
* The need for a large amount of training data to achieve good performance
* The potential for the network to produce degenerate results for longer rotation sequences
Arguments for acceptance:
* The paper proposes a novel and effective approach for synthesizing novel views of 3D objects
* The results demonstrate the quality of the network's predictions and the ability of the network to disentangle latent data factors
* The paper provides a thorough review of related work and clear explanation of the proposed approach
Arguments against acceptance:
* The limited scope of the proposed approach, which may not be generalizable to other types of transformations
* The need for a large amount of training data, which may not be feasible for all applications
* The potential for the network to produce degenerate results for longer rotation sequences, which may limit the usefulness of the approach.
Overall, I believe that the paper is well-written and demonstrates the effectiveness of the proposed approach. However, I also believe that the limited scope of the approach and the need for a large amount of training data are significant limitations that should be addressed in future work. 
Quality: 8/10
The paper is well-written and clearly explains the proposed approach. The results demonstrate the quality of the network's predictions and the ability of the network to disentangle latent data factors.
Clarity: 9/10
The paper is well-organized and easy to follow. The authors provide a thorough review of related work and clear explanation of the proposed approach.
Originality: 8/10
The paper proposes a novel recurrent convolutional encoder-decoder network for synthesizing novel views of 3D objects. However, the approach is limited to rotation transformations and may not be generalizable to other types of transformations.
Significance: 8/10
The paper demonstrates the effectiveness of the proposed approach on two datasets, including human faces and 3D chair models. However, the limited scope of the approach and the need for a large amount of training data may limit the usefulness of the approach.