This paper presents a novel approach to training neural networks that can be efficiently deployed on neuromorphic hardware, such as the TrueNorth chip. The authors propose a "constrain-then-train" approach, where they first constrain the network to provide a direct representation of the deployment system and then train within those constraints. This approach allows for the use of backpropagation to train networks with spiking neurons and extremely low-precision synapses.
The paper is well-written and clearly explains the motivation, methodology, and results of the research. The authors provide a thorough review of previous work in the area and demonstrate a good understanding of the challenges and limitations of training neural networks for neuromorphic hardware.
The strengths of the paper include:
* The proposal of a novel approach to training neural networks for neuromorphic hardware, which addresses the incompatibility between backpropagation and neuromorphic designs.
* The demonstration of the effectiveness of the approach on the MNIST dataset, achieving high accuracy and low energy consumption.
* The provision of a clear and detailed explanation of the methodology, including the network topology, training procedure, and mapping of the training network to the deployment network.
The weaknesses of the paper include:
* The reliance on a customized training rule, which may limit the applicability of the approach to other neural network architectures and tasks.
* The lack of comparison to other state-of-the-art methods for training neural networks on neuromorphic hardware.
* The limited evaluation of the approach on a single dataset (MNIST), which may not be representative of more complex real-world tasks.
Arguments for acceptance:
* The paper presents a novel and innovative approach to training neural networks for neuromorphic hardware.
* The results demonstrate the effectiveness of the approach in achieving high accuracy and low energy consumption.
* The paper provides a clear and detailed explanation of the methodology, which will be useful for other researchers in the field.
Arguments against acceptance:
* The approach may be limited to specific neural network architectures and tasks.
* The evaluation of the approach is limited to a single dataset, which may not be representative of more complex real-world tasks.
* The paper could benefit from a more thorough comparison to other state-of-the-art methods for training neural networks on neuromorphic hardware.
Overall, I believe that the paper makes a significant contribution to the field of neural networks and neuromorphic computing, and I recommend acceptance. However, I suggest that the authors address the weaknesses mentioned above, such as providing a more thorough comparison to other state-of-the-art methods and evaluating the approach on more complex datasets.