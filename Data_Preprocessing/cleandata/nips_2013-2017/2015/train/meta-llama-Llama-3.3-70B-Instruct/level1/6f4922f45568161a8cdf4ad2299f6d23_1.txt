This paper proposes a novel Covariance-Controlled Adaptive Langevin (CCAdL) thermostat for Bayesian posterior inference using Monte Carlo sampling. The method combines ideas from Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) and Stochastic Gradient Nose-Hoover Thermostat (SGNHT) to effectively dissipate parameter-dependent noise while maintaining a desired target distribution. The authors demonstrate the superiority of CCAdL over SGHMC and SGNHT in various large-scale machine learning applications, including Bayesian logistic regression and discriminative restricted Boltzmann machines.
The paper is well-written, and the authors provide a clear and concise introduction to the background and motivation of the research. The proposed method is thoroughly explained, and the mathematical derivations are sound. The numerical experiments are well-designed and demonstrate the effectiveness of CCAdL in practice.
The strengths of the paper include:
* The proposal of a novel method that addresses the limitations of existing stochastic gradient methods
* A thorough analysis of the method's properties and behavior
* Well-designed numerical experiments that demonstrate the method's effectiveness in practice
* A clear and concise writing style that makes the paper easy to follow
The weaknesses of the paper include:
* The method's reliance on estimating the covariance matrix of the noise, which can be computationally expensive in high dimensions
* The lack of a thorough analysis of the method's computational complexity and scalability
* Some of the numerical experiments could be more comprehensive, with more detailed comparisons to existing methods
Overall, the paper makes a significant contribution to the field of Bayesian posterior inference using Monte Carlo sampling. The proposed method has the potential to improve the efficiency and accuracy of Bayesian inference in large-scale machine learning applications.
Arguments pro acceptance:
* The paper proposes a novel method that addresses the limitations of existing stochastic gradient methods
* The method is thoroughly analyzed, and its properties and behavior are well-understood
* The numerical experiments demonstrate the method's effectiveness in practice
* The paper is well-written, and the authors provide a clear and concise introduction to the background and motivation of the research
Arguments con acceptance:
* The method's reliance on estimating the covariance matrix of the noise could be a limitation in high dimensions
* The lack of a thorough analysis of the method's computational complexity and scalability could be a concern
* Some of the numerical experiments could be more comprehensive, with more detailed comparisons to existing methods
Recommendation: Accept with minor revisions. The authors should address the weaknesses mentioned above, particularly the lack of a thorough analysis of the method's computational complexity and scalability. Additionally, the authors could provide more comprehensive numerical experiments to further demonstrate the method's effectiveness in practice.