This paper proposes a novel approach to Bayesian parameter estimation for deep neural networks, which is essential in problem settings where data is scarce or accurate posterior predictive densities are required. The authors introduce a method called "Bayesian dark knowledge" that combines online Monte Carlo methods, specifically stochastic gradient Langevin dynamics (SGLD), with model distillation to approximate the posterior predictive distribution. This approach allows for a compact and efficient representation of the posterior, which is particularly useful in applications such as active learning, reinforcement learning, and classifier fusion.
The paper is well-structured, and the authors provide a clear overview of the background and related work. The proposed method is thoroughly explained, and the experimental results demonstrate its effectiveness in various classification and regression problems. The authors also provide a detailed comparison with other approximate inference methods, including expectation propagation (EP) and variational Bayes (VB), and show that their approach outperforms these methods in terms of log-likelihood scores and predictive uncertainty.
The strengths of this paper include:
* The proposed method is simple to implement and scalable to large datasets.
* The authors provide a thorough analysis of the experimental results and compare their approach with other state-of-the-art methods.
* The paper addresses the problem of Bayesian parameter estimation in deep neural networks, which is a crucial aspect of many applications.
However, there are some weaknesses and potential areas for improvement:
* The authors could provide more insight into the choice of hyperparameters and the sensitivity of the method to these parameters.
* The paper could benefit from a more detailed discussion of the limitations and potential drawbacks of the proposed method.
* The authors mention that their approach can be used for other types of models, but it would be interesting to see experimental results for these cases.
Arguments pro acceptance:
* The paper proposes a novel and effective approach to Bayesian parameter estimation in deep neural networks.
* The experimental results demonstrate the superiority of the proposed method over other state-of-the-art approaches.
* The paper is well-structured and easy to follow, making it accessible to a broad audience.
Arguments con acceptance:
* The paper could benefit from a more detailed analysis of the hyperparameters and their impact on the method's performance.
* The authors could provide more insight into the limitations and potential drawbacks of the proposed method.
* The paper focuses primarily on classification and regression problems, and it would be interesting to see experimental results for other types of applications.
Overall, this paper presents a significant contribution to the field of Bayesian parameter estimation in deep neural networks, and the proposed method has the potential to be widely adopted in various applications. With some minor revisions to address the mentioned weaknesses, this paper would be a strong candidate for acceptance. 
Quality: 8/10
The paper is technically sound, and the authors provide a clear explanation of the proposed method. However, there are some areas where the analysis could be more detailed, such as the choice of hyperparameters and the sensitivity of the method to these parameters.
Clarity: 9/10
The paper is well-structured, and the authors provide a clear overview of the background and related work. The proposed method is thoroughly explained, and the experimental results are easy to follow.
Originality: 8/10
The paper proposes a novel approach to Bayesian parameter estimation in deep neural networks, which combines online Monte Carlo methods with model distillation. While the individual components of the method are not new, the combination of these components is innovative and effective.
Significance: 9/10
The paper addresses a crucial aspect of many applications, namely Bayesian parameter estimation in deep neural networks. The proposed method has the potential to be widely adopted in various fields, and the experimental results demonstrate its effectiveness in several classification and regression problems.