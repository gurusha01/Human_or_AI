This paper presents a novel approach to training recurrent neural networks as near-optimal feedback controllers for a range of dynamical systems and tasks, including swimming, flying, biped, and quadruped walking with different body morphologies. The method combines supervised learning with trajectory optimization, using a neural network to learn from the optimizer and generate similar behaviors online.
The paper builds upon previous work in reinforcement learning and stochastic optimal control, but achieves state-of-the-art results in continuous high-dimensional spaces involving complex dynamics. The authors demonstrate the effectiveness of their approach through a series of experiments, including locomotion tasks for various creature morphologies.
The strengths of the paper include:
* The ability to generate stable and realistic behaviors for a range of tasks and characters without requiring motion capture or task-specific features or state machines.
* The use of a single network architecture and parameters to create all controllers, without any specialized initializations.
* The demonstration of the importance of joint optimization and noise injection in achieving good performance.
The weaknesses of the paper include:
* The complexity of the approach, which may make it difficult to implement and tune for practitioners without significant expertise in trajectory optimization and neural networks.
* The reliance on a specific trajectory optimization method (Contact-Invariant Optimization) and neural network architecture, which may limit the generality of the approach.
* The lack of a systematic comparison with other methods, such as model-predictive control, which may provide alternative solutions to the same problems.
Arguments pro acceptance:
* The paper presents a significant advance in the state-of-the-art for control of complex dynamical systems, with potential applications in robotics, animation, and gaming.
* The approach is well-motivated and clearly explained, with a thorough analysis of the importance of joint optimization and noise injection.
* The experiments demonstrate the effectiveness of the approach for a range of tasks and characters, and provide a clear comparison with alternative methods.
Arguments con acceptance:
* The approach may be too complex and specialized for some practitioners, which may limit its adoption and impact.
* The reliance on a specific trajectory optimization method and neural network architecture may limit the generality of the approach.
* The lack of a systematic comparison with other methods may make it difficult to fully evaluate the strengths and weaknesses of the approach.
Overall, I believe that the paper presents a significant contribution to the field of control and neural networks, and that the strengths of the paper outweigh the weaknesses. I recommend acceptance, with the suggestion that the authors provide additional comparisons with other methods and consider simplifying the approach to make it more accessible to a broader range of practitioners. 
Quality: 8/10
The paper is well-written and clearly explains the approach, but may benefit from additional comparisons with other methods and a more detailed analysis of the limitations of the approach.
Clarity: 9/10
The paper is well-organized and easy to follow, with clear explanations of the approach and experiments.
Originality: 9/10
The paper presents a novel approach to training recurrent neural networks as near-optimal feedback controllers, with a significant advance in the state-of-the-art for control of complex dynamical systems.
Significance: 9/10
The paper has the potential to make a significant impact in the field of control and neural networks, with potential applications in robotics, animation, and gaming.