This paper introduces the Principal Differences Analysis (PDA) framework, a novel approach for analyzing differences between high-dimensional distributions. The method operates by finding the projection that maximizes the Wasserstein divergence between the resulting univariate populations. The authors also propose a sparse variant of the method, called SPARDA, to identify features responsible for the differences.
The paper relates to previous work on two-sample analyses, such as linear discriminant analysis (LDA) and the logistic lasso, but differs in its ability to capture arbitrary types of differences between high-dimensional distributions without restrictive assumptions. The authors demonstrate the effectiveness of PDA and SPARDA through various experiments, including synthetic data and real-world applications in gene expression analysis.
The strengths of the paper include:
* The introduction of a novel and powerful framework for analyzing high-dimensional distributions
* The ability to capture arbitrary types of differences without restrictive assumptions
* The provision of a sparse variant, SPARDA, for feature selection
* The demonstration of the method's effectiveness through various experiments
The weaknesses of the paper include:
* The computational complexity of the RELAX algorithm, which may be a limitation for large-scale applications
* The reliance on the choice of divergence measure, which may affect the results
* The lack of theoretical guarantees for the high-dimensional setting, which is an area for further research
Arguments for acceptance:
* The paper introduces a novel and powerful framework for analyzing high-dimensional distributions
* The method has been demonstrated to be effective in various experiments, including real-world applications
* The paper provides a clear and well-written exposition of the methodology and results
Arguments against acceptance:
* The computational complexity of the RELAX algorithm may be a limitation for large-scale applications
* The reliance on the choice of divergence measure may affect the results
* The lack of theoretical guarantees for the high-dimensional setting may be a concern for some reviewers
Overall, I believe that the paper makes a significant contribution to the field of machine learning and statistics, and I recommend acceptance. However, I suggest that the authors address the weaknesses mentioned above, particularly the computational complexity and the lack of theoretical guarantees, in future work.