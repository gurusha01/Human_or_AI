This paper proposes a novel approach, called Trimmed Graphical Lasso, for robust estimation of sparse Gaussian Graphical Models (GGMs) in the presence of outliers or heavy-tailed data. The method is inspired by the Least Trimmed Squares method used for robust linear regression and guards against outliers by an implicit trimming mechanism. The authors provide a rigorous statistical analysis of their estimator in the high-dimensional setting, which is a significant contribution as existing approaches for robust sparse GGMs estimation lack statistical guarantees.
The paper is well-written, and the authors clearly explain the problem setup, the proposed method, and the theoretical results. The experimental results on simulated and real gene expression data demonstrate the value of the approach, showing that it is competitive with alternative robust methods and outperforms the standard Graphical Lasso method in the presence of outliers.
The strengths of the paper include:
* The proposal of a novel and robust method for estimating sparse GGMs, which is a significant contribution to the field.
* The provision of rigorous statistical guarantees for the estimator, which is a major advantage over existing approaches.
* The experimental results, which demonstrate the effectiveness of the method in practice.
The weaknesses of the paper include:
* The method requires the choice of several tuning parameters, including the regularization parameter Î» and the trimming parameter h, which can be challenging in practice.
* The computational complexity of the method may be high, especially for large datasets, although the authors report that the method is competitive with alternative robust methods in terms of computational time.
Overall, the paper makes a significant contribution to the field of robust statistical estimation and is well-suited for presentation at NIPS.
Arguments pro acceptance:
* The paper proposes a novel and robust method for estimating sparse GGMs, which is a significant contribution to the field.
* The authors provide rigorous statistical guarantees for the estimator, which is a major advantage over existing approaches.
* The experimental results demonstrate the effectiveness of the method in practice.
Arguments con acceptance:
* The method requires the choice of several tuning parameters, which can be challenging in practice.
* The computational complexity of the method may be high, especially for large datasets.
However, the strengths of the paper outweigh the weaknesses, and I recommend acceptance.