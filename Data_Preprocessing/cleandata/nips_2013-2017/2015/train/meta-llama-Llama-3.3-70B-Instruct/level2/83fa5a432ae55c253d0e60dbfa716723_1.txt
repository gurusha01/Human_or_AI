This paper introduces the Principal Differences Analysis (PDA) framework for analyzing differences between high-dimensional distributions. The method operates by finding the projection that maximizes the Wasserstein divergence between the resulting univariate populations. The authors also propose a sparse variant of the method, called SPARDA, to identify features responsible for the differences.
The paper is well-written, and the authors provide a clear and concise introduction to the problem and their approach. The related work section is thorough, and the authors do a good job of highlighting the differences between their approach and existing methods.
The technical contributions of the paper are significant, and the authors provide a detailed analysis of the PDA and SPARDA frameworks. The use of the Wasserstein distance as a divergence measure is well-justified, and the authors provide a clear explanation of how it is used in the PDA framework. The SPARDA framework is also well-motivated, and the authors provide a clear explanation of how it can be used to identify features responsible for the differences between distributions.
The experimental results are impressive, and the authors demonstrate the effectiveness of the PDA and SPARDA frameworks on a range of datasets. The results on the MADELON dataset are particularly impressive, and the authors show that SPARDA is able to identify the relevant features with high accuracy. The results on the single-cell RNA-seq data are also interesting, and the authors demonstrate the ability of SPARDA to identify subtype-specific genes and genes involved in functional interactions between genes.
The strengths of the paper include:
* The introduction of a new framework for analyzing differences between high-dimensional distributions
* The use of the Wasserstein distance as a divergence measure
* The proposal of a sparse variant of the method, called SPARDA
* The impressive experimental results on a range of datasets
The weaknesses of the paper include:
* The paper is quite long and dense, and some readers may find it difficult to follow
* The notation is sometimes confusing, and the authors could have done a better job of defining the notation clearly
* The paper could have benefited from more discussion of the limitations of the approach and potential avenues for future work
Overall, I would recommend accepting this paper for publication. The technical contributions are significant, and the experimental results are impressive. With some revisions to address the weaknesses mentioned above, this paper has the potential to make a significant impact in the field.
Arguments for acceptance:
* The paper introduces a new framework for analyzing differences between high-dimensional distributions
* The use of the Wasserstein distance as a divergence measure is well-justified
* The experimental results are impressive, and the authors demonstrate the effectiveness of the PDA and SPARDA frameworks on a range of datasets
Arguments against acceptance:
* The paper is quite long and dense, and some readers may find it difficult to follow
* The notation is sometimes confusing, and the authors could have done a better job of defining the notation clearly
* The paper could have benefited from more discussion of the limitations of the approach and potential avenues for future work
Rating: 8/10
Confidence: 0.8
Recommendation: Accept with minor revisions.