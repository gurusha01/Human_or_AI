This paper proposes a multi-scale recurrent convolutional neural network (RCNN) for scene labeling, a challenging computer vision task that requires the use of both local discriminative features and global context information. The authors adopt a deep RCNN, which seamlessly integrates feature extraction and context modulation in multiple levels of representation, making it particularly suitable for scene labeling.
The paper is well-written, and the authors provide a clear and concise introduction to the problem of scene labeling and the motivation behind their approach. The related work section is comprehensive, and the authors provide a thorough review of existing methods for scene labeling, including non-parametric and parametric models, as well as neural network-based approaches.
The technical contributions of the paper are significant, and the authors propose a novel architecture that combines the strengths of convolutional neural networks (CNNs) and recurrent neural networks (RNNs). The use of intra-layer recurrent connections in the convolutional layers allows the model to capture both local and global information, and the multi-scale approach enables the model to handle objects of varying sizes.
The experimental results are impressive, and the authors demonstrate the effectiveness of their approach on two benchmark datasets, Sift Flow and Stanford Background. The results show that the proposed RCNN outperforms many state-of-the-art models in terms of accuracy and efficiency, and the authors provide a detailed analysis of the results, including the influence of different hyper-parameters and the comparison with other models.
The strengths of the paper include:
* The proposal of a novel architecture that combines the strengths of CNNs and RNNs for scene labeling
* The comprehensive review of existing methods for scene labeling
* The impressive experimental results on two benchmark datasets
* The detailed analysis of the results and the influence of different hyper-parameters
The weaknesses of the paper include:
* The lack of a clear comparison with other state-of-the-art models that use pre-trained features, such as the fully convolutional network (FCN)
* The limited analysis of the computational complexity of the proposed model
* The need for further experimentation to fully explore the potential of the proposed architecture
Overall, this is a strong paper that makes significant contributions to the field of computer vision, and the proposed RCNN architecture has the potential to be widely adopted for scene labeling and other related tasks. The authors provide a clear and concise presentation of their work, and the experimental results are impressive. With some minor revisions to address the weaknesses mentioned above, this paper has the potential to be a top-tier publication in the field. 
Arguments pro acceptance:
* The paper proposes a novel architecture that combines the strengths of CNNs and RNNs for scene labeling
* The experimental results are impressive, and the authors demonstrate the effectiveness of their approach on two benchmark datasets
* The paper provides a comprehensive review of existing methods for scene labeling
Arguments con acceptance:
* The lack of a clear comparison with other state-of-the-art models that use pre-trained features
* The limited analysis of the computational complexity of the proposed model
* The need for further experimentation to fully explore the potential of the proposed architecture.