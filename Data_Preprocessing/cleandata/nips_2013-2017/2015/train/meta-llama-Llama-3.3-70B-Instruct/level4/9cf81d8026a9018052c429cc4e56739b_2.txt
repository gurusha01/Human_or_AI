This paper proposes a pixelwise classification system that utilizes recurrent convolutional connections. 
The approach is based on a multiscale convolutional network, similar to the one presented by Farabet et al., but with the added features of shared weights and additive skip-connections between layers at each scale.
The model's performance is assessed using the Stanford Background and SIFT Flow datasets.
Although the method demonstrates promising results when trained from scratch, there are several areas that could be further investigated and evaluated.
* Firstly, it would be beneficial to compare the impact of sharing weights between recurrent connections to the same network using distinct convolution kernels in each iteration. While this may introduce additional parameters, it could potentially enhance performance without significantly increasing computational costs.
 
This comparison was partially made, but the CNN2 model has fewer total layers and a smaller receptive field, which may affect the outcome.
Moreover, the findings related to the effect of gamma (enabling or disabling skip connections) might be different under these conditions.
* Secondly, a more in-depth analysis of the effects of N and T would be valuable.
As far as I can determine, all RCNN networks use T=3, except for RCNN-large, which uses T=4.
However, RCNN-large is only evaluated for N=3.
It would be interesting to see its performance at N=4 and N=5.
* Additionally, there appears to be a discrepancy in the reported performance of RCNN and RCNN-large in Tables 1 and 2.
Table 2 reports an RCNN performance of 83.5/35.8 PA/CA, while Table 1 shows RCNN-large with a performance of 83.4/38.9 PA/CA, which seems better.
It is unclear why the latter was not used in Table 2.
* The related work section mentions that certain networks, such as [4], rely on post-processing techniques like superpixels to ensure consistency in neighboring pixel labels.
This implies that the proposed model may not suffer from this issue, but this is not evaluated in the experiments or demonstrated through qualitative examples.
No example predictions are provided, making it difficult to assess the qualitative output of the model.
* Furthermore, there are recent works in this area that could be discussed or compared, such as Chen et al.'s "Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs" and Eigen & Fergus's "Predicting Depth, Surface Normals and Semantic Labels with a Common Multi-Scale Convolutional Architecture". 
This approach achieves good performance for being trained from scratch; however, some aspects could be better explored and evaluated.