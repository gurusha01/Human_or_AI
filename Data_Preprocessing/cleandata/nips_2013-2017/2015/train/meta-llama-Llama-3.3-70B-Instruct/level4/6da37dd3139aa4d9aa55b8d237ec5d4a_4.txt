This research explores a relatively uncharted territory in automatic driving, focusing on 3D object proposal methods, and presents a novel approach that exhibits higher accuracy compared to existing methods. However, the processing time of 1.2 seconds may not be considered exceptionally fast. The paper is generally well-structured and clearly written, but several aspects warrant further clarification and investigation. Specifically, two key points require attention: 
1) The formulation of Equation 1 as a Markov Random Field (MRF) is not entirely clear, as the energy computation appears to consider individual 3D object proposals in isolation, rather than accounting for interactions between them.
2) The methodology relies on several assumptions, including the availability of clean depth data from stereo pairs, the coplanarity of objects on the ground, and the representability of objects' 3D heights and aspect ratios using a limited set of templates. It is crucial to assess the robustness of the proposed method to violations of these assumptions, particularly under conditions of sparse and erroneous depth data or failed ground plane estimation. Conducting sensitivity experiments would provide valuable insights into the method's performance under such scenarios.
The proposed 3D object bounding box proposal method aims to detect cars, bikes, and pedestrians in stereo images, leveraging assumptions pertinent to automatic driving, such as the availability of clean depth data, the coplanarity of objects, and their conforming to typical 3D dimensions and aspect ratios. Based on these assumptions, various 3D cues (e.g., 3D points density, free space, height priors) are computed within 1.2 seconds to generate 3D object proposals. Notably, the method achieves significantly higher recall rates compared to competing 2D and 3D methods when considering 500 proposals. Furthermore, when integrated with state-of-the-art CNN architectures, the proposed region proposal method yields substantial improvements in detection accuracy, particularly for objects that are challenging to detect.