The paper presents an efficient optimization algorithm, HONOR, for tackling nonconvex regularized problems by leveraging second-order information to accelerate convergence. Notably, the authors have successfully established that every limit point of the sequence generated by HONOR corresponds to a Clarke critical point, a feat that is particularly challenging in the context of nonconvex optimization compared to convex methods. The proposed algorithm demonstrates both theoretical rigor and computational efficiency. However, several aspects warrant further clarification.
1: The algorithm's design, which ensures that the current iterate remains within the same orthant as the previous iterate, thereby avoiding axis crossings between consecutive iterates, appears to introduce a dependency on the initial point $x^0$. This raises several questions:
- How sensitive is the solution obtained by HONOR to the choice of initial solution?
- What specific initial solution vector was utilized in the numerical experiments conducted by the authors?
- Do the results depicted in Figure 1 exhibit variability when different initial solutions are employed?
2: While HONOR's incorporation of second-order information is a significant advantage in terms of convergence speed, it may come at the cost of increased memory usage. Furthermore, for highly nonconvex problems, the positive definite matrix $H^k$ approximated by L-BFGS may substantially differ from the actual Hessian matrix of the optimization problem. The authors' thoughts on mitigating these potential issues would be valuable. The paper is well-written, and the development of an efficient algorithm with theoretical guarantees for nonconvex problems is highly significant. Nonetheless, addressing the concerns regarding the proposed algorithm is essential to further enhance its applicability and robustness.