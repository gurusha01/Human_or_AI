This study explores the generation of sentences from a sequence of images, proposing a coherent recurrent convolutional network (CRCN) that integrates convolutional neural networks, bidirectional recurrent neural networks, and an entity-based local coherence model.
Overall, the work is commendable, but there are areas for improvement: 
* The literature review lacks several relevant studies on video-to-sentence generation, such as the unified framework that jointly models deep video and compositional text to bridge vision and language.
* Although the quantitative results of the proposed method appear promising, the user study in Table 2 indicates similar performance to the RCN baseline, suggesting the need for significance testing to confirm the reliability of the observed improvement.
The algorithm presented for generating sentences from an image stream is noteworthy, with favorable quantitative results, but the user study reveals only a marginal advantage over baseline methods.