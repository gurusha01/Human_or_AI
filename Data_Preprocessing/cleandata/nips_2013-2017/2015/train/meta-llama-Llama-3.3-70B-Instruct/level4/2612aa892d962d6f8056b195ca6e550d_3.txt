This submission presents a novel algorithm for real-time control of 3D models, leveraging a neural network (NN) to generate animations after being trained offline to replicate the output of Contact-Invariant Optimization (CIO). Notably, the CIO and NN training processes are intertwined, with each informing the optimization criterion of the other. The method also incorporates noise injection through data augmentation and additive noise in the NN's hidden layers. Experimental results demonstrate the network's ability to produce realistic and stable control policies across diverse character models.
The proposed approach is intriguing, given the challenges associated with real-time control of arbitrary models. Although the method may seem straightforward at first glance ("learning a NN to predict CIO output"), the additional steps required to achieve success (joint training and noise injection) constitute significant new contributions, as evidenced by improved generalization in experiments.
However, the experimental results would be more convincing with comparisons to a larger dataset. The limited training trajectories (between 100 to 200 trials with 5 branched segments) may contribute to overfitting in the "no noise" variant. The "no joint" variant might also benefit from more diverse training trajectories, although this is less apparent.
The comparative evaluation is the paper's weakest aspect, as acknowledged in the introduction. A more comprehensive comparison to competing methods is needed, beyond the brief comparison to Model Predictive Control (MPC) at the end of the paper. Additionally, a reference for the MPC method is missing.
The mathematical explanations are generally clear and well-motivated, although some points are only superficially addressed, requiring additional references for replication (notably the CIO step, as seen in Eq. 6, where notations are undefined). Providing code would be a valuable resource for the community. One section, 3.2, which discusses generating optimal actions for noisy inputs, was unclear due to confusing notations, particularly the omission of the time index "t" and its implications for certain quantities.
Including time measurements for computations during real-time control would be beneficial, as this could be a significant bottleneck, especially in applications like video games where CPU resources are limited for animating individual characters.
Minor remarks include: 
- The term "biped location" could be clarified as referring to locomotion.
- The phrase "It is our aim to unity these disparate approaches" should be revised to "unite" or "unify".
- The target appears to be limited to x, y, z coordinates without considering the character's facing angle, which might be important in practice and could be easily incorporated.
- The term "noise injection" might be misleading, as it refers to data augmentation with re-computed targets, rather than denoising autoencoders.
- The use of initial network weights theta in the first iteration of Alg. 1 could be clarified, as well as the justification for using the same hyperparameter eta in both steps.
- Several minor errors, such as missing articles, incorrect acronym usage, and typographical errors, were noted throughout the text.
- The asynchronous joint optimization scheme in Section 6 differs significantly from the alternating scheme in Alg. 1, which could be mentioned earlier for clarity.
- The "no noise" variant in experiments could be split into "no data augmentation" and "no hidden noise injection" for more detailed analysis.
- Investigating whether alpha can be decreased to zero during optimization (for CIO only) could provide insights into the method's effectiveness, particularly regarding any "curriculum learning" effects.
Overall, this is an impressive application of neural networks to character control, although its practical benefits and applicability require further establishment.