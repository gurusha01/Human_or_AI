This manuscript presents Consensus Monte Carlo (CMC), a parallelization method for Markov Chain Monte Carlo (MCMC) algorithms, facilitating posterior inference over large datasets by factorizing the posterior into sub-posteriors. Each sub-posterior depends on a subset of datapoints, allowing for parallel sampling and subsequent transformation into samples from the true posterior via an aggregation function. However, existing aggregation methods are either simplistic, leading to high bias, or computationally expensive. The authors propose a more principled approach to combining samples by optimizing aggregation functions using variational inference.
The paper's clarity is commendable, making it easy to follow. The significance of this work lies in its potential to make parallel MCMC using CMC more practical, addressing the crucial problem of Bayesian inference for large datasets. The originality of the paper stems from its use of variational inference to optimize CMC aggregation functions, offering a notable improvement over fixed aggregation methods. Although estimating the entropy term poses challenges, the authors' strategy of minimizing a lower bound is a viable solution, contributing to a substantial reduction in error when estimating posterior expectations compared to simple baselines.
The quality of the method appears sound, but the experimental section falls short of expectations. While the inclusion of toy problems and datasets is useful for illustrating key aspects of the algorithm, such as aggregating structured samples, more realistic and comprehensive experiments are necessary. Given that parallel MCMC is primarily beneficial for large datasets, the comparison on small datasets (with the largest containing only 50K datapoints) is somewhat limiting. Furthermore, experimenting with more complex models like Latent Dirichlet Allocation (LDA) would make the method more appealing to practitioners, especially considering the availability of large, real datasets for such models. The comparison against simple baselines, without inclusion of more advanced methods like those by Neiswanger et al. or the Weierstrass sampler by Wang and Dunson, leaves questions about its relative performance. Additionally, a comparison with serial mini-batch algorithms such as Stochastic Gradient Langevin Dynamics (SGLD) would provide valuable insights, particularly regarding the potential advantages and disadvantages of the proposed method when considering the time required for aggregating samples and optimizing the aggregation function.
Despite these reservations, the paper is well-written and presents a significant contribution. However, the experimental section requires substantial enhancement to demonstrate the method's efficacy and practicality more convincingly. While leaning towards acceptance, rejecting the paper to await more comprehensive and realistic experiments would not be unjustified, as it would provide the authors an opportunity to strengthen their work and address the aforementioned limitations.