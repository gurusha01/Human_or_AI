This paper presents a novel training approach, scheduled sampling (SS), for recurrent neural networks (RNNs), where ground truth labels are occasionally substituted with model-generated predictions. Various schedules are proposed to determine when to replace the ground truth labels, effectively implementing different decay functions (linear, exponential, and inverse sigmoid). The results demonstrate improvements over a comparable RNN model without SS on tasks such as image captioning, constituency parsing, and speech recognition.
The experimental findings are intriguing, and the focus on enhancing robustness at test time is noteworthy. However, this paper raises several unanswered questions. Key concerns include:
- If SS functions as a regularizer, it is reassuring to see that it appears to be complementary to dropout. Nevertheless, a baseline comparison to always randomly sampling labels according to the proposed schedules, rather than utilizing model predictions, would be beneficial.
- To assess the effectiveness of SS in mitigating search error, a comparison to baselines with varying beam widths would be valuable. Does SS still offer benefits when the model employs a larger beam width?
- The hyperparameter k is a concern, as its setting is based on "expected speed of convergence" without discussion of its sensitivity or tuning process in the experiments.
At a higher level, this paper would benefit from a more rigorous probabilistic analysis to elucidate why the proposed heuristic appears to be effective. Experiments investigating the impact of SS as the amount of supervision varies would provide valuable insights. 
After considering the author's response, some concerns persist, particularly regarding the practical challenges of tuning the sampling schedule and the need for more in-depth analysis of the method. This paper introduces a promising training heuristic for RNNs, enhancing the robustness of predictions at test time. Although the experiments are encouraging, the underlying reasons for the method's effectiveness and the lack of both experimental and theoretical analysis are notable limitations.