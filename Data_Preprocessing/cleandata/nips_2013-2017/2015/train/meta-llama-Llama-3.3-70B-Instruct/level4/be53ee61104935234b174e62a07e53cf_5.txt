The paper under review investigates the Isotonic Regression problem in the context of $\ell_p$-norms, where $1\leq p \leq \infty$. Given a directed acyclic graph (DAG) $G(V,E)$, observations $y\in \bR^{|V|}$, and a weight vector $w$, the isotonic regression problem is formulated as the minimization problem: 
\begin{eqnarray}
\minx \|x-y\|{w,p} \mbox{ such that } xu \leq xv \mbox{ for all } (u,v)\in E,
\end{eqnarray}
where $\|\cdot\|{w,p}$ denotes the weighted $\ellp$-norm.
The key findings of the paper include a bound of $O(m^{1.5}\log^2 n \log(npw{max}^p/\delta))$ on the time complexity, which holds with high probability for $1\leq p < \infty$, as stated in Theorem 2.1. This result is compared to previous works in Table 1, highlighting the improvement in time complexity for $p<\infty$. For the case of $p=\infty$ and the Strict Isotonic Regression, the paper presents upper bounds on the time complexity for computing exact results in Theorems 1.2 and 1.3, respectively. These bounds improve upon previous results, with the exception of an $\ell1$ bound in two-dimensional space.
The authors achieve these results by transforming the original regression problem into an instance solvable by an approximate interior point algorithm, \textsc{ApproxIPM}. They demonstrate the efficiency and accuracy of a critical subroutine, \textsc{BlockSolve}, designed to compute an approximate Hessian inverse. This approach enables the proposed algorithm to attain better time complexity for $1\leq p<\infty$. The paper's contribution lies in generalizing a result for linear programs to $\ellp$ objectives and providing an improved analysis. For $\ell\infty$ Isotonic Regression and Strict Isotonic Regression, the authors reduce these problems to Lipschitz Learning problems and apply algorithms from existing literature to compute solutions.
Preliminary experiments on the proposed algorithm are presented in Table 2. However, the paper's theoretical contributions are incremental, building upon existing techniques in convex optimization and interior point methods. The main algorithm and its analysis are not clearly presented in the main body of the paper, although they can be found in the supplementary file. This omission may necessitate restructuring for improved presentation.
Several typos and undefined notations were identified, including an error in the condition for a connected graph, an incorrect failing probability, and undefined terms such as $\textsc{Solve}{HF}$ and \textsc{Solve}. These issues hinder the clarity and readability of the paper.
In terms of quality, the theoretical aspects of the paper are acceptable, but the experimental results are not sufficient for publication. The overall presentation, considering only the main body, falls short of expectations. The algorithm and its critical analysis are missing from the main body, making it challenging for readers to grasp the work's significance.
The originality and significance of the paper are limited, as it presents incremental improvements on the Isotonic Regression in $\ell_p$-norms. The experimental results are preliminary, and the main contributions to the algorithm and its design are not adequately presented in the main body of the paper. Overall, the paper requires significant revisions to enhance its clarity, presentation, and overall impact.