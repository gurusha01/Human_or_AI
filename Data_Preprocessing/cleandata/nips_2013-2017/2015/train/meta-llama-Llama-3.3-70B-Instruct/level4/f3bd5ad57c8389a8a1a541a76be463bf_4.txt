This manuscript proposes a refined version of Expectation Propagation (EP) that achieves a reduction in memory requirements, albeit at the expense of decreased accuracy and occasionally increased computational cost.
The authors delve into the relationships between their approach and other relevant algorithms, providing a comprehensive context for their work.
The extensive experimental evaluations presented in the paper offer a compelling argument for the practical viability of the proposed algorithm.
However, a notable weakness of the manuscript lies in its somewhat sloppy presentation.
Notably, the abstract and introduction conflate "computation" with "memory", despite these being distinct concepts. In reality, the proposed method, SEP, sometimes incurs additional computational costs in exchange for reduced memory usage.
The description of SEP lacks clarity regarding the number of iterations involved.
Furthermore, it is unclear whether SEP was run to convergence (if such a concept applies) or manually terminated in Table 1.
In Section 4.1, the statement that the algorithm "converges in expectation" is ambiguous, as it does not specify what is meant by "expectation" or what variables are being randomized.
A similar issue arises with Theorem 1, which is not accompanied by a rigorous proof. The "proof" provided in Appendix A merely reiterates the theorem without offering a substantive demonstration.
If the authors cannot provide a precise statement with a valid proof, this claim should be omitted from the manuscript.
The assertion in Section 4.4 that messages to latent variables associated with a single data point do not need to be stored relies on a specific assumption - namely, that the term p(xn | hn, theta) can be updated in a single step.
While this assumption holds for the model presented in Section 5.2, it is not universally applicable. For instance, in Latent Dirichlet Allocation (LDA), the latent variable for each document (topic proportions) cannot be updated in a single step, necessitating the storage of these messages unless computational costs are significantly increased.
Appendix B.2 should be corrected to state that "This procedure still reduces memory by a factor of N/K".
In Section 5.1, it is noted that ADF should collapse to a delta function at the true posterior mode, rather than the mean. Overall, the manuscript presents an elegant modification of EP, a thoughtful discussion of connections to other algorithms, and extensive experimental results.