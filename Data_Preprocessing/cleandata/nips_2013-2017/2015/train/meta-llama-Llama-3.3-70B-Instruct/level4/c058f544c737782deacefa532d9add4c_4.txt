Summary
This paper examines the minimization of strongly convex or partially strongly convex functions over polyhedra, presenting and analyzing various Frank-Wolfe algorithm variants. The authors demonstrate that these variants can circumvent the limitation of the standard Frank-Wolfe algorithm in leveraging strong convexity, leading to linear convergence for all presented variants. The analysis introduces a combinatorial positive constant related to a polyhedra condition number, with numerical results provided for synthetic and real examples.
Main comments
The paper introduces novel versions of existing algorithms from the literature, with linear convergence being a new and interesting finding for some variants. The concept of pyramidal width may have broader applications beyond linear oracle-based methods. The proof arguments appear sound, and there are no significant issues with the content. However, several points require clarification or additional detail, as outlined in the following sections.
Detailed comments
- The behavior of these algorithms without strong convexity assumptions should be discussed.
- The emphasis on affine invariance could be clarified, particularly regarding the surjectivity of the linear map.
- The proof of Theorem 3 in the appendix requires more precise argumentation, especially concerning the KKT conditions and the conclusion about the solution on the relative boundary of the cone.
- The MNP variant's requirement for a subroutine to minimize the objective over an affine hull has significant practical implications that should be emphasized.
- The claim that the analysis for partially strongly convex models follows directly by replacing a constant needs more justification, given the differences in constants between equations (21) and (34).
- A comparison with the estimated rates for the away step variant under partial strong convexity, as treated in [4], would be beneficial.
- The equivalence of pyramidal width and width for the simplex deserves more justification, along with a precise citation of [2].
- The convergence analysis of [12] does not cover the case of a strongly convex objective and set, contrary to the statement in the introduction.
Minor comments
- The abstract should specify "of the objective" when mentioning "weaker condition than strong convexity".
- A reference to the convergence rates of the projected gradient method could be added.
- Several typos and minor errors are noted, including "While the tracking the active set", "due our", "more computed more efficiently", and "overarching".
- Footnote 3's lower bound clarification and the potential size of the active set after many iterations should be addressed.
- The conjecture about the nonincreasingness property of the introduced constant could be discussed further.
- Figure 2's readability and notation consistency throughout the appendix should be improved.
- Specific line references are provided for corrections and clarifications, including the use of $r$ and $y$ in different contexts and the self-reference to "the appendix".