The authors present a kernel-based approach for cross-domain matching, aiming to retrieve a matching instance in the target set given an instance in the source set. Each instance from the two distinct domains is represented as a bag of features and embedded into a common space, known as the Reproducing Kernel Hilbert Space (RKHS), using kernel embedding for matching purposes. The features from both domains are learned jointly by maximizing a likelihood that is inversely proportional to the distance, specifically the Maximum Mean Discrepancy (MMD), of the embedded instances in RKHS. The proposed method demonstrates superior performance over standard approaches, such as Canonical Correlation Analysis (CCA) and kernel CCA, on various matching tasks including document-document, document-tag, and tag-image.
The writing is clear and the experimental results are impressive, with the method consistently outperforming other approaches in all three experiments. In the context of machine learning, excluding information retrieval, cross-domain matching is primarily addressed by CCA or kernel CCA, making this paper a valuable starting point for further exploration in this area.
However, regarding originality, the concept of embedding a bag of hidden features with a kernel and learning these features is not novel, as it was previously considered in [18]. The original contribution appears to lie in the application of this approach to cross-domain matching, coupled with a proposed probabilistic model similar to that in kernel logistic regression. Although the experimental results provide evidence of the method's superior performance over KCCA on certain tasks, the paper lacks sufficient motivation, justification, and description of the method's advantages for a deeper understanding.
Key comments and questions, in order of importance, include:
1. The problem of kernel CCA is not clearly articulated in the motivating paragraph spanning lines 70-78.
2. It is presumed that the learned latent vectors \(xf\) and \(yg\) play a more significant role in the algorithm than the kernel \(k\). A comparison between the Gaussian kernel \(k\) and a linear kernel with a large latent dimension \(q\) would be insightful, as a linear kernel with sufficient dimensionality might allow the learned latent vectors to perform the task without the need for a kernel.
3. The motivation behind the likelihood in Eq. 8 seems ad-hoc. Using \(||m(X)-m(Y)||^2\) as the loss in Eq. 11 could simplify optimization and reduce costs, as the log term in Eq. 11 would be eliminated.
4. A qualitative comparison between the proposed method and kernel CCA, beyond numerical results, would provide valuable insights. This could involve shortening sections 4.1 and 4.3 to accommodate a more detailed explanation.
5. Investigating the effect of varying the latent dimension \(q\) on precision and runtime would be beneficial, as the experiments currently focus solely on precision.
6. The computational cost of the method compared to kernel CCA should be addressed, considering that kernel CCA might be more efficient. The gradient in Eq. 12 is likely expensive, and the objective's non-convex nature could pose optimization challenges.
7. Clarification is needed on whether hyper-parameters were chosen by cross-validation and if "development data" refers to a validation set, as mentioned in lines 284-286.
8. It is unclear if KCCA uses the same learned features \(xf\) and \(yg\) as the proposed method in the experiments. If not, what kernel does KCCA employ, and what are the results when using the same features?
9. The abstract mentions keeping unpaired instances apart, but the implementation of this criterion in the method is not clear.
10. The claim that the method can learn a more complex representation (lines 100-102) lacks explanation and could be supported by experimental evidence.
Minor points include:
- Eq. 3 incorrectly refers to \(||m(X)-m(Y)||^2\) as a distance; it should be \(||m(X)-m(Y)||\) or MMD.
- The notation \(x_f\) should be clarified as a latent vector for word (feature) \(f\) in the experiments.
- The reference format is inconsistent, with some entries using abbreviated author names.
After considering the authors' rebuttal, which addressed some but not all questions, the paper remains an interesting contribution to kernel-based algorithms for cross-domain matching, with promising experimental results. However, the motivation and qualitative description of the method require further elaboration for a comprehensive understanding.