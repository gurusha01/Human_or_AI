This paper makes a significant contribution to the understanding of generalization error in adaptive data analysis by introducing the concept of max-information, establishing links to differential privacy and description length-based adaptive data analysis, and proposing novel algorithms. The notion of max-information is a natural fit for this problem, and its development is likely to facilitate the creation of new algorithms and approaches for accurate adaptive data analysis, such as the description length-based approach presented in the paper.
Quality: The paper tackles a crucial problem and substantially enhances our comprehension of it. It strikes a good balance between theoretical analysis, particularly in the examination of the max-information concept, and practical applications, including the development of two new algorithms and the presentation of empirical results.
Clarity: One minor drawback of the paper is that it attempts to cover too much ground in a limited space, making the main text somewhat dense. In contrast, the full version of the paper is more readable, suggesting that some results could be condensed or omitted from the main text to improve clarity. The introduction, in particular, could be significantly condensed to enhance readability. Additionally, a comparison between the main theorems and those in [6] would be beneficial, potentially highlighting the similarities and differences between the bounds presented in Theorem 9 of [6] and Corollary 20 of this paper. Such a comparison could provide valuable insights, especially considering that both appear to yield similar deviation bounds for sensitive 1/n functions when the differential privacy parameter is set to tau, analogous to Hoeffding's bound. Being more explicit about the paper's key contributions would also improve readability.
Originality: The work presented is original.
Significance: The paper's findings are significant.
Some minor observations and suggestions: 1. In Definition 3, the notation should be corrected to $I_\infty^\beta(S; \Acal(S))$.
2. In the experiment section of the main text, it is mentioned that Gaussian noise is used as an alternative to Laplace noise. However, it is unclear whether the figure presents results for Laplace noise or Gaussian noise. This paper provides important theoretical insights and algorithms for the problem of generalization in adaptive data analysis. Overall, the results are significant, and aside from a few minor issues, primarily related to the dense presentation of multiple results in a limited space, the paper is well-written and contributes meaningfully to the field.