It would be beneficial to include the execution times for all algorithms to provide a comprehensive understanding. The employment of five distinct algorithms for calculating a gradient step towards the constrained posterior appears overly complex, which may detract from the algorithm's appeal. A thorough justification for the necessity of each step would be helpful. The proposed methodology utilizes sparsity-enforcing posterior regularization, transforming inference in factor analyzers into a nonlinear process that enables the creation of hierarchical representations through model stacking. Although this technique is intriguing, its scalability is a concern due to its batch processing nature. The results presented seem plausible, despite the algorithm's significant computational expense compared to the baseline methods it is evaluated against.