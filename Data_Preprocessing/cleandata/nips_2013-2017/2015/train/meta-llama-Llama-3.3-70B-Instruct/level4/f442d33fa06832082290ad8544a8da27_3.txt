I find the concept of applying distributional methods to sentences, beyond their traditional use with words, to be highly promising. 
The experimental design appears to be thorough, with comparisons made across a diverse range of problems, demonstrating a comprehensive approach.
This paper proposes an unsupervised method for training vector representations of sentences, utilizing a GRU encoder to process a sentence and then predict the words in adjacent sentences. Overall, I have a very positive impression of this work. One potential enhancement could be to explore the use of skip-sentence vectors, as the current approach may not fully capture the nuances of sentence structure, given that a sentence does not necessarily equate to a single thought.