Summary
This paper investigates the issue of batch learning from logged bandit feedback, a problem with significant implications, such as in ad ranking. It highlights an "overfitting" issue in the recently proposed Conterfactual Risk Minimization (CRM) principle and presents a solution utilizing multiplicative control variates, which yields a biased estimator.
Quality
The paper is of high quality and well-motivated. As a follow-up to [1], it would have been beneficial to include more comprehensive experiments and a deeper analysis of the training objective's optimization, providing more detail than what is currently presented on line 415.
Clarity
The presentation is clear, and the paper is well-written, making it easy to follow and understand.
Originality
While this work builds upon [1], the modification of the risk estimator to be self-normalizing appears to significantly impact the experimental outcomes. This adjustment constitutes a notable contribution.
Significance
The problem of learning from logged data is indeed relevant. However, it remains challenging to assess how the substantial experimental improvements demonstrated in the paper will translate to real-world applications.
Various Remarks
On line 365, considering the multiple repetitions already conducted, it would be beneficial to include a measure of variance to provide a more comprehensive understanding. The paper effectively identifies and addresses a problem within the CRM principle, offering a solid, well-written, and relevant contribution. Nonetheless, the inclusion of extended experiments, particularly those involving real-world applications beyond what was presented in [1], would have strengthened the paper further.