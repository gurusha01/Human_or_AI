Review- ADDED after author response:
I appreciate the additional insights provided. It would be beneficial to incorporate some of the key points regarding the distinction between implicit and explicit exploration, as well as the selection of parameters in both settings, into the final manuscript.
======
The motivation behind this work stems from the observation that the explicit exploration term commonly used in multi-armed bandit algorithms can have a detrimental impact on performance, particularly in scenarios where certain arms are clearly suboptimal. The authors propose an alternative approach by utilizing the implicit exploration (IX) concept introduced by Kocak et al [NIPS-2014], demonstrating that the corresponding loss function with implicit exploration (a) streamlines the regret bound analysis and (b) enhances the constant factor in established regret bounds for various multi-armed bandit problem variants.
The paper is engaging, well-written, and the mathematical derivations appear sound (although a thorough proof verification was not conducted). Table 1 provides a concise summary of the primary theoretical findings. While I found the paper enjoyable to read, my enthusiasm for acceptance is moderate due to the following concerns:
1. Novelty and significance: The innovative aspect of this work lies in the application of the existing IX idea to several known algorithms and their subsequent analysis. Although the results in Table 1 represent improvements, these advancements are limited to small constant factors. I remain uncertain about the significance of this result in advancing the field and its potential practical impact.
2. Implicit vs. Explicit exploration: The fundamental premise is that explicit exploration is undesirable, a viewpoint with which I concur. However, there are two key issues associated with explicit exploration. Firstly, it introduces a tradeoff parameter (exploration-exploitation balance) that often requires tuning in practice, depending on the specific domain. The proposed algorithm, nonetheless, possesses a similar parameter (gamma in the denominator), which does not entirely resolve this issue. Secondly, as mentioned in the abstract, explicit exploration leads to algorithms sampling the losses of every arm at least Omega(sqrt(T)) times over T rounds, even when many arms are clearly suboptimal. The implicit claim is that the proposed algorithm is more efficient in allocating resources, particularly for arms that are obviously suboptimal. Nevertheless, this aspect of the theory has not been thoroughly explored in the paper, and Table 1 does not address this concern. Upon reading the abstract, I anticipated a result of the form: if a certain fraction of arms is obviously suboptimal, then the IX algorithm will provably allocate fewer resources to them. The inclusion of such a result would have substantially strengthened the paper.
Overall, I appreciate the paper but have some reservations.
A well-crafted paper with robust mathematical foundations applies a previously proposed implicit exploration concept to several multi-armed bandit algorithms, resulting in improved constant factors in various prior bounds. However, the advantages of implicit over explicit exploration are not entirely clear to me.