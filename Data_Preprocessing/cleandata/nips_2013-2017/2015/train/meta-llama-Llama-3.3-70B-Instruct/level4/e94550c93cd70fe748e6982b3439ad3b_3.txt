This paper, titled "Variational Consensus Monte Carlo," introduces a novel approach to aggregating samples in a low-communication Markov Chain Monte Carlo (MCMC) setting. The method generalizes the Consensus Monte Carlo combination function, defining a family of combination functions, and utilizes variational inference to identify the function that yields samples from the best approximation to the full posterior distribution. A key advantage of this approach is its potential to facilitate the combination of complex mathematical objects beyond simple vectors, thanks to the generalized form of aggregation.
The paper presents experiments on a Bayesian probit regression model, a normal-inverse Wishart model, and a mixture of Gaussians, demonstrating the effectiveness of the proposed method. The development of scalable methods for Bayesian inference that maintain a good approximation to the posterior distribution is a crucial goal, and this paper makes a significant contribution towards achieving this objective. By framing an existing low-communication parallel MCMC strategy in terms of optimizing a variational objective, the authors provide a clever and innovative perspective.
However, the primary aim of low-communication parallel MCMC methods is to reduce inference time while maintaining a good posterior approximation. Although the paper shows that the proposed method provides a good approximation of the posterior distribution compared to existing methods, there is a need for more comprehensive experiments to verify that it retains the speed benefits of low-communication MCMC relative to existing low-communication parallel MCMC methods and communication-based parallel MCMC methods. A comparison against the speedups attained by the Consensus Monte Carlo method in one model is provided, but a more thorough investigation would be beneficial.
It would be interesting to compare the proposed Variational Consensus Monte Carlo (VCMC) method to serial methods for variational inference in terms of inference speed and error. Despite being presented as a "variational Bayes algorithm," all comparisons in the paper are against MCMC methods, not variational Bayes methods. Given the recent popularity of scalable variational inference methods, such as stochastic gradient variational inference, and the existence of methods for low-communication parallel variational inference, experimental comparisons with these approaches would be valuable.
One limitation of the VCMC method is its inability to provide guarantees about the correctness of the final aggregated samples, which some scalable MCMC methods attempt to address. Nevertheless, this is not significantly worse than most variational inference methods, which typically choose the best posterior approximation from a family of distributions. The method is expected to produce better results than the Consensus Monte Carlo method, assuming the weighted-average combination function is within the pre-specified family of functions.
The paper presents some theoretical results, including blockwise concavity under certain conditions and its consequences. However, more discussion is needed to explain the purpose and benefits of these results, as well as their relevance to the variational inference literature. Overall, the paper makes significant progress towards developing scalable approximate Bayesian inference methods that maintain a good posterior approximation. The idea of optimizing the sample aggregation function is innovative and produces good results relative to the Consensus Monte Carlo method. Nevertheless, a more thorough empirical exploration of inference times, speedups, and comparisons with other methods, particularly variational methods, would further strengthen the paper.