This manuscript proposes a regression-based approach to approximate the predictive distribution using a simple, tractable model, thereby circumventing the high computational cost associated with Monte Carlo sampling for the true predictive distribution. The authors justify their adoption of a Bayesian framework, which is partially validated by their simulation results, as opposed to a plug-in approach. The methodology presented, although predictable, is a logical and reasonable choice: it involves minimizing the average Kullback-Leibler divergence between the true predictive distribution and a surrogate parametric model, utilizing the output of the Stochastic Gradient Langevin Dynamics (SGLD) algorithm. The performance of this method is demonstrated through simulations on various examples, showcasing its superiority over competing methods, as is common in such manuscripts. However, the algorithm's numerous parameters and their selection process are not adequately discussed. Overall, the manuscript presents an unremarkable yet worthwhile idea to explore, offering a natural and sensible approach to addressing the predictive distribution approximation challenge.