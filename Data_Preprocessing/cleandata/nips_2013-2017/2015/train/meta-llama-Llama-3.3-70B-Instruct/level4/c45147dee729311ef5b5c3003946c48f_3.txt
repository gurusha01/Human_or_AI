This manuscript presents a novel approach to multi-frame super resolution using a bidirectional recurrent convolutional network. The problem formulation is straightforward and sensible, leveraging the strengths of RNNs in a way that is likely to resonate with experts in the field. The proposed method appears to be a natural extension of recent work, such as Dong et al.'s ECCV 2014 paper on deep convolutional networks for image super resolution, which was limited to static frames. The evaluation provided is of reasonable quality, making the paper a suitable candidate for NIPS.
One of the most intriguing aspects of this work is the analysis in Table 2, where the authors investigate the impact of feedforward convolutions, recurrent convolutions, and conditional convolutions. However, the discussion about MATLAB vs Python and the differences in run times seems secondary to the more critical issue of GPU acceleration, which is commonly used in state-of-the-art systems. The paper mentions that the implementation is in Python (line 362), but it is unclear whether GPU acceleration was utilized. Clarification on this point is necessary, as the use of a GPU could significantly affect the method's performance and comparison to prior work. Many existing methods, including those relying on accurate motion estimation, could also benefit from GPU acceleration.
The paper requires proofreading to address language issues, such as those found in the abstract:
* "Considering that recurrent neural network[s] (RNNs) can..."
* "Different from vanilla RNN[s]..."
* "conditional convolutional connections from previous input layers to [the] current hidden layer are added for enhancing visual-temporal dependency mod[el]."
Additionally, the conclusions section contains a statement about future comparisons with other multi-frame SR methods, which could be rephrased for clarity.
Overall, this paper demonstrates strong quantitative and visual results, showcasing the effectiveness of the proposed bidirectional recurrent convolutional network approach for multi-frame super resolution. While there are some language issues that need to be addressed, the model is well-conceived, and the results exhibit a good balance of quantitative performance gains, visual quality improvements, and competitive computation times relative to prior art.