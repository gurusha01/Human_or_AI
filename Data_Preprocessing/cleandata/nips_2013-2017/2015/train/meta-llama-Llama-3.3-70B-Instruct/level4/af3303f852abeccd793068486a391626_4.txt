This paper, titled "Bayesian Dark Knowledge," proposes a novel approach to approximately learn Bayesian neural network models while mitigating the significant storage and computational costs associated with traditional methods. The authors achieve this by employing a "distillation" technique, where a "student" model is trained to replicate the predictions of a Bayesian "teacher" model. Notably, this process occurs simultaneously and online, eliminating the need to store large collections of samples.
The paper's contribution to the development of practical computational tools for Bayesian inference in neural networks is commendable, particularly in addressing the issue of excessive storage requirements in large-parameter models. However, the core concept of student-teacher learning is not entirely new, having been explored in previous research. The innovation lies in the online training methodology, which enables the student model to learn from the teacher without requiring the storage of samples or the teacher's full posterior-predictive labels.
One potential drawback of the proposed algorithm is the necessity for repeated training of the student model on the dataset D' at each iteration of the MCMC algorithm. This could lead to increased computational demands, especially if a large dataset D' is required for optimal performance. The paper could benefit from a more in-depth discussion on the selection and impact of D' on the method's performance, as well as detailed explanations of the experimental settings.
The experimental section, while demonstrating the method's potential, falls short in terms of thoroughness and polish. The authors' inability to compare their approach with other methods, such as EP and VB, due to limitations in accessing open-source code or timely implementation, is acknowledged. Nevertheless, completing these comparisons and refining the experiments would significantly strengthen the paper. The goal of developing methods for Bayesian neural networks without the need for storing and evaluating multiple model copies is crucial, and the proposed approach is a valuable contribution. However, further refinement of the experimental section is necessary to fully demonstrate the method's efficacy and robustness.