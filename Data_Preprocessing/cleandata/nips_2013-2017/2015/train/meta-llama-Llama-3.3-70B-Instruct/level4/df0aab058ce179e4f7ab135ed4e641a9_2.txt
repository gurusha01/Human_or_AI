The authors propose a novel approach to factor analysis by utilizing posterior regularization, as introduced by Ganchev et al, to enforce non-negativity constraints on the posterior distribution. This methodology is supported by proofs of convergence and correctness, as well as a scalable inference and learning framework for stacked constrained factor analysis models.
The presented method seems theoretically sound and offers a unique perspective, deviating from the conventional literature and marking the first instance where posterior regularization has been applied in the context of deep learning and unsupervised feature learning. The supplementary material demonstrates a high degree of thoroughness, although a detailed review was not conducted.
However, the empirical evaluation falls short of expectations, given the standards of the community. This limitation makes it challenging to assess the contribution of the paper. 
A key question arises regarding the evaluation of these models, particularly in the single-layer case and potentially in the multi-layer case, in terms of test set likelihood. Typically, unsupervised methods are quantitatively evaluated on datasets like MNIST using test set likelihood. The paper presents synthetic data results for specific metrics designed to demonstrate the model's effectiveness in satisfying the design goals of RFNs, but these results are difficult to interpret. Furthermore, the classification baselines used appear outdated. For instance, Komer et al (2014) reported a test set error of 11.7% on CONVEX using a combination of polynomial SVM and PCA preprocessing, whereas unsupervised learning on CIFAR has seen significant advancements, albeit sometimes with architectures that heavily rely on domain-specific knowledge.
Certain statements in the paper require clarification, such as the claim that current unsupervised deep learning approaches like autoencoders or restricted Boltzmann machines (RBMs) do not model specific structures in the data. It seems that individual unit filters can indeed model specific structures, and the subsequent reference to generative models is unclear, given that RBMs and deep belief networks are, in fact, generative models. 
The authors' response to the success of representations that eschew sparsity, such as maxout networks (Goodfellow et al, 2013), would be insightful. Additional elaboration on the role of normalizing constraints in the exposition would also be beneficial. It is assumed that the "projected Newton method" refers to the Newton step projected onto the constraint surface in terms of the closest point obeying the constraint, but explicit clarification would be helpful.
Following the rebuttal, the argument against using likelihood is somewhat convincing, although it seems plausible that the lost ground caused by posterior regularization in a shallow model could be recovered in a deep model. It is suggested that the CIFAR results and the drug design applications be highlighted in the main text, potentially relegating the presented table to the supplementary material, as CIFAR10/100 serves as a point of contact for many in the deep learning community.
The score has been upgraded to a 7, reflecting the intriguing approach to factor analysis, which applies non-negativity constraints on the posterior to obtain sparse representations. Although the method appears sound, with detailed discussion of implementation details necessary for scaling, the quantitative empirical evaluation is somewhat lacking due to the use of dated and uncommon benchmarks.