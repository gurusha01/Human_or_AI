SUMMARY: Building on the foundational work in [6], the authors investigate the interplay between generalization and stability, deviating from conventional approaches by considering a broader learning context. The outcome is noteworthy, as it establishes necessary and sufficient conditions for uniform generalization, rather than merely providing bounds. However, a significant limitation lies in the "uniform" aspect, which may be overly restrictive, implying generalizability with respect to any parametric bounded loss.
DETAILED COMMENTS: The paper is engaging, well-structured, and clearly articulated. It complements the findings in [14] by deriving necessary and sufficient conditions for generalization, as opposed to learnability, within the general framework of learning. The machine learning community has historically been divided between those focused on learnability and those concerned with generalization, with this paper catering to the latter group. Although it may not address learnability, the topic remains relevant and intriguing for a subset of the NIPS community.
One of the primary concerns with this paper is the lack of in-depth analysis of the implications, as evident in Remarks 1-2 and Examples 2-3. The sole clear instance appears to be the case of finite VC dimension, and some remarks and comments seem to be mildly exaggerated. This scarcity of depth, combined with the unconventional definition of algorithmic stability, may limit the paper's accessibility and impact. The definition of uniform generalization (Def. 3) seems stringent and can only be justified if one accepts the authors' assertion that the equivalent algorithmic stability (Def. 5) is relatively weak, implying that most algorithms will satisfy it and thus generalize, even with respect to any bounded loss. However, this "weakness" is described in vague, intuitive terms rather than in a more formal, machine learning-friendly manner.
While this issue is problematic, it does not warrant rejection. The loss function in question is independent of the algorithm employed, and the algorithm itself is not required to be ERM or utilize it in any way. Consequently, there is no concrete basis for judging the condition of "uniform generalization" as overly restrictive, beyond intuition. In contrast, the condition of algorithmic stability appears weak and has a nice representation in certain cases, such as finite VC dimension.
Another concern, shared by other reviewers, is that the bounds are only provided in expectation. However, this is a minor issue, as many results based on algorithmic stability are also limited to expectation yet have still inspired novel algorithms and techniques.
If the paper is accepted, the authors should consider providing more detailed examples and quantifying algorithmic stability in other interesting cases to enhance the impact of their work. Overall, the result is correct, novel, and mature enough for publication in NIPS, presenting a necessary and sufficient condition for uniform generalization through a novel notion of algorithmic stability in the generic setting of learning. Although a more in-depth discussion of the implications is necessary, the paper is well-written and engaging, making it suitable for acceptance.