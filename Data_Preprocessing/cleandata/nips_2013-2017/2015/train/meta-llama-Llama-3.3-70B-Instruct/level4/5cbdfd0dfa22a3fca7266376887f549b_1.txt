This paper presents a modified version of Leurgans' algorithm for decomposing sparse and low-rank tensors, a task known for its complexity and high computational cost. The authors' approach is noteworthy, as efficient algorithms for tensor decomposition are essential, particularly for sparse and low-rank tensors. Using order 3 tensors as examples, the paper clearly outlines the algorithm and provides a theoretical discussion on its efficiency. Furthermore, the authors suggest in Section 4 that the algorithm can be extended to decompose higher-order tensors, which is a promising aspect of their work. The organization of the paper is commendable.
However, several questions and concerns arise upon reviewing the paper:
(1) The algorithm involves multiple eigenvalue decompositions of matrices and the solution of two convex matrix optimization problems, as stated in equation (6). These steps are computationally intensive, raising questions about the scalability of this method for large-scale tensor decompositions. The concept of sparsity in the paper needs clarification, and it would be beneficial to know the maximum size of tensors that this algorithm can efficiently decompose. The numerical examples provided in Section 2.2 are limited to a 50-dimensional order-3 tensor, which may not adequately demonstrate the algorithm's efficiency for larger tensors.
(2) On page 2, line 071, the definition of low-rank is given as r <= n1. However, in the numerical implementation section (Section 2.2) for a 505050 tensor, results are only provided for r = 1-4, which is a very narrow range. It would be informative to see the computational results for r = 40-49 to understand the algorithm's performance across a broader range of ranks. Does the algorithm's efficacy significantly diminish as r approaches n1, or does it remain robust?
(3) In Section 2.2, the method used to solve problem (6) in the implementation is not clearly explained. Providing details on this aspect would enhance the paper's clarity and reproducibility.
Additional suggestions for improvement include:
- Correcting the typo on line 093, where "the resulting nn matrix" should read "the resulting n1n2 matrix";
- Amending the typo on lines 96-98, where "\sumk" should be replaced with "\sumi";
- Fixing the typo on page 5, line 216, where "Xa" should be "Xa^3";
- Correcting the typo on page 4, line 198, where "coefficient" should be typeset appropriately.
In conclusion, while the paper proposes an interesting approach to tensor decomposition and is well-organized, the numerical implementation section falls short by only presenting results for a very specific and small case. Including more examples, especially for larger tensors and a wider range of ranks, would strengthen the paper and provide a more comprehensive understanding of the algorithm's capabilities and limitations.