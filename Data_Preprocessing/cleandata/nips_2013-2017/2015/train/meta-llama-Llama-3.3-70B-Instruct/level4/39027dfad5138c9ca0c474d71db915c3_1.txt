Given my current travel schedule, I had limited time to complete this supplementary review, which is regrettable as I found the paper to be engaging. As a result, I may have overlooked or misinterpreted certain aspects, for which I apologize if that is the case.
When examining data based on a given hypothesis, there's often interest in assessing a different hypothesis. For non-deterministic hypotheses, such as those involving conditional distributions, estimating the loss under investigation can be achieved by reweighting data points, as illustrated between equations (1) and (2).
The authors appear to tackle a problem related to, yet distinct from, the issue of high variance in weights, which they term "propensity overfitting." The provided examples suggest this problem arises from insufficient exploration, where for a given x, only a few or even no y corresponding to the new hypothesis are observed. Since a similar rationale underlies the high variance of weights, a more detailed explanation of the relationship between these two problems would be beneficial.
Although I lacked the time to delve into the specifics or assess the novelty of the proposed solution, the underlying concept seems reasonable.
- On line 199, I am unclear about the statement. If n is small compared to k, we would expect to see only a few data points where xi equals yi, correct? In that case, shouldn't \hat R(h^*) be even smaller than -2? I may be missing something.
- The statement regarding an "unbiased counterfactual risk estimator used in prior works on BLBF [4, 5, 1]" seems questionable to me. Without familiarity with all three papers, I suspect that methods like clipping, which introduce bias while reducing variance, might be employed.
- I appreciate the availability of the code.
In summary, while I couldn't verify the technical soundness of the paper due to time constraints, it undoubtedly presents intriguing ideas worthy of further consideration. Therefore, I recommend acceptance.