This paper explores tensor graphical models for estimating sparse precision matrices with a Kronecker product structure, demonstrating favorable properties of the alternating minimization algorithm. 
The research builds upon earlier studies, such as [5, 6, 7, 8], by focusing on tensor rather than matrix data, thus offering a notable extension.
However, the findings rely heavily on certain assumptions, including the irrepresentable condition, which is known to be quite restrictive, and equation (3.4), for which determining an accurate initial estimate, especially in high-dimensional settings, poses a challenge.
The discussion following Theorem 3.5 notes that minimax-optimal results for K=2 have been previously established in [5, 8], which contradicts the claim of this paper being the first to discover this phenomenon. A more balanced comparison with [8] should be provided in Remark 3.6.
Furthermore, the proposed initial values for the precision matrices, as well as those obtained after iteration, do not clearly satisfy equation (3.4), raising concerns about their validity.
The methodology presented, including the proposal in (2.3) and the iterative algorithm, is relatively standard, and the theoretical framework appears to follow established practices.
The paper is well-structured and clear in its presentation.
While the paper contributes to the literature by extending matrix graphical models to tensor graphical models, as seen in [9], its originality is somewhat limited, as the rate in [9] has been surpassed by [8]. This work can be viewed as refining the results in [9] using alternative techniques to those in [8].
The significance of the paper is incremental, as it attempts to address an intriguing problem but relies on potentially flawed assumptions. The algorithm's performance is reminiscent of [8], yet the challenge of finding suitable initial values that satisfy (3.4) in high-dimensional scenarios remains unresolved.