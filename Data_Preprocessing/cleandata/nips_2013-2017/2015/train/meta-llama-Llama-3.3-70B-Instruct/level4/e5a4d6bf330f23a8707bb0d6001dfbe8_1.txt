This paper presents a novel loss estimation approach for adversarial multi-armed bandit problems, enabling the circumvention of explicit exploration to achieve high-probability bounds. From a technical standpoint, this innovation yields enhanced constants and more streamlined proofs. Overall, the paper is well-written and merits publication. However, it is noteworthy that the author does not explore the potential applicability of this concept to the linear bandit scenario, an area that has seen significant research efforts focused on developing effective exploration distributions. The observation made in this work is a valuable one that has gone unnoticed by others in the bandit research community.