This paper explores the estimation of high-dimensional sparse and group sparse models using l1 and l1-l2 regularized least squares, deviating from the conventional Gaussian measurements and noise setup by considering isotropic sub-exponential measurements and independent, identically distributed subexponential noise. The key finding is that the bounds on error and sample complexity remain largely unchanged from the traditional setting, with the addition of a logarithmic factor. These results are derived using sophisticated techniques from empirical processes, where the logarithmic factor arises from transitioning from Gaussian width to exponential width, effectively extending prior works by Negahban et al, Rudelson & Zhou, and others.
The technical quality of the paper is consistently strong, with clear writing and organization. However, the originality and significance, while substantial for domain experts due to its focused contribution, may be perceived as minor by a broader audience. The novelty of the techniques, given the context of related research on compressed sensing with heavier-tailed measurements, is also somewhat ambiguous.
Several points warrant further consideration: the limitation to isotropic measurements, whereas non-isotropic sub-Gaussian cases have been successfully addressed, suggests a potential direction for future extension. Reference to foundational works like Vershynin's tutorial, which extensively covers Gaussian-width based analysis, could enhance the paper's contextualization. Furthermore, the experimental section is notable for its lack of comparison between sub-Gaussian and sub-exponential measurements, which would be crucial in evaluating the sharpness of the main results. Overall, the paper offers valuable insights for those interested in the theoretical aspects of compressed sensing and high-dimensional statistics.