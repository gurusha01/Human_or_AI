The paper "Interactive control of diverse complex characters with neural networks" demonstrates the effectiveness of a compact and efficient neural network in representing a control policy for interactive character control in a physics simulator. 
This approach leverages trajectory optimization during the training phase to learn a neural network policy, with a key contribution being its versatility across various cyclic behaviors and body types.
General Comments ----------------
Upon reviewing this paper, it appears to be an application of deep learning techniques to existing methods in computer graphics, building upon recent advancements in the field. 
The capability of trajectory optimization to generate realistic control signals has been previously established, as acknowledged by the authors through citations of relevant prior work. 
Moreover, the use of neural networks to approximate step-by-step policy actions for tracing trajectories similar to those found by trajectory optimization has been explored in earlier research, such as [9]. 
Therefore, the authors should provide a clearer positioning of their work in relation to these preceding approaches. 
A notable comparison can be drawn with the recent work by Pieter Abbeel and Sergey Levine. It would be beneficial for the authors to elaborate on how their approach differs, whether in terms of learning speed, support for diverse body shapes, computational efficiency at runtime, or robustness to environmental variations.
Specific Comments -----------------
The statement "we found the resulting process can produce very large and ill-conditioned feedback gains" requires clarification. 
Consider reordering the discussion to present the strategy before explaining why LQG was not utilized. 
The notation between lines 226-240 is perplexing, introducing s(X) = \bar s and then defining a cost based on s(X) - \bar s, where the visual similarity between bars and squiggles may cause confusion. 
The claim "our approach produces softer feedback gains according to parameter \lambda" needs further explanation, specifically in comparison to alternative methods and the implications of having softer gains. 
Additionally, the rationale behind altering the initial state as part of the procedure should be provided. 
While the work is sound, the contribution's significance in relation to other recent and related research remains unclear.