This paper presents a pixelwise classification system using recurrent convolutional connections.
The method employs a multiscale convolutional network similar to Farabet et al., but introduces shared weights and additive skip-connections between layers in the networks applied at each scale.
The model is evaluated on Stanford Background and SIFT Flow datasets.
This approach appears to achieve good performance for being trained from scratch, but I think the several aspects could be better explored and evaluated.
* First, the effect of sharing weights between recurrent connections could be compared to the same network with different convolution kernels in each iteration; while this introduces more parameters, it might also stand to increase performance for about the same computational cost (i.e., same number of connections).
This was almost performed, but the CNN2 model has fewer total layers and a smaller RF.
It is also possible the findings for varying gamma (enabling/disabling skip connections) might change under these conditions.
* Second, the effects of N and T could be further expanded upon.
From what I can tell, all the RCNN networks use T=3, except RCNN-large, which uses T=4.
But RCNN-large is evaluated only for N=3.
How does it perform at N=4 and N=5?
* In addition, Table 2 RCNN has a reported performance of 83.5/35.8 PA/CA.
But in Table 1, RCNN-large has what looks like better performance at 83.4/38.9 PA/CA (last line).
Is there a reason the latter wasn't used in Table 2?
* The related work section states that [4] and similar networks rely on postprocessing, e.g. superpixels, to ensure consistency of neighboring pixels labels.
This seems to imply the proposed model does not suffer from this problem, but this is not evaluated in the experiments or with qualitative examples.
No example predictions are shown, so it isn't really clear what the outputs look like qualitatively.
* There are also some other recent works in this area that I think could be discussed or compared with, particularly Chen et al. "Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs", and Eigen & Fergus "Predicting Depth, Surface Normals and Semantic Labels with a Common Multi-Scale Convolutional Architecture" This approach appears to achieve good performance for being trained from scratch, however I think some aspects could be better explored and evaluated.