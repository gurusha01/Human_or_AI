- A question to clarify in the rebuttal: from Section 4.1 in [1], it is said that the CRM approach only makes sense for delta in [-1,0] (and thus they propose to rescale a general loss to [-1,0]). My guess is that it should be the same for NORM-POEM here -- i.e. (8) and (3) both uses the re-scale delta in [-1,0], correct? In this case, I do not understand what it means to use "delta > 0" in the experiment in Table 1. Please clarify.
== Other comments ==
- There is something I find missing in the setup for "batch learning from logged bandit feedback" of Section 3 (or from [1]): I feel the feedback should also be seen as a random variable, rather than a deterministic function as presented on line 110. Here is my rationale. Suppose that the partial feedback is coming from a classification problem where we just do not know the labels, we only get feedback by trying a prediction and seeing what is the loss. Suppose that there is a true classification loss Delta(y',y), and that the way the feedback is generated is, for a given input x, we make a prediction y using h_0; some god agent labels also the input to y'; and then tells us the loss Delta(y',y) that we incur (so here delta(x,y) is Delta(y',y) for the y' given to this example). On the other hand, often in classification, we suppose that the labeling can be noisy and so there is not necessarily a unique y' assigned to each x. This means that somewhere else in the log, we could have the same x as input, the same y that we played, but with a different delta(x,y) as the god agent just had given a different label for this one... This is why I think that in general delta(x,y) should be seen as a random number (in the classification example above the mean of this random variable for a fix x & played y should be the expectation of Delta(y',y) for y' distributed according to p(y'|x), the true noisy labeling distribution).
This perhaps does not change anything about the risk estimator (2); but at least the setup in (1) with the true risk should be presented with an additional expectation over the randomness of delta, to be more general.
- Line 170-171: I think it should be h(y|x) / h_0(y|x). Also, it might be worthwhile to mention that the lack of linearity was already pointed out in [1].
- Line 276: you should probably put argmin instead of argmax given that you are minimizing the risk...
- Line 319: replace bars with hats in the notation to be consistent with the previous convention.
 === Update after rebuttal ==
Thanks for the clarifications. [light reviewer]quality:6(out of 10) clarity: 6 originality: 8 significance: 8I think this is an interesting follow-up work on [1]. I find their analysis of the "propensity overfitting" interesting; and like the idea of using a multiplicative control variate to reduce it. The results show a clear improvement over POEM, on a problem (batch learning from logged bandit feedback) for which there is more and more interest.