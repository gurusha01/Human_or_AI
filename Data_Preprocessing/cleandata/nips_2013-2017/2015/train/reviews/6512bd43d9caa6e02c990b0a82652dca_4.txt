Abstract
The authors define uniform generalization in the sense that |\hat Remp(L(hD)) - \hat R(L(h_D))| -> 0
for all distributions P^n generating the data D in an i.i.d fashion and all loss functions L, where: - hD is the hypothesis of the algorithm for the data D - \hat Remp is the expected (w.r.t D~P^n) empirical risk
 with respect to the loss L, and \hat R is the expected
 true risk
(I hope I got this right, since their notation is not really
clear at this point). The definition of algorithmic stability is even more cryptic, please see Definition 5. In any case, the main Theorem 1 shows that both notions are
equivalent. Theorem 3 then shows that finite VC dimension implies their notion of algorithmic stability and some
addiitonal results are provided.
 Comments
As my attempt to summarize the paper already indicates
I had a somewhat hard time reading the paper, in particular since somewhat strange notations are used. This complicated appearance is in contrast to the rather simple ideas, see e.g. the proof of Theorem 1. In any case, my major concerns regarding the paper is that
the notions of genralization and stability are not really the ones we are usually interested in. For example, let us look at uniform generalization: If I want to understand an algorithm for least squares regression, I usually do not care
whether this algorithm also works for, say classification.
But this is exactly assumed in uniform generalization. In addition, I do not understand, why expected risks are
considered. Generalization is usually considered in a
"with high probability" setting and expectations are usually only taken to significantly simply considerations.
In the case of algorithmic stability, which should better be called uniform algorithmic stability since an infimum is taken over all distributions, I could not really get an intuition
about its meaning at all, and the few examples, the authors
provide are not helpful in this regard either (exception: Theorem 3, which is helpful).
 Minor comments: - The way expectations are denoted makes it hard to understand
 what is meant. There are better ways to denote such things
 without extra effor. - The "Markov chain notation" is also rather confusing. Again,
 there is no need to use this kind of notation.  The paper compares a certain notion of algorithmic stability witha certain form of uniform generalization. The main result shows that both notions are equivalent. In addition, a fewrather concrete cases are worked out in detail.