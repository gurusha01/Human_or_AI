This paper proposes to combine trajectory optimization with policy learning to enable interactive control of complex characters. The main proposal is to jointly learn the trajectories and the policy, with the additional empirical insight that decoupling the two optimization problems into alternating subproblems i) enables reusing of existing, well documented methods and ii) works sufficiently well in practice. Although I could follow the paper well, I'm not immersed in this domain well enough to comment on the potential impact of this paper, which on the surface certaintly looks like a technical prowess albeit with no novel theoretical insights.
 The authors combine an impressive level of technical sophistication at all levels - from the concepts down to their implementation - with equally impressive results. I found the claimed advantages of i) using sensory noise during training and ii) learning trajectories jointly with the policy, to have been clearly demonstrated.
 I also found the paper was clearly written, with what I think is the appropriate level of detail given the complexity of the problem and its implementation. Each section treats a separate aspect of the problem and there are very useful cross-references between sections.
In think the motivations for the extra optimization setp in sec 7 could have been better explained. At this stage, given what had been announced in previous sections, I was somehow expecting the policy to run without the need of any extra optimization.
Is that because there is always a residual trajectory cost (or policy regression error?) such that feeding the action given by the policy into the physical simulator would accumulate errors? I would imagine that the forward evolution of the dynamics takes into account physical constraints so that no physical implausibility can result anyway, but I might be missing something? I appreciate, though, that re-optimizing at every timestep lets you use larger timestep.
l153: similar to recent approaches... can you perhaps give one or two refs? It's counterintuitive to me that keeping updates small in parameter space would be a sensible thing to do in general, though in the end I understood that it's useful in a scenario like yours where you're block-alternating between subproblems.
typo: l89: to unify  The paper's results look rather impressive, and the proposed optimization scheme + implementation sensible to me. However this research area is slightly off my radar so it's difficult for me to be confident about novelty and significance.