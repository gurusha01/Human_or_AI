In this paper, the authors design a recurrent convolutional encoder-decoder network that can render an object from different pivoting viewpoints given a single 2D image of the object. The authors evaluate the performance of their proposed model via its ability to generate images of faces and chairs from rotated viewpoints. They also perform additional experiments to examine the benefits of curriculum learning, to evaluate the model's performance of disentangled representations through cross-view object recognition, and to explore the model's ability to perform class interpolation with chairs.
 Although the proposed model is well presented and detailed, the evaluation of its performance is rather inadequate. The experiments used to demonstrate the effectiveness of the proposed RNN model are largely qualitative (figures with visualizations of results should be scaled to an appropriate size for the reader to see). Introducing a quantitative measure of performance with an appropriate error metric (to compare with state-of-the-art results) should prove to be more insightful than qualitative assessments alone.
 In general, the paper is well written and easy to follow. There are a few minor grammatical errors (i.e. line 124 "rotate" -> "rotated").
The significance of this paper is predominantly impaired by its lack of ample experimentation and analysis. It would be relevant to include experiments with more datasets other than Multi-PIE and Chairs. Demonstrating the model's ability to render rotated viewpoints for different types of objects would make the network architecture seem less ad hoc. Additionally, it would also be interesting to see how the proposed model could generalize to handle object rotation trajectories that deviate from a static axis (non-repeating rotations). The paper develops a deep learning model for the task of rendering an object from different rotational viewpoints given a single 2D image of that object. Although the approach is novel and interesting, the paper lacks sufficient experimentation and relevant analysis to flesh out the model's significance and potential for results that are comparable to state-of-the-art 'geometry-based approaches' (line 51).