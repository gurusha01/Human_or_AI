TL;DR This paper describes a training heuristic, scheduled sampling (SS), for RNNs in which gold truth labels are sometimes replaced with sampled predictions from the model. Different schedules for deciding when to replace the gold labels are suggested, which all amount to different kinds of decay functions (linear, exponential, inverse sigmoid). Improvements over a comparable RNN model without SS are presented for the following tasks: image captioning, constituency parsing, and speech recognition.
This is a neat experimental result! While noise injection is an old idea, the focus on improving robustness at test time is interesting. But I worry that this paper raises more questions than it answers. Here are some specific concerns:
- If SS is working as a regularizer, it's good to know that it appears to be additive to dropout. However, it would also have been good to include the following baseline: what about always randomly sampling a label (according to the proposed schedules) rather than using model predictions?
- If the idea is to mitigate search error, I would have liked to see a comparison to baselines which use different beam widths. Is there still a benefit from SS if the model uses a larger beam width?
 - I'm a little worried about the hyper-parameter k. Setting it based on "expected speed of convergence" is a little nebulous, as there's no discussion of how sensitive it is, or how it was tuned in the experiments.
Aside from these specific concerns, at a high level I think this paper would benefit from a more rigorous probabilistic analysis. It would be great if the paper shed some light on why the proposed heuristic appears to work, e.g. by teasing apart the regularization effect. I would have liked to see some experiments showing the benefit of SS as the amount of supervision is varied.
UPDATE AFTER AUTHOR RESPONSE:
Thanks for addressing some of my concerns. However, I still worry a little bit about how difficult it is in practice to tune the sampling schedule, and wish there a little more analysis of the method. This paper describes a neat training heuristic for RNNs that improves robustness of predictions at test time. While the reported experiments are encouraging, it's not clear why the proposed method works and there's a severe lack of analysis (both experimental and theoretical).