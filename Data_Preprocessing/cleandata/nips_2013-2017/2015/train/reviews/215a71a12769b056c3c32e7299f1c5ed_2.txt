This paper proposes an architecture for very deep networks which enables input to be "carried" unchanged through a layer using gates dependent on the input itself.
This enables much deeper networks to be trained than would be possible with a standard feed forward architecture.
The authors perform a very interesting analysis of the trained networks to determine the manner in which the gates select their inputs in in different layers of the network, which is exactly what I would have wanted to see.
The paper is of high quality, clearly written, and original.
Though there is naturally some similarity to other recent work (notably FitNets, and LSTMs), the differences are clearly explained and where appropriate, they are compared.
Promising results are achieved.
I have no suggested improvements.
Note "Tables 3 and 3" (p5).
  This is a very solid paper.The proposed technique is novel and achieves good results.The analysis is interesting and thorough.