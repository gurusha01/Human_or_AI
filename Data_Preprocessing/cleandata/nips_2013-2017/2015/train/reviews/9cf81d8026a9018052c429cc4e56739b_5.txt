This paper presents a method for scene labelling based on Recurrent Convolutional Neural Networks, where the output of a convolutional layer is used as an additional input of the same layer (this is implemented by duplicating the layer several times). The input to the network is the input image plus several downscaled versions of of the input image to exploit contextual information better.
The approach is tested evaluated on two datasets, and compared to previous methods. The accuracy improvement is good, and the computation time impressive as the algorithm can run entirely on the GPU.
I found the paper interesting as it discusses very trendy issues but I have two main concerns: - the text is difficult to follow. For example, the use of the passive form in the first sentence of the last paragraph of the introduction makes it ambiguous. It took me some time to understand (or guess) that the authors meant "we adopt a multi-scale version of RCNN". - while the results are interesting, the contribution is limited, as it is only an application of RCNN (which were already applied to computer vision problems before) to image labeling.
More minor comments: - Section 3: state explicitly that RCL stands for recurrent convolutional layer. Same problem with LRN - just before Eq (3): it should be g(Zijkz), not sigma(zijk) - is it really worth discussing gamma?
The results with gamma = 0 are not as good as with gamma = 1, which is the "standard" way. This should not be surprising, because if a small gamma was interesting, the network could learn to use large values for w_k^rec  This paper presents a method for scene labelling based on Recurrent Convolutional Neural Networks. Results are interesting, but the text is difficult to follow and the contribution seems limited.