I have one concern with the fact that in the proof of Theorem
 2, lambda and L are set to depend on d. What are the
 implications of this choice? Is it a realistic choice?
 For a potentially useful additional citation, the following
 paper considers the same loss as the one you have in (4), and
 gives an efficient algorithm to globally solve it:
 "Scalable Metric Learning for Co-embedding", Mirzazadeh et
 al., 2015, ECML This paper is clearly written and provides noveltheoretical insights into the sample complexity of metriclearning and improvements from added regularization. Inaddition to carefully exploring the topic for both general andspecific cases theoretically, the empirical results aresimilarly methodical but compact and further reinforcethese properties on real datasets.