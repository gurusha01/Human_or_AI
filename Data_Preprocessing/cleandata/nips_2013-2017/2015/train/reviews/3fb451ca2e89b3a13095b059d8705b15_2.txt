This paper presents a method similar to Least Trimmed Squares for robust linear regression, except for graphical lasso.
The main idea is to improve upon the original graphical lasso such that it is more robust to outliers.
 The most significant contribution of this paper is the theoretical analysis showing that despite being a non-convex method, where the objective is biconvex, consistency results are given for any local minimum.
In C-4, was tao1 and tao2 ever defined?
 The weakness of the this paper is in the experimental results.
It would be great if the sensitivity vs. 1-specificity figures were included in the supplemental material with the x and y axes both going from 0 to 1.
As it's currently plotted, it's difficult to assess how much better the trimmed graphical lasso is performing. From examining the plots as is, my guess is that it does not make that much difference.
Also, for the trimmed graphical lasso,
the 100h/n ratio's considered were 80,85, and 90, which means there are very few outliers.
A stronger result would be if you could show that as the outliers increase, then trimmed graphical lasso's performance begins to differentiate itself from the other methods, especially the classical graphical lasso.  This paper presents Trimmed Graphical Lasso, which is a method that induces the trimming of particular samples that are less reliable, such that the method is more robust to outliers.The main contribution is providing statistical guarantees on the consistency of the estimator.The experimental results show that the method is competitive with existing methods, but do not demonstrate clear superiority.