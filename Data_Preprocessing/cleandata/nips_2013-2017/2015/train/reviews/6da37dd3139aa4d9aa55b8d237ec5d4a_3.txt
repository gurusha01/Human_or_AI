The problem of 3D object proposal is much
less well studied than 2D object proposal, and this paper has done a good job on developing effective approach for this task which fundamentally
differ from the popular 2D approach (grouping superpixels, e.g. Selective Search.)
 For evaluation, the paper did a good job on comparing with the state of the art approaches. But one missing component would be that although the paper is doing 3D object proposal there is no evaluation done in in 3D (all the detection are evaluate with 2D boxes).
 Although the paper focuses on exploiting contextual models specific to autonomous driving, it will be very interesting to see whether this approach can be generalized to other domains (e.g. indoor RGB-D scan). The task is fundamentally similar and the information that the paper makes use of such as object size priors, ground plane, free space, point cloud densities and distance to the ground will still be very useful in general RGB-D indoor scene. The challenges might be the indoor scene will be more clutter and more object categories. It will also make the compare with MCG-D [14] more fair, because it is designed for
indoor RGB-D scan, and haven't apply such strong
domain specific contextual model. Therefore, applying the proposed approach to RGB-D indoor scene will definitely make the paper much stronger.  The paper develop a novel and effective approach for 3D object proposal which fundamentallydiffer from the popular 2D approach e.g. Selective Search. I suggest the paper to include 3D evaluation into the paper, and also show the generalization ability of the approach by applying it into indoor RGB-D scan.