Hidden variables in Bayesian networks and in chain graphs add extra complexity to parameter learning and to inference. Mixed graphical models introduce bi-directed edges that can eliminate the hidden variables while preserving the conditional independencies induced by the DAG or chain graph representations. However, after applying latent projection operation to eliminate the hidden variable in the resulting mixed graphs, bi-directional and undirected edges can meet, which leads to issues when trying to factorize the model.
As a solution segregated graphs are proposed, which preserve the conditional independencies between the non-latent random variables in the original DAG or chain graph, and at the same time they avoid having nodes where undirected and bi-directed edges meet.
Clarity: The introduction uses notations that are only introduced in the background section, which makes the reading of the paper more difficult.
 Significance: It is hard to judge the paper's significance without having a real world practical example and its evaluation at hand.
Typo: line 099 "...B1,Y1..." -> "B1,Y2"  Segregated graphs are proposed, which can preserve conditional independencies between non-latent random variables in a Bayesian network or chain graph, while eliminating latent variables without introducing nodes where undirected and bi-directed edges meet. This can have a significant impact, however, this is not demonstrated through a practical example and with experimental evaluation.