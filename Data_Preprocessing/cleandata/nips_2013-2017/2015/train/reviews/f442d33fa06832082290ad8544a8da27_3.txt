I think the idea of extending distributional methods from words to sentences is great.
The experiments look carefully done and they compare on a large variety of different problems.
 This paper introduces an unsupervised way to train sentence vector representations. The idea is to take GRU to encode a sentence and then predict words of surrounding sentences.I like this paper a lot. I would strongly encourage to change it to skip-sentence vector though, sentence /= thought ;)