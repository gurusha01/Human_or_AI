The authors analyze the risk averse Markov decision process setting with static and dynamically consistent risk measures (mappings). The main contribution is, in particular, to show to form of the gradient for both the dynamic and static setting.
The paper is a generalization of previous results, which focused specifically on CVaR. This extension represents a minor, but useful, contribution. The results is a simple extension of the policy gradient in risk-neutral settings.
The paper is well organized, well written, and easy to follow.
The results are correct as far as I can tell.
Minor comments:
- Theorem 2.1: The notation \xi P_\theta is confusing. I suggest referring to Theorem 6.6 in [26] and using the same notation.
- Line
141: risk enevlop[e] - Section 3: To avoid confusing readers not familiar with the topic, it may be worth pointing out here that
MDPs with Markov risk measures are very tractable. The reason the problem in the paper is not tractable is because of the policy parametrization and NOT because of the risk measure.  The paper presents a minor but solid and important extension of existing results.