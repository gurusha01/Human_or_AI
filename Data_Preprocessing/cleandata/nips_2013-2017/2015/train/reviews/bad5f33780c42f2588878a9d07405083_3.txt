The paper introduces and studies an information-theoretic quantity, approximate max-information, which is used to quantify generalization properties of adaptive data analyses. The output of a data analysis algorithm with low approximate max-information can be regarded as "almost" independent of the data itself, in a particular sense that is useful for reasoning about subsequent analyses of the data that may depend on the algorithm's output. Differentially private algorithms have low approximate max-information, as do algorithms with a small cardinality range, and compositions of algorithms with low approximate max-information also have relatively low approximate max-information. A few applications are given: generalization of differentially private algorithms (Corollaries 19 and 20), a procedure for managing holdout set reuse in machine learning (Thresholdout), and a procedure for multiple hypothesis testing (or activities like that) on the same data (SparseValidate).
I think the paper should be accepted, as the paper gives an interesting perspective on generalization. Although it is similar to algorithmic stability concepts, I think approximate max-information captures a nice property that seems to be more useful and versatile than previous stability concepts (largely because of the composition property). All the applications are very interesting as well.
The paper fails to compare to some earlier work on generalization from learning theory. For instance, both Freund's work on self-bounding learning algorithms and Blum and Langford's work on micro-choice bounds seem particularly relevant. I also had some difficulty seeing the difference between the description length results and previous Occam/MDL-type bounds (again, see work by Blum and Langford).
I think the authors should discuss the interplay between tau and n in Thresholdout. Often, we hope to at least have tau = O(1/\sqrt{n}); this would imply budgets of constant size or smaller.
The results, of course, are still interesting in this case due to the allowance of adaptivity, and the "free" evaluation of "good" functions.
But I think pointing out this quantitative aspect is important for putting the results in perspective.
Some other comments are below: - Page 6, line 289: "k = I\infty^\beta(S; A(S)) = k" - Page 6, line 318,320: probability statements seem to be inverted. - Page 7, line 338: define $\mathcal E{S_h}[\phi]$ - Page 7, line 341: do you mean "true expectation $\mathcal P[\phi]$"?
Yet even more comments: - Another reviewer points out some issue with the statement of Theorem 9. Did you mean something like "For all i and t, Pr{ ai \neq \bot AND |ai - P[\phii]| > T + (t+1)\tau } \leq ..."? This would be good to clear up. - It would also be good to be more explicit about various qualitative claims (e.g., queries can be exponential in n). The user may not know when the budget will be exhausted, but may want simultaneous validity of all the non-\bot queries. So it seems that you will want to apply Theorem 9 with a union bound over the m queries. (Perhaps something more clever than a straight-up union bound could be done.) - Also, why does it matter that St (training set) be an iid sample?
---
Post-rebuttal remarks:
One major point of confusion in the text is Line 119-120. It sounds like we can have m = 2^{cn} and B = cn^2 simultaneously for some positive, but this clearly leads to trivial results in Theorem 9. Perhaps it's fine to use the terms "quadratic" and "exponential" a bit loosely, but I think it should be stated precisely and explicitly at least somewhere in the paper. I think the paper should be accepted, as the paper gives an interesting perspective on generalization. Although it is similar to algorithmic stability concepts, I think approximate max-information captures a nice property that seems to be more useful and versatile than previous stability concepts (largely because of the composition property), and all the applications are very interesting.