The authors propose a novel framework for computing a lower bound of the CV errors as a function of the regularization parameter. The main motivating question of the manuscript ("it is hard to tell how many grid-points would be needed in cross-validation") has been already extensively studied both from theoretical and empirical perspective. For example, see (Rifkin et al, MIT-CSAIL-TR-2007-025) or (Rasmussen and Williams, Gaussian Processes for Machine Learning, Chapter 5.)
 The proposed score and validation error bounds are technically sound. These results are direct application of the ideas from safe screening (bounding Lagrangian multipliers at the optimal solution). While this was clearly stated in the supplemental material a similar remark in the main body (e.g. section 3) of the manuscript could be helpful for the reader.
 The experimental setup to evaluate a theoretical approximation of the regularization parameter is not clearly presented. How exactly the grid search is performed: 10 fold cross-validation on the training set to obtain optimal parameters with final evaluation on the validation set? In that case, I assume that E_{v} on the training set should have been reported in Fig(3) instead of validation.
 The proposed score and validation error bounds are technically sound. Novelty is incremental and experimental setup/result is dissapointing.