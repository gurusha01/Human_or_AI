"Interactive control of diverse complex characters with neural networks" shows
 how a small, fast neural network can be used to represent a control policy for interactive control of a character in a physics simulator.
The approach uses trajectory optimization in a training phase to learn a neural network policy. The contribution is to show that the same architecture works across a range of more-or-less cyclic behaviours, and a range of body types.
 General Comments ----------------
 My reading of this paper is that it is an application of deep learning to existing (albeit recent) techniques in computer graphics.
 The ability of trajectory optimization to find realistic control signals has
been established by previous work, some of which is cited here.
 The use of neural networks to approximate the step-by-step actions required of a policy in order to trace out trajectories similar to the ones found by trajectory optimization has also been developed in previous work (such as e.g. [9]).
 The authors of this paper must therefore work harder to position the work that went into this paper relative to these previously-published approaches.
The
closest work to my mind is the recent line of work by Pieter Abbeel and Sergey Levine. How would the authors compare the approach here to that one? Is it meant to learn faster? To support a wider variety of body shapes? Is it meant to require less computation at runtime? To be more robust to certain environmental variabilities?
 Specific Comments -----------------
 What is meant by "we found the resulting process can produce very large and ill-conditioned feedback gains"?
 Consider moving the discussion of why you did not use LQG until after you have presented your strategy.
 The notation around lines 226-240 is confusing. You introduce s(X) = \bar s, and then define a cost in terms of s(X) - \bar s. The bars and squiggles are visually similar.
 What is meant by "our approach produces softer feedback gains according to parameter \lambda"? Softer than what? What does it mean for gains to be either soft or not soft? Why is it a good thing to change the initial state as part of your procedure? Sound work, but the contribution relative to other recent related work is not clear enough.