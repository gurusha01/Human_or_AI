The authors describe a scenario called "on the job learning", where requests are made to annotators in between receiving an example and outputting a prediction.
 Whilst it is clear how the algorithm works for a structured prediction task,
where elements of the sequence are queried, it's not clear at all how this was applied to the face recognition task - was it simply the instance being queried? In the non-structured setting the model wouldn't propagate information between adjacent positions (examples), so it seems like the utility function wouldn't make sense.
The threshold baseline has two parameters that are seemingly arbitrary. Where did these values come from and what is the sensitivity to these?
 A further baseline of uncertainty sampling, akin to that used in active learning, would be interesting.
 Finally, the authors are keen to make the distinction between this setting and active online learning, but active learning could be adapted quite simply to work in this domain, where the active set under consideration is now a sequence. For example, there's no reason why the model couldn't be updated in the same fashion on receiving responses, and then output a prediction at the end. Whilst this clearly wouldn't capture the temporal nature of the task, there is much theory to draw upon for choosing the query set. A seemingly novel framework, although some details are not clear, and it seems to be fairly restricted in applicability.