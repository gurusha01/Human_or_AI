The paper presents several EM-style algorithms for learning Continuous-Time Hidden Markov Models (CT-HMMs) and illustrates them on two disease evolution prediction tasks (Glaucoma and Alzheimer's). The paper motivation is nicely laid out and this framework is indeed more realistic than the usual discrete-time HMM in practical applications such as medicine and customer interaction. The framework of CT-HMM is clearly explained and the derivations of the algorithms appear to be correct. From a theoretical point of view, the approach is straightforward but the technical details for getting the algorithms are not trivial, so this makes a nice theoretical contribution. In terms of the empirical evaluation, it is nice that the authors work with real data sets, and this strengthens the paper. However, on the Glaucoma dataset, the comparison methods are very weak (linear and Bayesian linear regression). The more interesting comparison would be against a discrete-time HMM (one which ignores the elapsed time between visits). This comparison should be added to the paper.
The Alzheimer;'s results are more qualitative but it is nice to have a second task. Sec. 5 needs to be revised from the point of view of the writing, as it has a lot more unclear sentences and grammar errors than the rest of the paper. As a side note, using only exponential distributions for the transitions times, while standard in CTMCs, is not always best in practical terms - mixtures may be needed. This might be interesting for future work. The authors derive EM-style algorithms for learning Continuous-Time Hidden Markov Models (in which state transitions may occur between observations). The paper makes a nice theoretical contribution. The empirical evaluation could be improved, but the use of real data makes the work worthy of publication.