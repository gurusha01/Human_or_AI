Paper proposes a recurrent CNN architecture for multi-frame super resolution. It employs three kinds of convolutional filters: (i) Feed-forward; (ii) Recurrent; (iii) conditional convolutions. Overall the architecture is novel but seems straightforward combination of existing deep learning modules.
 Technical quality of paper is borderline. It is a straightforward combination of existing deep learning modules. However, at the same time novelty lies in the fact that it has not been done before for multi-frame SR.
 In the rebuttal authors should address the following questions: (i) How many parameters does the model have? (ii) Did they compare with pre-trained SR-CNN or whether they re-trained SR-CNN on the new data set? (iii) It is not clear why SR-CNN run-time slower than BRCN? (iv) In Fig 3 & 5 how does the images for SR-CNN looks like?
 Originality of the paper is incremental. In table 2 authors show how individual parts of the architecture contribute. Though simply BRCN {v,r} outperforms the existing methods. It is well acceptable by now that making architecture more complex and increasing the number of parameters helps improve the accuracy. This is evident from table 2 that BRCN {v,t} {v,r,t} & {v,r,t,b} gives incremental improvement in performance.
 Significance of the paper for NIPS audience is open for discussion. The architecture introduced in the paper is novel but it is incremental to the field of deep learning. Paper proposes a novel architecture for multi-frame SR. It is easy to follow and builds upon previous work on single-frame CNN for SR [6]. In experiments some details are missing which can be fixed. Overall the paper is incremental but thorough. Its suitability to NIPS audience is open for discussion.