This paper presents a variational inference approach to learn Recurrent Neural Networks (RNNs) that have stochastic transitions between hidden states. The model is a stochastic nonlinear dynamical system similar to a nonlinear state-space model where the noise between hidden states (i.e. the process noise) is not identically distributed but depends on the hidden state. The parameters of the generative model are learnt simultaneously with a recognition model via maximization of the evidence lower bound.
This is a solid paper which bridges the gap between RNNs and nonlinear state-space models. The presentation is clear with an emphasis on presenting the general ideas rather than the technical details. The model itself is simple to describe and the variational training procedure is now standard. There is probably an important engineering effort to achieve the reported results which is not obvious when reading the paper. Also there is no mention of computing machinery or training times.
The notation with subindices "< t" sometimes hides the Markovian structure of the model which can be useful when interpreting the factorizations of joint distributions.
The literature review does not seem to mention nonlinear state-space models (i.e. nonlinear versions of linear state-space models aka "Kalman filters"). Those models are popular in engineering, robotics, neuroscience and many other fields. The model presented in this paper could have an impact on fields beyond machine learning. It could be useful to be more explicit in the connection with nonlinear state-space models.
 A few questions:
If VRNN-Gauss was not able to generate well-formed handwritting, are all the plots labelled VRNN actually VRNN-GMM?
Is there any regularization applied to the model? If not, how was overfitting prevented?
Equation (1) gives ht as a function of xt while Equation (2) gives a distribution over xt as a function of ht. Is this intended? This is a solid paper which bridges the gap between RNNs and nonlinear state-space models. The experiments are convincing and the presentation is clear and well polished.