The author begins by proposing a strategy to embed feedback gains in neural network policies that makes them robust to disturbances and regression error. Trajectory optimization and policy optimization are softly coupled by a cost penalty for deviation, allowing the policy to learn reasonable approximations of optimal trajectories that are in fact simpler and more robust than the products of MPC-based trajectory optimization on their own. The tasks are optimized using sophisticated parallelization, though this is not the central purpose of the paper and more of a means to an end. Finally, a diverse set of robots are controlled using the trained feedback controllers.
This paper is of the highest quality, is incredibly clear, represents a tour de force of technique, and presents quite beautiful results in its applications. Bravo. This is a beautiful body of work that marries graphics, control, neural networks in the pursuit of generation of controllers for a diversity of body morphologies and tasks. It's inspiring.