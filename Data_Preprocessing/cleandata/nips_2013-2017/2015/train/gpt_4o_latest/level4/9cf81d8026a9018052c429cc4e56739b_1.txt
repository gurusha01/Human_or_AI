This paper introduces a recurrent convolutional neural network (RCNN) for semantic image segmentation, designed to encode and leverage contextual relationships. The proposed approach essentially combines ideas from [13], which employs a similar RCNN for object recognition, and [4], which inspires the multi-scale pipeline. Consequently, the technical novelty of the paper is somewhat limited (e.g., Sec. 3.1 closely mirrors prior works and could benefit from a clearer acknowledgment of this; however, the integration of these techniques can be regarded as a novel contribution). Despite this, the paper is well-executed, highly readable, and generally well-written. It provides a seemingly fair evaluation against state-of-the-art methods. Some additional recent works or evaluations could strengthen the paper, as noted below. The results are demonstrated on the Sift Flow and Stanford Background datasets, where the proposed method outperforms state-of-the-art techniques, even with the limited training data available for these datasets. Furthermore, parameter ablation studies are conducted to some extent. The method is also highly efficient.
Detailed Comments:
- The related work section could be more concise and precise. The distinctions between the proposed method and closely related works are not always entirely clear.
- Results on the PASCAL VOC dataset could be included, as it is a common benchmark for recent segmentation studies.
- Line 276 is vague and should be clarified for better understanding.
- Table 1: Why are only \(\gamma \in \{0, 1\}\) considered? It would be beneficial to include experiments or plots with varying \(\gamma\) values.
- Page 7: The organization of text, plots, and tables could be improved to reduce interleaving and enhance readability.
- The model referenced in line 387 should be added to the table, potentially with a footnote indicating that it uses different training data, or alternatively, a line break could be used for clarity.
- Additional qualitative analysis would be a valuable addition if space permits.
- The following recent works appear to be missing and should be cited, as they are relevant and provide strong results (e.g., on the Stanford Background dataset):
  - Feedforward Semantic Segmentation with Zoom-Out Features by Mohammadreza Mostajabi, Payman Yadollahpour, and Gregory Shakhnarovich (Toyota Technological Institute at Chicago).
  - Conditional Random Fields as Recurrent Neural Networks by Shuai Zheng et al. (arXiv:1502.03240).
Summary:
This paper provides a well-executed and principled combination of two existing techniques. While the technical novelty is somewhat limited, the results are convincing. Nonetheless, the paper would benefit from additional studies and refinements as outlined above.