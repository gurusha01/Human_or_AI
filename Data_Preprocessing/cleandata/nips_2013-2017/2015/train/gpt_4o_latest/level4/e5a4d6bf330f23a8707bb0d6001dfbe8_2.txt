ADDED after author response:
Thank you for the additional clarifications. It would be beneficial to include some of the points regarding implicit vs. explicit exploration and the choice of parameters in the two settings in the final version of the paper.
======
This work is driven by the observation that the explicit exploration term commonly employed in multi-armed bandit algorithms for arm selection can negatively impact performance, particularly in cases where certain arms are "obviously" suboptimal. To address this, the authors adopt the implicit exploration (IX) framework introduced by Kocak et al. [NIPS-2014], demonstrating that the associated loss function with implicit exploration (a) simplifies the analysis of regret bounds and (b) improves the constant factors in known regret bounds for several variants of the standard MAB problem.
The paper is engaging, well-written, and mathematically rigorous (though I did not verify all proofs in detail). The theoretical contributions are concisely summarized in Table 1. While I found the paper enjoyable to read, my enthusiasm for acceptance is moderate due to the following concerns:
1. Novelty and Significance: The primary contribution lies in extending the established IX framework to a range of existing algorithms and analyzing their performance. While the improvements reported in Table 1 are clear, they are limited to small constant-factor gains. This raises questions about the broader significance of the results in advancing the field or their practical implications.
2. Implicit vs. Explicit Exploration: The central premise of the paper is that explicit exploration is suboptimal, a viewpoint I generally agree with. Two key reasons for this are: (i) Explicit exploration introduces a tradeoff parameter (balancing exploration and exploitation) that often requires domain-specific tuning. However, the proposed algorithm also includes an analogous parameter (gamma in the denominator), which does not fully resolve this issue. (ii) Explicit exploration forces algorithms to sample the losses of all arms at least Ω(√T) times over T rounds, even when many arms are "obviously suboptimal." The implicit claim is that the proposed IX-based algorithm is less wasteful in such cases. However, this aspect is not explicitly analyzed in the paper. Table 1 does not address this issue, and I was expecting a result along the lines of: if a fraction of arms is "obviously suboptimal," the IX algorithm provably allocates fewer resources to them. Such a result would have significantly strengthened the paper.
Overall, I appreciate the paper but have some reservations.
Summary: This is a well-written paper with strong mathematical foundations that applies the previously introduced implicit exploration framework to several MAB algorithms, yielding improvements in constant factors for regret bounds. However, the advantage of implicit exploration over explicit exploration remains somewhat unclear.