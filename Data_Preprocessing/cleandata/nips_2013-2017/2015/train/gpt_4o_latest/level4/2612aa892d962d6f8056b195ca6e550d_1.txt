The author introduces a method to integrate feedback gains into neural network policies, enhancing their robustness against disturbances and regression errors. By softly coupling trajectory optimization and policy optimization through a cost penalty for deviations, the approach enables the policy to approximate optimal trajectories that are not only simpler but also more robust compared to those generated solely by MPC-based trajectory optimization. Sophisticated parallelization techniques are employed to optimize the tasks, though this serves more as a practical tool rather than the primary focus of the paper. Ultimately, the trained feedback controllers are successfully applied to control a diverse array of robotic systems.
This paper is of exceptional quality, remarkably clear, and showcases an impressive mastery of technique, delivering elegant results in its applications. It is a truly outstanding piece of work that seamlessly integrates graphics, control, and neural networks to develop controllers for a wide variety of body morphologies and tasks. Truly inspiring.