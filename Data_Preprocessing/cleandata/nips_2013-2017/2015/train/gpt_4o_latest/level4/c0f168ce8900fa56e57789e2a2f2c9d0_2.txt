The paper provides a finite-time analysis of a novel Monte Carlo (MC) algorithm referred to as Projected Langevin Monte Carlo (Projected LMC).
The optimization analogue of Projected LMC is stochastic gradient descent (SGD). The primary theoretical result demonstrates that, with a suitably chosen step-size and after a sufficiently large number of iterations, the sample distribution generated by Projected LMC can be made arbitrarily close to the target log-concave density.
The key contribution of the paper lies in establishing that the step-size for Projected LMC mirrors that of SGD and that the maximum number of iterations required by Projected LMC scales polynomially with the dimensionality of the space, up to a logarithmic factor.
Moreover, the proposed algorithm operates without requiring evaluation of the density itself, relying instead on its gradient.
This feature is particularly advantageous in scenarios where the normalization constant of the density is intractable.
The paper is well-structured and clearly written. It offers a novel theoretical analysis of the Projected LMC algorithm for sampling from log-concave distributions, leveraging only first-order oracle information. This work represents the first finite-time analysis of a Monte Carlo algorithm designed to sample from a log-concave distribution using solely the gradient of the log-density.