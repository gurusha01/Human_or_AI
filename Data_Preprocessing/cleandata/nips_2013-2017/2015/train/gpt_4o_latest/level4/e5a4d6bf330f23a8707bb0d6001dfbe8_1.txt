A novel loss estimation method for adversarial multi-armed bandits is introduced, enabling the avoidance of explicit exploration while achieving high-probability bounds. From a technical standpoint, this approach results in better constants and more straightforward proofs. This is a strong paper that merits publication. However, it is regrettable that the author does not address the potential applicability of this technique to the linear bandit setting, where significant effort has been devoted to designing effective exploration distributions. Overall, this is a sharp and insightful contribution that the bandit community has overlooked until now.