This study represents a logical extension of existing CNN-based object detection approaches. My concerns are outlined below:
1. In the optimization section, it appears that only a single iteration is performed for the alternating optimization between the RPN and R-CNN. If this is indeed the case, it implies that the proposals generated by the initial iteration of the RPN are assumed to be optimal, which is clearly not accurate.
2. When the pixel-wise sliding window is applied to the top layer of the CNN, what is the step size at the image level? Given that the CNN involves multiple rounds of max-pooling, the top layer operates at a significantly reduced scale compared to the input image. Consequently, the sliding window at the top layer may correspond to a large step size at the image level, potentially leading to imprecise bounding box localization.
3. What is the definition of $h_a$ in lines 173 and 174?
This work introduces a two-stage object detection framework based on convolutional neural networks (CNNs). The first stage involves region proposal generation, which adapts the traditional sliding window approach to operate on the top-layer feature map of the CNN (RPN). In the second stage, a fast R-CNN is applied to the proposed regions. By sharing convolutional layers between the RPN and R-CNN and leveraging GPU acceleration, the method achieves near real-time performance (approximately 5 fps).