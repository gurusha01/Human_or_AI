This paper investigates the task of generating sentences from an image stream. It proposes a coherent recurrent convolutional network (CRCN), which integrates convolutional neural networks, bidirectional recurrent neural networks, and an entity-based local coherence model.
Overall, this is a solid piece of work, but there are areas for improvement:  
 Some related works on video-to-sentence generation are missing, such as "Jointly modeling deep video and compositional text to bridge vision and language in a unified framework."*  
* While the quantitative results of the proposed method appear promising, the user study presented in Table 2 indicates performance comparable to one of the baselines, RCN. A significance test is necessary to confirm whether the observed improvement is statistically reliable.  
In summary, this is a well-designed algorithm for sentence generation from an image stream. The quantitative results are strong, but the user study demonstrates only a marginal advantage over the baselines.