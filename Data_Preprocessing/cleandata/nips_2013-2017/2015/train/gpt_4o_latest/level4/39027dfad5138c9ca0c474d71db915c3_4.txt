== Paraphrased Review ==
A question for clarification in the rebuttal: In Section 4.1 of [1], it is stated that the CRM approach is only valid for delta values within the range [-1,0], which is why they propose rescaling a general loss to fit within this interval. My assumption is that the same restriction applies to NORM-POEM in this paper—specifically, that both (8) and (3) rely on rescaled delta values within [-1,0]. Is this correct? If so, I am unclear on the interpretation of using "delta > 0" in the experiment presented in Table 1. Could you please clarify this?
== Additional Comments ==
- I believe there is a conceptual gap in the setup for "batch learning from logged bandit feedback" described in Section 3 (or as referenced in [1]). Specifically, the feedback should be treated as a random variable rather than a deterministic function, as currently described on line 110. Here's my reasoning: consider a classification problem where the labels are unknown, and feedback is obtained by making a prediction and observing the resulting loss. Suppose there exists a true classification loss function, Delta(y',y), and that feedback is generated as follows: for a given input x, a prediction y is made using h_0; a "god agent" assigns a label y' to the input; and the incurred loss, Delta(y',y), is provided as feedback (so here delta(x,y) corresponds to Delta(y',y) for the specific y' assigned to this example). However, in many classification scenarios, labeling can be noisy, meaning there isn't necessarily a unique y' for each x. Consequently, it's possible to encounter the same input x and the same prediction y in the log, but with a different delta(x,y), as the "god agent" might assign a different label in this instance. This suggests that, in general, delta(x,y) should be modeled as a random variable. In the classification example above, the mean of this random variable for a fixed x and y would correspond to the expected value of Delta(y',y), where y' is distributed according to the true noisy labeling distribution, p(y'|x).
While this observation may not affect the risk estimator in equation (2), it implies that the setup in equation (1) for the true risk should include an additional expectation over the randomness of delta to make it more general.
- Lines 170-171: I believe the correct expression should be h(y|x) / h_0(y|x). Additionally, it might be worth noting that the lack of linearity was already highlighted in [1].
- Line 276: It seems that "argmin" should be used instead of "argmax," as the goal is to minimize the risk.
- Line 319: To maintain consistency with the earlier notation, the bars should be replaced with hats.
== Update After Rebuttal ==
Thank you for the clarifications. [light reviewer]  
Quality: 6/10  
Clarity: 6/10  
Originality: 8/10  
Significance: 8/10  
I find this to be an interesting follow-up to [1]. The analysis of "propensity overfitting" is particularly compelling, and I appreciate the proposed use of a multiplicative control variate to mitigate it. The results demonstrate a clear improvement over POEM, addressing a problem—batch learning from logged bandit feedback—that is garnering increasing attention.