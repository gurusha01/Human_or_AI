The authors present a scenario termed "on-the-job learning," where annotators are queried between receiving an input example and producing a prediction.
While the algorithm's functioning is well-explained for structured prediction tasks, where specific elements of a sequence are queried, its application to the face recognition task remains unclearâ€”was the query simply the instance itself? In non-structured settings, the model would not propagate information across adjacent positions (examples), which raises questions about the utility function's validity in such cases.
The threshold baseline involves two parameters that appear to be arbitrarily chosen. What is the origin of these values, and how sensitive are the results to these choices?
Additionally, incorporating a baseline based on uncertainty sampling, similar to approaches used in active learning, would provide an interesting comparison.
Lastly, while the authors emphasize the distinction between this framework and active online learning, it seems that active learning could be straightforwardly adapted to this domain by treating the active set as a sequence. For instance, the model could be updated upon receiving responses and then produce a prediction at the sequence's end. Although this approach would not fully capture the temporal dynamics of the task, it could leverage existing theoretical insights for query selection. Overall, the framework appears novel, but certain details remain unclear, and its applicability seems somewhat limited.