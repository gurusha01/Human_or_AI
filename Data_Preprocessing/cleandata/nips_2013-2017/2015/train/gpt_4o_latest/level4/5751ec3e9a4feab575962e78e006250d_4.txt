Paraphrased Review
Summary of Paper
The manuscript introduces an evidence lower bound (ELBO) derived by averaging over a data-generating distribution. The authors demonstrate that optimizing this ELBO achieves remarkable performance in large-scale data streaming applications.
Quality
- L039: The phrase "the standard approach to probabilistic modeling" could be more precise if rephrased as "the standard approach to Bayesian probabilistic modeling," as probabilistic models can be constructed without necessarily having a dataset in hand.
- L044: Upon first reading, I wondered, "Why wouldn't the Bayesian posterior become more confident as more data is observed? This is, in fact, a desirable characteristic of Bayesian inference. Furthermore, 'over-dispersion' is a well-documented issue in many generalized linear models, and the typical remedy is to improve the model. Wouldn't the solution here also involve building a better model? Alternatively, if model uncertainty is a concern, perhaps averaging over multiple models could be considered." Later in the paper, it becomes clearer that the proposed method seeks robustness to model misspecification through a different approach.
- L051: My initial impression of this paragraph was that the core issue with Bayesian updating in streaming data scenarios is not the Bayesian procedure itself but rather the way the model is specified. If the data stream evolves over time and this change is not explicitly modeled, it is unsurprising that the updates yield suboptimal inferences. This issue arises from model misspecification rather than a flaw in the updating mechanism. Again, the proposed method seems to address robustness to these model specification challenges, which are particularly problematic in streaming data contexts. The introductory discussion could benefit from refinement to better set up the valuable contributions presented later in the paper.
- L056: The authors assert that explicitly modeling the time series entails significant computational costs. Can this claim be substantiated with a citation or supporting evidence?
- L165: There appears to be a misplaced parenthesis and possibly a missing \(\beta\) in the variational distribution for the F-ELBO.
- L165: The standard ELBO is conditioned on a specific dataset \(x\), whereas the F-ELBO averages over datasets \(x\) drawn from the population distribution \(X \sim F\alpha\). I am curious whether this averaging causes the F-ELBO to prioritize optimizing the ELBO over modes of \(F\alpha\). In contrast, conditioning on a specific \(x\), as in the standard ELBO, would not depend on how likely that dataset is under \(F\alpha\). Could the authors elaborate on the trade-offs between marginalizing over \(F\alpha\) versus conditioning on a sample from it?
- The results focus primarily on prediction rather than parameter estimation, which is entirely appropriate given the typical applications of streaming data. However, could the authors comment on the parameter estimates? Specifically, since the primary objective of maximizing the ELBO or F-ELBO is to obtain parameter estimates, is there anything notable about the resulting estimates?
- I appreciate that the F-ELBO provides a clear framework for understanding stochastic variational inference (SVI) and explains its mechanics well. However, if a generative model for \(p(X)\) is available, what are the trade-offs of using that distribution for averaging instead of \(X \sim F\alpha\)? I understand that if the model is misspecified, averaging with respect to it could exacerbate the updating issues described, whereas sampling from \(F\alpha\) is model-agnostic. Are there additional reasons why \(p(X)\) might be a suboptimal choice?
Clarity
- Greater clarity is needed to pinpoint exactly where the issues identified in paragraphs 2 and 3 of the introduction arise. For instance, L042 attributes the problems to "Bayesian updating on data streams," while L044 specifies that "the first problem is that Bayesian posteriors will become overconfident," and L051 states, "the data stream might change over time." After multiple readings, the intended meaning becomes clear, but the phrasing could be improved. For example, L044 might be revised to: "The first problem with Bayesian updating on data streams is that Bayesian posteriors tend to become overconfident." Similarly, L051 could be rephrased as: "The second problem with Bayesian updating on data streams is that the data stream may evolve over time, leading to ..."
Originality
The paper is original and offers a compelling justification for stochastic variational inference (SVI).
Significance
I find the paper to be highly significant and believe it will be a valuable contribution to the field. It presents an innovative approach to inference in streaming data scenarios. While I have some questions about the methodology, I consider this work a meaningful and important advancement for the community.