Paraphrased Review:
Summary:  
The paper introduces a Poisson-Gamma hierarchy for modeling count data.
The key contribution of the work lies in leveraging a hierarchy of gamma distributions and employing recently proposed innovative augmentation techniques to design a straightforward and efficient Gibbs sampler, despite the challenge of non-conjugacy. Combined with a Poisson likelihood, the authors effectively demonstrate the utility of this hierarchical approach for modeling count data.
The paper is technically robust. The task of extracting unsupervised multilayered representations from data is compelling, and the proposed model offers an intriguing alternative for handling count data.
Detailed Comments:  
1) Although it is true that Restricted Boltzmann Machines (RBMs) have conventionally relied on binary hidden units, recent research [1] has shown that employing rectified linear nonlinearities can yield improved representations. The nonlinearities introduced by the proposed gamma units seem to encompass the linear regime of rectified linear nonlinearities (where the linear regime is recovered in expectation when the expected rate parameter equals 1). This is an interesting observation, and it would be beneficial to elaborate on this connection more explicitly in the manuscript.
2) Scalability appears to be a significant concern for the proposed inference method. Based on the description, it seems that 1000 Gibbs sampling iterations are performed after adding each new layer, iterating over all variables in the network. This approach would likely face challenges in scaling to deeper architectures. How much time does it currently take to train the 5-layer networks used for multi-class classification? A discussion addressing these computational limitations would enhance the paper.
3) The comparisons for external classification tasks, specifically against DocNADE and over-replicated softmax, are not rigorous. The classification results are not directly comparable, as the competing methods are trained on different vocabularies. Additionally, the paragraph on qualitative analysis is uninformative and requires significant revision. The authors assert that the discovered topics become more specialized as one moves deeper into the hierarchy, but they provide minimal evidence to support this claim. It would be valuable for readers to examine the topics discovered at each layer in greater detail, and these could be included in a supplementary section. Furthermore, the authors claim, without adequate evidence, that the trained network can generate interpretable synthetic documents. Providing examples of such synthetic documents, perhaps in an appendix, would strengthen this claim.
[1] Nair, Vinod, and Geoffrey E. Hinton. "Rectified linear units improve restricted Boltzmann machines." Proceedings of the 27th International Conference on Machine Learning (ICML-10). 2010.
Overall:  
This is an engaging and well-executed paper. However, the experimental evaluations lack rigor, which prevents me from assigning a higher score.