The problem of 3D object proposal has received significantly less attention compared to 2D object proposal, and this paper presents an effective approach to address this task. The proposed method fundamentally differs from popular 2D approaches (e.g., grouping superpixels as in Selective Search).
For evaluation, the paper performs a commendable comparison with state-of-the-art methods. However, one notable limitation is the absence of evaluation in 3D, despite the focus on 3D object proposals. All detections are evaluated using 2D bounding boxes, which leaves a gap in the analysis.
While the paper emphasizes contextual models tailored to autonomous driving, it would be intriguing to explore whether this approach can generalize to other domains, such as indoor RGB-D scans. The task shares fundamental similarities, and the contextual information leveraged by the paper—such as object size priors, ground plane, free space, point cloud densities, and distance to the ground—would likely remain valuable in general RGB-D indoor scenes. However, indoor environments are typically more cluttered and contain a wider variety of object categories, posing additional challenges. Extending the approach to indoor RGB-D data would also enable a more direct comparison with MCG-D [14], which is specifically designed for indoor RGB-D scans but does not incorporate such strong domain-specific contextual models. Demonstrating the applicability of the proposed method in this setting would significantly strengthen the paper.
Overall, the paper introduces a novel and effective approach for 3D object proposal that fundamentally differs from popular 2D methods like Selective Search. I recommend including 3D evaluations in the paper and demonstrating the generalization capability of the approach by applying it to indoor RGB-D scans.