Review - QUALITY  
This paper presents an interesting concept. However, I believe it requires two significant revisions to appeal to a NIPS audience.  
First, the paper should explicitly acknowledge its experimental nature upfront and follow with a more comprehensive study. Specifically, the experiments need to clearly emphasize both the strengths (e.g., performance on large datasets) and the weaknesses (e.g., thorough comparisons and failure cases).  
Second, the paper would benefit from editorial improvements. Key sections (outlined below) require additional explanation. The experimental study should better motivate the setup and provide a more detailed, technical discussion of the results. This level of rigor is what a NIPS reader would expect from such a submission.  
Specific Comments:  
- Bayesian Probit Regression: The choice of reporting the approximate KL as a metric is unclear. Why not directly compare the means and variances of parameter estimates against benchmarks like Stan/NUTS? This approach seems more intuitive and natural.  
- Figure 3(c): It is unclear why SEP with \(K=1\) is compared to DSEP with \(K=10\). Is there a specific rationale for this comparison that I am missing?  
- Mixture of Gaussians: The switch to the F-norm metric is not well-justified. Wouldn't it be more informative to simulate scenarios where EP fails to recover the ground truth? It would be valuable to see whether SEP "fails in the same way" as EP or whether the single \(f(\theta)\) factor introduces different behavior.  
By the time I reached Section 5.3, I found the first two experimental sections somewhat unsatisfying. They do not provide sufficient insight into the behavior of SEP, particularly its failure modes. The investigation of minibatch sizes is limited, and the experiments fail to provide a clear and cohesive picture. Furthermore, given that the primary motivation of this work is to scale EP, it is puzzling that most experiments are conducted on small datasets.  
Section 5.3, in particular, requires substantial revision. The experimental setup is only briefly mentioned with a citation, which is inadequate. The discussion of results is overly conversational, lacking technical depth and specificity, and relies on vague terms like "often," "interestingly," "possibly," and "likely."  
CLARITY  
- Figure 3(b): The term "DAEP" is not explained anywhere, either in the figure caption or the main text.  
- Figure 2: Its contribution to the paper is unclear. I would recommend removing it and using the space to expand on Sections 3 and 4.1, which are critical to the paper but would benefit from a clearer and more detailed exposition.  
ORIGINALITY  
The idea is both novel and appealing. To the best of my knowledge, no prior work has directly addressed EP's memory constraints in this manner. The proposal is straightforward, and a NIPS reader is likely to think, "This is a good idea; I wonder why it works."  
SPECIFICS  
- Line 48: "... having a myriad of local ..."  
- Line 69: "truely" → "truly"  
- Line 149: "summaried" → "summarized"  
- Line 199: "arguable" → "arguably"  
- Line 214: This paragraph is vague. It is difficult to understand the reference without consulting the supplementary material, which diminishes the motivation to do so.  
- Line 257: Why is "mixture" capitalized?  
- Figure 2: This figure should appear on page 5, not page 6.  
- Line 290: The comparison metric here is confusing and unclear.  
- Line 292: Citation [25] does not exist. Should this be [24]? This raises concerns about the accuracy of citations throughout the paper.  
Summary  
This paper proposes a solution to EP's memory constraints by using a single approximating factor instead of one per likelihood term. While the paper acknowledges its limited theoretical contributions, the empirical results are somewhat underwhelming. As such, I am undecided about recommending acceptance in its current form. Depending on the feedback from other reviewers, I would encourage the authors to refine the empirical section, clarify the narrative, and resubmit. I am confident that, with these improvements, the paper will eventually be accepted.