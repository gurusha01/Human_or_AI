Summary of Paper: This work introduces a novel inference method for a low-rank matrix factorization model tailored to ordinal data, with an additional application explored.
It remains unclear whether MultiNomialLogit (MNL) models have been previously applied to these specific problems, leaving ambiguity as to whether the primary contribution lies solely in the inference method (nuclear norm minimization) or if the models themselves are novel contributions.
Regardless, the authors provide theoretical performance guarantees for their method but fail to validate it through experiments on either real-world or synthetic datasets.
Quality: Good - The theoretical framework is well-developed and appears rigorous.
The contributions reflect significant effort. Clarity: Poor - The paper requires substantial revisions to address both minor editorial issues and major structural problems in the flow of ideas within sections.
There should also be a more thorough discussion of the broader implications of the contributions. Originality: Mediocre - Low-rank matrix factorization has been extensively studied from numerous perspectives, making the contribution appear incremental.
I am less familiar with the novelty of the second application. Significance: Poor - The paper does not provide comparisons to existing methods (of which there are many for matrix factorization), either empirically or theoretically.
While even small improvements can have significant impact, the lack of evidence leaves the reader to infer that this work offers limited practical and minor theoretical advancements for the stated problems.
Detailed Points:  
- Line 20 (abstract): The phrase "A popular discrete choice model of multinomial logit model captures..." is awkward and unclear; likely an editing mistake.  
- Line 18: The discussion of personalized user preferences is unclear. The user is not introduced until after the problem of preference prediction, which creates a backward and convoluted sequence of ideas.  
- Abstract: While the abstract begins with motivating applications, the actual contribution appears to be purely theoretical (an approach and a bound), with no justification for the importance of the theory beyond it being a "natural approach" for inference on "a popular model." There is no discussion of how the theory impacts applications or any mention of experiments.  
- Line 33: Add a comma after "applications": "applications, such as..."  
- First line of the introduction and abstract are identical. While not explicitly prohibited, this repetition disengages the reader.  
- Lines 44, 53: Items in the list (e.g., (a) something, (b) something) lack parallel structure. For instance, (b) describes a goal while (a) describes a method, making the sequence of ideas confusing.  
- Line 57: The term "MultiNomialLogit model" is not consistently capitalized with the abstract and requires a citation.  
- Line 61: Capitalize "The" at the start of the sentence.  
- Line 62: It might be more effective to focus on one example in the introduction (e.g., bundling, which appears more novel) and defer the second example to the experiments/results section.  
- Line 70: Highlighting the contribution is commendable, but the authors should explain why this approach is "natural."  
- Contribution: The paper seems to suggest that MNL has already been applied to ordinal low-rank matrix factorization, but the authors are introducing a new inference method and applying it to two cases. Is this correct? Alternatively, is this the first application of MNL to ordinal data in matrix factorization? This distinction is unclear.  
- Line 76: The term "RUM" requires a citation.  
- Line 94: There are spacing issues.  
- Sections 3 and 4: The practical implications of the theorems and their corollaries are not clear. While the results may warrant closer study, the authors should explicitly highlight the key takeaways in plain language or through empirical demonstrations. The single figure provided does not significantly aid understanding.  
- Line 289: The introduction of RMSE is abrupt and lacks context. Additionally, while RMSE is a common metric, it is not well-suited for rank-based item recommendation tasks.  
- Discussion: The discussion section reads like a to-do list for future work rather than providing a cohesive summary of the paper's contributions. What are the key takeaways for the reader?  
In summary, while the contributions are reasonably clear, they are not well-motivated or justified. The paper requires significant editing for clarity, and the contributions should be empirically validated and compared to existing methods on real or synthetic datasets.