TL;DR This paper introduces a training heuristic called scheduled sampling (SS) for RNNs, where gold truth labels are occasionally replaced with predictions sampled from the model. Various schedules for determining when to replace the gold labels are proposed, corresponding to different decay functions (linear, exponential, inverse sigmoid). The authors demonstrate improvements over a comparable RNN model without SS across tasks such as image captioning, constituency parsing, and speech recognition.
This is an interesting experimental contribution! While the concept of noise injection is well-established, the emphasis on enhancing robustness during test time is compelling. However, I feel this paper raises more questions than it resolves. Below are some specific concerns:
- If SS functions as a regularizer, it's reassuring to see that it complements dropout. However, an important baseline is missing: what happens if we always randomly sample a label (following the proposed schedules) instead of using model predictions?
- If the goal is to address search error, it would have been useful to compare against baselines that vary beam widths. Does SS still provide an advantage when the model employs a larger beam width?
- The hyper-parameter k raises some concerns. Tuning it based on the "expected speed of convergence" feels vague, and there's no discussion of its sensitivity or how it was optimized in the experiments.
Beyond these specific points, I believe the paper would benefit from a more thorough probabilistic analysis. It would be valuable to understand why the proposed heuristic is effective, perhaps by disentangling its regularization effects. Additionally, experiments exploring the impact of SS under varying levels of supervision would have been insightful.
UPDATE AFTER AUTHOR RESPONSE:
Thank you for addressing some of my concerns. That said, I remain somewhat apprehensive about the practical challenges of tuning the sampling schedule and would have appreciated further analysis of the method. This paper presents an intriguing training heuristic for RNNs that enhances prediction robustness at test time. While the experimental results are promising, the underlying reasons for the method's effectiveness remain unclear, and the paper lacks sufficient analysis (both experimental and theoretical).