The paper employs a bidirectional convolutional RNN to perform multi-frame super-resolution and compares their approach against various single-frame and multi-frame methods.
This work appears to extend the model proposed by Dong et al. (2014) into the temporal domain. The convolutional network is adapted for temporal processing by incorporating feature maps that evolve over time, in addition to the standard feature maps in a feedforward convolutional network. The recurrent convolution mechanism introduced here is novel, and the model itself is relatively simple and elegant to implement.
However, the bidirectional aspect of the network is not novel and can be traced back to at least 1997 (Schuster and Paliwal) [http://www.di.ufpe.br/~fnj/RNA/bibliografia/BRNN.pdf]. Bidirectional networks are also widely used in the NLP and speech recognition domains.
The authors should clarify whether pretraining the feedforward weights is essential for the model's intended performance. If it is, they should provide more details about the pretraining process, such as whether it was conducted on static images or video frames processed individually.
The most significant performance gains are attributed to the recurrent/conditional convolutions, which is a noteworthy result. However, the marginal improvement observed when combining all connections (v, r, t) suggests that one of these connections may become redundant in the presence of the others.
The proposed method appears to outperform prior approaches, though it is challenging to assess the exact magnitude of the improvement.
Additional comments:  
-- There are no citations provided for bidirectional RNNs (see above).  
-- The filter visualization section does not offer much insight.  
-- The paper could better justify the architecture's design choices. Why should this approach be expected to outperform existing methods?  
-- It is unclear how edge effects are handled. For instance, convolutions typically reduce the image size. While the filter size of 1 in the temporal direction preserves the size when moving forward in time, deeper layers with a filter size of 9 result in smaller feature maps. The handling of this issue is not explained.  
-- In Figure 3, the image with the flag and power lines shows ringing artifacts in the region with the power lines. Could the authors comment on this?
Overall, I find the paper compelling. The introduction of recurrent convolution is a strong and intuitive idea.
The use of a convolutional RNN is a promising and novel contribution to this problem. However, the paper could provide more insight into why the proposed method performs better than existing approaches.