The authors address the problem of identifying policy parameters that minimize a specified risk measure. The paper considers a broad class of risk measures, defined by fundamental coherence properties such as convexity, monotonicity, and translation invariance. The proposed methodology leverages the dual representation of coherent risk measures, which expresses them as the convex hull of probability distributions. The risk associated with a random variable (e.g., a cost) is then characterized as the maximum expected value over this convex hull. To facilitate their analysis, the authors impose an assumption on the family of coherent risk measures, specifically bounding the maximum derivatives of the convex hull's boundaries (i.e., assuming the boundaries are M-Lipschitz continuous). Under this assumption, the authors derive analytical expressions for the optimal policy parameters (with respect to the risk measure) and propose a general gradient estimation algorithm applicable to both static (single-step decision) and dynamic (sequential decision-making) settings.
The paper is well-structured and clearly written. While I do not have extensive expertise in risk-sensitive optimization, I was able to comprehend most of the explanations provided. The primary contribution of this work lies in its unified analysis of a general class of risk measures, encompassing many widely used measures. I consider this to be a significant advancement. That said, a more comprehensive empirical evaluation of the proposed gradient algorithm would enhance the paper.
Some comments/questions:  
1. The preliminaries section could be clarified further, as the roles of \( P_{\theta} \) and \( \xi \) were somewhat confusing.  
2. Is Equation 2 essentially the definition of a convex envelope? If so, how does this impose stricter conditions than Theorem 2.1?  
3. I recommend including a discussion on how the analysis extends to distributions over continuous variables.  
4. It would be helpful to briefly mention in the short paper how the smoothness of the constraint functions contributes to the proof of Theorem 4.2.  
Overall, this is a strong theoretical contribution that introduces a general framework for risk-sensitive decision-making. The results appear promising, though the proofs warrant careful verification.