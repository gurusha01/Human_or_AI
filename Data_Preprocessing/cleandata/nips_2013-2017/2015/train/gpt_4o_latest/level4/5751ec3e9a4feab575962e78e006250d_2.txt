This paper introduces the population posterior distribution as a framework for Bayesian modeling of streaming data and demonstrates how stochastic optimization can be employed to derive a suitable approximation.
The authors validate their proposed framework and algorithm on latent Dirichlet allocation and Dirichlet process mixture models, using both text and geolocation datasets. The results indicate that the method outperforms prior approaches in certain scenarios.
Overall, I find the core idea of the paper to be compelling, and I believe it would be a strong fit for NIPS.
That said, there are several aspects of the paper that could benefit from further clarification and discussion.
First, while the authors consistently use the term "Bayesian modeling" throughout the paper, the title instead uses "Bayesian inference." This is misleading, as the paper does not provide a method for Bayesian inference. The title should be revised to reflect "Bayesian modeling."
Additionally, the notation in Eqs. 3 and 4 for the local variables is somewhat confusing. These variables are being optimized to the expectation of a population average, yet they are local to individual data points. This creates the impression that the learned local variational parameters might be conflated due to averaging. While I understand how the algorithm functions, it would be helpful if the authors could revise the notation to make this aspect clearer.
The step-size for gradient ascent is another point of concern, as it is not explicitly introduced in the algorithm. This omission should be addressed.
Furthermore, in the paragraph around line 153, the authors state that optimizing the F-ELBO does not guarantee minimization of the KL divergence, but then immediately claim in the next sentence that Appendix A shows it does. This contradiction needs to be resolved with a clearer explanation.
The discussion of the \(\alpha\) parameter in the experiments section is brief, but this parameter is crucial as it controls the level of uncertainty in the approximate posteriors. Since one of the key advantages of the method is that the posterior does not collapse to a point, it would be valuable to introduce and discuss this parameter earlier in the paper. The authors should emphasize its role, especially as it relates to dataset size.
Another point that warrants discussion is whether the algorithm converges and what convergence implies in this context. The authors argue that the population posterior avoids the issue of the posterior concentrating on a single point due to model mismatch. However, this assumes that practitioners expect their model to converge to the data-generating distribution as more data is observed. I am not convinced this assumption is widely held. Instead, the \(\alpha\) parameter's ability to maintain a fixed level of uncertainty (or at least a lower bound) seems more relevant for streaming data. The authors should reconsider how they frame this as a selling point.
The experiments section is well-executed and provides convincing results. However, I have a few questions and suggestions for improvement. Why does SVB perform worse in some cases? Is this due to local optima? The authors should also specify the step-size schedules used in their experiments and discuss whether the results are sensitive to these schedules. Additionally, it would be helpful to know how many replicates were used when permuting the order of the data, and error bars should be included in the results.
Finally, I have some minor comments:
- The paper contains numerous typos that should be corrected.
- The "Discussion and Future Work" section lacks any mention of future work. Given the novelty of this research, the authors should include some directions for future exploration.
To conclude, I thoroughly enjoyed reading this paper and found its contributions to be both innovative and significant. I hope the authors address my concerns, particularly those related to the clarity of presentation. With these improvements, I believe this paper would make an excellent addition to the NIPS proceedings.