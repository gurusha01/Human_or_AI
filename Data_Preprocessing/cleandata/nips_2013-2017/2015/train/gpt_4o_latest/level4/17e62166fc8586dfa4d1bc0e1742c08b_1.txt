This paper addresses the problem of retrieving natural sentences to describe a given sequence of images and forming a coherent sequence of sentences. This problem is undoubtedly important in the domains of computer vision and pattern recognition, but it is closely related to the task of generating multiple sentences to describe video content (e.g., [Rohrbach+ 2014]). A single video can be considered as a sequence of images, as it can be segmented into multiple video shots, each of which can be effectively represented by a key frame. However, this paper does not cite any prior work from this related line of research.
The paper is well-written and easy to understand. The problem is clearly defined and addressed using a set of robust techniques.
The proposed neural network model, CRCN, captures the relationships between a sequence of natural sentences and a sequence of images. The architecture of the model is technically sound and effectively incorporates discourse relationships through the use of entity-based coherence models.
The approach for generating a sequence of natural sentences is reasonable but somewhat simplistic: each natural sentence is directly linked to training images similar to a given image, and all the sequences are concatenated in the order of the corresponding images.
In Section 4.1, the authors state, "We reuse the blog data of Disneyland from the dataset of [11], and newly collect the data of NYC, using the same crawling method with [11]." However, the dataset has not been disclosed, and the referenced paper does not provide details about how the dataset was collected. This suggests that the authors of this paper are likely the same as those of [11], which compromises the anonymity of the submission.
Equation (2) appears to be incorrect, as it implies that st can be derived solely from ot, suggesting that the network is not fully connected. While the proposed neural network model is technically sound and effectively captures discourse relationships using entity-based coherence models, the method for generating a sequence of sentences for a given image stream is somewhat ad hoc. Overall, I believe this paper is suitable for acceptance as a poster presentation in its current form.