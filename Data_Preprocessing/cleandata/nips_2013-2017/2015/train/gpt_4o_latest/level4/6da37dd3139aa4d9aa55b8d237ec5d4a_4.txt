3D object proposal for autonomous driving represents a novel and relatively underexplored research direction. The proposed method demonstrates higher accuracy compared to existing approaches. However, the processing time of 1.2 seconds is not particularly fast. Overall, the paper is well-written, but I have a few questions and comments: 1) Equation 1 is described as an energy function, but it is unclear why it is considered a Markov Random Field (MRF). The energy appears to be computed for a single candidate 3D object proposal at a time. 2) Several assumptions made in the paper might not always hold. For example, if the depth data is sparse or contains significant errors, will the performance degrade substantially? Similarly, if the ground plane estimation fails, how significantly will the performance be affected? I suggest the authors conduct experiments to evaluate the sensitivity of the method to these assumptions. 
The paper proposes a 3D object bounding box generation method to detect cars, bikes, and pedestrians in stereo images. Since the focus is on autonomous driving, the method relies on the following strong assumptions: 1) clean depth maps can be obtained from stereo image pairs, 2) objects lie on a common ground plane, and 3) objects have typical 3D heights and aspect ratios that can be represented using a small set of templates. Based on these assumptions, several 3D cues—such as 3D point density, free space volume, and height priors—are computed (in 1.2 seconds) to generate 3D object proposals. The proposed method achieves significantly higher recall compared to competing 2D and 3D methods when limited to 500 proposals. Furthermore, by integrating the proposed region proposal method with a state-of-the-art convolutional neural network (CNN), substantial accuracy improvements are achieved for detecting challenging objects.