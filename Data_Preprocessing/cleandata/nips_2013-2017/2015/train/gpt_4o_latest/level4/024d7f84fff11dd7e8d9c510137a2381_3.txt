The authors investigate the risk-averse Markov decision process framework, considering both static and dynamically consistent risk measures (mappings). The primary contribution lies in deriving the gradient form for both the dynamic and static settings.
This work generalizes prior results, which were specifically focused on CVaR. While the extension is relatively minor, it is nonetheless a valuable contribution. The findings represent a straightforward extension of the policy gradient approach from risk-neutral settings.
The paper is well-structured, clearly written, and easy to comprehend.
The results appear to be correct based on my assessment.
Minor comments:
- Theorem 2.1: The notation \xi P_\theta is somewhat unclear. I recommend referring to Theorem 6.6 in [26] and adopting the same notation for clarity.
- Line 141: risk enevlop[e] - Section 3: To prevent confusion among readers less familiar with the topic, it may be helpful to clarify here that MDPs with Markov risk measures are generally very tractable. The intractability in this paper arises from the policy parametrization rather than the risk measure itself.  
Overall, the paper offers a minor but meaningful and robust extension to existing results.