The concept of extending distributional approaches from words to sentences is excellent.
The experiments appear to be meticulously conducted, with evaluations performed across a wide range of diverse tasks.
This paper presents an unsupervised approach for training sentence vector representations. The proposed method involves using a GRU to encode a sentence and subsequently predict the words in surrounding sentences. I find this paper highly compelling. However, I strongly recommend renaming the method to "skip-sentence vector," as a sentence does not necessarily equate to a thought. :)