The paper employs an online approximation of MCMC to sample parameters for a Bayesian neural network. The predictive distribution derived from these samples is subsequently optimized using stochastic approximation. Comparisons are made to recent advancements in approximate Bayesian inference applied to similar models and problems, with the assertion that the proposed method offers improvements (at least in certain aspects). However, the paper does not yet convincingly demonstrate that these methods will advance any specific application.
This work represents a fairly natural progression of prior research. It is concise, well-executed, clearly presented, and accessible for others to replicate, which suggests it could have significant impact.
Including some details on training times would enhance the paper. It is implied that training time is considerably slower than alternative methods, as the abstract specifically highlights test-time efficiency. However, this issue is largely sidestepped in the current presentation.
The paper should explicitly clarify that stochastic gradient Langevin dynamics only provides approximate posterior samples. This limitation extends beyond the usual MCMC concerns of burn-in, as it fails to accurately reflect the posterior even locally when exploring a mode for an extended period. While the cited developments address some aspects of this issue, they do not achieve the same level of accuracy as traditional batch MCMC on smaller problems. Although there may not be a better alternative for large-scale problems, it is important to avoid overstating the method's capabilities. For instance, the posterior discrepancy in Figure 2 is noticeable to careful readers but is not explicitly addressed in the text.
The claim that the priors are equivalent to L_2 regularization should be removed, as this equivalence only applies to MAP estimation, which is not the focus of this work. It is somewhat disappointing that simple spherical Gaussian priors are used, given the extensive research on Bayesian neural networks from the 1990s. These priors are difficult to take seriously, particularly in the context of very large and deep networks.
From an engineering perspective, the overall procedure is practical. However, further comparisons are necessary to determine whether it outperforms standard techniques such as regularization, early stopping, dropout, and other methods for mitigating overfitting. In scenarios where predictive distributions are the primary goal of inference, additional work is needed to make approximate Bayesian inference at this scale more reliable. Nonetheless, this paper represents an intriguing step in that direction.
Minor Comments:
- The title does not seem to accurately reflect the contribution. While it may sound appealing, the paper does not discuss uncovering "hidden" knowledge.
- The fitting algorithm does not appear to be standard SGD. Since subsequent theta samples in the final line are dependent, some justification based on stochastic approximation seems necessary.
- The notation "$5e-6$" is poorly formatted. It would be better to use "$5\!\times\!10^{-6}$," and "$1e-5$" could simply be written as "$10^{-5}$."
- References should follow the numerical "unsrt" style as specified in the NIPS style guide. Additionally, the references could be more complete: some proper nouns need capitalization, and author names are inconsistently formatted (some use initials while others are listed in full).
- This paper builds naturally on Snelson and Ghahramani's "Compact Approximations to Bayesian Predictive Distributions" (ICML 2005), extending their ideas to neural networks and incorporating online methods for MCMC and gradient-based fitting. The work is well-executed and effectively modernizes these concepts.