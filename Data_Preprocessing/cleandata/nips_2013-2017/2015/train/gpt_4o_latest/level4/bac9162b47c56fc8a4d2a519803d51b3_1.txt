This paper introduces a method for modeling student learning in the context of MOOCs using recurrent neural networks (RNNs). The proposed system is assessed based on its ability to predict whether a student will succeed or fail on specific exercises. The authors present an LSTM-based RNN architecture to address this problem and demonstrate its performance improvements over the standard Bayesian Knowledge Tracing (BKT) method.
This work represents a well-documented application paper on knowledge tracing, where the use of LSTM RNN appears to be a significant advancement. The dataset and baselines are appropriate, and the inclusion of the authors' code in the supplementary material is commendable. However, the usability of the code could be improved by providing a small README file to facilitate its use.
The paper's organization requires refinement: the definition of knowledge tracing in subsection 1.1 is isolated and should not be part of the introduction. Additionally, section 4 is problematicâ€”it would be better split and integrated into the introduction and the related work sections.
The motivation for using AUC as the evaluation metric is unclear. Why not rely on accuracy instead? This choice is not justified and does not seem to align with standard practices in knowledge tracing (though I am not an expert in the field, and I note that Figure 3 also includes accuracy).
Section 6.2 (and the supplementary material) is intriguing. Could the authors propose a way to quantitatively evaluate this task?
In summary, I found this paper to be both interesting and well-written. The demonstrated performance improvements represent a significant contribution, which I believe justifies its acceptance for publication at NIPS.