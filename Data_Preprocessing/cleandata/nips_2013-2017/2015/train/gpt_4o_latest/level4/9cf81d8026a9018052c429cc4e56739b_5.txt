This paper introduces a method for scene labeling using Recurrent Convolutional Neural Networks, where the output of a convolutional layer is fed back as an additional input to the same layer (achieved by duplicating the layer multiple times). The network takes as input the original image along with several downscaled versions of the image to better leverage contextual information.
The proposed approach is evaluated on two datasets and compared against prior methods. The accuracy improvements are notable, and the computational efficiency is impressive, as the algorithm is fully executable on a GPU.
I found the paper engaging as it addresses highly relevant topics, but I have two major concerns: - the text is challenging to follow. For instance, the passive voice in the first sentence of the last paragraph of the introduction creates ambiguity. It took me a while to infer that the authors intended to say, "we adopt a multi-scale version of RCNN." - while the results are promising, the contribution is somewhat limited, as it primarily involves applying RCNN (already used in prior computer vision tasks) to the problem of image labeling.
Minor comments: - Section 3: explicitly clarify that RCL refers to recurrent convolutional layer. The same issue applies to LRN. - Just before Eq (3): the notation should be g(Zijkz), not sigma(zijk). - Is the discussion on gamma truly necessary?
The results with gamma = 0 are inferior to those with gamma = 1, which is the standard approach. This is unsurprising, as if a small gamma were beneficial, the network could learn to assign large values to w_k^rec.  
In summary, this paper proposes a method for scene labeling using Recurrent Convolutional Neural Networks. While the results are interesting, the text is hard to follow, and the contribution appears limited.