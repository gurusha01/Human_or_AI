In numerous multiclass classification tasks involving a large number of classes, semantic similarities among classes are often observed. This paper introduces an algorithm named top-k SVM, specifically designed to address scenarios where a penalty is incurred only if the true class is absent from the top k predicted classes (e.g., the ImageNet challenge). By extending the loss function to incorporate top-k loss, the authors derive an efficient optimization procedure. Experiments conducted on large-scale datasets demonstrate the algorithm's scalability and show clear improvements over competing methods.
The paper is well-motivated and straightforward to follow. The addressed problem—handling similar classes in multiclass learning—is significant and frequently encountered in practical applications. The proposed top-k SVM algorithm effectively tackles this issue by accommodating cases where certain classes exhibit high similarity. The method scales efficiently to large datasets and demonstrates superior performance compared to alternative approaches.