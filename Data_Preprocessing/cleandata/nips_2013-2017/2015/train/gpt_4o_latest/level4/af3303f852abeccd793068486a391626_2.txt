The manuscript's central idea, within a regression framework, is to approximate the predictive distribution using a simple and tractable model, thereby avoiding the computational expense of approximating the true predictive distribution via Monte Carlo sampling. The authors justify their preference for a Bayesian approach (partially supported by their simulation results) over a plug-in method. The proposed approach is straightforward and reasonable: it involves minimizing an averaged KL divergence between the true predictive distribution and the surrogate parametric model, leveraging outputs from the SGLD algorithm. The method's performance is demonstrated through simulations on select examples, where, as is typical, it outperforms competing approaches. However, the manuscript does not address the numerous parameters that need to be selected in the algorithm. While the work does not present any surprising insights, it explores an idea that is worth investigating.