The paper introduces a recurrent CNN architecture tailored for multi-frame super-resolution, utilizing three distinct types of convolutional filters: (i) feed-forward, (ii) recurrent, and (iii) conditional convolutions. While the architecture is novel, it appears to be a relatively straightforward integration of existing deep learning components.
The technical quality of the paper is borderline. The proposed approach is a direct combination of established deep learning modules. However, its novelty lies in the fact that such a combination has not previously been applied to multi-frame super-resolution.
The authors should address the following points in their rebuttal: (i) What is the total number of parameters in the model? (ii) Did the authors compare their results with a pre-trained SR-CNN, or did they re-train the SR-CNN on the new dataset? (iii) Why is the runtime of SR-CNN slower than BRCN? (iv) In Figures 3 and 5, how do the SR-CNN-generated images appear?
The originality of the work is incremental. Table 2 demonstrates the contribution of individual components of the architecture. However, it is well-established that increasing architectural complexity and the number of parameters often leads to improved performance. This is evident in Table 2, where BRCN {v,r}, {v,t}, {v,r,t}, and {v,r,t,b} progressively enhance performance, albeit incrementally.
The significance of the paper for the NIPS audience remains debatable. While the architecture proposed is novel, it represents an incremental advancement in the field of deep learning. The paper builds upon prior work on single-frame CNNs for super-resolution [6] and is presented in a clear and comprehensible manner. However, some experimental details are missing and should be clarified. Overall, the paper is thorough but incremental, and its relevance to the NIPS audience warrants further discussion.