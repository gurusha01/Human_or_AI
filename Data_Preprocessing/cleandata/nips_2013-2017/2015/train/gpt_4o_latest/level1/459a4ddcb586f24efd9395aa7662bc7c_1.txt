The paper introduces a novel Markov Chain Monte Carlo (MCMC) sampling scheme for Bayesian nonparametric mixture models with Poisson-Kingman priors, addressing a key challenge in Bayesian nonparametrics: efficient inference in models with infinite-dimensional components. The authors propose a hybrid sampler that combines the strengths of conditional and marginal MCMC methods, achieving a compact representation of the infinite-dimensional component while reducing memory requirements and computational overhead. The paper provides a detailed theoretical foundation for the proposed method, including its relationship to existing stick-breaking constructions and size-biased sampling, and demonstrates its efficacy through comparative experiments on synthetic and real-world datasets.
Strengths:
1. Technical Contribution: The hybrid sampler is a significant innovation, offering a practical solution for inference in a large class of Bayesian nonparametric models. By explicitly representing only the size-biased weights of occupied clusters and introducing a surplus mass term, the method achieves a balance between computational efficiency and representational completeness.
2. Theoretical Rigor: The paper provides a thorough theoretical framework, including derivations of complete conditionals and connections to existing methods. The authors also address intractabilities in specific cases (e.g., σ-Stable Poisson-Kingman processes) with well-motivated solutions, such as auxiliary variable methods and reparameterizations.
3. Empirical Validation: The experiments demonstrate the hybrid sampler's superior performance in terms of effective sample size (ESS) and runtime compared to existing marginal and conditional samplers. The inclusion of a real-world dataset (galaxy velocities) enhances the practical relevance of the work.
4. Generality: The method is applicable to a wide range of Bayesian nonparametric priors, including σ-Stable and -logBeta Poisson-Kingman processes, showcasing its versatility.
Weaknesses:
1. Clarity: While the paper is technically sound, its presentation is dense and may be challenging for readers unfamiliar with Bayesian nonparametrics or Poisson-Kingman processes. Simplifying the exposition, particularly in Sections 2 and 3, would improve accessibility.
2. Limited Scope of Empirical Evaluation: The experiments, though compelling, focus on relatively small datasets and a limited range of priors. It would be beneficial to explore the method's scalability to high-dimensional or large-scale datasets.
3. Proposal Design in Metropolis-Hastings: The authors acknowledge suboptimal acceptance rates in the Metropolis-Hastings step for certain cases. While they suggest exploring better proposals as future work, this limitation affects the method's efficiency in some scenarios.
4. Comparison with Specialized Methods: The paper compares the hybrid sampler primarily with general-purpose marginal and conditional samplers. Including comparisons with specialized methods for specific priors (e.g., Dirichlet or Pitman-Yor processes) would provide a more comprehensive evaluation.
Arguments for Acceptance:
- The hybrid sampler is a novel and impactful contribution to Bayesian nonparametrics, addressing a longstanding challenge in the field.
- The method's theoretical foundation is robust, and its empirical performance is promising.
- The work is relevant to the NeurIPS community, given its focus on scalable inference methods for complex probabilistic models.
Arguments Against Acceptance:
- The paper's clarity could be improved, particularly for readers less familiar with the domain.
- The empirical evaluation, while solid, could be expanded to better demonstrate scalability and robustness across diverse settings.
Recommendation:
I recommend acceptance, as the paper presents a significant methodological advance with strong theoretical and empirical support. However, I encourage the authors to improve the clarity of the exposition and expand the empirical evaluation in future iterations.