Review
Summary
This paper introduces a kernel-based method for cross-domain instance matching, addressing challenges in aligning instances represented as multisets of features (e.g., bag-of-words). The proposed approach embeds features from different domains into a shared latent space, where instances are represented as distributions of their features. The framework leverages kernel embeddings of distributions to measure differences between these distributions in a reproducing kernel Hilbert space (RKHS). The method is trained to minimize the differences between paired instances while maximizing the separation of unpaired instances. Experimental results demonstrate the method's effectiveness in tasks such as multilingual document alignment, document-tag matching, and image-tag matching, outperforming existing methods like CCA, kernel CCA, and bilingual topic models.
Strengths
1. Technical Novelty: The proposed method introduces a novel use of kernel embeddings of distributions for cross-domain matching, which allows for efficient and nonparametric representation of feature distributions. This approach addresses limitations of existing methods like kernel CCA, which rely on predefined kernel functions that may not capture semantic relationships between features.
2. Comprehensive Evaluation: The paper evaluates the method on diverse datasets, including multilingual Wikipedia articles, document-tag pairs, and image-tag pairs. The results consistently show significant improvements over baseline methods, demonstrating the generalizability of the approach.
3. Clear Motivation: The paper provides a thorough discussion of the limitations of existing methods (e.g., linearity of CCA, reliance on generative models in bilingual topic models) and positions the proposed method as a discriminative alternative that can handle non-linear relationships.
4. Practical Relevance: The method addresses real-world challenges in cross-domain matching, such as multilingual document alignment and image annotation, which are important problems in natural language processing and computer vision.
Weaknesses
1. Clarity: While the technical details are thorough, the paper is dense and may be difficult for readers unfamiliar with kernel embeddings or RKHS. Key concepts, such as the intuition behind kernel embeddings and their role in the proposed method, could be explained more clearly for accessibility.
2. Computational Complexity: The paper does not provide a detailed analysis of the computational cost of the method, particularly for large-scale datasets. Gradient-based optimization for learning latent vectors may become computationally expensive as the number of features and instances increases.
3. Limited Discussion of Hyperparameters: The method relies on several hyperparameters (e.g., dimensionality of the latent space, kernel parameters), but the paper does not provide insights into their sensitivity or how they influence performance.
4. Comparison with Deep Learning: While the paper briefly mentions deep learning approaches, it does not include them in the experimental comparison. Given the increasing popularity of deep learning for cross-domain tasks, such as cross-modal retrieval, their exclusion limits the scope of the evaluation.
Arguments for Acceptance
- The method is technically sound and introduces a novel approach to cross-domain matching.
- Experimental results demonstrate significant improvements over existing methods across diverse datasets.
- The paper addresses an important and practical problem, with potential applications in NLP, computer vision, and information retrieval.
Arguments Against Acceptance
- The paper's clarity could be improved, particularly for readers unfamiliar with kernel methods.
- The lack of comparison with deep learning approaches limits the evaluation's comprehensiveness.
- Computational scalability for large datasets remains unclear.
Recommendation
I recommend acceptance of this paper, as it presents a novel and effective method for cross-domain instance matching, with strong empirical results and practical relevance. However, the authors should consider improving the clarity of the presentation and addressing computational scalability in future revisions.