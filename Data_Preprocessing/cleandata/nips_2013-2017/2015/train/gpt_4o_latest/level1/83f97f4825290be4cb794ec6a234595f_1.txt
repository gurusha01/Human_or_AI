This paper addresses the min-max hypergraph partitioning problem in a streaming computation model, where items must be irrevocably assigned to components as they arrive, with memory constraints limited to linear growth in the number of components. The authors propose a greedy algorithm that minimizes the maximum number of distinct topics (hyperedges) associated with any component. They provide theoretical guarantees for the algorithm's performance under a probabilistic input model inspired by the stochastic block model, demonstrating that the algorithm achieves balanced asymptotic recovery of hidden co-clusters under specific conditions. Additionally, the paper includes extensive empirical evaluations on real-world and synthetic datasets, showing that the greedy algorithm outperforms alternative online and even some offline approaches.
Strengths:
1. Novelty and Originality: The paper tackles a challenging and underexplored problem in the streaming computation model, extending prior work on graph partitioning to hypergraphs. The use of a hidden co-clustering model and the coupling of the greedy algorithm with Polya urn processes is innovative and well-motivated.
2. Theoretical Contributions: The authors provide rigorous theoretical analysis, including a recovery theorem with provable guarantees under specific conditions. The coupling argument and reduction to Polya urn processes are technically sound and novel.
3. Empirical Validation: The experimental results are thorough, comparing the proposed algorithm against multiple baselines and demonstrating its superior performance. The inclusion of both real-world and synthetic datasets strengthens the paper's claims.
4. Clarity: The paper is well-organized and clearly written, with detailed explanations of the problem, algorithm, and theoretical results. The inclusion of pseudocode for the greedy algorithm is helpful for reproducibility.
5. Significance: The problem has practical applications in clustering, load balancing, and query processing in large-scale systems, making the contributions relevant to both researchers and practitioners.
Weaknesses:
1. Assumptions in the Model: The recovery guarantees rely on specific conditions, such as the gap between probabilities \(p\) and \(q\) and the number of hidden clusters being at least \(k \log k\). While these assumptions are reasonable for theoretical analysis, their applicability to real-world scenarios with arbitrary inputs is less clear.
2. Limited Comparison to Offline Methods: While the paper compares the greedy algorithm to several online heuristics, the evaluation against offline methods like PARSA is less comprehensive. The authors acknowledge that PARSA achieves better results in some cases, but further analysis of this discrepancy would strengthen the paper.
3. Scalability of Theoretical Results: The theoretical analysis focuses on asymptotic recovery, but the practical implications for finite datasets are not fully explored. For example, the recovery time \(t_R\) and its dependence on input parameters could be discussed in more detail.
4. Generality of Input Model: The hidden co-clustering model is a natural extension of the stochastic block model, but its relevance to diverse real-world datasets is not fully justified. The authors could provide more discussion on how well this model aligns with practical applications.
Arguments for Acceptance:
- The paper presents a novel and well-motivated problem, with significant theoretical and practical contributions.
- The proposed algorithm is simple yet effective, with strong empirical performance.
- The theoretical analysis is rigorous and contributes to the understanding of streaming algorithms for hypergraph partitioning.
Arguments Against Acceptance:
- The reliance on specific assumptions for theoretical guarantees may limit the generality of the results.
- The comparison to offline methods is less robust, and the practical implications of the theoretical results are not fully explored.
Recommendation:
Overall, this paper makes a strong contribution to the field of streaming algorithms and hypergraph partitioning. While there are some limitations in the generality and practical applicability of the theoretical results, the combination of rigorous analysis and empirical validation makes the paper a valuable addition to the conference. I recommend acceptance, with minor revisions to address the discussed weaknesses.