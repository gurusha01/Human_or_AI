This paper presents a novel approach to decision tree learning by jointly optimizing split functions across all levels of the tree under a global objective, rather than relying on traditional greedy methods. The authors establish a connection between decision tree optimization and structured prediction with latent variables, introducing a convex-concave upper bound on the tree's empirical loss. Their method leverages stochastic gradient descent (SGD) to enable efficient training of deep trees with large datasets. Experimental results demonstrate that the proposed non-greedy decision trees outperform greedy baselines across multiple classification benchmarks.
Strengths:
1. Novelty and Originality: The paper introduces a significant departure from traditional greedy decision tree induction by formulating the problem as a global optimization task. The connection to structured prediction with latent variables is innovative and provides a strong theoretical foundation.
2. Technical Contributions: The development of a convex-concave surrogate objective and the reduction of gradient computation complexity from \(O(2^d p)\) to \(O(d^2 p)\) are notable contributions. These advancements make the training of deep trees computationally feasible.
3. Experimental Validation: The authors provide extensive experiments on multiple datasets, demonstrating superior generalization performance and reduced overfitting compared to greedy baselines. The results are consistent across varying tree depths.
4. Practical Impact: The method's scalability and ability to handle large datasets make it relevant for real-world applications, particularly in scenarios where deep trees are required.
5. Clarity and Organization: The paper is well-structured, with clear explanations of the methodology, theoretical underpinnings, and experimental setup.
Weaknesses:
1. Computational Overhead: While the authors address the computational challenges of deep tree training, the method still incurs higher computational costs compared to traditional greedy approaches, particularly for shallow trees or smaller datasets.
2. Limited Comparisons: The experiments focus primarily on single-tree performance. It would be valuable to compare the proposed method within ensemble frameworks (e.g., random forests or boosted trees) to assess its impact in such settings.
3. Hyperparameter Sensitivity: The reliance on tuning the regularization parameter (\(\nu\)) and learning rate (\(\eta\)) may limit the method's ease of use for practitioners. A discussion on automatic or adaptive tuning strategies would strengthen the paper.
4. Reproducibility: While the methodology is detailed, the paper does not provide sufficient implementation details or code, which could hinder reproducibility.
Suggestions for Improvement:
1. Include experiments comparing the method's performance in ensemble settings (e.g., forests or boosting) to highlight its broader applicability.
2. Provide more insights into the choice and sensitivity of hyperparameters, potentially exploring adaptive strategies.
3. Share implementation details or open-source the code to facilitate reproducibility and adoption by the community.
Recommendation:
This paper makes a strong contribution to decision tree learning by addressing the limitations of greedy induction and proposing a theoretically grounded, non-greedy alternative. Despite some computational overhead and limited ensemble comparisons, the method's novelty, technical rigor, and demonstrated performance gains make it a valuable addition to the field. I recommend acceptance, with minor revisions to address the reproducibility and hyperparameter concerns. 
Pro:
- Novel and theoretically sound approach.
- Strong experimental results demonstrating improved generalization.
- Practical relevance for large-scale datasets.
Con:
- Higher computational cost compared to greedy methods.
- Limited exploration of ensemble settings.
- Hyperparameter tuning challenges.