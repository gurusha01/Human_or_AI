The paper introduces a novel Covariance-Controlled Adaptive Langevin (CCAdL) thermostat aimed at improving convergence and efficiency in stochastic gradient Markov Chain Monte Carlo (SG-MCMC) methods, specifically for large-scale Bayesian inference. Building on existing methods like SGHMC and SGNHT, the proposed CCAdL method addresses a key limitation of these techniques: their inability to handle parameter-dependent noise in gradient approximations. By incorporating a covariance-controlled damping term, CCAdL ensures robust dissipation of noise while maintaining the desired invariant distribution. The authors demonstrate the method's efficacy through theoretical analysis and experimental validation on tasks such as Bayesian inference for Gaussian distributions, Bayesian logistic regression, and training discriminative restricted Boltzmann machines.
Strengths:  
1. Technical Contribution: The paper addresses a significant limitation in SG-MCMC methods by introducing a mechanism to handle parameter-dependent noise, which is a practical concern in large-scale machine learning applications.  
2. Experimental Validation: The proposed method consistently outperforms SGHMC and SGNHT in terms of convergence speed, robustness to hyperparameters, and sample quality across diverse tasks. The results are particularly compelling in large-scale Bayesian logistic regression and DRBM experiments.  
3. Practicality: The diagonal covariance approximation for high-dimensional problems is a thoughtful addition, reducing computational overhead without compromising performance.  
4. Theoretical Rigor: The authors provide a clear mathematical foundation for CCAdL, including proofs of its ability to preserve the desired invariant distribution.
Weaknesses:  
1. Incremental Contribution: While CCAdL combines ideas from SGHMC and SGNHT effectively, its novelty is somewhat incremental. The method builds on existing frameworks rather than introducing a fundamentally new paradigm.  
2. Limited Comparisons: The experimental evaluation is restricted to comparisons with SGHMC and SGNHT. The absence of comparisons with other recent mini-batch MCMC methods or non-stochastic gradient approaches limits the scope of the analysis.  
3. Writing Quality: The paper's clarity could be improved. The abstract contains ambiguous sentences, the introduction has an odd flow, and Section 2 lacks sufficient explanation of key terms, potentially hindering accessibility for readers unfamiliar with the domain.  
4. Figure Clarity: The inset "peaks" in Figure 1 add minimal value and could be omitted for better visual clarity.
Pro and Con Arguments for Acceptance:  
- Pro: The method is well-motivated, addresses a practical limitation of existing SG-MCMC methods, and demonstrates consistent performance improvements.  
- Con: The contribution is incremental, and the experimental scope is narrow, limiting its broader impact.  
Recommendations:  
The paper is technically sound and offers a meaningful improvement to SG-MCMC methods. However, the authors should broaden their experimental comparisons to include other state-of-the-art methods and refine the writing for better clarity. If these issues are addressed, the paper would make a valuable contribution to the field of large-scale Bayesian inference.