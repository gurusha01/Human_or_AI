The paper presents a bidirectional recurrent convolutional network (BRCN) for multi-frame super-resolution (SR), leveraging feedforward, recurrent, and conditional convolutions to model temporal dependencies in video sequences. The authors argue that their approach addresses limitations of existing multi-frame SR methods, such as high computational cost and sensitivity to motion complexity, by avoiding explicit motion estimation. The proposed architecture combines forward and backward recurrent sub-networks to capture temporal dynamics from both past and future frames. Experimental results demonstrate state-of-the-art performance and significant speed improvements compared to existing methods.
Strengths:  
The paper introduces a novel application of recurrent and conditional convolutions in the context of multi-frame SR, which is a meaningful extension of prior work. The bidirectional design is well-motivated and effectively models temporal dependencies, as evidenced by quantitative and qualitative results. The authors provide a thorough comparison with both single-image SR and multi-frame SR methods, showing consistent performance gains. The paper is clearly written and well-organized, making it accessible to readers familiar with deep learning and SR. Additionally, the significant runtime improvements over traditional multi-frame SR methods highlight the practical value of the proposed approach.
Weaknesses:  
While the architecture is novel in its application, it primarily combines existing deep learning modules (e.g., recurrent and convolutional layers) in a straightforward manner, resulting in incremental originality. The performance improvements appear to stem largely from increased model complexity and parameter count, rather than fundamental algorithmic advances. The paper lacks detailed comparisons with SR-CNN, particularly in terms of parameter count and runtime discrepancies, which are critical for evaluating the trade-offs between accuracy and efficiency. Additionally, some experimental details, such as the exact configurations of competing methods and the unclear SR-CNN image outputs in figures, need clarification. The authors should also address whether the proposed method generalizes well to diverse datasets beyond the limited set used in their experiments.
Pro Acceptance:  
- Novel application of bidirectional recurrent and conditional convolutions for multi-frame SR.  
- Significant performance and runtime improvements over existing methods.  
- Thorough experimental evaluation and clear presentation.  
Con Acceptance:  
- Incremental originality due to reliance on existing deep learning techniques.  
- Lack of detailed comparisons with SR-CNN and insufficient clarity in some experimental results.  
- Performance gains largely attributed to increased model complexity.  
Conclusion:  
The paper makes a solid contribution to the field of video super-resolution by proposing a novel architecture that achieves state-of-the-art results with improved efficiency. However, its originality is incremental, and some experimental details require further elaboration. The paper is suitable for the NIPS audience, but the authors should address the highlighted concerns in their rebuttal.