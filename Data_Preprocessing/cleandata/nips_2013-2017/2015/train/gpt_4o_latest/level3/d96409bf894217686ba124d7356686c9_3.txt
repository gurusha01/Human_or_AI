The paper presents a novel approach to structured prediction by learning messages in message-passing inference using deep Convolutional Neural Networks (CNNs). This method eliminates the need for learning potential functions, thereby significantly improving training efficiency for Conditional Random Fields (CRFs). The authors demonstrate the scalability of their approach, particularly for tasks with a large number of classes, and achieve state-of-the-art results on the PASCAL VOC 2012 semantic segmentation dataset. The paper also highlights the ability to perform high-quality predictions with just one message-passing iteration, making the inference process computationally efficient.
Strengths:
1. Novelty of Approach: The idea of directly learning factor-to-variable messages using CNNs is innovative and represents a departure from conventional CRF methods that rely on potential functions. This is a meaningful contribution to the field of structured prediction.
2. Efficiency: The proposed method bypasses expensive inference steps during training, making it computationally attractive. The reduced network parameter requirements due to the fixed output dimension further enhance scalability.
3. Performance: The method achieves state-of-the-art results on the PASCAL VOC 2012 dataset, outperforming several existing methods, including those that use conventional CRF learning approaches.
4. Clarity: The paper is well-written and provides sufficient technical details for reproducibility. The experimental results are thorough and include comparisons with relevant baselines.
Weaknesses:
1. Lack of Acknowledgment of Related Work: The paper does not adequately discuss its contributions in relation to prior work, particularly [12], which also explores learning messages in message-passing inference using CNNs. The distinction between the two approaches is not clearly articulated.
2. Originality Concerns: The proposed method essentially functions as an ensemble of four separate deep networks. This raises questions about its originality compared to single-network approaches. The paper does not sufficiently justify why this ensemble approach is fundamentally different or superior.
3. Baseline Comparisons: An ensemble model, which is a natural baseline for this method, is not included in the experiments. This omission makes it difficult to disentangle the contribution of the proposed message-learning framework from the ensemble effect.
4. Interpretability: The ensemble effect from multiple networks is not disentangled, which could impact the interpretation of the results. It remains unclear how much of the performance gain is attributable to the proposed method versus the ensemble architecture.
Recommendation:
While the paper introduces an important idea and achieves impressive results, the lack of acknowledgment of related work, insufficient discussion of originality, and missing baseline comparisons are significant drawbacks. To strengthen the paper, the authors should explicitly discuss their contributions relative to [12], include an ensemble baseline, and disentangle the ensemble effect from their proposed method. Despite these concerns, the paper's technical quality, clarity, and significance to the field make it a valuable contribution. I recommend acceptance, contingent on addressing the aforementioned issues.
Pro:
- Novel and efficient approach to structured prediction.
- Strong experimental results demonstrating state-of-the-art performance.
- Well-written and technically sound.
Con:
- Insufficient discussion of related work and originality.
- Missing baseline comparisons.
- Ambiguity in interpreting the ensemble effect.
Final Recommendation: Weak Accept.