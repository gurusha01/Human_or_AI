The paper introduces a multi-scale recurrent convolutional neural network (RCNN) for pixelwise scene labeling, leveraging recurrent convolutional connections with shared weights and additive skip-connections. The proposed model integrates local feature extraction and global context modulation seamlessly within each layer, eliminating the need for separate preprocessing or postprocessing steps. The RCNN is evaluated on the Stanford Background and SIFT Flow datasets, demonstrating competitive performance, particularly in terms of per-pixel accuracy (PA). The authors claim that their approach is efficient and end-to-end trainable, making it a promising contribution to scene labeling tasks.
Strengths:
1. Novelty and Integration: The paper presents a novel adaptation of RCNNs for scene labeling, combining multi-scale processing and recurrent connections. This approach effectively integrates local and global information, addressing a key challenge in pixelwise classification.
2. End-to-End Design: The model avoids preprocessing or postprocessing steps, which simplifies the pipeline and improves computational efficiency.
3. Empirical Results: The RCNN achieves state-of-the-art results on benchmark datasets, particularly in PA, and demonstrates efficiency in processing time compared to other methods.
4. Comprehensive Analysis: The paper provides a detailed exploration of hyperparameters (e.g., Î³, T, and weight sharing) and compares RCNN against baseline CNNs, highlighting the benefits of recurrent connections.
5. Scalability: The authors demonstrate that the RCNN can be scaled to smaller or larger models (e.g., RCNN-small and RCNN-large), offering flexibility for different computational constraints.
Weaknesses:
1. Weight Sharing Comparison: While the authors investigate weight sharing in recurrent connections, they do not provide a thorough comparison with models using different convolution kernels for recurrent iterations. This could clarify whether weight sharing limits the model's representational capacity.
2. Parameter Exploration: The effects of the number of scales (N) and iterations (T) are insufficiently explored, particularly for RCNN-large at higher N values. This limits insights into the scalability of the model.
3. Discrepancy in Metrics: There is an inconsistency in the reported PA/CA metrics between Table 1 and Table 2, which requires clarification to ensure the validity of the results.
4. Unvalidated Claims: The claim that the model avoids postprocessing for label consistency is not experimentally validated. Qualitative examples or ablation studies would strengthen this assertion.
5. Lack of Comparison with Recent Work: The paper does not adequately discuss or compare its approach with recent related works, such as Chen et al. and Eigen & Fergus. This omission weakens its positioning within the broader literature.
Recommendation:
While the paper demonstrates strong empirical results and introduces a novel approach to scene labeling, the weaknesses in experimental validation and related work discussion need to be addressed. The authors should clarify the discrepancies in reported metrics, explore the effects of key parameters more thoroughly, and provide qualitative evidence for their claims. Additionally, a deeper comparison with recent works would enhance the paper's significance. Overall, the paper is a valuable contribution but requires revisions to address these gaps.
Arguments for Acceptance:
- Novel and efficient approach to scene labeling.
- Strong empirical performance on benchmark datasets.
- Comprehensive analysis of some hyperparameters.
Arguments for Rejection:
- Incomplete exploration of key parameters (N, T).
- Discrepancy in reported metrics undermines reliability.
- Insufficient comparison with recent related works.
Final Decision: Weak Accept, contingent on addressing the identified weaknesses.