The paper introduces Stochastic Expectation Propagation (SEP), a novel extension of the Expectation Propagation (EP) algorithm, aimed at addressing EP's prohibitive memory requirements in large-scale Bayesian learning. Unlike traditional EP, which iteratively refines local approximations for each datapoint, SEP maintains and iteratively updates a global posterior approximation. This innovation reduces memory consumption by a factor of \(N\), making SEP particularly suitable for large datasets and complex models. The authors demonstrate SEP's effectiveness through experiments on Bayesian probit regression, mixture of Gaussians, and probabilistic backpropagation, showing that SEP achieves comparable accuracy to EP while significantly reducing memory usage.
Strengths
The paper presents a useful, original, and well-motivated idea with clear practical significance. SEP bridges the gap between EP's local approximation and global approaches like Variational Inference (VI), combining the strengths of both. The reduction in memory usage is a critical contribution, enabling Bayesian learning on large datasets without sacrificing accuracy. The experimental results are thorough, covering a range of models and datasets, and convincingly demonstrate SEP's scalability and performance. The connections drawn between SEP, EP, VI, and related methods provide valuable theoretical insights, situating SEP within the broader landscape of approximate inference techniques. Additionally, the extension of SEP to latent variable models and its flexibility in controlling granularity (e.g., Distributed SEP) are promising directions for future work.
Weaknesses
While the paper is of high quality, there are a few areas that require improvement. First, the lack of guaranteed convergence for EP is a known limitation, and it is unclear whether similar issues arise for SEP. This concern warrants further theoretical analysis, as the authors acknowledge. Additionally, while SEP's performance on Gaussian clustering is promising, the paper does not clarify whether SEP can adequately capture the multimodal nature of the posterior distribution in such cases. This is particularly important for applications involving complex posteriors. Lastly, the manuscript contains minor typographical errors that should be corrected for clarity and professionalism.
Pro and Con Arguments for Acceptance
Pros:
- Original and significant contribution to scalable Bayesian inference.
- Demonstrates strong experimental performance across diverse models and datasets.
- Reduces memory usage substantially, addressing a critical limitation of EP.
- Provides theoretical connections to existing methods, enhancing its relevance.
Cons:
- Lack of guaranteed convergence for SEP raises theoretical concerns.
- Insufficient discussion of SEP's ability to handle multimodal posteriors.
- Minor typographical errors detract from the overall polish of the paper.
Recommendation
Overall, this paper makes a valuable contribution to the field of approximate inference and is well-suited for the conference. While the theoretical concerns and minor weaknesses should be addressed in a revision, the significance and originality of the work outweigh these issues. I recommend acceptance.