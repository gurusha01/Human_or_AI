This paper presents a training methodology for neural networks that bridges the gap between backpropagation and neuromorphic hardware, specifically the TrueNorth chip. The authors propose a "constrain-then-train" approach, where the network is trained under constraints that align with the hardware's spiking neurons, low-precision synapses, and limited connectivity. The trained network is then mapped to the hardware for deployment. The experimental results demonstrate impressive accuracy (99.42% on MNIST with an ensemble of 64 networks) and energy efficiency (0.268 ÂµJ per classification with a single network), showcasing the potential of this approach for real-world applications.
Strengths:  
The paper addresses an important and timely problem: reconciling the algorithmic advances of deep learning with the energy efficiency of neuromorphic hardware. The experimental results are strong, achieving state-of-the-art accuracy and power efficiency on the MNIST dataset. The authors provide a detailed description of their methodology, including probabilistic representations of spikes and synapses, as well as the mapping process from training to deployment. The paper also discusses potential extensions to more complex datasets and architectures, which adds value for future research.
Weaknesses:  
The primary weakness lies in the paper's claims of novelty. The "constrain-then-train" methodology, while emphasized as novel, was previously proposed and tested in reference [15]. Similarly, the algorithm in Section 3.2 is a hybrid of references [14] and [15], derived using identical approximations, which the authors fail to adequately acknowledge. The claim in the introduction that this work is the first to incorporate spiking neurons, low-precision synapses, and constrained connectivity is misleading, as the "expectation backpropagation" algorithm in reference [15] already incorporates similar features. Additionally, the paper incorrectly cites its results as the best prior state-of-the-art for binary weights and neurons, when reference [15] achieved better results. These issues undermine the originality and transparency of the work.
Pro and Con Arguments for Acceptance:  
- Pro: Strong experimental results in both accuracy and energy efficiency. The methodology is clearly described and demonstrates practical relevance for neuromorphic hardware.  
- Con: The claimed novelty is overstated, with significant overlap with prior work. The paper does not adequately credit foundational contributions from references [14] and [15].
Recommendation:  
While the experimental results are compelling, the lack of novelty and misrepresentation of prior work are significant concerns. The paper would benefit from a more honest and thorough discussion of its relationship to existing methods, particularly reference [15]. I recommend rejecting the paper in its current form, but encourage the authors to revise and resubmit with proper attribution and a clearer focus on their unique contributions.