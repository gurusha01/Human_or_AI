The paper introduces a novel recurrent convolutional encoder-decoder network for synthesizing rotated views of 3D objects from a single 2D image. The authors focus on two object classes, faces and chairs, and demonstrate the model's ability to generate realistic transformations, disentangle latent factors, and interpolate between object classes. The proposed architecture leverages recurrent pose units and identity units to traverse the pose manifold while preserving object identity. Curriculum learning is employed to improve training efficiency and disentanglement. The paper also highlights the model's potential for cross-view object recognition and novel object synthesis.
Strengths:  
The proposed approach is innovative, combining recurrent neural networks with convolutional encoder-decoder architectures to address a challenging problem in 3D view synthesis. The use of curriculum learning is well-motivated and demonstrates clear benefits in improving both image quality and feature disentanglement. The experiments on disentangled representations and class interpolation are particularly interesting, showcasing the model's ability to generalize beyond the training data. The paper is well-written and provides sufficient technical details for reproducibility. The qualitative results, especially for faces and chairs, are visually compelling and demonstrate smooth transitions across rotational viewpoints.
Weaknesses:  
The evaluation is predominantly qualitative, which limits the ability to objectively assess the model's performance. While the authors compare their method to a state-of-the-art 3D morphable model and a KNN baseline, the lack of broader quantitative comparisons with other recent methods (e.g., GANs or variational autoencoders) undermines the paper's impact. The experiments are restricted to two datasets (Multi-PIE and Chairs), which limits the generalizability of the approach to other object classes or more complex scenes. Additionally, the model's reliance on static rotation trajectories raises questions about its applicability to dynamic or non-linear transformations. Minor grammatical errors in the text slightly detract from the overall presentation.
Pro and Con Arguments for Acceptance:  
Pro:  
1. Novel and well-motivated approach to 3D view synthesis.  
2. Strong qualitative results demonstrating smooth and realistic transformations.  
3. Interesting experiments on disentangled representations and class interpolation.  
4. Clear and detailed presentation of the methodology.  
Con:  
1. Insufficient quantitative evaluation and lack of comparisons with state-of-the-art methods.  
2. Limited experimentation on diverse datasets and object types.  
3. Focus on static rotation trajectories restricts broader applicability.  
Conclusion:  
While the paper presents a novel and promising approach, its impact is diminished by limited quantitative evaluation and narrow experimental scope. The method has potential but would benefit from broader comparisons, more diverse datasets, and an exploration of dynamic transformations. I recommend acceptance with the expectation that these limitations are addressed in future work.