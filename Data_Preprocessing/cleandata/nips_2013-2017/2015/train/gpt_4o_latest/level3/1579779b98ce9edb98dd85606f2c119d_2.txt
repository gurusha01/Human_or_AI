Review
This paper presents a novel method for non-greedy, joint optimization of decision tree parameters, addressing the limitations of traditional greedy, layer-by-layer training. By framing decision tree induction as a structured prediction problem with latent variables, the authors propose a convex-concave upper bound on empirical loss, optimized using stochastic gradient descent (SGD). The method demonstrates improved generalization and efficiency over greedy baselines, particularly for deep trees, and introduces innovations such as fast loss-augmented inference to reduce computational complexity.
Strengths:
1. Originality and Significance: The paper tackles an important and underexplored problem in decision tree learningâ€”joint optimization of split and leaf parameters. This is a significant step forward, as greedy methods often lead to suboptimal trees. The connection to structured prediction with latent variables is novel and well-motivated.
2. Technical Contributions: The proposed surrogate objective and its optimization via SGD are technically sound. The introduction of fast loss-augmented inference, reducing complexity to \(O(d^2p)\), is a notable contribution, making the method scalable for deep trees.
3. Empirical Performance: The method consistently outperforms greedy baselines across multiple datasets, demonstrating better generalization and reduced overfitting. The experiments also highlight the scalability benefits of the fast inference method.
4. Clarity in Derivation: The mathematical formulation and derivation of the surrogate objective and upper bound are clean and well-presented, showcasing a solid theoretical foundation.
Weaknesses:
1. Empirical Loss Bound Flaw: The derivation of the empirical loss bound (Eq. 7) is unclear, and the supplementary material does not provide a complete proof. This raises concerns about the theoretical rigor of the proposed bound.
2. Experimental Evaluation: The experimental section, while demonstrating the method's advantages, is limited in scope. A comparison with standard greedy training of non-axis-aligned split functions (e.g., OC1 or similar methods) is missing, which would provide a stronger baseline.
3. Unassigned Leaves: The issue of unassigned leaves during training is not adequately addressed. While the Stable SGD (SSGD) variant attempts to mitigate this, its effectiveness is not thoroughly evaluated.
4. Tree Depth Limitation: The need to predefine tree depth is a limitation that is not sufficiently discussed. Experiments exploring the impact of depth on performance would strengthen the paper.
5. Runtime Comparison: While the runtime benefits of fast loss-augmented inference are highlighted, a direct comparison with greedy methods in terms of runtime is absent. This would provide a more comprehensive evaluation of the method's efficiency.
Suggestions for Improvement:
1. Clarify and complete the proof of the empirical loss bound in Eq. (7) to address theoretical concerns.
2. Include a baseline comparison with standard greedy training of non-axis-aligned split functions to contextualize the performance gains.
3. Discuss the implications of unassigned leaves and explore alternative initialization or regularization strategies to address this issue.
4. Provide experiments that analyze the impact of tree depth and runtime comparisons with greedy methods to better validate the method's scalability and efficiency.
Recommendation:
While the paper has notable strengths in originality, technical contributions, and significance, the weaknesses in theoretical rigor and experimental evaluation limit its overall impact. I recommend acceptance with minor revisions, contingent on addressing the concerns about the empirical loss bound and expanding the experimental evaluation. The proposed method has the potential to advance the state of the art in decision tree learning, but further validation is necessary to solidify its contributions.