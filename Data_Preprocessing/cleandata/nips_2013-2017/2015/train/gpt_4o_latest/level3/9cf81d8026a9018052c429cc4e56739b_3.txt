This paper introduces a multi-scale recurrent convolutional neural network (RCNN) for scene labeling, a task requiring both local feature extraction and global context integration. Unlike traditional convolutional neural networks (CNNs), the RCNN incorporates intra-layer recurrent connections, enabling each convolutional layer to function as a two-dimensional recurrent neural network. This design allows the effective receptive field to expand iteratively, capturing broader contextual information. The authors further propose a multi-scale architecture to handle objects of varying sizes, achieving state-of-the-art performance on the Sift Flow and Stanford Background datasets.
The paper builds on prior work in scene labeling and recurrent neural networks, such as the use of CNNs with post-processing techniques like conditional random fields (CRFs) and recursive parsing trees. By integrating feature extraction and context modulation into a single end-to-end framework, the RCNN eliminates the need for separate preprocessing or post-processing steps. This approach is particularly innovative and aligns with recent trends in deep learning, such as the reformulation of CRFs as RNNs. However, the paper could benefit from a more explicit comparison with related work, particularly methods like fully convolutional networks (FCNs) that leverage pretraining on large datasets.
Strengths:
1. Technical Soundness: The RCNN is well-designed, with clear mathematical formulations and a robust experimental setup. The use of patch-wise training and image-wise testing is well-justified, and the results are supported by comprehensive ablation studies.
2. Significant Results: The model achieves competitive performance, particularly in per-pixel accuracy (PA), while maintaining efficiency. The RCNN also demonstrates scalability through its multi-scale design.
3. End-to-End Framework: The integration of feature extraction and context modulation into a single pipeline is a notable contribution, simplifying the scene labeling process.
4. Efficiency: The RCNN processes images faster than many competing models, making it practical for real-world applications.
Weaknesses:
1. Receptive Field Expansion: The explanation of how the effective receptive field expands with larger recurrent iterations (T) for still images (Line 174, Page 4) is insufficient. The authors should clarify this mechanism and provide empirical evidence to support their claims.
2. Class Imbalance: While the RCNN performs well on per-pixel accuracy, its average per-class accuracy (CA) is less competitive, particularly on datasets with unbalanced class distributions. The authors address this with weighted sampling, but further exploration of this limitation is warranted.
3. Originality: While the RCNN is a novel application of recurrent connections within convolutional layers, the concept of combining CNNs and RNNs is not entirely new. The paper could better highlight its unique contributions relative to prior work, such as [19] and [14].
Recommendation:
The paper is technically sound, presents promising results, and addresses a significant problem in computer vision. However, the authors should provide a clearer explanation of receptive field dynamics and strengthen the discussion of related work. Despite these minor weaknesses, the paper represents a meaningful contribution to the field and is suitable for acceptance. 
Pro: Innovative end-to-end design, strong experimental results, efficient implementation.  
Con: Insufficient explanation of receptive field expansion, limited novelty in concept.  
Final Recommendation: Accept with minor revisions.