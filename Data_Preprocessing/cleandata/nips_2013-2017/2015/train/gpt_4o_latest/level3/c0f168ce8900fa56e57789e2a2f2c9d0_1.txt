This paper introduces and analyzes the projected Langevin Monte Carlo (LMC) algorithm, a Markov chain designed for sampling from log-concave distributions within convex sets using a first-order oracle. The authors provide theoretical guarantees for the convergence of LMC in polynomial time, offering an alternative to existing methods like hit-and-run or ball walk, which rely on zeroth-order oracles. The work builds on prior research in stochastic calculus, Bayesian statistics, and optimization, particularly extending results from Dalalyan [2014] to the constrained case. The authors also highlight the connections between LMC and stochastic gradient descent (SGD), making this work relevant to both theoretical and applied machine learning communities.
Strengths:  
The paper presents a technically rigorous analysis of LMC, leveraging tools from stochastic calculus, Wasserstein distance, and coupling arguments to handle the challenges of projection and reflection in convex sets. The theoretical contributions, such as the big-O convergence guarantees, are significant and advance the understanding of first-order sampling methods. The connection between LMC and SGD is insightful, as it bridges optimization and sampling, potentially inspiring further research in stochastic approximation. Additionally, the experiments comparing LMC with hit-and-run provide preliminary evidence of LMC's practical utility, particularly in terms of runtime efficiency.
Weaknesses:  
Despite its technical depth, the paper has several shortcomings. First, key factual statements, particularly those related to convexity and MCMC methods, lack proper citations, such as the discussion of singularities in Dalalyan [2014]. This omission weakens the contextual grounding of the work. Second, the results section does not include a quantitative comparison with standard MCMC algorithms, such as Metropolis-Hastings or Gibbs sampling, nor does it provide performance metrics like mixing time or acceptance rates. This makes it difficult to assess LMC's relative strengths. The absence of a conclusions section leaves the paper feeling incomplete and lacking synthesis of its contributions. Furthermore, the plots in the experimental section lack axis labels and error bars, which diminishes their clarity and interpretability. Lastly, there appears to be a possible typo in line 307 involving an inequality with constant C, which could impact the validity of Lemma 3.
Arguments for Acceptance:  
- The paper provides a novel theoretical analysis of LMC, extending prior work to constrained settings.  
- The connection to SGD is compelling and could inspire new research directions.  
- Theoretical guarantees and preliminary experiments suggest potential practical impact.
Arguments Against Acceptance:  
- Missing citations and incomplete contextualization weaken the paper's scholarly rigor.  
- Lack of quantitative comparisons with standard MCMC methods limits the evaluation of LMC's performance.  
- The absence of a conclusions section and unclear plots reduce the paper's clarity and polish.  
- A potential typo in a key inequality raises concerns about the correctness of some results.
Recommendation:  
While the paper makes valuable theoretical contributions, the lack of proper citations, quantitative comparisons, and a conclusions section, combined with unclear experimental results, suggest it is not yet ready for acceptance. I recommend a major revision to address these issues.