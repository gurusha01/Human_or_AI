The paper addresses the novel problem of generating coherent sentence descriptions for a sequence of images, a significant extension from single image-caption generation to multi-image streams. This is a timely and underexplored area, particularly relevant for applications like travelogues or storytelling. The authors propose a multimodal architecture, the Coherent Recurrent Convolutional Network (CRCN), which integrates convolutional neural networks (CNNs) for image representation, bidirectional recurrent neural networks (BRNNs) for sentence modeling, and an entity-based local coherence model to ensure smooth transitions between sentences. The approach is evaluated on a large dataset of blog posts, demonstrating superior performance over state-of-the-art baselines through both quantitative metrics and user studies.
Strengths:
1. Novelty and Scope: The paper tackles an important and underexplored problem, extending the input-output dimensions to sequences, which is a logical and impactful progression for the field.
2. Model Design: The integration of CNNs, BRNNs, and a local coherence model into a unified architecture is innovative and well-motivated. The use of blog posts as a training corpus is also creative and practical.
3. Comprehensive Evaluation: The authors provide extensive evaluations, including BLEU, METEOR, and CIDEr scores, as well as human evaluations via Amazon Mechanical Turk (AMT). This strengthens the validity of their claims.
4. Reproducibility: The promise to release the source code and dataset is commendable and will facilitate further research in this area.
Weaknesses:
1. Inaccurate Claim: The paper incorrectly claims that [5] does not model coherence, whereas [5] explicitly incorporates semantic coherence through topic prediction. This oversight undermines the novelty claim.
2. Clarity Issues: Figure 2b and Equation (2) are inconsistent in describing the fully connected layer connections, which could confuse readers.
3. Evaluation Metric: The reliance on BLEU as a primary evaluation metric is suboptimal for single-reference sentences. METEOR, which is more robust for such tasks, should have been emphasized.
4. Ablation Study: The benefit of using two linear functions in Equation (2) is unclear and lacks an ablation study to justify its inclusion.
5. Parameter Sharing: The rationale for sharing parameters between the BRNN output and the local coherence model is not explained, leaving a gap in the understanding of the architecture.
6. Paragraph Vector Fine-Tuning: It is unclear whether the paragraph vector [16] is fine-tuned or kept fixed, which affects the reproducibility and interpretability of the results.
Recommendation:
The paper makes a significant contribution to the field and is well-suited for acceptance at the conference. However, the authors must address the inaccuracies regarding related work ([5]), clarify inconsistencies in the model description (Figure 2b and Equation (2)), and provide additional justification for design choices (e.g., parameter sharing, use of two linear functions). Furthermore, an ablation study and a stronger focus on METEOR as an evaluation metric would enhance the paper's rigor. Post-rebuttal, assuming these issues are addressed, I recommend acceptance.