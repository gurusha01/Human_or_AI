This paper addresses a critical issue in batch learning from logged bandit feedback (BLBF) by identifying and remedying the problem of propensity overfitting in the conventional counterfactual risk estimator. Building on the Counterfactual Risk Minimization (CRM) principle introduced by Swaminathan and Joachims (2015), the authors propose a self-normalized risk estimator that avoids the anomalies of the conventional estimator. This leads to the development of a new algorithm, Normalized Policy Optimizer for Exponential Models (Norm-POEM), which demonstrates improved generalization performance and robustness across multiple datasets.
The paper is technically sound and provides a rigorous theoretical foundation for the proposed self-normalized estimator. The authors clearly articulate the limitations of the conventional estimator, including its vulnerability to propensity overfitting and lack of equivariance, and justify the use of multiplicative control variates to address these issues. The theoretical contributions are supported by strong empirical results, with Norm-POEM consistently outperforming the baseline POEM algorithm on multi-label classification tasks. Notably, the proposed method achieves better generalization performance while maintaining computational efficiency, which enhances its practical applicability.
The clarity of the paper is commendable. The authors provide a thorough introduction to the BLBF problem, clearly explain the motivation for their approach, and present their theoretical and empirical findings in a well-structured manner. The inclusion of detailed experimental results and comparisons with prior work ensures that the reader can easily follow the contributions and evaluate their significance. Additionally, the paper provides sufficient information for reproducibility, including references to publicly available datasets and software.
The originality of the work lies in its novel formulation of the BLBF problem and the introduction of the self-normalized risk estimator. While the paper builds on prior work, it offers a significant advancement by addressing a previously unrecognized form of overfitting and demonstrating how this issue can be mitigated through a principled approach. The authors also provide a comprehensive discussion of related work, situating their contributions within the broader context of counterfactual learning and importance sampling.
In terms of significance, the proposed method has the potential for widespread impact. By addressing propensity overfitting, Norm-POEM improves the reliability and robustness of BLBF algorithms, which are critical for applications such as ad placement, recommendation systems, and web search. The faster convergence and better generalization performance of Norm-POEM make it a strong candidate for adoption in real-world systems.
Strengths:
- Identifies and addresses a critical issue (propensity overfitting) in BLBF.
- Provides a novel and theoretically grounded solution using the self-normalized estimator.
- Demonstrates strong empirical performance and computational efficiency.
- Clear writing and well-organized presentation.
Weaknesses:
- While the paper is thorough, the computational trade-offs of the self-normalized estimator could be explored in more detail.
- The method is evaluated only on multi-label classification tasks; additional experiments on other BLBF scenarios would strengthen the generalizability of the results.
Recommendation:
This paper makes a significant contribution to the field of counterfactual learning and BLBF. Its theoretical insights, combined with strong empirical results, advance the state of the art and address a critical limitation of existing methods. I recommend acceptance.