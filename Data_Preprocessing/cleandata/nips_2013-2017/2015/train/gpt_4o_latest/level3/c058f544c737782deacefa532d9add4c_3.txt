This paper investigates several variants of the Frank-Wolfe (FW) optimization algorithm, a method gaining renewed attention for its ability to handle structured constraints in machine learning applications. The authors focus on addressing the slow convergence of the classical FW algorithm, particularly when the solution lies on the boundary of the feasible region. They provide theoretical guarantees of global linear convergence for four FW variants—Away-Steps FW (AFW), Pairwise FW (PFW), Fully-Corrective FW (FCFW), and Wolfe's Minimum Norm Point (MNP) algorithm—under weaker conditions than strong convexity. The paper introduces a novel geometric quantity, the pyramidal width, which, combined with the classical condition number, determines the convergence rate. The authors also connect their findings to practical applications, such as submodular optimization and constrained Lasso problems, and provide empirical evidence supporting their theoretical results.
Strengths:
1. Theoretical Contributions: The paper makes significant theoretical advancements by proving global linear convergence for FW variants under relaxed conditions. This resolves gaps in prior work, which relied on stronger assumptions or incomplete proofs.
2. Novel Insights: The introduction of the pyramidal width as a geometric measure is innovative and provides a deeper understanding of the convergence behavior of FW algorithms.
3. Clarity and Organization: The paper is well-written and logically structured, making it accessible to readers familiar with optimization. The authors provide detailed algorithmic descriptions and proof sketches, which enhance clarity.
4. Relevance to Practice: The authors highlight practical scenarios, such as the flow polytope and L1-ball, where FW variants outperform classical FW. This connection to real-world applications strengthens the paper's significance.
5. Empirical Validation: The experiments demonstrate the improved performance of FW variants, aligning well with the theoretical claims.
Weaknesses:
1. Experimental Section: The experimental results, while illustrative, are limited in scope. The paper would benefit from a more comprehensive evaluation across diverse datasets and problem domains to better establish the practical competitiveness of FW variants.
2. Practical Guidance: While the paper provides theoretical guarantees, it does not sufficiently address when FW variants are preferable to other optimization methods (e.g., projected or proximal gradient methods) in real-world scenarios. A comparative analysis would enhance the paper's utility for practitioners.
3. Minor Errors: There are minor typographical and grammatical errors that require proofreading.
Pro and Con Arguments for Acceptance:
Pros:
- Strong theoretical contributions that advance the understanding of FW algorithms.
- Novel geometric insights with potential implications for complexity theory.
- Clear exposition and connection to practical applications.
Cons:
- Weak experimental section with limited practical guidance.
- Lack of direct comparisons with alternative optimization methods.
Recommendation:
This paper is a strong theoretical contribution to the field of optimization and is well-suited for NIPS. However, the experimental section needs to be expanded, and practical guidance should be improved. I recommend acceptance with minor revisions, focusing on strengthening the empirical analysis and addressing the minor errors.