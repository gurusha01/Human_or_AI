The paper presents a novel approach for unsupervised learning of sentence representations through an encoder-decoder model, termed "skip-thoughts." Inspired by the skip-gram model for word embeddings, the authors propose an objective function that encodes a sentence to predict its surrounding sentences, leveraging the continuity of text in books. The model employs Gated Recurrent Units (GRUs) for both encoding and decoding, enabling the generation of semantically meaningful sentence embeddings. These embeddings are evaluated across eight diverse tasks, including semantic relatedness, paraphrase detection, and sentiment classification, demonstrating competitive or superior performance compared to existing methods.
Strengths:
1. Novelty and Originality: The skip-thought model introduces a new unsupervised objective function for sentence representation learning, extending the skip-gram concept to the sentence level. This is a significant contribution to the field of distributed compositional semantics.
2. Robustness and Versatility: The learned embeddings are shown to generalize well across multiple tasks without task-specific fine-tuning, indicating the robustness of the representations.
3. Thorough Experimental Evaluation: The authors evaluate their method on a wide range of tasks, providing a comprehensive assessment of its effectiveness. The inclusion of a vocabulary expansion method to handle unseen words is a practical enhancement.
4. Clarity and Writing: The paper is well-written and organized, with clear explanations of the model architecture, training procedure, and experimental setup.
Weaknesses:
1. Computational Efficiency: The use of GRUs for both encoding and decoding makes the model computationally expensive, particularly when compared to simpler methods like paragraph vectors. Training time (two weeks) is a notable concern for scalability.
2. Experimental Clarity: The results section lacks transparency regarding whether some reported numbers are reproduced or borrowed from the literature. Explicitly distinguishing between these would improve reproducibility and clarity.
3. Limited Qualitative Analysis: While Table 4 provides examples of semantic relatedness, extending it to include cases where the model improves on semantically similar but lexically dissimilar sentences would better illustrate the model's strengths.
4. Performance on Classification Tasks: On classification benchmarks, skip-thought vectors underperform compared to supervised models tuned for specific tasks, highlighting a limitation in capturing task-specific nuances.
Recommendation:
The paper makes a strong scientific contribution by proposing a novel and effective method for unsupervised sentence representation learning. Despite concerns about computational efficiency and some experimental clarity, the strengths outweigh the weaknesses. The method's robustness across tasks and its potential for further exploration (e.g., deeper encoders, larger context windows) make it a valuable addition to the field. I recommend acceptance with minor revisions to address the clarity of experimental results and provide additional qualitative examples.
Arguments for Acceptance:
- Novel and impactful contribution to unsupervised sentence representation learning.
- Strong empirical results across diverse tasks.
- Well-written and comprehensive in scope.
Arguments Against Acceptance:
- High computational cost may limit practical applicability.
- Lack of clarity in experimental reproducibility.
- Limited qualitative insights into specific strengths of the model. 
Overall, the paper advances the state of the art in unsupervised learning of sentence embeddings and is a strong candidate for inclusion in the conference.