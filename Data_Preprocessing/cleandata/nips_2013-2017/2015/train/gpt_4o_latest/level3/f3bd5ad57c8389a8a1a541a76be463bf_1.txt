The paper presents Stochastic Expectation Propagation (SEP), a novel extension to Expectation Propagation (EP) aimed at addressing EP's memory constraints in large-scale Bayesian learning. SEP combines the local approximation benefits of EP with the global approximation benefits of Variational Inference (VI), significantly reducing memory consumption while maintaining competitive accuracy. The authors demonstrate SEP's performance on synthetic and real-world datasets across various models, including Bayesian probit regression, mixtures of Gaussians, and probabilistic backpropagation.
Strengths:  
The paper tackles a significant limitation of EP—its memory overhead scaling with the dataset size \(N\)—and proposes a promising solution. SEP is shown to reduce memory consumption by a factor of \(N\), making it feasible for large-scale applications. The idea of tying approximating factors into a global factor is innovative and well-motivated. The authors provide a clear connection between SEP and related methods, such as VI, stochastic VI, and assumed density filtering (ADF), situating SEP within the broader landscape of Bayesian approximation techniques. Experimental results demonstrate that SEP achieves accuracy comparable to EP while significantly reducing memory requirements, particularly in large-scale settings like probabilistic backpropagation. The paper also highlights SEP's flexibility in handling latent variable models and its potential for parallelization and distributed computation.
Weaknesses:  
The paper, while promising, requires substantial improvements in clarity and experimental rigor to appeal to a NIPS audience. Key sections, such as Section 5.3, lack sufficient technical detail, making it difficult to assess the experimental setup and results. The use of approximate KL divergence as a metric in Bayesian probit regression is unclear; comparisons with more standard methods like Stan/NUTS would provide stronger validation. The switch to F-norm in the mixture of Gaussians experiments is unexplained, leaving the rationale for this choice ambiguous. Additionally, Figure 3(c) comparing SEP and DSEP is confusing and requires clarification. The empirical analysis does not adequately explore failure cases or limitations of SEP, which would provide a more balanced evaluation. Figures like Figure 2 add little value and could be replaced with expanded discussions in Sections 3 and 4.1.
Clarity and Editorial Issues:  
The paper suffers from several clarity issues. DAEP in Figure 3(b) is not discussed, leaving the reader uncertain about its relevance. The grammar and phrasing in some sections are suboptimal, and there are vague paragraphs that hinder comprehension. Misplaced figures and unclear metrics further detract from the paper's readability. Citations are incomplete or incorrect in some cases, which undermines the paper's scholarly rigor.
Originality and Significance:  
The proposed method is original and addresses an important problem in scaling EP to large datasets. However, the empirical story is underwhelming, as the experiments do not convincingly demonstrate SEP's superiority over existing methods. While the memory savings are significant, the lack of a thorough exploration of SEP's limitations and failure cases weakens the paper's overall impact.
Recommendation:  
The paper presents an innovative and potentially impactful method, but it requires significant revisions before acceptance. The authors should:  
1. Improve the clarity and technical depth of key sections, particularly the experimental analysis.  
2. Provide stronger empirical validation through comparisons with standard baselines like Stan/NUTS and a more detailed exploration of failure cases.  
3. Address editorial issues, including grammar, vague paragraphs, and misplaced figures.  
4. Clarify confusing comparisons (e.g., Figure 3(c)) and justify metric choices (e.g., F-norm).  
Pro and Con Arguments:  
- Pro: Original and well-motivated solution to EP's memory constraints; significant memory savings; competitive accuracy with EP.  
- Con: Insufficient experimental depth; unclear metrics and comparisons; poor clarity and organization in key sections.  
Overall Impression:  
The paper has potential but requires substantial improvements in empirical analysis, clarity, and editorial quality to meet the standards of a NIPS audience.