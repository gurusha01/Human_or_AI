This paper addresses the estimation of sparse graphical models for high-dimensional tensor-valued data, proposing a novel alternating minimization algorithm for precision matrix estimation under the assumption of a tensor normal distribution. The authors demonstrate that their approach achieves optimal statistical rates of convergence and consistent graph recovery, even with a single tensor sample. The work builds on existing literature in sparse matrix graphical models and tensor decomposition, extending these frameworks to handle higher-order tensor data. The proposed method, termed Tensor Lasso (Tlasso), is computationally efficient and theoretically robust, with extensive simulations validating its performance against alternative methods.
Strengths:
1. Clarity and Presentation: The paper is clearly written, with well-defined symbols and mathematical rigor, making it accessible and enjoyable to read. The theoretical contributions are presented systematically, and the numerical experiments are well-documented.
2. Theoretical Contributions: The authors provide strong theoretical guarantees for their alternating minimization algorithm, including optimal rates of convergence in Frobenius, max, and spectral norms. The equivalence between tensor normal and multi-dimensional normal distributions is a key insight that could have broader implications.
3. Novelty and Generalization: The problem formulation generalizes the standard sparse precision matrix estimation to higher-order tensors, addressing practical challenges in fields like fMRI and recommendation systems. The ability to achieve estimation consistency with a single tensor sample is a significant advancement over prior work.
4. Empirical Validation: The simulations demonstrate the computational efficiency and accuracy of Tlasso compared to existing methods, such as Glasso and P-MLE. The results are compelling and support the theoretical claims.
Weaknesses:
1. Motivation for Practical Use: While the theoretical contributions are strong, the paper lacks sufficient motivation for why the proposed model is more suitable for practical problems. For instance, it would benefit from a more detailed discussion of real-world scenarios where the tensor normal distribution assumption and Kronecker product structure are valid.
2. Emphasis on Key Insights: The equivalence between tensor normal and multi-dimensional normal distributions is a critical quantitative relationship but is underemphasized in the narrative. Highlighting its implications could enhance the paper's impact.
3. Complexity of the Model: The non-convexity of the objective function and the reliance on alternating minimization may raise concerns about scalability and robustness in extremely high-dimensional settings, which are not fully addressed.
Recommendation:
The paper is recommended for acceptance due to its strong theoretical and technical contributions. The generalization of sparse precision matrix estimation to tensor data and the novel algorithmic approach represent a meaningful advancement in the field. However, the authors should consider revising the manuscript to better motivate the practical relevance of their model and emphasize the broader implications of their theoretical findings. Addressing these aspects would further strengthen the paper's contribution to both theory and application.