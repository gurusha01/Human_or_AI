The paper investigates several variants of the Frank-Wolfe (FW) algorithm for constrained convex optimization, focusing on strongly convex and partially strongly convex objectives over polyhedra. The authors make a significant contribution by proving global linear convergence for these variants—away-steps FW, pairwise FW, fully-corrective FW, and Wolfe's minimum norm point (MNP) algorithm—under conditions weaker than strong convexity. A key innovation is the introduction of the "pyramidal width," a geometric quantity that complements the classical condition number of the objective function. This novel concept has potential implications for complexity theory and optimization over polytopes.
The paper is technically sound and addresses an important problem in optimization, particularly for machine learning applications where structured constraints are common. The results are supported by rigorous theoretical analysis and supplemented with illustrative experiments. However, there are several areas where the paper could be improved. 
Strengths:
1. Novelty and Significance: The linear convergence result for FW variants under weaker conditions is a notable advancement. The introduction of pyramidal width as a geometric measure is both innovative and potentially impactful.
2. Comprehensive Analysis: The paper provides detailed proofs for convergence and discusses the implications of the pyramidal width in depth.
3. Practical Relevance: The algorithms are applied to real-world problems, such as constrained Lasso and video co-localization, demonstrating their utility.
4. Clarity of Contributions: The paper clearly delineates its contributions compared to prior work, addressing gaps in existing results.
Weaknesses:
1. Affine Invariance: The emphasis on affine invariance is intriguing but underexplored. The claims regarding surjectivity and related properties require further clarification.
2. Proof Issues: The proof of Theorem 3 has ambiguities, particularly in the interpretation of KKT conditions. This weakens the theoretical rigor.
3. Practical Challenges: The MNP variant, while theoretically interesting, is impractical due to its reliance on affine hull minimization and complex line search constraints.
4. Partially Strongly Convex Case: The treatment of this case is underdeveloped, with insufficient discussion of constants and convergence rates.
5. Comparison with Prior Work: The discussion of differences with prior work, such as [4] and [12], is limited. The claim about resolving an open problem from [12] appears inaccurate.
6. Writing and Presentation: The paper contains typos, unclear notations, and overly dense arguments. Figure 2 is difficult to interpret, and inconsistent notations in the appendix (e.g., for \(r\) and \(y\)) detract from readability.
Recommendation:
While the paper makes a strong theoretical contribution, the issues with clarity, proof rigor, and practical applicability temper its impact. I recommend acceptance with major revisions, contingent on addressing the following:
1. Clarify the notion of affine invariance and its implications.
2. Revise the proof of Theorem 3 for greater transparency.
3. Expand the discussion on partially strongly convex functions and their convergence rates.
4. Improve the writing, figures, and notations for better readability.
Pro and Con Arguments:
Pros:
- Advances understanding of FW variants with linear convergence.
- Introduces the novel concept of pyramidal width.
- Demonstrates practical relevance through experiments.
Cons:
- Proof ambiguities and unclear theoretical claims.
- Practical limitations of certain algorithmic variants.
- Writing and presentation issues.
Overall, the paper is a valuable contribution to the field but requires significant refinement to maximize its impact.