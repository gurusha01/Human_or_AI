This paper introduces a bidirectional recurrent convolutional network (BRCN) for multi-frame video super-resolution (SR), leveraging convolutional recurrent transitions to model temporal dependencies efficiently. The authors propose replacing traditional recurrent full connections with weight-sharing convolutional connections and introducing "conditional convolutions" to enhance visual-temporal dependency modeling. The method achieves state-of-the-art results while significantly reducing computational costs compared to existing multi-frame SR methods.
Strengths:  
The paper addresses a relevant problem in video SR by proposing a novel approach that avoids computationally expensive motion estimation. The use of convolutional recurrent transitions is well-motivated, and the bidirectional architecture effectively captures temporal dependencies from both past and future frames. The experimental results demonstrate clear improvements in both performance and efficiency, with the proposed method outperforming existing multi-frame SR approaches in terms of PSNR while being orders of magnitude faster. The ablation study further validates the contributions of individual components, such as recurrent and conditional convolutions, to the overall performance. The visualization of learned filters provides additional insight into the model's behavior. 
Weaknesses:  
1. Terminology: The term "conditional convolution" is misleading, as there is no actual conditioning mechanism involved. This could confuse readers and should be clarified or renamed.  
2. Clarity for Non-Experts: The explanation of motion-based methods, such as optical flow, is insufficient for readers unfamiliar with the topic. A brief overview would enhance accessibility.  
3. Second Hidden Layer: The detailed description of the second hidden layer is unnecessary and detracts from the paper's focus. Simplifying this section would improve readability.  
4. Abrupt TRBM Comparison: The comparison with Temporal Restricted Boltzmann Machines (TRBM) is introduced abruptly in Section 3.2. If this comparison is significant, it should be introduced earlier with proper context.  
5. Impact and Scope: While the application is interesting and achieves strong results, its impact on the broader NeurIPS community may be limited. The work appears more suited to a computer vision conference, given its focus on video SR and practical implementation rather than advancing fundamental machine learning techniques.
Pro and Con Arguments for Acceptance:  
- Pro: The paper presents a novel and efficient approach to video SR, achieving state-of-the-art results. The method is well-executed, with strong experimental validation and practical relevance.  
- Con: The limited scope and focus on video SR may not align well with the broader NeurIPS audience. Additionally, some aspects of the paper, such as terminology and clarity, require refinement.
Recommendation:  
The paper is technically sound and offers a valuable contribution to video SR. However, its scope and focus make it better suited for a computer vision conference. If submitted to NeurIPS, the authors should address the clarity issues, refine terminology, and better contextualize the TRBM comparison.