This paper introduces a novel Gaussian Process (GP)-based Bayesian optimization algorithm, termed Infinite-Metric GP Optimization (IMGPO), which achieves exponential convergence without requiring auxiliary optimization or the impractical δ-cover sampling procedure. The authors address a significant challenge in Bayesian optimization by eliminating these computational bottlenecks while maintaining strong theoretical guarantees. The paper builds on prior work, such as GP-UCB and BaMSOO, and demonstrates notable improvements in regret bounds, advancing the state of the art in global optimization.
The paper is well-written and didactic, with clear explanations of the methodology and effective use of graphs to illustrate experimental results. The theoretical analysis is rigorous, and the experimental results convincingly demonstrate the advantages of IMGPO over existing methods across a range of benchmark functions. The authors also provide insightful remarks on the trade-offs between relying on specific bounds versus considering infinitely many possible bounds, which enriches the broader understanding of bound-based optimization methods.
However, there are several areas for improvement. First, the abstract is somewhat redundant and could be streamlined to focus on the key contributions and results. For example, the repeated emphasis on eliminating δ-cover sampling could be condensed. Second, there are minor technical issues in the manuscript, such as the unclear definition of the function on line 49 and a misplaced parenthesis on line 72. These should be corrected for clarity. Additionally, while the paper is accessible to readers familiar with Bayesian optimization, it assumes a strong background in Gaussian Processes (GPs) and global optimization. As a reviewer unfamiliar with these topics, my evaluation is based on an educated guess, and I recommend the authors include a more detailed background section to make the paper accessible to a wider audience.
In terms of quality, the paper is technically sound, with claims well-supported by both theoretical analysis and experimental results. The clarity of the writing and organization is commendable, though minor issues should be addressed. The originality of the approach is evident, as the authors tackle a long-standing open problem in GP-based optimization. The significance of the results is high, as the proposed method has the potential to impact both theoretical research and practical applications in optimization.
Arguments for acceptance:
- The paper addresses an important and challenging problem in Bayesian optimization.
- Theoretical and experimental results convincingly demonstrate the superiority of the proposed method.
- The writing is clear and didactic, with effective use of visual aids.
Arguments against acceptance:
- Minor technical issues (e.g., unclear function definition, misplaced parenthesis) need to be resolved.
- The abstract could be more concise.
- The paper assumes familiarity with GPs and global optimization, which may limit its accessibility.
Overall, this paper makes a strong contribution to the field of Bayesian optimization and is recommended for acceptance, provided the minor issues are addressed.