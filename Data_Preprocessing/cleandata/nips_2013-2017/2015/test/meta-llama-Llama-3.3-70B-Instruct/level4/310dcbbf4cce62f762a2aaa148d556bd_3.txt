This manuscript examines a contextual bandit problem with a budget constraint B and a known time horizon T. At each trial, the agent encounters a context j, which is selected from a set {1,..,J} according to a fixed probability distribution π, and chooses an action k from the set {0} ∪ {1,..,K}, where 0 denotes "skip". If the agent selects k = 0, it receives no reward and incurs no cost. For k > 0, the agent obtains a reward y, which is drawn from a fixed probability distribution over [0,1] that depends on j and k, and incurs a cost c{j,k}, where c{j,k} is a known positive parameter. The agent's objective is to maximize the cumulative reward while ensuring that the cumulative cost does not exceed the budget B.
The majority of the paper focuses on a special case where π is known and c{j,k} = 1 for all j and k. In this scenario, the authors propose an algorithm with a regret bound of O(log T) under a mild condition. The paper also extends this algorithm to the more general case where π is unknown and c{j,k} values are arbitrary.
Notably, a more general setting has been explored in [16], but the algorithm presented therein has a regret bound of O(√T). Thus, this paper potentially presents the first work to achieve an O(log T) regret bound, albeit under a mild condition. The algorithm is rooted in an approximation method for computing the optimal action sequence when all statistical parameters are known. Although the algorithm is straightforward, it is highly intriguing.
The paper is well-motivated and clearly written. However, it would be more significant if the O(log T) regret bound held universally; otherwise, proving an Ω(√T) lower bound for boundary cases would be valuable.
Initially, I had concerns regarding the correctness of Lemma 1, which underpins all the results. Specifically, I questioned whether the optimal action sequence always satisfies condition (2) for all trials and whether the average constraint truly represents a relaxed version of the hard constraint. Following the rebuttal, my concerns regarding Lemma 1 have been addressed.
Some minor points to consider: Is determining the optimal action sequence exactly NP-hard? Can the results be extended to scenarios where T is unknown? Is it valid to assume u^1 > u^2 > ... > u^*_J without loss of generality, even in cases with an unknown context distribution? I strongly recommend accepting this paper.