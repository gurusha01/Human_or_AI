This paper explores iterative stochastic policy optimization, providing a bound on the expected cost of executing a new stochastic policy, regardless of the policy update method, using samples from a previous policy. The bound is demonstrated through an example of aerial vehicle navigation.
In terms of quality, the results indicate a significant improvement over the original policy, reducing the predicted collision rate from 50% to 10%. However, it would be beneficial to understand how the original policy was selected, as a 50% collision probability seems unusually high. The authors should provide evidence that a well-chosen set of control parameters cannot achieve better performance than the original policy.
The choice of alpha in Line 245 appears to impact the tightness of the bound, and it is unclear whether the closed-form solution is the optimal choice. 
Regarding clarity, Section 2.1 seems disconnected from the rest of the paper, and the concepts presented in the discrete-time dynamics are not well-linked to the subsequent discussion. The equivalence between the stochastic optimization problems mentioned in Line 105 is unclear, and the authors should elaborate on this point. Additionally, the stochastic problems presented in Lines 107 and 110 bear similarities to chance-constrained control, and the authors should discuss these similarities, potentially referencing relevant works such as Schwarm and Nikolaou (1999).
The figure text is too small to be readable, and the legends for figures 2(b), 2(c), 3(b), and 3(c) have three lines, but the blue line is not visible. The discussion of the results in Section 4 could be improved, as the current explanation does not provide sufficient insight into the plots.
In terms of originality, the authors acknowledge the challenge of obtaining bounds for the cost due to the unbounded change-of-measure likelihood ratio, making approaches based on Hoeffding's inequality impractical. They propose an alternative based on Catoni's work, but this reduces the apparent originality of the paper, as it relies heavily on prior research.
The significance of the result lies in its potential to enable the development of algorithms that yield robust policies, where the resulting cost will not exceed a known cost with high probability.
Some minor points to consider include referencing more relevant papers for robust MPC, such as the survey by Ma et al. The authors have tackled an interesting problem with a well-performing algorithm, but improving the presentation of the figures and discussion of the results would greatly enhance the paper's utility.