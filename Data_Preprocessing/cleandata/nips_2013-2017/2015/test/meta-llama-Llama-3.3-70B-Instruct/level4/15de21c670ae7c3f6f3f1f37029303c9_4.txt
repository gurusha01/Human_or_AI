Comments on Quality:
The paper presents convergence rates of learning algorithms in relation to mixing times, yielding meaningful and useful bounds. However, a notable limitation is that the lower bound (Theorem 7) is challenging to comprehend, warranting a more detailed explanation of the theorem and a broader discussion on applicable lower bounds to enhance understanding.
Comments on Clarity:
The overall presentation is well-organized and easy to follow.
Comments on Originality:
The formulation of the problem within the "fast mixing" model class and the accompanying theoretical findings appear to be novel contributions.
Comments on Significance:
While the significance of the work is not immediately apparent, it seems to address a knowledge gap in the literature concerning the use of MCMC for learning intractable models, thereby possessing some degree of significance. To strengthen the submission, a more in-depth analysis of its potential impact, including potential future extensions and opportunities for building upon the research, would be beneficial. The introduction of a new class of tractable models based on the approximability of expectations via MCMC, coupled with the novel theoretical results on convergence rates for learning these models, renders the submission noteworthy and worthy of acceptance.