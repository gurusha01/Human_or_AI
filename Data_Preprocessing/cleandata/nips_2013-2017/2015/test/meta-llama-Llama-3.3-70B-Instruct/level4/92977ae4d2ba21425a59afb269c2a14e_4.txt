This paper explores the challenges associated with the EM-algorithm in high-dimensional settings, where the M-step can become intractable or unstable. To address this, a regularization method is proposed, with the crucial aspect being the identification of an effective sequence of regularization coefficients to manage statistical error. The convergence of this method is established under specific conditions related to initialization, regularization penalty, and likelihood. The paper then examines three latent variable models and presents some simulation results.
Overall, the paper is well-motivated and presents a solid theoretical foundation. 
Some potential areas for improvement include: (1) providing a more in-depth discussion on the impact of the initialization parameter $\lambda_n^{(0)}$ and the contractive factor $\kappa$; (2) clarifying the connection between the theoretical framework, which focuses on Algorithm 2, and Algorithm 1, and considering the addition of simulation results for Algorithm 2; (3) enhancing Figure 1 to better illustrate its intended point, possibly demonstrating the convergence of the algorithm, and increasing the font size in figures for improved readability; (4) incorporating comparisons, either theoretical or simulation-based, with other methods, such as those outlined in [20], to further contextualize the proposed approach.
Additionally, there are a few typographical errors to correct, including those in the abstract and equation (2.2), where $y{\beta^}$ should be $f{\beta^}$ and $\log{\beta'}$ should be $\log f{\beta'}$. The paper effectively proposes a regularized EM algorithm with varying regularization coefficients for solving high-dimensional latent variable problems, with clear explanations of theory and examples, although the simulation section could be enhanced.