This paper presents a notable contribution by introducing a method to learn logarithmic online multiclass trees, which enhances the efficiency of multiclass prediction. The authors effectively explain the underlying principle of LOMTree and its advantages over one-vs-all (OAA) classifiers. They propose a straightforward objective function to achieve a maximally pure and balanced partition at each node. The overall tree quality is measured using an entropy function, and the algorithm is proven to converge to a tree with log(k) complexity. Experimental results on various datasets, ranging from 26 to 105k classes, demonstrate reasonable training and testing times.
The paper is well-written, although dense, and the proposed approach is innovative, comparing favorably to other tree-based classifiers while closely matching OAA performances. A few suggestions for improvement are noted: 
- The illustrative example of node construction in the supplementary material is exceptionally clear and would be more effective if included in the main paper, potentially alongside the algorithm.
- The online estimation of linear classifiers h at each node could be clarified by specifying whether the update involves a stochastic gradient with respect to J(). Additional details would significantly enhance the reproducibility of the research.
- The numerical experiments, although convincing, are somewhat brief. Including the performance of OAA classification in Table 4, at least for the smaller datasets, would facilitate comparison and provide a more comprehensive overview.
Overall, the paper offers an engaging and novel algorithm for constructing an efficient tree-based classifier, supported by a compelling theoretical study and numerical experiments.