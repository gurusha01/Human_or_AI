This manuscript presents a novel application of proximal algorithms for variational inference, showcasing the interpretation of natural gradient methods as a proximal point algorithm and extending proximal gradient methods, also known as mirror-descent, to non-conjugate settings.
The authors demonstrate the efficacy of their approach on real datasets for regression and classification tasks using non-conjugate models, highlighting the potential of this method.
Overall, the paper is well-written and would be a valuable contribution to the NIPS proceedings, offering a fresh perspective on variational inference.
To further enhance the manuscript, it would be beneficial for the authors to cite the recent work by Theis and Hoffman, "A trust-regions method for stochastic variational inference with applications to streaming data", as their method can be viewed as a proximal point method, closely related to the one derived in this paper.
Additionally, a discussion on the connection between mirror-descent and Bayes theorem-like updates, particularly in the context of equations 11, 12, and 13, would be insightful, especially when considering the case where \beta^k = 1.
The transition from the proximal point viewpoint to the proximal gradient methods could be smoothed out with a more detailed explanation, providing clarity for readers.
It is also worth noting that a thorough proof-read is necessary to address the numerous grammatical and mathematical typos present in the manuscript.
In conclusion, despite some minor criticisms, this paper presents a significant contribution to the field, leveraging proximal algorithms for variational inference in non-conjugate settings, and would be a great fit for the NIPS proceedings, with its nicely written content and valuable insights.