The authors propose a novel system for predicting video frames in ATARI games, taking into account the actions performed within the game. The key innovation lies in the introduction of a multiplicative transformation layer, which selectively applies weights based on the action vector provided. To ensure scalability, the weight tensor is factorized, and image encoding and decoding are handled by a established convolutional network architecture.
Two distinct architectures are presented: a feed-forward network that processes a fixed number of preceding frames and a recurrent network that utilizes a single frame, augmented by an LSTM layer preceding the transformation layer. It would be beneficial for the authors to explicitly define LSTM and its expansion, at least once in the paper, for clarity.
The qualitative evaluation of generated frames, as demonstrated in the supplementary videos, is compelling. The quantitative assessment, using mean squared pixel error, is clearly presented, although it is unsurprising that the proposed system outperforms linear and nonlinear predictors that do not account for game actions.
An additional experiment, where generated frames are used as input for a DQN agent instead of real frames, yields expected results. The performance is inferior to that achieved with real input frames but surpasses random play, with the proposed system outperforming no-action predictors.
A noteworthy application of this system is its potential to enhance exploration during agent training. By selecting actions that lead to predicted frames with the least similarity to previously encountered frames, rather than random actions, the final performance is significantly improved in certain games.
Furthermore, the system can be employed to automatically analyze game dynamics. Game actions with similar effects can be identified through similarities in the transformation weight matrix, and the system can estimate which image pixels are directly controlled by actions and which are governed by uncontrollable game dynamics.
The authors claim that, to their knowledge, this paper is the first to make and evaluate long-term predictions on high-dimensional video conditioned by control inputs. Although this may be true, particularly in the context of LSTM usage, it is worth noting that earlier work, such as a 1991 paper by Schmidhuber and Huber, explored similar concepts using neural predictors to forecast the next visual input frame of a fovea, given previous input and action, within a reinforcement learning framework. Schmidhuber's subsequent papers at IJCNN 1990 and NIPS 1991 also featured recurrent predictors and action generators, albeit without LSTM. It would be beneficial for the authors to highlight the distinctions between their system and prior work, including the use of different reinforcement learning methods.
The results are clear, and the paper is well-structured. With minor revisions, as suggested above, the paper is recommended for acceptance. The proposed architecture for video frame prediction in ATARI games, based on game actions, yields promising results, particularly in improved exploration during agent training and a simple analysis of game dynamics.