The manuscript proposes a hierarchical model of count vectors, leveraging Poisson Factor Analysis at each layer to extract interpretable topics, and binary units to capture topic correlations between layers. Notably, the use of Markov Chain Monte Carlo (MCMC) and Stochastic Variational Inference (SVI) enables straightforward inference, with all conditional posteriors in closed form, allowing the model to scale with the number of non-zero observations and hidden units. This approach represents an incremental advancement over existing work, such as Zhou et al. (2012), by removing the global beta-Bernoulli process and incorporating the Bernoulli-Poisson link to circumvent the need for sigmoid belief networks.
Both the proposed model and its inference methodology are characterized by their elegance and simplicity. Although the model builds upon prior research, its potential impact on the scientific community should not be underestimated. 
1. The experimental evaluation undertaken in the paper focuses primarily on comparative analyses with other deep and single-layer models. However, a more in-depth exploration of the proposed model's intrinsic properties is noticeably lacking.
 a. The methodology used to determine the layer widths is not clearly outlined. Were multiple layer configurations, including those beyond two layers, thoroughly investigated?
 b. How does the model account for overdispersion in the data, a common phenomenon that can significantly affect model performance?
 c. What guidance is offered on how the layer widths should be adjusted as the model depth increases?
2. The superior performance of even the single-layer model over ORSM and LDA (which shares similarities with PFA) is striking. Is this attributable to the discriminative approach to topic modeling employed? Unfortunately, the paper does not provide a satisfactory explanation for this observation.
3. The omission of ORSM from Table 1 is puzzling. The paper introduces a refinement to existing deep network topic models by integrating concepts from Zhou et al. (2012) and Zhou et al. (2015), demonstrating how a hierarchy of Poisson Factor Analysis units can be interconnected using hidden binary units. While the contribution may be considered incremental, the simplification of both MCMC and variational inference due to local conjugacy, coupled with the experimental results showing improved performance, is noteworthy. A significant limitation of the paper, however, is the lack of a comprehensive experimental investigation into the model's structural parameters, which appear to be fixed arbitrarily. Despite this, the work is likely to garner considerable interest from both the deep learning and topic modeling communities.