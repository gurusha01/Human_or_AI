The submission introduces a modified proximal gradient algorithm for variational Bayes. The algorithm turns out to be equivalent to natural gradient descent with a certain choice of step sizes.
 Comments on Quality:
The quality of the ideas in the paper is high, though not without flaws. The proximal gradient framework provides a clean way to deal with nonconjugacy and the equivalence to natural gradient descent serves as a justification and a useful link to a widely accepted method.
 The flaws as far as ideas go are as follows. (1) As the authors note, the algorithm is actually not a proximal gradient algorithm because the KL term goes the wrong way. The motivation for doing things this way appears to be efficiency (the optimization problem decouples across parameters in the authors' setup, but not in the true proximal gradient setup). (2) Because of issue 1, the algorithm cannot be shown to converge except in special cases (e.g. beta_k --> 0 fast enough and in fact that seems necessary and sufficient).
Unfortunately, the submission does not sufficiently analyze the algorithm to demonstrate its utility. The primary argument for the algorithm appears to be potentially improved results in practice. Yet, the performance gains seem too small to justify the order of magnitude increase in runtime required to use the authors' method. Much stronger results, showing substantial improvements over the mean field baseline, would be necessary to make the submission compelling enough for acceptance.
On the whole, the reviewer believes the work has potential, but that it is too preliminary to be published in the conference.
Comments on Clarity:
Most of the paper is presented clearly, apart from Sections 5-6, which are nearly impossible to follow. The reviewer suggests the authors revise these to make them easier to understand.
Comments on Originality:
The work appears original.
Comments on Significance:
For now, the significance appears low. The algorithm could, however, have meaningful practical significance---further experiments are required to determine that. The proximal gradient variational Bayes algorithm proposed in the submission is intriguing and warrants further investigation. The results presented in the submission, however, are not strong enough to justify accepting the paper.