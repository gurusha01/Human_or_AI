The paper introduces the difficulty of EM-algorithm in high-dimensional setting, where M-step can be unsolvable or unstable. Then regularization method is proposed, the key to which seems to be finding a good sequence of regularization coefficients to control the statistical error. Convergence is proved given condition on the initialization, regularization penalty and the likelihood. 3 latent variable models are then analyzed and some simulation result is provided.
Overall it is a good paper which is well motivated with nice theory.
A couple of thoughts: (1) more discussion about the effects of the initialization parameter $\lambda_n^{(0)}$ and contractive factor $\kappa$ can be helpful (2) the theory actually deals with algorithm 2, it might be good to clarify how the theory is linked to algorithm 1. It may also be interesting to show some simulation result for algorithm 2 (3) not sure about what figure 1 is trying to illustrate (probably that the algorithm does converge?). Also the font size for figures should be improved (4) some comparison (either in theory or in simulation) with competing methods (say [20]) can be helpful
Typo: abstract (e.g. a la[19]) equation (2.2) y{\beta^} should be f{\beta^}; \log{\beta'} should be \log f{\beta'}  Good paper that proposes solving high-dimensional latent variable problems using regularized EM algorithm with varying regularization coefficients. Theory and examples are well explained but simulation part can be improved