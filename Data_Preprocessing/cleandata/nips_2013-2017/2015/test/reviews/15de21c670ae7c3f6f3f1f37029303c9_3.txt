A key problem in Markov networks is weight learning, which is often defined as finding a setting of weights (attached to the features) such that the likelihood is maximized. Typically, a gradient descent algorithm is used to learn the weights and a key sub-task in this algorithm is computing the gradient. Since the latter is NP-hard in general, MCMC algorithms are often employed in lieu of exact algorithms to compute it.
The paper derives theoretical results showing that if the weights (parameters) are such that MCMC converges quickly to the stationary distribution on them, then the weight learning algorithm (that uses MCMC to compute the gradient) is a FPRAS. The paper considers two cases: unregularized case (convex case) and ridge-regularized case (non-convex case), and derives separate bounds for each.
The paper is generally well written with a few typos here and there. I was not able to verify all the proofs, however, they look plausible.
Although, the theoretical results look impressive, they are of little to no practical relevance (I like that the authors acknowledge this). I think it is virtually impossible to ensure that the parameters satisfy the constraints required by the theorems. Have the authors given this any thought? Specifically, whether it is possible to enforce this condition artificially (the condition can be seen as a form of regularization and actually using ridge regression in addition to it may yield over-regularized models). If this latter problem can be solved, together with these theoretical results, you have a very strong paper.
Overall, a reasonably well-written paper that formalizes the conditions under which using MCMC for weight learning (with and without regularization) yields a FPRAS. However, this condition is of little to no practical relevance. Non-trivial research problems need to be addressed before the results derived in the paper can yield a practical/accurate algorithm for weight learning.
 A reasonably well-written paper that formalizes the conditions under which using MCMC for weight learning (with and without regularization) yields a FPRAS. However, this condition is of little to no practical relevance. Non-trivial research problems need to be addressed before the results derived in the paper can yield a practical/accurate algorithm for weight learning.