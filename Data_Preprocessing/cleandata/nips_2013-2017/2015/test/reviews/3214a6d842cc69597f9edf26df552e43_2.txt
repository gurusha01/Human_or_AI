This paper presented the use of proximal algorithms to perform variational inference.
The authors showed that natural gradient methods can be interpreted as a proximal point algorithm and also used proximal gradient methods (a.k.a mirror-descent) to non-conjugate settings.
The algorithm was demonstrated on non-conjugate models for regression and classification on real data sets.
Overall, this is a very nice paper that would be a great addition to the NIPS proceedings.
I think that the authors should definitely reference the recent work of Theis and Hoffman "A trust-regions method for stochastic variational inference with applications to streaming data" as their method is the proximal point method derived in this paper (though they do not explicitly say it's a proximal point method).
Additionally, there has been some recent work relating mirror-descent to Bayes theorem-like updates which Eqs. 11, 12, and 13 essential are (if \beta^k = 1), so some discussion of this would be nice as well.
Also, there's a somewhat abrupt transition from the proximal point viewpoint of variational inference to using proximal gradient methods and an explanation of this transition would be very helpful.
Lastly, there are a good amount of typos, both grammatical and mathematical, that definitely should be fixed with a careful proof-read.
Again, I think that this is a great paper that would fit in nicely at NIPS. This is a nicely written paper that uses proximal algorithms to perform variational inference and is applicable to non-conjugate settings.Other than some small criticisms I think that the paper would be a nice addition to the NIPS proceedings.