The paper easy to read and easy to understand in big strokes the ideas and the message it conveys. However I found that the authors sometimes (maybe to improve readability) skip certain details. It is not obvious how important these details are , but makes a quick reproducible of the results hard.
I will point out a few things that I would like the authors to be more clear about:
* specify in more details the model ! Is not clear how the decoder is symmetric to
 the encoder. How do you upsample as you go down?
 * what learning procedure was used to train the generative model (SGD,
 SGD+momenum, RMSprop, Adam, Ada-delta, Adagrad .. to name just a few of
 the more popular approaches) ?
* For the LSTM was there any clipping used (most LSTM models out there rely
 on gradient clipping for stability)
* What learning rate, momentum etc. was used. Where this chosen based on
 intuition, or did the authors run a grid search (or random sampling of
 the hyper-parameters)
* How is the data constructed more exactly? Was there any pruning used to
 make sure that you get enough frames from each stage of a game (the image
 statistics early on are potentially very different from later e.g.
 pacman and might require balancing the dataset)?
What is the average episode length (compared to the average length of the movie you can generate)?
* is the curriculum learning (going from 1,3,5 frames in the future)
 necessary? Does it result in more stable generation? Was this validated
 experimentally?
* the authors claim that the action should have a multiplicative
 interaction, which I think is a reasonable assumption. Has this fact been
 verified experimentally though? Given that the task is novel, it is hard
 to judge how important these bits are.  The paper is well written, though occasionally lacks details of the exact experimental procedure which most probably makes the result un-reproducable. The results are impressiveand the authors make some interesting observations and analysis about the behavior of their model.