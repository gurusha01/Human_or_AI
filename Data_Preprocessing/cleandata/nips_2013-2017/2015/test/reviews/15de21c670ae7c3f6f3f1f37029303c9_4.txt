Comments on Quality:
The results give rates of convergence of learning algorithms in terms of mixing times. The bounds appear meaningful and useful.
 The only significant complaint is that the lower bound (Theorem 7) is very difficult to interpret. An expanded discussion of the theorem and, more generally, the lower bounds applicable to the problem, would be desirable.
Comments on Clarity:
The presentation is clear.
Comments on Originality:
Both the framing of the problem (in terms of the "fast mixing" model class) and the theoretical results appear original.
 Comments on Significance:
The significance is unclear to the reviewer. It does seem that the paper fills a gap in the literature on learning intractable models using MCMC, and in this sense it does seem significant.
 The submission would be improved by further discussion of the work's potential impact (including future extensions and opportunities to build on it). The submission introduces a novel class of tractable models based on good MCMC-based approximability of expectations. The theoretical results giving convergence rates for learning these models appear novel and interesting, and the submission should therefore be accepted.