This paper addresses a critical challenge in the inference of Determinantal Point Processes (DPPs), specifically the computational bottlenecks associated with likelihood-based parameter learning. The authors propose novel, nonspectral bounds on the likelihood of DPPs, applicable to both finite and continuous domains. These bounds circumvent the need for spectral decomposition, a computationally expensive operation, and enable efficient variational inference and exact Markov Chain Monte Carlo (MCMC) methods. The authors demonstrate the utility of their approach through experiments on synthetic data and a real-world diabetic neuropathy dataset, showcasing the scalability and effectiveness of their methods.
Strengths:
1. Technical Contribution: The derivation of nonspectral bounds is a significant advancement. Unlike prior work that relies on spectral approximations (e.g., [7]), the proposed bounds are computationally cheaper and adaptable through the optimization of pseudo-inputs. This innovation is well-motivated and addresses a key limitation in DPP inference.
2. Broad Applicability: The methods are applicable to both finite and continuous domains, making them versatile for a wide range of applications, from modeling diversity in search engine results to spatial patterns in biological data.
3. Experimental Validation: The experiments are thorough and demonstrate the practical utility of the proposed methods. The synthetic Gaussian-Gaussian DPP experiment validates the correctness of the MCMC sampler, while the diabetic neuropathy dataset highlights the method's applicability to real-world problems.
4. Clarity of Presentation: The paper is well-organized, with clear explanations of the technical derivations and experimental results. The use of figures to illustrate key findings, such as the placement of pseudo-inputs, is effective.
Weaknesses:
1. Interpretability Trade-off: The choice to parametrize the kernel \( L \) instead of \( K \) sacrifices interpretability, as acknowledged by the authors. While this trade-off is common in the literature, it limits the broader understanding of the model's parameters, particularly in applications where interpretability is critical.
2. Variational Inference Limitations: The variability in results across independent runs of the variational inference method (Section 5.1) raises concerns about its robustness. While the authors recommend MCMC as an alternative, this issue could have been explored further.
3. Limited Discussion of Related Work: Although the paper references key prior works, it could benefit from a more detailed comparison with recent advances in DPP inference, particularly those that address similar computational challenges.
4. Scalability to Large Datasets: While the bounds are computationally cheaper than spectral methods, the scalability to very large datasets (e.g., millions of points) remains unclear. A discussion of potential limitations in such scenarios would strengthen the paper.
Arguments for Acceptance:
- The paper makes a significant technical contribution by introducing nonspectral bounds for DPP likelihoods, a novel and impactful idea.
- The methods are well-validated through experiments, demonstrating both theoretical soundness and practical utility.
- The work addresses a key computational bottleneck in DPP inference, advancing the state of the art.
Arguments Against Acceptance:
- The robustness of the variational inference method is questionable, as evidenced by inconsistent results in Section 5.1.
- The trade-off between tractability and interpretability, while common, limits the broader applicability of the proposed methods.
Recommendation: Accept with minor revisions. The paper makes a strong scientific contribution, but the authors should address the robustness of the variational inference method and provide a more detailed discussion of related work and scalability.