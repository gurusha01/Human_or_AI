The paper proposes a novel variational inference method based on a proximal framework using the Kullback-Leibler (KL) divergence as the proximal term. The authors make two key contributions: (1) introducing a KL proximal-point algorithm and demonstrating its equivalence to natural gradient-based variational inference methods, and (2) developing a proximal-gradient algorithm for non-conjugate models by splitting and linearizing difficult terms, resulting in subproblems with closed-form solutions. The proposed method is computationally efficient and applicable to a wide variety of models, with experiments on real-world datasets showing comparable performance to existing methods.
Strengths:
1. Novelty and Originality: The paper presents a novel application of the KL divergence as a proximal term in variational inference, which is a significant contribution to the field. The proximal-gradient approach for non-conjugate models is particularly innovative, as it effectively simplifies optimization problems.
2. Technical Soundness: The authors rigorously establish the equivalence between the KL proximal-point algorithm and natural gradient methods, providing theoretical guarantees for convergence. The derivations are detailed and well-supported by prior literature.
3. Practical Utility: The method is computationally efficient, especially for high-dimensional problems, as it avoids explicit computation of large covariance matrices. The use of the kernel trick further enhances scalability.
4. Experimental Validation: The experiments on Bayesian logistic regression and Gaussian process models demonstrate that the proposed method performs comparably to or better than existing methods like expectation propagation (EP) and Laplace approximation. The results are well-documented and reproducible.
5. Clarity: The paper is well-organized, with clear explanations of the algorithms, derivations, and experimental setup. The inclusion of pseudo-code and detailed derivations in the supplementary material is commendable.
Weaknesses:
1. Limited Scope of Experiments: While the experiments demonstrate the method's efficacy, they are limited to a few datasets and models. Additional experiments on more diverse datasets and complex models would strengthen the paper.
2. Comparison to Recent Work: The paper does not adequately compare its approach to more recent advancements in variational inference, particularly those published in recent NIPS proceedings. This could raise questions about the method's relative novelty and significance.
3. Hyperparameter Selection: The fixed step-size used in the experiments might not generalize well across datasets. A more robust approach, such as adaptive step-size selection, could improve the method's applicability.
4. Acknowledgment of Limitations: The paper does not explicitly discuss the limitations of the proposed method, such as potential challenges in extending it to very large-scale datasets or highly non-convex optimization problems.
Recommendation:
I recommend acceptance with minor revisions. The paper presents a novel and technically sound contribution to variational inference, with significant potential for impact in the field. However, the authors should address the limited scope of experiments and provide a more comprehensive comparison to recent work. Additionally, discussing the limitations of the method and potential future directions in greater detail would enhance the paper's completeness.
Arguments for Acceptance:
- Novel and theoretically grounded contributions.
- Computational efficiency and practical utility.
- Clear and well-organized presentation.
Arguments Against Acceptance:
- Limited experimental scope.
- Insufficient comparison to recent work.
Overall, the paper is a strong submission that advances the state of the art in variational inference and warrants inclusion in the conference program.