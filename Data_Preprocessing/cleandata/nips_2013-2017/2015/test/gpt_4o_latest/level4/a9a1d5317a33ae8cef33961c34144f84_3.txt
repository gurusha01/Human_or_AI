This paper introduces two methods for post-processing the score-valued outputs of a binary classifier, converting them into class probability estimates.
The proposed techniques are straightforward and computationally efficient. While the paper is publishable in principle, in its current state, it contains numerous significant weaknesses that make it unsuitable for acceptance. These issues are detailed below.
The distinction between the paper's contributions and the background material remains unclear until the conclusion.
The content of Section 2 appears overly simplistic, particularly Proposition 2, which relies on basic sorting and binary search. Yet, this is presented as one of the paper's "major" contributions.
The hyperparameters of the learning models were tuned by minimizing the training error. For example, Gaussian kernel SVMs can easily achieve zero training error, leading to overfitting. This practice invalidates the experimental results, rendering them meaningless. This issue alone is sufficient grounds for rejection.
Although the proposed methods consistently outperform baseline approaches, the improvement is marginal. Given that the new methods require more computational resources than Platt's method, their practical relevance is questionable. A discussion addressing this concern is missing. To justify acceptance, the authors must demonstrate that these methods are of interest to the broader community.
Minor comments:
Contrary to the paper's claim, Platt's method is not invariant to the (sigmoidal?) transformation of scores into the unit interval. It is unclear whether this transformation is applied when using Platt's method in the experiments.
The paper mentions that most models produce outputs within the unit interval, which could be interpreted as probabilities. However, this point is not explored further in the experimental evaluation. Why is this the case?
In Section 5.2, the authors assert that isotonic regression lacks a simple ad-hoc regularization technique. However, it is unclear why Platt's regularization approach—adding two virtual scores of plus and minus infinity—cannot be applied here.
The title begins with "Large-scale," yet the paper does not address large-scale data processing, nor does it include any content related to large-scale applications.
The plots in Figure 1 are too small to be legible in a standard black-and-white printout.
In summary, this paper has too many critical shortcomings to warrant publication.