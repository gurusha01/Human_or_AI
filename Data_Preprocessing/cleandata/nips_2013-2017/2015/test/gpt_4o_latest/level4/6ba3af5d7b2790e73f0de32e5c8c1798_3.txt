The paper is straightforward to read and effectively communicates its core ideas and message. However, I noticed that the authors occasionally omit certain details, perhaps in an effort to enhance readability. While the significance of these missing details is unclear, their absence complicates the reproducibility of the results.
Below, I outline several aspects where I believe the authors should provide additional clarity:
* Provide more detailed specifications of the model. It is unclear how the decoder is designed to be symmetric to the encoder. Specifically, how is upsampling handled as the model progresses through the layers?
* Clarify the learning procedure used to train the generative model. Was it trained using SGD, SGD with momentum, RMSprop, Adam, AdaDelta, Adagrad, or another optimization method?
* For the LSTM component, was gradient clipping employed? Gradient clipping is a common technique used to stabilize LSTM models, and its use (or lack thereof) should be explicitly stated.
* Specify the learning rate, momentum, and other hyperparameters used. Were these values chosen based on intuition, or were they determined through a grid search or random sampling of hyperparameters?
* Elaborate on how the dataset was constructed. Was any pruning performed to ensure sufficient frames were captured from each stage of a game? For example, early-stage image statistics in games like Pac-Man may differ significantly from later stages, potentially requiring dataset balancing.
* What is the average episode length, and how does it compare to the average length of the generated movie?
* Is the curriculum learning approach (e.g., predicting 1, 3, or 5 frames into the future) essential? Does it contribute to more stable generation, and was this experimentally validated?
* The authors assert that the action should have a multiplicative interaction, which seems like a reasonable assumption. However, has this been experimentally verified? 
Given the novelty of the task, it is challenging to assess the importance of these details. Overall, the paper is well-written but occasionally lacks specifics about the experimental procedures, which likely hinders reproducibility. Nonetheless, the results are impressive, and the authors provide intriguing observations and analyses regarding their model's behavior.