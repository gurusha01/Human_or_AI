A framework for regularized EM algorithms is introduced and thoroughly analyzed. The primary motivation for incorporating regularization is to enable estimation in high-dimensional settings under structural constraints, where unconstrained estimation becomes statistically infeasible and where the standard EM algorithm may not even be well-defined. Central to the approach is a regularized EM algorithm, which modifies the traditional M step by maximizing the Q function minus a regularization term applied to the model parameter, scaled by a regularization coefficient.
This work builds upon and refines earlier research in this area. The key novel contributions are as follows. First, while prior work focused solely on sparsity as the structural assumption, this paper extends the framework to accommodate more general regularizers, including those applicable to both sparse and low-rank structures. The statistical assumptions on the estimator of the Q function are adjusted accordingly to align with this broader regularization framework. Second, the paper introduces a specific method for selecting the regularization coefficient, which is updated iteratively and ensures proper control of the optimization error relative to the statistical estimation error.
It would be beneficial to include additional discussion or illustrative examples regarding the decomposability condition, the subspace compatibility constant, the norm ||_{R^*} (used in the critical statistical condition 5), and the set C(S, \bar S, R). This work generalizes and enhances prior research on EM algorithms for high-dimensional problems under structural constraints. The novel contributions are significant and enhance the practical applicability of the theoretical framework.