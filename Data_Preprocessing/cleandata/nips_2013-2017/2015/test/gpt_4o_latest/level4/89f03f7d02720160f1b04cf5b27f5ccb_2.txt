This paper tackles the challenge of blind signal extraction (recovery) in the presence of Gaussian noise.
To address the noisy ICA problem, the authors propose a fixed-point iteration method aimed at maximizing directional kurtosis.
The fixed-point iteration is performed within a pseudo-Euclidean space.
Using the proposed "pseudo-Euclidean gradient iteration (PEGI)" framework, the authors introduce two algorithms: one for estimating a single column of the mixing matrix and another employing an adapted deflation method to recover the full mixing matrix while avoiding redundancy in component extraction.
Clarity:
The paper is well-written and enjoyable to read. However, it lacks some key references to related work (see below).
Originality:
The approach shares similarities with the established fastICA method and GI-ICA [21] (Voss et al., NIPS 2013). However, it diverges in a significant way: it eliminates the need for pre-whitening (orthogonalization) or "quasi-whitening" (quasi-orthogonalization).
The main contributions are:
1. Gradient-based fixed-point iterations for kurtosis maximization performed in a pseudo-Euclidean space.
2. Analysis and insights into optimally selecting the pseudo-Euclidean space for the noisy ICA scenario.
These contributions are technically sound and sufficiently novel.
Significance:
Addressing ICA in noise-corrupted settings is a critical problem that is likely to interest the NIPS community.
While robustness to Gaussian noise is a known property of higher-order cumulant-based methods, the integration of this robustness into a fixed-point algorithm is both elegant and noteworthy, making the contribution significant.
An additional strength is the straightforward extension to the complex case, as demonstrated in the supplemental material.
However, the experimental section is somewhat limited, as it only includes synthetic data and omits comparisons with many other robust ICA methods. That said, the experimental results do show improvements over GI-ICA, particularly by eliminating the need for the cumbersome quasi-orthogonalization step in [21].
On the other hand, numerous methods exist for the noisy ICA problem. Notably, "RobustICA" [R2] appears to be a strong competitor, as [R3] demonstrates that the fixed-point algorithm can be viewed as a special case of gradient descent with an optimally chosen step size, as proposed in [R2]. Unfortunately, this comparison is missing. Additionally, the relative Newton method by Zibulevsky [R5], which minimizes a quasi-ML cost function, would have served as a better baseline.
Another concern is that estimating fourth-order cumulants/kurtosis generally requires a substantial amount of data (e.g., 1e+5â€“1e+6 samples, as illustrated in Figure 2). Furthermore, the practical applicability of the method to real-world data remains unproven.
Further Comments:
- It is recommended to compare fastICA with the pow3 nonlinearity instead of the tanh nonlinearity in Figure 1.
- Why is the iteration index \( k \) omitted in Algorithm 2?
Additional References:
[R1] Sergio Cruces, A. Cichocki, S. Amari, "The Minimum Entropy and Cumulant Based Contrast Functions for Blind Source Extraction", Lecture Notes in Computer Science LNCS-2085, Springer-Verlag, pp. 786-793, 2001.
[R2] Vicente Zarzoso and Pierre Comon, "Robust Independent Component Analysis by Iterative Maximization of the Kurtosis Contrast With Algebraic Optimal Step Size," IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 21, NO. 2, FEBRUARY 2010, 10.1109/TNN.2009.2035920.
[R3] H. Li and T. Adali, "A class of complex ICA algorithms based on the kurtosis cost function," IEEE Transactions on Neural Networks, 19(3):408-420, 2008.
[R4] Javidi S, Mandic DP, Took CC, and Cichocki A: "Kurtosis-based blind source extraction of complex non-circular signals with application in EEG artifact removal in real-time," Front Neurosci, 5, 105 (2011).
[R5] M. Zibulevsky, "Relative Newton and Smoothing Multiplier Optimization Methods for Blind Source Separation," chapter in the book: S. Makino, T.W. Lee, and H. Sawada eds., Blind Speech Separation, Springer Series: Signals and Communication Technology XV, 2007.
[R6] P. A. Regalia and E. Kofidis, "Monotonic convergence of fixed-point algorithms for ICA," IEEE Trans. Neural Netw., vol. 14, no. 4, pp. 943-949, Jul. 2003.
Summary:
The authors present an elegant modification of the fixed-point iteration for robust ICA within a kurtosis-maximization framework. The insights provided are valuable to the ICA community, although the practical applicability of the method to real-world data remains to be demonstrated.