Determinantal point processes (DPPs) have garnered considerable attention in recent machine learning research due to their ability to model repulsion among points in a set.
This repulsion is characterized through a positive definite kernel function.
A key challenge, however, lies in learning the parameters of this kernel from observed point realizations.
This task is particularly difficult due to the intractable normalization constant, which involves summing over all possible cardinalities and point configurations.
A recent method [7] addresses this challenge by estimating the spectrum and using it to derive incremental upper and lower bounds, enabling a provably-correct "retrospective" Markov chain Monte Carlo (MCMC) approach for kernel parameter inference.
The current paper introduces a novel type of bound that facilitates MCMC inference without requiring eigenvalue estimation.
This method also supports a variational learning framework and establishes connections to inducing-point methods for scalable inference in Gaussian process models.
The paper is technically robust and well-written.
I was previously unaware of the inequality used to derive the lower bound in Proposition 1, and it appears to be an excellent fit for this problem.
This is an innovative approach to circumvent the estimation challenges faced in [7].
I particularly appreciate the connections drawn to Gaussian process inducing points and the ability to perform variational inference with this framework.
Overall, this paper was a pleasure to read.
That said, I have two technical concerns that I believe should be addressed.
First, while I find this approach appealing, I am not entirely convinced that replacing power iterations with nonlinear optimization problems of increasing dimensionality constitutes a significant computational advantage.
Second, it is unclear to me whether simply increasing the cardinality guarantees convergence of the bounds, given the coupled nature of the optimization problem.
I suspect that this optimization problem is highly non-convex, which implies that increasing cardinality alone may not sufficeâ€”one must also ensure that a global minimum is achieved.
This issue should be explicitly addressed, as a local minimum could potentially prevent the procedure from bounding away the Bernoulli threshold, thereby obstructing the ability to perform an MCMC step.
Presentation Issues:
- Page 7, Figure 1: Please include axis labels for the figures.
- The proof of the proposition is a critical component of the paper and represents its central insight. I would have preferred to see it included in the main body of the paper rather than relegated to the appendix.
- Page 7, Line 361: "... the variational lower is ..." (incomplete phrase).
This is an excellent paper that employs a clever technique to bound the partition function of a determinantal point process, offering the potential for faster inference and meaningful connections to other modeling approaches.