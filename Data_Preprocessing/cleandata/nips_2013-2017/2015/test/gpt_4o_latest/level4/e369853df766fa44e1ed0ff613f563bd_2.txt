A commendable work that introduces logarithmic online multiclass trees (LOMTree) for efficient multiclass prediction. The authors present the core principle behind LOMTree and highlight its advantages compared to OAA classifiers. They propose a straightforward objective function to determine a partition at a given node, aiming to achieve partitions that are both maximally pure and balanced. The global quality of the tree is then quantified using an entropy-based function. The proposed algorithm is proven to converge to a tree with a log(k) complexity. Numerical experiments conducted on datasets ranging from 26 to 105k classes demonstrate reasonable training and testing times.
This is a well-written and solid paper, though somewhat dense. The proposed method is novel and performs favorably compared to other tree-based classifiers, achieving results close to those of OAA classifiers. I have a few comments to address:
- The example illustrating the construction of a node, provided in the supplementary material, is particularly clear. It would be beneficial to include this example in the main paper (perhaps alongside the algorithm) rather than relegating it to the supplementary material.
- The linear classifiers \( h \) at each node are trained online. Is the update performed using stochastic gradient descent with respect to \( J() \)? Providing additional details here would significantly enhance reproducibility.
- The numerical experiments section feels somewhat brief. Including the performance of OAA classification in Table 4 (at least for the smaller datasets) would facilitate a more direct comparison. While these results are mentioned in the text, they should also be presented in the table for clarity.
Overall, this is an interesting paper that proposes a novel algorithm for constructing an efficient tree-based classifier. The theoretical analysis and numerical experiments are both convincing.