This paper addresses a relatively straightforward budget-constrained contextual bandit problem with discrete contexts and actions. The primary contribution lies in the computational efficiency of the proposed algorithm (achieved through LP approximation) and the log(T) regret bound it attains.
The paper is well-written and easy to understand.
Suggestions: For future work, consider incorporating a parametric model for the reward function, which could be particularly beneficial when dealing with a large number of contexts. In Section 4.1, when integrating UCB with ALP, provide a clearer explanation of the reasoning behind the UCB-ALP algorithm. For instance, it seems that the approach aligns with the principle of optimism in the face of uncertainty, which might be analogous to the policy update mechanism in UCRL2. Additionally, including some numerical experiments in an extended version of the paper would be a valuable enhancement.
You may also want to reference this paper: http://arxiv.org/abs/1506.03374. Overall, this paper deserves acceptance as it introduces an efficient algorithm for budget-constrained contextual bandits with optimal regret in most scenarios. The work is both interesting and a meaningful improvement over existing methods.