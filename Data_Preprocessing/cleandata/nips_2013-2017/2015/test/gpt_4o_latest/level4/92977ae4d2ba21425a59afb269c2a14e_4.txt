The paper addresses the challenges of the EM algorithm in high-dimensional settings, where the M-step can become either unsolvable or unstable. To tackle this, a regularization method is proposed, with the central idea being the identification of an effective sequence of regularization coefficients to manage the statistical error. The authors establish convergence under specific conditions related to initialization, the regularization penalty, and the likelihood. Three latent variable models are examined, and some simulation results are presented.
Overall, this is a well-motivated paper with solid theoretical contributions.
A few suggestions: (1) It would be beneficial to include more discussion on the impact of the initialization parameter $\lambda_n^{(0)}$ and the contractive factor $\kappa$. (2) The theoretical analysis primarily pertains to algorithm 2; clarifying its connection to algorithm 1 would enhance the paper. Additionally, providing simulation results for algorithm 2 would be valuable. (3) The purpose of figure 1 is unclearâ€”perhaps it is intended to demonstrate convergence? Improving the font size in the figures would also enhance readability. (4) Including a comparison, either theoretically or through simulations, with competing methods (e.g., [20]) would strengthen the paper.
Typographical errors: In the abstract, there is a formatting issue (e.g., "a la[19]"). In equation (2.2), $y{\beta^}$ should be $f{\beta^}$, and $\log{\beta'}$ should be $\log f{\beta'}$. 
In summary, this is a strong paper that proposes a regularized EM algorithm with varying regularization coefficients to address high-dimensional latent variable problems. While the theoretical aspects and examples are well-developed, the simulation component could be further refined.