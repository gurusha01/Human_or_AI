This paper explores the application of proximal algorithms for performing variational inference.
The authors demonstrate that natural gradient methods can be interpreted as a proximal point algorithm and extend this framework by employing proximal gradient methods (also known as mirror descent) in non-conjugate settings.
The proposed algorithm is validated on non-conjugate models for regression and classification tasks using real-world datasets.
Overall, this is an excellent paper that would make a strong contribution to the NIPS proceedings.
However, I recommend that the authors cite the recent work by Theis and Hoffman, titled "A trust-regions method for stochastic variational inference with applications to streaming data," as their method aligns with the proximal point method described in that paper (even though the connection to proximal point methods is not explicitly stated there).
Additionally, there has been recent research linking mirror descent to Bayes theorem-like updates, which are essentially captured by Eqs. 11, 12, and 13 (when \(\beta^k = 1\)). A discussion of this connection would enhance the paper.
The transition from the proximal point perspective of variational inference to the use of proximal gradient methods feels somewhat abrupt, and providing a clearer explanation of this shift would improve the flow of the paper.
Finally, there are several typos, both grammatical and mathematical, that should be addressed through a thorough proofreading process.
In conclusion, this is a well-written paper that leverages proximal algorithms for variational inference and demonstrates applicability to non-conjugate settings. Despite a few minor issues, I believe this paper would be a valuable addition to the NIPS proceedings.