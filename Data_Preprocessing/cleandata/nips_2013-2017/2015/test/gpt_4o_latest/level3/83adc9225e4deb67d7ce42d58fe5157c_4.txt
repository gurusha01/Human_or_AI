This paper proposes a novel kernel-based graphical model structure learning method using score matching, which circumvents the need for estimating the normalization constantâ€”a common challenge in nonparametric density estimation. The authors demonstrate that their method achieves asymptotically consistent structure recovery and provide a theoretical foundation for its performance. The approach is particularly significant as it extends structure learning to non-Gaussian distributions, addressing an important open problem in probabilistic graphical models.
The paper compares the proposed method with graphical lasso for Gaussian distributions and other algorithms for nonparanormal distributions. Empirical results indicate that the method performs comparably to graphical lasso for Gaussian data and outperforms it for nonparanormal data. However, the experiments are limited in scale, and the paper lacks clarity on the selection of kernel parameters, which are critical for the method's performance. The absence of code further limits reproducibility and hinders the broader adoption of the approach.
Theoretical analysis is a strong point of the paper, with detailed proofs provided for the consistency of the proposed method. However, the reviewer was unable to fully verify the correctness of these proofs due to their complexity. Including derivations in supplementary material would enhance accessibility and allow for more thorough verification by readers.
The paper is well-organized and written in clear language, but the extensive use of complex mathematical notations may pose a challenge for readers unfamiliar with the topic. A table of notations would significantly improve readability. Additionally, parameter choices for the second model in the experiments are not provided, which detracts from the clarity and reproducibility of the results.
The originality of the work is commendable, as it introduces a novel method that builds upon and extends existing literature on kernel-based probabilistic graphical models. However, the paper could benefit from stronger connections to related work in kernel-based PGM literature to better contextualize its contributions.
In terms of significance, the paper addresses a challenging and impactful problem, but the limited empirical evaluation and lack of code reduce its immediate impact. Suggestions for improvement include providing code, clarifying parameter choices, adding a table of notations, and including detailed derivations in supplementary material. Correcting minor typos and undefined notations would further enhance the paper's quality.
Pros for acceptance:
- Novel and theoretically sound approach to nonparametric graphical model structure learning.
- Addresses an important open problem in the field.
- Extensive theoretical analysis supports the method's consistency.
Cons for acceptance:
- Limited empirical evaluation and lack of clarity on kernel parameter selection.
- No code provided, reducing reproducibility.
- Complex mathematical notations hinder readability for a broader audience.
Overall, while the paper makes a meaningful contribution, addressing the identified weaknesses would significantly strengthen its impact and accessibility.