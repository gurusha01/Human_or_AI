This paper presents a novel approach to image restoration by combining the strengths of generative and discriminative models. Specifically, it proposes a discriminatively trained feed-forward "gating network" to predict latent variables in a Gaussian Mixture Model (GMM), significantly reducing computational costs while maintaining the modularity and performance of generative models. The authors demonstrate that their method achieves comparable denoising performance to the original GMM-based EPLL algorithm but with a speedup of over two orders of magnitude. The paper also highlights the modularity of the approach, showing its applicability to tasks like image deblurring without retraining.
Strengths:
1. Clarity and Narrative: The paper is well-written and clearly structured, making it accessible to readers. The authors provide a thorough background on both generative and discriminative approaches, situating their work within the broader context of image restoration research.
2. Technical Soundness: The proposed method is technically sound and supported by both theoretical insights and experimental results. The authors carefully evaluate the trade-offs between accuracy and computational efficiency, demonstrating that their approach achieves a significant speedup with minimal loss in performance.
3. Practical Relevance: The paper addresses a critical limitation of generative models—their computational inefficiency—while preserving their modularity. This is particularly valuable for real-world applications where noise models and restoration tasks vary widely.
4. Convincing Results: The experimental results are compelling, showing that the proposed method achieves state-of-the-art performance in denoising and deblurring tasks. The visual comparisons and quantitative metrics (e.g., PSNR) further validate the approach.
5. Simplicity of the Approach: The method is conceptually simple yet effective, leveraging discriminative training to optimize the most computationally expensive step in GMM-based restoration.
Weaknesses:
1. Speed Comparison with MLPs: While the paper demonstrates significant speed improvements over traditional GMMs, it does not provide a direct comparison with modern discriminative methods like Multi-Layer Perceptrons (MLPs). This omission leaves some ambiguity about the relative computational efficiency of the proposed method.
2. Modularity in Practice: The paper emphasizes the modularity advantage of generative models but does not include a concrete example where this modularity is critical. Including such an example would strengthen the argument for the practical utility of this feature.
3. Generality Beyond GMMs: While the authors suggest that the approach could generalize to other generative models with latent variables, they only evaluate it on GMMs. A broader evaluation would enhance the paper's significance.
Recommendation:
I recommend acceptance of this paper, as it makes a meaningful contribution to the field of image restoration by addressing a key limitation of generative models. The work is technically sound, clearly presented, and supported by strong experimental results. However, the authors are encouraged to address the raised concerns in the final version, particularly by providing a practical example of modularity and a comparison with MLPs. 
Arguments for Acceptance:
- Significant speedup with minimal loss in performance.
- Maintains the modularity of generative models, which has practical advantages.
- Clear and well-organized presentation.
- Strong experimental validation.
Arguments Against Acceptance:
- Lack of direct comparison with MLPs in terms of speed.
- No practical example demonstrating the importance of modularity.
- Limited evaluation beyond GMMs.
Overall, this paper is a valuable contribution to the field and should be included in the conference proceedings.