This paper proposes two methods, Inductive Venn–Abers Predictors (IVAPs) and Cross Venn–Abers Predictors (CVAPs), for converting binary classifier scores into class probabilities. The authors claim these methods achieve perfect calibration and computational efficiency while providing consistent empirical improvements over existing calibration techniques, such as Platt's method and isotonic regression. The paper also introduces a minimax approach for merging imprecise probabilities into precise ones, with experimental results suggesting that CVAPs outperform baseline methods across several datasets.
Strengths:  
The paper addresses an important problem in machine learning—calibrating classifier scores into probabilities—and provides a theoretically grounded solution. The methods are computationally efficient, leveraging basic sorting and isotonic regression, and the authors demonstrate consistent empirical improvements over baseline methods. The inclusion of both log loss and Brier loss as evaluation metrics is commendable, as it provides a more comprehensive assessment of the proposed techniques. Additionally, the discussion of cross-validation in CVAPs adds robustness to the approach, and the minimax merging strategy is a thoughtful contribution.
Weaknesses:  
1. Clarity and Organization: The distinction between the paper's contributions and prior work is unclear until the conclusion, making it difficult to discern the novelty of the proposed methods early on. Section 2, particularly Proposition 2, presents trivial computational steps (sorting and binary search) as a major contribution, which undermines the significance of the work.  
2. Experimental Design: The hyperparameters are tuned by minimizing training error, which risks overfitting and renders the experimental results less meaningful. Additionally, the claim that most models output unit interval values interpreted as probabilities is not explored in the experiments.  
3. Misrepresentation of Related Work: The paper misrepresents Platt's method as invariant to score conversion and overlooks its regularization technique. Similarly, it incorrectly claims that isotonic regression lacks ad-hoc regularization, ignoring Platt's contributions.  
4. Limited Significance: While the proposed methods consistently outperform baselines, the effect size of the improvement is small, raising questions about the practical relevance of the contributions. The title's reference to "Large-scale" is misleading, as the paper does not address scalability challenges.  
5. Presentation Issues: The plots in Figure 1 are too small to be readable in black-and-white printouts, which detracts from the paper's clarity.
Arguments for Acceptance:  
- The methods are computationally efficient and theoretically grounded.  
- The paper introduces a novel minimax merging strategy for probabilities.  
- CVAPs show consistent empirical improvements over baselines.
Arguments Against Acceptance:  
- The novelty of the contributions is overstated, with trivial computational steps presented as significant.  
- Experimental results are undermined by overfitting and lack of exploration of key claims.  
- Misrepresentation of related work and misleading claims (e.g., scalability) reduce the paper's credibility.  
- The small effect size of improvements limits the practical impact.
Recommendation:  
While the paper makes some interesting contributions, the overstated novelty, flawed experimental design, and limited practical significance suggest it is not yet ready for publication. A major revision is needed to clarify contributions, address experimental shortcomings, and provide a more honest comparison with existing methods.