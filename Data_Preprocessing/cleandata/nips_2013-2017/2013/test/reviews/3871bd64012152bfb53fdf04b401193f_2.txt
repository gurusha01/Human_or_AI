Learning with Noisy Labels 
The paper addresses the problem of binary classification in the situation 
where the training labels are corrupted by class-conditional random noise. 
The authors propose 2 surrogate-loss based learning methods to address the problem: 
the first exploits a simple symmetry condition on the loss function used to 
provide a simple unbiased estimator of the non-noisy risk and the second 
promotes the use of a weighted 0-1 loss that comes from an appropriate reduction 
of the problem of learning from noisy labels. 
The paper is a very clean and strong contribution. It provides original 
theoretical results (e.g. learnability with convex surrogate in the case 
of noise, noise-tolerance of SVMs, and so on) as well as compelling empirical 
results. Everything is wrapped up in a nicely written paper. 
I essentially have questions on future directions: 
- the authors mention adversarial noise: before going to this point, is there something that can be said 
about learnability with monotonic noise, as defined by Bylander ? 
- what about richer noise models like Constant Partition Classification Noise (CPCN) noise ? 
 Very good paper, providing significant result to learn binary classifiers from noisy labels using convex surrogates. Technical results are important, the writing is good and the experiments are compelling.