This paper presents a new technique for domain adaptation for computer vision datasets, which typically present multiple aspects, e.g. viewpoint, illumination, level of clutter, compression, etc. Instead of simply equating domains with datasets, which ends up mixing those aspects together, the proposed technique automatically partitions the set of all images over all datasets into domains. The partitioner is driven by two principles: making separate domains in feature space, and making them so that a good discriminative classifier can be trained on each of them (to classify the original classes, not to separate the domains). This technique is more likely to partition according to the underlying aspects rather than datasets. 
Originality and significance: 
There is only little work on automatically defining domains, and this paper proposes a good idea towards automatically discovering useful domains, that will support training better classifiers for the original problem. 
On the negative side, I am not fully convinced of the proposed optimization method (section 2), as it's not clear how closely it solves the original problem (2)+(3). Moreover, the two proposed driving criteria are not well integrated yet: the maximal learnability criterion is only used as a 'wrapper around' the maximal separability criterion, in order to determine the number of domains. Essentially, it acts as a post-hoc validation score deciding how good is the domain partitioning learned for a given number of domains, but the partitioning itself is made based on the separability criterion alone. An integrated process would instead produce the partitioning that maximises some goal function including both criteria directly. 
Despite these shortcomings, which might be due to the fact that this type of work is still at quite exploratory stages, I feel that the paper is a step in the right direction for the community and should be accepted. 
Quality and clarity: 
The paper is well written, but lacks figures to illustrate the concepts presented. 
Experiments: 
On the positive side, the experiments show a significant advantage in using the domains produced by the proposed method, over just using datasets as domains, and over the very recent domain discovery technique [19] (sec. 4.2). 
The idea of including the test set in the 'reshaping' process is interesting, but not clearly presented (sec. 4.3). Also, this corresponds to an imputation setting (i.e. all test data is available at the same time), but this is not stated clearly. 
On the negative side, the image descriptor used is very simple and outdated: just one bag-of-words of sparse SURF features for the entire image, and with just 800 codebook entries. This is really weak nowadays. I recommend the authors to use a spatial pyramid of bag-of-words, computed on dense SURF features. Also, it is not clear what similarity measure is used to compare image descriptors, hopefully X^2 or an intersection kernel? The Euclidean distance is not suitable for comparing histograms. As a next step, a Fisher Vector representation could help further and finally place the image representation in this paper at the level of modern systems. The following papers might help the authors: Zhang IJCV 2006; Jurie CVPR 2005; Lazebnik CVPR 2006; Perronin ECCV 2010. 
 Overall, the paper presents interesting novel ideas on an important problem and achieve good results. The paper can be improved in several way, especially in terms of the image representation used.