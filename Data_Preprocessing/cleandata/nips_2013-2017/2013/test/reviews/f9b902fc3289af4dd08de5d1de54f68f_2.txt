This paper proposes a discriminative clustering algorithm inspired by mean shift and the idea of finding local maxima of the density ratio (ratio of the densities of positive and negative points). The work is motivated by recent approaches of [4,8,16] aimed at discovering distinctive mid-level parts or patches for various recognition tasks. In the authors' own words from the Intro, "The idea is to search for clusters of image patches that are both 1) representative... and 2) visually discriminative. Unfortunately, finding patches that fit these criteria remain rather ad-hoc and poorly understood. While most current algorithms use a discriminative clustering-like procedure, they generally don't optimize elements for these criteria, or do so in an indirect, procedural way that is difficult to analyze. Hence, our goal in this work is to quantify the terms 'representative' and 'discriminative', and show that that a generalization of the well-known, well-understood Mean-Shift algorithm can produce visual elements that are more representative and discriminative than those of previous approaches." I find this motivation very compelling and like the formulation of discriminative clustering in terms of maximizing the density ratio. 
The derivation of the clustering objective starts out promisingly enough on p. 2-3, by p. 4 it makes a number of confusing leaps that seem to take it pretty far from the original formulation. Specifically, on lines 188-190, the authors comment on eq. (5), "representing a patch multiple times is treated the same as representing different patches. Ideally, none of the patches should be double-counted." This leads to the introduction of "sharing coefficients" that ensure competition between clusters. However, isn't "double-counting" actually necessary in order to accurately estimate the local density of the patches, i.e., the more similar patches there are close to a given location in the feature space, the higher the density should be? Or does "double-counting" refer to something else? This needs to be clarified. Next, the discussion following eq. (6) appears to introduce heuristic criteria for setting the sharing coefficients, and even more heuristics are needed to deal with overlapping patches (lines 199-211). As a result, by the time we get to the final objective (eq. 7), the original one (eq. 1) seems to have been abandoned or changed beyond recognition. While the authors start out rightly decrying the heuristic nature of approaches such as [4,8,16], they end up deriving something no less heuristic. 
Strengths 
========= 
+ The idea of deriving a discriminative clustering algorithm by maximizing the density ratio is novel and compelling. 
+ The experimental results are the main point in favor of accepting the paper. According to Table 1, the proposed approach outperforms even the very recent results of [8] on the MIT Indoor Scene dataset (however, see below). 
Weaknesses 
========== 
- The derivation of the clustering objective makes several poorly explained leaps (see above). The authors need to better motivate the different steps of their derivation and explain the relationship to related methods. For one, while the paper is titled "Discriminative Mean Shift", the connection of the proposed method and mean shift is less than apparent: the original mean shift formulation is purely local (each point in the feature space finds its closest local maximum), while the method derived in this paper appears to globally optimize over cluster centers by introducing a "competition" criterion. If I understand correctly, this is not simply a difference of maximizing local density vs. density ratio. A better discussion would be helpful. Also, the final objective (eq. 7) has a strong margin-based feel to it. Similarity (or lack thereof) to other existing margin-based clustering approaches should be discussed. 
- For that matter, there should be citations to other existing discriminative clustering formulations, such as 
Linli Xu, James Neufeld, Bryce Larson, and Dale Schuurmans, Maximum margin clustering, NIPS 2005. 
- The proposed optimization algorithm does not appear to have any theoretical guarantees (lines 257-259). 
- While the experimental results appear extremely strong, it is hard to get any insight as to why the proposed method outperforms very recent well-engineered systems such as those of [8]. Is this due to the clustering objective or to other implementation details described in lines 406-422? Since there are many potential implementation differences between the proposed approach and the baselines it compares against (including feature extraction, pre- and post-processing, classification), the causes behind the superior performance reported in this paper are not at all clear. Some of the claims that are made in the experimental section are not supported by any quantitative or qualitative evidence shown in the paper, e.g., "small objects within the scene are often more useful features than global scene statistics: for instance, shoe shops are similar to other stores in global layout, but they mostly contain shoes." 
 This paper is above the acceptance threshold owing primarily to the strong experimental results, but the derivation of the clustering method is not clearly presented and appears to have several poorly motivated heuristic steps.