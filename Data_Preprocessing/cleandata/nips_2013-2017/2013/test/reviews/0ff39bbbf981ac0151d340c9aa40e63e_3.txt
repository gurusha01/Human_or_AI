The paper proposes a method for translingual representation learning by first using matrix completion to create multilingual vectors for each row, and then performing CL-LSI on the multilingual vectors. 
Quality: While this seems like a good idea, I'm not sure that the results are robust. The positive results could simply be caused by the scaling of LSI being better than OPCA or CCA for a linear SVM. 
I would urge the authors to use an ML system that is insensitive to rescalings of the individual feature: for example, boosted decision trees (available in Weka). If the boosted decision trees on top of the two-step system works better than other techniques, then I believe the result. 
Significance: If this is really a robust result, it would be neat, because matrix completion is a well-controlled non-linear inference technique. 
Novelty: The idea seems new. 
Clarity: There were some issues of clarity in the paper. Line 113 talks about "construct[ing] a unified document-term matrix for all documents". I'm not sure whether this means using one term for every surface form (like "Merkel"), or labeling each surface form from each language (like "Merkelen" and "Merkelde"). Please clarify. Also, the description of the experimental setup is split across Table 1, so it took me a little while to figure it out. 
 Seems like a neat idea. I wish that the authors tried other classifiers than linear SVM -- I just don't know whether the result is robust, or a scaling artifact.