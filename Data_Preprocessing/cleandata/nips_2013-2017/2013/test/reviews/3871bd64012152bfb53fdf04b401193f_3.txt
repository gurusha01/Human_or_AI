Overall, I found the paper quite well-written. 
I think the assertion in the abstract (and then again in the Experiments 
section), that you learn with 88% accuracy when 80% labels are flipped is 
incorrect. You are only flipping 40% of the labels (the probability of 
flip is convex combination of \rho+ and \rho- and not their sum). In 
any, case the goal is to get better accuracy as noise rate goes to half, 
not one (where the problem is trivially easy with just all labels 
flipped). 
I wonder if it is worthwhile to compare your methods with Kearns' SQ 
setting. Since minimizing a convex loss can be done by gradient methods 
(which have statistical analogues). And so you would get tolerance to 
random classification noise for free. (Kearns does not allow 
class-conditional noise, but I think that part can be handled easily.) I'm 
not sure what kind of excess risk bounds you would get by such 
SQ-simulation. 
Minor quibbles: 
-------------- 
1. You use the term PU learning, without ever defining it. 
2. You use "so-called" very often. Especially for zero-one loss. Why is it 
so-called? If you have objection to the name you should state it. 
--- 
Update: Regarding using the SQ model. Even if you are using surrogate loss, your optimization problem can be solved using an algorithm that only makes statistical queries rather than data points. 
 This paper considers the problem of learning in the presence of randomclassification noise. In contrast with the PAC-like models, the maingoal here is if the goal is to minimize some convex loss function (withrespect to the true models), this can be done by suitable modificationseven when the labels are noisy (in many cases).The paper also contains some experiments studying the proposed methods andother related techniques.