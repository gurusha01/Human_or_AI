This paper studies an interesting problem of visual concept learning, particularly paying attention to determine the degree to which a concept should be generalized. For this purpose, the work first focuses on how to generate a large-scale dataset of concepts at various levels of abstraction from ILSVRC and collect human judgements on AMT, and then presents Bayesian concept learning algorithm to handle perceptual uncertainty. The problem of learning concepts of various levels of abstraction is interesting. However, this reviewer finds that the algorithm presentation is unclear and lacks intuitive explanations. In addition, the experimental evaluation is somewhat weak because it doesn't compare with strong baselines. 
More detailed comments are listed as follows: 
1. In Eq. (4) and (5), is I(.) an indicator function? Please clarity. 
2. In Eq. (4), I(xi \subseteq h) implies that $h$ is a set and $xi$ is also a set. This is confusing to this reviewer. Why is $xi$ a set? In contrast, in Eq. (5), I(\hat{y}i \in h) shows that $\hat{y}_i$ is an item. Please clarify. 
3. In Eq. (5), it seems that the summation is only effective for the first term, i.e. A{j\hat{y}i}. The remaining part is irrelevant to index $j$. Therefore the summation of A{j\hat{y}i} becomes one column vector. Is this what you want to get? I cannot understand the motivation of this equation. 
4. It seems there is a typo in the last line of page 5. "… the true leaf node is $j$ given the classifier output being $j$". Please check if you do want to put two $j$. 
5. In line 243, page 5, the sentence "for example, as the number of examples that are all Dalmatians increases, it becomes increasingly likely that the concept is just Dalmatians and not dogs in general even though both are logically possible, …" is true. But what does this mean to the hypothesis size? The hypothesis is quite confusing in the paper. It seems that the authors define the hypothesis size as the number of samples belonging to a hypothesis. How can this be defined in real world, given that the number of potential images belonging to any concept can be infinitely large? Is the number of samples in ImageNet a reasonable way to define the hypothesis size? 
6. Given so many unclear places in the algorithm presentation, it is quite hard to understand the proposed algorithm and know why it can really work, although the algorithm presentation is just of high level. 
7. The baseline methods are not sufficiently strong and convincing. For example: 
a) For the naïve vision approach, only GIST feature is used, whereas the proposed algorithm uses a overcomplete feature set of 160K dimensions. This is unfair to compare the two algorithms. 
b) The paper mentions the latest work of deep neural network [10, 9] in Section 4.3. Why not choose DNN or its variant as a baseline method? Simply because it requires more training data? If DNN could output the proposed algorithm given that the training data can be easily collected from ImageNet, I would doubt the value of this work. 
 The paper studies an interesting problem of learning concepts at various levels of abstraction and the authors did put great efforts in constructing a large-scale concept learning dataset with human judgements collected on AMT. However, the algorithm presentation is unclear and lacks intuitive explanations. Also the experimental evaluation is unconvincing as some baseline method is implemented in a too simple way and some stronger baselines are not compared.