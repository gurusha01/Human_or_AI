The goal of this paper is to sample from a continuous 
determinantal point process, which until now has not been done 
for general continuous kernels. The authors provide a general 
`meta'-algorithm that works in principal for general kernels --- 
though ease-of-derivation may vary from kernel to kernel. 
Previous work dealt with translation invariant kernels in compact domains. 
The random Fourier features method proposed here extends the 
applicability of random Fourier features to general Euclidean spaces 
(where the kernel is translation invariant). And the proposed Nystrom 
method extends this even further to general kernels but relies 
on good landmark selection (and generally performs better in low 
dimensional problems). 
While the RFF and Nystrom methods had been used in the discrete 
version of the DPP, the main novelty of the current work is to 
figure out how to do parts of the approximation `analytically' in some 
special cases. In particular, explicit sampling algorithms are worked 
out for Gaussian/Cauchy/Laplace kernel settings. 
Overall, I quite enjoyed reading the paper as it was well motivated 
and accessible. The NIPS margins have been violated, however, which made 
the paper quite long. Otherwise, it makes for a nice contribution 
to the DPP thread in machine learning and I recommend acceptance. 
Minor comments/suggestions: 
- I would have appreciated more detail in the derivation of the Gibbs 
sampling step for the repulsive mixture. The authors seem to have 
just written down a posterior which takes the form of a DPP. It 
would be easier to follow if the prior and likelihood for the 
`interesting' sampling step were written out explicitly. 
- In Algorithm 1 in the appendix, the authors use Y and script-Y, 
which are not the same, but somewhat confusing on a first read. 
- It would be interesting to see a derivation of the Nystrom method 
on a non-translation invariant kernel (to show off what it can 
handle that the Fourier based features cannot). 
 This paper forms a nice extension to the exciting DPP (determinantal point processes) line of work in machine learning. It was also a pleasure to read. I hope it is accepted.