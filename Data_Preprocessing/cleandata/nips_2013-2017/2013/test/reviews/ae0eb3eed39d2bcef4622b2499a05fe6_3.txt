This paper studies the problem of large scale unsupervised learning. It proposes the paradigm of "optimistic concurrency control", which assumes that conflicts are unlikely and if conflicts do arise a conflict-resolution protocol is invoked. The paper then applies the approach to three clustering related problems: clustering, feature learning and online facility location. It also proves the serializability of the proposed algorithms. It provides the experimental results on simulated data sets. 
This paper is well-organized and clearly written. It provides enough technical details and theoretical support. The idea of OOC is neat and practical. Although the paper presents the idea from the point view of concurrency control, however in more general speaking, the key point of large scale machine learning is how to update the global parameter from the local parameters from each parallelized parts. The proposed approach provides a simple and practical way to update the global parameters (global cluster assignments) from local ones (local cluster assignments). However, this update strategy does not necessarily work for other unsupervised learning or supervised learning algorithms. In general, the update strategy is algorithm-dependent. My major concern about this work is its experimental results. The experiments cannot prove the usefulness of the proposed algorithms. First, it is only based on simulated data, which does not provide insights how the algorithm will be useful for real data sets. Second, it should provide cluster quality comparison with other distributed clustering algorithms in the literature. 
 The paper provides a neat idea for distribute unsupervised learning (clustering) with a good presentation. However, the experiments are not strong enough to support the usefulness of the proposed algorithms.