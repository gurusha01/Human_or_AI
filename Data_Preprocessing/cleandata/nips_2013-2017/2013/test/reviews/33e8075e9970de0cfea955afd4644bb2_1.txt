The paper proposes an approach for constructing a linear wavelet transform on weighted graphs based on the lifting scheme, which has a number of favourable properties: 1) linear in memory and time with the size of the graph, 2) adaptive to a class of signals, 3) exact analysis and synthesis, i.e. allows for perfect signal reconstruction, 4) efficient training through resemblance with deep auto-encoder networks. 
The paper is presented well: it is clearly structured and well written. After a nice overview and introduction, the authors give a detailed derivation of their construction and show in a number of experiments the validity and versatility of their approach. 
The proposed approach and wavelet construction builds on previous work but makes a non-trivial contribution to the field of graph-based signal processing by deriving a general-purpose wavelet transform with a number of favourable properties. 
The authors make an interesting connection between wavelet construction on graphs and auto-encoder networks. It is likely that this paper will trigger further development in this line of research. It is also likely to serve as a flexible tool in the analysis of signals on graphs. 
Additional comments: 
* great if the authors could be more precise what sufficient in section 4.5 means? In a general problem how would one determine how many eigenvectors need to be taken into account? 
* What is the meaning of the colorbars in Fig. 4 and 5. ? 
* In Sec. 4.7 change "It is also possible o" -> "It is also possible to" 
 The paper elaborates a non-trivial general-purpose wavelet transform for signals on weighted graphs, which exhibits a number of favourable properties. It makes an interesting connection to auto-encoder networks and is likely to trigger further work along these lines.