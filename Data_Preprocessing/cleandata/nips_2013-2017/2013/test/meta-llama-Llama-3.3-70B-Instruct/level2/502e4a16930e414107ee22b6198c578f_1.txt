This paper presents a thorough analysis of the number of iterations required by Policy Iteration (PI) algorithms to converge to the optimal policy in a Markov Decision Process (MDP). The authors consider two variations of PI: Howard's PI and Simplex-PI. They provide new upper bounds on the number of iterations required by these algorithms, which are sharper than previous results.
The paper is well-organized and clearly written. The authors provide a comprehensive review of existing results and carefully explain their new contributions. The proofs of the main theorems are detailed and easy to follow.
The main claims of the paper are:
1. Howard's PI terminates after at most n(m-1)  (1/(1-γ))  log(1/(1-γ)) iterations.
2. Simplex-PI terminates after at most n(m-1)  n  (1/(1-γ)) * log(n/(1-γ)) iterations.
3. For deterministic MDPs, Simplex-PI terminates after at most O(n^5  m^2  log^2 n) iterations.
4. For MDPs satisfying a certain structural assumption, Simplex-PI terminates after at most n^2  (m-1)  (log(nr) + log(nt)) iterations.
The support for these claims is based on a combination of theoretical analysis and mathematical proofs. The authors use contraction properties of the PI algorithms to establish the upper bounds on the number of iterations.
The usefulness of the results is evident, as they provide a better understanding of the convergence properties of PI algorithms. The results can be used to improve the efficiency of PI algorithms in practice.
The paper demonstrates a good understanding of the field and relevant literature. The authors cite previous work and provide a clear comparison of their results with existing ones.
The novelty of the paper lies in the new upper bounds on the number of iterations required by PI algorithms. The authors also provide a generalization of previous results to stochastic MDPs.
The completeness of the paper is satisfactory, as the authors provide detailed proofs and explanations of their results.
The limitations of the paper are acknowledged by the authors, who note that the analysis of Howard's PI is still largely open and constitutes their main future work.
Overall, I would recommend accepting this paper for publication. The results are significant, and the paper is well-written and easy to follow. The authors demonstrate a good understanding of the field and provide a clear comparison of their results with existing ones.
Arguments pro acceptance:
* The paper presents new and significant results on the convergence properties of PI algorithms.
* The authors provide a comprehensive review of existing results and carefully explain their new contributions.
* The proofs of the main theorems are detailed and easy to follow.
Arguments con acceptance:
* The analysis of Howard's PI is still largely open and constitutes the main future work.
* The results may not be directly applicable to all types of MDPs.