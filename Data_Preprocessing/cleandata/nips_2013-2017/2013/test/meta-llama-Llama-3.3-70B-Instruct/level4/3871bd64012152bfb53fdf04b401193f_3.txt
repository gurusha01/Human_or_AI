Overall, I found the paper to be well-structured and clearly written. 
However, I noticed a discrepancy in the abstract and Experiments section, where it is claimed that the model achieves 88% accuracy when 80% of the labels are flipped. Upon closer examination, it appears that only 40% of the labels are actually flipped, as the probability of flip is a convex combination of \rho+ and \rho-, rather than their sum. Furthermore, the objective should be to improve accuracy as the noise rate approaches 0.5, rather than 1, where the problem becomes trivially easy with all labels flipped.
I suggest considering a comparison with Kearns' Statistical Query (SQ) setting, as minimizing a convex loss can be achieved through gradient methods, which have statistical analogues, thereby providing tolerance to random classification noise. Although Kearns' setting does not account for class-conditional noise, this limitation can likely be addressed with minimal modifications. It would be interesting to explore the excess risk bounds that could be obtained through SQ-simulation.
Some minor issues that require attention include:
-------------- 
1. The term "PU learning" is used without definition, which may cause confusion for readers unfamiliar with the concept.
2. The phrase "so-called" is frequently used, particularly when referring to the zero-one loss. It is unclear why this terminology is used, and if there are objections to the name, they should be explicitly stated.
--- 
Update: Regarding the application of the SQ model, even when using surrogate loss, the optimization problem can be solved using an algorithm that relies solely on statistical queries rather than individual data points. This paper investigates the problem of learning in the presence of random classification noise, differing from PAC-like models in its focus on minimizing convex loss functions with respect to true models, even when labels are noisy. The paper also presents experimental studies on the proposed methods and related techniques.