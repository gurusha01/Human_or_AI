This manuscript presents a significant contribution to the expanding field of Monte Carlo Tree Search (MCTS) research by introducing a novel approach. The core concept involves representing the distribution of accumulated rewards in the search tree as a mixture of Gaussian distributions, utilizing a Dirichlet distribution as a prior for mixture weights and a Normal-Gamma distribution as a prior for the mixtures. The authors provide justification for their normality assumptions based on the central limit theorem and offer a concise overview of the process for setting the hyperparameters of these priors. By integrating this Bayesian formulation with Thompson sampling, the authors propose a refined version of MCTS that appears to mitigate the heuristic nature of Upper Confidence Bound (UCB) methods and enhances the exploration-exploitation tradeoff.
The paper's structure and presentation are well-organized, with clear explanations of the ideas and mathematical concepts. Although there are noticeable language issues throughout the manuscript, they do not significantly impede comprehension. However, addressing these issues, particularly in the introduction, would improve the paper's clarity. The authors effectively introduce the necessary concepts, justify the underlying modeling assumptions, present the model, and integrate these components. A more detailed comparison between Thompson sampling and UCB, including their specific assumptions and relative strengths and weaknesses, would further enhance the paper.
The empirical evaluation is robust, but the authors should provide a more comprehensive comparison of the computational complexity of their algorithm with that of Upper Confidence bound applied to Trees (UCT), including quantitative data and figures. Given that this algorithm is more complex than UCT and thus likely to run slower, understanding the magnitude of this slowdown (in terms of seconds, hours, or days) is crucial. The efficiency of UCT stems partly from its speed, which enables more extensive sampling within the same timeframe as more complex methods, leading to more accurate empirical estimates. Additionally, it would be beneficial to quantify the separate contributions of Thompson sampling and the use of the Dirichlet-NormalGamma distribution compared to vanilla UCT to understand their individual impacts.
A critical question arises regarding the assumptions of convergence to a normal distribution, which rely on a fixed future policy and thus a Markov chain rollout. However, since the policy is not fixed and evolves over time due to learning or exploratory randomness, it appears that these assumptions may be invalidated. Although the empirical results suggest that these assumptions do not significantly harm the method's performance, addressing this concern is essential. Overall, this paper presents a solid, novel improvement to MCTS by utilizing Bayesian mixture modeling to represent accumulated rewards in a Markov Decision Process (MDP). The idea is well-conceived, clearly explained, and empirically validated, but the manuscript could benefit from minor improvements in language, a more detailed analysis of computational complexity, and a careful examination of the validity of certain assumptions.