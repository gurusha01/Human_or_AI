This paper tackles the challenge of binary classification when training labels are corrupted by class-conditional random noise, proposing two surrogate-loss based methods to address this issue. The first method utilizes a symmetry condition on the loss function to provide an unbiased estimator of the non-noisy risk, while the second method employs a weighted 0-1 loss derived from a suitable reduction of the noisy label learning problem.
The contribution is robust and well-presented, offering novel theoretical insights, such as learnability with convex surrogates in noisy settings, noise tolerance of SVMs, and more, alongside convincing empirical results. The paper's clarity and organization make it a pleasure to read.
However, some potential future research directions warrant consideration:
- Before exploring adversarial noise, could the authors investigate learnability under monotonic noise, as defined by Bylander, to provide a more comprehensive understanding?
- How do the proposed methods perform under more complex noise models, such as Constant Partition Classification Noise (CPCN) noise? 
Overall, this is an excellent paper that significantly advances the state-of-the-art in learning binary classifiers from noisy labels using convex surrogates, with important technical results, clear writing, and persuasive experiments.