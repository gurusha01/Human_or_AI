This study aims to automatically identify latent domains within a training set, which is then utilized in a domain adaptation framework to enhance classification performance on a test set. The authors propose a function that quantifies the difference between two feature vectors using a specified kernel, with the objective of partitioning data points into domains that maximize this function across each pair of domains. This problem is formulated as an integer programming problem with two key constraints: each data point is assigned to exactly one domain, and the distribution of class labels in each domain must align with the input distribution across the entire dataset. To solve this, the problem is relaxed into a continuous optimization problem with a quadratic cost and linear constraints, and the optimal number of domains is determined through cross-validation.
The approach is evaluated on two datasets: static images from [2] and the IXMAS multi-view action dataset from [15], demonstrating improved performance over the domain adaptation method presented in [19]. 
The strengths of the paper include its clear writing and the novelty of the approach, as well as the appreciable performance gains over [19]. 
However, I initially lean towards rejection due to two primary concerns that I hope will be addressed in the rebuttal, potentially changing my evaluation: 
(i) The paper's motivation is unclear. The claim on line 77 that "simply clustering images by their appearance is prone to reshaping datasets into per-category domains" lacks evidence and a clear explanation of how the model formulation in Section 2 addresses this issue, specifically how it prevents reshaping into per-category domains.
(ii) Relatedly, the necessity of the second constraint ("label prior constraint") on line 154 is questionable. I am interested in seeing the performance without this constraint and suggest comparing it to baselines where data is partitioned using k-means clustering or unsupervised object discovery (e.g., Sivic et al., ICCV '05) over appearance vectors. Additionally, evaluating the performance when the dataset is randomly partitioned into equal sets would be beneficial.
Further comments include:
+ Clarifying the meaning of "maximally different in distribution from each other" (line 82), specifically what distribution is being referred to.
+ Noting that \beta_{mk} as formulated seems to already be on a simplex (line 166).
+ Pointing out the apparent difference in constraints between the formulation starting on line 153 and those on line 182.
+ Requesting justification or proof for the bound mentioned on line 215.
+ Seeking more details on the use of the geodesic flow kernel [4], including whether it was reimplemented or if publicly available source code was used (line 289).
+ Asking for insights into the performance differences, particularly why the proposed approach outperforms the baselines and systematic failures of the baselines that the proposed approach overcomes (lines 313/340).
+ Correcting the notation in Eq (1) from M'k to Mk'.
+ Suggesting the inclusion of the citation "Unbiased Look at Dataset Bias" by A. Torralba and A. Efros from CVPR 2011.
After considering the rebuttal, which addressed my concerns regarding the paper's motivation and the label prior constraint, I lean slightly towards acceptance.