This manuscript explores the intriguing problem of visual concept learning, with a specific focus on determining the optimal level of concept generalization. To tackle this, the authors first construct a large-scale dataset of concepts at varying levels of abstraction from ILSVRC, accompanied by human judgments collected on Amazon Mechanical Turk (AMT). They then propose a Bayesian concept learning algorithm designed to handle perceptual uncertainty. The problem of learning concepts across different levels of abstraction is indeed captivating. However, upon review, it is found that the algorithm's presentation lacks clarity and intuitive explanations, which hinders understanding. Furthermore, the experimental evaluation is somewhat compromised due to the absence of comparisons with robust baselines.
Detailed comments are provided below:
1. In equations (4) and (5), the function I(.) appears to be an indicator function. Clarification on this would be beneficial.
2. The notation in equation (4), specifically I(xi ⊆ h), suggests that both $h$ and $xi$ are sets, which is confusing. The reason for $xi$ being represented as a set needs explanation, especially since in equation (5), $\hat{y}i$ is treated as an individual item, as indicated by I($\hat{y}_i$ ∈ h).
3. Equation (5) seems to imply that the summation primarily affects the first term, A{j$\hat{y}i$}, with the remaining parts being independent of the index $j$. This reduces the summation of A{j$\hat{y}i$} to a single column vector. The motivation behind this equation and its intended outcome require further elucidation.
4. A potential typo is noticed on the last line of page 5, which states "...the true leaf node is $j$ given the classifier output being $j$". It should be verified if the repetition of $j$ is intentional.
5. The statement in line 243 on page 5, regarding the increase in examples of Dalmatians making it more likely for the concept to be specifically about Dalmatians rather than dogs in general, is logically sound. However, its implications on hypothesis size are unclear. The definition of hypothesis size as the number of samples belonging to a hypothesis is confusing, especially considering that the number of potential images for any concept can be infinitely large. The use of sample numbers from ImageNet as a proxy for hypothesis size needs justification.
6. The numerous unclear aspects of the algorithm's presentation make it challenging to comprehend the proposed algorithm and understand its efficacy, despite the high-level overview provided.
7. The baseline methods employed are not sufficiently robust or convincing. For instance:
a) The naive vision approach uses only GIST features, whereas the proposed algorithm utilizes an overcomplete feature set of 160K dimensions, making the comparison unfair.
b) The paper mentions recent deep neural network works [10, 9] in Section 4.3 but does not include them as baseline methods. The rationale for this omission, such as the requirement for more training data, should be explained. If a deep neural network could replicate the proposed algorithm's performance with easily collectible training data from ImageNet, it would raise questions about the novelty of this work.
In conclusion, while the paper addresses an interesting problem and the authors have made significant efforts in creating a large-scale concept learning dataset with human judgments, the unclear algorithm presentation and the lack of convincing experimental evaluations, particularly due to weak baseline comparisons, are notable drawbacks.