This manuscript proposes a novel approach for jointly learning the structure and parameters of stochastic AND-OR grammars, which are capable of capturing various recursive phenomena, including those found in natural language and other grammatical systems. The authors introduce a methodology for unsupervised structure learning by iteratively adding new AND-OR fragments and evaluating the resulting model's likelihood and prior gains. 
Experimental evaluations are conducted on two tasks: learning event grammars and image grammars, yielding competitive results with existing state-of-the-art methods. 
Overall, the paper presents a promising framework for learning stochastic grammars based on AND and OR rules, offering a potentially tractable solution. However, several concerns arise: 
1) The scalability of the learning algorithm is not explicitly addressed, raising questions about its feasibility when dealing with large datasets comprising thousands of data points.
2) The absence of experiments on natural language sentences is notable, given the inherent applicability of such grammars to this domain. It would be beneficial to investigate the viability of the proposed method on benchmark datasets like the Penn Treebank, which has been a focus of previous research, such as the work by Klein and Manning. While the paper demonstrates a viable approach to estimating the structure and parameters of stochastic AND-OR grammars and reports favorable outcomes on two tasks, additional experiments, particularly those involving natural language data, would strengthen the manuscript.