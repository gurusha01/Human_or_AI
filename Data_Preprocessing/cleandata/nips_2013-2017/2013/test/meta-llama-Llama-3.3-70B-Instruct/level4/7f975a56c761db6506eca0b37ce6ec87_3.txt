This manuscript presents novel distributed algorithms for k-means and k-median clustering methods, leveraging the concept of constructing a global coreset in a distributed manner using local approximation cost information. The paper is well-structured and contains substantial technical content, including a distributed protocol for k-means/median clustering based on coreset construction, theoretical guarantees on approximation quality, and upper bounds on communication costs, along with experimental evaluations demonstrating the superiority of the proposed approach over existing methods.
However, several limitations accompany this work. Primarily, the main technical contribution of the paper is not immediately clear, particularly in light of existing research presented in references [5], [10], and [19]. The utilization of coreset ideas for approximating clustering algorithms is a well-established concept, as seen in [5] and [10], and a distributed clustering algorithm based on coreset construction has been proposed in [19]. Upon closer examination, it becomes apparent that this paper contributes a distributed coreset construction method that is independent of network topology and improves upon the algorithm in [19] by reducing communication costs by a factor of sqrt(n). Nonetheless, the distributed coreset construction outlined in Algorithm 1 and the associated bounds appear to directly apply results from [5] in a straightforward manner.
The inclusion of theoretical analysis and upper bounds on coreset size and communication costs is a notable aspect of the paper. However, these upper bounds seem excessively loose for practical application purposes. For instance, given a specific dataset and its distribution across a distributed network, determining the coreset size remains unclear. The provided bound for achieving this in k-means, O(kd/(e^4)), could yield an impractically large coreset size even for moderately large k, d, and relatively small e. For example, with k=10, d=100, and e=0.1, the predicted coreset size based on the bound is 10 million, which could far exceed the actual data size.
The experimental section raises additional questions, as the number of distributed sites used is relatively small (e.g., 10 for Pendigits, 25 for ColorHistogram). It would be beneficial to see the results of experiments conducted with a larger number of distributed sites. Furthermore, the datasets employed in the experiments are of relatively low dimensionality, prompting the question of whether this approach would be effective for high-dimensional sparse data. In conclusion, while the paper is well-written and contains solid technical content, it also has several drawbacks, including an unclear technical contribution and overly loose upper bounds.