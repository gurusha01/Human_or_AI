The authors investigate binary classification under random, class-conditional noise in training data, proposing two approaches that modify a surrogate loss function and establish performance bounds. Specifically, they offer guarantees for convex surrogate risk minimization with random label noise, making no assumptions about the true distribution, and present two methods to adjust a given surrogate loss. Experimental results are provided using synthetic and benchmark datasets.
The paper is well-structured and technically robust. Although the theoretical findings are noteworthy, they do not significantly surpass existing research in related areas. A potential concern lies in the assumption of constant class noise in the training data, which may not accurately reflect real-world scenarios. This concern is valid despite the paper's theoretical focus, and its technical soundness and clarity are notable. The theoretical contributions, while not groundbreaking, are still appreciable, but the assumption of constant class noise may be questionable in terms of practical relevance.