This manuscript introduces a novel approach to domain adaptation in computer vision datasets, which typically exhibit multiple facets such as viewpoint, illumination, and level of clutter. Unlike conventional methods that conflate domains with datasets, thereby intertwining these aspects, the proposed technique automatically segregates the collective set of images across datasets into distinct domains. The domain partitioning is guided by two fundamental principles: creating separate domains in feature space and ensuring that a robust discriminative classifier can be trained on each domain to classify the original classes. This method is more inclined to partition domains based on underlying aspects rather than datasets.
Originality and significance:
The paper contributes to the limited body of work on automatic domain definition, presenting a promising concept for discovering useful domains that can support the training of enhanced classifiers for the original problem.
However, the proposed optimization method outlined in section 2 raises concerns, as it is unclear how effectively it addresses the original problem stated in equations (2) and (3). Furthermore, the two driving criteria are not well-integrated, with the maximal learnability criterion serving merely as a post-hoc validation metric to determine the optimal number of domains, rather than being directly incorporated into the partitioning process. A more integrated approach would yield a partitioning that maximizes a goal function encompassing both criteria.
Despite these limitations, which may be attributed to the exploratory nature of this research, the paper represents a positive step forward for the community and warrants acceptance.
Quality and clarity:
The manuscript is well-written but lacks illustrative figures to facilitate comprehension of the presented concepts.
Experiments:
The experiments demonstrate a significant advantage in utilizing the domains generated by the proposed method over using datasets as domains and over the recent domain discovery technique [19] (section 4.2). The concept of incorporating the test set in the 'reshaping' process is intriguing but not clearly articulated (section 4.3), and it corresponds to an imputation setting where all test data is available simultaneously, although this is not explicitly stated.
A notable drawback is the use of a simplistic and outdated image descriptor, comprising a single bag-of-words of sparse SURF features for the entire image, with a limited 800-codebook entries. This is inadequate by current standards. It is recommended that the authors employ a spatial pyramid of bag-of-words computed on dense SURF features. Additionally, the similarity measure used to compare image descriptors is unclear, and it is hoped that X^2 or an intersection kernel was utilized, as the Euclidean distance is unsuitable for comparing histograms. Consideration of a Fisher Vector representation could further enhance the image representation, bringing it in line with modern systems. Relevant references that may aid the authors include Zhang (IJCV 2006), Jurie (CVPR 2005), Lazebnik (CVPR 2006), and Perronin (ECCV 2010).
Overall, the manuscript presents innovative ideas on a crucial problem and achieves commendable results. However, there is room for improvement, particularly in terms of the image representation employed.