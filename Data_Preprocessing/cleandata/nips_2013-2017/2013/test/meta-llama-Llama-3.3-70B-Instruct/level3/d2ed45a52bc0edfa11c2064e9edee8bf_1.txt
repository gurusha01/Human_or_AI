This paper presents a novel approach to visual concept learning, combining object classification tools and Bayesian generalization to improve upon baseline methods. The authors introduce a large-scale dataset for visual concept learning, leveraging ImageNet images and human annotators to provide ground truth labels. The paper is well-written and engaging, making it a strong fit for the NIPS community.
The proposed algorithm demonstrates significant improvement over baseline methods, showcasing the potential of integrating machine vision and cognitive science techniques. The use of probabilistic predictions from visual classifiers as input to a Bayesian generalization model allows for more accurate and human-like concept learning. The authors' decision to collect and make available a large-scale dataset for visual concept learning is a valuable contribution to the field, enabling future research and development in this area.
However, there are some areas that require further attention. The authors' claim about the criteria for choosing levels of nested concepts lacks validation, and relevant citations, such as Rosch et al. (1976), should be provided to support their argument. Additionally, there appear to be potential errors in the equations in section 4.1, including a possible mix-up between P(h|X) and P(X|h), and unclear notation in equation 4. The description of the extension of [5] (HB) is also unclear and requires clarification, particularly regarding the subtree's accuracy over example images versus query images.
The paper's strengths include its originality, significance, and technical soundness. The authors' approach is novel and addresses a challenging problem in machine vision, making it a significant contribution to the field. The paper is also well-organized and clearly written, providing sufficient information for expert readers to reproduce the results.
Arguments for acceptance include:
* The paper presents a novel and significant contribution to the field of machine vision
* The proposed algorithm demonstrates improved performance over baseline methods
* The authors provide a valuable contribution to the field by collecting and making available a large-scale dataset for visual concept learning
Arguments against acceptance include:
* The lack of validation for the criteria for choosing levels of nested concepts
* Potential errors in the equations in section 4.1
* Unclear description of the extension of [5] (HB)
Overall, the paper is well-written and presents a significant contribution to the field. With some revisions to address the mentioned concerns, it has the potential to be a strong addition to the NIPS conference.