This paper presents a unified formalization of stochastic And-Or grammars and proposes an unsupervised approach to learning the structures and parameters of such grammars. The approach optimizes the posterior probability of the grammar and induces compositions and reconfigurations in a unified manner. The paper is well-written, and the authors provide a clear and concise explanation of the proposed approach.
The paper has several strengths. Firstly, the proposed approach is original and poses an important and interesting question. The authors provide a unified formalization of stochastic And-Or grammars that is agnostic to the type of data being modeled, which is a significant contribution to the field. Secondly, the approach is evaluated on two different datasets, including event grammars and image grammars, and the results show satisfactory performance.
However, the paper also has some weaknesses. One of the main limitations is that the approach uses overly simple algorithm forms that do not account for step costs or joint search and stopping policies. Additionally, the comparison between human and algorithm performance may not be entirely fair due to the algorithms' arbitrary stopping rules and lack of sensitivity to the objective. Furthermore, the contribution of GP and sampling policy to the performance of BO algorithms is not clearly separated, making it difficult to determine the source of their effectiveness.
The paper also lacks clear figure descriptions, and there are some minor errors and unclear points, such as the calculation of "mean shortest distance". Moreover, the authors' approach and method have some problems that need to be elaborated on. For example, the authors propose to search for And-Or fragments in the learning algorithm, but it is not clear how this is done in practice.
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The paper is also well-organized, and the authors provide a clear and concise explanation of the proposed approach. However, the paper could benefit from more detailed explanations of some of the technical aspects, such as the calculation of the posterior gain and the prior gain.
In terms of originality, the paper presents a novel approach to learning stochastic And-Or grammars, and the authors provide a unified formalization of such grammars that is agnostic to the type of data being modeled. The paper also provides unique experimental data and evaluates the approach on two different datasets.
In terms of significance, the paper addresses an important and interesting question, and the proposed approach has the potential to make a significant impact in the field. The paper also provides a clear and concise explanation of the proposed approach, which makes it easy to follow and understand.
Overall, I would recommend accepting this paper, but with some revisions to address the weaknesses mentioned above. The authors should provide more detailed explanations of some of the technical aspects, such as the calculation of the posterior gain and the prior gain. Additionally, the authors should clarify the contribution of GP and sampling policy to the performance of BO algorithms and provide more detailed explanations of the search for And-Or fragments in the learning algorithm.
Arguments for acceptance:
* The paper presents a novel approach to learning stochastic And-Or grammars.
* The authors provide a unified formalization of such grammars that is agnostic to the type of data being modeled.
* The approach is evaluated on two different datasets, including event grammars and image grammars, and the results show satisfactory performance.
* The paper addresses an important and interesting question and has the potential to make a significant impact in the field.
Arguments for rejection:
* The approach uses overly simple algorithm forms that do not account for step costs or joint search and stopping policies.
* The comparison between human and algorithm performance may not be entirely fair due to the algorithms' arbitrary stopping rules and lack of sensitivity to the objective.
* The contribution of GP and sampling policy to the performance of BO algorithms is not clearly separated.
* The paper lacks clear figure descriptions, and there are some minor errors and unclear points.