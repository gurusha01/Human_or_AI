This paper presents a novel approach to distributed machine learning, leveraging optimistic concurrency control (OCC) to achieve high parallelism while preserving correctness. The authors demonstrate the effectiveness of OCC in various settings, including clustering, feature learning, and online facility location. The paper improves upon previous bounds on the complexity of policy iteration for finite MDPs and generalizes results to stochastic MDPs under additional restrictions.
The results are significant to the RL community, providing a better understanding of the complexity of policy iteration in finite settings. The paper's improvements are partly marginal, but its streamlined proofs and extension to stochastic MDPs are notable contributions. The paper is relatively well-written, but contains some typos and areas for improvement in fluency and clarity.
The results are believed to be sound, but some minor issues, such as unspecified lemmas, need to be addressed. The authors provide a thorough analysis of the OCC approach, including serializability, scalability, and approximation guarantees. The experimental results demonstrate strong scalability in practice, with near-perfect scaling achieved in some cases.
The paper's strengths include its novel approach to distributed machine learning, its thorough analysis, and its experimental evaluation. The weaknesses include some minor issues with clarity and the need for further refinement of the OCC approach. Overall, the paper makes a significant contribution to the field of distributed machine learning and is a strong candidate for acceptance.
Arguments pro acceptance:
* Novel approach to distributed machine learning
* Thorough analysis of OCC approach
* Experimental evaluation demonstrates strong scalability
* Significant contribution to the field of distributed machine learning
Arguments con acceptance:
* Some minor issues with clarity
* Need for further refinement of OCC approach
* Limited evaluation of OCC approach in certain settings
Overall, the paper's strengths outweigh its weaknesses, and it is a strong candidate for acceptance. With some minor revisions to address the issues mentioned above, the paper has the potential to make a significant impact in the field of distributed machine learning.