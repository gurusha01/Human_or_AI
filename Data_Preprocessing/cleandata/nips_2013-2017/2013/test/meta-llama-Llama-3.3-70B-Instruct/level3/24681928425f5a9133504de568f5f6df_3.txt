This paper proposes a novel approach to distributed machine learning using optimistic concurrency control (OCC), which offers a middle ground between strict concurrency constraints and coordination-free parallelism. The authors demonstrate the effectiveness of OCC in three problem areas: clustering, feature learning, and online facility location. The paper is technically sound, and the authors provide a clear and well-structured presentation of their approach.
The strengths of the paper include its novelty, clarity, and significance. The OCC approach is a new and well-motivated paradigm for distributed machine learning, and the authors provide a thorough analysis of its correctness and scalability. The paper is well-organized, and the authors provide sufficient background information and references to related work. The results are significant, as they demonstrate the potential of OCC to achieve high parallelism without sacrificing correctness.
However, there are some weaknesses and areas for improvement. The experimental section is unclear and difficult to understand, particularly for readers without prior knowledge of recent visual-grammar papers from S. C. Zhu's group. The authors could provide more details and concrete illustrations of their experiments to make the results more understandable and useful. Additionally, the paper's results are presented purely quantitatively, which is a letdown. The authors could have shown that interesting structure is learned through their approach, which would have made the paper more compelling.
Some specific questions and suggestions for the authors include:
* Can the authors provide more intuition about why OCC is particularly suitable for machine learning algorithms?
* How do the authors plan to extend their approach to more complex machine learning models and tasks?
* Can the authors provide more details about the implementation of their algorithms and the experimental setup?
* How do the authors plan to address the potential limitations and challenges of their approach, such as the need for careful tuning of hyperparameters?
Overall, this is a strong paper that makes a significant contribution to the field of distributed machine learning. With some revisions to address the weaknesses and areas for improvement, the paper has the potential to be even more effective in communicating the authors' ideas and results to the reader.
Arguments pro acceptance:
* The paper proposes a novel and well-motivated approach to distributed machine learning.
* The authors provide a thorough analysis of the correctness and scalability of their approach.
* The results are significant and demonstrate the potential of OCC to achieve high parallelism without sacrificing correctness.
Arguments con acceptance:
* The experimental section is unclear and difficult to understand.
* The paper's results are presented purely quantitatively, which is a letdown.
* The authors could provide more details and concrete illustrations of their experiments to make the results more understandable and useful.