This paper proposes a novel approach to distributed machine learning, called optimistic concurrency control (OCC), which offers a middle ground between strict concurrency constraints and coordination-free parallelism. The authors demonstrate the effectiveness of OCC in three problem areas: clustering, feature learning, and online facility location. The paper is well-written, and the contribution of using OCC in a machine learning setting is clearly identified.
The paper provides a thorough analysis of the OCC approach, including its correctness and scalability. The authors establish the serializability of the distributed algorithms, which allows them to preserve the theoretical properties of the serial algorithms. They also provide a scalability analysis, which shows that the communication cost depends on the number of clusters and processing resources, but not directly on the number of data points.
The experimental results demonstrate the effectiveness of the OCC approach in practice. The authors show that the OCC algorithms achieve strong scalability on a distributed computing platform, with near-perfect scaling in some cases. The results also demonstrate that the OCC approach can handle large datasets and achieve good approximation guarantees.
The paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The authors are careful and honest about evaluating both the strengths and weaknesses of the work. The paper is clearly written, well-organized, and provides enough information for the expert reader to reproduce the results.
The originality of the paper lies in its novel application of OCC to machine learning problems. The authors provide a unique combination of familiar techniques, and the paper differs significantly from previous contributions. The related work is adequately referenced, and the authors provide a clear discussion of the differences between their approach and previous work.
The significance of the paper lies in its potential to advance the state of the art in distributed machine learning. The OCC approach provides a new way to design distributed algorithms that preserve correctness while achieving good scalability. The paper addresses a difficult problem in a better way than previous research and provides unique insights into the application of OCC to machine learning problems.
Arguments pro acceptance:
* The paper proposes a novel approach to distributed machine learning that preserves correctness while achieving good scalability.
* The paper provides a thorough analysis of the OCC approach, including its correctness and scalability.
* The experimental results demonstrate the effectiveness of the OCC approach in practice.
* The paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results.
Arguments con acceptance:
* The paper may benefit from more comparisons with other algorithms, such as KL-UCRL, which has been proven to have better empirical performance than UCRL2 on certain environments.
* The paper could provide more context on the current state-of-the-art values for the regret bound of PSRL.
* There are some minor errors and formatting issues in the paper, including typos and inconsistent reference formatting.