This paper proposes a novel approach to distributed machine learning, called optimistic concurrency control (OCC), which offers a middle ground between strict concurrency constraints and coordination-free parallelism. The authors demonstrate the effectiveness of OCC in three problem areas: clustering, feature learning, and online facility location. The paper is well-written, and the ideas are clearly presented.
The strengths of the paper include:
* The introduction of a new paradigm for distributed machine learning, which has the potential to improve the scalability and efficiency of machine learning algorithms.
* The provision of a clear and detailed explanation of the OCC approach, including its application to various machine learning problems.
* The presentation of theoretical results, such as the serializability of the distributed algorithms and the approximation guarantees for the online facility location algorithm.
* The evaluation of the OCC approach through large-scale experiments, which demonstrate its scalability and effectiveness in practice.
The weaknesses of the paper include:
* The assumption that conflicts are infrequent, which may not always be the case in practice.
* The potential for high communication overhead, particularly in the validation phase of the OCC algorithm.
* The lack of comparison with other distributed machine learning approaches, such as divide-and-conquer schemes or coordination-free parallelism.
Arguments for acceptance:
* The paper introduces a novel and promising approach to distributed machine learning, which has the potential to improve the scalability and efficiency of machine learning algorithms.
* The paper provides a clear and detailed explanation of the OCC approach, including its application to various machine learning problems.
* The paper presents theoretical results and experimental evaluations that demonstrate the effectiveness of the OCC approach.
Arguments against acceptance:
* The paper assumes that conflicts are infrequent, which may not always be the case in practice.
* The paper does not provide a comprehensive comparison with other distributed machine learning approaches.
* The paper could benefit from more detailed analysis of the communication overhead and its impact on the scalability of the OCC approach.
Overall, I believe that the paper makes a significant contribution to the field of distributed machine learning and deserves to be accepted. However, the authors should address the weaknesses mentioned above, particularly the assumption of infrequent conflicts and the lack of comparison with other approaches. 
Quality: 8/10
The paper is well-written, and the ideas are clearly presented. The theoretical results and experimental evaluations are convincing, but the paper could benefit from more detailed analysis of the communication overhead and its impact on the scalability of the OCC approach.
Clarity: 9/10
The paper is well-organized, and the ideas are clearly presented. The notation is consistent, and the figures and tables are helpful in understanding the concepts.
Originality: 9/10
The paper introduces a novel approach to distributed machine learning, which has the potential to improve the scalability and efficiency of machine learning algorithms.
Significance: 8/10
The paper makes a significant contribution to the field of distributed machine learning, but its impact could be further enhanced by more comprehensive comparisons with other approaches and more detailed analysis of the communication overhead.