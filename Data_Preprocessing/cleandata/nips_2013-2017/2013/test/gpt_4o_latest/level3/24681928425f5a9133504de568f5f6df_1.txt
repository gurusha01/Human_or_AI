The paper presents a novel method for learning the structure of stochastic And-Or grammars (AOGs), offering a unified framework that is agnostic to the type of data being modeled. By framing the problem as a special case, the authors make the structure learning process more tractable. The proposed approach iteratively induces grammar fragments in a unified manner, optimizing the posterior probability of the grammar. The method is evaluated on both event and image grammars, achieving competitive or superior performance compared to prior approaches.
Strengths:
1. Technical Contribution: The paper provides a unified formalization of stochastic And-Or grammars, which is a significant step forward in making these grammars applicable to diverse data types, such as images and events. The integration of structure and parameter learning into a single framework is particularly noteworthy.
2. Algorithm Design: The proposed algorithm is well-motivated and sensible. The use of And-Or fragments to unify the learning of compositions and reconfigurations is an innovative approach that addresses challenges like data scarcity and ambiguity in grammar induction.
3. Experimental Results: The method demonstrates strong empirical performance, outperforming prior approaches on synthetic and real-world datasets for both event and image grammars. The inclusion of evaluations on multiple datasets enhances the credibility of the results.
4. Clarity and Organization: The paper is well-written and organized, with clear explanations of the methodology and experimental setup. The inclusion of figures and examples aids in understanding the learning process.
Weaknesses:
1. Overstated Generalization: The claim of generalizing previous work is somewhat overstated. While the method builds on prior approaches, it does not fully subsume them, particularly in terms of handling specific nuances of Stolcke and Omohondro's method or other established techniques.
2. Limited Comparisons: The experimental evaluation could be more comprehensive. Specifically, comparisons with Stolcke and Omohondro's grammar induction method are missing, which would provide a stronger baseline for assessing the proposed approach.
3. Scalability: While the algorithm is described as efficient, the scalability to larger datasets or grammars with more complex structures is not thoroughly discussed or demonstrated.
Arguments for Acceptance:
- The paper introduces a novel and unified approach to learning stochastic And-Or grammars, which is a valuable contribution to the field.
- The proposed method is technically sound and demonstrates strong empirical performance.
- The work addresses a challenging problem and has the potential to inspire further research in grammar induction.
Arguments Against Acceptance:
- The lack of comparisons with Stolcke and Omohondro's method limits the ability to fully contextualize the contribution.
- The claim of generalization over prior work is not entirely substantiated.
Recommendation:
Overall, this is a solid and well-executed paper that makes a meaningful contribution to the study of stochastic And-Or grammars. While the experimental evaluation could be improved, the strengths of the work outweigh its weaknesses. I recommend acceptance, with the suggestion that the authors temper their claims of generalization and include additional comparisons in future versions.