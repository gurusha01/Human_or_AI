The paper presents a novel discriminative mean-shift algorithm for discovering mid-level visual features, addressing limitations in existing methods for visual element discovery. By extending the classic mean-shift algorithm to a discriminative setting, the authors propose a principled approach that identifies visually coherent patch clusters that are both representative and discriminative. A key contribution is the introduction of the purity-coverage curve as a robust evaluation metric, which provides a more systematic comparison of visual discovery methods. The algorithm demonstrates significant improvements on the MIT 67-scene dataset, achieving state-of-the-art performance in scene classification, with mid-level patches alone boosting accuracy from 46% to 64%. These results highlight the algorithm's effectiveness and its potential to advance mid-level visual representation research.
Strengths:
1. Technical Novelty: The paper introduces a discriminative extension of the mean-shift algorithm, which is both theoretically grounded and practically impactful. The use of density ratio estimation for mode seeking is a novel contribution that addresses the limitations of classical mean-shift in discriminative tasks.
2. Evaluation Framework: The purity-coverage curve is a valuable addition to the field, offering a principled way to evaluate and compare visual discovery methods. This framework is likely to be adopted by future research.
3. Empirical Results: The algorithm achieves impressive performance on the MIT 67-scene dataset, outperforming prior methods, including those leveraging improved Fisher vectors. The substantial improvement in scene classification accuracy underscores the significance of the proposed approach.
4. Clarity and Organization: The paper is well-written and logically structured, making the methodology and results accessible to readers. The inclusion of qualitative and quantitative results further strengthens the presentation.
5. Efficiency: The proposed algorithm requires only a single pass through the data, making it computationally efficient for large-scale datasets.
Weaknesses:
1. Running Time Comparison: While the algorithm is described as efficient, a direct comparison of running times with baseline methods is missing. Including this would provide a more comprehensive understanding of its computational advantages.
2. Generality: The paper focuses primarily on the MIT 67-scene dataset. Testing the algorithm on additional datasets, such as the SUN dataset, would help validate its generalizability and explore its ability to capture semantic structures.
3. Related Work: While the paper references prior work, it could better differentiate itself from closely related methods, particularly those using discriminative clustering techniques.
4. Source Code: The authors mention that the source code will be made available, but its absence at submission limits reproducibility and immediate adoption by the community.
Suggestions for Improvement:
1. Include a running time analysis to compare the computational efficiency of the proposed algorithm with baselines.
2. Test the algorithm on the SUN dataset to evaluate its robustness and ability to generalize to other visual domains.
3. Cite and discuss related work more thoroughly, particularly methods that use similar discriminative clustering approaches.
4. Ensure the source code is released promptly to facilitate reproducibility.
Recommendation:
This paper makes a strong scientific contribution by addressing a critical problem in mid-level visual feature discovery with a novel algorithm and evaluation framework. The results are compelling, and the methodology is well-supported by theoretical and experimental evidence. While there are minor concerns regarding running time analysis, dataset diversity, and related work discussion, these do not detract significantly from the paper's overall quality. I recommend acceptance to NIPS, as it advances the state of the art and provides a solid foundation for future research in this area.