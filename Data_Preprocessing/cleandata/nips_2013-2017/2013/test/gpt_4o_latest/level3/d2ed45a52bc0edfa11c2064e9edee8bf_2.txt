The paper addresses the challenging problem of visual concept learning, emphasizing generalization levels and perceptual uncertainty, and proposes a Bayesian framework to bridge cognitive science and machine vision. The authors introduce a large-scale dataset, constructed using ImageNet (ILSVRC) and human annotations via Amazon Mechanical Turk (AMT), to evaluate their approach. While the problem is novel and the dataset is a valuable contribution, the paper suffers from several critical issues that limit its impact.
Strengths:  
The paper tackles an important and underexplored problem in machine vision, moving beyond traditional classification tasks to address human-like generalization from limited examples. The proposed dataset is a significant contribution, as it provides a benchmark for evaluating visual concept learning with human-grounded labels. The integration of Bayesian generalization with perceptual classifiers is an interesting and original approach, and the results demonstrate a clear improvement over naïve baselines. The authors also provide a detailed experimental setup and analysis, including precision-recall metrics and per-level generalization comparisons, which enhance the rigor of the evaluation.
Weaknesses:  
1. Clarity: The presentation of the Bayesian concept learning algorithm is overly technical and lacks intuitive explanations, making it difficult for readers to grasp the core ideas. Equations (4) and (5), which are central to the method, require further clarification, particularly regarding the use of indicator functions and set representations. The motivation and structure of Equation (5) are unclear, and the definition of hypothesis size is confusing and lacks real-world applicability. Additionally, the high-level description of the algorithm raises doubts about its practical effectiveness.  
2. Experimental Evaluation: The experimental evaluation is weak due to the absence of comparisons with strong baselines, such as deep neural networks (DNNs). The inclusion of only limited-feature naïve baselines makes the comparisons appear biased. The paper does not adequately justify why stronger methods were excluded, which undermines the credibility of the results.  
3. Dataset and Implementation: While the dataset is a valuable resource, the paper does not provide sufficient details about its construction process, such as the quality control measures for AMT annotations. Additionally, the reported classifier accuracy (41.33% top-1) is suboptimal compared to state-of-the-art ImageNet classifiers, which may limit the generalizability of the proposed method.  
4. Writing and Typos: The paper contains a typo in the last line of page 5, which should be corrected for clarity. The overall writing could benefit from better organization and clearer explanations.
Pro and Con Arguments for Acceptance:  
Pros:  
- Novel problem formulation and dataset contribution.  
- Interesting integration of Bayesian generalization with perceptual inputs.  
- Demonstrates improvement over naïve baselines.  
Cons:  
- Lack of clarity in algorithm presentation and key equations.  
- Weak experimental evaluation with insufficient baseline comparisons.  
- Suboptimal classifier performance and limited real-world applicability.  
Recommendation: While the paper introduces a novel problem and makes interesting contributions, the lack of clarity, insufficient baseline comparisons, and weak experimental evaluation significantly undermine its quality. I recommend rejection in its current form but encourage the authors to address these issues and resubmit to a future venue.