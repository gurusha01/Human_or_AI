This paper addresses the challenging problem of automatically discovering latent domains in datasets for improved classification performance within a domain adaptation framework. The authors propose a novel approach that imposes two key properties on domains: maximum distinctiveness and maximum learnability. The methodology involves defining a kernel-based function to measure distribution differences, partitioning data into domains to maximize this function, and formulating the problem as integer programming with constraints, later relaxed to a continuous optimization framework. The number of domains is determined via a domain-wise cross-validation (DWCV) procedure. The approach is evaluated on object and human activity recognition tasks, showing significant performance improvements over a prior domain adaptation method ([19]).
Strengths
The paper presents a novel and well-motivated approach to latent domain discovery, addressing a critical gap in domain adaptation research. The use of nonparametric methods to measure domain distinctiveness and the introduction of DWCV for determining the number of domains are innovative contributions. The experimental results demonstrate clear performance gains over prior work, validating the effectiveness of the proposed method. The paper is well-written and organized, with a clear exposition of the methodology and detailed experimental results. Additionally, the qualitative analysis of identified domains provides valuable insights into the factors influencing domain formation, such as object pose, background, and lighting.
Weaknesses
The paper raises some concerns regarding its motivation and constraints. The authors argue against per-category domain reshaping but provide limited evidence or explanation for why this is suboptimal. It remains unclear how the model formulation explicitly enforces this avoidance. The label prior constraint (LPC) is another area of concern, as its necessity is not well-justified. A comparison of performance without LPC and against simpler baselines like k-means clustering or random partitioning would strengthen the argument for its inclusion. Additionally, terms like "maximally different in distribution" and specific bounds in the optimization constraints require further clarification. The paper also lacks a systematic analysis of why the proposed approach outperforms [19] and examples of baseline failures it overcomes. Finally, implementation details, such as the use of the geodesic flow kernel, are insufficiently described, leaving questions about reproducibility.
Minor Comments
The paper contains minor errors, such as a typographical issue in Eq (1) (M'k should be Mk'). The authors should also consider citing "Unbiased Look at Dataset Bias" to provide additional context on dataset bias in domain adaptation.
Verdict
The paper makes a significant contribution to the field of domain adaptation by introducing a novel and effective approach to latent domain discovery. While the concerns regarding motivation, LPC, and baseline comparisons were partially addressed in the rebuttal, they remain areas for improvement. Overall, the paper leans toward acceptance due to its originality, clarity, and demonstrated performance gains, but addressing the highlighted weaknesses would make the contribution even stronger.