The paper introduces Dirichlet-NormalGamma Monte-Carlo Tree Search (DNG-MCTS), a novel algorithm for online planning in Markov Decision Processes (MDPs) with unknown transition probabilities. By leveraging Thompson sampling for action selection and Bayesian mixture modeling to represent accumulated rewards as mixtures of Normal distributions, the authors aim to improve upon the exploration-exploitation trade-off in Monte-Carlo Tree Search (MCTS). The paper is well-written, original, and presents an interesting approach, but certain aspects of its soundness and claims require further scrutiny.
Strengths:
1. Novelty and Originality: The use of Thompson sampling in MCTS is innovative and aligns with recent empirical findings on its superiority over UCB in multi-armed bandit (MAB) problems. The Bayesian framework for modeling rewards as mixtures of Normal distributions is a compelling extension of prior work.
2. Clarity and Organization: The paper is well-structured, with clear explanations of the algorithm, its assumptions, and experimental setup. The inclusion of detailed derivations and theoretical justifications enhances its readability.
3. Experimental Results: The algorithm demonstrates competitive performance against UCT in benchmark MDP domains, particularly in terms of sample complexity. This supports the claim that DNG-MCTS advances the state-of-the-art in certain scenarios.
Weaknesses:
1. Normality Assumption: The assumption that returns at non-leaf nodes can be modeled as Normal distributions is questionable, especially when policies are non-stationary during the search process. The justification based on the central limit theorem (CLT) for Markov chains is flawed, as the modified CLT does not account for policy changes or finite horizons.
2. Convergence Guarantees: The claim of convergence to the optimal action using Thompson sampling is overstated. While Thompson sampling has theoretical guarantees in stationary MABs, its application to non-stationary MDPs lacks rigorous convergence proofs. This is a significant gap in the theoretical analysis.
3. Computational Complexity: The paper acknowledges that DNG-MCTS requires 2-4 times more computation per iteration than UCT due to the sampling overhead. Reporting CPU running times alongside sample complexity would provide a more comprehensive evaluation of its practical utility.
4. Experimental Clarity: The term "iteration" in the experiments section is ambiguous and requires clarification. Does it refer to a single simulation, a full tree expansion, or a complete decision-making cycle?
5. Minor Issues: Some references are incorrectly cited as arXiv preprints when they are published in conferences. This should be corrected for accuracy.
Recommendation:
While the paper presents a novel and promising approach, its theoretical assumptions and claims require further validation. Addressing the concerns about the normality assumption, convergence guarantees, and computational overhead would strengthen the contribution. I recommend acceptance with major revisions to clarify these issues and improve the robustness of the work.
Arguments for Acceptance:
- Novel and well-motivated algorithm.
- Competitive experimental results.
- Clear and well-organized presentation.
Arguments Against Acceptance:
- Questionable assumptions about return distributions.
- Lack of rigorous convergence guarantees.
- Computational overhead not fully addressed.
Overall, the paper is a valuable contribution to the field, but revisions are necessary to ensure its claims are well-supported and its practical implications are clear.