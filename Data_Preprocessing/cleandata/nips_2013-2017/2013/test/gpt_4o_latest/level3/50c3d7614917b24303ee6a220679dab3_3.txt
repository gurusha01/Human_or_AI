This paper presents a novel approach to approximately sample from continuous-state Determinantal Point Processes (DPPs) using eigen-decomposition of the dual kernel matrix. The authors propose two efficient sampling schemes based on low-rank kernel approximations: one leveraging Nystr√∂m and Random Fourier Features (RFF) techniques, and another employing Gibbs sampling for k-DPPs. These methods address the computational challenges of extending DPP sampling from discrete to continuous spaces, which has historically been infeasible for general kernels. The paper demonstrates the utility of these techniques in two applications: repulsive mixture modeling and synthesizing diverse human poses.
Strengths:
1. Technical Contribution: The paper provides a significant advancement in continuous DPP sampling, a problem that has hindered the broader application of DPPs in continuous domains. The proposed low-rank approximations and Gibbs sampling methods are well-motivated and theoretically grounded.
2. Experimental Validation: The empirical results convincingly demonstrate the effectiveness of the proposed methods. For instance, the use of DPPs as repulsive priors in mixture models leads to better-separated clusters and more interpretable density estimates. Similarly, the application to human pose synthesis highlights the method's ability to generate diverse samples with better coverage compared to i.i.d. sampling.
3. Relevance and Impact: The work addresses a challenging and important problem in machine learning, with applications in clustering, density estimation, and generative modeling. The proposed methods are likely to inspire further research and practical applications in the ML community.
4. Clarity and Presentation: The paper is well-organized and clearly written. The authors provide a thorough review of related work, detailed derivations, and supplementary materials to support reproducibility.
Weaknesses:
1. Notation and Presentation Issues: The notation for \( n \) above Equation 16 is unclear, which could confuse readers. Additionally, figure references in the text are occasionally misaligned, detracting from the overall readability.
2. Limited Discussion of Limitations: While the authors acknowledge that the RFF method introduces bias and that the Gibbs sampler may mix slowly in high-repulsion settings, a more detailed discussion of these limitations and potential mitigations would strengthen the paper.
3. Scalability Analysis: Although the authors claim linear scaling with dimensionality \( d \), a more detailed empirical analysis of runtime and memory requirements across varying dimensions would be beneficial for practitioners.
Arguments for Acceptance:
- The paper addresses a long-standing challenge in continuous DPP sampling with innovative and practical solutions.
- The methods are well-supported by theoretical analysis and empirical results, demonstrating both effectiveness and broad applicability.
- The work is highly relevant to the ML community and advances the state of the art in probabilistic modeling and sampling.
Arguments Against Acceptance:
- Minor clarity and presentation issues could hinder accessibility for some readers.
- The discussion of limitations and scalability could be expanded to provide a more balanced evaluation of the methods.
Recommendation:
Overall, this paper makes a strong scientific contribution and is well-suited for publication. The proposed methods are novel, impactful, and supported by rigorous analysis and experiments. Addressing the minor clarity and notation issues would further enhance the paper's quality. I recommend acceptance.