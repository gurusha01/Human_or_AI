The paper presents a novel two-step matrix completion approach for cross-domain classification, specifically targeting cross-language text classification. The method leverages labeled data from an auxiliary source domain and unlabeled parallel bilingual documents to bridge the language gap. The proposed approach constructs a sparse document-term matrix, applies matrix completion using a projected gradient descent algorithm, and subsequently reduces feature dimensions via Latent Semantic Indexing (LSI). The resulting low-dimensional representations are used to train a monolingual classifier. The paper is well-motivated, addressing the critical challenge of disjoint feature spaces in cross-language classification, and reports strong experimental results on multilingual Amazon product reviews.
Strengths:
1. Novelty and Simplicity: The two-step approach effectively combines matrix completion and LSI, offering a simple yet powerful method for cross-language representation learning. The use of matrix completion to infer missing entries in a sparse document-term matrix is a novel contribution.
2. Convergence Guarantee: The theoretical guarantee for the convergence of the projected gradient descent algorithm adds rigor to the proposed method.
3. Empirical Performance: The method demonstrates superior performance compared to baseline methods (e.g., CL-LSI, CL-KCCA, CL-OPCA) across 18 cross-language sentiment classification tasks. Notably, it performs well even with limited parallel bilingual data, highlighting its robustness.
4. Clarity of Presentation: The paper is generally well-organized, with detailed explanations of the optimization algorithm and experimental setup.
Weaknesses and Suggestions:
1. Choice of Dimensionality Reduction: The use of LSI for dimensionality reduction is not adequately justified. Why was LSI chosen over alternatives like Principal Component Analysis (PCA) or Canonical Correlation Analysis (CCA)? Additionally, the role of LSI in mitigating feature sparseness could be better explained.
2. Low-Rank Assumption: The assumption that a fully observed document-term matrix would be low-rank is questionable, given the inherent sparsity and high dimensionality of text data. A more detailed discussion or empirical validation of this assumption would strengthen the paper.
3. Experimental Clarity: The experimental setup requires clarification, particularly regarding the composition of training data. The discrepancy between results in Figure 1 and Table 1 should be addressed to avoid confusion.
4. Comparative Analysis: The running time of the proposed method is not reported. A comparison of computational efficiency with baseline methods like CL-LSI, CL-KCCA, and CL-OPCA would provide a more comprehensive evaluation.
5. Result Reporting: The paper could better distinguish and separately report the contributions of labeled source data and unlabeled parallel data to the overall performance.
Minor Issues:
- Fix minor notation inconsistencies and redundant phrases for improved clarity.
- Provide additional intuition on why the proposed method (TSL) outperforms other methods, particularly in relation to the low-rank condition and its interaction with matrix completion.
Recommendation:
Overall, the paper makes a valuable contribution to cross-language text classification by proposing a simple and effective method with strong empirical results. However, addressing the aforementioned weaknesses—particularly the justification for LSI, the low-rank assumption, and experimental clarity—would significantly enhance its impact. I recommend acceptance, contingent on revisions to address these issues.