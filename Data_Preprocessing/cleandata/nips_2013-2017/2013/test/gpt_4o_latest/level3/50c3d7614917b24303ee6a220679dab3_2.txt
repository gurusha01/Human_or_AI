This paper presents a general meta-algorithm for sampling from continuous determinantal point processes (DPPs), extending their applicability to a wide range of kernel functions. The authors propose two efficient sampling schemes: one leveraging low-rank kernel approximations via Nystrom and random Fourier features (RFF), and another based on Gibbs sampling for k-DPPs. The work addresses a significant gap in the literature, as prior methods for continuous DPP sampling were computationally infeasible for general kernels. The paper also demonstrates practical applications in repulsive mixture modeling and human pose synthesis, showcasing the utility of their methods.
Strengths:
1. Novelty and Contribution: The paper makes a meaningful contribution by extending RFF to general Euclidean spaces for translation-invariant kernels and introducing a Nystrom-based method for general kernels. The partially analytical approximations and explicit sampling algorithms for Gaussian, Cauchy, and Laplace kernels are particularly innovative.
2. Technical Soundness: The proposed methods are grounded in solid theoretical analysis, with clear derivations and justifications for the approximations. The dual representation of DPPs and the use of the Schur complement for Gibbs sampling are elegant and well-motivated.
3. Practical Relevance: The empirical results demonstrate the effectiveness of the proposed methods in real-world applications, such as repulsive mixture modeling and generating diverse human poses. The scalability of the methods to high-dimensional spaces is a significant advantage.
4. Clarity and Accessibility: The paper is well-written and accessible to readers familiar with DPPs and kernel methods. The authors provide sufficient background and detailed explanations of their algorithms.
Weaknesses:
1. Notation and Algorithm Presentation: Algorithm 1 suffers from some notation confusion, which could hinder reproducibility. A clearer explanation of the Gibbs sampling step and its computational complexity would improve the paper's clarity.
2. Empirical Evaluation: While the paper includes a thorough empirical analysis, the Nystrom method is only evaluated on translation-invariant kernels. Demonstrating its performance on non-translation-invariant kernels would strengthen the claims of general applicability.
3. Page Limit Exceedance: The paper exceeds the NeurIPS page limits, which may indicate a need for more concise presentation. Some sections, such as the detailed derivations, could be moved to the supplementary material.
Arguments for Acceptance:
- The paper addresses a critical challenge in continuous DPP sampling, making it a valuable contribution to the field.
- The methods are novel, technically sound, and applicable to a wide range of problems.
- The empirical results are convincing and demonstrate the practical utility of the proposed algorithms.
Arguments Against Acceptance:
- The paper exceeds the page limits, and some sections could be streamlined.
- The evaluation of the Nystrom method on non-translation-invariant kernels is missing, leaving a gap in the empirical validation.
Recommendation:
I recommend acceptance of this paper, as its contributions significantly advance the state of the art in continuous DPP sampling. However, the authors should address the clarity issues in Algorithm 1 and consider showcasing the Nystrom method on non-translation-invariant kernels to further strengthen the paper.