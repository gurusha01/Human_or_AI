The paper addresses the problem of binary classification in the presence of class-conditional random label noise (CCN), a practically significant challenge in supervised learning. The authors propose two novel methods to modify surrogate loss functions: (1) an unbiased estimator approach and (2) a weighted surrogate loss approach. Both methods are theoretically analyzed, with provable risk bounds and practical implications. Notably, the paper demonstrates that commonly used methods such as biased SVMs and weighted logistic regression are inherently noise-tolerant. Experimental results on synthetic and benchmark datasets validate the robustness of the proposed methods, achieving competitive performance even under high noise rates. This work builds on prior research on noisy labels, including foundational studies on random classification noise (Angluin and Laird, 1988) and convex loss functions (Manwani and Sastry, 2013), while addressing gaps in the literature, such as the lack of general results for CCN.
Strengths:
1. Theoretical Contributions: The paper provides rigorous theoretical guarantees for risk minimization under CCN, including novel results for convex surrogate losses and weighted loss functions. The derivation of risk bounds and the conditions for convexity are significant contributions.
2. Practical Relevance: The methods are computationally efficient and easy to implement, making them accessible for real-world applications. The demonstration of noise tolerance in biased SVMs and weighted logistic regression bridges theory and practice.
3. Experimental Validation: The experiments are thorough, comparing the proposed methods against state-of-the-art approaches on both synthetic and real-world datasets. The results convincingly show the robustness of the methods under varying noise rates.
4. Novelty: The work extends prior research by addressing CCN without restrictive assumptions on the true distribution, making it a meaningful advancement in the field.
Weaknesses:
1. Clarity: While the theoretical sections are detailed, some parts of the paper, particularly the derivation of the unbiased estimator and the weighted loss functions, could benefit from clearer explanations and more intuitive examples to aid understanding.
2. Limited Scope of Noise Models: The paper focuses on CCN and does not address more complex noise models, such as adversarial or instance-dependent noise. While the authors acknowledge this as future work, it limits the immediate applicability of the methods in more challenging settings.
3. Empirical Comparisons: Although the proposed methods perform well, the experiments could include additional baselines, particularly recent advancements in robust learning under noisy labels, to provide a more comprehensive evaluation.
Arguments for Acceptance:
- The paper makes significant theoretical contributions to learning under CCN, filling a gap in the literature.
- The proposed methods are practical, efficient, and validated through extensive experiments.
- The work is highly relevant to the NeurIPS community, addressing a fundamental problem in machine learning with both theoretical and empirical rigor.
Arguments Against Acceptance:
- The clarity of some theoretical sections could be improved to enhance accessibility for a broader audience.
- The scope is limited to CCN, and the methods may not generalize to more complex noise models.
Recommendation:
I recommend acceptance of this paper. Its contributions to the theoretical understanding of learning under CCN, combined with practical algorithms and strong empirical results, make it a valuable addition to the conference. Improvements in clarity and broader scope could further enhance the impact of this work.