The paper introduces a method for translingual representation learning by initially employing matrix completion to generate multilingual vectors for each row, followed by applying CL-LSI on these multilingual vectors.
Quality: While the approach appears promising, I have concerns about the robustness of the results. The observed positive outcomes might simply stem from the scaling properties of LSI being more favorable than those of OPCA or CCA when paired with a linear SVM.
I recommend that the authors test their two-step system with a machine learning model that is invariant to feature rescaling, such as boosted decision trees (available in Weka). If boosted decision trees outperform other techniques when applied to this system, I would be more convinced of the validity of the results.
Significance: If the results are indeed robust, this would be an interesting contribution, as matrix completion is a well-established non-linear inference method.
Novelty: The proposed idea appears to be novel.
Clarity: There are some clarity issues in the paper. For instance, Line 113 mentions "construct[ing] a unified document-term matrix for all documents," but it is unclear whether this involves using a single term for each surface form (e.g., "Merkel") or assigning distinct labels for each surface form in each language (e.g., "Merkelen" and "Merkelde"). This should be clarified. Additionally, the description of the experimental setup is fragmented across Table 1, which made it somewhat challenging to follow.
Overall, this seems like an interesting idea. However, I strongly encourage the authors to explore classifiers beyond linear SVM, as the current results may be influenced by scaling artifacts rather than reflecting the true robustness of the method.