The paper introduces a straightforward yet remarkably effective method for constructing the feature space for face verification (determining whether two face images correspond to the same individual). The approach involves pre-selecting a set of training templates and, during testing, computing the image signature through an innovative projection onto the principal components of the training set. Furthermore, the authors have compiled a novel face verification dataset comprising 12,500 images of 450 individuals, none of whom are present in the LFW or PubFig datasets.
POSITIVE:
(1) The proposed approach is simple, well-motivated, and rigorously evaluated.
(2) The experimental results clearly demonstrate significant improvements over state-of-the-art methods and several baselines across four datasets (LFW, PubFig, PubFig83, and the newly introduced dataset). Notably, the template images derived from the new dataset were effectively applied to all other datasets.
Particularly noteworthy is Figure 3(b), which evaluates face verification accuracy as a function of the number of frames removed from each template's transformation sequence. Impressively, the accuracy remains stable even when up to 80% of the (non-consecutive) frames are discarded. Additionally, Figure 3(c) highlights a striking robustness to background clutter when compared to standard HOG representations.
(3) The paper is exceptionally well-written, clear, and easy to understand.
COMMENTS:
- Displaying ROC curves from four different datasets on a single set of axes (Figure 5c) is somewhat unconventional.  
- I am eager to see future extensions of this technique applied to object recognition tasks.  
The paper introduces a novel image representation that is robust to non-affine transformations of the object and convincingly demonstrates its efficacy in the context of face verification.