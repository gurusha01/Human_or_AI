This paper examines human behavior in several active search tasks and compares it to a range of established active search algorithms. The authors find that Bayesian optimization (BO) algorithms, particularly those combined with Gaussian Process (GP) priors, align more closely with human data.
Quality:
Overall, the paper is technically sound. However, I have a significant concern regarding the appropriateness of the algorithms used. Specifically, the algorithms are overly simplistic for the more complex tasks presented to humans. For instance, the algorithms fail to account for the step cost of querying a location, which humans naturally consider. Humans effectively solve a composite sampling and stopping problem, whereas the algorithms treat sampling and stopping as separate processes, relying on seemingly arbitrary stopping rules that are not sensitive to the objective (e.g., achieving higher accuracy with fewer function calls). While this limitation may not undermine the paper's primary conclusion—that BO algorithms with GP priors capture human search behavior effectively—it does raise questions about the fairness of the comparison between humans and algorithms. Notably, Figure 4e suggests that if the algorithms employed a more sophisticated, joint policy for search and stopping, their performance could match that of humans. Although the authors touch on this issue in their discussion, I believe it warrants further elaboration.
Another issue is that most BO algorithms use different mechanisms than non-Bayesian algorithms to determine the next query location. This raises the question of how the authors disentangle the contributions of the GP model from the sampling policy. For instance, GP-UCB performs well, but is this due to the GP's learning capabilities or the UCB sampling policy? Clarifying this distinction would strengthen the paper.
Clarity:
The text is generally well-written, but the figures lack sufficient descriptions (see specific questions below).
Originality:
The paper is original.
Significance:
While I have concerns about the methodology, as outlined above, the paper addresses an important and intriguing question, providing unique and valuable experimental data. It also evaluates a comprehensive set of well-known search algorithms, which enhances its contribution to the field.
Minor Comments:
- Page 3, 1st paragraph: Shouldn't it be 25 functions and 23 subjects?  
- Figure 3: I do not observe MPI intersecting the box, as claimed in the text.  
- Page 4: Which second-order measure captures the order of the query sequence? I am unclear on how "mean shortest distance" is calculated.  
- What do the histograms in several plots in Figure 6 represent?  
Summary:  
This is a strong paper that is both original and addresses an important, thought-provoking question. However, there are some methodological issues in its current form that need to be addressed.