The authors address the problem of binary classification in the presence of random, class-conditional noise in the training data. They introduce two approaches that involve suitably modifying a given surrogate loss function and establish performance bounds. Specifically, they provide guarantees for risk minimization of convex surrogates under random label noise in a general framework, without imposing any assumptions on the true data distribution. Additionally, they propose two alternative methods for adapting a surrogate loss function. The experimental results are demonstrated on synthetic data as well as several benchmark datasets.
The paper is well-written and seems to be technically sound. While the theoretical contributions are non-trivial, they are not particularly groundbreaking, especially when compared to prior work in similar settings.
One aspect that may warrant scrutiny is the practical relevance of the problem setting. Is the assumption of constant class-conditional noise in the training data a realistic one? This concern remains valid despite the paper's theoretical focus.