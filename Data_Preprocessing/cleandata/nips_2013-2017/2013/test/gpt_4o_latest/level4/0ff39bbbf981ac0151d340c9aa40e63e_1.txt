The paper introduces a matrix completion method for cross-domain classification, which effectively utilizes labeled data from an auxiliary domain as well as unlabeled parallel data. The proposed approach consists of two main steps. First, it constructs a single incomplete matrix that integrates all documents and domains, and then completes this matrix by enforcing low-rank and sparsity constraints using the projected gradient descent algorithm. Second, it applies Latent Semantic Indexing (LSI) to reduce the feature dimensionality of the completed matrix and subsequently trains a standard classifier on the transformed representation. The paper also provides a convergence guarantee for the projected gradient descent algorithm and demonstrates promising experimental results.
Below are some comments and questions:
- After estimating the completed matrix \( M^ \), you reduce the feature dimensionality from \( d \) to \( k \) using LSI due to \( M^ \)'s "insufficient capacity to handle feature sparseness." Could you elaborate on this reasoning? Is the primary motivation to reduce the dimensionality for computational efficiency, given that \( M^* \) becomes relatively dense despite the sparsity constraints? If so, why was LSI chosen over alternative dimensionality reduction techniques, such as PCA?
- The paper appears to address two distinct aspects of leveraging external data: (1) utilizing labeled source language data to improve learning on labeled target language data, and (2) leveraging unlabeled parallel data. If this interpretation is correct, it would be beneficial to explicitly separate these aspects and report the results for each individually.
- The experimental setup in Section 5.2 requires clarification. For training, did you use (a) 4k labeled source language documents, (b) 100 labeled target language documents, and (c) 2k unlabeled parallel documents? Are the classification results reported on the remaining 1900 labeled target language documents? Furthermore, in Section 5.3, are you varying the number of unlabeled parallel documents from 200 to 2k? If so, why does the performance of CL-KCCA surpass TSL in Figure 1 for EFM and EGM at 2k, but not in Table 1?
- Could you clarify why a fully observed document-term matrix would be low-rank? While it is sparse, it seems unlikely that any document would be a linear combination of others in the vocabulary space, which would imply the rank is \( \min(d, k) \). 
- Can you provide an intuition for why TSL generally outperforms other methods, particularly CCA? A multiview approach like CCA seems well-suited for cross-language representation learning. In contrast, the matrix completion approach appears less intuitive. Is the primary advantage of your method the low-rank constraint on \( M^* \)? How does this compare with other techniques?
- What is the runtime of the proposed algorithm? How does the computational cost of the projected gradient descent algorithm compare to other methods such as CL-LSI, CL-KCCA, and CL-OPCA?
Suggested revisions:
- Replace "(ij)" with "(i,j)" two sentences before Equation (2).
- Remove "such as" in the sentences preceding Equations (4) and (5).
In summary, the paper presents a matrix completion approach for cross-domain classification. While some technical aspects require further clarification, the method is straightforward, effective, and generally well-articulated.