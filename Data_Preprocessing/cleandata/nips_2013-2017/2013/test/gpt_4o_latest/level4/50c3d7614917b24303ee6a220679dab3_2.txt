The objective of this paper is to develop a method for sampling from a continuous determinantal point process (DPP), a task that has not previously been achieved for general continuous kernels. The authors propose a general "meta-algorithm" that, in principle, is applicable to a wide range of kernels, although the ease of implementation may vary depending on the specific kernel.
Prior research has focused on translation-invariant kernels within compact domains. The random Fourier features (RFF) approach introduced in this paper extends the utility of random Fourier features to general Euclidean spaces, provided the kernel is translation-invariant. Furthermore, the proposed Nystrom method broadens this applicability to general kernels, though its performance depends on effective landmark selection and tends to be more suitable for low-dimensional problems.
While RFF and Nystrom methods have been previously applied to discrete DPPs, the key innovation of this work lies in determining how to perform parts of the approximation "analytically" in certain special cases. Specifically, the authors derive explicit sampling algorithms for Gaussian, Cauchy, and Laplace kernel settings.
Overall, I found the paper to be well-motivated, clearly written, and enjoyable to read. However, the authors have exceeded the NIPS margin requirements, which has resulted in a somewhat lengthy paper. Despite this, the work represents a valuable contribution to the DPP literature in machine learning, and I recommend its acceptance.
Minor comments and suggestions:  
- The derivation of the Gibbs sampling step for the repulsive mixture could benefit from additional detail. The authors directly present a posterior that resembles a DPP, but providing an explicit breakdown of the prior and likelihood for this "interesting" sampling step would enhance clarity.  
- In Algorithm 1 (appendix), the use of Y and script-Y is somewhat confusing on an initial read, as they are not equivalent. Clarifying this distinction would improve readability.  
- It would be valuable to include a derivation of the Nystrom method for a non-translation-invariant kernel, as this would highlight its capabilities beyond what Fourier-based features can achieve.
This paper represents a meaningful extension to the growing body of work on DPPs in machine learning. It was a pleasure to review, and I hope it is accepted.