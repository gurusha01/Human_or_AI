This paper considers a setting where several contextual linear bandits are connected by the underlying graph. The assumptions is the weight vectors of the respective nodes are smooth over the graph (are close for neighbors). This appears to a be a good and rich enough model for recommendations in social networks. 
The algorithm runs classical contextual linear bandits on each node (which node is being tried is determined by nature), but then shares this information with other nodes as well so they also update their model estimates and confidence widths appropriately via Laplacian. 
Unfortunately, the regret analysis provided is disappointing. The authors in fact provide the analysis for a different algorithm than they propose and evaluate in the experiments. This could be perhaps acceptable but I found no reason whatsoever over for this. There is no discussion, 
how CB vs. TCB would change the algorithm, its evaluation and the deployment. At least the difference between TCB and CB should be discussed better than one could use the results from [1]. It is therefore possible, that the TCB-kind algorithm does not do well in the experiments or that for CB-kind it is not possible to provide learning guarantees. 
Maybe it would be better just to not include such analysis. 
Regarding the current analysis, it is not clear how big the terms ln|M_t| and 2L can be. How do they behave with T and n? This is needed in order to get some insight from the provided regret bound. And how does the graph noise influence these quantities? 
Furthermore, typically [4,9] the analyses for linear bandits give at least a guideline to set the exploration parameter \alpha. Unfortunately, we do get this from the analysis provided. 
What is the dependence of the upper bound on alpha anyway? Is it hidden in some of the quantities mentioned above? 
The experiment on the other hand are treated very well. The descriptions are very detailed and well explained. It is also great that the authors performed the experiments on real data and described the practical details to make the experiments reproducible. 
Finally, L186 - L190 The paper mentions that through graph, the reward influences other nodes in the "lesser extent", "somehow informatively" and "similar updates" are desired. However I do not see a parameter for "somehow" or "similar" in the algorithm. Could that be done by regularizing L by a multiple of I instead of I. In the experimental section, the authors mention that the clustering acts as a regularizer. Would not regularizing the Laplacian instead be 
a more principled way to achieve this regularization? 
Other comments 
- Why it is L(u1,...un) in the regret bound and not the regularized version, 
since the Laplacian is regularized in the algorithm? 
After the rebuttal: While this is a good work, I believe that including the theoretical analysis of a changed algorithm with not entirely clear relationship between the two, makes it confusing. I would increase my score if the theoretical analysis was taken away. 
 This paper extends the contextual bandits to the setting where the different bandits share their weight-vector via provided graph (useful in the social network setting). Very good experiments, but the analysis provided is disappointing and does not appear to be useful.