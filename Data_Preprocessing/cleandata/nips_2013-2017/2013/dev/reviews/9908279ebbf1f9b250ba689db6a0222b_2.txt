The authors propose a robust and sparse principal component regression (PCR) estimator for non-Gaussian data. This is motivated by theoretical arguments on when classical PCR is justified over least squares regression (when a low-rank structure is present) and by data / noise with heavy and dependent tails. Finally, the approach is demonstrated successfully on simulated and experimental equity data. 
The writing is very clear. There are two significant contributions: 
1. The authors show the when PCR is preferable to standard least squares regression (collinearity invariance, exploitation of low-rank structure in the design / sample covariance matrix). This is illustrated promptly with a few simple and intuitive synthetic experiments. 
2. Large-d-small-n cases are handled by a robust PCR variant under an elliptical family of densities model, that specialize in capturing heavy and dependent tails in the data. 
The simplicity of the proposed algorithm is salient: 
- Project data on the sparse principal eigenvector of the sample Kendall's tau (akin to sparse PCA on the sample covariance, via the truncated power algorithm). 
- Regress Y on Xu. 
Other notes: 
- line 373, F distribution -> exponential distribution 
- why do you scale the prediction error by 100 times instead of scaling the error axis? I might have misunderstood here.  After rigorously showing clear advantages of PCR vs least squares, the paper presents a novel semiparametric approach on sparse and robust PCR.I've read the author's rebuttal.