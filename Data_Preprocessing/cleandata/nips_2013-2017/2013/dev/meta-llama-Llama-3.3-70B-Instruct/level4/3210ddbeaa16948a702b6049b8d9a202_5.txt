This paper presents a novel approach to approximating the chi-square kernel using signed Cauchy random projections, which is a generalization of the Sim-hash algorithm. The connection between chi-square and collision probability serves as the motivation for this work. 
The reviewer finds the proposed method to be innovative and interesting, as it establishes a link between chi-square and random Cauchy projections, which has not been explored previously. The paper's significance lies in its potential applications to high-dimensional sparse approximations of the chi-square kernel, which could be beneficial in various text and image processing tasks.
However, the writing quality is poor, making it challenging to understand the paper's objective from the outset. The first theorem appears to be unrelated to the rest of the paper, as it provides a bound that is later stated to be non-tight. The focus of the paper shifts to the alpha=1 case in section 4, where the relationship between collision probability and chi-square is introduced and subsequently proven in the binary case. The logical flow of the paper is disjointed, with some theorems, such as Theorem 1 and approximation (12), seeming unnecessary. The conclusions drawn in the paper appear to be random and out of order, giving the impression that the paper is more of a research memo than a rigorously organized manuscript. As a result, the reviewer is torn between assigning a score of 5 or 6, as the paper requires a complete rewrite before it can be presented to readers.
Despite the paper's organizational issues, the finding itself is noteworthy. Lemma 5 is a significant result, as it establishes a low error bound for the approximation in the binary case. The discovery that cos^{-1}(chi^2) can be approximated using an inner product is a novel contribution. However, the method used to approximate chi^2 is less satisfactory, as it requires applying the cosine function to transform sign(x)*sign(y), resulting in a loss of computational efficiency in large-scale learning. It would be interesting to investigate whether the approximated cos^{-1}(chi^2) can be translated into a linear approximation of the more useful chi^2 cumulative distribution function (CDF) or if further theoretical and empirical results can be obtained for cos^{-1}(chi^2).
Additional notes and relevant references are provided to contextualize the paper's contributions. When alpha = 1, the bound in Theorem 1 corresponds to the geodesic distance on the simplex, as defined in Lafferty and Lebanon's work on diffusion kernels. The Hellinger distance, which is obtained by taking the square root of all input u and v, is widely used in natural language processing and computer vision but is known to be inferior to chi-square. Chi-square is a crucial metric in computer vision, and several papers have explored its approximation. Relevant references include Sreekanth et al.'s work on generalized RBF feature maps and Li et al.'s recent arXiv paper on a linear approximation to the chi^2 kernel with geometric convergence rate.
In response to the authors' rebuttal, the reviewer acknowledges the potential applications of the proposed method to streaming data, which provides some justification for the use of the acos(chi2) metric. However, the main concerns regarding the lack of theoretical and practical insights into the acos(chi2) kernel and the poor writing and organization of the paper remain. As a result, the reviewer has decided to change the score to 6, with the hope that the authors will address these concerns in future revisions. Performance comparisons with the arXiv paper would be a valuable addition, but this was not a factor in the initial review score.