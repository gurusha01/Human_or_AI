This paper examines the efficacy of Alternative Importance Sampling (AIS) in assessing the performance of learning algorithms for Markov Random Fields (MRFs), highlighting the quest for a superior alternative to conventional annealing paths. By focusing on the bias of expected log-weight and its monotonic relationship with the variance of AIS output, the authors investigate the asymptotic behavior of various annealing paths. 
The paper is well-structured and clearly explained, with illustrative examples, such as the comparison of paths between Gaussian distributions in Figure 1 and the visualization of intermediate Restricted Boltzmann Machines (RBMs) in Figure 4, which facilitate understanding. The analysis appears sound, although the supplementary proof was not thoroughly examined.
A concern arises regarding the methodology for obtaining moment-averaged models, specifically the use of Persistent Contrastive Divergence (PCD) with relatively short training times for moment matching. The sensitivity of AIS outcomes to the accuracy of target distribution moments and intermediate model parameters warrants further investigation. Additionally, a comparison of the total computational cost of the proposed method with geometric average-based methods would be beneficial.
It is also noteworthy that, in the context of RBMs, assigning more models at the low-temperature end in geometric averaging paths often yields significantly smaller variance than linear scheduling in practice. The authors' consideration or comparison of this phenomenon in their experiments would provide valuable insights. 
Ultimately, the paper presents a compelling alternative to traditional geometric average annealing schedules for AIS, demonstrating reduced variance and increased effective sample size in output weights. The writing is clear, and the results are convincing, making this a notable contribution to the field.