This paper presents a novel approach to conserving prior experiences in reinforcement learning (RL) problems, enabling their application to subsequent runs with different reward functions. Notably, the system operates under the assumption of limited learning capacity, making it beneficial to utilize a surrogate reward function that facilitates the agent's learning of the actual reward. The core idea is to learn an internal reward function as a function of the external reward, offering a practical and plausible perspective on RL.
The concept is intriguing and appealing, with the underlying "bounded rationality" assumption rendering the method a valuable contribution to the field. The paper is generally well-written, although clarity is compromised in the network routing domain, with specific issues detailed below.
Methodologically, the paper aligns with the "reward-shaping" paradigm, demonstrating convincing success in the provided examples. While the methodology is not entirely new, the approach presented is sufficiently original and effective to merit publication.
Several specific points require clarification:
- Line 323: The definition of "trajectory-count" parameters for UCT is unclear; are these related to the number of sample runs?
- Line 332: The text and figure 4 appear inconsistent regarding the colors, coefficient signs, and semantics, specifically with regards to "negative/dark/discouraging exploration".
- Line 370: The purpose of decomposing into G1, G2, G_3 is unclear; what is the rationale behind this decomposition?
- Line 403: The modeling of the transition function is unclear, particularly regarding the use of reward mapping and potential modifications to the transition function.
- Line 418: The "competing policy transfer agent" is not defined; what model does it employ?
Overall, the method proposed is an interesting approach to transfer learning under limited resources, situated within the established "reward shaping" methodology. Despite minor weaknesses in the description of the second example, the paper presents a valuable contribution to the field.