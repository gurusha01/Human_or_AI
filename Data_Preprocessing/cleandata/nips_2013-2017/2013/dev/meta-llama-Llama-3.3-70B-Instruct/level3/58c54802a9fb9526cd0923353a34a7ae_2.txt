This paper proposes a novel approach to transfer learning in multi-task settings, where an agent learns to map external reward functions to internal reward functions that guide its behavior. The authors build on earlier work by Singh et al. (2010) and Sorg et al. (2010), extending their concepts to a multi-task setting where an agent learns an internal reward function and a mapping from external to internal reward functions. The key insight is that guiding an agent's behavior with reward functions other than the task-specifying reward function can help overcome computational bounds in the agent architecture.
The paper is well-written and easy to follow, providing a clear explanation of the problem setting, the proposed approach, and the empirical evaluation. The authors demonstrate the effectiveness of their approach in two example scenarios, a grid world domain and a networking routing domain, showing that it can substantially improve the agent's performance relative to other approaches.
The strengths of the paper include its clear presentation, thorough empirical evaluation, and the novelty of the proposed approach. The authors also provide a detailed discussion of the related work and the limitations of their approach.
However, there are some weaknesses to consider. The success of the algorithm depends on the availability of good features for the mapping from external rewards to internal rewards, which is crucial for its practical application. Additionally, the paper could benefit from a more detailed analysis of the theoretical properties of the proposed approach and its relationship to other transfer learning methods.
In terms of the conference guidelines, the paper meets the criteria for quality, clarity, and significance. The paper is technically sound, well-organized, and provides enough information for the expert reader to reproduce its results. The approach is novel and has the potential to be useful in a variety of applications. However, the paper could be improved by providing more detailed comparisons to other transfer learning methods and a more thorough analysis of the theoretical properties of the proposed approach.
Arguments pro acceptance:
* The paper proposes a novel approach to transfer learning in multi-task settings.
* The approach is well-motivated and builds on earlier work in the field.
* The empirical evaluation is thorough and demonstrates the effectiveness of the approach.
* The paper is well-written and easy to follow.
Arguments con acceptance:
* The success of the algorithm depends on the availability of good features for the mapping from external rewards to internal rewards.
* The paper could benefit from a more detailed analysis of the theoretical properties of the proposed approach and its relationship to other transfer learning methods.
* The paper could be improved by providing more detailed comparisons to other transfer learning methods.