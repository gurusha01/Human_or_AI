This paper presents a significant improvement on current estimators of entropy in multidimensional binary distributions, which is crucial for advancing our understanding of the neural code. The work relies on the sparsity of population responses to derive a Bayesian estimator that achieves a bias comparable to existing estimators using significantly less data. The method is applied to real data, revealing that retinal ganglion cells "code synergistically" in time, although this section requires expansion for more robust insights.
The presentation of the derivation and results is clear, with only minor comments needed for improvement. The submission offers an important improvement on entropy estimation methods by utilizing a more sophisticated prior than previously used. The paper is well-organized, and the authors provide enough information for the expert reader to reproduce the results.
The paper's strengths include its ability to handle high-dimensional data, its robustness to non-Gaussian distributions, and its potential to advance our understanding of the neural code. The weaknesses of the paper include the need for expansion on the application to real data and the potential for further improvement on the estimator's bias.
Arguments for acceptance include:
* The paper presents a significant improvement on current estimators of entropy in multidimensional binary distributions.
* The method is applied to real data, revealing new insights into the neural code.
* The presentation of the derivation and results is clear, with only minor comments needed for improvement.
Arguments against acceptance include:
* The section on the application to real data requires expansion for more robust insights.
* The estimator's bias could be further improved.
Overall, the paper is well-written, and the authors demonstrate a good understanding of the subject matter. The paper's strengths outweigh its weaknesses, and it has the potential to make a significant contribution to the field. I recommend acceptance with minor revisions to address the comments mentioned above.
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The authors are careful and honest about evaluating both the strengths and weaknesses of the work. The paper is a complete piece of work, and it is not merely a position paper.
In terms of clarity, the paper is clearly written, and the organization is logical and easy to follow. The authors provide enough information for the expert reader to reproduce the results.
In terms of originality, the paper presents a new and significant improvement on current estimators of entropy in multidimensional binary distributions. The method is novel, and it has the potential to advance our understanding of the neural code.
In terms of significance, the paper has the potential to make a significant contribution to the field. The results are important, and they could have a significant impact on our understanding of the neural code. The paper addresses a difficult problem in a better way than previous research, and it provides unique data, conclusions, or a unique theoretical or pragmatic approach.