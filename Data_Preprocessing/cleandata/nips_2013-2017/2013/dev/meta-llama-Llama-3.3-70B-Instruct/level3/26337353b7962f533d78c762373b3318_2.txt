This paper proposes a novel convex relaxation of sparse principal subspace estimation based on the convex hull of rank-d projection matrices, known as the Fantope. The authors formulate the sparse principal subspace problem as a semidefinite program with a Fantope constraint and show that the proposed estimator achieves a near-optimal rate of convergence in subspace estimation without assumptions on the rank of the solution or restrictive spiked covariance models.
The paper is well-written, and the proposed approach is original, with relevant literature adequately referenced. The results are potentially important for researchers and practitioners working with high-dimensional data, offering improved robustness of inference and flexibility in imposing prior knowledge. The method's ability to parallelly optimize assembly assignments and time courses at every level of interest is a significant advantage, making it valuable for experiments with coherent activation of neurons within an assembly.
The strengths of the paper include:
* A novel and efficient algorithm for solving the semidefinite program, based on the alternating direction method of multipliers (ADMM)
* Strong statistical guarantees for a wide array of input matrices, including sample covariance and Kendall's tau correlation matrices
* A general theoretical framework that accommodates other matrices, in addition to sample covariance
* Numerical examples that demonstrate the superiority of the proposed approach over deflation methods in both computational and statistical efficiency
The weaknesses of the paper include:
* The assumption of exact sparsity on the principal subspace, which may not always hold in practice
* The need for careful selection of the regularization parameter and dimension d, which can be challenging in practice
* The potential for the method to be computationally expensive for very large datasets
Overall, I believe that this paper makes a significant contribution to the field of sparse principal subspace estimation and is a strong candidate for acceptance at NIPS.
Arguments pro acceptance:
* The paper proposes a novel and efficient algorithm for solving the semidefinite program
* The paper provides strong statistical guarantees for a wide array of input matrices
* The paper demonstrates the superiority of the proposed approach over deflation methods in both computational and statistical efficiency
Arguments con acceptance:
* The assumption of exact sparsity on the principal subspace may not always hold in practice
* The need for careful selection of the regularization parameter and dimension d can be challenging in practice
* The potential for the method to be computationally expensive for very large datasets
Recommendation: Accept, with minor revisions to address the weaknesses mentioned above.