This paper proposes two novel Bayesian entropy estimators, ĤDBer and ĤDSyn, for estimating the entropy of binary spike trains in neural systems. The authors introduce a hierarchical mixture-of-Dirichlets prior with a base measure designed to integrate prior knowledge about spike trains into the model. The key idea is to use a synchrony distribution as the base measure, which captures the statistical structure of simultaneously recorded spike responses.
The paper is well-written, and the authors provide a clear and detailed explanation of their approach. The use of a synchrony distribution as a base measure is a novel and interesting idea, and the authors demonstrate its effectiveness in capturing the correlation structure of neural data. The paper also provides a thorough comparison with existing entropy estimators, including the Nemenman-Shafee-Bialek (NSB) and Best Upper Bound (BUB) estimators.
The strengths of the paper include its originality, technical soundness, and clarity. The authors provide a clear and concise explanation of their approach, and the paper is well-organized and easy to follow. The use of simulations and real neural data to demonstrate the effectiveness of the proposed estimators is also a strength.
However, there are some weaknesses to the paper. One potential limitation is that the authors assume that the synchrony distribution is known or can be estimated accurately, which may not always be the case. Additionally, the paper could benefit from a more detailed discussion of the computational complexity of the proposed estimators and their scalability to large neural datasets.
In terms of significance, the paper addresses an important problem in neuroscience, namely the estimation of entropy in neural systems. The proposed estimators have the potential to be widely used in the field, and the paper provides a significant contribution to the literature on probabilistic inference in neural circuits.
Overall, I would recommend accepting this paper for publication. The paper is well-written, technically sound, and provides a significant contribution to the field. While there are some potential limitations, the authors provide a clear and concise explanation of their approach, and the paper is well-organized and easy to follow.
Arguments pro acceptance:
* The paper proposes a novel and interesting approach to estimating entropy in neural systems.
* The authors provide a clear and concise explanation of their approach, and the paper is well-organized and easy to follow.
* The use of simulations and real neural data to demonstrate the effectiveness of the proposed estimators is a strength.
* The paper addresses an important problem in neuroscience and provides a significant contribution to the literature on probabilistic inference in neural circuits.
Arguments con acceptance:
* The authors assume that the synchrony distribution is known or can be estimated accurately, which may not always be the case.
* The paper could benefit from a more detailed discussion of the computational complexity of the proposed estimators and their scalability to large neural datasets.