This paper presents a novel approach to transfer learning in long-lived agents that must solve a sequence of tasks over a finite lifetime. The key idea is to reuse reward functions across tasks, which is a departure from traditional transfer learning methods that focus on reusing value functions, policies, or models. The authors build on the optimal rewards problem (ORP) framework, which separates the task-specifying objective reward function from the internal reward function used to guide agent behavior.
The paper is well-written and clearly explains the motivation, background, and technical details of the approach. The authors provide a thorough discussion of the related work and highlight the novelty of their contribution. The experimental evaluation is comprehensive, covering two domains: a grid world and a networking routing domain. The results demonstrate the effectiveness of the reward mapping approach in improving the agent's performance compared to other methods, including a competing policy transfer method.
The strengths of the paper include:
* The novelty of the approach, which addresses an important problem in transfer learning
* The clear and concise writing style, which makes the paper easy to follow
* The comprehensive experimental evaluation, which provides strong evidence for the effectiveness of the approach
The weaknesses of the paper include:
* The lack of theoretical analysis, which would provide a deeper understanding of the conditions under which the reward mapping approach is effective
* The limited scope of the experimental evaluation, which only considers two domains and a specific set of task sequences
* The need for further clarification on the implementation details, such as the choice of hyperparameters and the specific algorithms used for learning the reward mapping function
Overall, the paper presents a significant contribution to the field of transfer learning and reinforcement learning. The reward mapping approach has the potential to be applied to a wide range of domains and tasks, and the authors' experimental evaluation provides a strong foundation for further research.
Arguments pro acceptance:
* The paper presents a novel and significant contribution to the field of transfer learning
* The experimental evaluation is comprehensive and provides strong evidence for the effectiveness of the approach
* The paper is well-written and clearly explains the technical details of the approach
Arguments con acceptance:
* The lack of theoretical analysis limits the understanding of the conditions under which the reward mapping approach is effective
* The limited scope of the experimental evaluation may not generalize to other domains and tasks
* The need for further clarification on the implementation details may limit the reproducibility of the results.