This paper proposes a novel convex relaxation of sparse principal subspace estimation based on the convex hull of rank-d projection matrices, known as the Fantope. The authors provide an efficient algorithmic scheme using alternating direction method of multipliers (ADMM) and establish a near-optimal convergence rate for estimation of the principal subspace of a general covariance matrix. The paper also provides a general theoretical framework for analyzing the statistical properties of the method for arbitrary input matrices.
The strengths of the paper include its ability to estimate multiple principal components simultaneously, its efficiency in computation, and its strong statistical guarantees. The use of the Fantope constraint allows for a convex relaxation of the problem, making it computationally tractable. The authors also provide a thorough analysis of the statistical properties of the method, including a near-optimal convergence rate and a general theoretical framework for analyzing the method's performance.
However, there are some weaknesses to the paper. The experimental section is somewhat unconvincing, lacking phase-transition diagrams and comparisons with existing methods. The paper's method is an incremental update of DSPCA using the Fantope constraint, and the theoretical results are mostly incremental and not particularly exciting. Additionally, the authors' discussion on orthogonality constraints is unclear, making them seem more embarrassing than useful.
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The paper is clearly written, well-organized, and provides enough information for the expert reader to reproduce the results. However, the paper's originality is somewhat limited, as it builds upon existing work on DSPCA and the Fantope constraint. The significance of the paper is moderate, as it provides a useful extension to existing methods for sparse principal subspace estimation.
Overall, the paper is a good scientific contribution to the field, but it has some limitations. The authors could improve the paper by providing more convincing experimental results, clarifying the discussion on orthogonality constraints, and highlighting the significance and originality of the work more clearly.
Arguments pro acceptance:
* The paper provides a novel and efficient algorithm for sparse principal subspace estimation.
* The paper establishes a near-optimal convergence rate for estimation of the principal subspace of a general covariance matrix.
* The paper provides a general theoretical framework for analyzing the statistical properties of the method for arbitrary input matrices.
Arguments con acceptance:
* The experimental section is somewhat unconvincing, lacking phase-transition diagrams and comparisons with existing methods.
* The paper's method is an incremental update of DSPCA using the Fantope constraint, and the theoretical results are mostly incremental and not particularly exciting.
* The authors' discussion on orthogonality constraints is unclear, making them seem more embarrassing than useful.