This paper presents a study on exploration in Multi-Armed Bandits (MAB) in a distributed setting, where multiple players collaborate to identify an ε-optimal arm. The authors investigate the tradeoff between the number of arm pulls required by each player and the amount of communication between them. The main contribution of the paper is a non-trivial speedup of √k in the learning performance of the players when allowing only one round of communication.
The paper is well-written, and the authors provide a clear and concise introduction to the problem, related work, and their contributions. The technical sections are also well-organized, and the proofs of the theorems are provided in the appendix. The authors demonstrate a good understanding of the field and provide a comprehensive review of related work.
The paper's strengths include:
1. Novelty: The paper presents a new and interesting problem setting, which is relevant to large-scale applications.
2. Technical quality: The authors provide rigorous proofs and analysis of their algorithms, demonstrating a high level of technical expertise.
3. Clarity: The paper is well-written, and the authors provide clear explanations of their ideas and results.
However, there are some weaknesses and potential areas for improvement:
1. Limited scope: The paper focuses on a specific setting, where each player is allowed only one transmission. It would be interesting to see how the results generalize to more complex communication models.
2. Lack of experimental evaluation: The paper is purely theoretical, and it would be beneficial to include experimental results to demonstrate the practicality of the algorithms.
3. Open questions: The authors mention several open questions, such as whether a better speedup can be achieved with more than one round of communication. It would be interesting to see these questions explored in future work.
In terms of the conference guidelines, the paper meets the criteria for quality, clarity, originality, and significance. The authors provide a clear and concise summary of their results, and the paper is well-organized and easy to follow.
Arguments for acceptance:
1. The paper presents a novel and interesting problem setting.
2. The authors provide rigorous proofs and analysis of their algorithms.
3. The paper is well-written and easy to follow.
Arguments against acceptance:
1. The paper has a limited scope, focusing on a specific setting.
2. The lack of experimental evaluation may limit the paper's practical impact.
3. Some of the open questions mentioned by the authors may be seen as a limitation of the current work.
Overall, I recommend accepting the paper, as it presents a significant contribution to the field of MAB and distributed learning. However, I suggest that the authors consider addressing some of the weaknesses and open questions mentioned above in future work.