This paper proposes two novel Bayesian entropy estimators, ĤDBer and ĤDSyn, for estimating the entropy of binary spike trains. The authors develop a hierarchical mixture-of-Dirichlets prior with a base measure designed to integrate prior knowledge about spike trains into the model. The prior is centered on a simple parametric model, such as a Bernoulli distribution, which captures high-level statistical features of the data, and is combined with a Dirichlet distribution to assign prior mass to distributions far from the parametric model.
The paper is well-written, and the authors provide a clear and concise introduction to the problem of entropy estimation in neural data. The proposed estimators are thoroughly motivated, and the authors provide a detailed derivation of the Bayesian framework. The use of a synchrony distribution as a base measure is a key innovation, allowing the authors to capture the statistical structure of simultaneously recorded spike responses.
The paper has several strengths. Firstly, the authors provide a thorough evaluation of the proposed estimators on both simulated and real neural data, demonstrating their superior performance compared to existing methods. Secondly, the authors provide a clear and concise explanation of the underlying theory, making the paper accessible to a broad audience. Finally, the authors provide a MATLAB implementation of the estimators, making it easy for others to reproduce their results.
However, there are also some weaknesses. Firstly, the paper assumes that the spike trains are binary, which may not always be the case in practice. Secondly, the authors do not provide a thorough analysis of the computational complexity of the proposed estimators, which could be a limitation in practice. Finally, the authors do not provide a clear discussion of the limitations of the proposed estimators, such as their sensitivity to hyperparameters or their performance on non-stationary data.
Arguments pro acceptance:
* The paper proposes a novel and well-motivated approach to entropy estimation in neural data.
* The authors provide a thorough evaluation of the proposed estimators on both simulated and real neural data.
* The paper is well-written, and the authors provide a clear and concise explanation of the underlying theory.
Arguments con acceptance:
* The paper assumes that the spike trains are binary, which may not always be the case in practice.
* The authors do not provide a thorough analysis of the computational complexity of the proposed estimators.
* The authors do not provide a clear discussion of the limitations of the proposed estimators.
Overall, I believe that the paper is a strong contribution to the field of neural data analysis, and I recommend acceptance. However, I suggest that the authors address the weaknesses mentioned above, such as providing a more thorough analysis of the computational complexity and limitations of the proposed estimators. 
Quality: 8/10
The paper is technically sound, and the authors provide a clear and concise explanation of the underlying theory. However, the authors do not provide a thorough analysis of the computational complexity of the proposed estimators.
Clarity: 9/10
The paper is well-written, and the authors provide a clear and concise explanation of the underlying theory. The notation is clear, and the figures are well-labeled.
Originality: 8/10
The paper proposes a novel approach to entropy estimation in neural data, but the underlying theory is not entirely new.
Significance: 9/10
The paper has the potential to make a significant impact in the field of neural data analysis, as it provides a novel and well-motivated approach to entropy estimation.