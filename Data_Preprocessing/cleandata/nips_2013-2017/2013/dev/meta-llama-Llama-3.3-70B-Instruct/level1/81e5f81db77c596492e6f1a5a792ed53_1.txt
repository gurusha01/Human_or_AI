This paper proposes a novel convex relaxation of sparse principal subspace estimation based on the convex hull of rank-d projection matrices (the Fantope). The authors establish a near-optimal convergence rate for estimation of the principal subspace of a general covariance matrix without assuming the spiked covariance model. The paper also provides a general theoretical framework for analyzing the statistical properties of the method for arbitrary input matrices, including sample covariance and Kendall's tau correlation matrices.
The strengths of the paper include:
* The proposal of a novel and efficient algorithm for sparse principal subspace estimation, which can be solved using alternating direction method of multipliers (ADMM).
* The establishment of a near-optimal convergence rate for the estimator, which is a significant improvement over existing methods.
* The provision of a general theoretical framework for analyzing the statistical properties of the method, which can be applied to a wide range of input matrices.
* The demonstration of the superiority of the proposed method over existing deflation methods in both computational and statistical efficiency through simulation studies.
The weaknesses of the paper include:
* The assumption of exact sparsity on the principal subspace, which may not always hold in practice.
* The lack of investigation into the performance of the method under weak sparsity assumptions or other types of penalties.
* The need for further research into the choice of dimension d and regularization parameter λ, which are of great practical interest.
Arguments pro acceptance:
* The paper proposes a novel and efficient algorithm for sparse principal subspace estimation, which is a significant contribution to the field.
* The paper establishes a near-optimal convergence rate for the estimator, which is a major improvement over existing methods.
* The paper provides a general theoretical framework for analyzing the statistical properties of the method, which can be applied to a wide range of input matrices.
* The simulation studies demonstrate the superiority of the proposed method over existing deflation methods.
Arguments con acceptance:
* The assumption of exact sparsity on the principal subspace may not always hold in practice, which could limit the applicability of the method.
* The lack of investigation into the performance of the method under weak sparsity assumptions or other types of penalties may limit the scope of the paper.
* The need for further research into the choice of dimension d and regularization parameter λ may be seen as a limitation of the paper.
Overall, the paper is well-written, and the authors have made a significant contribution to the field of sparse principal subspace estimation. The paper is suitable for publication in a top-tier conference like NIPS, and I would recommend acceptance.