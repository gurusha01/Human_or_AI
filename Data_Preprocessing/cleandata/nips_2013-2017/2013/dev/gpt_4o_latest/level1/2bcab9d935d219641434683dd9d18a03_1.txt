This paper addresses the challenging problem of olfactory inference, proposing two biologically plausible algorithms—variational inference and sampling—to approximate the posterior distribution of odors based on receptor neuron activity. The authors introduce a novel "spike and slab" prior, which assumes that most odors have zero concentration, making it more realistic than smooth priors used in prior work (e.g., Beck et al., 2012). Both algorithms are mapped onto neural dynamics and evaluated for their speed and accuracy. The results show that both methods can infer odors within 100 ms, making them behaviorally indistinguishable. However, the two approaches differ in their neural connectivity requirements and predictions about activity patterns, offering experimentally testable hypotheses. This work builds on prior studies of probabilistic inference in sensory systems while advancing the state of the art by incorporating a more ecologically valid prior and focusing on olfactory processing.
Strengths:
1. Scientific Contribution: The paper provides a significant contribution by introducing a biologically plausible framework for olfactory inference, grounded in a realistic prior distribution. This is a notable improvement over prior work.
2. Experimental Relevance: The authors demonstrate that the two algorithms make distinct predictions about neural activity, enabling experimental validation. This is a strong point, as it bridges theoretical modeling and empirical neuroscience.
3. Technical Rigor: The derivation of neural dynamics for both algorithms is thorough, and the simulations are well-designed to test their speed and accuracy.
4. Clarity of Results: The paper clearly demonstrates that both algorithms achieve rapid inference, consistent with behavioral observations, and highlights their differences in coding strategies (log-probability vs. probability).
5. Future Directions: The discussion acknowledges the limitations of the current model and outlines promising avenues for future research, such as incorporating hierarchical priors and learning mechanisms.
Weaknesses:
1. Generative Model Simplifications: The generative model assumes linearity, binary connectivity, and Poisson noise, which may oversimplify the biological reality. While the authors acknowledge this, it limits the immediate applicability of the results.
2. Complexity of Neural Implementation: Both algorithms require neurons to compute nontrivial nonlinearities (e.g., logarithms, digamma functions), which may be biologically challenging. The paper could benefit from a deeper discussion of how these computations might be approximated in neural circuits.
3. Limited Scope of Simulations: The simulations focus on small-scale systems (40 receptor types and 400 odors), which may not fully capture the complexity of real olfactory systems. Scaling up the model could reveal additional insights.
4. Experimental Validation: While the authors propose testable predictions, no experimental data are provided to support the plausibility of the proposed algorithms. This limits the immediate impact of the work.
Arguments for Acceptance:
- The paper addresses an important and underexplored problem in sensory neuroscience.
- It provides a novel and biologically plausible framework for olfactory inference.
- The results are clear, well-supported, and experimentally testable.
- The work advances the field by incorporating a realistic prior and focusing on ecologically relevant timescales.
Arguments Against Acceptance:
- The generative model and neural implementation rely on several simplifying assumptions.
- The biological plausibility of the required nonlinear computations is not fully addressed.
- The scope of the simulations is limited, and no experimental validation is provided.
Recommendation:
Overall, this paper makes a valuable contribution to the field of computational neuroscience by proposing and rigorously analyzing two biologically plausible algorithms for olfactory inference. While there are some limitations, the strengths outweigh the weaknesses. I recommend acceptance with minor revisions to address the discussion of neural implementation and scalability.