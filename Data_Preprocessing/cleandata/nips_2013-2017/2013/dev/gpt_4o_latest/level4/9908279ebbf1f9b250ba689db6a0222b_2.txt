The authors introduce a robust and sparse principal component regression (PCR) estimator tailored for non-Gaussian data. Their work is driven by theoretical insights into the conditions under which classical PCR outperforms least squares regression (specifically in the presence of a low-rank structure) and by the challenges posed by data/noise with heavy and dependent tails. The proposed method is validated through both simulated and real-world equity data experiments.
The manuscript is well-written and easy to follow. The contributions of the paper are twofold:  
1. The authors establish when PCR is advantageous compared to standard least squares regression, emphasizing its collinearity invariance and ability to leverage low-rank structures in the design/sample covariance matrix. This is effectively demonstrated using a series of simple and intuitive synthetic experiments.  
2. For large-d-small-n scenarios, the authors propose a robust PCR variant under an elliptical family of densities model, specifically designed to address heavy and dependent-tailed data.  
The simplicity of the proposed algorithm is noteworthy:  
- The data is projected onto the sparse principal eigenvector of the sample Kendall's tau (analogous to sparse PCA on the sample covariance matrix, implemented via the truncated power algorithm).  
- Subsequently, Y is regressed on Xu.  
Additional comments:  
- Line 373: Replace "F distribution" with "exponential distribution."  
- Why is the prediction error scaled by 100 times instead of adjusting the error axis? This might be a misunderstanding on my part.  
After thoroughly demonstrating the advantages of PCR over least squares regression, the paper introduces a novel semiparametric approach for sparse and robust PCR. I have reviewed the authors' rebuttal.