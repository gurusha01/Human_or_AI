Simple concept with compelling results.  
If the contribution is genuinely novel, the paper warrants acceptance.  
Thus, the novelty claim should be thoroughly verified.  
Is this truly a boosting algorithm? In my view, it seems more appropriate to classify it as a pursuit algorithm, as it does not appear to hinge on altering the distribution of examples. This distinction is significant because there are closely related works (e.g., kernel matching pursuit, http://www.iro.umontreal.ca/~vincentp/Publications/kmp_techreport2000.pdf, section 3) that are situated within the pursuit literature rather than the boosting literature. While this work is similar, it is not identical to those.  
Regarding overlap with papers 539 and 956: I previously reviewed paper 956, which presents a multiclass extension of the same concept. However, paper 956 is less clear and could have been condensed into a single paragraph within paper 481. Similarly, paper 539 explores a semi-supervised extension of the same idea and could also have been summarized in paper 481. Fragmenting the work into these minimal publishable units is not ideal. I believe the community would benefit most from accepting paper 481, rejecting papers 539 and 956, and advising the author to reference these extensions in the final version of the NIPS paper, with a more detailed discussion deferred to a future journal publication.  
Detailed comments:  
[page 1, line 44] -- The problem is not always convex, even with surrogate losses. This depends on the chosen family of functions. Recommend accepting only paper 481, as it encapsulates the core contribution.