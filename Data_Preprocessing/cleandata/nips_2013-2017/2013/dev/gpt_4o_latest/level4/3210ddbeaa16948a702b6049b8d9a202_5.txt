This paper introduces the use of signed Cauchy random projections to approximate the chi-square kernel with relatively low error rates. The motivation stems from generalizing the SimHash algorithm and observing that the chi-square metric is linked to collision probability.
The reviewer finds the proposed approach both innovative and intriguing, as it appears to be the first attempt to connect chi-square with random Cauchy projections. The work holds significant potential for applications involving very high-dimensional sparse approximations of the chi-square kernel, which are relevant for tasks in text and image processing.
However, a major concern lies in the paper's writing, which is extremely poor and often unclear. From the outset, the paper fails to clearly articulate its main goal. The first theorem feels disconnected from the rest of the paper, as it provides a bound that is later stated to be non-tight. Starting from Section 4, the focus shifts to the case where alpha equals 1, proposing and later proving a connection between collision probability and the chi-square kernel in the binary case. The overall structure and logic of the paper appear disorganized and inconsistent, with theorems (e.g., Theorem 1 and the approximation in Equation 12) that seem to lack clear purpose or relevance. The conclusions also appear disjointed and random (e.g., lines 424–427). Overall, the paper resembles a research memo more than a rigorously structured scientific article. As a result, the reviewer is conflicted between assigning a score of 5 or 6, as the paper requires substantial rewriting before it can be presented to a wider audience.
That said, the core findings remain compelling. Lemma 5 is a strong result, establishing a low error bound for the binary case approximation. The novel result showing that cos⁻¹(chi²) can be approximated by an inner product is particularly noteworthy. However, the method of approximating chi² is less satisfying, as it requires applying the cosine function to transform sign(x) * sign(y), meaning the approximation is no longer an inner product and thus does not offer computational advantages for large-scale learning. It would be interesting to explore whether the approximated cos⁻¹(chi²) could lead to a linear approximation of the more practical chi² CDF function, or whether additional theoretical and empirical insights could be derived for cos⁻¹(chi²).
Additional Notes and References:
- When alpha = 1, the bound in Theorem 1 corresponds to the geodesic distance on the simplex, as defined in Lafferty and Lebanon's Diffusion Kernels on Statistical Manifolds (JMLR, 2005).
- Taking the square root of all input values (u, v) corresponds to the Hellinger distance, which is widely used in NLP and vision but is generally considered inferior to the chi-square kernel.
- The chi-square kernel is particularly important in computer vision, and several papers have addressed its approximation. Relevant references include:
  - Sreekanth, Vedaldi, and Zisserman, Generalized RBF Feature Maps for Efficient Detection (BMVC, 2010), which proposes an approximation for exp-chi², empirically shown to outperform the chi² kernel in classification tasks. Notably, exp-chi² resembles the CDF of the chi² distribution and is thus more appropriate as a comparison metric.
  - Li, Lebanon, and Sminchisescu, A Linear Approximation to the Chi² Kernel with Geometric Convergence (arXiv:1206.4074v3), which provides a formula for approximating each dimension of the chi² kernel with geometric convergence. This approach could, in principle, be combined with standard Gaussian random projections to approximate chi² on very high-dimensional sparse features. A comparison between this method and the proposed approach would be valuable.
---
Comments on Rebuttal:
The authors' point about the applicability of their method to streaming data is valid and adds merit to the otherwise poorly justified acos(chi²) metric. While this metric is not yet well-understood, its computability for streaming data is an interesting advantage. Based on this clarification, the reviewer has decided to adjust the score to 6. However, the primary concerns remain:  
1. The lack of theoretical and/or practical insights into the acos(chi²) kernel.  
2. The disorganized and unclear writing throughout the paper.
Performance comparisons with the referenced arXiv paper would have been an interesting addition but did not influence the initial score. The score is based solely on the two concerns outlined above. While the proposed approach to approximate the cos⁻¹(chi²) kernel using signed random Cauchy projections is intriguing, the lack of clarity and rigor in the writing significantly undermines the paper's overall quality.