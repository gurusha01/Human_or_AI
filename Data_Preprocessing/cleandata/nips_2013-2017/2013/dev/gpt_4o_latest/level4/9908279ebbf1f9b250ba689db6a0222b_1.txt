The authors propose a novel approach for robust principal component regression tailored for non-Gaussian data. Initially, they demonstrate that principal component regression surpasses classical linear regression in scenarios where both dimensionality and sample size increase, owing to its insensitivity to collinearity and its ability to leverage low-rank structures. Through parameter sweeps, they validate their theoretical findings, showing that the mean square error aligns with their theoretical predictions. Subsequently, the authors introduce a new principal component regression method under the assumption that the random vector and noise follow an elliptical distribution, which is a more generalized framework than the conventional Gaussian assumption. They show that this generalized method outperforms traditional principal component regression across various elliptical distributions (e.g., multivariate-t, EC1, EC2) while maintaining comparable performance for Gaussian distributions. Lastly, they evaluate their method on real-world financial data, demonstrating that it outperforms both standard principal component regression and the lasso regression technique.
This paper is of exceptional quality. The introduction provides a clear and comprehensive overview of related work and effectively highlights the significant contributions of this study. The paper is well-structured, with logically organized sections and clear mathematical explanations. The figures are well-designed and reinforce the authors' arguments. The proposed principal component regression method consistently outperforms the standard approach on both synthetic and real-world datasets.
However, the authors could provide additional clarification regarding their implementation of lasso regression in the simulation study and the analysis of equity data. Specifically, how was the number of selected features determined in the lasso method? Was the sparsity pattern adjusted by varying the threshold or by tuning the lasso trade-off parameter? Additionally, after determining the sparsity pattern, was the solution refined? For instance, lasso regression can identify the sparsity pattern, but the regression could then be re-run (polished) without the $l_1$ penalty to improve the solution.
Furthermore, in their analysis of equity data, the authors focused on a specific subset of stock data. Was there a particular rationale for selecting this category, or were other categories also evaluated? The results would be even more compelling if the authors demonstrated improved performance across multiple sectors.
In summary, the authors present a rigorous and high-quality study on a novel method for robust principal component regression. While there are a few minor points that could be clarified, the paper is overall an excellent contribution to the field.