The paper explores applications of online learning in the context of predictable loss sequences. Initially, earlier results are extended to encompass HÃ¶lder-smooth loss functions. The proposed framework is subsequently utilized to derive solutions for saddle-point problems and to facilitate efficient computation of equilibria in two-player zero-sum games (for cooperative players, with guarantees provided if one player does not cooperate). Lastly, the paper addresses convex programming problems, though I find some of the underlying assumptions in this section questionable.
The problems tackled in the paper are naturally interesting, and the approach is innovative. However, it is somewhat misleading that the "predictable sequence framework" relies on past observations and smoothness to evaluate the quality of predictions, rather than a more direct notion of predictability.
The paper is generally well-written and clear. Nevertheless, I have two significant concerns that the authors should address in their response:
1. The learning rates throughout the paper are determined by peeking into the future: specifically, \(\etat\) depends on \(\nablat\), which is only revealed after the update with \(\etat\) has been performed and the subsequent gradient (loss) \(\nablat\) is disclosed.
2. Section 5: I find the assumption that \(F^*\) can be known in advance, or determined via binary search, problematic. Why would verifying the existence of a solution with a specific value be simpler than actually finding the solution itself? This raises questions about the validity of assuming the exact (rather than approximate) value of the maximum is known without also knowing an optimal solution. If the latter is the case, the entire optimization process seems redundant.
Minor Comments:
1. The proof of Lemma 1 appears unnecessary, as it is copied verbatim from [9], except for the unproven first line in the statement. It would be more appropriate to refer to Lemma 3 of [9] instead.
2. In the proof of Lemma 2 (line 571), it seems that \(1/\eta1 \leq 1/R{\text{max}}\) is implicitly assumed, which is equivalent to assuming the gradient norm is bounded by 1. This assumption should either be explicitly stated or avoided.
3. Line 11: It appears that \(\rho\) should be \(1/\sqrt{H}\) to cancel the first term in (3), which would worsen the bound in line 113.
4. The inequalities in the derivations (e.g., lines 587, 590, 637, 645, 655, 659, etc.) should be explained in greater detail. While not necessarily difficult to follow, the inequalities are often lengthy, making it challenging to discern the differences.
5. Corollary 5: Clearly define the norms \(F\) and \(X\).
6. Proposition 6: Equation (9) bounds the average (or normalized) regret. The same applies to Lemma 7.
Additionally, the authors may find the ICML paper Dynamical Models and Tracking Regret in Online Convex Programming by Eric Hall and Rebecca Willett (JMLR W&CP 28(1):579-587, 2013) relevant, as it addresses predictability in a related, though distinct, context.
Comments After the Rebuttal Period:
- Learning rates: The corrections provided by the authors seem reasonable.
- Section 5 (knowing \(F^\) in advance): Based on the authors' response, \(F^\) can only be known approximately, and this approximation incurs a cost in the bounds. Thus, I would not agree that knowing \(F^*\) can be assumed without loss of generality. However, the explanation provided in the rebuttal is satisfactory.
- Bound in line 113: The authors are correct; this was my mistake.
In conclusion, I believe this is a solid paper with several interesting contributions.