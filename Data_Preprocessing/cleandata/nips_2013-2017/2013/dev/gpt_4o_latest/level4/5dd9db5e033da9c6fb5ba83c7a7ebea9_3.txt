Paraphrased Review:
Summary of Ideas:  
The authors address a known proximal problem, demonstrating that its minimization provides at least as much information as minimizing the Lovász extension.  
When a submodular function is expressed as a sum of simpler submodular functions, solving the dual of the proximal problem can be achieved using projections, avoiding the reliance on non-smooth functions as seen in prior methods.
Evaluation:  
This paper introduces an improved approach for handling additively decomposable submodular functions by leveraging novel dual decompositions of a less commonly utilized form of the Lovász extension.  
These decompositions enable the process to circumvent some of the challenges associated with non-smoothness in earlier techniques. The empirical results, particularly in image processing applications, are promising.  
The paper effectively outlines prior work, but this comes at the cost of providing only a high-level overview of the novel contributions.  
For instance, one key technical contribution is the application of the DR variant from reference [5] to dual (9), which is tailored for the sum of two functions. However, since [5] also focuses on two functions, it is unclear how these algorithms extend to cases where \( r > 2 \), despite such results being highlighted in the experimental section under the name DR-para. Additionally, the dependence of iteration complexity on \( r \) remains unexplored.  
Another example is the third major contribution, which is relegated to the supplementary material without formally presenting an algorithm or theorem.  
Pros:  
- Decomposable submodular functions are relevant in practical applications, and improved methods for minimizing them are valuable.  
- The novel dual formulations have the potential to inspire further research into algorithms for solving them, beyond the methods proposed in this paper.  
Cons:  
- While the paper critiques prior work for lacking iteration and computational complexity bounds, the proposed optimization problems and algorithms also lack corresponding iteration complexity analyses. Although a full analysis could be deferred to future work, some insight into how \( r \) influences complexity across the different algorithms is missing.  
- The presentation of the algorithms, as distinct from the dual formulations, is insufficiently clear.  
Detailed Comments:  
- Line 072: The phrase "the level set {k, xk^ \ge 0} of ... x^" is ambiguous. Did the authors mean {k | xk^* \ge 0}? Additionally, reference [2] covers multiple topics, so a more specific citation for the fact being discussed would be helpful.  
- Line 088: It would be beneficial to reference Section 3 here, where examples of such decompositions are provided. Additionally, offering some insight into the types of "simplicity" that might characterize the summand functions would be valuable.  
- Line 116: The notation \( a(A) \), where \( a \in \mathbb{R}^n \) and \( A \subseteq V \), does not appear to be introduced anywhere in the paper.  
- Line 117: This statement is misleading. Section 2 defers to the supplementary material, which itself lacks sufficient explicit detail.  
- Line 138: Replace "computed the" with "computed by the."  
- Line 156: The term "discrete gaps" is used here and elsewhere but is not clearly defined. Does it refer to the duality gaps between \( F(A) \) and a specific dual problem? Similarly, the term "smooth gaps" is unclear.  
- Line 170: The statement "In the appendix..." should be accompanied by an explicit algorithm, as well as a lemma and proof detailing its complexity. None of these are present in the main paper or the supplementary material.  
- "problems have size 640x427. Hence ... have r = 640 + 247": Either there is a typo (427 should be 247), or the relationship between these values is not explained clearly. Additionally, the reasoning behind solving for \( r = 2/3 \) should be clarified.  
- Figure 2:  
  - The inconsistencies between the vertical and horizontal axes make comparisons difficult.  
  - The caption states "From top to bottom: four different images," but it appears to refer to only two images. Expanding the benchmark would be beneficial.  
- Figure 3:  
  - Does "non-smooth problems" refer to the previously existing duals? The legends suggest that the new duals are being used.  
- Empirical Evaluation: Comparisons of convergence based on iteration counts are only meaningful if iteration costs are comparable. Are they?  
In summary, while the dual formulations are intriguing, the algorithms themselves are not presented as clearly. The paper should prioritize providing explicit details on the novel aspects, even if this comes at the expense of some detail on existing methods.