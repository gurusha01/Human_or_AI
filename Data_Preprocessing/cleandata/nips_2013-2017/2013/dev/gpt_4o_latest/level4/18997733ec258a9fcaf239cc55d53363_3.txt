This paper investigates a scenario where multiple contextual linear bandits are interconnected through an underlying graph structure. The key assumption is that the weight vectors of neighboring nodes are smooth over the graph, meaning they are similar for adjacent nodes. This framework seems to be a compelling and sufficiently rich model for recommendation systems in social networks.
The proposed algorithm operates by running classical contextual linear bandits independently on each node (with the node being selected by nature). However, the algorithm incorporates information sharing across nodes, enabling them to update their model estimates and confidence intervals appropriately using the graph Laplacian.
Regrettably, the regret analysis presented in the paper is unsatisfactory. The authors provide an analysis for a different algorithm than the one they propose and evaluate in their experiments. While this might be acceptable under certain circumstances, the paper offers no justification for this discrepancy. There is no discussion about how the differences between CB and TCB would impact the algorithm, its evaluation, or its deployment. At the very least, the distinction between TCB and CB should be more thoroughly discussed rather than relying on the results from [1]. This omission raises concerns that the TCB-style algorithm may not perform well in the experiments, or that the CB-style algorithm may lack provable learning guarantees. It might be more prudent to omit the theoretical analysis altogether if it cannot be directly tied to the proposed algorithm.
Regarding the current analysis, it is unclear how large the terms ln|M_t| and 2L can become or how they scale with T and n. This information is crucial for deriving meaningful insights from the regret bound. Additionally, the impact of graph noise on these quantities is not addressed.
Moreover, in prior work [4,9], analyses of linear bandits typically provide guidance on setting the exploration parameter \(\alpha\). Unfortunately, the analysis here does not offer such guidance. It is also unclear how the upper bound depends on \(\alpha\)—is this dependence embedded in the aforementioned quantities? Clarifying this would improve the utility of the analysis.
On the other hand, the experimental section is handled exceptionally well. The descriptions are thorough and clearly articulated. The use of real-world data and the detailed explanation of practical aspects to ensure reproducibility are commendable.
Finally, in lines L186–L190, the paper mentions that the graph causes the reward to influence other nodes to a "lesser extent," "somehow informatively," and with "similar updates." However, the algorithm does not appear to include a parameter to quantify "somehow" or "similar." Could this be achieved by regularizing the Laplacian with a multiple of the identity matrix instead of just the identity matrix? In the experimental section, the authors note that clustering acts as a regularizer. Wouldn't regularizing the Laplacian itself be a more principled approach to achieve this regularization?
Additional comments:
- Why does the regret bound involve \(L(u1, \ldots, un)\) instead of the regularized version, given that the Laplacian is regularized in the algorithm?
After the rebuttal: While this work is promising, including a theoretical analysis for a modified algorithm with an unclear relationship to the proposed one introduces unnecessary confusion. I would be inclined to increase my score if the theoretical analysis were removed. 
In summary, this paper extends contextual bandits to a setting where different bandits share their weight vectors via a graph structure, which is particularly relevant for social network applications. The experiments are excellent, but the theoretical analysis is disappointing and does not seem to add value.