The paper introduces a novel method using sign stable random projections to efficiently approximate the chi-square (χ²) similarity in high-dimensional data, particularly for data streams. The authors propose leveraging only the signs of projected data, significantly reducing storage requirements and computational overhead. They demonstrate that for α = 1 (Cauchy random projections), the collision probability can be well-approximated as a function of the χ² similarity, a widely used measure in histogram-based features for text and vision applications. The paper provides theoretical bounds, experimental validations, and practical applications, showcasing the method's utility for large-scale machine learning tasks.
Strengths:
1. Novelty and Practicality: The proposed method is a significant advancement, offering a practical and efficient way to handle high-dimensional data. By using only 1-bit representations, the approach addresses storage and computational challenges, which are critical in large-scale applications.
2. Theoretical Rigor: The paper provides a solid theoretical foundation, including bounds for collision probabilities and connections to χ² similarity. The approximations for α = 1 are particularly compelling and well-supported by both simulations and real-world experiments.
3. Experimental Validation: The authors validate their method on diverse datasets, including UCI-PEMS and MNIST-Small, demonstrating its effectiveness in classification tasks. The experiments also highlight the accuracy of the χ² approximations, even for sparse and non-binary data.
4. Relevance: The method aligns well with the needs of modern machine learning, where histogram-based features and streaming data are prevalent. The ability to integrate with linear classifiers and near-neighbor search further enhances its applicability.
5. Future Directions: The authors outline promising avenues for future research, such as sparse random projections and coding strategies, which could further extend the method's utility.
Weaknesses:
1. Bound Tightness: While the theoretical bound for collision probability is sharp for α close to 2, it becomes less accurate for α ≤ 1. This limitation is acknowledged but not fully addressed, leaving room for improvement in theoretical guarantees.
2. Limited Dataset Scope: Although the experiments are convincing, the datasets used are relatively small compared to the scale of modern applications. Larger-scale evaluations would strengthen the claims.
3. Approximation Accuracy: While the χ² approximations are accurate, the paper does not explore their impact on downstream tasks in detail. For instance, how the approximation errors influence classification accuracy remains underexplored.
4. Implementation Details: The paper could benefit from more detailed discussions on implementation, particularly for practitioners aiming to adopt the method in real-world systems.
Recommendation:
I recommend acceptance of this paper. The proposed method is innovative, theoretically sound, and practically relevant, addressing critical challenges in high-dimensional data processing. While there are minor limitations, they do not detract from the overall contribution, and the outlined future directions provide a clear path for further advancements.
Pro and Con Summary:
Pros:
- Significant storage and computational efficiency.
- Strong theoretical and experimental support.
- High relevance to modern machine learning tasks.
Cons:
- Theoretical bounds are less tight for α ≤ 1.
- Limited evaluation on large-scale datasets.
- Approximation errors' impact on downstream tasks is underexplored. 
Overall, this paper makes a substantial contribution to the field and is well-suited for presentation at NIPS.