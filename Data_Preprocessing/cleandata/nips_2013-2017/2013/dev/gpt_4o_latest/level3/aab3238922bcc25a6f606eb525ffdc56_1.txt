The paper introduces the Randomized Dependence Coefficient (RDC), a novel method for measuring statistical dependence between random variables. RDC combines a copula transformation with random non-linear projections and kernel Canonical Correlation Analysis (kCCA), achieving computational complexity of \(O(n \log n)\). The method is designed to address limitations of existing dependence measures, such as high computational costs, difficulty in implementation, and inability to handle multidimensional variables. The authors provide a clear and concise implementation in just five lines of R code, emphasizing its simplicity and scalability.
Strengths:
1. Clarity and Presentation: The paper is well-written, logically organized, and easy to follow. The inclusion of theoretical foundations, such as the connection to the Hirschfeld-Gebelein-RÃ©nyi (HGR) coefficient, demonstrates a strong theoretical grounding.
2. Efficiency and Scalability: The \(O(n \log n)\) complexity is a significant improvement over many existing methods, making RDC suitable for large-scale datasets.
3. Experimental Validation: The method is validated on both synthetic and real-world datasets, showing competitive performance in feature selection tasks and robustness to additive noise. The empirical results suggest RDC is a practical and effective tool for dependence measurement.
4. Ease of Implementation: The simplicity of the RDC implementation is a notable advantage, making it accessible to practitioners and researchers.
Weaknesses:
1. Originality: While RDC is an interesting combination of existing techniques (copula transformation, random projections, and kCCA), it lacks significant novelty. The method primarily integrates known components rather than introducing fundamentally new ideas.
2. Comparison with kCCA: The claim that RDC is faster than kCCA is not convincingly supported. Existing methods like incomplete Cholesky decomposition for kCCA achieve similar or better efficiency, and the comparison is insufficiently explored.
3. Regularization Concerns: The role of the parameter \(k\) in random projections as a regularization mechanism is not thoroughly analyzed. The stochastic nature of random projections may lead to score fluctuations, raising concerns about robustness.
4. Fairness of Comparisons: The experimental comparisons with other methods, particularly kCCA, appear limited. The lack of hyperparameter tuning for kCCA in some experiments undermines the validity of the results.
Pro and Con Arguments for Acceptance:
- Pro: The paper provides a scalable, easy-to-implement method with solid empirical performance. It has potential utility as a complementary tool for dependence measurement in large datasets.
- Con: The method lacks originality, and the comparisons with existing techniques are not entirely fair or comprehensive.
Recommendation: While the paper demonstrates strong empirical results and practical utility, the lack of significant novelty and concerns about the fairness of comparisons warrant a borderline decision. The authors should address these issues in a revised version. If accepted, the paper would be a valuable contribution to the field, particularly for practitioners seeking efficient dependence measures.