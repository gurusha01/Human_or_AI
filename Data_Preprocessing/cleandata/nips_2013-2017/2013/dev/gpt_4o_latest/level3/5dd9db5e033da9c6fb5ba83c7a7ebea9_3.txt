The paper presents a novel approach to minimizing decomposable submodular functions by leveraging proximal problems and dual decomposition techniques. The authors argue that solving the proximal problem provides more information than directly minimizing the Lov√°sz extension, and they propose methods that avoid the challenges of non-smooth optimization. Their approach uses reflection-based methods, such as Douglas-Rachford splitting, which eliminate the need for hyperparameter tuning and are easily parallelizable. The paper demonstrates the efficacy of these methods through experiments on image segmentation tasks, showing faster convergence compared to existing techniques.
Strengths:
1. Novelty and Potential Impact: The paper introduces a fresh perspective on submodular function minimization by framing it as a best approximation problem. The use of reflection-based methods, particularly Douglas-Rachford splitting, is innovative and has the potential to inspire further research in optimization and algorithm design.
2. Practical Benefits: The proposed methods are easy to implement, parallelize, and do not require hyperparameter tuning, making them attractive for real-world applications.
3. Empirical Validation: The experiments demonstrate significant improvements in convergence speed over existing methods, particularly for image segmentation tasks. The parallelization results are promising, showing substantial speedups with multiple cores.
4. Clarity in Prior Work: The paper provides a thorough review of prior methods and situates its contributions within the broader context of submodular optimization.
Weaknesses:
1. Lack of Algorithmic Clarity: The presentation of the proposed algorithms is insufficiently detailed. Key contributions, such as formal algorithmic descriptions and theoretical guarantees, are deferred to the supplementary material, which limits the paper's self-contained nature.
2. Iteration Complexity: The paper does not analyze the iteration complexity of the proposed methods, particularly the dependence on the number of components \(r\). This omission makes it difficult to assess the scalability of the approach for larger problems.
3. Experimental Limitations: The empirical evaluation lacks comparisons of iteration costs, which would provide a more comprehensive understanding of convergence behavior. Additionally, the relationship between the parameter \(r\) and problem size is unclear, and figure axes are inconsistent, reducing the clarity of the results.
4. Notational and Clarity Issues: Several terms, such as "discrete gaps," are undefined, and the level set notation is unclear. Missing references further detract from the paper's clarity.
Recommendation:
While the paper offers a novel and promising approach to submodular function minimization, its weaknesses in algorithmic exposition, theoretical analysis, and experimental rigor limit its overall impact. I recommend acceptance with minor revisions, provided the authors address the following:
1. Include formal algorithmic descriptions and theorems in the main text.
2. Provide an iteration complexity analysis, particularly addressing the dependence on \(r\).
3. Clarify experimental setups, improve figure consistency, and include iteration cost comparisons.
4. Address notational ambiguities and define all terms clearly.
Pros and Cons:
Pros:
- Novel dual decomposition approach with practical benefits.
- Promising empirical results, especially for parallel implementations.
- Potential to inspire further research in submodular optimization.
Cons:
- Lack of clarity in algorithmic presentation and theoretical analysis.
- Limited empirical evaluation and unclear experimental setups.
- Missing references and notational issues.
In summary, the paper makes a valuable contribution to submodular optimization but requires improvements in clarity and rigor to maximize its impact.