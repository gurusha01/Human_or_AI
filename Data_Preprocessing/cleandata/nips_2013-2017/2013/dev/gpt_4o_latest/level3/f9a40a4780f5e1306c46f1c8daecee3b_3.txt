This paper presents a significant advancement in entropy estimation for multidimensional binary distributions, with a focus on neural spike train data. The authors propose two novel Bayesian entropy estimators, ĤDBer and ĤDSyn, which leverage the sparsity of neural responses and integrate prior knowledge about spike train statistics. By incorporating parametric and empirical synchrony distributions as priors, the proposed methods address the inefficiencies of existing estimators, such as the Nemenman–Shafee–Bialek (NSB) estimator, which assumes uniform spike word probabilities. The work is well-motivated by the challenges of analyzing neural codes in the era of large-scale multi-electrode recordings, where data limitations and statistical biases pose significant hurdles.
Strengths:
1. Technical Quality: The paper is technically sound, with rigorous derivations and clear explanations of the proposed methods. The hierarchical mixture-of-Dirichlets prior is a sophisticated and well-justified approach that effectively captures the sparsity and correlation structure of neural spike trains.
2. Empirical Performance: The proposed estimators outperform traditional methods, particularly in scenarios with limited data, a critical constraint in neuroscience. The ĤDSyn estimator, in particular, demonstrates rapid convergence and robustness across simulated and real neural datasets.
3. Significance: The work addresses a fundamental problem in neuroscience—accurate entropy estimation for understanding neural coding. The application to retinal ganglion cells provides intriguing insights into temporal synergistic coding, highlighting the potential of these methods for uncovering novel biological phenomena.
4. Clarity and Organization: The paper is well-written and logically organized, with detailed descriptions of the models, algorithms, and experiments. The inclusion of computational optimizations ensures practical applicability, and the availability of a MATLAB implementation enhances reproducibility.
Weaknesses:
1. Generality of Results: While the methods are demonstrated on retinal ganglion cells, the broader applicability to other neural systems remains uncertain. The authors acknowledge this limitation but could provide additional discussion or experiments to address it.
2. Biological Interpretation: The finding of temporal synergistic coding is intriguing but underexplored. A deeper biological interpretation or validation of this result would strengthen the paper's impact.
3. Empirical Synchrony Distribution: The reliance on the empirical synchrony distribution for ĤDSyn raises questions about its robustness in cases with extremely limited data. Further analysis of this dependency would be valuable.
Recommendation:
This paper represents a meaningful contribution to the field of computational neuroscience and information theory. Its methodological innovations and empirical results are compelling, and the work is highly relevant to the NeurIPS community. The strengths of the paper far outweigh its weaknesses, which are relatively minor and could be addressed in future work. I recommend acceptance, with the suggestion that the authors expand on the biological implications of their findings and explore the generalizability of their methods to other datasets.
Pros:
- Rigorous and innovative methodology.
- Strong empirical performance with limited data.
- Clear presentation and reproducibility.
Cons:
- Limited exploration of biological insights.
- Generalizability to other neural systems is uncertain.
Overall, the paper advances the state of the art in entropy estimation and has the potential to inspire further research in both theoretical and applied domains.