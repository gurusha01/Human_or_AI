The paper presents an extension of the Optimistic Mirror Descent (OMD) algorithm to Hölder-smooth loss functions and demonstrates its applicability to structured optimization problems, zero-sum games, and convex programming. The authors build on the notion of predictable sequences to refine regret bounds and achieve faster convergence rates in specific scenarios. Notably, the paper recovers the Mirror Prox algorithm as a special case and addresses an open question by Daskalakis et al. regarding simple algorithms for uncoupled dynamics in zero-sum games. Additionally, the authors propose a simplified approach to the Max Flow problem, matching prior results in complexity while reducing procedural overhead.
Strengths:
1. Generalization and Novelty: The extension of OMD to Hölder-smooth functions is a significant theoretical contribution, providing a smooth interpolation between worst-case and predictable gradient scenarios. The approach is novel and demonstrates versatility across multiple domains, including game theory and optimization.
2. Applications: The framework is applied to diverse and impactful problems, such as saddle-point optimization, zero-sum games, and convex programming. The simplified Max Flow algorithm is particularly noteworthy for its practical implications.
3. Clarity of Results: The theoretical results are well-supported by rigorous proofs, and the regret bounds are clearly articulated. The interpolation between different smoothness regimes is an elegant contribution that advances the state of the art.
Weaknesses:
1. Use of Future Information: A major criticism is the reliance on future gradients (\(\nablat\)) to set learning rates (\(\etat\)), which is unrealistic in practical online settings. This undermines the applicability of the proposed methods in real-world scenarios.
2. Assumption of Known \(F^\): The assumption that \(F^\) is known or can be determined via binary search is problematic. This is a strong requirement that limits the generality of the optimization framework.
3. Clarity and Presentation: Several aspects of the paper could be improved for better readability:
   - The proof of Lemma 1 should reference Lemma 3 of [9] instead of copying it verbatim.
   - Assumptions about gradient norm bounds in Lemma 2 should be explicitly stated.
   - The parameter \(\rho\) in line 11 should be clarified to avoid confusion with the bound in line 113.
   - Lengthy inequalities (e.g., lines 587, 590, 637) should be broken down for better comprehension.
   - Norms used in Corollary 5 (\(F\) and \(X\)) should be explicitly defined.
   - Proposition 6 and Lemma 7 should clarify that equation (9) bounds average/normalized regret.
Related Work: The paper builds on prior work in online learning and optimization but could benefit from referencing the ICML 2013 paper by Hall and Willett, which discusses predictability in related contexts.
Rebuttal Response: The authors' clarification regarding learning rate corrections and approximate knowledge of \(F^*\) is acceptable but does not fully address the practical limitations of these assumptions.
Final Assessment: Despite the noted issues, the paper is a solid contribution to the field. The generalization to Hölder-smooth functions and the novel applications of OMD are valuable advancements. However, the reliance on impractical assumptions and the need for improved clarity in presentation temper the overall impact. 
Arguments for Acceptance:
- Significant theoretical contributions and novel applications.
- Rigorous proofs and clear regret bounds.
- Addresses open questions in game theory and optimization.
Arguments Against Acceptance:
- Unrealistic reliance on future information and known \(F^*\).
- Presentation issues that hinder readability and reproducibility.
Recommendation: Accept with minor revisions to address clarity issues and better contextualize assumptions.