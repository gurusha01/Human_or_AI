This paper introduces a novel framework for multi-level sparse matrix factorization (SHMF), with a hierarchical rank-decreasing structure that enables the simultaneous detection of neurons, assemblies, and their temporal activities from calcium imaging data. The authors propose a bilevel formulation that incorporates structured sparsity constraints and allows for both hierarchical and heterarchical relationships between levels. Unlike prior methods, SHMF jointly optimizes all levels of decomposition, rather than relying on a greedy, level-by-level approach. The method is validated on synthetic data and real-world calcium imaging datasets, demonstrating its ability to recover neuronal assemblies and infer co-activation patterns.
Strengths:
1. Originality and Novelty: The concept of multi-level sparse factorization is innovative, particularly in its application to neuroscience data. The ability to infer hierarchical and heterarchical relationships while jointly optimizing all levels is a significant advancement over existing methods.
2. Clarity and Explanation: The paper is well-written and provides a clear explanation of the proposed framework, supported by detailed mathematical formulations and visual representations (e.g., Fig. 3). The authors effectively contextualize their work within the broader literature, referencing related methods such as NMF, hierarchical topic models, and structured sparsity approaches.
3. Experimental Validation: The experiments on synthetic data are thorough, with quantitative metrics (e.g., graph edit distance, sensitivity, and precision) demonstrating the superiority of SHMF over baseline methods. The application to real-world data further highlights the practical utility of the approach.
4. Significance: Given the growing importance of calcium imaging in neuroscience, the proposed method has the potential to become a valuable tool for analyzing complex neural activation patterns. The ability to detect overlapping and correlated neurons, as well as assemblies, is particularly noteworthy.
Weaknesses:
1. Convergence and Computational Complexity: While the optimization strategy (block coordinate descent) is described, the paper does not provide a detailed analysis of the convergence properties or computational complexity of the algorithm. This omission limits the reader's ability to assess the scalability of the method for larger datasets.
2. Parameter Tuning: The reliance on user-specified parameters (e.g., tradeoff parameters η, λ) is a limitation. While the authors note that the ranks ql are less critical, exploring data-driven or adaptive methods for parameter tuning could enhance the usability of the framework.
3. Generality: Although the method is demonstrated on calcium imaging data, its applicability to other domains with hierarchical structures is not explored. This could limit its perceived impact outside neuroscience.
Pro and Con Arguments for Acceptance:
Pros:
- Innovative and well-motivated framework with clear contributions to neuroscience and matrix factorization literature.
- Strong experimental results demonstrating practical utility and robustness.
- Clear and detailed presentation of the methodology.
Cons:
- Lack of discussion on convergence and computational efficiency.
- Dependence on user-specified parameters without adaptive tuning mechanisms.
- Limited exploration of applicability beyond neuroscience.
Recommendation:
This paper makes a significant contribution to the field of unsupervised learning and neuroscience by introducing a novel multi-level sparse factorization framework. While there are some areas for improvement, particularly in terms of computational analysis and parameter tuning, the strengths of the paper outweigh its weaknesses. I recommend acceptance, with minor revisions to address the concerns raised.