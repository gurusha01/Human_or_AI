The paper introduces the Randomized Dependence Coefficient (RDC), a novel measure of nonlinear dependence between random variables, and proposes a three-step approach involving copula transformation, random nonlinear projections, and Canonical Correlation Analysis (CCA). The authors position RDC as a scalable and computationally efficient alternative to existing nonlinear dependence measures, addressing limitations such as high computational cost, dimensionality restrictions, and implementation complexity. The paper builds on the Hirschfeld-Gebelein-RÃ©nyi Maximum Correlation Coefficient (HGR) and provides theoretical guarantees for each step of the RDC computation. The authors validate RDC's effectiveness through experiments on synthetic and real-world datasets, demonstrating its utility in tasks such as feature selection.
Strengths:
1. Novelty and Practicality: The RDC framework is highly innovative, combining theoretical rigor with practical utility. Its computational simplicity (O(n log n)) and ease of implementation (five lines of R code) make it accessible for widespread adoption.
2. Theoretical Guarantees: The paper provides strong theoretical foundations for each step of the RDC computation, enhancing its credibility. The connection to HGR and the use of random nonlinear projections are well-justified.
3. Empirical Validation: The experimental results are compelling. Figure 4, in particular, demonstrates RDC's ability to capture nonlinear dependencies across diverse association patterns. The feature selection experiments on real-world datasets further highlight its practical significance.
4. Clarity and Organization: The paper is well-written and logically structured, making it easy to follow the technical details and experimental results. The inclusion of R code in the appendix is a thoughtful touch for reproducibility.
5. Significance: While nonlinear correlation is not a central topic in machine learning, it serves as a valuable building block for tasks like regression, feature selection, and independence testing. RDC's scalability and robustness make it a significant contribution to the field.
Weaknesses:
1. Parameter Sensitivity: The paper acknowledges that the choice of parameters (e.g., number of random features, scaling factor) is crucial for RDC's performance. However, the parameter selection process is heuristic and lacks a systematic approach, which could limit its applicability in some scenarios.
2. Overfitting in Specific Cases: The experiments reveal that RDC struggles with certain association patterns, such as linear relationships and step functions, due to overfitting or the smoothness prior induced by sinusoidal features.
3. Comparison Scope: While the paper compares RDC to several state-of-the-art methods, the omission of KCCA in some experiments due to hyperparameter tuning challenges is a missed opportunity for a more comprehensive evaluation.
Pro and Con Arguments for Acceptance:
Pro: The paper is highly novel, theoretically sound, and demonstrates strong empirical performance. Its computational efficiency and practical relevance make it a valuable contribution to the field.  
Con: The parameter sensitivity and occasional performance issues in specific patterns could limit its robustness in certain applications.
Recommendation:
I recommend acceptance of this paper. Despite minor weaknesses, the RDC framework is a significant advancement in nonlinear dependence measurement, offering a scalable and practical solution with strong theoretical underpinnings. The paper is well-suited for the conference audience and has the potential to inspire further research and applications.