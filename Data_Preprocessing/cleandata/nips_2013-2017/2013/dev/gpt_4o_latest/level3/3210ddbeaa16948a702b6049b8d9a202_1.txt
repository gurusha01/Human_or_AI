The paper proposes a hashing scheme based on random projections using a symmetric alpha-stable distribution and analyzes its collision probability for points in \( \mathbb{R}^D \). The key contribution is the observation that for \( \alpha = 1 \) (Cauchy random projections) on binary data, the collision probability can be approximated as a function of the chi-square (\( \chi^2 \)) similarity. This is significant given the widespread use of \( \chi^2 \) similarity in histogram-based features for applications in computer vision and natural language processing. However, the paper's broader claims and practical implications warrant further scrutiny.
Strengths:
1. Novelty: The connection between collision probability under Cauchy random projections and \( \chi^2 \) similarity is novel and could have implications for efficient similarity computations in high-dimensional data.
2. Theoretical Rigor: The proofs provided in the appendix are clear and mathematically sound, particularly for the bounds on collision probability and the proposed approximations.
3. Experimental Validation: The paper includes experiments on real-world datasets (e.g., MNIST and UCI-PEMS) and simulated data to validate the proposed approximations. The results demonstrate that the approximations for \( \chi^2 \) similarity are accurate, especially for sparse data.
4. Practical Relevance: The proposed method reduces storage requirements by using only 1-bit representations of projections, which is advantageous for large-scale and streaming applications.
Weaknesses:
1. Approximation Quality for General Data: While the approximation is accurate for binary and sparse data, the bound for general data is loose, raising questions about its utility in broader contexts. The paper does not adequately address the implications of this limitation.
2. Utility for Learning Tasks: The paper does not convincingly demonstrate the usefulness of the kernel defined by the hashing scheme for practical tasks like classification with linear SVMs. While the authors mention its potential, empirical evidence on datasets like MNIST is insufficient.
3. Loss of Efficiency: The experiments suggest that approximating \( \chi^2 \) similarity from collision probabilities may require kernel SVMs and exhaustive search, which undermines the efficiency gains promised by linear SVMs and near-neighbor search.
4. Incomplete Problem Resolution: The paper does not resolve the broader problem of designing a hashing scheme that directly approximates \( \chi^2 \) similarity, leaving a gap in its practical applicability.
Recommendation:
While the paper presents an interesting theoretical contribution, its practical utility remains unclear. The lack of strong evidence for the usefulness of the proposed hashing scheme in real-world learning tasks is a significant drawback. Additionally, the reliance on kernel SVMs for approximating \( \chi^2 \) similarity contradicts the claimed advantages of linear SVMs. To strengthen the paper, the authors should provide more comprehensive experiments demonstrating the kernel's utility and address the limitations of the approximation for general data.
Arguments for Acceptance:
- Novel theoretical insights connecting Cauchy random projections to \( \chi^2 \) similarity.
- Clear and correct proofs for the proposed bounds and approximations.
- Potential for applications in high-dimensional and streaming data scenarios.
Arguments Against Acceptance:
- Insufficient empirical evidence on the practical utility of the proposed method for learning tasks.
- Loose bounds for general data, limiting the method's applicability.
- Loss of computational efficiency in approximating \( \chi^2 \) similarity.
Overall, the paper makes a valuable theoretical contribution but falls short in demonstrating its practical impact, which is critical for acceptance at a venue like NeurIPS.