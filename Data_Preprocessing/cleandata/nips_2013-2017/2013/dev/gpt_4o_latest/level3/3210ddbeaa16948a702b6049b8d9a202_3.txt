The paper proposes fast methods to compute non-linear kernels, particularly chi-square (χ²) kernels, for non-negative vectors using sign stable random projections. It explores the approximation of other kernels by varying the scale parameter α in stable distributions and provides two formulas to approximate collision probability as a function of χ² similarity. The authors argue that their method is particularly useful for high-dimensional data, data streams, and histogram-based features common in computer vision and natural language processing. While the ideas presented are promising, the paper suffers from significant issues in clarity, structure, and rigor.
Strengths:
1. Novelty and Potential Impact: The paper introduces an innovative approach to approximate χ² similarity using sign stable random projections. This is particularly relevant for applications in large-scale machine learning and data streams, where computational efficiency and storage are critical.
2. Practical Applications: The method has clear utility for scenarios involving histogram-based features, such as text and image classification, and offers significant storage savings by using 1-bit representations.
3. Experimental Validation: The authors provide experimental results on datasets like UCI-PEMS and MNIST-small, demonstrating the potential of their method for classification tasks. The proposed approximations of collision probability are shown to be accurate in both simulated and real-world datasets.
Weaknesses:
1. Clarity and Organization: The paper is poorly organized and difficult to follow. The structure feels reversed, as empirical collision probabilities are more naturally used to approximate χ² similarities in applications, yet this connection is not presented clearly. The lack of an explicit algorithm layout for the main contribution further hampers readability.
2. Motivation: The motivation for using χ² similarity is inadequately justified. While the paper highlights its popularity in histogram-based features, it does not convincingly explain why χ² similarity is superior to other measures in the presented contexts. The examples, such as the UCI-PEMS dataset, are confusing and insufficiently justified.
3. Theoretical Rigor: Lemma 4 is presented without proof, and the analogy with Lemma 2 is invalid. This undermines the theoretical soundness of the paper. Additionally, the rebuttal on the positive semi-definiteness (psdness) of the acos χ² kernel is unconvincing.
4. Presentation of Results: While the experimental results are promising, the lack of clear explanations and visual clarity in figures makes it difficult to assess the significance of the findings.
Pro and Con Arguments for Acceptance:
- Pro: The paper introduces a novel and potentially impactful method for approximating χ² similarity, which could benefit large-scale learning applications.
- Con: The paper is messy, lacks theoretical rigor, and fails to provide clear motivation or justification for its approach. Significant revisions are needed to improve clarity and organization.
Recommendation: While the paper contains promising ideas, it requires substantial improvements in presentation, structure, and theoretical rigor to be suitable for NIPS. The authors should focus on reorganizing the content, providing explicit algorithmic details, justifying their motivations, and addressing the theoretical gaps. At its current state, I recommend rejection but encourage resubmission after major revisions.