This paper presents a novel approach to submodular function minimization (SFM) by formulating it as an orthogonal projection problem, enabling the use of easily parallelizable algorithms. The authors focus on decomposable submodular functions, leveraging their structure to solve the proximal problem more efficiently than existing methods. By avoiding cumbersome parameter tuning and employing reflection-based methods such as Douglas-Rachford splitting, the proposed approach achieves faster convergence and is straightforward to implement. Experimental results validate the benefits of the method for minimizing the Lov√°sz extension over \([0,1]^n\), particularly in image segmentation tasks and other applications involving graph cuts and concave functions.
Strengths:  
The paper makes a significant contribution by connecting SFM to a best approximation problem, which is both theoretically elegant and practically impactful. The use of reflection methods, such as Douglas-Rachford splitting, is a novel and effective strategy that avoids hyperparameter tuning, a common challenge in optimization. The authors provide a thorough theoretical foundation, including dual formulations and connections to convex optimization, which are well-supported by prior work. The experimental results demonstrate the practical utility of the proposed methods, showing faster convergence compared to traditional approaches. Additionally, the paper is well-written, with clear explanations of complex concepts, making it accessible to readers with a background in optimization and submodular analysis.
Weaknesses:  
Despite the emphasis on parallelizability as a key advantage of the proposed methods, the paper lacks empirical evidence to substantiate the claimed speedups in parallel implementations. While the experiments demonstrate the effectiveness of the algorithms in terms of iteration counts and convergence rates, a detailed comparison with existing parallel algorithms, such as those for graph cuts, is missing. This omission weakens the paper's claims about the scalability and practical utility of the approach in large-scale settings. Furthermore, while the paper references related work extensively, it would benefit from a more explicit discussion of how the proposed methods compare to state-of-the-art parallel SFM algorithms in terms of computational complexity and runtime.
Arguments for Acceptance:  
1. The paper introduces a novel and theoretically sound approach to SFM, advancing the state of the art.  
2. The proposed methods are easy to implement, hyperparameter-free, and demonstrate faster convergence in experiments.  
3. The work has potential applications in diverse fields, including machine learning, computer vision, and signal processing.  
4. The clarity and organization of the paper make it a valuable resource for researchers in the field.
Arguments Against Acceptance:  
1. The lack of empirical evidence for parallel speedups undermines the paper's claims about scalability.  
2. A more detailed comparison with existing parallel SFM methods is needed to contextualize the contributions.  
3. The experiments, while promising, are limited in scope and do not fully explore the practical implications of the approach.
Recommendation:  
Overall, this paper makes a strong theoretical contribution to SFM and demonstrates promising experimental results. However, the lack of empirical validation for parallel performance is a notable shortcoming. I recommend acceptance, provided the authors address this limitation in a future revision or supplementary material.