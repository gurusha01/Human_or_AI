This paper introduces two novel Bayesian entropy estimators, ĤDBer and ĤDSyn, tailored for estimating the entropy of binary spike trains in neural data. The authors address a critical limitation of existing methods, such as the Nemenman–Shafee–Bialek (NSB) estimator, which fail to exploit the statistical sparsity and higher-order dependencies characteristic of neural spike trains. By leveraging priors informed by synchrony distributions, the proposed methods incorporate a priori knowledge about spike patterns, leading to more efficient and accurate entropy estimation. The paper demonstrates the feasibility of these estimators through simulations and real neural data, showing that ĤDSyn, in particular, outperforms traditional methods in terms of convergence and accuracy.
Strengths:
1. Technical Quality: The paper is technically sound, with a clear derivation of the proposed methods and their computational efficiency. The hierarchical mixture-of-Dirichlets prior is a thoughtful and innovative approach to addressing the sparsity and correlation structure in neural data.
2. Experimental Validation: The authors provide extensive experimental results, comparing their methods to established approaches like NSB and BUB. The results convincingly demonstrate the superiority of ĤDSyn, especially in scenarios with limited data.
3. Significance: The work addresses a fundamental problem in neuroscience and information theory—accurate entropy estimation for neural spike trains. The proposed methods have the potential to advance the state of the art and inspire further research in neural coding and statistical modeling.
4. Clarity and Organization: The manuscript is well-written and logically organized. The inclusion of mathematical derivations, visualizations, and practical applications (e.g., temporal dependence analysis) enhances the reader's understanding.
Weaknesses:
1. Higher-Order Dependencies: While the methods rely on spike count-based descriptions, the performance under higher-order dependencies is not thoroughly explored. This could limit the applicability of the approach to datasets with complex temporal or spatial correlations.
2. Comparative Analysis: The paper would benefit from a more comprehensive comparison with other methods, such as BUB, under controlled scenarios like GLM-generated spike trains. This would strengthen the argument for the accuracy and robustness of the proposed estimators.
3. Minor Issues: 
   - Line 163: A missing reference needs to be addressed.
   - Line 221: Clarify if \(\alpha=0\) implies a uniform distribution.
   - Line 296: Typo ("for" should be "form").
Recommendation:
The paper presents a significant contribution to the field of neural data analysis, with novel methods that are both theoretically sound and practically impactful. However, addressing the noted weaknesses—particularly the exploration of higher-order dependencies and additional comparative analyses—would further solidify its contributions. I recommend acceptance, contingent on minor revisions to address the above points.
Arguments for Acceptance:
- Novel and well-motivated methods for entropy estimation.
- Strong experimental results demonstrating practical utility.
- Clear and well-organized presentation.
Arguments Against Acceptance:
- Limited exploration of higher-order dependencies.
- Insufficient comparative analysis with alternative methods in some scenarios.