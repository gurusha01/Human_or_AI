An associative memory mechanism for pattern completion of non-binary integer valued data is proposed for which the authors claim that the number of stored patterns can be exponential in the number of neurons. The main result of this paper is an analysis of the performance of this memory model in the presence of intrinsic neural noise. Interestingly it is shown by the analysis and simulations that intrinsic noise can increase the performance of the model. 
Comments: 
1) It would be important to add results supporting that the model can store exponentially many patterns. Either theoretical capacity results or simulation curves how recall error behaves as a function of the number of stored patterns. 
2) To make the paper stand-alone, it would be important to describe the learning algorithm from [10] at least the main principle 
3) For integer-valued data it is somewhat artificial to confine the (external) additive noise to be -1, 0 or 1. Can the model handle larger additive errors? 
4) The discussion stresses the neurobiological relevance of this model. You also should discuss that many elements of your algorithm are not biologically plausible, e.g., the negative activity in the control neurons, the algorithm loops Alg1 and Alg 2 etc. 
5) It would be important in the final version of the paper to include the essential proof lines from the appendix. 
6) To gain space, you could omit the 3D figure, Fig 4, which is redundant with Fig. 5. 
 An associative memory mechanism for pattern completion of non-binary integer valued data is proposed for which the authors claim that the number of stored patterns can be exponential in the number of neurons.