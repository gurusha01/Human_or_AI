This work provides new algorithms for differentially private online learning in basically all settings where results are known in the non-private case. The results very closely parallel (with some additional small factors and dependences) the best non-private bounds. There has been significant recent interest in differentially private learning, and this paper gives a much more comprehensive and compelling suite of results than previous work. 
The approach is actually quite simple at its heart---do follow the approximate leader using a private (noisy) history that you maintain using standard algorithms for maintaining a differentially private counter. The natural suitability of follow the leader algorithms for privacy has been observed before, but the treatment here and the actual bounds obtained are very nice. 
I'd prefer that you describe this work as giving a class of private learning algorithms, or a technique for constructing such algorithms, rather than a "general technique for making online algorithms differentially private" (since it's not the case that you can take an arbitrary online algorithm and make it private using this technique---right?). 
The practice of citing references without listing authors made this paper hard to read---I was constantly flipping to the bibliography, since in many cases knowing the reference was important to understanding the ideas (e.g. in cases where the text did not make sufficiently clear whether the referenced work was in the private or non-private case). 
In Table 1, it's probably worth reminding the reader that the delta in the first column comes from (eps, delta)-DP. 
Why aren't there citations for the non-private results in Table 2? And also, the caption says it's the full-information setting, but the results are clearly for the bandit setting. And it seems your results for the adaptive case should have a T^3/4, not T^2/3, no? 
Do you think the explicit dependences you see on the dimensionality are necessary when preserving privacy? Do you think there's a provable (small) gap between what is achievable in the dependence on T between private and non-private algorithms (accounting for your different poly-log factors)? 
The second to last paragraph on p.6 has strange redundancy. 
 A simple and appealing approach and set of results on private online learning.