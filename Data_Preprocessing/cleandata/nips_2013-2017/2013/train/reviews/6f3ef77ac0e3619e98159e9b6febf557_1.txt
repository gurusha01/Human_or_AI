This paper presents a generative model for natural image patches which takes into account occlusions and the translation invariance of features. The model consists of a set of masks and a set of features which can be translated throughout the patch. Given a set of translations for the masks and features the patch is then generated by sampling (conditionally) independent Gaussian noise. An inference framework for the parameters is proposed and is demonstrated on synthetic data with convincing results. Additionally, experiments are run on natural image patches and the method learns a set of masks and features for natural images. When combined together the resulting receptive fields look mostly like Gabors, but some of them have a globular structures. 
Quality: 
The model is interesting and accounts for some very important constituents of natural images. I like the explicit modeling of translation invariance and the relation drawn between this and convolutional networks in the discussion. Results are quite interesting as well. 
I have several reservations though which I would be happy if the authors can address to. 
My main concern is about the conditional independence assumption given the mask and features (with locations) - why was the noise chosen to be pixel-wise independent? This really limits the expressive power of the model in my opinion, as it only allows the resulting patches to have a "sprite" like structure, with similar features just masked and translated. I would be happy to see samples from the model as well, and compare them to natural image patches. 
Additionally, I would love to see what happens when you train the model on non-filtered (unwhithened) patches, and see the effect of whitening here, as I suspect it has a large part of the resulting receptive fields. 
Finally, the background model seems both artificial and simplistic to me. I am not sure what "background" is even in natural images, it is mostly other elements of the scene just scaled down, or blurred - why not just constrain all the pixels to be covered by at least one mask? It would have been nice if a "background" element was learned automatically from the data (flat mask with simple features, for example). 
Clarity: 
The paper is all in all well written, but since the model is quite complex there are many different parameters, and I must say that sometimes their definition is hidden in some inline equation which makes it harder to follow. I would suggest making Figure 1 more approachable by replacing the mask and features used to something synthetic which would convey the message. The current ones used not very intuitive (for example, if the feature and mask would be switched I don't think anyone would notice). A simple mask and a simple texture would probably be easier to understand here. 
Originality: 
Looks like an original work with an interesting model and good analysis. 
Significance: 
This work would be interesting to the natural image statistics community, as well as to parts of the neuroscience and sparse coding people around. 
 An interesting paper with a detailed model which accounts to some basic properties of natural images. While there are some concerns here, all in all this is good solid work.