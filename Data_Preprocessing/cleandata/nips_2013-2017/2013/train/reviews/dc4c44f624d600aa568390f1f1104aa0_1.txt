The paper investigates a technique for efficiently combining multiple rankings into a Placket Luce model. The key idea is to use so-called breakings, which are subsets of the total ranking information. The authors show that consistency is an important property, which is, e.g., satisfied by top-k rankings (1,2 > 3,4,5), but not by an adjanceny ranking (1 > 2,2 > 3,3 > 4,4 > 5). 
The paper is o.k. The presentation of the method appears occassionally overly formal, but the examples make the message quite clear. 
I did not understand why the method is called "Generalized Method of Moments". What is the method of moments, and how has it been generalized here? For a while I thought that the MM in the experimental comparison stands for the non-generalized MM, but it stands for "Minorize Maximization". 
The authors also assume that the reader is familiar with the MM method (which I am not). Thus, it is difficult to appreciate the contribution. The authors claim that MM is standard method for rank aggregation, but I think they should have also considered other methods. 
Why are the top-k and the bottom-k breaking not symmetric in structure? Why would anyone use the bottom-k breaking? 
 Overall, the paper appears quite reasonable, but I don't think that this contribution will make a strong impact. In any case, the experimental evidence (improvement over MM on synthetic datasets and on the Sushi datasets) does not strike me as convincing enough.