This paper presents an active learning approach to structured prediction problems, utilizing an entropy measure to select which nodes in a partially-labeled example to query. The paper builds on recent work by Schwing et al on efficient inference methods for structured learning models with missing labels. 
Two variants are proposed and explored. The first finds the output node in unlabelled or partially labeled examples with highest entropy after learning on labeled and partially labelled examples. The second includes the unlabelled examples in learning, and here no extra inference computation is necessary since the entropies for all nodes are computed during learning. 
The experiments are clear and results are pretty good. One issue is that the only comparison is to a baseline which selects nodes to label randomly. This is a fairly weak straw-man. It would have been good to explore some other strategy, such as expected error reduction. It also would have been good to examine how the active learning performs as the proportion of weakly labeled to unlabelled to full-labeled data varies. Nonetheless, the consideration of amount of computation required, and effect of the epsilon factor, are well done. 
One issue that the authors should address is how approximation errors in entropy (whose estimation relies on convex belief propagation) may affect the results. 
Overall the paper is well executed but not especially novel. Uncertainty-based query selection is the standard active learning approach, and the inference and learning methods explored here stay very close to that of Schwing et al. The fact that the results are good are very encouraging, and suggest that this will be a very fruitful direction for structured prediction research. This paper presents an active learning approach to structured prediction problems, utilizing an entropy measure to select which nodes in a partially or unlabelled example to query. The method is a fairly straightforward extension of a recent learning/inference method, but the results are pretty strong.