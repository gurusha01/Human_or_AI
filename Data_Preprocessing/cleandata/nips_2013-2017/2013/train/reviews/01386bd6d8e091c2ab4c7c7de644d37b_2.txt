This paper shows that you can infer network properties of a large network by sequentially recording from subnetworks and then stitching the resulting sub-models. Extended to point-process data, this could be applied to a lot of datasets where the typically a few of the channels are moved every day. I am not really aware of any similar work (J. W. Pillow and P. Latham, "Neural characterization in partially observed populations of spiking neurons" seems to come the closest), and it seems like a powerful idea. 
In practice it's not clear how much this method is limited to data that is close to linear-Gaussian, and I don't get a good intuition from the paper how the fitting might break down from various deviations to the assumption. In the extreme case, where the full model can be estimated from one subset (up to a linear transformation of the latent dimensions, as the authors state), it's not clear how much additional information about the coupling matrix is gained from adding on other subsets, as opposed to, say, just using more data from one of the subsets. 
Another point that raises some questions is, why does the model on real data only work if there is some overlap between the two population? Obviously this suggests that the linear-Gaussian simulated data does not tell the full story, but it would be nice to have at least some intuition what the overlap does to better constrain the model. 
In the experiments on real data, where the linearity assumption probably breaks, one must also wonder how much of the explained noise correlations (which are fit well, the couplings themselves hardly correlate to the true couplings at all in 3b) are due to common input and not direct, pair-wise couplings. I would assume that the noise correlations could be better modeled with latent variables than pairwise couplings. 
The authors devote a lot of space to intro and discussion, but are awefully light on the details of the estimation. The equation for the M step on the bottom of page 3 is presented as the main contribution, but not really explained or derived. Maybe it's a trivial result to LDS experts, but that would erode a lot of the novelty of the paper. I think the authors had a very good idea, but it just needs to be explained better to properly convey the significance of the result. 
 A neat idea tested against real data, but some details aren't clear.