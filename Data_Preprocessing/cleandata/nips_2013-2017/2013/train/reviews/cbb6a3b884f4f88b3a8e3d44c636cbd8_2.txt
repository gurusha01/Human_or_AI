This paper investigates a tradeoff in hierarchical classification: when a hierarchy is deep, a classifier needs to make a decision at every level of the tree which is likely to propagate errors. When a hierarchy is flat(ter), less decision need to be made so there is less room for errors to propagate, however, the decisions are harder (because the cardinality of is higher). 
This paper introduces a data-dependent generalization error bound for kernel based hypotheses. The main theorem of the paper states an upper bound on the generalization error of a hierarchical classifier in terms of the empirical error and the Rademacher complexity of the classifier. The former encouraging flat classifiers, the latter encouraging deep classifiers. 
The paper uses the insight from the generalization bound to come up with a strategy to prune hierarchical classifiers. The paragraph starting on line 307 was a bit unclear to me; I missed the motivation of the methodology using the metaclassifier and how it relates to improvements in the generalization bound. 
The paper is clearly written and solves an interesting and important problem. On the theoretical side, the paper contributes to the literature on hierarchical classification. My main issue with the paper is that it is unclear how to use their insights for anyone doing hierarchical classification. I think the authors can do a better job of describing the practical take-away around how to best do pruning of a hierarchy to improve hierarchical classification. A well written theoretical paper on the important topic of hierarchical classification. The writeup falls short on taking the theoretical insight and deriving practical procedures for improving hierarchical classification.