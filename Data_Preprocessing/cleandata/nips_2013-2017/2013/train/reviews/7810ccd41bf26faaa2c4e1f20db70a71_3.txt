The paper proposes a criterion called \Sigma-optimality for active learning in Gaussian Random Fields (GRFs). V-optimality (proposed before), queries nodes that minimize the L2 loss. The paper argues that for classification problems V-optimality is not ideal (as a surrogate for the 0/1 more appropriate loss). 
\Sigma-optimality was proposed before but not for active learning. The paper shows that \Sigma optimality leads to a submodular function and provides a (1 âˆ’ 1/e) approximation bound to the global optimum. It also shows that experimentally it outperforms V-optimality and other active learning criteria, when a greedy algorithm is used. 
Like V-optimality, \Sigma-optimality tend to pick nodes that have high variance or are correlated with nodes with high variance. However, the paper makes the observation based on Eq. 3.7 that \Sigma optimality also prefers nodes that have 'more influence', usually nodes in the cluster centers. 
Experiments show that on synthetic datasets (generated according to the assumed model) \Sigma-opt outperforms V-opt and random. The graphs are shown for specific model parameters \beta and \delta. It would be interesting to see when \Sigma optimality breaks, in particular when random or V-opt are close (or better) than the proposed approaches. What happens on sparse graphs or highly connected ones? 
I am surprised by how badly MIG works and to a lesser extend also for the terrible performance of Uncertainty-based active learning. Is there any explanation for this? It would be useful to include in the paper how MIG was employed and include a discussion to contrast these methods (together with Unc) with the proposed approach. 
This paper is clearly written. It is a small extension of previous ideas, in particular the use of V-optimality for the same problem and borrowing the idea of \Sigma-optimality from recent previous work. Its significance is primarily based on the improved performance shown in the experimental evaluation. However, it is not very clear why it outperforms other methods with such ease. Overall, the paper is based on using \Sigma optimality as active learning criterion in GRFs (for classification), a well-known problem. \Sigma optimality have been proposed before, thus the mild novelty is in its use for active learning. The proven submodularity guarantee is an incremental contribution.