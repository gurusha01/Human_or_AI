This paper discusses two new methods for estimating the density ratio of two probabilities. The first method uses the equation of importance sampling, and formulates it in the form of a regularization problem where L^2 norm of the deviation from the equality and RKHS regularization term are used (Type I Fredholm equation). The second method considers a kernel where the locality parameter should go to zero for consistency. The latter is also expressed in the form of regularization (Type II Fredholm equation). The paper shows some theoretical results on convergence, and demonstrates the practical performance experimentally. 
While the method has similarity to existing methods such as KMM, it is a strong advantage of the proposed one that the L^2 formulation enables us to apply cross-validation (CV) approach to choose the parameters in the algorithm. Unlike supervised problems, where CV is dominant as a method for choosing parameters in practice, there are no general methods for unsupervised learning. The paper solves this issue for density ratio estimation with a clever idea of using L^2 norm. 
It is nicer to make a remark that the objective function given by RKHS, such as in KMM, is not appropriate for choosing a kernel with CV, since the values of the objective function depend on the kernel, and thus not comparable. 
In Theorem 1, by the (-t/log \lambda) factor, the derived convergence rate is slow with fixed t. In many literatures of kernel methods, with fixed t, one can derive a polynomial rate with respect to the sample size after fixing the rate of \lambda. Are there any reasonable additional assumptions that give a polynomial rate for the proposed estimator? Caponnetto and De Vito (2007), for example, make assumptions on the spectrum of the operator K_{p,t} to derive the optimal rate for kernel ridge regression. I guess that making a stronger assumption on q/p will also derive a polynomial rate. It will be more interesting if the authors discuss such polynomial rate under stronger assumptions with fixed t. 
In estimating a density ratio, we usually need to make an assumption that q/p is in a nice function class such as Sobolev. It is important to note that this assumption is very strong, requiring some knowledge on the ratio or tails of p and q. Under such an assumption on q/p, the opposite ratio p/q is usually behaves badly. It is necessary to include some discussions somewhere on this limitation of density ratio estimation. 
This is not a requirement, but the supplementary materials should be improved. There are many typos and minor mistakes, which make it hard to check the correctness of the theoretical results in the main paper. For instance, in Lemma 5, W2^2 should be Ws^2, and the bound should be D1 (t/-log \lambda)^2 + \lambda^{1-\alpha} D2 \|f\|_2^2. The expressions at line 675 and 686 are incorrect, while Eq.(31) is correct. In the proof of Lemma 5, the domain of the integral at line 1147 must be \| \xi\|^2 \geq. Since the theoretical results of convergence consist of main contributions of this paper, I advise the authors to revise the supplementary material. 
References: 
Caponnetto A., De Vito E. Optimal Rates for Regularized Least-Squares Algorithm. Foundations of Computational Mathematics, 7 331-368 (2007). 
 The paper proposes a new approach to the density ratio estimation. The strong point is that CV can be effectively applied to choose parameters.