210 - What Are the Invariant Occlusive Components of Image Patches? A Probabilistic Generative Approach 
The paper demonstrates that learning and inference are feasible in a nonlinear generative model of natural images that captures translation invariance and occlusion. This is an interesting extension of previous work on Occlusive Component Analysis. When applied to natural image patches, it confirms the previous finding that modeling occlusions leads naturally to globular receptive fields beyond the usual oriented, Gabor-like filters. 
The paper is technically sound, well written, and puts the presented work in the larger context of probabilistic models of images. The results are not surprising given previous work on OCA, but the technical advance over convolutional networks (namely the occlusive nonlinearity, and the ability to learn a substantially larger number of components) is impressive. 
- Quality 
The model is a translation invariant extension of OCA, that includes all possible planar translations. Therefore inference is intractable, but the paper clearly demonstrates an efficient approximation based on preselection. 
The results on natural images are analyzed quantitatively, by fitting linear receptive fields to the inferred components, and showing that the majority of the RFs are oriented Gabors, but a large proportion of RFs can be characterized as globular or containing more complex structure. 
Two aspects of the results on artificial data (Section 4) seem potentially worrying to me. 
First, in Fig. 2C the system learns all the true components, plus one that was not used to generate the data; this extra component resembles the globular RFs that are a signature of this model, so isn't it worrying that the model 'hallucinates' one in a simple artificial dataset that does not contain any? How do artificial patches, for which this "dumpy" component is inferred to be present, look like? What proportion of globular fields would be found if the model was trained on noise inputs, or on occlusion-free natural image patches (eg textures)? 
Second, on line 231 the authors state: "We assess the reliability of our learning algorithm by repeating the learning procedure with the same 
configuration but different random parameter initializations. The algorithm covers all the generative components in 11 out of 20 repetitive runs." Doesn't this mean that on almost half the cases the training converges to the wrong solution? 
- Clarity 
The paper is clearly written, well organized, and contains all the information necessary to understand the model and the results. Here are some minor suggestions: 
- Line 232: "access" should be "assess" 
- Line 319: I think "W" should be "R" ?? 
- Reference 34 appears not to be used? 
- Originality 
To my knowledge, the main novelty of the paper is to extend OCA to include translation invariance. Inference in this model is intractable but the authors provide an efficient approximation using the existing technique Expectation Truncation. This also results in a technical advance over other convolutional network approaches in terms of the number of components that can be learned. 
- Significance 
The paper provides a demonstration that complex nonlinear generative models can be efficiently trained on natural image patches. It will be interesting to see whether the quantitative (components) and qualitative (globular RFs) improvements over existing invariant models translate into better performance at perceptual tasks. 
 The paper extends the Occlusive Component Analysis model to incorporate translation invariance, using a variational approximation to train the model on natural images. The results are somewhat expected and confirm previous findings of OCA, but the approach overall makes a step forward in demonstrating the feasibility of sophisticated generative model of complex signals.