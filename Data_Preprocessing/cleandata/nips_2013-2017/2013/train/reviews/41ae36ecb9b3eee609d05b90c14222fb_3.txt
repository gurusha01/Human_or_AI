--------added after authors' rebuttal-------- 
The proof for |Rk| <= kappa |Xk - X_{k+1}| has been explicitly established in 
"Scalable nonconvex inexact proximal splitting", Suvrit Sra, NIPS'12. 
(Lemma 4) 
--------end-------- 
For trace norm regularized risk minimization, a popular method is the proximal gradient algorithm. The sublinear global convergence rate of this algorithm is well-understood while it is also known that the rate is linear if the loss is additionally strongly convex. This paper relaxes the strong convexity assumption by following the framework established by Luo and Tseng. In particular, the authors proved a local error bound that allows them to show that the proximal gradient converges asymptotically at a linear rate for trace norm regularization. The paper more or less follows the usual pattern to prove the local error bound, with a new observation that allows simultaneous diagonalization of the matrices. 
Quality: 
This paper appears to be technically sound. The only gap I had in mind is in the appendix, line 085. Please explain why such a choice of kappa3 (say alpha < 1) leads to the claimed inequality R(X^k) <= kappa3 |X^k - X^{k+1}|_F ? 
Clarity: 
I could follow the paper without much difficulty. Although due to the technical nature, it might be a good idea to lay out the main claims first and then go to details one by one. Particularly, after stating the local error bound, the authors might want to postpone the very technical proof of the local error bound but turn immediately to prove the linear rate (which by the way, has hardly anything new in it). 
Originality: 
The originality of this paper is moderate. The observation that allows the authors to simultaneously diagonalize matrices seems to be new and interesting; other than that, the authors more or less follow the existing approach to establish the local error bound. The rest steps are not new. 
Significance: 
The significance of this paper is mainly in theory, with little impact on algorithm design though. While it is certainly great to extend the linear convergence rate of the proximal gradient algorithm to more practical scenarios (i.e., relaxed form of strong convexity), the significance is nevertheless lowered by the asymptotic nature of the proof (and claim). The way the authors handle the diagonalization of matrices might be of some independent interest. This work proved that the proximal gradient algorithm, when applied to trace norm regularized risk minimization, converges asymptotically at a linear rate (under a relaxed form of strong convexity). The authors mostly follow a well-established framework due to Luo and Tseng, with a new observation that allows them to (simultaneously) diagonalize matrices hence (more or less) reduce to the vector case. Overall, this work is incremental and is moderately interesting in the theoretical aspect.