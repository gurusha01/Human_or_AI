This paper presents an approach to active learning for structured output spaces. The idea is to use local marginals for selection rather than performing inference for all random variables and then selecting the query for active learning. For computing the local marginals, the approach builds upon [28]. 
I like the direction and the task in the paper. Active learning for structured spaces is an important problem in vision which is hardly being looked at. Therefore, the research in the paper is quite relevant. I think the paper makes some important contribution (although building upon the past work). 
However, there are a few issues with the paper: 
1. The experiments are shown on indoor geometry task. I believe for broader impact the authors should show experiments on other task such as scene labeling or human pose ...Both of these are structured spaces and will increase the impact hugely. 
2. The baselines in the experiment are just ablative ones. I wonder if the paper can be compared to [7],[33]. Also, I am not sure but isn't [7] similar to Algo 1 and [33] similar to Algo2. I would like a more explicit comparison to how the paper is different from [7,33]. 
3. Sec 2.2 is quite difficult to understand. I would suggest reducing the related work and focusing more on sec 2.2 
4. There are absolutely no qualitative results in the paper! I believe showing qualitative results and why one image is preferred over another will help explain the whole active learning process better. I think the paper misses those intuitive discussion about why this approach works ? 
5. Finally I think the paper should cite 
Siddiquie et al, Beyond Active Noun Tagging: Modeling Contextual Interactions for Multi-Class Active Learning, In CVPR 2010. 
This paper performs active learning on structured output space and use the structure/contextual interactions for selecting the queries.  I like the direction of the paper. While the approach is not completely novel, it takes the right steps and I believe it should be accepted.