This paper investigates how to automatically set the step size of policy gradient methods, in particular focusing on the Gaussian policy case. The paper provides a lower bound on the difference in performance when taking a gradient step, and optimizes this lower bound with respect to the step size. 
Overall, I like the approach of thoroughly studying the interplay between step size and policy performance. While the paper could be improved with clearer, more direct results, I think this is a fine, albeit incremental result for NIPS. 
Quality. The paper contains a hefty amount of theoretical work, but sometimes lacks a certain focus, e.g. Theorem 3.3 seems extraneous to the main result. I think the paper would be improved with a clear directing line throughout and less "beating around the bush". 
The experimental results are somewhat disappointing. While a meaningful comparison, they don't strongly confirm the superiority of the approach. 
Clarity. The paper is sometimes hard to follow because some of the steps are relegated to the supplemental material or ignored altogether. For example, the authors argue repeatedly using stationary points without providing formal details. 
Originality. This is original work. 
Significance. I appreciate the idea of improving policy gradient methods by refining the step size, and doubly so by obtaining a theoretical grasp of the problem. But I think the results presented here are marginally significant. 
Suggestion. The algorithmic aspect of this work (Section 5) comes in late, and seems mostly an afterthought. I think the paper could be much improved by emphasizing the algorithm, and subsequently deriving the quantities needed in the bound. Overall, I like the approach of thoroughly studying the interplay between step size and policy performance. While the paper could be improved with clearer, more direct results, I think this is a fine, albeit incremental result for NIPS.