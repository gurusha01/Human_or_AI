Proposes a agglomerative approach to scalably clustering networks into hierarchical communities. The prior over (possibly non-binary) trees, and algorithm structure, are essentially unchanged from prior work on Bayesian rose trees [12]. The likelihood is modified in a straightforward way to handle networks, and a bit more work allows sufficient statistics to still be cached efficiently. The presentation is very clear and experiments compare favorably to a baseline model with flat community structure, but comparisons to other hierarchical network models are lacking. 
SIGNIFICANCE & RELATED WORK: 
The paper is generality well written and seems to be technically sound. The presentation in Sec. 3 is particularly dense, I wonder if there might be a simpler way of notating and explaining (9) and the parts which build on it. 
Since comparisons are limited to models that do not incorporate hierarchy in their latent structure, experiments mostly show how modeling hierarchy is beneficial for relational datasets, but not whether they are better than other hierarchical methods that currently exist. For example, there are at least two papers that model the underlying latent community structure in a hierarchical fashion. The "multiscale community blockmodel for Network exploration" (Ho et. al 2012) utilizes a nested CRP and the "Mondrian Process" (Roy et. al 2009) defines a novel stochastic process that results in hierarchical structures over K-d trees as its prior. The paper fails to mention these two Bayesian nonparametric models which potentially are capable of discovering a more refined latent structure. 
ORIGINALITY & CLARITY: 
The model considered here seems to be a Bayesian rose tree with a standard block-model likelihood. So, the innovations are all in how this new likelihood changes the way sufficient statistics are recursively updated in the greedy agglomerative clustering. The likelihood can be computed in O(Nodes + Edges) time, which is certainly a nice feature. Unfortunately a description of this is not very good - there's an allusion to dynamic programming before (10), but it's hard to understand the details. Also regarding recursive updating of sufficient statistics, there are some equations but not a lot of help in understanding why they're correct. 
TERMINOLOGY: 
It is questionable whether the "nonparametric" terminology is appropriate here - Blundell et al. [12] phrase the rose tree approach in terms of model selection, and contrast it with nonparametric methods in their discussion. I am in agreement with their interpretation. 
EXPERIMENTS: 
The qualitative experiment on Sampson is fine, and the comparison to the IRM is nice in terms of showing the benefits of averaging over many hypotheses when making predictions. Again the biggest limitation is the lack of comparison to other hierarchical network models. There is some discussion about scalability, but none of the networks tested here are especially huge. 
 Capably integrates prior work on Bayesian rose trees with stochastic block model likelihoods for networks, and generalizes efficient agglomerative clustering methods to this scenario. This allows effective hierarchical community discovery in experiments, but comparisons to other hierarchical network models are lacking.