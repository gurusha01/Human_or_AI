The paper explores theoretical issues in active sensing -- situations where people much actively gather information to achieve some goal. A extension to a previous model (C-DAC) is proposed which myopically gathers information in order to maximize a task-specific cost function. The model is compared against an alternative that favors information without respect to cost (Infomax). The overall goal of the paper is interesting and important. The novelty of the paper is somewhat reduced simply because it reports an extension to Ahmad & Yu (2013) to deal myopically with action selection. This is fine but I wondered how novel or important that aspect of the modeling actually was (e.g., it didn't seem to figure centrally into explanations of the experiment itself). 
There is some prior work on this issue. In particular, the authors might check out Markant & Gureckis, 2012 "Does the utility of information influence sampling behavior?" which explores a similar issue: whether people optimize information or some task-specific cost function. They found that information optimizing provided a better fit to people's behavior. 
The paper was poorly written overall. The abstract was much too long, the paper exceeded the 8 page limit at NIPS, and the paper cites Ahmad & Yu, 2013 in almost every sentence including twice in the abstract alone! I had a really hard time understanding the experiment design. Terms like "patch" are introduced without definition (is a patch a set of trials with a particular distribution of target probabilities, or possible target locations? I couldn't really tell). Also, while the overall theoretical issue seemed well motivated, the paper itself focused on this "confirmatory search" phenomena which the authors seemed to ad-hoc identify in their data. Why was this phenomena selected or critical for differentiating the models? 
Also, the model result for section 3 were not that compelling. The full C-DAC hits all the qualitative patterns as do the myopic one. The authors don't discuss what this means. Is it the case that the measures the authors selected here just don't tell any of the models apart very well? No fit statistics or quantification of the advantage for the more limited model is offered other than to describe is as "more psychologically plausible." Section 4 was also very opaque. I didn't understand the policy-space graphs in Figure 3 and I suspect that most readers will have significant difficulty with this as well. It is unclear what "Greedy MAP" is as well as this model is never mentioned in the paper. 
The analysis presented in Figure 4 is odd because if this is meant to be a model of humans, no mention is made of human performance. It is fine to say that the myopic C-DAC model performs well on a number of metrics, but as a model it should match human observer as well (unless this is meant as a engineering analysis of a computer vision based visual search algorithm?). 
Note My initial evaluation was a little more negative, but after discussion with the other reviewers I have given a 7. I think some of the critical comments above still apply, but there are also strengths including the emphasis on multiple model comparison, the empirical data, and the novelty of deriving theorems about the optimal stopping rule. I thought the author's response was helpful and it would be nice if the paper was edited somewhat in accordance with the reviewer questions to be more clear if it is accepted. 
 A myopic modification is added to a recent model of cost-sensitive active sensing. The model is fit to data from a visual search task, and the myopic model appears to fit the data of the experiment fairly well. However, qualitatively the full (non-myopic) model performs about the same. Other aspects of the paper were somewhat difficult to understand given what was written including the graphs of policy-space functions. Overall I think there are a lot of interesting ideas here, but the paper is not quite developed yet. The contribution beyond the original C-DAC model is unclear (outside of a vauge notion of being more psychologically plausible because it doesn't optimize multiple steps ahead into the future).