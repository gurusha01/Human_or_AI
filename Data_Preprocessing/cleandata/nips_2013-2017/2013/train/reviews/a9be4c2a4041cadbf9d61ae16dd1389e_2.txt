This paper presents a convex approach to train a two-layer model in supervised learning. This is achieved by incorporating large margin losses in the training objectives, adopting indmax transfer for the second layer and multi-label perception model with a step transfer for the first layer; finally, convex relaxations are applied that make global training of a two-layer model possible. 
The paper is well written, and the process of linking all the factors together and deriving a convex objective is interesting and insightful. The authors did a good job presenting the technical steps taken to the ultimate convex formulation, with some nice intermediate results. The global training methodology proposed in this paper is meaningful from a deep learning perspective, and experimental results are convincing to demonstrate the significance of global training. 
 The paper presents a convex approach to train a conditional two-layer model. The technical work in this paper is solid, while the conclusion is significant and insightful.