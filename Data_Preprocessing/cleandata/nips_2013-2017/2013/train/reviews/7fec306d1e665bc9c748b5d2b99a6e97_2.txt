The paper presented a reduction approach to reducing the size of deep models, in order to improve the training efficiency of deep learning. The main contribution is: (1) the exploration of prior knowledge for the redundancy of deep models, such as spatial parameter smoothness for images; (2) the use of kernel ridge regression for parameter interpolation from a subset; 
The paper is clearly written. The work seems to be original. 
The authors claimed the approach should be very general, i.e., even applicable to non-image tasks. They described some extension of the methods to handle non-image data, such as autoencoder pertaining. But in the experiments there is nothing for non-image datasets. Therefore the point is very weak. 
All the experiments on images are on pretty small datasets with simpler patterns. It's hard to believe any methods that are good for data like CIFAR will be supposed good for more realistic datasets such as ImageNet. Therefore the value of this work is not entirely convincing. 
I have read the authors' rebuttal. I don't think I would change my recommendation.  This work is novel, with some quite interesting ideas to reduce the size of deep networks. The value of the work has not been convincingly demonstrated in the experiments.