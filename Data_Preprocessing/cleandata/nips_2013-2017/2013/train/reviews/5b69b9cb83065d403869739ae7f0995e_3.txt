This paper proposes an approximate message passing algorithm for matrix factorization. After showing that the matrix factorization problem can be seen as a generalization of clustering problem, the message passing algorithm derived for matrix factorization is specialized to clustering. Lastly, experiments were conducted to compare the proposed algorithm with the k-means++ algorithm. 
Quality: Mathematical derivations in this paper are very sketchy and omits many non-trivial steps even in appendix. 
1) In line 139 of Appendix, why is the second term of (11) O(1/\sqrt(m))? \beta seems to be omitted in Section 2. 
2) Some of the analysis, including derivation of (19), seems to assume that m and n grows in the same order. After all, asymptotic analysis in this section are a bit terse and I am concerned about its mathematical rigor. 
3) In line 167, why is m \tauw^2 the expectation of A{il}^2? A is observed data, and m\tau_w^2 is only variance of the likelihood; the rational for such approximation should be verified. 
4) How would the message passing algorithm derived for finite \beta converge to the MAP problem? Message passing algorithm minimizes the KL divergence, but \lim\beta \min KL = \min \lim\beta KL does not necessarily hold. 
5) The proof of Proposition 1 is too brief for me. How is (17) derived? 
Clarity: The paper is well-structured and it is not difficult to grasp what is the main point of the paper. 
Originality: Since authors are mostly concerned about estimating first and second moments of the marginal posterior, isn't the whole algorithm just application of Expectation-Propagation (EP) to matrix factorization? EP was already used in matrix factorization in the following paper: http://research.microsoft.com/pubs/79460/www09.pdf Section 1 of Appendix seems to be standard EP updated procedures; please correct me if I am wrong. 
Also, it seems that there should be an interesting connection between the clustering algorithm proposed by authors and the clutter problem of original EP paper: http://research.microsoft.com/en-us/um/people/minka/papers/ep/minka-ep-uai.pdf , if the likelihood of clutter problem is switched to the uniform mixture of gaussian distributions. Just to clarify, in this paragraph I am just suggesting a connection and not attacking the originality of the paper. 
Significance: Authors mainly focus on its application to clustering, but considering the vast amount of literature on clustering, comparing only to k-means++ may not be sufficient to prove the practical usefulness of the algorithm.  Proofs in this paper, even in appendix, are very sketchy and thus it is hard to evaluate its technical correctness. Also, I suspect that it is an application of expectation-propagation to matrix factorization problem, which was already done by Stern et al. http://research.microsoft.com/pubs/79460/www09.pdf