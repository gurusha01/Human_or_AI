This paper describes a two-stage approach to distributed submodular maximization, known as GreeDi. Error bounds are derived for the GreeDi algorithm, which provide a theoretical guarantee on the greedy approximate solution to the centralized solution. The authors demonstrated the effectiveness on 6 data sets. 
Here are my comments. 
1. It is confusing to have kappa and k in Theorem 4.2. It is hard to distinguish them in reading. 
2. Regarding the bound in Theorem 4.2, it would be helpful to comment on the tightness. I note that there is a factor min(m,k) inside. 
3. In experiments, it would be informative to report generalized performance, such as negative log predictive probability. The decrease on objective functional is expected, while it is interesting to know how much it affect generalization. 
4. It is unclear which experiments are handling decomposable functions in Section 5. 
5. In Figure 1(e), the label on x axis should be k. 
6. In Figure 1(f), why the ratio at the smallest m starts below 1, while it starts from 1 in Figure 1(a)-1(d). 
7. How do we explain the dip when k=10 in Figure 1(c)? 
8. Adding references to Today Module of Yahoo!, that helps readers carry out related research. 
 It is an interesting study for distributed data mining.