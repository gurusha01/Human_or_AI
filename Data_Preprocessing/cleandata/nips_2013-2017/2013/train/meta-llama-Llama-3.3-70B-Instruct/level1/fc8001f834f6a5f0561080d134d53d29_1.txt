This paper presents a novel approach to approximate nearest neighbor retrieval in both metric and non-metric spaces using a VP-tree with a learned pruner. The authors propose two simple yet effective learning-to-prune methods, density estimation through sampling and "stretching" of the triangle inequality, which are evaluated on various data sets with different distance functions, including Euclidean, KL-divergence, and Itakura-Saito distance.
The paper is well-written, and the authors provide a clear and concise introduction to the problem of nearest neighbor search and the existing solutions. The proposed method is thoroughly explained, and the experimental evaluation is comprehensive, including comparisons with state-of-the-art methods such as the bbtree, multi-probe LSH, and permutation methods.
The strengths of the paper include:
* The proposed method is shown to be competitive with state-of-the-art methods in both metric and non-metric spaces, and in some cases, it provides better trade-offs between rank approximation quality and retrieval speed.
* The authors provide a thorough analysis of the applicability of their method and prove a theorem supporting its applicability to a class of non-metric distances.
* The paper includes a detailed evaluation of the proposed method on various data sets, including those with high-dimensional and low-dimensional data.
The weaknesses of the paper include:
* The proposed method is not significantly novel, as it builds upon existing work on VP-trees and learning-to-prune methods.
* The experimental evaluation could be more comprehensive, including more data sets and distance functions.
* Some of the results, such as the comparison with the bbtree, could be more thoroughly analyzed and discussed.
Arguments pro acceptance:
* The paper presents a well-written and clear introduction to the problem and the proposed method.
* The experimental evaluation is comprehensive and includes comparisons with state-of-the-art methods.
* The proposed method is shown to be competitive with state-of-the-art methods in both metric and non-metric spaces.
Arguments con acceptance:
* The proposed method is not significantly novel, and the paper could benefit from more thorough analysis and discussion of the results.
* The experimental evaluation could be more comprehensive, including more data sets and distance functions.
* Some of the results, such as the comparison with the bbtree, could be more thoroughly analyzed and discussed.
Overall, the paper is well-written, and the proposed method is shown to be competitive with state-of-the-art methods. However, the paper could benefit from more thorough analysis and discussion of the results, as well as a more comprehensive experimental evaluation. 
Quality: 8/10
The paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. However, the proposed method is not significantly novel, and the paper could benefit from more thorough analysis and discussion of the results.
Clarity: 9/10
The paper is clearly written, and the authors provide a clear and concise introduction to the problem and the proposed method. The experimental evaluation is also well-explained.
Originality: 7/10
The proposed method is not significantly novel, as it builds upon existing work on VP-trees and learning-to-prune methods. However, the paper presents a thorough analysis of the applicability of the method and proves a theorem supporting its applicability to a class of non-metric distances.
Significance: 8/10
The paper presents a competitive method for approximate nearest neighbor retrieval in both metric and non-metric spaces, which is a significant problem in various fields, including computer vision, machine learning, and data mining. However, the paper could benefit from more thorough analysis and discussion of the results, as well as a more comprehensive experimental evaluation.