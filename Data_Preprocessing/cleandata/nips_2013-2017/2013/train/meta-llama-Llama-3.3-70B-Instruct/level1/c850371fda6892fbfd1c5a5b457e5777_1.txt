This paper presents a significant contribution to the field of online learning, providing differentially private algorithms for a large class of online learning problems in both full information and bandit settings. The authors modify the popular mirror descent approach, specifically the follow-the-approximate-leader (FTAL) algorithm, to design private online learning algorithms that minimize a convex loss function.
The paper is well-structured, and the authors provide a clear overview of the problem, related work, and their contributions. The technical sections are detailed and well-explained, making it easier to follow the authors' arguments. The use of the tree-based sum protocol to maintain a differentially private running sum of gradients is a key innovation in this work.
The authors provide strong theoretical guarantees for their algorithms, including regret bounds that match the dependence on the input length T of the optimal non-private regret bounds up to logarithmic factors in T. The results are significant, as they provide the first non-private algorithms for private online learning in the bandit setting and improve over previous work in the full information setting.
The paper's strengths include:
* The authors provide a clear and concise overview of the problem and related work.
* The technical sections are well-explained, and the authors provide detailed proofs of their results.
* The use of the tree-based sum protocol is a key innovation in this work.
* The authors provide strong theoretical guarantees for their algorithms.
The paper's weaknesses include:
* The regret bounds for general convex functions have a suboptimal dependence on the parameter ε.
* The regret bounds for convex bandits are worse than the non-private bounds for linear and multi-arm bandits.
* The paper does not provide experimental results to validate the authors' theoretical claims.
Arguments for acceptance:
* The paper presents a significant contribution to the field of online learning.
* The authors provide strong theoretical guarantees for their algorithms.
* The use of the tree-based sum protocol is a key innovation in this work.
Arguments against acceptance:
* The regret bounds for general convex functions have a suboptimal dependence on the parameter ε.
* The regret bounds for convex bandits are worse than the non-private bounds for linear and multi-arm bandits.
* The paper does not provide experimental results to validate the authors' theoretical claims.
Overall, I recommend accepting this paper, as it presents a significant contribution to the field of online learning and provides strong theoretical guarantees for the authors' algorithms. However, the authors should be encouraged to address the weaknesses mentioned above in future work. 
Quality: 8/10
The paper is well-written, and the authors provide clear and concise explanations of their results. The technical sections are detailed and well-explained.
Clarity: 9/10
The paper is well-organized, and the authors provide a clear overview of the problem and related work.
Originality: 8/10
The use of the tree-based sum protocol is a key innovation in this work, and the authors provide new results for private online learning in the bandit setting.
Significance: 9/10
The paper presents a significant contribution to the field of online learning, and the authors' results have important implications for private online learning.