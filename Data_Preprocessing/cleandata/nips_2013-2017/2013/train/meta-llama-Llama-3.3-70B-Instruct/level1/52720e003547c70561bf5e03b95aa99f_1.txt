This paper presents a large-scale distributed framework for estimating sparse precision matrices using the CLIME estimator. The authors propose an inexact alternating direction method of multipliers (ADMM) algorithm for CLIME, which can scale to millions of dimensions and run on hundreds of cores. The framework solves CLIME in column-blocks, using block cyclic distribution to achieve load balancing, and establishes convergence rates for both the objective and optimality conditions.
The paper relates to previous work on sparse precision matrix estimation, including the CLIME estimator, and discusses the limitations of existing methods in terms of scalability. The authors also position their work within the context of recent efforts to scale up machine learning algorithms to "Big Data".
The strengths of the paper include:
* The proposal of a scalable and efficient algorithm for sparse precision matrix estimation, which can handle large-scale problems.
* The establishment of convergence rates for the algorithm, providing theoretical guarantees for its performance.
* The evaluation of the algorithm on both shared-memory and distributed-memory architectures, demonstrating its scalability and efficiency.
The weaknesses of the paper include:
* The assumption of a sparse precision matrix, which may not always be the case in practice.
* The use of a block cyclic distribution scheme, which may not be optimal for all problem sizes and architectures.
* The lack of comparison with other state-of-the-art methods for sparse precision matrix estimation, such as graphical lasso or sparse inverse covariance estimation.
Arguments for acceptance:
* The paper presents a significant contribution to the field of sparse precision matrix estimation, providing a scalable and efficient algorithm for large-scale problems.
* The algorithm is well-motivated and theoretically grounded, with established convergence rates.
* The experimental evaluation demonstrates the scalability and efficiency of the algorithm on both shared-memory and distributed-memory architectures.
Arguments against acceptance:
* The paper assumes a sparse precision matrix, which may not always be the case in practice.
* The comparison with other state-of-the-art methods is limited, and it is unclear how the proposed algorithm performs relative to other methods.
* The block cyclic distribution scheme may not be optimal for all problem sizes and architectures, and further evaluation is needed to determine its effectiveness.
Overall, the paper presents a significant contribution to the field of sparse precision matrix estimation, and the proposed algorithm has the potential to be widely used in practice. However, further evaluation and comparison with other state-of-the-art methods are needed to fully assess its effectiveness. 
Quality: 8/10
The paper is well-written and clearly presents the proposed algorithm and its theoretical guarantees. The experimental evaluation is thorough and demonstrates the scalability and efficiency of the algorithm.
Clarity: 9/10
The paper is well-organized and easy to follow, with clear explanations of the proposed algorithm and its components.
Originality: 8/10
The paper presents a significant contribution to the field of sparse precision matrix estimation, but the idea of using ADMM for sparse precision matrix estimation is not new.
Significance: 9/10
The paper has the potential to make a significant impact in the field of sparse precision matrix estimation, providing a scalable and efficient algorithm for large-scale problems.