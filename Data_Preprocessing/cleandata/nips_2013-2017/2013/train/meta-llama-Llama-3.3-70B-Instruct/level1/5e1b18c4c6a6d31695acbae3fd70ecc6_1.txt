This paper presents a novel unsupervised feature selection method for text data based on the principle of minimum description length and a dictionary-based compression scheme. The authors formulate document compression as a binary optimization task and develop an efficient approximate algorithm to solve it. The method is shown to reduce the feature set size by two orders of magnitude while matching the text categorization accuracy achieved in the full feature space.
The paper is well-written, and the authors provide a clear motivation for their work, relating it to previous research in feature selection and compression-based methods. The technical contributions are sound, and the optimization algorithm is well-explained. The experiments demonstrate the effectiveness of the method on two benchmark datasets, and the results are impressive, with the compressed features achieving state-of-the-art classification accuracy.
The strengths of the paper include:
* The novel application of compression-based methods to feature selection, which provides a fresh perspective on the problem.
* The development of an efficient optimization algorithm that can handle large datasets.
* The thorough experimental evaluation, which demonstrates the effectiveness of the method on different tasks and datasets.
The weaknesses of the paper include:
* The method is limited to sequential data, which may not be applicable to all types of data.
* The choice of the pointer cost parameter λ is crucial, and the authors do not provide a clear guideline for selecting its value.
* The method may not be suitable for very large datasets, as the compression scheme may become computationally expensive.
Arguments pro acceptance:
* The paper presents a novel and interesting approach to feature selection, which has the potential to impact the field.
* The technical contributions are sound, and the optimization algorithm is well-explained.
* The experimental results are impressive, and the method achieves state-of-the-art classification accuracy on two benchmark datasets.
Arguments con acceptance:
* The method is limited to sequential data, which may not be applicable to all types of data.
* The choice of the pointer cost parameter λ is crucial, and the authors do not provide a clear guideline for selecting its value.
* The method may not be suitable for very large datasets, as the compression scheme may become computationally expensive.
Overall, I believe that the paper is well-written, and the technical contributions are sound. The experimental results are impressive, and the method has the potential to impact the field. However, the limitations of the method should be carefully considered, and the authors should provide more guidance on selecting the pointer cost parameter λ. With some revisions to address these concerns, I would recommend accepting the paper.