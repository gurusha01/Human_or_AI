This paper proposes a fast algorithm for ridge regression, called Subsampled Randomized Hadamard Transform-Dual Ridge Regression (SRHT-DRR), which is designed to handle the case where the number of features is much larger than the number of observations (p >> n). The algorithm uses a Randomized Walsh-Hadamard Transform to precondition the design matrix, followed by a subsampling of features, to reduce the computational cost of the dual ridge regression solution.
The main claims of the paper are: (1) SRHT-DRR has a computational cost of O(np log(n)), which is significantly faster than the true dual ridge regression solution, which has a cost of O(n2p); and (2) SRHT-DRR only inflates the risk of the true solution by a small amount, with a risk inflation bound of (1 + ∆)^2, where ∆ = C √(k log(2k/δ)/psubs).
The paper provides a clear and well-organized presentation of the algorithm, including a detailed description of the Randomized Walsh-Hadamard Transform and its properties. The theoretical analysis of the algorithm is also well-done, with a clear presentation of the risk inflation bound and its implications.
The experimental results presented in the paper demonstrate the effectiveness of SRHT-DRR in terms of both computational cost and accuracy. The results show that SRHT-DRR achieves significant speedups over the true dual ridge regression solution, with only a small loss of accuracy. The comparison with PCA and randomized PCA is also interesting, and highlights the advantages of SRHT-DRR in terms of both speed and accuracy.
Overall, I would rate this paper as strong in terms of quality, clarity, and originality. The paper presents a novel algorithm for ridge regression that is both fast and accurate, and provides a clear and well-organized presentation of the algorithm and its theoretical analysis. The experimental results are also well-done and demonstrate the effectiveness of the algorithm.
Here are some specific strengths and weaknesses of the paper:
Strengths:
* The paper presents a novel algorithm for ridge regression that is both fast and accurate.
* The theoretical analysis of the algorithm is well-done, with a clear presentation of the risk inflation bound and its implications.
* The experimental results are well-done and demonstrate the effectiveness of the algorithm.
Weaknesses:
* The paper could benefit from a more detailed comparison with other fast algorithms for ridge regression, such as iterative methods or stochastic gradient descent.
* The paper assumes that the design matrix is full rank, which may not always be the case in practice. It would be interesting to see how the algorithm performs in cases where the design matrix is not full rank.
* The paper could benefit from a more detailed discussion of the implications of the risk inflation bound, and how it relates to the choice of the subsampling size psubs.
Arguments for acceptance:
* The paper presents a novel algorithm for ridge regression that is both fast and accurate.
* The theoretical analysis of the algorithm is well-done, with a clear presentation of the risk inflation bound and its implications.
* The experimental results are well-done and demonstrate the effectiveness of the algorithm.
Arguments against acceptance:
* The paper could benefit from a more detailed comparison with other fast algorithms for ridge regression.
* The paper assumes that the design matrix is full rank, which may not always be the case in practice.
* The paper could benefit from a more detailed discussion of the implications of the risk inflation bound, and how it relates to the choice of the subsampling size psubs.