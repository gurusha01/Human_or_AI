This paper presents a novel unsupervised feature selection method for text data based on lossless data compression. The authors propose a dictionary-based compression scheme that extracts a succinct feature set by finding a set of word k-grams that minimizes the cost of reconstructing the text losslessly. The method is formulated as a binary optimization task and solved approximately via a sequence of reweighted linear programs.
The paper's main claims are that the proposed method can reduce the feature set size by two orders of magnitude without incurring a loss of performance on text categorization tasks, and that it can expedite training times and require significantly less labeled training data. The authors demonstrate the performance of their method on two datasets, including the 20 Newsgroups dataset and a movie review dataset from IMDb.
The strengths of the paper include its clear and well-organized presentation, its thorough evaluation of the proposed method, and its comparison to existing feature selection methods. The authors also provide a detailed discussion of the limitations of their method and potential avenues for future work.
However, there are some weaknesses to the paper. One potential limitation is that the method relies on a tunable parameter, the pointer cost, which may require careful tuning for optimal performance. Additionally, the method may not be suitable for very large datasets, as the computational complexity of the optimization algorithm may become prohibitive.
Overall, the paper presents a significant contribution to the field of unsupervised feature selection for text data. The proposed method is novel, well-motivated, and thoroughly evaluated, and it has the potential to be useful in a variety of applications.
Arguments pro acceptance:
* The paper presents a novel and well-motivated method for unsupervised feature selection for text data.
* The method is thoroughly evaluated on two datasets and compared to existing feature selection methods.
* The paper provides a clear and well-organized presentation of the proposed method and its evaluation.
* The method has the potential to be useful in a variety of applications, including text categorization and exploratory data analysis.
Arguments con acceptance:
* The method relies on a tunable parameter, the pointer cost, which may require careful tuning for optimal performance.
* The method may not be suitable for very large datasets, as the computational complexity of the optimization algorithm may become prohibitive.
* The paper could benefit from additional evaluation on more datasets and comparison to more feature selection methods.
Recommendations for improvement:
* Provide additional evaluation on more datasets and comparison to more feature selection methods.
* Investigate the sensitivity of the method to the tunable parameter, the pointer cost, and provide guidance on how to choose this parameter in practice.
* Consider extending the method to handle very large datasets, potentially by using distributed computing or approximate optimization algorithms.