This paper presents a novel application of the classification-based modified policy iteration (CBMPI) algorithm to the game of Tetris, a popular benchmark for optimization techniques. The authors conjecture that Tetris is a game where good policies are easier to represent and learn than their corresponding value functions, which motivates the use of policy-space search algorithms like CBMPI. The experimental results demonstrate that CBMPI outperforms previous approximate dynamic programming (ADP) algorithms and achieves state-of-the-art results, comparable to those of the cross-entropy (CE) method, but with significantly fewer samples.
The paper is well-written, and the authors provide a clear and concise introduction to the problem, the CBMPI algorithm, and the experimental setup. The results are thoroughly discussed, and the authors provide a detailed comparison with previous work. The use of different feature sets, such as the Dellacherie-Thiery (D-T) features and the Bertsekas features, allows for a comprehensive evaluation of the algorithm's performance.
The strengths of the paper include:
* The novel application of CBMPI to Tetris, which demonstrates the algorithm's potential in complex domains.
* The thorough experimental evaluation, which provides a clear understanding of the algorithm's performance and its comparison to previous work.
* The use of different feature sets, which allows for a comprehensive evaluation of the algorithm's performance.
The weaknesses of the paper include:
* The lack of a detailed analysis of the computational complexity of CBMPI, which would provide a better understanding of the algorithm's scalability.
* The limited discussion of the hyperparameter tuning process, which is crucial for the algorithm's performance.
* The absence of a comparison with other policy-space search algorithms, which would provide a more comprehensive understanding of the algorithm's strengths and weaknesses.
Overall, the paper presents a significant contribution to the field of ADP and reinforcement learning, demonstrating the potential of policy-space search algorithms in complex domains. The results are impressive, and the paper provides a thorough evaluation of the algorithm's performance. However, some limitations and areas for future work are identified, which could further improve the paper's quality and impact.
Arguments for acceptance:
* The paper presents a novel application of CBMPI to Tetris, which demonstrates the algorithm's potential in complex domains.
* The experimental results are thorough and demonstrate the algorithm's state-of-the-art performance.
* The paper provides a clear and concise introduction to the problem, the CBMPI algorithm, and the experimental setup.
Arguments for rejection:
* The lack of a detailed analysis of the computational complexity of CBMPI, which limits the understanding of the algorithm's scalability.
* The limited discussion of the hyperparameter tuning process, which is crucial for the algorithm's performance.
* The absence of a comparison with other policy-space search algorithms, which limits the understanding of the algorithm's strengths and weaknesses.