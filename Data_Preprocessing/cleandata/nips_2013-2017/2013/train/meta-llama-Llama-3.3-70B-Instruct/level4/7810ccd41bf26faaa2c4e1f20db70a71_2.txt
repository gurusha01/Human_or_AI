The authors propose utilizing the Σ-Optimality criterion for active learning in Gauss-Markov random fields, a concept initially introduced by Garnett et al for active surveying, albeit without recognizing its submodular property at the time. 
In this framework, both labeled and unlabeled data are embedded as nodes in a graph, with edge weights calculated via a kernel to capture similarity between them. The motivation behind adopting an active learning approach stems from the potential cost associated with acquiring labels for the entire dataset, prompting the need for a criterion to selectively label the remaining unlabeled data. The authors demonstrate that the Σ-Optimality criterion satisfies the submodular monotone property, thereby ensuring that greedy selection achieves a performance guarantee of (1-1/e) relative to optimal selection. However, it is crucial to clarify that this optimality is specific to the criterion itself, rather than classification accuracy. While the empirical results exhibit promising classification performance, the criterion serves as a surrogate.
The introduction references several existing criteria, including those by Settles, Krause et al, and Ji and Han, which are compared to the proposed Σ-Optimality criterion. Nevertheless, the computational complexity of calculating the reward is only briefly discussed. For instance, both V-optimality and Σ-Optimality require computing the inverse of the graph Laplacian over the remaining unlabeled data, whereas other criteria may have lower complexity. This aspect is significant, as the problem is framed in terms of costs, and the performance of all criteria will eventually converge. A more comprehensive comparison should include the cost of computing the reward, which may potentially favor the proposed method.
The citation of Streeter and Golovin for results on submodular set functions seems misplaced, as the relevant reference should be Nemhauser et al.
Section 2.3 contains inaccuracies, as the intractability of subset selection is a consequence of combinatorics, not submodularity. Furthermore, establishing the submodular property does not necessitate a greedy solution; rather, it guarantees certain performance bounds for greedy selection relative to optimal selection.
The fact that Garnett et al initially proposed the Σ-Optimality criterion in 2012 should be acknowledged earlier in the paper, revising the abstract to reflect that the authors analyze and demonstrate the utility of a previously suggested criterion.
The establishment of the submodular property, as well as the suppressor-free properties, is noteworthy. The empirical results are sufficient to support the claims.
Overall, the paper is fairly clear, and the results are interesting, representing a contribution to the field. However, the authors should address the aforementioned comments to improve the manuscript.
Minor comments include the absence of a horizontal axis in Figure 3, which is assumed to represent the probability of correct classification, although the caption description is ambiguous. 
In essence, the authors demonstrate that a previously proposed criterion is a monotone submodular function, enabling greedy selection to achieve performance guarantees relative to optimal selection for an active learning problem, with experimental results showing superior performance compared to previously proposed criteria.