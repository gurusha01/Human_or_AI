This manuscript provides an examination of a k-nearest neighbor-based algorithm, initially proposed by Chaudhuri and Dasgupta, with a focus on its application to data residing on or near a manifold. The primary finding indicates that the convergence rate of the algorithm is influenced by the intrinsic dimension of the underlying manifold. To derive this result, the authors successfully adapt the theoretical framework established by Chaudhuri and Dasgupta to the manifold setting, leveraging sampling techniques developed by Niyogi, Smale, and Weinberger. Furthermore, for data concentrated on a manifold, they utilize tools introduced in a series of works by Rinaldi and others.
The theoretical foundations presented appear sound, yielding noteworthy results. Although the analyzed algorithm might be more suited for stratified spaces rather than manifolds, this is a relatively minor consideration. A significant drawback of the paper is that the algorithm itself is not novel, and many of the theoretical tools employed have been previously established. However, it is worth noting that this criticism is not unique to this paper and can be applied to numerous theoretical contributions in the field of NIPS. The authors contribute by providing a theoretical analysis of cluster trees on manifolds, demonstrating that the convergence rate is indeed a function of the manifold's properties.