This paper explores the automatic classification of unstructured social group activity videos by utilizing a latent topic model based on replicated softmax to extract mid-level representations. The core concept presented is the integration of sparse Bayesian learning and replicated softmax, resulting in the proposed "relevance topic model (RTM)". In RTM, discriminative topics and sparse classifier weights are learned jointly, with the authors proposing a variational EM algorithm for model parameter estimation and inference. The algorithm is tested on a benchmark dataset, demonstrating superior performance compared to other supervised topic models and baseline algorithms.
The paper is well-organized, well-motivated, and proposes ideas that are useful in related areas such as video scene analysis, classification, and recognition. It adequately cites relevant research papers. However, the significance of using sparsity on the BOW representation, classifier, and hierarchical prior on the weight is unclear. Additionally, the differences between the attributes used in previous research and the topics discovered by the proposed RTM are not well-defined. While the idea of using the Replicated softmax model for extracting latent topics is not novel, the joint learning of latent topics and classifier weights is an interesting and novel concept.
Section 3.3 contains complex mathematical equations that are challenging to follow. The experimental results demonstrate good performance of the proposed algorithm, but the experimental backup is weak due to two issues: poor generalization performance when using many instances, and limited comparison to only the baselines in previous research. To strengthen the comparison, it is suggested to include additional baseline methods where topics are extracted via previous replicated softmax models, but classifier weights are learned separately.
The key idea of joint learning of latent topics and classifier weights is interesting and has potential applications in related research fields, such as video context classification and recognition. To further highlight the strength of this concept, it is recommended to include additional baseline methods in the experiment section for comparison. Overall, the paper proposes a useful concept, but requires clarification on certain aspects and stronger experimental validation to demonstrate its effectiveness.