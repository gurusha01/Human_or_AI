Review: Variance Reduction for Stochastic Gradient Optimization
Please note that due to the large volume of papers to review and the limited time available, this assessment focuses solely on the main paper, without verifying the accuracy of the results or examining the supplementary materials in detail.
This paper introduces a novel approach to reducing the variance of gradient steps in stochastic gradient descent procedures by utilizing control variates. The method leverages structured correlation to decrease variance, differing from the averaging technique employed in minibatching. The concept is well-explained, and the paper is generally well-written. The contribution, although not entirely new, is deemed somewhat innovative and is likely to resonate with the NIPS audience.
STRENGTHS:
- Develops a unique technique to enhance the performance of SGD, distinct from minibatching, and applies it to a specific problem.
- The experiments demonstrate the effectiveness of this technique, making it a valuable addition to the existing toolkit.
WEAKNESSES:
- It is unclear how to construct control variates for other problems, limiting the approach's broader applicability.
COMMENTS: This is a well-implemented paper that addresses a significant challenge in SGD - its theoretical soundness versus practical limitations. The presentation is convincing, but some claims appear slightly exaggerated. 
One concern is the notion of novelty, as the authors acknowledge the prior use of control variates but fail to reference a relevant ICML 2012 paper by Paisley et al., which also employed control variates for variance reduction in gradient estimation. The novelty of the current approach relative to this prior work is not entirely clear.
The experimental comparisons between the proposed approach and minibatching seem somewhat arbitrary, with factors like mini-batch size (100) not being thoroughly justified. The authors' claim that "Algorithm A outperforms Algorithm B on these datasets" lacks insight into the underlying reasons, particularly given the single run with fixed learning rates. It is uncertain whether tuning the learning rates would yield different results. Instead of focusing on comparative performance, the authors should explore the potential benefits and limitations of this technique, including potential diminishing returns or practical trade-offs.
The statement "It can be shown that this simpler surrogate to the Aâˆ— due to Eq. 6 still leads to a better convergence rate" would benefit from an explicit reference to the supplementary material if a proof exists or be omitted if it does not.
It is also unclear whether this approach is applicable to subgradients or limited to proper gradients.
TYPOS/SMALL ITEMS:
- 058: "discussion on"
- before (4): clarify that $h$ can depend on $g$
ADDITIONAL COMMENTS AFTER THE REBUTTAL:
* Regarding novelty, the tone rather than the substance is the issue - using control variates to reduce variance is not a new concept. However, the current application is sufficiently distinct from the referenced ICML paper.
* Given the authors' response, I am satisfied and have adjusted my score accordingly. This paper proposes a technique using control variates to reduce the variance of gradient steps in stochastic gradient descent procedures. I believe the contribution is novel, and the NIPS audience will appreciate it.