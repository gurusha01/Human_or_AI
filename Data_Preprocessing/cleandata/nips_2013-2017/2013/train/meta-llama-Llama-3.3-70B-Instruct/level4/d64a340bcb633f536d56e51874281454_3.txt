This paper introduces a novel wrapper technique, referred to as SWAP, which can be applied to a given sparse solution to enhance the likelihood of obtaining the maximally sparse solution, as measured by the L0 norm. The method involves optimally swapping pairs of basis vectors to minimize a quadratic penalty term. The authors provide both theoretical and empirical evidence to demonstrate that SWAP is more robust to dictionary correlations, which can hinder the performance of convex L1-norm-based algorithms, such as Lasso, and greedy techniques like OMP or CoSaMP. At a high level, the key idea is that SWAP is less sensitive to correlations among dictionary columns, requiring only that the correlations among 2k or fewer columns be considered, where k is the sparsity level of the L0 solution.
One of the primary advantages of SWAP is its versatility, as it can be applied to improve the estimation quality of solutions produced by virtually any sparse estimation technique. Furthermore, under specific technical conditions related to the cardinality and support of the maximally sparse solution, SWAP may potentially recover the true support even when other algorithms fail. Although concrete examples demonstrating this are lacking, the paper is generally well-composed and thought-provoking.
However, a significant limitation of SWAP is that its formal recovery results rely on knowledge of the cardinality k of the optimal solution, which is typically unknown in practice. It is unclear how the algorithm will perform when k is not available in advance, unlike Lasso, which can provide provable recovery guarantees without explicit knowledge of k. Another potential limitation is that SWAP may not be scalable to large problem sizes due to its computational complexity, which increases cubically with the problem size, whereas other greedy algorithms scale quadratically. The convergence rate of SWAP also remains an open question. The experiments provided in the paper are limited to low sparsity levels (k = 20 or smaller), and it would be interesting to investigate SWAP's performance in more realistic, higher-dimensional settings.
The setup for the primary result, Theorem 4.1, is complex and could benefit from a more comprehensive, intuitive description. It would be helpful to provide an example dictionary that satisfies the conditions of the theorem while violating the corresponding conditions for Lasso. The experimental results section proposes a block diagonal dictionary, but it is unclear whether this dictionary satisfies the required conditions. Assuming the initial solution has more than one inactive element, there will generally be a subset of k atoms with correlated inactive elements, which raises questions about the advantage of SWAP over Lasso.
As the paper is primarily technical, with involved proof techniques, it would be helpful to provide context on which aspects of the proof resemble existing work and which are novel. While the proof techniques are similar to those developed in other statistical settings, the application to SWAP appears to be new.
Additional comments and suggestions include:
* Investigating a modified version of SWAP that searches for the best atom to add and then the best atom to delete, which could reduce computational complexity.
* Clarifying the relative vector sizes on line 221, as the current statement appears to be incorrect.
* Verifying the calculation on line 269, as a factor of 16 may be missing.
* Elucidating the claim on line 291 regarding the scaling of the number of measurements n with k and p-k, as it appears to imply that n could be smaller than k.
* Providing more details on the experimental setup, such as the assignment of active variables to blocks on line 310.
Overall, this is a solid paper presenting novel analysis of a simple algorithm, although further empirical evidence and explanations would enhance its practical value.