This manuscript presents a novel approach to learning Bayesian networks for continuous variables in high-dimensional spaces, relying on the assumption of a Gaussian distribution for each random variable conditioned on its parent nodes. To construct a sparse set of parent nodes, the authors employ a LASSO objective function, subject to the constraint that the resulting structure must form an acyclic graph. By reframing the network structure constraint as an ordering problem, the authors propose an A search algorithm that maximizes the LASSO objective function while ensuring a directed acyclic graph. The LASSO objective function, without the DAG constraint, serves as an admissible heuristic in the A search. Although this search remains computationally intensive for large graphs, the authors introduce a method to further prune the search space, enhancing efficiency.
The manuscript is well-written, providing clear motivation and sufficient implementation details. The use of the LassoScore for optimization in the dynamic programming algorithm, coupled with the unconstrained LassoScore as a heuristic function, demonstrates cleverness. Simulation studies convincingly show that the approximate algorithm outperforms traditional greedy approaches while maintaining fast runtimes, even for large networks. Performance graphs indicate that substantial pruning of the search graph results in minimal losses compared to the optimal solution.
However, the assumption of a linear Gaussian network, implied by the use of a linear regression model with fixed noise error for conditional distributions, appears to be a strong assumption. As acknowledged in the rebuttal, recovering network structure is a challenging problem, even in Gaussian networks. 
The application described in section 3.1 lacks clarity, particularly in how stock price data is represented as a Bayesian network. The use of Bayesian networks for stock market analysis is unfamiliar to this reviewer, and it is unclear what type of model is used or why stock market data would exhibit a specific network structure. Although the rebuttal addresses this concern by referencing relevant literature, these references should be incorporated into section 3.1 for improved clarity.
Overall, this is a well-crafted paper that leverages the relationship between a DAG structure and an ordering of random variable dependencies to implement a clever A* algorithm for optimizing a constrained LASSO objective function. The resulting algorithm performs efficiently and accurately, uncovering network structure in synthetic data generated from this model.