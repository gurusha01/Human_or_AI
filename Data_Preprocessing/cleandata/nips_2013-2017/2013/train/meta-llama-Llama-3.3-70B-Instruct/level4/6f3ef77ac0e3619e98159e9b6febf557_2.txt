Review- 210 - What Are the Invariant Occlusive Components of Image Patches? A Probabilistic Generative Approach 
This paper presents a nonlinear generative model for natural images, capturing translation invariance and occlusion, and demonstrates its feasibility for learning and inference. This work builds upon previous research on Occlusive Component Analysis, confirming that modeling occlusions leads to the emergence of globular receptive fields, in addition to the typical oriented, Gabor-like filters, when applied to natural image patches. 
The paper is technically rigorous, well-structured, and effectively situates the presented work within the broader context of probabilistic image models. Although the results are somewhat anticipated, given the foundation laid by previous OCA research, the technical advancements, particularly the incorporation of occlusive nonlinearity and the capacity to learn a substantially larger number of components compared to convolutional networks, are noteworthy. 
- Quality 
The proposed model extends OCA to achieve translation invariance, encompassing all possible planar translations, which renders exact inference intractable. However, the authors successfully demonstrate an efficient approximation method based on preselection, addressing this challenge. 
The analysis of natural image results is quantitative, involving the fitting of linear receptive fields to the inferred components. This analysis reveals that while a majority of the receptive fields are oriented Gabor filters, a significant proportion can be characterized as globular or possessing more complex structures. 
Two aspects of the artificial data results (Section 4) raise potential concerns. 
Firstly, in Fig. 2C, the system identifies all the true components plus an additional, unused component that resembles the globular receptive fields characteristic of this model. This raises the question of whether the model 'hallucinates' such components in simple artificial datasets lacking them. It would be beneficial to examine the appearance of artificial patches for which this "spurious" component is inferred and to investigate the proportion of globular fields that would be found if the model were trained on noise or occlusion-free natural image patches. 
Secondly, the authors mention on line 231 that repeating the learning procedure with the same configuration but different random parameter initializations results in the algorithm covering all generative components in 11 out of 20 runs. This implies that in nearly half the cases, the training converges to an incorrect solution, which is a significant concern. 
- Clarity 
The paper is well-written, organized, and provides all necessary information to comprehend the model and its results. A few minor suggestions for improvement include: 
- Correcting "access" to "assess" on Line 232.
- Verifying if "W" should be "R" on Line 319.
- Removing unused Reference 34. 
- Originality 
The primary novelty of this paper, to the best of my knowledge, lies in extending OCA to incorporate translation invariance. Although inference in this model is intractable, the authors leverage the Expectation Truncation technique to provide an efficient approximation, thereby achieving a technical advancement over other convolutional network approaches in terms of learnable components. 
- Significance 
This paper demonstrates the feasibility of efficiently training complex nonlinear generative models on natural image patches. It will be intriguing to observe whether the quantitative and qualitative improvements over existing invariant models translate into enhanced performance in perceptual tasks. 
The extension of the Occlusive Component Analysis model to include translation invariance, using a variational approximation for training on natural images, represents a step forward in the development of sophisticated generative models for complex signals, despite the results being somewhat expected and confirming previous OCA findings.