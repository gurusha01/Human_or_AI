This paper proposes a novel probabilistic sampling method for selecting entries from large matrices, deviating from traditional deterministic approaches that rely on threshold-based selection. The authors aim to find an optimal matrix B that approximates the input matrix A, with optimality defined by the loss ||B-A||. Although the approach is grounded in mathematical arguments, several aspects of the paper were unclear. The introduction, for instance, lacked clarity, with the formula in (1) not yielding a probability as it produces a score between zero and one, suggesting a potential misunderstanding. Furthermore, the specification of Bij belonging to the set (-thetai, 0, thetai) seemed incorrect, potentially requiring revision to (-1/thetai, 0, 1/theta_i). The assertion that B should be an unbiased estimator of A also lacked convincing justification. Similar mathematical inconsistencies were noted in subsequent sections, such as in Theorem 1.1, where the expected value of a matrix being zero likely should refer to the n x m zero matrix.
A significant concern lies in the motivation behind this research. The rationale provided, including the "streaming model" scenario where entries are decided upon individually, did not compellingly demonstrate why the machine learning community should prioritize sampling models for matrix data over deterministic threshold-based methods. The argument against the usefulness of deterministic approaches in Section 3's final paragraph was unconvincing. To strengthen the paper, concrete applications necessitating sampling models for matrix data should be highlighted. While the problem itself is intriguing, a more robust justification for the research is essential to demonstrate its relevance and potential impact.