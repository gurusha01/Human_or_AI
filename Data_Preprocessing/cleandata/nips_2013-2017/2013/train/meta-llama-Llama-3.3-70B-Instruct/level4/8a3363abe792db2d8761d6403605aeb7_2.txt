This paper examines the application of graph cut methods to semi-supervised classification and clustering, a dominant approach over the last decade. However, hypergraphs offer a more preferable alternative as they can capture higher-order data information more effectively than traditional graphs. While existing methods have their limitations, as outlined in Section 1, this work explores a novel approach by directly addressing hypergraph cut using the total variation of the Lovasz extension.
The paper proposes two frameworks in Sections 3 and 4 and presents an algorithm for solving the associated problems in Section 5. The experimental results in Section 6 demonstrate promise. The concept presented in this paper is intriguing, although the derivation can be challenging to follow. Without being intimately familiar with the optimization problems discussed in Sections 4 and 5, I did not delve into the technical specifics. Nonetheless, the extension in Section 3, which adapts graph Laplacian matrices for semi-supervised learning to the proposed functionals, appears natural, and the theoretical results seem accurate.
I have a couple of minor inquiries. Firstly, Definition 2.1 stipulates that \(f1 \leq \ldots \leq fn\), but it is unclear whether this constraint holds when \(f\) is treated as an optimization variable in later sections. Could the authors clarify when this condition is valid? Secondly, the experiments involve converting numerical features into categorical ones using 10 equal-sized bins, which might lead to information loss. Is this a concern?
Comment after authors' feedback
The authors have addressed my concerns regarding the experimental setup, providing clarification. The paper's exploration of hypergraph cut using the total variation of the Lovasz extension is indeed interesting, with promising experimental results.