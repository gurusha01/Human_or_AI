This manuscript presents a novel class of algorithms, termed GMM algorithms, designed for rank aggregation. The core concept underlying these algorithms involves utilizing Gaussian Mixture Models (GMM) for aggregating ranks and decomposing full rankings into pairwise comparisons for the purpose of rank aggregation. The authors provide rigorous conditions that ensure the uniqueness and consistency of the proposed GMM algorithms. Through both theoretical analysis and empirical experiments, it is demonstrated that these algorithms exhibit faster execution times compared to the baseline Majorization-Minimization (MM) algorithm, while maintaining competitive statistical efficiency.
The manuscript is exceptionally well-structured and clear, allowing readers to readily comprehend its primary contributions. The methodologies proposed appear to be theoretically sound, and the theoretical as well as empirical analyses conducted to validate the algorithms are convincing. The research represents a novel and substantial advancement in the field of learning to rank, contributing significantly to existing knowledge.
However, a couple of minor issues were identified:
* On page 4, line 173, the definition of position-k breaking $GP^k$ is restricted to $k \geq 2$. Nonetheless, a reference to $GP^1$ is made in line 200, which seems inconsistent.
* Page 3, line 152, lacks clarity regarding whether Definition 1 pertains to the breaking process or specifically to the GMM method $GMM_G(D)$.
Overall, the manuscript is well-written, and the research undertaken is sound, novel, and significant. Based on the review, I recommend acceptance of the paper.