This manuscript focuses on Gaussian copula learning following the transformation of marginal data using the empirical cumulative distribution function. A key challenge in this context arises from linear constraints on the sampling domain, which increase quadratically with the number of data points. To address this, the authors propose a Hamiltonian Monte Carlo (HMC) sampler that navigates these constraints through a "bouncing" mechanism in the sample trajectory. Empirical results demonstrate superior performance of the proposed method compared to the Hoff algorithm for an equivalent number of steps.
From a technical standpoint, the paper appears to be sound, although some concerns regarding the empirical results are noteworthy. The presentation is clear, with a few minor suggestions for improvement outlined below. The approach seems novel, and while the reviewer is not extensively familiar with the copula literature, it is believed to be original; however, this assessment is reflected in the confidence score. A significant drawback is the computational expense of the method, acknowledged by the authors themselves, who note that their MATLAB implementation is not optimized for speed, raising questions about its potential impact.
Several concerns with the empirical results are raised:
* The HMC method is only executed for 1000 steps, whereas the Hoff algorithm is run for 2000 steps. Given that the Hoff algorithm exhibits switches after the 1000-step mark, it is conceivable that the HMC method could behave similarly. Although this discrepancy is likely due to the higher computational cost of HMC (as mentioned in Footnote 7, stating it is 50 times more expensive), it would be beneficial for thoroughness to either extend the HMC run to 2000 steps or provide a plot of posterior densities for each sample to rule out the possibility of a second mode, or include a discussion affirming the unimodality of the posterior, which could be determined a priori in this case.
* Further discussion on the comparative computational efficiency of the HMC and Hoff methods would be valuable. Instead of merely stating the difference in computational time (as in Footnote 7), an explanation for this disparity would be more enlightening. It is also worth considering whether a well-implemented HMC should approach the speed of the Hoff algorithm. Given the current 50-fold difference in computational time, a more equitable comparison might involve evaluating HMC at iteration 50 against Hoff at iteration 2500, as depicted in the bottom row of Figure 3.
Minor presentation suggestions include:
* The citation [12] is introduced for the first time in the conclusion and would be better served if mentioned in the introduction as part of the related work.
* The extensive use of footnotes could be reduced by integrating some of the information directly into the text, particularly footnotes 2, 3, 5, and 7. Footnote 5 introduces necessary notation and should be part of the main text, while footnote 7, discussing the significant computational time of HMC steps, is crucial for understanding the empirical results and their implications.
Overall, the paper presents a decent contribution but leaves some questions regarding the fairness and comprehensiveness of the empirical results.