This paper presents a method for discovering latent structure in social network data by leveraging triangle count statistics, similar to the bag-of-words approach used in text analysis. The key innovation is rooted in the aMMSB model, where instead of parameterizing all interactions between communities, the authors focus on triangle configurations to identify a set of K roles, thereby reducing the number of parameters and enhancing scalability. The application of stochastic variational inference enables the derivation of both global and local updates for the proposed model.
The primary modeling contribution combines aMMSB with MMTM in a straightforward manner, although it requires meticulous bookkeeping. The presentation could be improved for better clarity. While the learning algorithm largely follows stochastic variational inference, the authors introduce an intuitive approximation for the local update rule, which is noteworthy.
Given the common occurrence of directed networks, a more detailed exploration of how these methods could be extended would be beneficial. Several concerns persist, including the comparison of the Parsimonious Triangular Model (PTM) to ERGMs, which seems misleading as ERGMs can encompass a broader range of statistics beyond triangles, and the notion of PTM as a "latent space counterpart" is unclear.
Additionally, questions arise regarding the interpretability of the inferred latent space, the distinction between Delta^1 and Delta^2, the justification for subsampling triangles, and the binary notion of "role" in the model. The choice of a .125 threshold for latent space recovery and its potential impact on results also warrants further discussion. The experiments' reliance on a specific latent space model to generate power-law networks and the claimed K^3 complexity of PTM CGS, despite arguments for O(K) parameters, require clarification.
Furthermore, the performance of the method with fewer observed edges is a concern, as the experiments only withhold 10% of the edges. The surprising outperformance of MMSB on a synthetic network generated via MMSB in Figure 1 also needs explanation. Overall, this work employs stochastic variational inference to learn a mixed-membership blockmodel with restricted parameters on triangle counts, achieving a more scalable O(NK) algorithm through its modeling choices and approximations.