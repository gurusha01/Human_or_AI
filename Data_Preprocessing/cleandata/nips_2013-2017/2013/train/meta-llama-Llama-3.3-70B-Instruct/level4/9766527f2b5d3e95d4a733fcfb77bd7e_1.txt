DETAILED COMMENTS: 
This study explores the application of control variates to mitigate the variability of stochastic gradient descent algorithms, addressing a crucial issue pertinent to all stochastic approximation methods. Although this approach has been previously investigated in the machine learning community, as seen in the work by John Paisley, David M. Blei, and Michael I. Jordan, titled "Variational Bayesian Inference with Stochastic Search" presented at the 29th International Conference on Machine Learning in 2012, the authors of this paper provide additional examples for widely used models such as Latent Dirichlet Allocation (LDA) and Non-negative Matrix Factorization (NMF). Furthermore, the paper includes experimental results in the context of logistic regression and LDA.
The concept of utilizing control variates in logistic regression and variational inference has been previously discussed in [Paisley's 2012 work], albeit with differences in application compared to this paper. It is essential for the authors to cite this prior work, clearly articulate the novel contributions of their research, and conduct a comparative analysis with the control variates selected in the aforementioned study.
In the logistic regression experiments, the comparison between variance reduction techniques and standard stochastic gradient descent (SGD) is conducted using the same fixed step size for both methods. This approach seems unreasonable, as a fair comparison should involve selecting the optimal step sizes independently for variance reduction and standard SGD.
The additional computational overhead associated with using control variates is not explicitly stated. Given the absence of a computational complexity analysis, it would be beneficial to include comparisons based on CPU time or wall-clock time to provide a more comprehensive understanding. 
This paper investigates the use of control variates to reduce the variability of stochastic gradient descent algorithms, but it is necessary to clarify the novelty of this work and justify the choice of fixed step sizes for both variance reduction and standard SGD in the logistic regression experiments.