The authors propose a novel algorithm for reconstructing matrices from noisy observations, focusing on low-rank matrices with specific factor assumptions, and leveraging an Approximate Message Passing approach to accelerate the traditionally computationally intensive Bayesian method. This work also explores the connection between matrix reconstruction and K-means clustering, presenting an intriguing application area for the suggested algorithms.
In my assessment, the application of Approximate Message Passing to matrix reconstruction appears to be innovative and noteworthy. While the relationship between low-rank matrix factorizations and K-means is relatively established, with techniques like PCA offering a factor two approximation for K-means, this connection enables the authors to conduct a comprehensive experimental evaluation. Their approach is compared to both k-means and k-means++, with empirical results indicating it is faster and more efficient. Notably, the evaluation considers both the Frobenius norm residual and the actual clusterings, enhancing the robustness of the experimental analysis.
A significant limitation of the paper is the scarcity of theoretical guarantees regarding the algorithm's convergence. This is not unexpected, given that many K-means algorithms also lack strong theoretical underpinnings. To strengthen their work, the authors could benefit from citing theoretical computer science literature that offers provably accurate algorithms for the K-means objective function. Overall, the paper presents a compelling application of Approximate Message Passing algorithms to low-rank matrix reconstruction and K-means, with promising experimental results, albeit with somewhat limited theoretical foundations.