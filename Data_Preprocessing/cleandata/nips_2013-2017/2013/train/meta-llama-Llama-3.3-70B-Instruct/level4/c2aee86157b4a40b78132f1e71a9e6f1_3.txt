Response to Author Response---
I appreciate the clarifications provided. However, I would like to highlight a few key points that require further attention:
- Although characterizing the class of problems with small optimal policy trees is an intriguing research direction, the paper could benefit from a more detailed discussion of the approach's strengths and limitations, even if a comprehensive theoretical answer is not provided. The authors likely have intuitive insights into the types of problems where this algorithm excels and those where it may struggle. Sharing these insights would significantly enhance the paper's quality.
- Regarding the comparison with DESPOT, my previous question was not only about its ability to exploit prior information but also about its requirement for such knowledge to perform well. A straightforward empirical comparison can be conducted by evaluating DESPOT with an uninformed default policy, such as a uniform random policy. This experiment would provide valuable information about the algorithm's performance in the absence of prior knowledge, regardless of the outcome. If DESPOT performs well, it would alleviate concerns about its dependence on prior knowledge. Conversely, if it performs poorly, it would highlight the types of problems where DESPOT may not be the best choice. Either way, this additional experiment would increase the paper's informative value without requiring substantial extra effort or space.
---Summary of paper---
This paper introduces an online POMDP planning algorithm that combines classical search methods and Monte Carlo sampling for action selection. The algorithm's core idea involves pre-sampling random events in the roll-out tree and computing a good policy for the determinized future, with leaf values estimated using Monte Carlo samples of a default policy. The policy search is regularized to prefer smaller policies, which fall back on the default policy after a limited number of steps. A heuristic branch-and-bound algorithm is used to prune the determinized tree, reducing the computational cost of finding a policy. Performance bounds are provided in terms of the number of samples, tree depth, and optimal policy size. Experimental results demonstrate the algorithm's strong performance in several large POMDPs compared to contemporary competing methods.
---Quality---
The analysis appears to be technically sound, with derived bounds offering insights into the algorithm's properties. Although it is unclear how much these bounds apply once DESPOT is approximated, they generally align with the provided intuitions.
One aspect that I would have liked to see more discussion on is the strengths and weaknesses of this approach, particularly in comparison to UCT-like methods (e.g., POMCP). The introduction claims that R-DESPOT exhibits better worst-case behavior, but this only holds if the optimal policy tree is small. A more in-depth discussion of the implications of a small policy and the types of problems where this is likely to occur would strengthen the paper. It is essential to understand when this assumption may not hold and how it depends on the choice of default policy, as a small policy is one that largely defers to the default policy. This raises concerns that the method's performance may rely heavily on the availability of a high-quality default policy.
Furthermore, the experiments may not provide a entirely fair comparison, as R-DESPOT is given a domain-specific default policy in each case. While the authors have attempted to keep these policies simple and intuitive, they still constitute prior knowledge not provided to other methods. This makes it challenging to determine how much of the performance gap is due to the method itself and how much is attributed to the choice of default policy. Although this does not necessarily undermine the results, it would be reasonable to claim that R-DESPOT can exploit prior knowledge that other methods cannot or that would be difficult to encode for other methods. If this is the intended claim, it should be explicitly stated and justified, at least intuitively. Even if providing comparable prior knowledge to other methods is challenging, I would have liked to see the performance of R-DESPOT with a uniform random default policy, as this would be informative about the algorithm's suitability for problems without an informed default policy.
---Clarity---
I found the paper to be clear and highly readable. The mathematics in the supplementary materials are well-presented and easy to follow.
One minor suggestion is to clarify the paragraph at the end of Section 3, which initially seemed out of place. A simple statement, such as "We will utilize this idea in the next section to develop a more practical algorithm," would help foreshadow the introduction of the R-DESPOT algorithm.
There is a typo near the bottom of page 1: "behavoior."
---Originality---
Although the method presented here builds upon existing ideas, it combines them in a novel and interesting way. The approach is well-contextualized within the relevant literature.
---Significance---
The problem of efficient planning in high-dimensional partially observable environments is both important and challenging. The algorithm presented here is grounded in theoretical performance bounds and demonstrates strong empirical performance. While I still have questions regarding the need for prior knowledge, such knowledge is available in some domains. The algorithm's potential impact lies in its representation of a viable alternative approach to UCT-like algorithms, offering a different style of analysis that may inspire further algorithmic developments in this area. The paper is clear, the problem is important, and the method is new, interesting, and reasonably well-evaluated. Therefore, I recommend accepting the paper. However, I believe that the paper could be significantly improved by including more intuitive discussions of the algorithm's strengths and weaknesses, particularly with regards to the role of prior knowledge in performance differences observed in the experiments.