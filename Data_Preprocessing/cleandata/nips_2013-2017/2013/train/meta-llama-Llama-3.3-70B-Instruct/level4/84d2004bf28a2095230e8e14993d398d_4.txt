This manuscript presents a novel approach to large-scale submodular function maximization through a distributed algorithm utilizing MapReduce. The core contribution lies in partitioning the ground set and processing subsets on individual machines, which are then merged to obtain an approximate solution. The authors provide approximation guarantees for their method and demonstrate its tightness. Additionally, they examine the algorithm's performance under specific dataset and function assumptions.
Overall, the authors tackle a highly challenging problem with significant potential for real-world applications. The experimental validation is comprehensive and thorough. It is also acknowledged that obtaining satisfactory performance guarantees without additional assumptions is inherently difficult due to the problem's complexity.
However, the theoretical analysis falls short of expectations. The guarantees appear somewhat weak, with the primary guarantee (Theorem 5.1) showing a linear factor dependence on m and k, which is discouraging. While the worst-case analysis confirms the algorithm's tightness, it is anticipated that the choice of partitions significantly impacts performance. A more detailed analysis considering the distribution of choices or heuristics for effective distribution selections would be beneficial. In comparison, a simple modular upper bound-based approximation achieves a factor k approximation, raising questions about the theoretical performance of GREEDI, especially for large m, which is of practical interest.
A critical aspect that requires clarification is the evaluation of graph-based submodular functions, which are common in practice. These functions, including graph cut-like functions and exemplar-based clustering objectives, necessitate a sum over all elements in V for evaluation, despite the smaller set under consideration. Given the large dataset motivation, where individual machines may not hold the entire dataset, it is unclear how to evaluate these functions within the proposed distributed framework without incurring significant memory issues. Potential solutions, such as evaluating the function over subsets Vi, would alter the submodular function and invalidate the guarantees. This issue warrants a detailed explanation in the rebuttal.
Minor suggestions include clarifying the proof of Theorem 4.1, particularly the tight instance, which is currently difficult to follow. Comparing GREEDI with the actual greedy algorithm on smaller datasets could provide insight into its performance relative to the best serial algorithm. Furthermore, including timing analyses and memory requirements in the experimental results would enhance the paper's completeness.
In conclusion, while the paper addresses a novel and challenging problem with potential for practical impact, its theoretical contribution is limited. The algorithm's performance and the issues surrounding graph-based submodular functions need to be more thoroughly addressed to strengthen the manuscript.