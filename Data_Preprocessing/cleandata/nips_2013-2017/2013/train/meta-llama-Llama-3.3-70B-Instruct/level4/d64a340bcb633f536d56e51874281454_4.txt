This manuscript presents a novel greedy algorithm, termed SWAP, designed for sparse recovery from correlated measurements. The algorithm operates by iteratively swapping variables until no further reduction in the loss function is achievable. The implementation of the algorithm is straightforward and easy to comprehend. Additionally, the paper provides a comprehensive theoretical analysis, which guarantees exact sparse recovery with high probability. The experimental results, conducted on both synthetic and real-world datasets, demonstrate the efficacy of the proposed algorithm.
Major Comments:
1. The manuscript claims that the proposed algorithm excels in handling measurement matrices with high correlations. However, it is unclear why this algorithm outperforms standard sparse learning algorithms in addressing sparse problems with high correlations. A more intuitive explanation is needed. Furthermore, it would be beneficial to demonstrate the advantages of the proposed algorithm in the theoretical analysis, particularly in the context of solving high-correlation sparse learning problems.
2. The theoretical analysis should be compared to other existing sparse learning algorithms with support recovery analysis to determine if any advantages exist. Specifically, it should be clarified whether the assumptions made are weaker than those in other algorithms.
3. The assumptions outlined in equations (3), (4), (7), and (8) are non-standard in the context of existing sparse learning algorithms. Providing intuitive explanations for these assumptions would be helpful, as would a comparison with commonly used assumptions in other algorithms.
4. Several existing sparse learning algorithms, such as those referenced in [1], [2], and [3], are designed to address high-correlation sparse learning problems. A comparison between the proposed algorithm and these existing algorithms would be beneficial.
5. The description of the proposed algorithm on line 104 lacks clarity. For instance, the definition of $L^{(1)}_{I,i^\prime}$ is not provided, which hinders understanding of the algorithm's operation.
References:
[1] Zou, H. and Hastie, T. Regularization and variable selection via the elastic net. Journal of the Royal Statistical Society. Series B, 67(2):301, 2005.
[2] Bondell, H.D. and Reich, B.J. Simultaneous regression shrinkage, variable selection and clustering of predictors with OSCAR. Biometrics, 64(1):115, 2008.
[3] Shen, X. and Huang, H.C. Grouping pursuit through a regularization solution surface. Journal of the American Statistical Association, 105(490):727â€“739, 2010.
This manuscript proposes a novel greedy algorithm, SWAP, for sparse recovery from correlated measurements, accompanied by a detailed theoretical analysis guaranteeing exact sparse recovery with high probability.