This paper presents a modification to random forests, replacing trees with Directed Acyclic Graphs (DAGs) to enhance memory efficiency. It introduces two methods for automatic DAG learning.
However, the overall quality of this submission falls short of the NIPS threshold. The novelty it brings to random forests is minimal, primarily limited to the substitution of DAGs for trees. The claimed advantage of DAGs in terms of memory efficiency is not adequately substantiated. 
Furthermore, the proposed technique appears to be somewhat arbitrary. Although it begins with an optimization problem outlined in equations 2-4 in Section 3, the optimization process described in Section 3.1 resorts to ad-hoc local search methods. The algorithmic descriptions in Section 3.1 are vague and lack clarity, making it doubtful that anyone could implement the algorithm based on the provided details. Additionally, there is no assurance of convergence, even to a local minimum.
The experimental results fail to convincingly demonstrate the benefits of the proposed approach. The primary claim of improved memory efficiency is not sufficiently supported, as the experiments only show a reduction in the number of nodes in the models generated. However, the number of nodes is just one factor contributing to model size; other components like splitting functions and class distributions at leaf nodes also play a role. It is unclear how the reduction in nodes translates to memory efficiency, especially considering that nodes might only account for a small percentage of the overall model size, potentially resulting in negligible memory savings. Given the decreasing cost of memory, minor reductions in memory usage (e.g., a few kilobytes) may not be significant in real-world applications.
In essence, this paper seems to offer a trivial modification of existing techniques, lacking the potential for substantial impact and falling below the standards expected for NIPS.