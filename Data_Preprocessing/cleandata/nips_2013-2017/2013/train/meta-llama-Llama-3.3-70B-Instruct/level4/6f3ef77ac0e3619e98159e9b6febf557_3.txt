This paper presents a novel generative image model that integrates low-level feature shifting and nonlinear, stochastic masking processes. The authors propose approximate inference and learning algorithms, demonstrating their effectiveness on grayscale image patches. 
The paper's clarity, organization, and readability are notable strengths. Although the concept builds upon existing ideas, such as translation invariance and occlusive image generation, the novel approximations for inferring occluding components lead to an innovative model parameter structure, comprising feature weights and mask probabilities. The results, while similar to those of previous feature learning algorithms, show promise, particularly if the model can be extended hierarchically.
However, the paper's focus is unclear: is it aimed at generating predictions and theories for biological processing or proposing new representations for computer vision? If the focus is on computer vision, the authors should compare their occlusion solution to existing models, such as max-rule feature combinations, dead leaves models, and masked RBM, and explain why translation invariance makes their model more tractable than convolutional models. 
If the goal is to provide a theoretical result for neuroscience, the authors should emphasize the model's predictions and explanations for observed properties of neurons in the visual cortex. They should address the biological plausibility of their model, particularly the assumption of complete translation invariance, and offer novel predictions or explanations to make the model useful for experimentalists. 
Additional comments include questions about the benefits of stochastic component assignment, the limitation of all-or-none feature activation, and the relationship between convolutional neural networks and approximate inference with expectation truncation. The computation of "estimated Receptive Fields" seems unnecessary, as the mask-feature product is effective for visualizing and interpreting model parameters. 
The authors' claim about complex cells being "fully translation invariant" is inaccurate, and their model units may be better represented as populations of cells in a convolutional network with replicated receptive fields. Recent methods for characterizing features encoded by translation-invariant neurons could be cited to strengthen the paper. 
The idea of building hierarchical versions of this model is intriguing, but the authors should provide more specific ideas on constructing multi-layered occlusive models and the features they will extract from natural images. The results presented are not significantly different from other learning algorithms, so demonstrating the promise of model extensions is crucial.
Minor comments include questions about image patch boundary handling, mask constraints, and the motivation for prefiltering with center-surround. A summary of the approximations required for model tractability would be helpful, as would insight into why all globular components have positive centers. Overall, the paper is well-written but describes an incremental advance, and the authors have only replicated features learned with other models, suggesting a need for further development and differentiation.