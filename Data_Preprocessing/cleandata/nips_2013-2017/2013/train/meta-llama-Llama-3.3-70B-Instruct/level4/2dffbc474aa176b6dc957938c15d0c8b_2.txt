The authors present a novel application of particle Markov chain Monte Carlo (MCMC) to Gaussian process state-space models, specifically focusing on the ancestral sampling particle Gibbs algorithm introduced by Lindsten et al. The paper is well-structured and offers an original perspective on the use of particle MCMC in this context. Furthermore, the development of model-specific methodologies, such as sparse GP-SSM, adds value to the contribution.
However, a notable omission is the lack of comparative analysis with other particle MCMC schemes, particularly the particle marginal Metropolis-Hastings (PMMH) scheme and particle Gibbs with backward sampling, as discussed in Whiteley et al. Incorporating these comparisons would be relatively straightforward and would provide valuable insights into the performance of the proposed algorithm relative to existing methods.
Moreover, the inclusion of graphical representations illustrating the algorithm's performance, such as autocorrelation function (ACF) or effective sample size (ESS) as functions of the number of particles (N) and time steps (T), would significantly enhance the interpretability of the results. As presented, the findings lack clarity on the scaling requirements for N with respect to T. It is hypothesized that for such models, PMMH may necessitate a quadratic increase in particles with T, as observed in Whiteley et al., whereas particle Gibbs methods may require a sublinear increase, highlighting the importance of such comparisons.
In summary, this is a well-crafted application of particle MCMC to GP state-space models. Nonetheless, the paper's impact could be substantially improved by incorporating comparisons with PMMH and particle Gibbs with backward sampling, which would offer a more comprehensive understanding of the proposed algorithm's efficacy and scalability.