This manuscript investigates the optimal allocation of control questions (with known answers) versus target questions (with unknown answers) in crowdsourcing for estimating continuous quantities. The authors propose two models for estimating worker parameters (bias and variance) using control questions: a two-stage estimator that relies solely on control items and a joint estimator that utilizes both control and target items to derive maximum likelihood estimates. They provide detailed derivations of the optimal number of target items (k) for each scenario, presenting their results in a clear and concise manner. The empirical evaluation of these models on synthetic and real-world data demonstrates their effectiveness in estimating the optimal k, including cases where the model is well-specified and misspecified. The authors conclude with practical recommendations for selecting between the models, offering valuable insights for practitioners.
The problem addressed in this paper is of significant importance and practical relevance, as crowdsourcing often relies on control questions to estimate bias and variance in judgments. Unlike previous theoretical work, which has largely ignored the use of control questions or assumed their absence, this study examines the value of control items and determines the optimal number to use in a given setting. As someone who has conducted numerous crowdsourced tasks and is familiar with the challenges of estimating worker parameters, I found this thorough treatment of the topic to be highly engaging and relevant.
The paper excels in its clarity, organization, and technical rigor. The writing is exceptionally clear, from the introduction and motivation to the explanation of the methodology and experimental design. The notation and development of the estimation algorithms are easy to follow, and the discussion of model mismatch and recommendations for real-world applications is insightful and practical. The experiments are well-designed and carefully executed, providing strong support for the derived estimates. I highly recommend this paper to colleagues working on crowdsourcing analysis, as well as to users of crowdsourcing platforms, as it is an outstanding contribution to the field that is likely to be well-received at the conference and widely cited in the future. Overall, this excellent paper provides a comprehensive investigation of the relative value of control items in crowdsourcing, offering a novel and highly practical perspective on a crucial aspect of estimating continuous quantities.