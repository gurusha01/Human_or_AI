This paper evaluates the performance of Classification-Based Policy Iteration (CBPI) on the Tetris benchmark problem, analyzing the impact of various parameters on its performance. The results show that Direct Policy Iteration (DPI) performs similarly to the cross-entropy method and CBPI, which is not surprising due to similarities in policy representation and optimization. The analysis convincingly shows that standard Tetris features are not suitable for representing value functions optimized by approximate policy iteration, but fails to identify why or how to design better features.
The paper lacks comparison with other algorithms that compute approximate value functions differently, such as Smoothed Approximate Linear Programming, which limits the importance and implications of the results. The evaluation of major algorithms on Tetris is thorough, but the paper lacks additional insights into the reasons for the difference in solution quality, limiting the applicability of the results to other domains.
In terms of quality, the paper is technically sound, and the claims are well-supported by experimental results. However, the paper presents no new technical results, which is a significant limitation. The paper is clearly written, well-organized, and adequately informs the reader. The results are important, and the paper addresses a difficult problem in a better way than previous research. However, the paper does not advance the state of the art in a demonstrable way, as the results are largely incremental.
The strengths of the paper include a thorough evaluation of CBPI on Tetris, a clear and well-organized presentation, and important results. The weaknesses include the lack of new technical results, limited comparison with other algorithms, and limited insights into the reasons for the difference in solution quality.
Arguments for acceptance:
* The paper presents a thorough evaluation of CBPI on Tetris, which is a significant contribution to the field.
* The results are important, and the paper addresses a difficult problem in a better way than previous research.
* The paper is clearly written, well-organized, and adequately informs the reader.
Arguments against acceptance:
* The paper presents no new technical results, which is a significant limitation.
* The paper lacks comparison with other algorithms that compute approximate value functions differently.
* The paper lacks additional insights into the reasons for the difference in solution quality, limiting the applicability of the results to other domains.
Overall, I would recommend accepting the paper, but with revisions to address the limitations mentioned above. The paper has significant strengths, but also significant weaknesses that need to be addressed to make the paper more impactful.