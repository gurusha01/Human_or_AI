This paper proposes a novel approach to improve the efficiency of Gibbs sampling in Markov random fields (MRFs) by projecting the input model onto a set of fast-mixing models. The success of inference by Gibbs sampling in MRFs depends on the mixing rate of the underlying Monte Carlo Markov chain, and the authors aim to accelerate this process by projecting the input model onto a set of models with bounded spectral norm of the matrix of absolute values of Ising edge strengths.
The proposed approach involves projecting the input model onto a set of models with bounded spectral norm, and then performing inference on the obtained model. The projection is defined by divergences of Gibbs distribution, and is forced to preserve the graph structure. The authors consider four different divergences, including Euclidean distance, KL, piecewise KL, and reversed KL divergences, and provide algorithms for each of them.
The experimental results show that the proposed methods outperform other methods, including loopy BP, TRW, MF, and Gibbs sampling on the original model, in terms of accuracy and runtime-vs-accuracy evaluation. The authors also find that the proposed method with reversed KL divergence performs consistently best.
The paper is well-written, and the authors provide a clear and concise explanation of the proposed approach and its theoretical foundations. The experimental results are extensive and demonstrate the effectiveness of the proposed methods. However, there are some minor errors and areas for improvement. For example, the authors could provide more details on the stopping criteria for the inner iterations of the projected gradient algorithm, and consider experimental comparison with larger models.
Overall, the paper makes a significant contribution to the field of approximate inference in MRFs, and the proposed approach has the potential to improve the efficiency of Gibbs sampling in a wide range of applications. The strengths of the paper include its originality, technical soundness, and clarity of presentation. The weaknesses include some minor errors and areas for improvement, such as the lack of reported runtime for some algorithms and the need for more detailed analysis of the experimental results.
Arguments pro acceptance:
* The paper proposes a novel and original approach to improve the efficiency of Gibbs sampling in MRFs.
* The theoretical foundations of the proposed approach are sound and well-explained.
* The experimental results are extensive and demonstrate the effectiveness of the proposed methods.
* The paper is well-written and easy to follow.
Arguments con acceptance:
* There are some minor errors and areas for improvement, such as the lack of reported runtime for some algorithms.
* The authors could provide more details on the stopping criteria for the inner iterations of the projected gradient algorithm.
* The experimental comparison with larger models is limited, and more extensive experiments would be beneficial to demonstrate the scalability of the proposed approach.