This paper presents a distributed optimization algorithm called Distributed Stochastic Dual Coordinate Ascent (DisDCA) for solving regularized loss minimization problems in a distributed framework. The algorithm is shown to have strong convergence guarantees and is empirically competitive with well-tuned ADMM implementations. The paper is well-written and technically sound, with a notable section on the tradeoffs between computation and communication in distributed learning.
The DisDCA algorithm is a distributed implementation of stochastic dual coordinate ascent, which has been shown to have better convergence properties than stochastic gradient descent in some cases. The algorithm is designed to work in a star network, where each machine updates its local dual variables and then communicates with the other machines to update the global primal variable. The paper provides a convergence analysis of the algorithm, which shows that it has a strong guarantee of convergence rates for smooth and non-smooth loss functions.
One of the key strengths of the paper is its analysis of the tradeoff between computation and communication in distributed learning. The authors show that increasing the number of samples per iteration can reduce the number of iterations required for convergence, but may also increase the computation cost per iteration. Similarly, increasing the number of machines can reduce the computation cost per iteration, but may also increase the communication cost. The authors provide a detailed analysis of this tradeoff and show that there is an effective region of the number of samples and machines where the communication cost can be reduced by increasing the number of samples and the computation cost can be reduced by increasing the number of machines.
The paper also presents a practical variant of DisDCA, which uses an incremental update of the dual variables and a local copy of the primal variable on each machine. The authors show that this variant has substantial improvements over the basic variant and other variants, and is empirically competitive with well-tuned ADMM implementations.
The experiments in the paper demonstrate the effectiveness of DisDCA in optimizing SVMs on large datasets. The authors compare DisDCA with SGD-based and ADMM-based distributed algorithms and show that it is a strong competitor in terms of convergence rate and running time.
Overall, the paper is well-written and technically sound, and presents a significant contribution to the field of distributed optimization. The analysis of the tradeoff between computation and communication is particularly noteworthy, and the practical variant of DisDCA is a useful contribution to the field.
Arguments for acceptance:
* The paper presents a significant contribution to the field of distributed optimization.
* The analysis of the tradeoff between computation and communication is thorough and well-presented.
* The practical variant of DisDCA is a useful contribution to the field.
* The experiments demonstrate the effectiveness of DisDCA in optimizing SVMs on large datasets.
Arguments against acceptance:
* The paper could benefit from more detailed comparisons with other distributed optimization algorithms.
* The analysis of the tradeoff between computation and communication could be more extensive.
* The paper could benefit from more discussion of the implications of the results for practice.
However, overall, the paper is well-written and technically sound, and presents a significant contribution to the field of distributed optimization. Therefore, I recommend acceptance.