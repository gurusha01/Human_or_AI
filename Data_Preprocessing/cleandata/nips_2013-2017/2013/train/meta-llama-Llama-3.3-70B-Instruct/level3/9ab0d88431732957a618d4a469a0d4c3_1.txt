This paper proposes a novel approach to online POMDP planning, called DESPOT, which constructs a sparse tree of scenarios to balance the trade-off between exploration and exploitation. The authors also introduce R-DESPOT, a regularization-based algorithm that searches the DESPOT for a near-optimal policy, and its anytime approximation, AR-DESPOT. The paper provides theoretical analysis and experimental results, demonstrating the effectiveness of the proposed approach.
The strengths of the paper include its well-written and clear presentation, as well as its ability to tackle large POMDPs. The experimental results show that AR-DESPOT outperforms two of the fastest online POMDP planning algorithms, AEMS2 and POMCP, on several domains, including a very large one with approximately 10^56 states. The paper also provides a thorough discussion of related work and a clear explanation of the algorithms.
However, there are some weaknesses and areas for improvement. The experimental evaluation in Section 6 is limited, and the choice of alpha parameter is crucial but not properly explored. The upper bound assumption in the paper may not be valid in practice, particularly when dealing with arbitrary outliers. Additionally, the discussion on related works is limited, and the authors could explore other approaches to robustness, such as using mixture models with explicit outlier components or Bayesian priors.
Arguments for acceptance:
* The paper proposes a novel and effective approach to online POMDP planning, which can tackle large POMDPs.
* The experimental results demonstrate the effectiveness of the proposed approach, outperforming two of the fastest online POMDP planning algorithms.
* The paper provides a thorough discussion of related work and a clear explanation of the algorithms.
Arguments against acceptance:
* The experimental evaluation is limited, and more extensive experiments are needed to fully demonstrate the effectiveness of the proposed approach.
* The choice of alpha parameter is crucial but not properly explored, and more analysis is needed to understand its impact on the algorithm's performance.
* The upper bound assumption may not be valid in practice, and more robust methods for handling outliers should be explored.
Overall, the paper presents a significant contribution to the field of online POMDP planning, and with some revisions to address the weaknesses, it has the potential to be a strong paper.