This paper presents a distributed stochastic dual coordinate ascent (DisDCA) algorithm for solving regularized loss minimization problems in a distributed framework. The algorithm is designed to take advantage of the computational power of multiple machines or cores to optimize the problem in a parallel fashion. The authors provide a convergence bound for the algorithm and analyze the tradeoff between computation and communication.
The paper's main contributions include the development of the DisDCA algorithm, which possesses two key characteristics: parallel computation over multiple machines and sequential updating of dual variables per iteration on individual machines followed by a "reduce" step for communication among processes. The authors also provide a practical variant of the algorithm, which leverages the up-to-date information for updating the dual variables, and compare it with the basic variant and other distributed algorithms, such as stochastic gradient descent (SGD) and alternating direction methods of multipliers (ADMM).
The paper's strengths include its clear and well-organized presentation, as well as its thorough analysis of the tradeoff between computation and communication. The authors provide a rigorous convergence bound for the algorithm and demonstrate its effectiveness through experiments on large datasets. The paper also provides a comparison with other distributed algorithms, which shows that DisDCA is a strong competitor in optimizing support vector machines (SVMs).
However, the paper also has some weaknesses. One of the main limitations is that the algorithm's performance is sensitive to the choice of the number of samples (m) and the number of machines (K). The authors provide some guidance on how to choose these parameters, but it is not clear how to optimize them in practice. Additionally, the paper assumes that the data is distributed evenly across the machines, which may not always be the case in practice.
In terms of originality, the paper presents a novel combination of familiar techniques, including stochastic dual coordinate ascent and distributed optimization. The authors also provide a new perspective on the tradeoff between computation and communication, which is an important consideration in distributed optimization.
The significance of the paper lies in its potential to improve the scalability and efficiency of machine learning algorithms in distributed environments. The DisDCA algorithm has the potential to be applied to a wide range of machine learning problems, including SVMs, logistic regression, and others. The paper's results also provide insights into the tradeoff between computation and communication, which can inform the design of future distributed optimization algorithms.
Overall, I would recommend accepting this paper for publication. The paper presents a well-organized and clearly written presentation of a novel distributed optimization algorithm, along with a thorough analysis of its convergence and tradeoff between computation and communication. The paper's results demonstrate the effectiveness of the algorithm and provide insights into its potential applications.
Arguments pro acceptance:
* The paper presents a novel distributed optimization algorithm with a rigorous convergence bound.
* The algorithm has the potential to improve the scalability and efficiency of machine learning algorithms in distributed environments.
* The paper provides a thorough analysis of the tradeoff between computation and communication.
* The results demonstrate the effectiveness of the algorithm and provide insights into its potential applications.
Arguments con acceptance:
* The algorithm's performance is sensitive to the choice of parameters (m and K).
* The paper assumes that the data is distributed evenly across the machines, which may not always be the case in practice.
* The paper could benefit from more extensive experiments and comparisons with other distributed algorithms.