This paper explores the tradeoff between deep and flat hierarchies in classification, where deep hierarchies may propagate errors, while flat hierarchies have harder decisions with higher cardinality. The authors introduce a data-dependent generalization error bound for kernel-based hypotheses, which provides an explanation for several empirical results related to the performance of flat and hierarchical classifiers. The bound suggests that hierarchical classifiers are well-suited for unbalanced, large-scale taxonomies, while flat classifiers are preferred for well-balanced taxonomies.
The paper also proposes a strategy to prune hierarchical classifiers based on the generalization bound, using a meta-classifier to decide which nodes to prune. However, the methodology using a meta-classifier is unclear and lacks motivation. The experimental results demonstrate the effectiveness of the proposed pruning strategy, which leads to statistically significant better results compared to both the original taxonomy and a randomly pruned one.
The strengths of the paper include its well-written theoretical analysis, which provides a clear explanation for the performance of flat and hierarchical classification strategies in large-scale taxonomies. The introduction of a data-dependent generalization error bound for multiclass, hierarchical classifiers is a significant contribution to the literature. The paper also provides a thorough experimental evaluation, which demonstrates the effectiveness of the proposed pruning strategy.
However, the paper falls short in providing practical procedures for improving hierarchical classification. The methodology using a meta-classifier is unclear, and the authors could provide more motivation and explanation for this approach. Additionally, the paper could benefit from more discussion on the implications of the theoretical results and how they can be applied in practice.
Overall, the paper is well-written, and the theoretical analysis is sound. However, the paper could be improved by providing more clarity on the methodology and more discussion on the practical implications of the results.
Arguments pro acceptance:
* The paper provides a clear explanation for the performance of flat and hierarchical classification strategies in large-scale taxonomies.
* The introduction of a data-dependent generalization error bound for multiclass, hierarchical classifiers is a significant contribution to the literature.
* The experimental results demonstrate the effectiveness of the proposed pruning strategy.
Arguments con acceptance:
* The methodology using a meta-classifier is unclear and lacks motivation.
* The paper falls short in providing practical procedures for improving hierarchical classification.
* The paper could benefit from more discussion on the implications of the theoretical results and how they can be applied in practice.
Recommendation: Accept with minor revisions. The authors should provide more clarity on the methodology using a meta-classifier and provide more discussion on the practical implications of the results. Additionally, the authors could provide more motivation for the proposed pruning strategy and discuss its limitations and potential applications.