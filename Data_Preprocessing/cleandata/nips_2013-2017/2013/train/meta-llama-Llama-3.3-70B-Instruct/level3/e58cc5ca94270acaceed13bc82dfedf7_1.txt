This paper proposes a method for completing an n-by-m matrix M with rank r by utilizing side information matrices A and B to estimate a low-dimensional matrix Z. The authors prove that using side information matrices can significantly reduce the number of entries needed to complete M, especially when the dimensions of A and B are much smaller than M. The proposed method is compared to previous works on matrix completion with side information, and its advantage over one of the previous methods is demonstrated.
The paper provides a nice sample complexity analysis and promising experimental results to support the proposed method. However, a limitation of the paper is that the assumption of having side information matrices is strong, which may not always be the case in practice. Nevertheless, the paper does provide an example where this assumption is appropriate.
In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The paper is clearly written, well-organized, and adequately informs the reader. The authors are careful and honest about evaluating both the strengths and weaknesses of the work.
The originality of the paper lies in its ability to establish a linear convergence rate for the proximal gradient method (PGM) for solving a class of trace norm-regularized problems without requiring strong convexity of the objective function. The paper also provides a new Lipschitzian error bound for trace norm-regularized problems, which could be of independent interest.
The significance of the paper is that it addresses a difficult problem in a better way than previous research. The results have the potential to be used by other researchers and practitioners in the field of machine learning, and the paper provides a unique theoretical and pragmatic approach to matrix completion.
Arguments for acceptance:
* The paper proposes a novel method for matrix completion with side information and provides a thorough analysis of its performance.
* The paper establishes a linear convergence rate for the PGM for solving a class of trace norm-regularized problems without requiring strong convexity of the objective function.
* The paper provides a new Lipschitzian error bound for trace norm-regularized problems, which could be of independent interest.
* The experimental results demonstrate the effectiveness of the proposed method.
Arguments against acceptance:
* The assumption of having side information matrices is strong and may not always be the case in practice.
* The paper could benefit from more extensive experimental results to further demonstrate the effectiveness of the proposed method.
* The paper may not be of interest to researchers outside of the machine learning community.