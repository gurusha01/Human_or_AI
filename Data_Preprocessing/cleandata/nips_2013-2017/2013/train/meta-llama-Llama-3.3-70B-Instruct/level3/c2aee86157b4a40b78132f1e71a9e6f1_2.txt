This paper proposes a novel approach to online POMDP planning, called Determinized Sparse Partially Observable Tree (DESPOT), which compactly captures the execution of all policies under a set of sampled scenarios. The authors also introduce Regularized DESPOT (R-DESPOT), an algorithm that searches for a policy balancing size and accuracy, and its anytime approximation, Anytime Regularized DESPOT (AR-DESPOT). The paper provides theoretical analysis and experimental results showing that AR-DESPOT outperforms two of the fastest online POMDP planning algorithms, AEMS2 and POMCP, and scales up better to large POMDPs.
The strengths of the paper include its technically sound and well-executed approach, which provides a novel solution to the online POMDP planning problem. The authors provide a clear and detailed explanation of the DESPOT and R-DESPOT algorithms, as well as a thorough analysis of their theoretical properties. The experimental results are also impressive, demonstrating the effectiveness of AR-DESPOT in various domains, including Tag, LaserTag, RockSample, and Pocman.
However, there are some weaknesses and limitations to the paper. The approach is considered incremental, and its impact may be limited. The reliance on tree search is sensitive to the branching factor, which is not theoretically or experimentally considered. The importance of the initial lower bound is also unclear. Additionally, the paper lacks clarity in its representation, such as in Table 1, and raises questions about the meaning of a "simple policy" and what to do if one does not exist.
Arguments for acceptance include:
* The paper provides a novel and technically sound approach to online POMDP planning.
* The experimental results demonstrate the effectiveness of AR-DESPOT in various domains.
* The paper provides a clear and detailed explanation of the DESPOT and R-DESPOT algorithms.
Arguments against acceptance include:
* The approach is considered incremental, and its impact may be limited.
* The reliance on tree search is sensitive to the branching factor, which is not theoretically or experimentally considered.
* The paper lacks clarity in its representation, and raises questions about the meaning of a "simple policy" and what to do if one does not exist.
Overall, the paper is well-written and provides a significant contribution to the field of online POMDP planning. However, the limitations and weaknesses of the approach should be carefully considered, and the authors should be encouraged to address these issues in future work.