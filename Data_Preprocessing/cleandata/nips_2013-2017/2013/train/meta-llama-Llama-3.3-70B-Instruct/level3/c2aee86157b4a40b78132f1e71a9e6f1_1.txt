This paper presents a new online approach for solving Partially Observable Markov Decision Processes (POMDPs) called Regularized DESPOT (R-DESPOT), which builds on state-of-the-art methods like POMCP and AEMS2. The core idea of R-DESPOT is to control complexity using constraints on policy size, which has potential for major impact on solving large POMDPs. The paper includes empirical results comparing R-DESPOT with other recent POMDP methods, as well as a new LaserTag domain that could be reused by other researchers.
The paper is well-written in parts, but lacks technical detail in others, including clarification of differences between DESPOT and R-DESPOT, and summary of key differences between POMCP and DESPOT. The review raises questions about the empirical results, including what aspects of the proposed framework have the most impact in practice and why certain comparisons were not made. For example, the use of outdated results for AEMS2 and the lack of comparison with AEMS2 using particle filtering belief representation are concerning.
The paper presents a key new insight of pruning the forward search tree using regularization of the policy size, which is interesting and has potential for major impact. However, the review requests more information on technical details, such as the PRUNE function, parameter selection, and time constraint imposition. The experiments show strong results, but the review expresses concerns about the limitations of the results and discussion, making it difficult to assess the work's impact.
Overall, the paper has potential, but lacks technical detail and has limitations in results and discussion. The strengths of the paper include its novel approach to online POMDP planning, its ability to scale up to large state spaces, and its strong empirical results. The weaknesses include the lack of technical detail, the limitations of the empirical results, and the need for more comparison with other state-of-the-art methods.
Arguments pro acceptance:
* The paper presents a novel approach to online POMDP planning that has potential for major impact.
* The paper includes strong empirical results that demonstrate the effectiveness of the proposed method.
* The paper is well-written in parts and provides a clear overview of the proposed method.
Arguments con acceptance:
* The paper lacks technical detail in some areas, which makes it difficult to understand the proposed method.
* The empirical results are limited and do not provide a comprehensive comparison with other state-of-the-art methods.
* The paper does not provide enough information on the parameter selection and time constraint imposition, which are crucial for the proposed method.
In terms of quality, the paper is technically sound, but the claims are not well-supported by theoretical analysis or experimental results in some areas. The paper is a complete piece of work, but it is not clear if the authors are careful and honest about evaluating both the strengths and weaknesses of the work. In terms of clarity, the paper is well-organized, but it lacks technical detail in some areas, which makes it difficult to understand the proposed method. In terms of originality, the paper presents a novel approach to online POMDP planning, but it is not clear how this work differs from previous contributions. In terms of significance, the paper has potential for major impact, but the results are limited and do not provide a comprehensive comparison with other state-of-the-art methods.