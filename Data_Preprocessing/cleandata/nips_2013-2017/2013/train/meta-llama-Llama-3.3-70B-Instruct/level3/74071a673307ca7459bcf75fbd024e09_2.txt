This paper presents a thorough analysis of the achievable regret trade-offs in the context of online learning with expert advice, specifically for the absolute loss game with two experts. The authors provide an exact characterization of the set of realizable trade-offs, which is a convex polygon, and exhibit the optimal strategy witnessing each Pareto optimal trade-off. They also study the asymptotic regret rate trade-off profile and show that the expected trade-off is achievable but not tight.
The paper's primary contributions, Theorems 6 and 8, provide tight minimax characterizations of the achievable trade-offs for the two-expert case. Theorem 6 characterizes the Pareto frontier of the set of realizable trade-offs for a given horizon T, while Theorem 8 characterizes the asymptotic Pareto frontier as T tends to infinity. The authors also provide a randomized procedure for optimal play that extends the randomized procedures for balanced regret profiles from previous work.
The paper's strengths include its thorough analysis of the two-expert case, its clear and well-organized presentation, and its provision of a randomized procedure for optimal play. The authors also provide a detailed discussion of the related work and clearly motivate their contributions.
However, the paper's limitations include its restriction to the two-expert case, which may not be of greater practical interest. The authors acknowledge this limitation and suggest that extending their results to the general case of K > 2 experts is a major next step. Additionally, the paper's Section 5.2, which attempts to recover standard sqrt(T log K) bounds from the K=2 algorithm, is unclear in its purpose and usefulness.
In terms of quality, the paper is technically sound, and the authors provide a clear and detailed proof of their main results. The paper is also well-written, and the authors provide a clear and concise introduction to the problem and its motivation.
In terms of originality, the paper presents a novel analysis of the achievable regret trade-offs in the context of online learning with expert advice. The authors' use of a randomized procedure for optimal play and their characterization of the asymptotic Pareto frontier are also novel contributions.
In terms of significance, the paper's results have implications for the design of online learning algorithms that can provide asymmetric regret guarantees. The authors' characterization of the achievable trade-offs and their provision of a randomized procedure for optimal play can inform the development of such algorithms.
Overall, I would recommend accepting this paper for publication, as it presents a thorough and novel analysis of the achievable regret trade-offs in the context of online learning with expert advice. However, I would suggest that the authors clarify the purpose and usefulness of Section 5.2 and provide more discussion of the potential extensions of their results to the general case of K > 2 experts.
Arguments pro acceptance:
* The paper presents a thorough and novel analysis of the achievable regret trade-offs in the context of online learning with expert advice.
* The authors provide a clear and well-organized presentation of their results.
* The paper is technically sound, and the authors provide a clear and detailed proof of their main results.
* The authors' use of a randomized procedure for optimal play and their characterization of the asymptotic Pareto frontier are novel contributions.
Arguments con acceptance:
* The paper's restriction to the two-expert case may limit its practical interest.
* Section 5.2 is unclear in its purpose and usefulness.
* The paper could benefit from more discussion of the potential extensions of the results to the general case of K > 2 experts.