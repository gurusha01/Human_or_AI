The paper addresses the challenging problem of support recovery in high-dimensional linear regression, particularly in scenarios where the measurement matrix exhibits high correlations among columns. The authors propose a novel greedy algorithm, SWAP, which iteratively swaps variables between the estimated support and its complement to minimize the least-squares loss while maintaining a fixed sparsity level. This approach is theoretically analyzed, and the authors provide conditions under which SWAP achieves accurate support recovery, demonstrating that it requires milder assumptions compared to traditional methods relying on the irrepresentability condition. The paper also includes numerical experiments on synthetic and genomic datasets to showcase SWAP's practical benefits.
Strengths:
1. Theoretical Contributions: The paper provides rigorous theoretical guarantees for SWAP, including iteration bounds and conditions for accurate support recovery. The analysis highlights SWAP's ability to tolerate higher correlations in the measurement matrix compared to existing methods.
2. Algorithm Simplicity: SWAP is computationally straightforward and can be used as a wrapper around existing sparse recovery algorithms, enhancing their performance without significant overhead.
3. Clarity and Accessibility: The paper is well-written, with clear motivations, detailed explanations of the algorithm, and minimal technical complexity, making it accessible to a broad audience.
4. Empirical Performance: Numerical results demonstrate that SWAP consistently outperforms state-of-the-art algorithms in terms of support recovery accuracy, particularly in highly correlated settings.
Weaknesses:
1. Experimental Design: Fixing the support size to the true value in synthetic experiments introduces potential bias, and the paper does not adequately address how the sparsity level \(k\) should be selected in real-world applications.
2. Algorithm Complexity: While the algorithm is conceptually simple, the computational cost of rank-k projection matrices and the number of iterations required for convergence are not fully analyzed. This could become prohibitive when the initial support contains many false positives.
3. Performance Metrics: The absence of false positive rate (FPR) as an evaluation metric limits the ability to fully assess SWAP's performance, particularly in synthetic experiments.
4. Loss Function for Genomic Data: Using the least-squares loss for binary response data in genomic experiments is questionable, as it may not align with the classification nature of the task.
5. Comparative Analysis: The paper does not compare SWAP to other methods specifically designed for correlated predictors, such as elastic-net or Trace-Lasso, which are widely used in practice.
Pro and Con Arguments for Acceptance:
- Pro: The paper makes a significant theoretical contribution by relaxing assumptions required for support recovery and provides a simple, effective algorithm that enhances existing methods.
- Con: The experimental design and lack of comparisons to other correlated predictor methods leave gaps in the empirical validation of SWAP's advantages.
Overall Assessment:
The paper presents a theoretically sound and practically promising algorithm for sparse recovery in high-dimensional settings with correlated predictors. However, concerns about the experimental design, practical applicability, and lack of comprehensive comparisons to state-of-the-art methods reduce its impact. If these issues are addressed in a revised version, the paper could make a valuable contribution to the field.