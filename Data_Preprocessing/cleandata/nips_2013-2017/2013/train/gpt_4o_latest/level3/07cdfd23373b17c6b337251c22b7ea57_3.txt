The paper presents a scalable approximate inference algorithm for the "triangle model" of networks, termed the Parsimonious Triangular Model (PTM). By leveraging parameter sharing and stochastic variational inference, the authors achieve significant scalability, analyzing networks with over a million nodes and hundreds of latent roles on a single machine within hours. The work builds on the bag-of-triangles representation of networks and introduces a parsimonious statistical model with O(K) parameters, enabling efficient inference with O(NK) complexity. The authors demonstrate competitive or improved accuracy for latent space recovery and link prediction compared to state-of-the-art methods, while being orders of magnitude faster.
Strengths:  
The paper is well-written, clearly organized, and addresses a critical challenge in network analysis: scalability. The proposed PTM model is both innovative and practical, reducing the parameter space from O(KÂ³) in prior models to O(K), which is a significant contribution. The use of stochastic variational inference for efficient optimization is well-motivated and experimentally validated. The experiments are comprehensive, covering synthetic and real-world networks, and the results convincingly demonstrate the method's scalability and accuracy. The ability to process million-node networks in hours is a notable achievement, and the comparison to existing methods highlights the advantages of the proposed approach.
Weaknesses:  
1. The term "parsimonious modeling" is not standard in probabilistic modeling contexts and should be clarified or replaced with a more precise term.  
2. The introduction's claim that down-sampling zeros compromises accuracy is misleading, as Gopalan et al. suggest otherwise. This statement should be revised for accuracy.  
3. The defense of the triangle model by analogy to Latent Dirichlet Allocation (LDA) is inappropriate, as LDA generates valid documents, whereas the triangle model does not always produce valid networks. This analogy should be reconsidered.  
4. The method for generating power-law networks in the latent space is vague and requires further elaboration.  
5. The paper lacks a direct comparison to Gopalan et al.'s algorithm, which would provide a more comprehensive evaluation. Including such a comparison would strengthen the experimental section.  
6. Minor edits are needed: "mixture-membership" should be corrected to "mixed-membership," and the last sentence on page 8 should be removed for a stronger conclusion. Additionally, the JMLR version of "Stochastic Variational Inference" should be cited in the bibliography.
Pro and Con Arguments for Acceptance:  
Pro:  
- The paper addresses a significant scalability challenge in network analysis.  
- The proposed model and inference algorithm are novel and technically sound.  
- Experimental results are compelling, demonstrating both scalability and accuracy.  
- The writing is clear and well-structured, making the contributions accessible.  
Con:  
- Some claims in the introduction are misleading or inadequately supported.  
- The analogy to LDA is inappropriate and detracts from the argument.  
- The lack of a direct comparison to Gopalan et al.'s algorithm is a notable omission.  
Recommendation:  
I recommend acceptance, contingent on addressing the identified weaknesses. The paper makes a valuable contribution to scalable network modeling, and its strengths outweigh the weaknesses. However, the authors should revise the introduction, clarify key terms, and include a comparison to Gopalan et al.'s algorithm to strengthen the paper further.