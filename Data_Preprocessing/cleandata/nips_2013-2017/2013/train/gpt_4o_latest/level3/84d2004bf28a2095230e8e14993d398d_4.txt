The paper presents a novel distributed algorithm, GREEDI, for submodular function maximization under cardinality constraints in a MapReduce framework. This is a significant contribution to addressing the computational challenges posed by large-scale datasets, where centralized approaches are infeasible. The authors provide theoretical analysis, experimental validation, and practical applications, making the work relevant to both researchers and practitioners in machine learning and distributed computing.
Strengths:
1. Novelty and Practical Relevance: The introduction of GREEDI is a meaningful advancement in distributed submodular optimization. The algorithm is simple, communication-efficient, and well-suited for MapReduce-style computations, addressing a critical bottleneck in large-scale machine learning tasks.
2. Experimental Validation: The experimental section is thorough, demonstrating the effectiveness of GREEDI on real-world applications such as exemplar-based clustering and active set selection in Gaussian processes. The scalability of the algorithm is convincingly shown through large-scale experiments using Hadoop.
3. Potential Impact: The paper addresses an important and challenging problem with clear real-world applications, such as clustering and active learning, which makes the contribution significant.
Weaknesses:
1. Weak Theoretical Guarantees: The theoretical analysis of GREEDI's performance is limited. The approximation guarantees depend heavily on the number of partitions (m) and the cardinality constraint (k), which may result in suboptimal performance in certain scenarios. This dependency is discouraging, and stronger theoretical bounds would enhance the paper's impact.
2. Partition Dependence: The algorithm's performance is highly sensitive to the choice of partitions, yet the paper does not provide guidance or heuristics for effective partitioning. This is a critical omission, as poor partitioning could degrade performance.
3. Graph-Based Submodular Functions: The paper lacks clarity on handling graph-based submodular functions, especially when datasets exceed memory limits. This is a significant limitation, as graph-based problems are common in large-scale machine learning.
4. Critical Issue with Submodular Function Alteration: The evaluation of graph-based objectives on subsets could alter the submodular function, potentially invalidating guarantees. This issue is not adequately addressed and requires further clarification.
5. Proof Clarity: The proof of Theorem 4.1 is difficult to follow and could benefit from better exposition and simplification.
6. Comparison with Serial Greedy Algorithm: A direct comparison between GREEDI and the serial greedy algorithm on smaller datasets is missing, which would provide a clearer understanding of the trade-offs in performance and scalability.
7. Timing and Memory Analysis: The experimental results lack detailed analysis of timing and memory requirements, which are critical for evaluating the practical feasibility of the algorithm.
Pro and Con Arguments for Acceptance:
- Pro: The paper addresses a novel and important problem, introduces a practical algorithm with potential real-world applications, and provides extensive experimental validation.
- Con: The theoretical contributions are limited, and critical issues such as partition dependence and graph-based submodular functions are not adequately addressed.
Recommendation: While the paper makes a meaningful contribution to distributed submodular optimization, the weaknesses in theoretical guarantees and clarity, as well as the lack of guidance on practical implementation details, are significant. I recommend acceptance only if the authors address the critical issues, particularly partition dependence, submodular function alteration, and proof clarity, in a revised version.