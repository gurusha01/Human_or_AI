The paper investigates the performance of classification-based policy iteration (CBPI) on the Tetris benchmark, focusing on parameter analysis rather than introducing new technical innovations. It provides a thorough comparison of CBPI with the cross-entropy (CE) method and direct policy iteration (DPI), demonstrating that CBPI achieves state-of-the-art results in Tetris, particularly excelling in sample efficiency. However, the study is limited in scope and leaves several important questions unanswered.
Strengths:
1. Thorough Evaluation: The experimental setup is robust, with detailed comparisons across multiple algorithms (CBPI, DPI, CE, and Î»-PI) and parameter configurations. The authors convincingly demonstrate CBPI's superiority in sample efficiency, achieving comparable or better performance than CE with significantly fewer samples.
2. Significant Results: CBPI achieves the best-reported performance in Tetris, setting a new benchmark of 51 million lines on the large board. This is a notable contribution to the field, as Tetris has historically been challenging for approximate dynamic programming (ADP) methods.
3. Insight into Policy vs. Value Function Representation: The study highlights that Tetris policies are easier to represent and optimize than value functions, reinforcing the importance of policy-based approaches in certain domains.
Weaknesses:
1. Lack of Generalizability: The analysis is confined to Tetris and does not explore other algorithms that compute value functions differently, such as Smoothed Approximate Linear Programming, which has shown promise on this benchmark. This omission limits the broader applicability of the findings.
2. Feature Analysis is Incomplete: While the paper identifies that standard Tetris features (e.g., Bertsekas features) are unsuitable for value function optimization, it fails to explain why or propose alternative feature sets. This leaves a critical gap in understanding the underlying dynamics of feature suitability.
3. No Theoretical Insights: The paper does not provide theoretical explanations for the observed performance differences between CBPI, DPI, and CE. This limits the contribution to empirical observations without advancing the theoretical understanding of these methods.
4. Missed Opportunities for Comparison: The omission of Smoothed Approximate Linear Programming and other advanced ADP methods in the experimental comparison is a notable oversight, as it could have provided a more comprehensive evaluation.
Arguments for Acceptance:
- The paper sets a new performance benchmark for Tetris, which is a significant achievement.
- The results are well-supported by extensive experiments and provide valuable insights into the advantages of policy-based methods over value function-based approaches.
- The work is relevant to the NIPS community, as it addresses a challenging benchmark and contributes to the understanding of ADP algorithms.
Arguments Against Acceptance:
- The lack of theoretical insights and incomplete feature analysis reduce the scientific depth of the paper.
- The limited scope of the study, focusing solely on Tetris and excluding other promising algorithms, restricts its broader impact.
- The paper does not advance the state of the art in algorithm design, as it primarily evaluates existing methods.
Recommendation:
While the paper provides significant empirical results and a thorough evaluation of CBPI on Tetris, its lack of theoretical contributions and limited generalizability are notable weaknesses. I recommend acceptance with revisions, emphasizing the need for a deeper analysis of feature suitability and a broader comparison with other ADP methods.