This paper presents a novel approach to learning and inference in nonlinear generative models for natural images, with explicit modeling of translation invariance and occlusion. Building on Occlusive Component Analysis (OCA), the authors extend the framework to include nonlinear feature superposition and efficient inference through Expectation Truncation (ET). The model demonstrates its ability to learn both Gabor-like and globular receptive fields (RFs), offering insights into the neural encoding of images in the primary visual cortex. The work is contextualized within probabilistic models of images and compared to convolutional neural networks (CNNs), highlighting its advantages in handling occlusions and achieving higher overcompleteness.
Strengths:
1. Technical Soundness: The paper is technically robust, with well-supported theoretical analysis and experimental results. The use of ET for efficient inference in an otherwise intractable model is particularly noteworthy.
2. Novelty: The extension of OCA to include translation invariance and nonlinear feature superposition is a clear contribution. The emergence of globular RFs alongside Gabor-like filters is a novel finding, aligning with biological observations.
3. Significance: The model's ability to handle occlusions and learn a large number of components surpasses traditional CNNs. This has implications for perceptual tasks and advances the state of the art in generative modeling.
4. Clarity: The paper is well-organized and provides sufficient detail for reproducibility, although minor issues like typos and unused references should be addressed.
Weaknesses:
1. Artificial Data Concerns: The model occasionally "hallucinates" extra components in artificial datasets, raising questions about its reliability. Additionally, repetitive training runs show variability in recovering all generative components, indicating sensitivity to initialization.
2. Limited Biological Plausibility: While the model aligns with some biological findings, its lack of direct correspondence to simple cell responses in V1 may limit its interpretability in a biological context.
3. Computational Complexity: Although ET makes the model tractable, the approach remains computationally intensive, particularly for scaling to larger datasets or incorporating additional transformations.
Arguments for Acceptance:
- The paper addresses a challenging and significant problem in generative modeling, offering a novel solution with clear advantages over existing methods.
- The emergence of globular RFs provides a compelling link to biological vision, which may inspire further research.
- The technical rigor and clarity of the work make it a valuable contribution to the field.
Arguments Against Acceptance:
- The variability in training outcomes and issues with artificial data reliability raise concerns about the robustness of the approach.
- The computational demands of the model may limit its practical applicability in large-scale settings.
Recommendation:
Overall, this paper makes a strong scientific contribution, with clear novelty and significance. Despite some concerns about robustness and scalability, the work is well-executed and provides valuable insights into nonlinear generative modeling. I recommend acceptance, with minor revisions to address the noted weaknesses.