This paper proposes a novel approach to reduce the number of free parameters in neural networks by leveraging redundancy in learned parameters. Specifically, it introduces a method where a subset of parameters is learned, and the remaining parameters are predicted via interpolation using kernel ridge regression. The method assumes a low-rank decomposition of the weight matrix, with one matrix constrained using prior knowledge (e.g., pixel correlation) and the other learned dynamically. The authors demonstrate the effectiveness of this approach across multiple architectures (MLP, CNN, RICA) and datasets (MNIST, CIFAR-10, STL-10), showing that up to 95% of parameters can be predicted without performance degradation in some cases.
Strengths:
1. Novelty and Originality: The paper presents a unique approach to parameter reduction, which differs from traditional weight factorization methods by explicitly incorporating prior knowledge into the parameterization process. This is a fresh perspective on addressing redundancy in neural networks.
2. Empirical Validation: The method is evaluated on diverse architectures and datasets, demonstrating its applicability to both fully connected and convolutional networks. The results on MNIST and CIFAR-10 are particularly promising, showing significant parameter savings without accuracy loss.
3. Potential Impact: The proposed technique could have practical implications for reducing computational and memory costs in large-scale neural networks, particularly in distributed training scenarios.
4. Interpretability: The connection between the proposed method and pooling operations, as well as its interpretation as a linear transformation, provides a clear conceptual understanding of the approach.
Weaknesses:
1. Experimental Scope: The evaluation is heavily focused on vision datasets and moderately sized networks. The lack of experiments on non-vision datasets (e.g., text or time-series data) limits the generalizability of the findings.
2. Kernel Evaluation: The proposed data-dependent kernel is only evaluated on a single dataset/architecture, and no comparisons are made to alternative kernels or random baselines. This weakens the claim of its general utility.
3. Robustness Concerns: The method shows a significant performance drop when predicting 50% of parameters in convolutional networks, raising questions about its robustness in deeper architectures.
4. Practical Impact: While the method demonstrates parameter reduction, it does not achieve state-of-the-art performance on any benchmark, nor does it explore its utility in training larger networks.
5. Hyperparameter Optimization: The paper lacks clarity on how hyperparameters, such as the subset of learned parameters or kernel length scales, are optimized, which could affect reproducibility.
6. Dataset-Specific Performance: The reduced parameterization shows strong results on CIFAR-10 but minimal impact on STL-10, suggesting that the method's effectiveness may be dataset-dependent.
Arguments for Acceptance:
- The paper introduces a novel and conceptually interesting approach to parameter reduction.
- It demonstrates promising results on standard datasets, showing potential for practical applications.
- The method is orthogonal to existing techniques like dropout and maxout, making it complementary to other advances in deep learning.
Arguments Against Acceptance:
- The experimental evaluation is limited in scope, with insufficient exploration of non-vision tasks and larger networks.
- The robustness and generalizability of the method are questionable, given the performance drop in certain cases and the dataset-specific results.
- The empirical evaluation of the kernel design is incomplete, and comparisons to alternative methods are missing.
Recommendation:
While the paper makes a valuable contribution by introducing a novel parameter reduction technique, its limitations in experimental scope, robustness, and practical impact suggest that it is not yet ready for acceptance at a top-tier conference like NeurIPS. The authors are encouraged to address these issues in future work by expanding the evaluation to non-vision datasets, exploring larger architectures, and providing stronger comparisons to state-of-the-art methods.