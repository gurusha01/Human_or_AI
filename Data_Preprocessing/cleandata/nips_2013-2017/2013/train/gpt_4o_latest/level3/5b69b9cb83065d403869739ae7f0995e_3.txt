The paper introduces an Approximate Message Passing (AMP) algorithm for low-rank matrix factorization and extends it to clustering, comparing its performance to k-means++. The authors frame matrix reconstruction in a Bayesian context, leveraging structural properties like sparsity, and propose an AMP-based approach to solve both the marginalization and Maximum A Posteriori (MAP) problems. A key contribution is the application of this AMP algorithm to clustering, reformulating the clustering task as a low-rank matrix reconstruction problem. Experimental results demonstrate that the proposed AMP-based clustering algorithm outperforms Lloyd's k-means and k-means++ in terms of K-means loss and accuracy, especially for high-dimensional data.
Strengths:
1. Clarity and Structure: The paper is well-organized, with a clear exposition of the problem, methodology, and experimental results. The connection between low-rank matrix factorization and clustering is effectively articulated.
2. Novelty in Application: While AMP algorithms have been explored in matrix factorization, their application to clustering with explicit constraints on cluster assignments is a novel contribution.
3. Experimental Validation: The authors provide comprehensive numerical experiments on both synthetic and real datasets, showing that the proposed AMP algorithm consistently outperforms k-means++ in terms of clustering accuracy and K-means loss.
4. Efficiency: The AMP algorithm demonstrates fast convergence, with computational complexity linear in the matrix size, making it scalable to large datasets.
Weaknesses:
1. Mathematical Rigor: The mathematical derivations are incomplete in several places, raising concerns about the theoretical soundness of the proposed algorithm. For example, the justification for the second term in Equation (11) being \(O(1/\sqrt{m})\) is missing, and the assumptions about \(m\) and \(n\) growing in the same order are not clearly stated.
2. Proofs and Convergence: The proof of Proposition 1 is overly brief, particularly the derivation of Equation (17), and the convergence of the AMP algorithm to the MAP solution for finite \(\beta\) is not rigorously addressed.
3. Limited Comparisons: The experimental comparisons are restricted to k-means++ and Lloyd's k-means, which are relatively simple clustering algorithms. Given the extensive clustering literature, comparisons with more advanced methods (e.g., spectral clustering, Gaussian Mixture Models) would strengthen the paper.
4. Originality Concerns: The AMP algorithm appears to be a direct application of Expectation-Propagation (EP) principles, and the novelty of the algorithm itself is limited. The authors should clarify how their approach differs from existing EP-based methods for matrix factorization.
5. Connection to Prior Work: The potential link between the proposed clustering algorithm and the clutter problem in EP literature is not explored in depth. This connection could provide additional theoretical insights.
Recommendation:
While the paper presents an interesting application of AMP to clustering and demonstrates promising empirical results, the lack of mathematical rigor and limited experimental comparisons weaken its overall contribution. The paper would benefit from addressing the specific theoretical gaps, expanding comparisons to more sophisticated clustering methods, and clarifying its novelty relative to prior work. If these concerns are addressed, the paper could make a valuable contribution to the field. For now, I recommend a weak reject. 
Pros for Acceptance:
- Novel application of AMP to clustering with explicit constraints.
- Strong empirical performance on synthetic and real datasets.
- Clear and well-structured presentation.
Cons for Acceptance:
- Incomplete mathematical derivations and proofs.
- Limited experimental comparisons with advanced clustering methods.
- Ambiguity in the originality of the algorithm relative to prior work.