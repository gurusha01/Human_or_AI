This paper presents a novel approach to approximate inference in continuous-time Gaussian Markov process models, leveraging expectation-propagation (EP) to achieve significant computational efficiency. The authors extend the classical Kalman-Bucy smoothing framework to handle non-Gaussian observations, enabling inference in models with both discrete and continuous-time likelihoods. The proposed method demonstrates substantial speedup over traditional sampling-based approaches, such as Monte Carlo methods, while maintaining reasonable accuracy. The paper is technically solid, clearly written, and well-organized, making it accessible to readers familiar with the field.
Strengths:  
The originality of the paper is noteworthy, as it addresses a gap in the literature by developing an EP-based algorithm for continuous-time inference. The authors' derivation of fixed-point update equations and their hybrid algorithm combining EP and variational updates is both elegant and practical. The method's ability to handle continuous-time likelihoods, such as those arising in spiking neuronal models and point processes, is a significant contribution. Experimental results, including applications to neural spike train data and log Gaussian Cox processes, demonstrate the method's computational efficiency and robustness. The inclusion of post-inference correction methods further enhances the accuracy of the marginal approximations. The paper's clarity and detailed supplementary material ensure reproducibility, which is commendable.
Weaknesses:  
While the paper is technically sound, the experimental evaluation could be more comprehensive. The authors primarily focus on specific applications, such as neural data and point processes, but broader testing on high-frequency financial data or other benchmarks would strengthen the paper's claims of general applicability. Additionally, while the method achieves reasonable accuracy, the paper does not thoroughly compare its performance against state-of-the-art methods beyond Monte Carlo sampling. This limits the ability to assess its competitiveness in terms of accuracy. Finally, the reviewer suggests exploring the linearization of the loss function using extended Kalman-Bucy methods, which could potentially improve the algorithm's performance further.
Arguments for Acceptance:  
1. The paper addresses a challenging and relevant problem in continuous-time inference, contributing a novel and efficient solution.  
2. The proposed method achieves significant computational speedup, which is crucial for real-world applications involving large datasets.  
3. The paper is well-written, technically rigorous, and includes sufficient details for reproducibility.  
Arguments Against Acceptance:  
1. The experimental evaluation lacks breadth, with limited testing on diverse datasets and benchmarks.  
2. The paper does not fully explore potential improvements, such as incorporating extended Kalman-Bucy methods.  
3. Limited comparison with other state-of-the-art methods restricts the ability to evaluate its overall impact.  
Conclusion:  
Overall, this paper makes a valuable contribution to the field of approximate inference in continuous-time stochastic processes. While there are areas for improvement, particularly in experimental validation and comparative analysis, the method's originality and computational efficiency warrant its acceptance. The reviewer recommends acceptance with minor revisions to address the experimental and methodological gaps.