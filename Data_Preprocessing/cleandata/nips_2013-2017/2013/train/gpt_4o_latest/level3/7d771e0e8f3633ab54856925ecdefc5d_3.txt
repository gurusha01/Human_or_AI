This paper introduces a novel pruning technique to enable symbolic Modified Policy Iteration (MPI) in Markov Decision Processes (MDPs) with large factored action spaces. The authors propose Opportunistic Policy Iteration (OPI), a new algorithm that balances between value iteration (VI) and MPI by selectively applying policy constraints only when they do not increase the size of the value function representation. This approach addresses the scalability challenges of symbolic planning in exponentially large state and action spaces, a significant bottleneck in prior work. The paper also introduces a memory-bounded version of OPI, allowing a tradeoff between memory usage and computation time. Empirical results demonstrate that OPI significantly outperforms state-of-the-art symbolic planners in terms of scalability and convergence speed.
Strengths:
1. Motivation and Novelty: The paper is well-motivated, addressing a critical scalability issue in symbolic planning for factored-action MDPs. The introduction of OPI as a middle ground between VI and MPI is novel and provides a fresh interpretation of MPI.
2. Experimental Validation: The experiments are thorough, covering multiple domains (Inventory Control, SysAdmin, and Elevator Control) with varying complexities. Results convincingly show that OPI improves convergence, avoids memory issues faced by FA-MPI, and scales better with increasing action space sizes.
3. Practical Impact: The pruning technique and memory-bounded OPI provide practical tools for tackling previously intractable problems, making the work significant for both researchers and practitioners in symbolic planning and decision-making under uncertainty.
4. Theoretical Contributions: The authors provide theoretical guarantees for OPI's convergence and its ability to maintain compact representations, supported by Theorem 1 and Proposition 2.
Weaknesses:
1. Clarity and Notation: The paper suffers from inconsistent and unclear notation, particularly in the explanation of Theorem 1. The distinction between \(\hat{T}^Q\pi\) and \(T^Q\pi\), as well as the necessity of repeated pruning, is not adequately explained, making it difficult for readers to follow the technical details.
2. Proposition 2: While the pruning procedure is central to the paper, Proposition 2 is somewhat trivial and lacks a clear guarantee on the extent of tree size reduction. This limits the theoretical rigor of the pruning approach.
3. Representation Limitations: The paper acknowledges that the ADD representation is less effective for certain domains, as evidenced by the limited compression ratio for value functions in the Uniring domain. This suggests that the scalability of the approach may be domain-dependent.
4. Writing and Organization: While the high-level ideas are clear, the paper could benefit from improved organization and more detailed explanations in the technical sections. Suggestions include clarifying the pseudocode and providing more intuitive examples for key concepts like pruning.
Recommendation:
Despite the noted weaknesses, I recommend this paper for acceptance. Its contributions are significant, addressing a critical bottleneck in symbolic planning for factored-action MDPs. The experimental results are compelling, and the proposed techniques advance the state of the art in a meaningful way. However, the authors should address the clarity issues, particularly in the theoretical sections, to make the work more accessible to a broader audience.
Arguments for Acceptance:
- Novel and well-motivated pruning technique with practical and theoretical contributions.
- Strong experimental validation demonstrating scalability and convergence improvements.
- Advances the state of the art in symbolic planning for factored-action MDPs.
Arguments Against Acceptance:
- Inconsistent and unclear notation, particularly in Theorem 1.
- Proposition 2 lacks depth and guarantees on pruning efficacy.
- Limited effectiveness of the ADD representation in certain domains.
Overall, the strengths outweigh the weaknesses, and the paper makes a valuable contribution to the field.