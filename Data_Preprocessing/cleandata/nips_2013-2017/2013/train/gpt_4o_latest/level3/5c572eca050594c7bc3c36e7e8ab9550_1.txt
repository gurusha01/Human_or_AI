The paper proposes a novel approach to density ratio estimation by reformulating it as a Fredholm integral equation and solving it using Tikhonov regularization within the Reproducing Kernel Hilbert Space (RKHS) framework. The resulting algorithm, FIRE (Fredholm Inverse Regularized Estimator), is theoretically analyzed and experimentally validated. The authors also introduce a novel unsupervised model selection method, CD-CV (Cross-Density Cross-Validation), and demonstrate its application in various settings, including covariate shift and importance sampling. This work builds on and extends prior research in density ratio estimation, such as Kernel Mean Matching (KMM) and Least Squares Importance Sampling (LSIF), by providing a more principled and flexible framework.
Strengths:
1. Novelty and Importance: Reformulating density ratio estimation as a Fredholm integral equation is a novel and theoretically grounded contribution. This approach connects classical operator theory with modern machine learning, offering new perspectives on density ratio estimation.
2. Theoretical Rigor: The paper provides detailed theoretical analysis, including concentration bounds and convergence rates for Gaussian kernels in both Euclidean and manifold settings. This adds significant value to the work.
3. Practical Contributions: The FIRE algorithm is simple, flexible, and computationally efficient. The introduction of CD-CV for unsupervised parameter selection addresses a critical challenge in semi-supervised learning.
4. Experimental Validation: The authors compare FIRE with existing methods like LSIF and TIKDE on multiple datasets and demonstrate strong empirical performance.
Weaknesses:
1. Missing Proofs and References: While the theoretical results are promising, the proofs are relegated to supplementary material and were not verified by the reviewer. Additionally, some mathematical statements lack references or detailed justification.
2. Clarity and Accessibility: The paper assumes familiarity with advanced concepts like Tikhonov regularization and Fredholm integral equations. A brief explanation of these concepts would improve accessibility for a broader audience.
3. Comparative Analysis: The performance comparison with other methods, including minimax bounds, is insufficiently detailed. The paper should clarify why the naive plug-in approach is inferior to FIRE.
4. Practical Demonstrations: The lack of experiments on toy problems with known densities (p and q) makes it difficult to assess the method's accuracy in controlled settings.
5. Dataset References: The datasets used (CPUsmall, Kin8nm, USPS) are not adequately referenced, which limits reproducibility.
Recommendation:
The paper addresses an important problem with a novel and theoretically sound approach. However, it requires improvements in clarity, comparative analysis, and practical demonstrations. I recommend acceptance, provided the authors address the following:
1. Add missing proofs or references for mathematical claims.
2. Include a brief explanation of Tikhonov regularization and Fredholm integral equations for accessibility.
3. Clarify the limitations of the naive plug-in approach and expand on the comparative performance analysis.
4. Demonstrate the method on toy problems with known densities.
5. Provide references for the datasets used.
Arguments for Acceptance:
- Novel and theoretically grounded approach.
- Strong empirical results and practical utility.
- Addresses a significant challenge in semi-supervised learning.
Arguments Against Acceptance:
- Missing proofs and insufficient comparative analysis.
- Lack of clarity and accessibility for non-expert readers.
- Limited practical demonstrations on controlled problems.
Overall, this paper is a promising contribution to the field and aligns well with the conference's focus on advancing the state of the art in machine learning.