The paper presents an active learning framework for structured output spaces, leveraging local marginal entropies for query selection. This approach builds upon prior work [28] and addresses the underexplored problem of active learning in structured spaces, which is particularly relevant for vision tasks. The authors demonstrate their method on the task of 3D room layout prediction, achieving state-of-the-art performance while labeling only ~10% of the random variables. The proposed algorithms, including "separate active" and "joint active," balance computational efficiency and accuracy, with the latter exploiting unlabeled data during learning. The paper also explores batch active learning and strategies for reusing computation to improve efficiency.
Strengths:
1. Relevance and Contribution: Active learning for structured output spaces is a challenging and underexplored problem, and the paper makes a meaningful contribution by proposing efficient algorithms that reduce labeling effort significantly. The focus on local marginals as a surrogate for uncertainty is intuitive and well-motivated.
2. Technical Soundness: The proposed methods are technically sound, with clear derivations and integration into structured prediction frameworks. The use of local entropies for query selection is both novel and computationally practical.
3. Experimental Results: The experiments convincingly demonstrate the effectiveness of the approach, achieving competitive performance with minimal labeling. The comparison between "separate" and "joint" active learning algorithms, as well as the exploration of batch learning, adds depth to the evaluation.
4. Efficiency: The paper addresses computational challenges by reusing computations and warm-starting optimization, which is a practical contribution for real-world applications.
Weaknesses:
1. Limited Scope of Experiments: The experiments are restricted to 3D room layout prediction, which limits the generalizability of the results. Broader evaluations on tasks like scene labeling or human pose estimation would significantly enhance the paper's impact.
2. Baseline Comparisons: The experimental baselines are primarily ablative, and the paper lacks comparisons with related methods such as [7] and [33]. A detailed discussion of differences and advantages over these methods is necessary.
3. Clarity Issues in Section 2.2: Section 2.2 is dense and difficult to follow, which may hinder understanding for readers unfamiliar with the technical background. Reducing the length of the related work section and focusing on clarifying this section would improve readability.
4. Lack of Qualitative Results: The paper does not include qualitative results, such as visualizations of the active learning process or the impact of labeled variables. These would provide intuitive insights into the approach's effectiveness.
5. Missing Citation: The paper should cite Siddiquie et al. (CVPR 2010), which also addresses active learning in structured output spaces using contextual interactions.
Recommendation:
While the paper is not entirely novel, it makes meaningful contributions to active learning for structured prediction, a challenging and impactful area. The technical rigor and promising results warrant acceptance, provided the authors address the identified weaknesses. Specifically, adding broader experiments, comparisons with related methods, and qualitative results would strengthen the paper significantly.
Arguments for Acceptance:
- Addresses a relevant and underexplored problem.
- Proposes technically sound and efficient algorithms.
- Demonstrates significant reduction in labeling effort with competitive performance.
Arguments Against Acceptance:
- Limited experimental scope reduces generalizability.
- Insufficient comparisons with related work.
- Clarity issues in key sections and lack of qualitative results.
Overall, I recommend acceptance with minor revisions to address the identified weaknesses.