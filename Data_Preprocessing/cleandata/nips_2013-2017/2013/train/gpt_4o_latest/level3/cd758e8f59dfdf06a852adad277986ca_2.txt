This paper addresses the problem of estimating the cluster tree of a density supported on or near a low-dimensional manifold embedded in high-dimensional space. By extending the robust single linkage (RSL) algorithm of Chaudhuri and Dasgupta (2010), the authors achieve convergence rates that depend only on the intrinsic manifold dimension \(d\), rather than the ambient dimension \(D\). This is a significant contribution to high-dimensional clustering, as it mitigates the curse of dimensionality under the manifold hypothesis. The paper also sketches a lower bound for the sample complexity of RSL algorithms and extends the analysis to noisy settings, including clutter and additive noise.
Strengths:
1. Significance: The paper tackles a critical problem in high-dimensional data analysis, offering theoretical guarantees for clustering on manifolds. The independence of rates from \(D\) is a notable advancement, aligning with the manifold hypothesis and making the results relevant for practical applications in machine learning and data science.
2. Technical Rigor: The proofs, though closely following prior work, are adapted to the manifold setting, addressing challenges such as curvature and condition numbers. The extension to noisy data further strengthens the paper's applicability.
3. Clarity of Results: The authors provide explicit sample complexity bounds and discuss the dependence on parameters like \(\rho\), \(\tau\), and \(\epsilon\), which are central to understanding the algorithm's performance.
Weaknesses:
1. Lack of Emphasis on Key Insight: The main insight—achieving rates dependent on \(d\) rather than \(D\)—is not sufficiently emphasized or intuitively explained. A more detailed discussion of why this occurs and its implications would enhance the paper's impact.
2. Similarity to Prior Work: While the adaptation to manifolds is non-trivial, the proof structure heavily mirrors Chaudhuri and Dasgupta (2010). This makes it difficult to discern the novel contributions without careful scrutiny.
3. Ambiguity in Definitions: The definition of the "class of RSL algorithms" is vague, potentially confusing readers about the scope of the lower bound results.
4. Limited Examples: The absence of a simple synthetic example illustrating the phenomenon of \(d\)-dependent rates limits accessibility for readers unfamiliar with the technical details.
5. Parameter Discussion: The role of \(\rho\) is underexplored, and its connection to the main results could be clarified further.
Pro and Con Arguments for Acceptance:
- Pro: The paper makes a significant theoretical contribution by extending RSL to manifold-supported densities, achieving dimension-independent rates. The results are well-grounded in theory and extend to noisy settings, broadening their applicability.
- Con: The lack of intuitive explanations, reliance on prior proof structures, and insufficient examples reduce the accessibility and perceived novelty of the work.
Suggestions for Improvement:
1. Provide an intuitive explanation of why the rates depend on \(d\) rather than \(D\), possibly with a visual or synthetic example.
2. Clarify the definition of the "class of RSL algorithms" and its implications for the lower bound.
3. Expand the discussion on \(\rho\) to better connect it to the main results.
4. Highlight the novelty of the manifold extension more explicitly in the introduction and conclusion.
Recommendation: Weak Accept. While the paper makes a valuable contribution, addressing the clarity and emphasis issues would significantly strengthen its impact.