The paper presents an unsupervised feature selection method for text data grounded in the principle of Minimum Description Length (MDL). By leveraging a dictionary-based compression scheme, the authors aim to extract succinct and meaningful features from text corpora. The method formulates document compression as a binary optimization problem, which is approximated via a series of reweighted linear programs solved efficiently using the Alternating Directions Method of Multipliers (ADMM). The proposed approach is shown to reduce the feature space by two orders of magnitude while maintaining competitive performance on text classification tasks, with additional benefits such as faster training times and reduced labeled data requirements.
Strengths:
1. Efficiency and Scalability: The method achieves significant dimensionality reduction (two orders of magnitude) without sacrificing classification accuracy. The algorithm is linear in input size when the maximum k-gram length is fixed and is highly parallelizable, making it suitable for large-scale datasets.
2. Unsupervised Nature: The approach does not rely on labeled data, making it versatile for exploratory analysis and preprocessing in diverse machine learning tasks.
3. Robustness: Unlike Lempel-Ziv-based methods, the proposed scheme is invariant to document concatenation order, addressing a key limitation of existing compression-based feature selection techniques.
4. State-of-the-Art Results: The method achieves competitive performance on benchmark datasets (20 Newsgroups and IMDb), demonstrating its practical utility.
5. Interpretability: The compression-based approach provides a compact feature set that can elucidate structure in unsupervised tasks, such as PCA, and requires less training data for supervised tasks.
Weaknesses:
1. Novelty Concerns: While the approach is interesting, its novelty within the NLP domain is unclear. The connection between compression and feature selection has been explored in prior work (e.g., MDL and Lempel-Ziv-inspired methods). The authors should better position their contribution relative to existing literature.
2. Optimality of Compression: It is not explicitly clarified whether the proposed coding scheme achieves optimal lossless compression in terms of minimum entropy. This is a critical theoretical aspect that requires further elaboration.
3. Reweighting Scheme Interpretation: The interpretation of the reweighting scheme as a majorization-minimization procedure is not sufficiently clear. Additional explanation or mathematical derivation would enhance the clarity of this aspect.
4. Optimization Techniques: The use of projections on norms and iterative reweighting draws heavily on well-studied techniques in optimization literature. The authors should provide more context and cite relevant references to distinguish their contributions.
5. Limited Scope of Experiments: While the method is claimed to be applicable to other sequential data types, the experiments are restricted to text datasets. Extending the evaluation to other domains (e.g., clickstream or genomic data) would strengthen the paper's claims of generalizability.
Recommendation:
The paper is technically sound, well-organized, and addresses an important problem in feature selection for text data. However, the novelty of the approach and its theoretical contributions require further clarification. Additionally, the authors should provide more context on the optimality of their compression scheme and expand the experimental scope to demonstrate broader applicability. With these improvements, the paper would make a strong contribution to the field.
Arguments for Acceptance:
- Significant efficiency gains and practical utility in text classification tasks.
- Robustness and scalability of the proposed method.
- Strong experimental results demonstrating state-of-the-art performance.
Arguments Against Acceptance:
- Unclear novelty in the context of prior work.
- Insufficient theoretical discussion on optimality and reweighting scheme.
- Limited experimental scope beyond text data.
Overall, the paper is a promising contribution but requires revisions to address the aforementioned concerns.