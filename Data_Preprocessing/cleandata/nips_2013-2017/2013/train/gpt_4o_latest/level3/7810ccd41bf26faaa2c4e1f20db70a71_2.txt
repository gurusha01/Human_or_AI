The paper introduces Σ-Optimality as a criterion for active learning in Gaussian Random Fields (GRFs), building upon the foundational work of Garnett et al. (2012). The authors demonstrate that Σ-Optimality satisfies the submodular monotone property, enabling greedy selection to achieve a (1−1/e) approximation to the global optimum. This is a significant theoretical contribution, as it extends submodularity guarantees from V-Optimality to Σ-Optimality. Additionally, the authors establish that GRFs satisfy the suppressor-free condition, which is an interesting and valuable insight into the properties of GRFs.
The empirical results are compelling, showing that Σ-Optimality outperforms V-Optimality and other active learning criteria (e.g., Settles, Krause et al., Ji and Han) on real-world datasets such as DBLP, Cora, and CiteSeer. These results suggest that Σ-Optimality is a robust and effective criterion for active learning in classification tasks, particularly in the early stages of querying. However, the guarantees provided are with respect to the Σ-Optimality criterion itself rather than direct classification accuracy, which the authors acknowledge. This distinction is important and could be explored further in future work.
The paper is generally well-written and clear, with a logical structure that guides the reader through the theoretical and empirical contributions. However, there are areas where improvements are needed. First, the computational complexity of Σ-Optimality is not adequately discussed. The authors note that computing the reward (e.g., inverting the graph Laplacian) is computationally expensive, but a more detailed comparison with other criteria in terms of scalability and runtime would strengthen the paper. Second, the citation of Streeter and Golovin for submodular set functions should be replaced with Nemhauser et al., as the latter is the more appropriate reference. Third, Section 2.3 incorrectly attributes subset selection intractability to submodularity and overstates the necessity of greedy selection. This misstatement should be revised for accuracy.
Despite these limitations, the paper makes a meaningful contribution to the field of active learning by providing theoretical guarantees for Σ-Optimality and demonstrating its practical utility. The ambiguous description of Figure 3's horizontal axis, likely representing the probability of correct classification, should also be clarified. Overall, the paper is a strong submission with both theoretical and empirical significance, though addressing the noted weaknesses would further enhance its impact.
Pros:  
- Extends submodularity guarantees to Σ-Optimality.  
- Establishes suppressor-free properties for GRFs.  
- Strong empirical results demonstrating practical utility.  
- Clear and well-organized presentation.  
Cons:  
- Limited discussion of computational complexity.  
- Misattribution of references and inaccuracies in Section 2.3.  
- Guarantees are with respect to the criterion, not classification accuracy.  
Recommendation: Accept with minor revisions.