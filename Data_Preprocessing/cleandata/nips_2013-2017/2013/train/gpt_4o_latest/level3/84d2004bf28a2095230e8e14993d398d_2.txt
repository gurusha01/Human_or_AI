The paper addresses the critical problem of distributed submodular function maximization, which is highly relevant for large-scale machine learning applications such as clustering and Gaussian process inference. The proposed GREEDI algorithm is a simple, practical, and scalable two-stage protocol that leverages MapReduce-style computations. The authors provide a strong theoretical foundation, demonstrating that GREEDI achieves performance close to the centralized greedy solution under reasonable assumptions. The empirical results are promising, showcasing the algorithm's effectiveness on datasets with tens of millions of points.
Strengths:  
1. Relevance and Novelty: The paper tackles an important problem in distributed machine learning, proposing a novel method for submodular maximization that is both scalable and theoretically grounded. The use of MapReduce and the focus on cardinality constraints make the approach practical for real-world applications.  
2. Theoretical Analysis: The authors provide a rigorous theoretical analysis of GREEDI, including bounds on its performance relative to centralized solutions. The exploration of Lipschitz functions and decomposable objectives adds depth to the analysis.  
3. Empirical Validation: The experiments demonstrate the scalability of GREEDI on massive datasets, including 80 million Tiny Images and 45 million user visits. The results show significant improvements over baseline methods, such as random/greedy and greedy/merge.  
4. Efficiency: The use of lazy evaluation in the greedy algorithm is a notable efficiency improvement, though it could be explored further.  
Weaknesses:  
1. Experimental Section: The experimental results lack detailed explanations of baseline comparisons and performance metrics. For example, while GREEDI outperforms other methods, the reasons for its superiority (e.g., reduced redundancy or better marginal gains) are not thoroughly discussed.  
2. Runtime and Scalability: Despite the paper's focus on scalability, there is no explicit discussion of runtime or CPU cost. This omission is critical for practitioners evaluating the feasibility of deploying GREEDI in resource-constrained environments.  
3. Lazy Evaluation and Alternatives: Lazy evaluation is mentioned but not sufficiently highlighted as a key efficiency trick. Additionally, the potential use of lazy evaluation combined with MapReduce as an alternative to the proposed approximation deserves exploration.  
4. Submodularity Intuition: The concept of "diminishing returns," which underpins submodularity, should be introduced earlier to provide readers with an intuitive understanding of the problem.  
5. Ambiguity in "Fit on One Machine": The phrase "fit on one machine" is vague and needs clarification (e.g., RAM, disk, or CPU constraints).  
Suggestions for Improvement:  
- Provide a more detailed comparison of baseline methods, including qualitative insights into why GREEDI outperforms them.  
- Include a discussion of runtime and computational costs to better assess scalability.  
- Highlight lazy evaluation more prominently and explore its combination with MapReduce.  
- Introduce the concept of submodularity and "diminishing returns" earlier in the paper for clarity.  
- Clarify ambiguous terms like "fit on one machine" to avoid confusion.  
Pro and Con Arguments for Acceptance:  
Pros:  
- Addresses a critical and timely problem in distributed machine learning.  
- Provides a novel, theoretically sound, and empirically validated solution.  
- Demonstrates scalability to massive datasets, making it highly practical.  
Cons:  
- Experimental section lacks depth in baseline comparisons and runtime analysis.  
- Some key concepts (e.g., lazy evaluation, submodularity) are underexplored or insufficiently explained.  
Recommendation: Accept with minor revisions. The paper makes a significant contribution to distributed submodular maximization, but addressing the weaknesses would enhance its clarity, impact, and practical utility.