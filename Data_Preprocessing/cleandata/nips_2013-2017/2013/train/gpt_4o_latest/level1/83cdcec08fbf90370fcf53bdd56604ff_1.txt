The paper addresses the adaptive anonymity problem, proposing a generalization of k-anonymity to accommodate varying privacy preferences across individuals. By introducing the concept of b-matching and its symmetric variant, the authors provide a framework that allows users to specify personalized anonymity levels, δi, while maintaining theoretical privacy guarantees. The proposed relaxation of k-anonymity achieves better utility (fewer data suppressions) and avoids the degeneracy issues of traditional k-anonymity when users have heterogeneous privacy requirements. The authors present novel algorithms for constructing δ-regular bipartite graphs, analyze their privacy guarantees under various attack models, and validate their approach empirically on benchmark and social datasets.
Strengths
1. Novelty and Originality: The paper introduces a significant extension to k-anonymity by addressing the limitations of uniform anonymity levels. The use of b-matching and its symmetric variant is a novel contribution that generalizes existing privacy frameworks.
2. Theoretical Rigor: The authors provide a thorough theoretical analysis, including privacy guarantees for both single and sustained attacks. The proofs and lemmas are well-grounded and demonstrate the resilience of the proposed methods.
3. Practical Algorithms: The proposed algorithms are computationally efficient, with clear approximation guarantees. The inclusion of both asymmetric and symmetric variants provides flexibility for different use cases.
4. Empirical Validation: The experiments on UCI datasets and Facebook social data convincingly demonstrate the utility improvements of the proposed methods over traditional k-anonymity approaches. The adaptive anonymity setting is particularly compelling for real-world applications.
5. Clarity of Motivation: The paper clearly articulates the limitations of k-anonymity in handling heterogeneous privacy preferences and provides a well-motivated solution.
Weaknesses
1. Complexity of Presentation: While the theoretical contributions are strong, the paper is dense and may be challenging for readers unfamiliar with graph theory or b-matching. Simplifying some of the mathematical exposition could improve accessibility.
2. Limited Comparison to Differential Privacy: Although the paper briefly mentions differential privacy, a more detailed comparison of the proposed method's trade-offs (e.g., utility vs. privacy guarantees) with differential privacy approaches would strengthen its positioning.
3. Scalability: While the algorithms are efficient, the empirical evaluation does not explore scalability to very large datasets, which is critical for practical deployment in big data scenarios.
4. Real-World Utility Metrics: The experiments focus on minimizing the number of suppressions (stars), but it would be helpful to evaluate the impact of these suppressions on downstream tasks, such as machine learning model performance.
Arguments for Acceptance
- The paper addresses an important and underexplored problem in privacy-preserving data publishing.
- It provides a novel and theoretically sound framework with practical algorithms and empirical validation.
- The ability to handle adaptive anonymity levels is a significant advancement over existing methods.
Arguments Against Acceptance
- The paper's dense presentation may limit its accessibility to a broader audience.
- The lack of detailed comparisons with differential privacy and scalability experiments leaves some questions unanswered.
Recommendation
I recommend acceptance of this paper, as it makes a meaningful and rigorous contribution to the field of privacy-preserving data publishing. However, the authors should consider improving the clarity of presentation and expanding the discussion on scalability and comparisons with differential privacy in the final version.