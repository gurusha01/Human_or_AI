Review
Summary
The paper addresses the challenging task of recognizing unstructured social group activities in web videos, which is hindered by the semantic gap between low-level visual features and class labels, as well as the scarcity of labeled training data. The authors propose a novel supervised topic model, the "Relevance Topic Model" (RTM), which integrates sparse Bayesian learning with the Replicated Softmax model to jointly learn discriminative mid-level video representations and sparse classifier weights. The model replaces binary hidden units with rectified linear units to better capture the complexity of video data and employs a variational EM algorithm for efficient parameter estimation and inference. Experimental results on the USAA dataset demonstrate that RTM outperforms existing supervised topic models (e.g., MedLDA and gClassRBM) and achieves state-of-the-art performance, particularly in scenarios with limited labeled training data. The paper also extends RTM to multimodal data, further improving classification performance.
Strengths
1. Technical Novelty: The integration of sparse Bayesian learning with Replicated Softmax is innovative and effectively addresses the problem of discovering discriminative latent topics for video classification.
2. Empirical Performance: The model achieves state-of-the-art results on the USAA dataset, outperforming competitive baselines, especially in low-data scenarios. This highlights its robustness and practical utility.
3. Scalability: The proposed model is naturally extendable to multimodal data without altering the learning and inference procedures, making it versatile for real-world applications.
4. Clarity of Contributions: The paper clearly differentiates itself from prior work, such as MedLDA and gClassRBM, by emphasizing the use of sparse Bayesian learning and rectified linear units for better generalization and expressiveness.
5. Efficient Inference: The use of variational methods and a quadratic bound on the log-sum-exp function ensures computational efficiency, which is crucial for large-scale video datasets.
Weaknesses
1. Limited Dataset: The evaluation is restricted to the USAA dataset, which, while challenging, is relatively small and specific. The generalizability of RTM to other datasets or domains is not demonstrated.
2. Complexity of Model: The mathematical formulation and inference process are highly complex, which may hinder reproducibility and adoption by practitioners without significant expertise in Bayesian methods.
3. Ablation Studies: While the paper compares RTM to other models, it lacks detailed ablation studies to isolate the contributions of individual components, such as the rectified linear units or the sparse Bayesian learning.
4. Interpretability of Topics: Although the paper highlights the sparsity of relevance topics, it does not provide qualitative insights into the learned topics or their semantic alignment with video classes, which could enhance interpretability.
Arguments for Acceptance
- The paper addresses a significant and underexplored problem in video classification, advancing the state of the art.
- The proposed model is technically sound, with strong theoretical foundations and empirical validation.
- The integration of sparse Bayesian learning and rectified linear units is novel and impactful, offering a meaningful contribution to the field.
Arguments against Acceptance
- The evaluation is limited to a single dataset, raising concerns about the model's generalizability.
- The complexity of the model and its inference process may limit accessibility and practical adoption.
- The lack of qualitative analysis and ablation studies leaves some aspects of the model's contributions underexplored.
Recommendation
Overall, this paper makes a strong contribution to the field of video classification and is well-suited for presentation at NeurIPS. While there are some limitations, particularly regarding generalizability and interpretability, the strengths of the work outweigh these concerns. I recommend acceptance, with minor revisions to address the interpretability of topics and provide additional insights into the model's generalizability.