The paper presents a novel Approximate Message Passing (AMP) algorithm for Bayesian low-rank matrix reconstruction and its application to clustering. The authors extend existing AMP algorithms to enable maximum a posteriori (MAP) estimation, offering a flexible framework for incorporating structural properties like sparsity and non-negativity. They also reformulate clustering as a low-rank matrix reconstruction problem, introducing an AMP-based clustering algorithm that directly enforces the constraint that each data point belongs to exactly one cluster. Numerical experiments demonstrate that the proposed AMP algorithm outperforms Lloyd's K-means algorithm and other methods, particularly for high-dimensional data.
Strengths:
1. Technical Soundness: The paper is technically rigorous, with a strong theoretical foundation. The authors derive their AMP algorithm systematically and provide a detailed discussion of its properties, including computational efficiency and convergence guarantees.
2. Novelty: The extension of AMP algorithms to handle MAP estimation and clustering is a significant contribution. The paper also bridges the gap between low-rank matrix reconstruction and clustering, which is a fresh perspective.
3. Performance: The proposed AMP algorithm achieves superior results in both synthetic and real-world datasets, outperforming established methods like Lloyd's K-means and K-means++. The inclusion of state evolution analysis further supports the algorithm's reliability for large-scale problems.
4. Clarity of Results: The numerical experiments are well-designed, with clear metrics (e.g., normalized K-means loss, accuracy, and iteration count) and comprehensive comparisons across multiple algorithms.
Weaknesses:
1. Clarity: While the technical content is thorough, the presentation is dense and may be challenging for readers unfamiliar with AMP or Bayesian inference. Simplifying the exposition, particularly in the algorithm derivation, could improve accessibility.
2. Limited Discussion of Related Work: Although the paper references prior work, it could provide a more detailed comparison with recent advances in matrix factorization and clustering, particularly those beyond variational Bayes and Lloyd's K-means.
3. Convergence Guarantees: The authors assume convergence of the AMP algorithm but do not provide a formal proof. While they discuss fixed-point properties and state evolution, a more robust theoretical analysis of convergence would strengthen the contribution.
4. Real-World Applicability: The experiments on the ORL face dataset are promising, but the paper could benefit from additional real-world applications to demonstrate broader utility, such as in recommendation systems or bioinformatics.
Arguments for Acceptance:
- The paper introduces a novel and technically sound algorithm that advances the state of the art in low-rank matrix reconstruction and clustering.
- It demonstrates significant empirical improvements over existing methods, particularly in high-dimensional settings.
- The work is likely to inspire further research in AMP-based approaches and their applications.
Arguments Against Acceptance:
- The presentation is dense, which may limit its accessibility to a broader audience.
- The lack of formal convergence guarantees could raise concerns about the algorithm's robustness in all scenarios.
Recommendation:
Overall, the paper makes a strong scientific contribution, addressing a challenging problem with a novel and effective approach. While some aspects could be improved, the strengths outweigh the weaknesses. I recommend acceptance, with minor revisions to improve clarity and expand the discussion of related work.