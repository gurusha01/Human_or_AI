The paper introduces a Distributed Stochastic Dual Coordinate Ascent (DisDCA) algorithm for solving Regularized Loss Minimization (RLM) problems in a distributed framework. The authors address a notable gap in the literature by extending stochastic dual coordinate ascent (SDCA) methods, which are known for their strong theoretical guarantees and competitive performance compared to stochastic gradient descent (SGD), to distributed settings. The paper provides a detailed analysis of the tradeoff between computation and communication, presents convergence bounds for smooth and Lipschitz continuous loss functions, and introduces a practical variant of DisDCA that improves upon the basic version. Empirical results validate the theoretical findings and demonstrate the effectiveness of DisDCA compared to SGD- and ADMM-based distributed optimization algorithms.
Strengths:
1. Novelty and Originality: The paper extends SDCA methods to distributed frameworks, a relatively unexplored area, and provides a rigorous analysis of computation-communication tradeoffs. This is a meaningful contribution to distributed optimization literature.
2. Theoretical Rigor: The authors derive convergence bounds for both smooth and Lipschitz continuous loss functions and provide insights into the effective regions of parameters (m and K) for balancing computation and communication.
3. Practical Relevance: The introduction of a practical variant of DisDCA, which leverages up-to-date information during updates, is a valuable addition. The empirical results demonstrate significant improvements in convergence speed and scalability.
4. Comparative Evaluation: The paper compares DisDCA with SGD- and ADMM-based methods, highlighting its competitive performance. The experiments on large-scale datasets (e.g., covtype and kdd) further validate the algorithm's applicability to real-world problems.
Weaknesses:
1. Clarity: While the theoretical analysis is thorough, the presentation is dense and may be challenging for readers unfamiliar with distributed optimization. Simplifying or summarizing key results could improve accessibility.
2. Limited Scope of Practical Variant Analysis: The convergence bound for the practical variant is not established, leaving a gap in the theoretical understanding of its performance. This omission weakens the otherwise strong theoretical contributions.
3. Parameter Sensitivity: Although DisDCA is described as parameter-free, the practical variant introduces local updates, which may implicitly depend on problem-specific characteristics. A more detailed discussion of potential limitations or failure cases would strengthen the paper.
4. Broader Applicability: The focus is primarily on SVM formulations. While this is a reasonable starting point, extending the discussion to other machine learning models would enhance the paper's generalizability.
Arguments for Acceptance:
- The paper addresses an important and underexplored problem in distributed optimization.
- It provides both theoretical and empirical contributions, with clear evidence of competitive performance.
- The practical variant demonstrates meaningful improvements, making the work relevant to practitioners.
Arguments Against Acceptance:
- The lack of theoretical guarantees for the practical variant limits the completeness of the work.
- The presentation could be more accessible, particularly for non-experts in distributed optimization.
Recommendation:
I recommend acceptance with minor revisions. The paper makes a significant contribution to distributed optimization, particularly in extending SDCA methods to distributed frameworks. Addressing the clarity issues and providing additional insights into the practical variant would further strengthen the work.