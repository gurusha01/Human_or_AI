This paper introduces an extension of Factorized Asymptotic Bayesian (FAB) inference to Latent Feature Models (LFMs), addressing a significant limitation of FAB's applicability to models without block-diagonal Hessian matrices. The authors demonstrate that the Factorized Information Criterion (FIC) for LFMs shares the same form as that for mixture models (MMs), enabling FAB inference to be applied to LFMs. This extension provides desirable properties such as automatic feature selection, parameter identifiability, and improved computational efficiency. The paper also proposes a shrinkage acceleration method inspired by a convex-concave procedure (CCCP) to reduce computational costs and discusses a merging post-processing step to address parameter identifiability. Empirical evaluations show that FAB/LFMs outperform state-of-the-art methods like Indian Buffet Processes (IBP) and Variational Bayesian (VB) methods in terms of model selection, prediction accuracy, and computational efficiency.
Strengths:
1. Novelty and Contribution: The paper makes a significant contribution by extending FAB inference to LFMs, a challenging task due to the lack of block-diagonal Hessian matrices. The theoretical derivation of FIC for LFMs and its equivalence to FIC for MMs is rigorous and well-supported.
2. Practical Impact: The proposed FAB/LFM framework offers a fully automated model selection mechanism, which is a valuable advancement over existing methods that often require hyperparameter tuning or manual intervention.
3. Computational Efficiency: The introduction of the shrinkage acceleration method is a practical innovation that significantly reduces computational costs, as demonstrated in the experiments.
4. Empirical Validation: The paper provides comprehensive empirical evaluations on synthetic and real-world datasets, showing that FAB/LFMs achieve superior performance in terms of model selection accuracy, predictive performance, and computational efficiency.
5. Clarity of Results: The experimental results are well-organized, and the comparisons with state-of-the-art methods are thorough and fair.
Weaknesses:
1. Clarity of Presentation: While the theoretical derivations are rigorous, some sections, particularly those involving mathematical notation (e.g., Lemma 1 and Theorem 2), could benefit from clearer explanations or additional intuition to aid readers less familiar with the topic.
2. Limited Discussion of Limitations: The authors briefly mention that FAB may perform worse in small-sample scenarios due to the inaccuracy of FIC approximations but do not explore this limitation in depth or provide mitigation strategies.
3. Scope of Experiments: Although the experiments are comprehensive, additional comparisons with other modern nonparametric Bayesian methods (beyond IBP and VB) could strengthen the claims of superiority.
4. Supplementary Materials: Several critical proofs and algorithmic details are relegated to the supplementary materials, which may hinder the accessibility of the paper's contributions.
Arguments for Acceptance:
- The paper addresses a significant limitation of FAB inference and extends its applicability to LFMs, a non-trivial and impactful advancement.
- The proposed methods are theoretically sound and empirically validated, demonstrating clear improvements over existing approaches.
- The work is relevant to the NeurIPS community, particularly for researchers in Bayesian inference and latent variable models.
Arguments Against Acceptance:
- The paper's presentation could be improved, particularly in terms of clarity and accessibility for a broader audience.
- The discussion of limitations and potential drawbacks is relatively sparse, leaving some open questions about the method's robustness in certain scenarios.
Recommendation:
I recommend acceptance of this paper. While there are minor issues with clarity and scope, the paper makes a strong theoretical and practical contribution to Bayesian inference and latent feature modeling. Its innovations, particularly the extension of FAB to LFMs and the shrinkage acceleration method, are likely to have a significant impact on the field.