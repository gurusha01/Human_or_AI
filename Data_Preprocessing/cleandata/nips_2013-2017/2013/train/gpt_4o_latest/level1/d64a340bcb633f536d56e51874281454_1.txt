This paper addresses the problem of sparse recovery in high-dimensional settings where the measurement matrix contains highly correlated columns, a scenario where standard algorithms like Lasso and OMP often fail. The authors propose a novel greedy algorithm, SWAP, which iteratively swaps variables in the support estimate to minimize a loss function. The paper provides both theoretical guarantees and empirical evidence demonstrating SWAP's effectiveness, particularly as a wrapper around existing sparse recovery algorithms. The authors prove that SWAP can achieve accurate support recovery under relatively mild conditions on the restricted eigenvalues of the measurement matrix and the correlations between its columns. Numerical experiments on synthetic and real-world datasets (e.g., gene expression data) further validate the algorithm's superior performance compared to state-of-the-art methods.
Strengths
1. Novelty and Originality: The SWAP algorithm introduces a unique approach to sparse recovery by maintaining a fixed sparsity level and iteratively refining the support estimate. This distinguishes it from other greedy algorithms like FoBa and CoSaMP, which often estimate supports with higher sparsity levels before pruning.
2. Theoretical Contributions: The paper rigorously derives statistical guarantees for SWAP, including conditions under which it achieves consistent support recovery. The analysis is thorough and highlights how SWAP tolerates higher correlations in the measurement matrix compared to existing methods.
3. Practical Utility: By acting as a wrapper, SWAP enhances the performance of existing sparse recovery algorithms, making it a versatile tool. The empirical results, particularly on real-world gene expression datasets, demonstrate its practical relevance.
4. Clarity and Organization: The paper is well-structured, with a clear exposition of the problem, algorithm, theoretical results, and experiments. The inclusion of detailed pseudocode and illustrative figures aids comprehension.
Weaknesses
1. Computational Complexity: While the authors discuss the computational cost of SWAP, a more detailed comparison of runtime with other algorithms would strengthen the paper. For large-scale problems, the iterative nature of SWAP may pose scalability challenges.
2. Initialization Dependence: The performance of SWAP heavily depends on the quality of the initial support estimate. While the authors recommend using other sparse recovery algorithms for initialization, the paper could explore strategies for improving initialization robustness.
3. Limited Theoretical Analysis of Convergence Rate: Although SWAP is shown to converge in practice, the lack of a formal analysis of its convergence rate is a gap in the theoretical contributions.
4. Empirical Comparisons: While SWAP outperforms existing methods in terms of support recovery accuracy, the experiments could include a broader range of real-world datasets and scenarios to generalize the findings.
Arguments for Acceptance
- SWAP addresses a significant limitation of existing sparse recovery algorithms, advancing the state of the art in handling correlated measurement matrices.
- The combination of theoretical guarantees and empirical validation makes the contribution both rigorous and practical.
- The algorithm's versatility as a wrapper enhances its applicability across various domains.
Arguments Against Acceptance
- The computational complexity and scalability of SWAP are not fully addressed, which may limit its use in large-scale applications.
- The dependence on initialization and lack of convergence rate analysis leave room for improvement in the theoretical framework.
Recommendation
Overall, this paper makes a strong contribution to the field of sparse recovery and is well-suited for presentation at NeurIPS. I recommend acceptance, with minor revisions to address the computational complexity and initialization robustness.