Review - Quality: 5 (out of 10)  
Clarity: 6  
Originality: 6  
Significance: 9  
SUMMARY:  
The authors present a method to accelerate the stochastic gradient optimization algorithm by employing the 'control variate' trick, a well-known variance reduction technique in Monte Carlo simulations (e.g., as explained in [3]). The control variate is a vector designed to have a high correlation with the noisy gradient while having an expectation that is easier to compute. Since standard convergence rates for stochastic gradient optimization are influenced by the variance of gradient estimates, reducing this variance should theoretically accelerate convergence. The authors demonstrate this approach using Taylor approximations to construct control variates for two applications: regularized logistic regression and MAP estimation for the latent Dirichlet Allocation (LDA) model. They compare constant step-size SGD with and without variance reduction for logistic regression on the covtype dataset, arguing that variance reduction enables larger step-sizes without high variance, leading to faster empirical convergence. For LDA, they compare the adaptive step-size version of the stochastic optimization method from [10] with and without variance reduction, showing faster convergence on the held-out test log-likelihood across three large corpora.  
EVALUATION:  
Pros:  
- The general idea of variance reduction for SGD using control variates is appealing and has the potential for significant impact, given the widespread use of SGD.  
- The motivation is strong, the examples of control variates are convincing, and the general approach (using Taylor approximations) appears generalizable.  
- The paper is relatively easy to follow.  
Cons:  
- The experimental evaluation is limited, with only one dataset used for logistic regression and an inconsistent setup for LDA.  
- The related work section is incomplete.  
QUALITY:  
The theoretical motivation for the proposed approach is strong, as reducing the variance of gradient estimates directly impacts the convergence rate constant. However, the empirical evaluation is lacking:  
1) For logistic regression, the authors only evaluate their method on the covtype dataset. Previous literature on SGD optimization has shown that behavior can vary significantly across datasets and step-sizes (e.g., see Figures 1 and 2 in "A Stochastic Gradient Method with an Exponential Convergence Rate for Finite Training Sets," arXiv:1202.6258v4). A broader evaluation across multiple datasets is necessary.  
2) For the LDA experiments, the authors deviate from the experimental setup in [10] and [4], making their results difficult to compare. For instance, they use a different mini-batch size (500 vs. 100) and a smaller held-out test set (2k vs. 10k). This inconsistency is concerning, especially since their baseline results for the state-of-the-art method in [10] are systematically worse than those reported in [10]. The authors should clarify these discrepancies in their rebuttal.  
3) An additional baseline that is missing is a comparison between their control variate method and other variance reduction techniques, such as using different mini-batch sizes (as mentioned in the introduction). For example, [4] demonstrates the impact of mini-batch sizes on variance reduction.  
CLARITY:  
The paper is generally clear and easy to follow. Figure 1 is particularly helpful. However, several points need clarification:  
- The authors should explicitly describe how they estimate the covariance quantities in their experiments to compute \(a^*\). Do they use empirical covariances from the mini-batch? This should be reiterated in the experiments section, along with a discussion of how the computational cost compares to standard SGD.  
- Figure 2 is difficult to interpret. The authors should add markers to distinguish the different lines.  
- Additional suggestions for improvement are provided below.  
ORIGINALITY:  
The use of variance reduction techniques for SGD in this generality appears novel. However, the paper lacks a thorough discussion of related work. For example, the authors should include a comparison to "Variational Bayesian Inference with Stochastic Search" by John Paisley, David Blei, and Michael Jordan (ICML 2012), which also employs control variates to reduce variance in stochastic optimization for variational Bayes. The authors should clarify their novel contributions relative to this prior work. Another relevant reference is "Variance Reduction Techniques for Gradient Estimates in Reinforcement Learning" by Evan Greensmith, Peter L. Bartlett, and Jonathan Baxter (JMLR 2004), which, while less directly competitive, is worth mentioning.  
SIGNIFICANCE:  
The proposed approach has the potential to generalize to many other settings where SGD is used, beyond the two applications discussed in the paper. Given the widespread use of SGD for large-scale optimization, the potential impact of this work is significant. While the empirical results are somewhat weak, the theoretical intuition is compelling, and a more comprehensive empirical evaluation could demonstrate substantial improvements. Additionally, the theoretical argument does not rely on having a finite training set, suggesting that the method could also be applied in true stochastic optimization settings where full expectations cannot be computed, and running averages are used instead.  
Other Detailed Comments:  
- Line 058: Replace "discuss" with "discussion."  
- Line 089: Clarify that the matrix \(A\) depends on \(w\).  
- Equation (5): Note that \(\text{Cov}(g, h)\) is not symmetric in general, so the second term should be \(-(\text{Cov}(g, h) + \text{Cov}(g, h)^T)\).  
- Equation (6): The RHS should use \(\text{Cov}(h, g)\) (or \(\text{Cov}(g, h)^T\)), not \(\text{Cov}(g, h)\).  
- Paragraph 150-154: It may be worth mentioning that in the case of maximal correlation, one could set \(hd = gd\), which would reduce the variance to zero. However, this is impractical since \(E[h_d]\) cannot be computed efficiently.  
- Lines 295-296: The sentence "This is different from the case in Eq. 11 for logistic regression, which is explicit" is ambiguous. Clarify what is meant by "explicit."  
- Figure 3: Specify the \(w\) used to compute the Pearson coefficient. Are the true covariances or mini-batch estimates used?  
Update After Rebuttal:  
The authors should address the related work in their final version and implement the corrections mentioned above (I will verify this). While the authors make a meaningful contribution beyond [Paisley et al. 2012], they should acknowledge that [Paisley et al. 2012] already used control variates to improve optimization for variational objectives, albeit not in as general a manner as in this submission. The experiments remain a weak point, which tempers my enthusiasm for acceptance.  
In summary, I appreciate the idea of variance reduction for SGD, and the authors provide compelling examples for logistic regression and LDA. This concept has the potential for significant impact, but the empirical evaluation is insufficiently robust.