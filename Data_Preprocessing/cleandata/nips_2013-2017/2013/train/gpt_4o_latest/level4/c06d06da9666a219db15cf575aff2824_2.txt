The authors address the problem of learning an undirected graphical model by framing it as a large (and intractable) constraint satisfaction problem (CSP). Specifically, given observations of the variables, X, they focus on identifying the junction tree, T, that maximizes the marginal likelihood p(X|T). Instead of exhaustively searching through the space of all possible junction trees, the authors reformulate the task as a weighted CSP and propose leveraging an off-the-shelf CSP solver to identify the optimal junction tree.
The core contribution of the paper lies in the formulation of the CSP, which involves characterizing a junction tree as a collection of cliques and separators defined over a balanced maximum weight spanning tree. While the paper is well-written and appears to present a novel perspective, its practical utility is limited due to the exponential number of constraints required to formulate the CSP. This raises the question: what practical advantage is gained by recasting the structure learning problem as a CSP? It would have been valuable to explore an approximate CSP formulation that relaxes some conditions while remaining computationally feasible or a bounded version of the CSP that identifies the most likely junction tree with a restricted clique size. Additionally, it is unclear how a non-uniform prior over graph structures could be incorporated into this framework, which would be desirable for learning sparse or low-treewidth models. Overall, the authors propose an innovative formulation of structure learning as a CSP and introduce an elegant tool—the balanced spanning tree—for analyzing and designing algorithms involving junction trees. However, the approach's practical applicability is hindered by the exponential growth in constraints required for the CSP.