An associative memory mechanism for pattern completion of non-binary, integer-valued data is introduced, with the authors asserting that the storage capacity of the model can scale exponentially with the number of neurons. The primary contribution of this work is the analysis of the model's performance under the influence of intrinsic neural noise. Notably, both theoretical analysis and simulations demonstrate the counterintuitive result that intrinsic noise can enhance the model's performance.
Comments:
1) It is crucial to provide evidence supporting the claim that the model can store an exponential number of patterns. This could be achieved through either theoretical capacity analysis or simulation results illustrating how recall error varies with the number of stored patterns.
2) To ensure the paper is self-contained, it is essential to include a description of the learning algorithm from [10], at least summarizing its core principles.
3) For integer-valued data, restricting the (external) additive noise to values of -1, 0, or 1 seems somewhat artificial. Can the model accommodate larger additive noise values?
4) While the discussion emphasizes the neurobiological relevance of the model, it is also important to address the fact that several aspects of the algorithm lack biological plausibility, such as the negative activity in the control neurons and the iterative loops in Algorithms 1 and 2.
5) In the final version of the paper, it would be beneficial to include the key proof steps currently relegated to the appendix.
6) To save space, consider removing the 3D figure (Fig. 4), as it appears redundant with Fig. 5.