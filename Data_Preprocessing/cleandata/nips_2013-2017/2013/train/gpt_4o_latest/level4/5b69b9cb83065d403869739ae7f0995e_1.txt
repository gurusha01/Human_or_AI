The authors propose an algorithm for matrix reconstruction under noisy observations. The study focuses on low-rank matrices with additional assumptions on their factors and employs an Approximate Message Passing (AMP) approach to accelerate the traditionally computationally intensive Bayesian methods. Furthermore, the authors establish a connection between matrix reconstruction and K-means clustering, which serves as an intriguing application domain for the proposed algorithms.
To the best of my knowledge, using the Approximate Message Passing approach for matrix reconstruction is novel and compelling. While the connections between low-rank matrix factorizations and K-means clustering are relatively well-established (e.g., PCA is known to provide a factor-two approximation for K-means), this linkage enables the authors to conduct a thorough experimental evaluation of their algorithms. They compare their method against K-means and K-means++ and demonstrate, based on empirical results, that their approach is faster and more efficient than these classical methods. Notably, the authors evaluate both the Frobenius norm residual and the resulting cluster assignments, which adds value to their experimental analysis.
The primary limitation of the paper lies in the lack of strong theoretical guarantees regarding the convergence of the proposed algorithm. However, this is not entirely surprising, as many existing algorithms for K-means also exhibit limited theoretical properties. The authors could strengthen their work by citing additional papers from Theoretical Computer Science that present provably accurate algorithms for the K-means objective. Overall, this is a solid contribution that introduces Approximate Message Passing algorithms for low-rank matrix reconstruction and K-means clustering. The experimental results are promising, though the theoretical aspects remain somewhat underdeveloped.