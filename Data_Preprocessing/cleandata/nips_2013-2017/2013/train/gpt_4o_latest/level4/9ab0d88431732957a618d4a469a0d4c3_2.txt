This paper presents a generalized framework for multiple model learning, incorporating a regularization term that assigns weights to individual data points, making the method robust to outliers. The authors provide theoretical justification for their formulation, supplemented by some empirical results.
Quality, clarity, and significance:  
While the paper includes some intriguing findings, its quality and significance are undermined by numerous unclear explanations in both the textual descriptions and mathematical notations.
- Definition 1: The definition is unclear. Why is the tuple (or rather, a triplet) consisting of two sets and one function referred to as a "problem"? It seems that the actual problem lies in minimizing the weighted loss.  
- Line 109: The bold symbol \( \mathbf{m} \) is ambiguous. It appears to represent a vector of \( m_j \) for \( j = 1 \) to \( k \), but such a vector is already defined as \( M \) in line 104.  
- Example 1: It would be helpful to explicitly show what \( X \), \( M \), and \( l \) represent for each example.  
- Line 147: The claim that an outlier "tends to infinity" requires further clarification.  
- Lemma 2: The definition of \( P_{\Delta^n} \) is missing and should be provided.  
- Section 3.1 (Empirical Results): The choice of \( \alpha \) and the method for setting it are unclear. As noted in line 73, \( \alpha \) must be chosen appropriately, which is critical for the proposed formulation. However, the paper does not explain how to determine \( \alpha \). For instance, cross-validation is not applicable in unsupervised learning, so an alternative strategy is needed. Additionally, an analysis of the sensitivity of the results to changes in \( \alpha \) would add value.  
- Figure 3.1: The meaning of "Dataset" on the x-axis is unclear. Why does RW MAD increase monotonically as the datasets change? This requires explanation.  
- Line 320: The mathematical definition of the breakdown point should be explicitly stated.  
- Line 336: In \( l(mj, xi) \), the roles of \( mj \) and \( xj \) appear to be reversed (see Definition 1).  
- Line 337: Adding an intuitive explanation for the number "22" would improve readability.  
- Line 375: The expression \( l(\cdot, m_j) \) is unclear. It seems that a specific \( x \) is required to define the value at \( \cdot \).  
Originality:  
The paper introduces a generalization of multi-model learning with a regularization term, but its level of originality is moderate. Nevertheless, this approach is relevant and important for advancing the field. While the theoretical results are interesting, the paper's presentation lacks polish, and the empirical evaluation is insufficient.