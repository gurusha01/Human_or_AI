Summary of the Paper
This study addresses the support recovery problem in linear regression within a high-dimensional framework, specifically focusing on identifying the non-zero entries in the regression parameter vector when the number of predictors \( p \) exceeds the sample size \( n \). The authors introduce a straightforward greedy algorithm, well-suited for scenarios with high correlation among predictors. Starting with an initial estimate \( S \) of the true support, the algorithm iteratively swaps each variable in \( S \) with each variable in \( S^c \), one at a time, seeking to minimize the squared loss. The sparsity level (i.e., the number of non-zero entries in the coefficient vector) is preserved throughout the process. This method, termed SWAP, is often employed to refine the results of classical sparse recovery techniques, such as LASSO, by using their output as the initial support estimate \( S \).
The paper provides a thorough theoretical analysis of SWAP, detailing both its limitations and guarantees. It outlines the conditions required for accurate support recovery and establishes bounds on the number of iterations needed. Notably, the assumptions for SWAP are shown to be less restrictive than the commonly used irrepresentability condition. Additionally, the authors demonstrate the utility of SWAP through numerical experiments on synthetic and genomic datasets.
Comments
The paper is well-written and engaging. It provides clear motivations and introduces the SWAP procedure with minimal prerequisites, aided by an illustrative example in the introduction. Despite its simplicity, SWAP appears to be a promising approach. A particularly strong aspect of the paper is its theoretical analysis, which is presented in a clear and accessible manner. Each parameter and assumption is well-motivated, and no unnecessary technical details are left unexplained. This transparency also highlights the method's limitations.
However, I have a few remarks and questions:  
- Remark 3.3: It is unclear what "Line 3" refers to (likely Line 4 in Algorithm 1). While the authors provide a complexity analysis for this "Line 3," the computational cost of the rank-\( k \) projection matrix remains unspecified. Quantitative results would have been helpful to assess the additional computational burden compared to a standard LASSO fit. Furthermore, Proposition 4.1 suggests that the number of iterations could become prohibitive if the initial support estimate contains more than half false positives.  
- Fixed Support Size: With SWAP, the support size remains fixed at the initial estimate. In the synthetic experiments, the authors report results by arbitrarily setting the support size to the true value, which could bias the findings. In the genomic example, the sparsity level \( k \) varies, but it is evident that the optimal \( k \) is not always the same for SWAP and the initialization method. How is \( k \) practically chosen in these cases?  
- Performance Metrics: In the synthetic experiments, the authors report the true positive rate (TPR) and the number of iterations. However, the false positive rate (FPR) is not provided, which is essential for evaluating performance. Without the FPR, it is unclear whether the initialization methods operate in a regime where they maintain a high TPR at a reasonable FPR.  
- Genomic Data Example: The use of classification (binary response) in the genomic data example is surprising. The squared loss used for swapping variables seems ill-suited for this type of outcome. Moreover, the initialization methods may not perform well in this context, potentially making it easier for SWAP to enhance the support. Many genomic datasets are available with continuous outcomes, which might provide a more appropriate test bed.  
- Comparison with Correlation-Handling Methods: While SWAP is designed to handle correlated predictors, the paper does not compare it to other methods specifically developed for highly correlated settings, such as elastic net or Trace-Lasso, which are widely available.  
In summary, this paper introduces a simple yet compelling method with solid theoretical underpinnings. It is well-written and easy to follow. However, I have reservations about the numerical experiments and the lack of comparisons with state-of-the-art methods. While SWAP enhances certain sparse recovery algorithms in specific scenarios, it remains unclear whether these scenarios are well-suited to the methods being enhanced.