Graph cut methods for semi-supervised classification and clustering have been dominant over the past decade. Hypergraphs, by incorporating higher-order information about data compared to ordinary graphs, are expected to be more advantageous. However, existing methods come with their own limitations, as discussed in Section 1.
In contrast, this paper explores a direct approach to handling the hypergraph cut by leveraging the total variation of the Lovász extension. Two frameworks are introduced in Sections 3 and 4, accompanied by an algorithm for solving the associated problems, as detailed in Section 5. The experimental results presented in Section 6 appear promising.
The core idea of this paper is intriguing. However, the derivations are somewhat difficult to follow. I have not verified the technical details, as I am not well-versed in the optimization problems discussed in Sections 4 and 5. Nonetheless, the extension in Section 3, which generalizes semi-supervised learning from graph Laplacian matrices to the proposed functionals, seems natural, and the theoretical results appear to be valid.
I have two minor questions. First, in Definition 2.1, the condition \( f1 \leq \ldots \leq fn \) is imposed. However, it seems that in later optimizations, \( f \), as an optimization variable, may not always satisfy this constraint. Under what circumstances is this condition valid? Second, in the experiments, numerical features are converted into categorical features using 10 equal-size bins. Could this lead to a potential loss of information?
Comment after authors' feedback
The authors have addressed my concern regarding the experimental setup. This paper investigates a direct approach to handling the hypergraph cut using the total variation of the Lovász extension. The proposed idea is compelling, and the experimental results are encouraging.