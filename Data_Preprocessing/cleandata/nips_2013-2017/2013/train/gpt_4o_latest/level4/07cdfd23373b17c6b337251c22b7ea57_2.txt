This paper introduces a method for uncovering latent structures in social network data. The proposed model is trained on triangle count statistics derived from a preprocessing step, akin to the bag-of-words representation used for text documents. The primary modeling innovation is inspired by the aMMSB: instead of parameterizing all between-"community" interactions, the authors focus on triangle configurations to define a set of K roles for parameterization. This approach reduces the number of model parameters, enabling a more scalable implementation. The authors leverage recent advancements in stochastic variational inference, deriving both global and local update rules for their model.
The novel contribution of this work lies in its straightforward integration of the aMMSB with the MMTM, though the process involves somewhat tedious bookkeeping. However, the clarity of the presentation could be improved.
While much of the learning algorithm directly applies stochastic variational inference, the authors propose an intuitive and intriguing approximation for the local update rule.
Given the widespread occurrence of directed networks, it would be beneficial to include a detailed discussion on how these methods could be extended to such cases.
Key concerns:
- The statement that "our Parsimonious Triangular Model (PTM) is essentially a latent space counterpart to ERGMs, that represents the processes of generating triangular motifs" is puzzling: 1) ERGMs can incorporate a much broader range of statistics beyond triangles, and 2) it is unclear how PTM qualifies as a "latent space counterpart" unless all latent space network models are considered as such.  
- Are the inferred latent spaces interpretable? If so, what insights can be drawn about the similarities and differences among the graphs?  
- The distinction between Δ¹ and Δ² is not clearly explained.  
- The paper does not sufficiently justify why subsampling triangles for each node (using Δ) provides an adequate approximation.  
- If the goal is to recover the "set of non-zero roles," the model might benefit from incorporating a more binary notion of "role."  
- How sensitive are the latent space recovery results to the threshold of 0.125, which appears somewhat arbitrary?  
- Many latent space models can generate power-law networks. Which specific model was used in the experiments?  
- Why does PTM CGS have a complexity of K³? Wasn't it argued earlier that there are O(K) parameters rather than O(K³)?  
- A potential concern is the model's performance when fewer edges are observed. In the experiments, only 10% of the edges were held out, possibly because removing too many edges could bias the distribution of adjacent triangles during preprocessing.  
- It seems counterintuitive that the method outperforms MMSB on a synthetic network generated using MMSB (Figure 1, left 4 panels).  
This work employs stochastic variational inference to train a mixed-membership blockmodel (with a constrained set of parameters) on triangle counts in a graph. The modeling decisions and approximations enable a more scalable O(NK) algorithm.