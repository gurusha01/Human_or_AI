The paper proposes a reduction approach aimed at decreasing the size of deep models to enhance the training efficiency of deep learning. The primary contributions are: (1) leveraging prior knowledge about the redundancy in deep models, such as spatial parameter smoothness in image data; and (2) employing kernel ridge regression for parameter interpolation from a subset.
The paper is well-written and appears to be original.
The authors assert that the proposed approach is highly general and could be applied to non-image tasks. They discuss potential extensions of the method, such as autoencoder pretraining for non-image data. However, the experimental evaluation does not include any non-image datasets, making this claim unsubstantiated.
All the experiments conducted on image datasets involve relatively small datasets with simpler patterns. It is difficult to extrapolate the effectiveness of the proposed methods to more complex and realistic datasets, such as ImageNet, based solely on these results. Consequently, the practical value of this work remains unconvincing.
After reviewing the authors' rebuttal, my recommendation remains unchanged. While the work is novel and introduces some intriguing ideas for reducing the size of deep networks, the experimental evidence does not sufficiently demonstrate its value.