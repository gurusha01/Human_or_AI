This paper presents a spectral algorithm for learning Hidden Markov Models (HMMs) from non-sequential observations. Inspired by various scientific applications, the authors introduce a sampling model for non-sequential data, which bears some resemblance to the generative framework of Latent Dirichlet Allocation (LDA). Leveraging recent advances in spectral techniques for learning LDA, HMMs, and mixture models, the authors establish sample complexity bounds for recovering the parameters of an HMM with continuous outputs under this sampling model. The final section includes a simple simulation that demonstrates the algorithm's behavior on a synthetic dataset. All proofs are provided in the supplementary material.
The primary contribution of this work lies in identifying a sampling model for non-sequential data generated by an HMM that is tractable for theoretical analysis using recent spectral learning methods, and in deriving finite-sample bounds under this model. However, the experimental evaluation is minimal and arguably unnecessary given the theoretical nature of the paper. The space devoted to this section could potentially be better utilized to emphasize the novel aspects of the proofs included in the appendix.
Overall, the paper is well-written, and the authors provide clear explanations of the intuitions underlying their results. Nonetheless, the mathematical exposition is somewhat dryâ€”particularly the sample bounds, which prioritize precision over asymptotic insights, making them challenging to interpret.
While the content of the paper is not highly original, there is some innovation in the proposed generative model for non-sequential data and its subsequent analysis. That said, the proof techniques, though intricate, are closely aligned with those used in prior spectral learning studies. Furthermore, the problem of applying spectral learning to HMMs using non-sequential data has already been explored in prior work (e.g., "Spectral Learning of Hidden Markov Models from Dynamic and Static Data," T. Huang and J. Schneider, ICML 2013).
The practical significance of the proposed method hinges on its performance with real-world data, which is unlikely to conform to the sampling model defined in the paper. While the authors leave this as future work, the sample sizes required to achieve favorable results in their synthetic experiments suggest that the method may not be suitable for scenarios with limited data availability.
 Typo   
[line 107] V2 -> X2  
This paper provides the first finite-sample bounds for learning HMMs from non-sequential data under a reasonable sampling model. The relevance of this approach depends on whether the algorithm can perform effectively on real-world problems that inspired the model.