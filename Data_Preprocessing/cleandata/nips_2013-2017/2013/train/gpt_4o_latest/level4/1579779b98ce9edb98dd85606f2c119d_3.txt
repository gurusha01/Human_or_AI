The authors provide an analysis of a class of Monte Carlo Tree Search (MCTS) algorithms that can employ, with some mild restrictions, any no-regret selection method. The primary theoretical contribution of the paper is a proof of convergence to an epsilon-Nash equilibrium in the context of simultaneous-move games.
A notable limitation of the work is that the convergence established is asymptotic, with no explicit rates provided. This limitation arises naturally from the authors' framework, as the selection method is only assumed to be epsilon-Hannan consistent. While this is not necessarily a critical flaw—given that, to the best of my knowledge, no existing work provides convergence proofs for MCTS methods in extensive-form games with simultaneous moves—it does raise questions about the practical implications of the results.
That said, the question of convergence rates is important. Backward induction, for instance, can compute an exact equilibrium, so understanding the rates of convergence for this approach would provide valuable context. Do the authors have any insights into the rates that might be achieved if a specific regret rate, such as the \(\sqrt{T}\) bound guaranteed by exponential weights, is assumed for the selection method?
The paper concludes with experimental results. The authors compare the mean reward propagation approach used in their analysis to the standard method of propagating the current sample value. They observe that mean reward propagation slightly underperforms in practice. Additionally, they attempt to empirically explore the convergence rate of their method.
In summary, this is a well-written and technically sound paper. However, I have some reservations about the overall significance of the contribution due to the absence of convergence rate results. On one hand, MCTS methods are known to perform well in practice, so establishing asymptotic convergence is a meaningful first step. On the other hand, given that convergence results already exist for MCTS in sequential-move settings, the contribution feels somewhat incremental.
Nitpicks:
- Figure 1: Replace "leafs" with "leaves."
- Line 144: Should "inverted" be "negated" instead?
- Line 10 of Algorithm 1: The notation \((a1, a2)\) seems incorrect and should likely be \((i, j)\) or possibly \((\sigma1, \sigma2)\). This is particularly confusing since \(a_{i,j}\) was earlier defined as the payoff in a single-stage matrix game.
- Line 172: The notational inconsistency between \((i, j)\) and \(a\)'s appears to persist throughout the paper. While I won't enumerate all instances, these should be carefully revised.
Overall, I found this to be a well-written and enjoyable paper. While I have concerns about the impact of the work due to the lack of convergence rate analysis, it represents a meaningful contribution to the study of MCTS methods.