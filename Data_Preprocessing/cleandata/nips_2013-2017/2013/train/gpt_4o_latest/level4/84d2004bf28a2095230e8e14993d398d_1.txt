This paper presents a two-stage method for distributed submodular maximization, referred to as GreeDi. The authors derive error bounds for the GreeDi algorithm, offering a theoretical guarantee on the greedy approximate solution relative to the centralized solution. The proposed approach is evaluated on six datasets, demonstrating its effectiveness.
Here are my comments:  
1. The use of both Îº (kappa) and k in Theorem 4.2 is confusing, as it is difficult to distinguish between them during reading.  
2. Regarding the bound in Theorem 4.2, it would be beneficial to discuss its tightness. I observe that the bound includes a factor of min(m, k).  
3. In the experiments, reporting generalized performance metrics, such as negative log predictive probability, would be insightful. While a decrease in the objective function is expected, it would be interesting to understand its impact on generalization.  
4. It is unclear which experiments in Section 5 address decomposable functions. Clarifying this would improve the presentation.  
5. In Figure 1(e), the x-axis label should be k.  
6. In Figure 1(f), it is unclear why the ratio at the smallest m starts below 1, whereas it begins at 1 in Figures 1(a)-1(d).  
7. How can the dip observed at k = 10 in Figure 1(c) be explained?  
8. Adding references to the Today Module of Yahoo! would assist readers in conducting related research.  
Overall, this is an interesting contribution to the field of distributed data mining.