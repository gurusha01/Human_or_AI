This paper focuses on learning Gaussian copulas by transforming the marginals of the data using the empirical cumulative distribution function (CDF). The primary challenge lies in the linear constraints on the sampling domain, whose number grows quadratically with the size of the dataset. To address this, the authors propose a Hamiltonian Monte Carlo (HMC) sampler, where the constraints are managed by allowing the sample trajectory to "bounce" off them. The paper includes empirical results, demonstrating superior performance of the proposed method compared to the Hoff algorithm for the same number of steps.
The paper appears technically sound, though I have some reservations about the empirical results. The presentation is generally clear, aside from a few minor points noted below. The approach seems novel, as I am unaware of similar methods in the literature, though I am not deeply familiar with the copula domain, which is reflected in my confidence score. However, the computational expense of the method is a concern, as the authors acknowledge that their MATLAB implementation is not particularly efficient, raising questions about its broader applicability.
My specific concerns regarding the empirical results are as follows:
* The HMC is only run for 1000 steps, whereas the Hoff algorithm is run for 2000. The Hoff algorithm appears to make a few additional switches after 1000 steps, which could lead readers to question whether the HMC method might exhibit similar behavior if run longer. This discrepancy is likely due to the significantly higher computational cost of HMC (noted as being 50 times slower in Footnote 7). While I do not doubt the final results, particularly given the supplementary plots, it would enhance the thoroughness of the paper to either run the HMC for 2000 steps, provide a plot of posterior densities for each sample to confirm that the Hoff algorithm's jumps are not due to a second mode, or include a discussion affirming that the posterior is definitively unimodal (which I believe can be established a priori in this case).
* The paper would benefit from a more detailed discussion of the relative computational costs of the HMC and Hoff methods. Footnote 7 offers a justification, but a more in-depth explanation is needed. For instance, should a well-optimized HMC implementation be expected to approach the efficiency of Hoff? Given the current disparity (HMC taking 50 times longer), it might be more appropriate to compare HMC at iteration 50 with Hoff at iteration 2500 in the bottom row of Figure 3.
A few minor presentation issues:
* Citation [12] is introduced for the first time in the conclusion. If it is significant, it should be referenced earlier, ideally in the introduction as part of the related work.
* The use of footnotes could be reduced. Several footnotes, such as 2, 3, 5, and 7, could be integrated into the main text without disrupting the flow. Footnote 5, in particular, introduces notation and should be included in the main text as it is essential for understanding. Similarly, Footnote 7 should be moved into the main text, as it provides critical context about the computational cost of HMC, which is relevant to the discussion of empirical results.
Overall, this is a solid paper, but there are some concerns about the fairness of the empirical comparisons that should be addressed.