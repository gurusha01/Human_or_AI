This paper introduces novel algorithms for differentially private online learning, covering nearly all scenarios where non-private results are already established. The derived bounds closely align with the best-known non-private results, differing only by minor additional factors and dependencies. Given the growing interest in differentially private learning, this work offers a significantly more comprehensive and compelling set of results compared to prior research.
The core idea is conceptually straightforward—implement a follow-the-approximate-leader strategy using a private (noisy) history, maintained via standard algorithms for constructing differentially private counters. While the suitability of follow-the-leader algorithms for privacy has been previously noted, the treatment here and the resulting bounds are particularly elegant.
I suggest framing this work as presenting a class of private learning algorithms or a method for constructing such algorithms, rather than describing it as a "general technique for making online algorithms differentially private." This distinction is important since the proposed approach does not universally apply to all online algorithms—correct?
The practice of citing references without listing author names made the paper challenging to follow. I frequently had to consult the bibliography, as understanding the referenced work was often crucial (e.g., in cases where the text did not clarify whether the cited results pertained to the private or non-private setting).
In Table 1, it would be helpful to remind readers that the delta in the first column corresponds to (ε, δ)-differential privacy.
Why are there no citations for the non-private results in Table 2? Additionally, the caption claims the results are for the full-information setting, but the table clearly presents results for the bandit setting. Furthermore, shouldn't the adaptive case results exhibit a T^3/4 dependence rather than T^2/3?
Do you believe the explicit dimensionality dependencies observed are inherently necessary for ensuring privacy? Also, is there a provable (albeit small) gap in the dependence on T between private and non-private algorithms, accounting for the differing poly-logarithmic factors?
The second-to-last paragraph on p.6 contains unnecessary redundancy and could be streamlined.
Overall, this is a simple yet compelling approach with strong results for private online learning.