The paper establishes that learning and inference are achievable in a nonlinear generative model for natural images that accounts for both translation invariance and occlusion. This work represents a compelling extension of prior research on Occlusive Component Analysis (OCA). When applied to natural image patches, the model corroborates earlier findings that incorporating occlusions naturally leads to globular receptive fields, in addition to the standard oriented, Gabor-like filters. 
The paper is technically robust, well-articulated, and situates the presented work within the broader context of probabilistic image models. While the results align with expectations based on prior OCA research, the technical advancements—specifically the occlusive nonlinearity and the ability to learn a significantly larger number of components—are noteworthy.
- Quality  
The model extends OCA by incorporating translation invariance across all possible planar translations. While this makes exact inference intractable, the authors effectively demonstrate an efficient approximation method based on preselection.  
The results on natural images are quantitatively analyzed by fitting linear receptive fields to the inferred components. The findings reveal that while most receptive fields (RFs) are oriented Gabors, a substantial proportion exhibit globular or more complex structures.  
However, two aspects of the results on artificial data (Section 4) raise potential concerns:  
1. In Fig. 2C, the model learns all the true components but also an additional component that was not part of the data generation process. This extra component resembles the globular RFs characteristic of the model. Shouldn't it be concerning that the model "hallucinates" such a component in a simple artificial dataset devoid of these features? What do the artificial patches look like when this "dumpy" component is inferred? Additionally, what proportion of globular fields would emerge if the model were trained on noise inputs or occlusion-free natural image patches (e.g., textures)?  
2. On line 231, the authors state: "We assess the reliability of our learning algorithm by repeating the learning procedure with the same configuration but different random parameter initializations. The algorithm covers all the generative components in 11 out of 20 repetitive runs." Does this not imply that in nearly half of the cases, the training converges to an incorrect solution?  
- Clarity  
The paper is well-written, logically structured, and provides all the necessary details to comprehend the model and its results. A few minor suggestions for improvement:  
  - Line 232: Replace "access" with "assess."  
  - Line 319: Should "W" be "R"?  
  - Reference 34 appears to be unused.  
- Originality  
The primary innovation of the paper lies in extending OCA to incorporate translation invariance. Although inference in this model is intractable, the authors propose an efficient approximation using the Expectation Truncation technique. This also represents a technical improvement over other convolutional network approaches in terms of the number of components the model can learn.  
- Significance  
The paper demonstrates that complex nonlinear generative models can be trained efficiently on natural image patches. It remains to be seen whether the quantitative (components) and qualitative (globular RFs) improvements over existing invariant models will translate into enhanced performance on perceptual tasks.  
By extending the Occlusive Component Analysis model to include translation invariance and leveraging a variational approximation for training on natural images, the paper takes an important step forward. While the results largely confirm prior findings from OCA, the approach underscores the feasibility of sophisticated generative models for complex signals.