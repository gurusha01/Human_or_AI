The paper introduces a novel approach to interactive reinforcement learning, where human feedback is directly interpreted as policy labels.  
The manuscript is well-written and easy to follow. The proposed method is robust and appears to be grounded effectively in the existing literature.  
In my view, the strongest aspect of the paper is the simplicity of the proposed method, named Advise, which requires fewer meta-parameters compared to state-of-the-art methods. Moreover, the single meta-parameter, C (representing the estimated consistency of human feedback), is not highly sensitive. Combined with the results demonstrating that Advise performs on par with or better than existing approaches, this makes Advise a particularly compelling method.  
However, the paper also has some notable weaknesses, especially for a NeurIPS submission:  
The benchmark examples used for evaluation appear overly simplistic.  
Additionally, the theoretical contribution of the method compared to the state-of-the-art is relatively modest.  
Despite these limitations, I am inclined to slightly favor recommending acceptance of the paper, as the idea is interesting and the method itself is promising.  
A few minor issues to address:  
- Page 1, line 32 or 33 (PDF numbering appears slightly misaligned): "In this paper WE introduce..."  
- Page 2, line 75 or 76: "This is THE most common..."  
- Page 5, Table 1: The table is too small and could benefit from better formatting.  
- Pages 6-8, Figures 2-5: These figures are too small (at least in the printed version). The axis ticks are illegible, and the plots are too densely packed. While I understand the challenge of adhering to the NeurIPS page limit, improving figure readability is essential.  
- Page 7, line 373 or 374: "interpret feedback is as a direction" â€“ this phrase should be rephrased for clarity.  
In summary, the paper proposes an interesting method for interactive reinforcement learning that is simpler and requires fewer meta-parameters while achieving equal or better performance compared to state-of-the-art methods. However, it lacks significant theoretical innovation and evaluates performance only on relatively simple benchmarks.