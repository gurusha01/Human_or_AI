The authors address the challenge of sparse precision matrix estimation using CLIME and propose a scalable variant, CLIME-ADMM, complemented by a distributed computational framework. The paper includes empirical comparisons of the CLIME-ADMM algorithm with state-of-the-art methods such as DC-QUIC, Tiger, and Flare.
The notation is dispersed across Sections 1, 2, and 3, which could hinder readability. Consolidating all notations into a single table may improve clarity. For instance, symbols such as \(\rho\) and \(\eta\) are not explicitly defined in the text.
The block cyclic data distribution strategy is intriguing, but its ability to achieve load balancing and scalability is not immediately evident. Furthermore, there are no experimental results provided to substantiate this claim.
The algorithm appears to select the column block size in an ad hoc manner. Is there any theoretical justification or intuition behind the choice of \(k\)? Additionally, a broader concern is that the algorithm may not fully qualify as "distributed," as no explicit mechanisms for message passing or inter-process communication are described. It might be more appropriate to frame this as a parallel implementation.
Minor comments:
- Section 1: Replace "where \(\lambda\) is a tunning parameter" with "where \(\lambda\) is a tuning parameter."
- Section 5.1: Replace "As Tiger is parameter tunning free" with "As Tiger is parameter tuning free."
- Section 2: Replace "CLIME is summerized in" with "CLIME is summarized in."
The paper presents a large-scale parallel algorithm for sparse precision matrix estimation using CLIME. The key innovation lies in estimating the precision matrix by column blocks rather than column-by-column. Empirical results leveraging OpenMPI and ScaLAPACK are provided.