---Response to Author Response---
Thank you for the additional clarifications. I have just a couple of further points:
- While I agree that characterizing the class of problems with small optimal policy trees would be an interesting theoretical contribution, I believe the paper could better articulate the strengths and limitations of the proposed approach, even without fully addressing this question. Surely, the authors have some intuitive examples of scenarios where this algorithm excels and others where it may struggle. Including these insights would, in my view, significantly enhance the paper.
- Similarly, my question about DESPOT's use of prior information was not solely about whether it can exploit such information effectively. It is equally important to determine whether DESPOT depends on prior knowledge to perform well. From this perspective, an empirical comparison does not seem overly challenging; for instance, DESPOT could be tested with an uninformed default policy (e.g., uniform random). If it performs well, it would mitigate concerns about the necessity of a high-quality default policy. Conversely, if it performs poorly, it would highlight the types of problems where DESPOT may not be the best choice. Either outcome would add valuable insights to the paper without requiring substantial additional effort or space.
---Summary of Paper---
This paper introduces an online POMDP planning algorithm that integrates classical search techniques with Monte Carlo sampling to select actions. The core idea is to pre-sample random events (in the style of PEGASUS) within the roll-out tree and then compute a robust policy for the determinized future, with leaf values estimated using Monte Carlo simulations of a default policy. The policy search is regularized to favor "smaller policies" (those that revert to the default policy after a few steps), and the determinized tree is pruned using a heuristic branch-and-bound method to reduce computational overhead. Theoretical performance bounds are provided in terms of the number of samples, tree depth, and the size of the optimal policy on the tree. Experimental results demonstrate that the algorithm performs competitively on several large POMDPs compared to state-of-the-art methods.
---Quality---
The technical analysis appears sound, and the derived bounds provide useful insights into the algorithm's properties (though it is unclear how well these bounds hold when DESPOT is approximated). For the most part, the analysis aligns with the intuitions presented.
The main improvement I would like to see is a more thorough discussion of the approach's strengths and weaknesses, particularly in comparison to UCT-like methods such as POMCP. The introduction asserts that R-DESPOT has better worst-case behavior, but this advantage hinges on the assumption that the optimal policy tree is "small." The paper would benefit greatly from a deeper exploration of what this assumption implies. In what types of problems is a small policy tree likely to exist, and when might this assumption fail dramatically? My concern is that the reliance on a small policy tree may depend heavily on the choice of default policy (since a "small" policy is one that frequently defers to the default policy). This raises the question of whether the method's success is contingent on having a high-quality default policy. While leveraging simple optimal policies is a reasonable approach, it is unclear whether this is the best way to conceptualize simplicity. Clarifying what this assumption entails in terms of problem characteristics would strengthen the paper.
Additionally, I am concerned about the fairness of the experimental comparisons. R-DESPOT is provided with a domain-specific default policy in each experiment. While these policies appear intuitive and straightforward to specify, they still represent prior knowledge that is not made available to the competing methods. This makes it difficult to discern how much of the observed performance gap is attributable to the algorithm itself versus the choice of default policy. I do not believe this invalidates the results, but the paper should explicitly address this issue. For example, it would be reasonable to claim that R-DESPOT is particularly adept at leveraging prior knowledge that other methods cannot easily utilize. If this is the case, the claim should be clearly stated and supported with intuition. Even if it is challenging to provide comparable prior knowledge to other methods, I would have liked to see R-DESPOT's performance with a uniform random default policy. Even poor performance in this scenario would be informative, as it would clarify whether R-DESPOT is suitable for problems where no informed default policy is available.
---Clarity---
The paper is well-written and easy to follow. I found the mathematical exposition in the supplementary materials to be particularly clear and well-structured.
One minor suggestion: the paragraph at the end of Section 3 initially felt somewhat out of place. Upon reaching Section 4, it became clear that it was intended to foreshadow the R-DESPOT algorithm. This could be made more explicit with a statement such as, "We will use this idea in the next section to develop a more practical algorithm."
Typographical error near the bottom of page 1: "behavoior" should be corrected to "behavior."
---Originality---
While the proposed method builds on several established ideas, it combines them in a novel and compelling way. The paper situates the approach well within the existing literature.
---Significance---
Planning efficiently in high-dimensional, partially observable environments is both a critical and challenging problem. The proposed algorithm is grounded in theoretical performance guarantees and demonstrates strong empirical results. While I still have questions about the reliance on prior knowledge, there are certainly domains where such knowledge is available. The algorithm's primary potential for impact lies in its presentation of a viable alternative to UCT-like methods and its introduction of a distinct analytical perspective. This work could inspire further advancements in this area. The paper is clear, the problem is important, and the method is innovative, interesting, and reasonably well-evaluated. I therefore recommend acceptance. However, I strongly encourage the authors to enhance the paper by including a more intuitive discussion of the algorithm's strengths and weaknesses and revising the experimental section to explicitly address the role of prior knowledge in the observed performance differences.