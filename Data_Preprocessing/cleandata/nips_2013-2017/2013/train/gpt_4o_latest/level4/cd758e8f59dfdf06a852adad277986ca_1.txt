The paper addresses the problem of estimating the cluster tree when the probability density function is supported on a d-dimensional manifold embedded in a D-dimensional ambient space. The authors demonstrate that the RSL algorithm proposed in (1) is consistent, and its convergence rate, broadly speaking, depends on the intrinsic dimension d of the manifold rather than the ambient dimension D. However, the convergence rate also depends on the condition number τ and includes an ε^{d+2} term instead of the ε^2 term seen in simpler settings.
The primary contribution of the paper is achieved by extending the methodology from (1). To accomplish this, the authors establish two key results: first, a bound on the size of an s-net in the manifold setting, and second, bounds on the deformation of volume (i.e., showing that B(x, r) ∩ M has approximately the volume of a d-dimensional ball of radius r, where d is the manifold's dimension). Both results are derived under the assumption of a small condition number.
I find it valuable to explore how the convergence rate changes under the manifold assumption, and the paper provides both nontrivial lower and upper bounds. While the convergence rate depends on quantities that are not directly observable (such as the manifold's dimension and the condition number), the results are still intriguing.
However, I found the writing to be unclear, and some definitions are confusing or imprecise:  
*  
1) The statement in Theorem 4 is incorrect. A significantly stronger result is proven in Theorem 6 of [1] compared to Definition 3-consistency (see also the remark following Theorem 6 in [1]).  
Theorem 6 states that, with high probability, uniformly for every pair A, A' satisfying (σ, ε)-separation, we achieve both separation and connectedness.  
Theorem 4, on the other hand, claims that for every pair A, A' satisfying (σ, ε)-separation, we achieve separation and connectedness with high probability.  
These two statements are not equivalent. Please revise this.  
*  
2) In Definition 3, the notation is unclear: What is n? What is C_n (is it a random variable? How is it defined? Is it distinct from ĥC?)? I had to refer back to the definition in (1) to infer the intended meaning.  
3) In the use of Lemma 16, it would be helpful to explicitly index and reference the inequalities applied at each step. Not all steps are transparent. For instance, in the final step, it seems that you use the inequality (1 + 4r/τ)(1 + 4r/τ) < (1 + 6r/τ), but this is not even hinted at. The derivation should be clarified.  
4) In Lemma 18:  
- It appears that a factor of 1/2 is missing from the definition of v_cap.  
- It would also be helpful to explicitly mention that Γ(1/2) = √π, as its omission makes the derivation unclear.  
Further suggestions:  
- The lower bound derived in the paper depends on the condition number τ. It might be worth explicitly noting that this lower bound does not improve upon the lower bound in (1) but instead differs in its applicability. For example, in the case of a linear subspace with 1/τ = 0, the lower bound in this paper becomes meaningless, whereas the bound from (1) remains valid.  
- Regarding the parameter ρ, does it make sense to choose the salience parameter such that 2σ > τ? Would it not be simpler to assume (3σ/16) < (τ/16)?  
The authors provide an interesting generalization of results to the manifold setting, particularly through their bounds on the s-net. However, the paper is not sufficiently clear, and Definition 3 appears to be incorrect.