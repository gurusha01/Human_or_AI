Review - Variance Reduction for Stochastic Gradient Optimization  
NOTE: Due to the large number of papers to review and the limited time available, I did not attempt to verify the correctness of the results. Consequently, I primarily focused on the main paper and did not delve into the proofs or additional details provided in the supplementary material. This review should therefore be considered an evaluation of the main paper alone.  
This paper introduces a method leveraging control variates to reduce the variance of gradient steps in stochastic gradient descent (SGD) procedures. The proposed approach relies on a structured correlation to achieve variance reduction, distinguishing it from the averaging method commonly used in minibatching. The intuition behind the method is clear, and the paper is generally well-written. While the contribution appears to be somewhat novel (though the concept itself is not entirely new), I believe the NIPS audience will find it valuable.  
STRENGTHS:  
- Proposes a method to enhance the performance of SGD that differs from minibatching and applies it to a specific problem.  
- Experimental results demonstrate that the method is effective, making it a useful addition to the toolkit for SGD optimization.  
WEAKNESSES:  
- The paper does not provide sufficient clarity on how control variates could be constructed for other problems.  
COMMENTS:  
This is a well-executed, implementation-focused paper that addresses a significant challenge with SGD—its theoretical appeal versus its practical challenges. While the presentation is convincing, some of the claims feel slightly overstated.  
One concern is the question of novelty. The authors acknowledge that control variates have been used in other contexts, but they fail to cite a relevant recent work by Paisley et al. (ICML 2012), which also employs control variates for variance reduction in gradient estimation, specifically in the context of HDPs. While it is understandable that keeping track of all related literature can be challenging, the novelty of this work in comparison to the ICML paper remains unclear.  
Additionally, some experimental details appear somewhat arbitrary (e.g., the choice of a minibatch size of 100). As a result, the comparisons between this method and minibatching feel overstated. The approach of "Algorithm A outperforms Algorithm B on these datasets" lacks depth, particularly when it is based on a single run with fixed learning rates. Would tuning the learning rates change the results? It is unclear. Instead, the authors should focus on exploring the extent to which their method provides benefits, as well as identifying scenarios where diminishing returns or practical trade-offs may arise.  
For example, the statement "It can be shown that, this simpler surrogate to the A∗ due to Eq. 6 still leads to a better convergence rate" would benefit from explicit references to the supplementary material (if a proof exists) or should be omitted if such a proof is not provided.  
Another question is whether this method works exclusively with proper gradients or if it can also be applied to subgradients.  
TYPOS/SMALL ITEMS:  
- Line 058: "discussion on"  
- Before Equation (4): Clarify that $h$ can depend on $g$.  
ADDITIONAL COMMENTS AFTER THE REBUTTAL:  
- Regarding novelty, my concern is more about the tone than the substance. While the use of control variates for variance reduction is not new (as the authors themselves acknowledge), I agree that the current application is sufficiently distinct from the ICML paper referenced above.  
- Since my comments were not extensive, I am satisfied with the authors' response and have adjusted my score accordingly.  
This paper introduces a method using control variates to reduce the variance of gradient steps in stochastic gradient descent. I believe the contribution is novel (though the concept is well-known in the control literature), and the NIPS audience is likely to find it valuable.