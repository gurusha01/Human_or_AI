This paper presents a method for identifying Bayesian networks for continuous variables in high-dimensional settings. The approach assumes that any given random variable follows a Gaussian distribution when conditioned on its parent nodes. To construct a sparse set of parent nodes for each random variable, the authors employ a LASSO objective function, subject to an additional constraint ensuring the resulting structure forms a directed acyclic graph (DAG). The structural constraint is formulated as an ordering problem, and the authors propose an A search algorithm to identify a DAG that maximizes the LASSO objective function. The unconstrained LASSO objective function is utilized as an admissible heuristic within the A search. Since this search remains computationally expensive for graphs with a large number of nodes, the authors introduce a method to further prune the search space.
The paper is well-written, with clear motivation and sufficient detail to enable third-party implementation.
The use of the LassoScore for optimization within the dynamic programming algorithm, combined with the unconstrained LassoScore as a heuristic function, is innovative. The simulation studies effectively demonstrate that the approximate version of the proposed algorithm significantly outperforms standard greedy approaches, while maintaining fast runtimes even for large networks. The performance graphs indicate that substantial pruning of the search space results in only minimal performance degradation compared to the optimal solution.
Although the paper describes the method as learning network structures for continuous variables, the use of a linear regression model with fixed noise error for conditional distributions (section 2.1) implies an assumption of linear Gaussian relationships for the random variables. This appears to be a strong assumption; however, as noted in the rebuttal, recovering structure is challenging even in Gaussian networks.
The application discussed in section 3.1 is somewhat unclear, particularly regarding how stock price data is represented as a Bayesian network. The reviewer is unfamiliar with the use of Bayesian networks in stock market analysis, and it is not immediately evident to a general audience what type of model is employed or why stock market data would exhibit a specific network structure. The references mentioned in the rebuttal should be incorporated into section 3.1 to address this gap.
Overall, this is a strong paper that leverages the relationship between DAG structures and the ordering of random variable dependencies to implement a clever A* algorithm for optimizing a constrained LASSO objective function. The resulting algorithm is both efficient and accurate, successfully recovering network structures in synthetic data generated from the proposed model.