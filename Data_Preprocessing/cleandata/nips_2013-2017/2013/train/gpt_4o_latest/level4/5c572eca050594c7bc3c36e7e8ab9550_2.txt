This paper introduces two novel methods for estimating the density ratio between two probability distributions. The first method leverages the importance sampling equation, reformulating it as a regularization problem involving the L^2 norm of the deviation from equality and a reproducing kernel Hilbert space (RKHS) regularization term, corresponding to a Type I Fredholm equation. The second method employs a kernel-based approach where the locality parameter must approach zero to ensure consistency. This method is also expressed as a regularization problem, corresponding to a Type II Fredholm equation. The paper provides theoretical results on convergence and validates the practical utility of the proposed methods through experimental evaluations.
Although the proposed methods share similarities with existing approaches like Kernel Mean Matching (KMM), a key advantage lies in the L^2-based formulation, which enables the use of cross-validation (CV) for parameter selection. In contrast to supervised learning, where CV is a standard technique for parameter tuning, there are no widely accepted methods for unsupervised learning. This paper addresses this gap for density ratio estimation by cleverly utilizing the L^2 norm. 
It would be beneficial to note that objective functions defined in RKHS, such as those in KMM, are unsuitable for kernel selection using CV because the values of the objective function depend on the kernel, making them incomparable.
In Theorem 1, the convergence rate derived includes a (-t/log λ) factor, which results in a slow rate when t is fixed. In much of the kernel methods literature, a polynomial convergence rate with respect to sample size can often be achieved under fixed t by appropriately fixing the rate of λ. Could the authors explore reasonable additional assumptions that might yield a polynomial rate for the proposed estimator? For instance, Caponnetto and De Vito (2007) derive optimal rates for kernel ridge regression by imposing assumptions on the spectrum of the operator K_{p,t}. Similarly, stronger assumptions on q/p might enable the derivation of a polynomial rate. It would enhance the paper if the authors discussed such rates under stronger assumptions with fixed t.
In density ratio estimation, it is typically necessary to assume that q/p belongs to a well-behaved function class, such as a Sobolev space. However, this assumption is quite restrictive, as it requires prior knowledge about the ratio or the tails of p and q. Moreover, under such assumptions, the inverse ratio p/q often exhibits poor behavior. The paper should include a discussion of this limitation of density ratio estimation.
Although not mandatory, the supplementary materials require improvement. Numerous typos and minor errors make it difficult to verify the correctness of the theoretical results presented in the main paper. For example, in Lemma 5, W2^2 should be Ws^2, and the bound should read D1 (t/-log λ)^2 + λ^{1-α} D2 \|f\|_2^2. Additionally, the expressions on lines 675 and 686 are incorrect, while Eq. (31) is accurate. In the proof of Lemma 5, the domain of integration on line 1147 should be \|\xi\|^2 ≥. Since the theoretical convergence results are a major contribution of this paper, I strongly recommend that the authors revise and correct the supplementary material.
References:  
Caponnetto A., De Vito E. Optimal Rates for Regularized Least-Squares Algorithm. Foundations of Computational Mathematics, 7, 331–368 (2007).
In summary, this paper presents a novel approach to density ratio estimation, with the significant advantage that CV can be effectively utilized for parameter selection.