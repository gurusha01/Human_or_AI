This paper presents a commendable contribution to an important problem area. It proposes a simple, practical algorithm that is easy to implement, and the empirical results are strong. The theoretical analysis is thorough and transparent, acknowledging that the approach may not always perform optimally but that the underlying assumptions are reasonable for typical learning tasks.
My primary critique is that the paper feels constrained by space limitations. The experimental section, in particular, is overly concise, with insufficient explanation of the baseline comparison methods and limited discussion of the results. (For instance, Figure 1 is overly dense and difficult to interpret.) The strong performance of the greedy/max approach is intriguing and merits further discussion. Additionally, the paper lacks any discussion of runtime or CPU cost for the proposed and baseline methods, which is surprising for a paper emphasizing scalability. This omission should be addressed.
Another notable gap is the limited discussion of lazy evaluation, which appears to offer significant efficiency gains. This practical technique should be highlighted, especially in a paper focused on scalability, as it could be valuable for engineering-oriented readers who may not be familiar with it. Furthermore, I wonder whether combining lazy evaluation with a MapReduce framework could serve as an alternative to the proposed approximation method. While the first round of selection may be computationally expensive, subsequent rounds could be made highly efficient (e.g., evaluating the next 100 candidates in parallel). Although the first paragraph of Section 3.2 suggests this approach is impractical for large k, large k is inherently computationally expensive, so this tradeoff might still be worth exploring.
The concept of "diminishing returns" should also be introduced earlier, ideally in the introduction or the beginning of Section 3, as it provides an intuitive explanation of submodularity for readers unfamiliar with the concept.
Another point of ambiguity is the phrase "fit on one machine." It is unclear whether this refers to fitting in RAM, on disk, or within CPU processing constraints. The first paragraph of Section 2 implies that CPU cost is the primary bottleneck, but disk I/O is often equally significant. It would also be helpful to discuss the potential benefits of using a large-RAM machine with multiple cores (e.g., 16 or more).
To make room for the additional details I am requesting, I suggest the following cuts:
- Section 6 can be removed entirely, as it does not add substantial value to the paper.
- The pseudo-code for Algorithm 1 can be omitted.
- In Section 1, the first two sentences of the third paragraph and its last sentence can be cut, with the remaining sentence merged into the preceding paragraph.
- The first paragraph of Section 2 can be significantly condensed.
- Paragraphs 2 and 3 of Section 3.2 can be removed. (However, the naive approach of sampling the dataset to fit on one machine and running the standard algorithm could be briefly mentioned here.)
Overall, the paper introduces a simple yet novel method for submodular maximization in a distributed framework. It demonstrates theoretical soundness under reasonable assumptions and achieves strong empirical results across various applications.