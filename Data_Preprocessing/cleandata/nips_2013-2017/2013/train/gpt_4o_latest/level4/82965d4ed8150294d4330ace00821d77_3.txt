The authors propose a set of techniques aimed at reducing both memory storage requirements and computational costs associated with applying linear templates. Their approximation methods achieve notable speed-ups without substantial accuracy loss. Furthermore, the authors explore trade-offs between speed and accuracy by varying factors such as the number of quantization levels, the choice between 16-bit and 32-bit arithmetic, and the decision to re-score windows or not. Specifically, the core idea involves replacing the convolution operation with a look-up table. To optimize this approach, the authors employ k-means clustering for quantization, effectively reducing dimensionality (with Fig. 2 demonstrating the superiority of k-means over PCA). Additionally, the paper introduces computational models that highlight the speed-up achieved by the proposed methods compared to state-of-the-art detection algorithms on Pascal VOC 2007. Similar conclusions are drawn from experiments conducted on exemplar SVM.
Reference [2] appears to be the most relevant prior work but is not cited in the paper, leaving a critical comparison absent. Much of the groundwork overlaps with [2], which diminishes the novelty of the contribution. Specifically, [2] introduces an approximation of filters using sparse coding, as well as the use of nearest neighbor and PCA approaches.
While the proposed idea is both interesting and impactful in accelerating detection tasks, the contribution feels overly incremental. The replacement of the dot product in the convolution operator has already been explored in [1]. Furthermore, [2] demonstrates significant speed-ups using a sparse intermediate representation and a nearest neighbor approach to retrieve the closest part filters, with PCA also serving as a baseline. The scalability of the proposed method with an increasing number of classes is a notable strength. Additionally, [3] achieves considerable speed-ups and appears to complement the proposed method, aligning with the "cascade" section of the paper.
Pros:  
+ The authors address the critical problem of accelerating the convolution step, which is central to many detection systems.  
+ The proposed method effectively balances accuracy and speed.  
+ The simplicity of the approach is appealing.  
+ The authors have committed to releasing the source code.  
+ The paper is generally well-written.  
Cons:  
- The paper's contribution is incremental.  
- The experiments presented in Tables 1, 2, and 3 are unclear. For instance, the reported total time for the same method varies across tables. The authors should clarify how they estimated the running time of inaccessible algorithms.  
- It is unclear which specific approximation technique (e.g., simple look-up table, packed look-up table, 16-bit arithmetic, deformation estimates) contributes most to the speed-up. The authors should conduct experiments to isolate and evaluate the importance of each technique.  
- Implementation details are insufficiently described. The authors should specify the programming language used for each method in the experiments, along with any "programming tweaks" applied.  
References:  
[1] "Fast, Accurate Detection of 100,000 Object Classes on a Single Machine" by T. Dean et al.  
[2] "Sparselet Models for Efficient Multiclass Object Detection" by H. Song et al.  
[3] "Branch and Rank: Efficient, Non-linear Object Detection" by A. Lehmann et al.  
In summary, while the paper is significant for its contribution to speeding up the convolution step, the proposed idea lacks novelty and appears to be incremental.