Review - Overview  
The paper introduces a lower bound on the expected performance improvement for policy gradient methods, which can subsequently be utilized to optimize the step-size. The bound is presented in a general form, then tailored for Gaussian policies, and finally adapted for REINFORCE and G(PO)MDP/PGT. The approach is empirically validated on a simple LQG problem.
Quality  
The theoretical contribution is substantial and well-developed. The experiment effectively demonstrates the proposed approach. While it would be fascinating to see how the adaptive step-size performs in motor control and robotics applications, this is understandably beyond the scope of the current work.
Clarity  
The paper is well-written and successfully explains the origins and proofs of the theorems and lemmas. I appreciate the paper's structure, which transitions from theoretical foundations to more applied aspects. However, the final section (Sect. 6) feels somewhat condensed and rushed.
Originality  
To the best of my knowledge, this is the first work to explore adaptive step-sizes for policy gradient methods from a theoretical perspective.
Significance  
Although tighter bounds would be desirable (as noted in Sect. 6), the results are theoretically intriguing and show promise in the experimental evaluation.
Minor Comments:  
- Table 1: Consider adding a row with the optimal step-size (determined via line search, as discussed in Sect. 1).  
- Line 75: The phrase "do not need to tune a free parameter" could be misleading. While these algorithms lack a step-size parameter, other parameters, such as the exploration magnitude, still require tuning.  
- Table 1: Highlight the "winners" for clarity.  
- Table 1: The result of 1 step for alpha* with sigma=5 seems implausible and may be a fortunate coincidence.  
- Table 2: Clarify how iterations are counted—does this refer to the number of update steps or (number of update steps) × (number of trajectories)?  
- Table 2: Consider using scientific notation (e.g., 1e5) instead of ">100,000."  
- Table 2: A comparison to heuristic approaches would be particularly insightful here.  
- Supplementary Material (Fig. 1 & 2): A logarithmic scale for the iteration axis could improve visibility of early-stage behavior (e.g., alpha=1e-5/t). Adding axis labels would also enhance clarity.
Public Review:  
The author response adequately addresses most of the points raised. Spelling, grammar, and minor formatting/LaTeX suggestions have been omitted here. The paper addresses an important open problem from a theoretical perspective and achieves results with significant potential for practical applications.