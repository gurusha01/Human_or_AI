This paper establishes theoretical bounds on the performance of a convex tensor decomposition algorithm regularized by the latent Schatten norm, offering an improvement over prior results obtained using the overlapped Schatten norm for regularization.
Quality: The paper derives theoretical results for tensor decomposition with the latent Schatten norm, and the dual characterization of the overlapped and latent Schatten norms is particularly noteworthy. However, the experimental section is quite brief and lacks sufficient detail. For example, how were the Tucker ranks \((r1, \ldots, rk)\) of the examples selected? How does group regularization, such as \(l_{1,\infty}\), behave when the tensor exhibits low rank across all modes simultaneously? Additionally, how does the proposed method compare to non-convex approaches in terms of performance?
Clarity: The paper is well-structured and clearly presented, making it easy to follow.
Originality: The primary novel contribution of the paper is the duality result between the overlapped and latent Schatten norms, which appears to be of independent interest.
Significance: Tensor decomposition is a critical problem with applications in various domains. By improving upon existing results for this problem, the paper makes a meaningful contribution. The theoretical findings are compelling, and the paper is well-written overall. However, the experimental evaluation is limited and only briefly discussed in the latter part of the paper.