The paper introduces a novel definition of total variation on hypergraphs, establishes its convexity and connection to cuts, explores applications to learning and normalized cuts (for clustering), derives proximity operators for use in optimization algorithms, and provides numerical experiments benchmarking against Zhou's 2006 method. The paper spans multiple sub-disciplines, presenting numerous ideas and a few theorems (though, as expected, it does not address global solutions for the normalized cut problem, which remains an open challenge). Despite the breadth of material, the paper maintains focus and is generally well-written, with only minor grammatical issues.
Section 5 aligns most closely with my expertise, and I find it satisfactory. However, I am less familiar with prior work on spectral clustering and hypergraph-based approaches. The authors claim this paper represents the first significant advancement in seven years (since Zhou [11]), and while I am inclined to believe this, I cannot be entirely certain. If this claim holds, the paper warrants acceptance and will likely gain recognition. That said, I am somewhat skeptical that no more recent work than [11] has been cited, given the attention this area has received (or perhaps the focus has shifted to tensors, leaving hypergraphs underexplored?).
Additional comments:  
- Comparisons are limited to [11], which uses the same hypergraph framework and reduces it via the CE technique to a graph problem. However, problems like SSL and clustering can be approached from entirely different perspectives. Including a comparison with an alternative approach, even a simple one like k-means for clustering (or explaining its inapplicability), would strengthen the paper. The recursive cluster-splitting approach used here is clearly suboptimal (though it is a standard technique).  
- Line 121: The phrase "the optimal cut" should be revised to "an optimal cut," as the symmetry of the problem implies that a mirror-image cut would also suffice.  
- The discussion surrounding Theorem 4.1 is somewhat vague and would benefit from additional clarification. For instance, the application of the second equation in the theorem is unclear.  
- The term "tight relaxation" (mentioned in Section 4 and the introduction) is ambiguous. If it refers to "the tightest," the authors should define the class of relaxations being considered, as it is not the class of convex functions in this case. Alternatively, if it means "tighter than the linear eigenproblem relaxation," this should be justified. For graphs, such claims are supported by empirical evidence; for hypergraphs, deriving the linear relaxation and testing it would provide similar justification.  
- Section 5: The method in [24] has been significantly extended, as noted in works like Condat 2011 (http://www.optimization-online.org/DB_HTML/2011/12/3284.html). Notably, [24] can handle smooth functions, which often yield better convergence rates by leveraging derivatives rather than proximity operators. For the first G term in Table 1, why not treat it as a smooth term? Additionally, on line 276, the phrase "the main idea" (repeated three times on this page) is not well-articulated, as the described concept is not unique to [24]. Instead, [24] allows for the separation of multiple terms.  
- Regarding TV on a grid (2D), isotropic TV is often preferred despite lacking a closed-form proximity operator or efficient computation algorithm. Anisotropic TV, while simpler to work with, is more commonly used. The TV definition in this paper appears to generalize anisotropic TV. It would be intriguing to explore whether an isotropic TV definition for hypergraphs is feasible.  
- Proposition 5.1: The sorting step results in O(n log n) complexity. Could the sort be avoided by simply finding the largest and smallest entries of the input? This would reduce complexity to O(n). While handling cases with multiple max/min values might be challenging, it could still be feasible.  
- Experiments: These are well-executed overall. However, when constructing hypergraph edges based on data points with identical feature values, would it not be advantageous to also create edges (albeit with lower weights) for points with similar feature values?  
- The table on page 8 lacks an explanation of its entries. Are they some form of error metric? Clarification is needed.  
- Line 415: The statement "Our method... minimizes the normalized cut on the hypergraph" is misleading. Since a convex method is applied to a nonconvex problem, the best-case scenario would be reaching a stationary point or local minimum. The phrasing should be adjusted to "attempts to minimize."  
Grammar:  
- Lines 276 and 301: Replace "proximum" and "proxima" with "proximity operator," as the former terms are not standard.  
- Line 416-417: The phrasing is awkward and should be revised.  
- The authors frequently use the construction "allow to" and its variants (e.g., "suggest/recommend to use," "favor to split off," "propose to solve"). These should be corrected to use gerunds, such as "suggest using" instead of "suggest to use." For example, "Hypergraphs allow to encode" should be revised to "Hypergraphs allow one to encode."  
- The word "however" is occasionally misused. For instance, on line 199, "however" should be replaced with "hence," and on line 408, it should be replaced with "thus."  
In conclusion, this paper introduces a significant topic and explores it thoroughly, yielding promising results. The numerical experiments are well-conducted, and the method compares favorably to Zhou's 2006 approach. My primary concern is the potential omission of recent work on hypergraphs from the past seven years, which could provide further context or improvements over [11].