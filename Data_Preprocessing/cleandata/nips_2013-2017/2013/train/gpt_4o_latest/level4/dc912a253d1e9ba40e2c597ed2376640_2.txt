This paper integrates a recent advancement in stochastic dual coordinate ascent with the conventional parallelization strategy of assigning a mini-batch of examples to each process and averaging the resulting gradients. While this combination is innovative, the most significant contribution lies in the derived trade-off bounds between communication and computation. This work is poised to be influential, as it introduces a novel methodology. However, its impact is limited by poorly designed experiments. Specifically, the authors fail to address the role of input dimensionality in the bounds, particularly in scenarios involving sparse data, which is a common characteristic of big data.
Two major limitations affect the significance of the proposed trade-off:
- In the discussion on page 5, the authors neglect to account for the number of dimensions, denoted as \(d\). For dense data, \(d\) could be treated as a constant factor since both communication and computation costs are linear in \(d\) (assuming the main computational loop involves \(W \cdot x\), which is \(O(d)\)). However, in the case of sparse data, the computation cost for a single dot product scales with the number of non-zero features, denoted as \(d'\). Consequently, the total computation cost per iteration becomes \(O(m \cdot d')\). In the worst-case scenario, where no features overlap among the \(m\) examples, the communication cost also scales as \(O(m \cdot d')\), undermining the critical \(m\)-ratio analysis presented on page 5. For instance, in the KDD Cup dataset, only one feature out of one million is non-zero.
- The experiments focus solely on the number of iterations, disregarding the total runtime, which includes communication latency. Furthermore, the time per iteration depends on the parameter settings. As a result, the experiments in Figure 3, which suggest that increasing \(m\) always reduces the number of iterations, are misleading. Each iteration incurs a computation cost of \(O(m \cdot d)\) and a communication cost of \(O(d)\). A more convincing evaluation would include a curve showing the total training time, with specific values of \(m\) and \(K\) that minimize this time.
In summary, the experimental results lack significance, as they merely demonstrate a reduction in the number of iterations as a function of \(m\) and \(K\)—a trivial observation that does not require Theorem 1. Additionally, the authors provide only limited details about the experimental setup, mentioning openMPI without clarifying the architecture:
- Is the setup a cluster? If so, how many nodes and cores per node?
- Is it a single multicore system? If shared memory is used, communication costs would be negligible.
The most intriguing insight from Theorem 1 is the existence of an "effective region" for \(K\) and \(m\). However, the experiments only show that decreasing \(\lambda\) expands the range of \(m\) and \(K\). A more impactful result would involve identifying an effective upper threshold for the \(mK\) product, supported by actual training times.
Detailed Comments:
- Tens of hundreds of CPU cores: Does this mean thousands of cores or tens of clusters with hundreds of cores? If communication costs are relevant, the target should be clusters, not multicore systems with shared memory.
  
- Proof of Theorem 1: While the proof is correct and straightforward from the bound \(E(\epsilonD^t)\), the remainder of the proof appears unnecessary. The final sentence is particularly confusing, as there is no mention of \(T0\):  
  "We can complete the proof of Theorem 1 for the smooth loss function by plugging the values of \(T\) and \(T_0\)."  
  There seem to be extraneous lines unrelated to the proof.
- Parameter-free claim: The authors repeatedly claim that DisDCA is parameter-free, but the choice of \(\lambda\) is crucial.
- Terminology (P3, l128): The text suggests that \(\alpha\) is the dual variable associated with \(w\), not \(x\). This may be a matter of terminology.
- Figure 3:  
  - Typo: "varing" → "varying."  
  - The plots are difficult to read.
This paper presents a highly interesting new algorithm with a theoretical derivation of a communication/computation trade-off. Unfortunately, the experiments fail to adequately demonstrate this trade-off.