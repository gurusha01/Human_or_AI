This paper addresses the problem of estimating continuous quantities using crowdsourcing, with a focus on optimizing the number of control items (questions with known answers) to balance worker evaluation and target item accuracy. The authors present theoretical and empirical analyses for two consensus methods: a two-stage estimator and a joint estimator. They derive rules of thumb for practitioners, showing that the optimal number of control items scales as \(O(\sqrt{\ell})\) for the two-stage estimator and \(O(\ell/\sqrt{nt})\) for the joint estimator, where \(\ell\) is the number of items each worker answers, and \(nt\) is the number of target items. The paper also explores the impact of model misspecification and applies its findings to real-world datasets.
Strengths:
1. Clear Problem Definition and Motivation: The paper addresses a practical and well-motivated problem in crowdsourcing, providing actionable insights for practitioners.
2. Theoretical Rigor: The authors present detailed mathematical analyses for the two-stage and joint estimators, deriving closed-form solutions and asymptotic results under different models (bias-only, bias-variance, and variance-only).
3. Empirical Validation: The theoretical predictions are validated through simulations and experiments on real-world datasets (price estimation and NFL game forecasting), demonstrating the practical relevance of the findings.
4. Novel Contributions: The paper provides new insights into the trade-offs between control and target items, as well as the sensitivity of consensus methods to model misspecification. The scaling rules for optimal control item allocation are particularly valuable.
5. Practical Implications: The results are presented in a way that is accessible to practitioners, offering clear recommendations for different scenarios.
Weaknesses:
1. Model Assumptions: The paper assumes Gaussian models for worker biases and variances, which may not fully capture the complexity of real-world crowdsourcing data. While the authors acknowledge this limitation, more discussion on alternative models or robustness to non-Gaussian data would strengthen the work.
2. Sensitivity to Model Misspecification: The joint estimator is shown to be highly sensitive to model misspecification, but the paper does not provide concrete strategies for mitigating this issue beyond switching to the two-stage estimator. Further exploration of robust methods would be beneficial.
3. Limited Scope of Real-World Experiments: While the experiments on real datasets are valuable, they are limited to two domains. Additional datasets from other application areas (e.g., medical diagnosis or image labeling) would enhance the generalizability of the findings.
4. Complexity of Practical Implementation: The theoretical results rely on assumptions about random bipartite graph structures and asymptotic conditions, which may not always hold in practice. More discussion on how to adapt these results to irregular or sparse worker-item assignments would be helpful.
Recommendation:
I recommend acceptance of this paper, as it makes a significant contribution to the field of crowdsourcing and provides both theoretical insights and practical guidance. While there are some limitations in terms of model assumptions and sensitivity to misspecification, the strengths of the paper outweigh these concerns. The work is likely to be of interest to both researchers and practitioners, and it advances the state of the art in understanding the trade-offs in crowdsourced estimation tasks.
Pro and Con Arguments for Acceptance:
Pros:
- Rigorous theoretical analysis with clear practical implications.
- Empirical validation on both synthetic and real-world datasets.
- Novel insights into the trade-offs between control and target items.
- Practical rules of thumb for practitioners.
Cons:
- Sensitivity of the joint estimator to model misspecification.
- Limited exploration of alternative models and robustness.
- Narrow scope of real-world experiments.
Overall, this paper represents a valuable contribution to the field and should be presented at the conference.