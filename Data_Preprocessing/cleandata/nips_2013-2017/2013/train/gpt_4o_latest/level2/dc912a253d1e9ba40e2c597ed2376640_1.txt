The paper presents a Distributed Stochastic Dual Coordinate Ascent (DisDCA) algorithm for solving Regularized Loss Minimization (RLM) problems in distributed environments. The authors claim three main contributions: (1) the development of DisDCA with convergence guarantees for smooth and non-smooth loss functions, (2) an analysis of the tradeoff between computation and communication, and (3) empirical validation of DisDCA's effectiveness compared to distributed stochastic gradient descent (SGD) and alternating direction methods of multipliers (ADMM) for optimizing SVMs. The paper also introduces a practical variant of DisDCA that leverages updated local information for faster convergence.
Strengths:
1. Novelty and Significance: The paper addresses a notable gap in distributed optimization by extending stochastic dual coordinate ascent (SDCA) methods to distributed settings. The focus on the tradeoff between computation and communication is timely and relevant for large-scale machine learning applications.
2. Theoretical Rigor: The convergence analysis is thorough, with clear derivations of bounds for both smooth and Lipschitz-continuous loss functions. The effective region of parameters (m, K) is well-characterized, providing practical insights for algorithm deployment.
3. Empirical Validation: The experiments on real-world datasets (covtype and kdd) are comprehensive, demonstrating the algorithm's scalability and competitive performance against SGD-based and ADMM-based baselines. The practical variant of DisDCA shows significant improvements over the basic variant.
4. Clarity of Contributions: The paper clearly delineates its contributions, particularly in the context of prior work on distributed SGD and ADMM.
Weaknesses:
1. Limited Novelty in Practical Variant: While the practical variant of DisDCA shows empirical improvements, its novelty is somewhat limited as it builds on standard ideas of leveraging updated local information. The theoretical convergence analysis for this variant is also missing, which weakens its contribution.
2. Comparison with Related Work: Although the paper compares DisDCA with SGD and ADMM, it lacks a deeper discussion on how DisDCA differs fundamentally from other distributed SDCA approaches, such as those by Tak√°c et al. (2013). This could help clarify its unique contributions.
3. Parameter Sensitivity: The analysis of the tradeoff between computation and communication is insightful, but practical guidelines for choosing m and K in real-world scenarios are not provided. This could limit the algorithm's usability for practitioners.
4. Clarity of Presentation: While the theoretical sections are detailed, the dense mathematical exposition may be challenging for readers unfamiliar with SDCA. Simplifying or summarizing key results could improve accessibility.
Pro and Con Arguments for Acceptance:
- Pro: The paper provides a significant extension of SDCA to distributed settings, with strong theoretical guarantees and competitive empirical results.
- Con: The practical variant lacks theoretical analysis, and the novelty over existing distributed SDCA methods is not fully established.
Recommendation: Accept with Minor Revisions. The paper makes a meaningful contribution to distributed optimization, but the authors should address the theoretical gap for the practical variant and provide clearer comparisons with related work. Additionally, practical guidelines for parameter selection would enhance the paper's impact.