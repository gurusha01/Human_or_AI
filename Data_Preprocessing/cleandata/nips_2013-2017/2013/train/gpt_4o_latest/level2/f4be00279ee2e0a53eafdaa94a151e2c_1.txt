The paper presents a novel approximate inference algorithm for continuous-time Gaussian Markov process models that integrates both discrete and continuous-time likelihoods. The main contribution is the derivation of a hybrid fixed-point iteration algorithm combining expectation propagation (EP) updates for discrete-time terms and variational updates for continuous-time terms. The authors extend the Kalman-Bucy smoothing procedure to non-Gaussian observations, enabling its application to models such as spiking neuronal models and box likelihood models. Experimental results demonstrate the algorithm's high distributional accuracy and computational efficiency compared to discrete-time approaches, particularly in neural applications.
Strengths:
1. Novelty and Originality: The paper addresses a significant gap in the literature by proposing an inference algorithm that operates in the continuous-time domain, a problem that has been largely unexplored in the statistical machine learning community. The hybrid algorithm combining EP and variational updates is innovative and well-motivated.
2. Technical Soundness: The derivation of the continuous-time limit of the EP algorithm is rigorous, and the authors provide detailed explanations of the fixed-point updates and their convergence properties. The use of corrections to improve marginal approximations is a valuable addition.
3. Practical Significance: The method is demonstrated to be computationally efficient and accurate, making it suitable for real-world applications such as neural spike train modeling and point process inference. The ability to handle continuous-time data naturally is a significant advantage over traditional discrete-time approaches.
4. Experimental Validation: The experiments on synthetic and real-world datasets (e.g., neural spike trains) convincingly demonstrate the method's effectiveness. The comparison with MCMC sampling and discrete-time methods highlights the proposed algorithm's strengths in terms of accuracy and computational savings.
Weaknesses:
1. Clarity: While the technical derivations are thorough, the paper is dense and may be challenging for readers unfamiliar with expectation propagation or stochastic differential equations. Simplifying some explanations or providing more intuitive summaries could improve accessibility.
2. Limited Scope of Applications: The experiments focus primarily on neural and point process models. While these are important applications, additional examples from other domains (e.g., finance or physics) could broaden the paper's appeal.
3. Assumptions on Linearity: The method assumes a latent linear diffusion process, which may limit its applicability to more complex, non-linear systems. Although the authors discuss potential extensions to non-linear processes, these are not explored in detail.
4. Comparative Analysis: While the paper compares its method to discrete-time approaches and MCMC sampling, it does not benchmark against other state-of-the-art continuous-time inference methods, if any exist.
Pro and Con Arguments for Acceptance:
Pros:
- The paper introduces a novel and technically sound algorithm with significant potential for real-world applications.
- The hybrid EP-variational approach is innovative and well-validated through experiments.
- The work addresses a critical gap in continuous-time inference, advancing the state of the art.
Cons:
- The paper's clarity could be improved for broader accessibility.
- The focus on linear diffusion processes limits the generality of the approach.
Recommendation:
I recommend acceptance of this paper, as it makes a substantial contribution to the field of continuous-time inference. While there are areas for improvement, particularly in clarity and scope, the proposed method is both novel and impactful, with strong experimental validation. The paper is likely to stimulate further research in this area and has significant practical relevance.