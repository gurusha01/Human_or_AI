This paper introduces the concept of adaptive anonymity, a generalization of k-anonymity that allows individuals to specify their desired level of privacy through an anonymity parameter, δi. The authors propose novel algorithms and theoretical guarantees to implement this framework, demonstrating improved utility and flexibility compared to traditional k-anonymity. The paper is well-motivated, addressing a critical limitation of existing privacy-preserving methods, and provides both theoretical analysis and empirical validation on benchmark and social datasets.
Strengths:
1. Novelty and Significance: The paper tackles a meaningful problem—accommodating heterogeneous privacy preferences—which is a significant advancement over existing privacy frameworks like k-anonymity. The proposed relaxation using b-matching and symmetric b-matching is innovative and addresses the degeneracy issues of k-anonymity in heterogeneous settings.
2. Theoretical Rigor: The authors provide a solid theoretical foundation, including privacy guarantees under single and sustained attack models. The use of graph-theoretic constructs (e.g., δ-regular bipartite graphs) is well-justified and mathematically sound.
3. Algorithmic Contributions: The proposed algorithms (variational bipartite b-matching and symmetric b-matching) are efficient and scalable, with clear approximation guarantees. The inclusion of runtime complexity and convergence analysis adds to their credibility.
4. Empirical Validation: The experiments on UCI datasets and Facebook social data convincingly demonstrate the utility improvements of the proposed methods over traditional k-anonymity approaches. The adaptive anonymity setting is particularly well-handled, showcasing the practical relevance of the work.
Weaknesses:
1. Clarity: While the paper is technically sound, the presentation is dense and could benefit from better organization. For instance, the transition between theoretical guarantees and algorithmic implementation is abrupt, making it harder for readers to follow the flow.
2. Comparative Baselines: The experimental section primarily compares the proposed methods to a single agglomerative clustering baseline. Including additional baselines, such as other state-of-the-art privacy-preserving methods, would strengthen the empirical claims.
3. Real-World Applicability: While the theoretical guarantees are robust, the paper does not address how the proposed methods would handle dynamic datasets or real-world adversarial scenarios where privacy preferences may evolve over time.
4. Discussion of Limitations: The paper briefly mentions the potential weaknesses of asymmetric b-matching under sustained attacks but does not explore this limitation in depth. A more explicit discussion of trade-offs between utility and privacy in different graph families (e.g., symmetric vs. asymmetric) would be valuable.
Recommendation:
This paper makes a significant contribution to the field of privacy-preserving data sharing, particularly in its ability to handle heterogeneous privacy preferences. While the clarity and breadth of experimental baselines could be improved, the theoretical and algorithmic contributions are compelling. I recommend acceptance with minor revisions, focusing on improving the clarity of exposition and expanding the experimental comparisons.
Arguments Pro Acceptance:
- Novel and impactful contribution to privacy-preserving frameworks.
- Strong theoretical guarantees and efficient algorithms.
- Empirical results demonstrate clear utility improvements.
Arguments Against Acceptance:
- Limited experimental baselines.
- Dense presentation may hinder accessibility for a broader audience.
- Insufficient exploration of real-world applicability and limitations.
Overall, this paper advances the state of the art in privacy-preserving data sharing and is a valuable addition to the conference.