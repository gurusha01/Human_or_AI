The paper presents a novel algorithm, Subsampled Randomized Hadamard Transform-Dual Ridge Regression (SRHT-DRR), designed to accelerate ridge regression in the high-dimensional setting where the number of features (p) far exceeds the number of observations (n). The authors claim that SRHT-DRR achieves a computational complexity of \(O(np \log(n))\), a significant improvement over the standard dual ridge regression solution's \(O(n^2p)\) complexity. The algorithm leverages a Randomized Walsh-Hadamard Transform followed by feature subsampling, ensuring computational efficiency while maintaining accuracy. Theoretical risk bounds are provided, and the algorithm's performance is validated through experiments on both synthetic and real-world datasets.
Strengths:
1. Novelty and Significance: The paper addresses an important problem in the era of big data, where efficient algorithms for high-dimensional regression are crucial. The use of structured random projections (SRHT) combined with feature subsampling is a novel and impactful contribution.
2. Theoretical Guarantees: The authors provide rigorous theoretical analysis, including risk inflation bounds, which demonstrate that SRHT-DRR only slightly inflates the risk compared to the true ridge regression solution. This is a strong point, as it ensures the method's reliability.
3. Empirical Validation: The experiments on synthetic and real-world datasets convincingly show that SRHT-DRR achieves comparable accuracy to the true ridge regression solution while significantly reducing computational cost. The comparisons with PCA and randomized PCA further highlight the algorithm's advantages.
4. Clarity of Presentation: The paper is well-organized, with clear explanations of the algorithm, its computational cost, and its theoretical properties. The inclusion of detailed experimental results and visualizations strengthens the paper's impact.
Weaknesses:
1. Limited Discussion of Limitations: While the paper acknowledges the trade-off between computational efficiency and risk inflation, it does not explore potential limitations of SRHT-DRR in depth. For instance, the impact of subsampling size (\(p_{subs}\)) on accuracy and computational cost could be discussed more thoroughly.
2. Comparison with Other Methods: Although the paper compares SRHT-DRR with PCA and randomized PCA, it does not benchmark against other state-of-the-art methods for high-dimensional regression, such as sketching-based approaches or kernel ridge regression variants.
3. Scalability to Extremely Large Datasets: While SRHT-DRR is faster than traditional ridge regression, the paper does not explicitly discuss its scalability to extremely large datasets where even \(O(np \log(n))\) might be prohibitive. This could be an important consideration for practitioners.
4. Reproducibility: While the theoretical details are comprehensive, the paper does not provide sufficient implementation details or code for reproducibility. This could hinder adoption by the community.
Recommendation:
Overall, the paper makes a significant contribution to the field of high-dimensional regression by proposing a computationally efficient algorithm with strong theoretical guarantees and empirical performance. The strengths of the paper outweigh its weaknesses, and it is well-suited for presentation at NIPS. However, the authors are encouraged to address the identified weaknesses in a future revision, particularly by discussing limitations, benchmarking against additional methods, and providing implementation details.
Arguments for Acceptance:
- Novel and impactful contribution to high-dimensional regression.
- Strong theoretical guarantees and empirical validation.
- Clear and well-organized presentation.
Arguments against Acceptance:
- Limited discussion of limitations and scalability.
- Lack of benchmarking against other state-of-the-art methods.
- Insufficient implementation details for reproducibility.
Final Decision: Accept with minor revisions.