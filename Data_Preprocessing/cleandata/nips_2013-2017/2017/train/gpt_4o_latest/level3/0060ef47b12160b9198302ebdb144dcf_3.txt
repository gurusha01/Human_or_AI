Review
This paper introduces a novel saliency mask generation method that is both fast and accurate, capable of processing 100 224x224 images per second on a standard GPU. The proposed approach trains a masking model to identify the tightest rectangular crop containing the salient region for a requested class, leveraging black-box classifiers such as AlexNet, GoogleNet, and ResNet. By utilizing multi-scale image feature maps (e.g., ResNet-50) for initial localization and refining the masks through upsampling blocks, the method achieves state-of-the-art performance on the ImageNet localization task, outperforming other weakly supervised techniques. The authors also propose a new saliency metric to evaluate the interpretability and quality of saliency maps, which aligns well with their objectives.
Strengths  
1. Technical Contribution: The paper presents a significant advancement in saliency detection by introducing a model-based approach that eliminates the need for iterative optimization. This is a notable improvement over existing methods, which are computationally expensive and often produce suboptimal results.
2. Performance: Experimental results demonstrate superior performance on ImageNet localization compared to prior weakly supervised methods. The proposed saliency metric further validates the interpretability of the generated masks.
3. Real-Time Capability: The ability to process 100 images per second makes this method suitable for real-time applications, such as video saliency detection and autonomous systems.
4. Clarity and Presentation: The paper is well-written and organized, with sufficient references to related work and intuitive discussions on the design choices. The inclusion of detailed experiments and visual examples strengthens the paper's claims.
5. Generality: The method is model-agnostic and generalizes well to unseen datasets, as demonstrated by its performance on CIFAR-10 without relying on pre-trained weights.
Weaknesses  
1. Real-World Applicability: While the method claims real-time performance, the applicability to larger images or high-resolution datasets is not addressed. The scalability of the approach remains unclear.
2. Small Salient Objects: The paper does not explicitly discuss how the method handles small or sparse salient regions, which could be a limitation in certain applications.
3. Missing Metrics: Table 3 lacks some key metrics, which raises concerns about the completeness of the evaluation. Additional comparisons with other state-of-the-art methods would strengthen the results.
4. Bias in Masking Model: While the authors acknowledge potential biases in their masking model, this issue is not thoroughly investigated, leaving room for further exploration.
5. Minor Issues: Grammatical errors in lines 273 and 151 should be corrected for improved readability.
Arguments for Acceptance  
- The paper introduces a novel and impactful approach to saliency detection, advancing the state of the art in weakly supervised methods.  
- The real-time capability and generalizability of the method open up new possibilities for practical applications.  
- The proposed saliency metric provides a valuable tool for evaluating interpretability, which is a critical aspect of explainable AI.
Arguments Against Acceptance  
- Concerns about scalability and handling of small salient objects are not adequately addressed.  
- Missing metrics in Table 3 and limited discussion on real-world applicability weaken the experimental evaluation.  
- The potential biases in the masking model require further investigation to ensure robustness.
Conclusion  
Overall, this paper makes a strong contribution to the field of saliency detection and explainable AI. While there are some limitations, the strengths outweigh the weaknesses, and the method has significant potential for future research and applications. I recommend acceptance with minor revisions to address the concerns raised.