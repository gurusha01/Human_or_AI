The paper presents a novel approach to modeling temporal point processes using Wasserstein Generative Adversarial Networks (WGAN), bypassing the traditional reliance on intensity functions and maximum likelihood estimation (MLE). The authors propose a likelihood-free framework, leveraging Wasserstein distance as a more robust objective function, and employ recurrent neural networks (RNNs) for both the generator and discriminator. This work is positioned as a significant departure from existing intensity-based methods, with the promise of improved performance in scenarios where parametric assumptions about the underlying process are either unrealistic or unknown.
Strengths:
1. Originality: The paper introduces an intensity-free, likelihood-free approach to point process modeling, which is a novel contribution to the field. Extending WGANs to temporal point processes is innovative and addresses limitations of MLE, such as mode dropping and sensitivity to parametric misspecification.
2. Theoretical Contributions: The authors propose a computationally efficient distance measure for comparing point processes, which is interpretable and avoids excessive computational overhead. The use of a regularized dual formulation for optimization is also noteworthy.
3. Empirical Validation: The proposed WGANTPP model demonstrates reasonable performance on both synthetic and real-world datasets. The robustness of the approach is highlighted, particularly in scenarios where the underlying generative process is unknown or misspecified.
4. Significance: The work has potential applications in diverse domains, such as healthcare, finance, and social networks, where point processes are commonly used to model event sequences.
Weaknesses:
1. Reproducibility: The paper lacks sufficient details about the experimental setup, datasets, and hyperparameters, making it difficult for others to reproduce the results. For example, the real-world data analysis section does not provide enough specifics about preprocessing or parameter tuning.
2. Weak Baselines: The comparison baselines are limited to traditional parametric models and an RNN trained with MLE. More flexible and modern alternatives, such as neural point process models with attention mechanisms, could provide a fairer evaluation.
3. Distance Measure Limitations: While the proposed distance measure is computationally efficient, it may struggle with noise from extraneous events. Local alignment-based distances or dynamic time warping could potentially offer more robust alternatives.
4. Clarity Issues: There are minor errors in the paper (e.g., a potential mistake in Eq. 3 and a mix-up in Section 3.1 regarding parameter settings for \(\alpha\) and \(c\)). Additionally, a spelling error ("demosntrate") detracts from the overall polish.
5. Scope of Applicability: The paper does not clearly articulate specific applications where the proposed Wasserstein distance is more advantageous than log-likelihood-based methods, leaving questions about its practical utility.
Recommendation:
The paper is a promising contribution to the field of point process modeling, with clear theoretical and empirical advancements. However, the lack of reproducibility and weak baseline comparisons are significant drawbacks. I recommend acceptance with minor revisions, contingent on the authors addressing reproducibility concerns, clarifying the scope of their method, and strengthening baseline comparisons.
Arguments for Acceptance:
- Novel and theoretically sound approach to point process modeling.
- Demonstrates robustness in scenarios with misspecified generative processes.
- Potential for broad applicability across multiple domains.
Arguments against Acceptance:
- Insufficient documentation of experimental details for reproducibility.
- Comparisons with stronger baselines are needed for a fair evaluation.
- The proposed distance measure may not handle noisy data effectively.
Overall, the paper represents a meaningful step forward but would benefit from additional rigor and clarity in its presentation.