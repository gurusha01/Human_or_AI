The paper introduces NeuralFDR, a novel method for controlling the False Discovery Rate (FDR) by learning optimal p-value thresholds as a function of hypothesis-specific feature vectors. Unlike traditional methods such as Benjamini-Hochberg (BH) or Independent Hypothesis Weighting (IHW), NeuralFDR leverages multi-dimensional, continuous, and discrete features through a neural network architecture. The authors demonstrate that NeuralFDR achieves superior performance in simulations and real-world datasets, making substantially more discoveries while maintaining FDR control. The method is theoretically grounded, with guarantees for FDR control under independence and weak dependence, and offers interpretable thresholds that align with domain-specific insights.
Strengths:
1. Innovation and Originality: NeuralFDR represents a significant advancement over existing FDR control methods by introducing a flexible, end-to-end approach that handles multi-dimensional features. This is a clear improvement over methods like IHW, which struggle with high-dimensional feature spaces.
2. Empirical Performance: The method consistently outperforms state-of-the-art techniques in both simulated and real-world datasets, such as RNA-Seq and GTEx data, making more discoveries while adhering to FDR constraints. The interpretability of the learned thresholds adds practical value, as they align with known biological phenomena.
3. Theoretical Guarantees: The authors provide rigorous theoretical analysis, including high-probability FDR control and asymptotic guarantees under weak dependence. The cross-validation procedure is designed to mitigate overfitting, a common concern in data-driven FDR control.
4. Clarity and Organization: The paper is well-written and provides sufficient details for reproducibility. The inclusion of visualizations, such as learned thresholds, enhances understanding.
Weaknesses:
1. Probabilistic Modeling: The relationship between p-values (pi) and features (Xi) lacks formal probabilistic treatment. This raises concerns about potential circularity, as the features may implicitly influence the p-values.
2. Non-parametric Alternatives: The authors claim that multi-dimensional features preclude non-parametric methods, but this is debatable. Techniques like nearest-neighbors or kernel-based methods could adapt to intrinsic dimensions, and their exclusion warrants further justification.
3. Variance in the Mirror Estimator: The mirroring estimator may suffer from high variance when the threshold t(x) is small, akin to bias-variance trade-offs in Storey's approach. This could impact the robustness of the method in certain scenarios.
4. Cross-Validation Concerns: While cross-validation is used to prevent overfitting, the noisy nature of the FDR estimator raises questions about its reliability in controlling test set FDR. The dependence of Theorem 1's error bound on the number of folds also suggests potential trade-offs.
5. Scalability: NeuralFDR performs well on large datasets with high alternative proportions but may struggle with smaller datasets or sparse signals. This limitation is acknowledged but not fully addressed.
Minor Corrections:
- Line 136: Replace "this" with "these."
Recommendation:
The paper makes a strong contribution to the field of FDR control by introducing a novel and effective method that leverages modern machine learning techniques. While there are some concerns regarding probabilistic modeling and scalability, the strengths of the approach outweigh its weaknesses. I recommend acceptance, with minor revisions to address the noted concerns and improve clarity.