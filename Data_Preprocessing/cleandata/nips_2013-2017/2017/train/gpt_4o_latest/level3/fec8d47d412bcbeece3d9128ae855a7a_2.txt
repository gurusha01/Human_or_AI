The paper presents NeuralFDR, a novel method leveraging neural networks to model the relationship between hypothesis features and discovery thresholds in multiple hypothesis testing. By incorporating hypothesis-specific features, NeuralFDR aims to maximize statistical power while controlling the false discovery rate (FDR). This approach addresses limitations of existing methods, such as Benjamini-Hochberg (BH) and Independent Hypothesis Weighting (IHW), which either ignore features or struggle with multi-dimensional, continuous features. The authors provide theoretical guarantees for FDR control and demonstrate the method's effectiveness through simulations and real-world datasets, including RNA-Seq and GTEx data.
Strengths:  
The paper makes a significant contribution by introducing an end-to-end algorithm that flexibly handles multi-dimensional continuous features, a notable improvement over existing methods like IHW. The use of neural networks allows for a more expressive and adaptable decision threshold, which is shown to outperform state-of-the-art methods in both simulated and real-world scenarios. The theoretical guarantees for FDR control and the interpretability of the learned thresholds are commendable, providing both rigor and practical insights. The empirical results are well-documented, with NeuralFDR demonstrating higher discovery rates while maintaining FDR control, particularly in high-dimensional feature settings. The biological interpretability of the thresholds in the GTEx and RNA-Seq datasets further underscores the method's utility.
Weaknesses:  
One notable omission is the lack of discussion on the computational demands of NeuralFDR compared to simpler methods like BH or IHW. Given the increasing scale of datasets, this could impact the method's adoption. Additionally, in the GTEx analysis, the authors did not explore the inclusion of additional features, which might have further increased discoveries. This is particularly relevant given the relatively small percent improvement observed in this dataset. The paper could also benefit from reporting percent increases alongside absolute values in results (e.g., Line 215 and Table 2) to provide clearer context for the improvements.
Clarity and Presentation:  
The paper is well-written and logically organized, with sufficient detail for reproducibility. However, minor improvements in clarity, such as the inclusion of percent increases in results, would enhance readability. The figures effectively illustrate the method's performance and interpretability.
Originality and Significance:  
NeuralFDR represents a novel and impactful contribution to the field of multiple hypothesis testing. By addressing the limitations of existing methods and demonstrating superior performance, it advances the state of the art. The method's ability to handle multi-dimensional features and its biological interpretability make it particularly relevant for modern data-rich applications.
Pro and Con Arguments for Acceptance:  
Pros:  
- Innovative use of neural networks for hypothesis testing.  
- Theoretical guarantees for FDR control.  
- Superior performance in simulations and real-world datasets.  
- Interpretability of learned thresholds.  
Cons:  
- Limited discussion of computational efficiency.  
- Missed opportunity to explore additional features in the GTEx analysis.  
- Minor presentation issues (e.g., lack of percent increases in results).  
In conclusion, NeuralFDR is a high-quality contribution that addresses a critical challenge in hypothesis testing. While minor issues remain, they do not detract from the overall significance and utility of the work. I recommend acceptance.