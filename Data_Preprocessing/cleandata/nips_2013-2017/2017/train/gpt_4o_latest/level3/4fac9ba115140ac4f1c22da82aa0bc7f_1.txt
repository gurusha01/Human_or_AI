The paper introduces a novel cost-aware gradient boosting framework, CEGB, which constructs deep regression tree ensembles optimized for both accuracy and evaluation cost. By incorporating prediction cost penalties into the gradient boosting objective and employing a best-first tree-growing strategy, the method achieves a balance between computational efficiency and predictive performance. The authors demonstrate the approach's superiority over existing methods like GREEDYMISER and BUDGETPRUNE across multiple datasets, including Yahoo! LTR and MiniBooNE, and provide source code for reproducibility.
Strengths:
1. Clarity: The paper is well-written, with a clear exposition of the problem, methodology, and experiments. Despite the extensive use of mathematical notation, the explanations remain accessible to readers familiar with gradient boosting.
2. Practical Relevance: The proposed CEGB framework addresses a critical need for cost-sensitive learning, making it valuable for time-constrained applications such as real-time classification and resource-limited settings.
3. Experimental Validation: The experiments are comprehensive, covering diverse datasets and scenarios (e.g., feature acquisition vs. evaluation costs). The results convincingly demonstrate CEGB's advantages in terms of accuracy-cost tradeoffs.
4. Implementation Feasibility: The authors emphasize the ease of integrating their approach into existing gradient boosting libraries, enhancing its practical utility.
Weaknesses:
1. Modest Contribution: While the method builds on gradient boosting and introduces cost-aware tree construction, the novelty feels incremental compared to prior work like GREEDYMISER and BUDGETPRUNE. The paper would benefit from a more explicit breakdown of CEGB's innovations and their individual impact on performance.
2. Cost Measurement Ambiguity: The Precision vs. Cost curves lack clarity regarding how costs are measured and compared across methods, potentially undermining the validity of the reported improvements.
3. Applicability of Prior Methods: The paper does not adequately justify why existing methods like GREEDYMISER or BUDGETPRUNE cannot be applied in certain experimental settings (e.g., Section 5.2). A direct comparison in these scenarios would strengthen the argument for CEGB's superiority.
4. Figures and Visualizations: Figure 1 could be replaced with a more insightful comparison of tree structures generated by CEGB, GREEDYMISER, and BUDGETPRUNE. This would help illustrate the practical differences in tree construction.
Low-Level Technical Issues:
- Equation 7: Clarify why \(\lambda\) appears only in the first cost term.
- Equation 12: Verify whether denominators should include \(\lambda\).
- Figure 4b: Define "levels" for better interpretability.
- Symbol Redefinition: Avoid reusing symbols like \(\beta_m\) and \(\alpha\) without clear context.
Overall Assessment:
The paper presents a well-executed adaptation of gradient boosting for cost-sensitive learning. However, its contributions are somewhat incremental, and the lack of clarity in cost comparisons weakens its claims. While the method shows promise for practitioners, the paper falls slightly below the acceptance threshold due to these limitations. Addressing the cost measurement issues and providing clearer justifications for CEGB's innovations would significantly strengthen the work.
Arguments for Acceptance:
- Strong practical relevance and ease of implementation.
- Comprehensive experimental validation.
- Clear writing and organization.
Arguments Against Acceptance:
- Incremental novelty compared to prior work.
- Ambiguities in cost measurement and comparisons.
- Insufficient justification for the inapplicability of prior methods.
Recommendation: Borderline reject.