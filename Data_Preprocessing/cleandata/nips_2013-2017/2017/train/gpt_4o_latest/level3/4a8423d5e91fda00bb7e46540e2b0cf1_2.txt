The paper addresses the problem of selective classification in the context of deep neural networks (DNNs), introducing the SGR algorithm to guarantee a desired error rate with high probability while maximizing coverage. This is a timely and important contribution, as selective classification has been underexplored for DNNs, despite its potential for mission-critical applications like autonomous driving and medical diagnostics. The authors leverage two confidence-based rejection mechanisms—Softmax Response (SR) and Monte Carlo Dropout (MC-dropout)—to construct selective classifiers, demonstrating their effectiveness on CIFAR-10, CIFAR-100, and ImageNet datasets.
Strengths:
1. Novelty: The paper tackles a significant gap in the literature by applying selective classification to DNNs, a domain where such methods have been largely absent. The proposed SGR algorithm is a meaningful extension of prior work on selective prediction.
2. Practical Relevance: The ability to guarantee a specific error rate with high confidence is highly valuable for safety-critical applications. The empirical results, particularly the ability to achieve a 2% top-5 error on ImageNet with 60% coverage, underscore the potential impact of this work.
3. Theoretical Rigor: The SGR algorithm is grounded in a solid theoretical framework, with guarantees on risk and coverage derived using tight numerical bounds.
4. Empirical Validation: The experiments convincingly demonstrate the viability of the approach, with results showing significant reductions in error rates for all datasets considered.
Weaknesses:
1. Algorithm Complexity: The complexity of solving Equation (4) and the overall computational cost of the SGR algorithm (notably the mlog(m) sorting step) are not sufficiently clarified. This could hinder reproducibility and scalability for large datasets.
2. MC-Dropout Performance: The underperformance of MC-dropout on ImageNet is noted but not well-explained. Visualizations or deeper analysis of confidence functions could provide valuable insights into this discrepancy.
3. Dataset Splits: The methodology for splitting the CIFAR and ImageNet datasets is unclear. Using proper validation and full test sets would strengthen the evaluation and ensure fair comparisons.
4. Comparison with Alternatives: The paper lacks comparisons with other selective classification methods, such as cost-based abstention approaches. This omission makes it difficult to assess the relative advantages of the proposed method.
5. Clarity Issues: While the paper is generally well-written, there is a typo in Section 5.3 ("mageNet"), and some sections (e.g., the explanation of SR and MC-dropout) could benefit from additional detail and clarity.
Recommendation:
The paper presents a promising and practical approach to selective classification for DNNs, with strong theoretical underpinnings and compelling empirical results. However, the lack of clarity on algorithm complexity, dataset splits, and comparisons with alternative methods are notable weaknesses. Addressing these issues would significantly enhance the paper's impact and rigor.
Arguments for Acceptance:
- The paper addresses an important and underexplored problem.
- The proposed SGR algorithm is novel and theoretically sound.
- The empirical results demonstrate the practical utility of the approach.
Arguments Against Acceptance:
- Insufficient clarity on algorithm complexity and dataset splits.
- Lack of comparisons with alternative methods.
- Limited analysis of MC-dropout's underperformance.
Overall, I recommend acceptance with minor revisions, as the strengths outweigh the weaknesses, and the paper makes a meaningful contribution to the field.