The paper introduces a novel Fourier feature-based distance for comparing phase functions of probability distributions, inspired by Maximum Mean Discrepancy (MMD), and demonstrates its utility in statistical testing and learning tasks. The proposed approach encodes invariance to additive symmetric noise, enabling robust statistical testing and learning from distributions with minimal assumptions about the noise properties. By leveraging phase features, the authors address challenges in nonparametric two-sample testing and learning from labeled bags of samples, providing a framework that is particularly effective for complex statistical problems where traditional methods struggle. The paper evaluates the proposed methodology on synthetic and real-world datasets, demonstrating its robustness and applicability in scenarios such as signal decoding and covariate shift in noisy datasets.
Strengths:
1. Technical Novelty: The introduction of phase discrepancy (PhD) and phase features represents a significant advancement in encoding invariance to additive symmetric noise. This is a novel contribution that builds on and extends prior work on kernel embeddings and MMD.
2. Robustness to Noise: The framework effectively disentangles signal from noise, addressing a critical challenge in real-world data analysis. This is particularly evident in the experiments on the Higgs, Aerosol, and Dark Matter datasets.
3. Theoretical Rigor: The paper provides a solid theoretical foundation, including proofs and propositions, to support the proposed methods. The mathematical clarity enhances the credibility of the work.
4. Practical Relevance: The potential applications in signal decoding for mobile and satellite communication systems highlight the practical significance of the proposed approach.
5. Experimental Validation: The extensive experiments on synthetic and real-world datasets demonstrate the utility of the proposed methods in both hypothesis testing and learning tasks. The comparison with baseline methods further substantiates the claims.
Weaknesses:
1. Assumptions on Noise: The assumption of symmetric positive definite (SPD) noise and indecomposability of random variables may limit the generalizability of the approach. While the authors acknowledge this limitation, further exploration or relaxation of these assumptions would strengthen the work.
2. Scalability: The computational complexity of the PhD test, particularly for large datasets or high-dimensional data, is not explicitly addressed. This could be a bottleneck in practical applications.
3. Inflated Type I Error: The PhD test exhibits inflated Type I error rates under large noise levels, as noted in the experiments. This limitation should be addressed in future work to improve reliability.
4. Clarity in Presentation: While the paper is well-organized, certain sections, such as the derivation of phase features and their connection to Fourier features, could benefit from clearer explanations or visual aids to enhance accessibility for a broader audience.
Arguments for Acceptance:
- The paper addresses a significant gap in nonparametric testing and learning by introducing a robust framework for handling noisy distributions.
- The proposed methods are theoretically sound and practically relevant, with demonstrated applicability across diverse datasets.
- The work advances the state of the art in kernel methods and distribution-based learning, making it a valuable contribution to the field.
Arguments Against Acceptance:
- The reliance on specific assumptions (e.g., SPD noise, indecomposability) may limit the applicability of the approach in certain scenarios.
- The inflated Type I error rates for the PhD test under large noise levels raise concerns about its robustness in extreme cases.
Conclusion:
Overall, the paper makes a strong scientific contribution by introducing a novel and robust framework for statistical testing and learning on distributions. While certain limitations warrant further investigation, the strengths of the work outweigh its weaknesses. I recommend acceptance, with minor revisions to address clarity and scalability concerns.