The paper introduces NeuralFDR, a novel algorithm leveraging neural networks to learn a discovery threshold for multiple hypothesis testing, incorporating hypothesis-specific features. The authors argue that existing methods like Benjamini-Hochberg (BH) and Independent Hypothesis Weighting (IHW) either ignore these features or handle them in limited ways. NeuralFDR aims to maximize discoveries while controlling the False Discovery Rate (FDR), with theoretical guarantees and empirical validation on synthetic and real-world datasets.
Strengths:
1. Relevance and Novelty: The paper addresses an important problem in multiple hypothesis testing, particularly in fields like computational biology and healthcare, where hypothesis-specific features are abundant. The use of neural networks for this task is novel and allows for flexible handling of multi-dimensional features, advancing beyond the limitations of existing methods like IHW.
2. Empirical Results: NeuralFDR demonstrates superior performance in terms of the number of discoveries while maintaining FDR control across synthetic and real datasets. The interpretability of the learned thresholds is a notable advantage, as it aligns with domain-specific biological insights (e.g., SNP proximity to genes in GTEx data).
3. Theoretical Guarantees: The paper provides strong theoretical guarantees for FDR control under i.i.d. assumptions and asymptotic guarantees under weak dependence, which is relevant for real-world scenarios like genetic studies.
4. End-to-End Approach: Unlike other methods, NeuralFDR offers an end-to-end solution, avoiding the need for manual feature engineering or grouping, which is particularly beneficial for high-dimensional feature spaces.
Weaknesses:
1. Restrictive Assumptions: The method assumes i.i.d. triplets and independence, which are unrealistic in many real-world applications (e.g., bioinformatics datasets with linkage disequilibrium or gene co-expression networks). The assumption of a non-increasing alternative distribution is also questionable and limits generalizability.
2. Overemphasis on Neural Networks: While the use of neural networks is innovative, the paper does not sufficiently justify why simpler parametric models would not suffice, especially for low-dimensional tasks. This raises concerns about overfitting and computational overhead.
3. Exposition and Clarity: Algorithm 1 and the cross-validation procedure lack clarity, making it difficult for readers to reproduce results. Key variables and hyperparameter choices are insufficiently explained, and robustness experiments are missing.
4. Randomness and Stability: The reliance on cross-validation introduces randomness, and the paper does not adequately demonstrate the stability of results across different partitions.
5. Dependence on Hypothesis Count: The method does not explicitly account for the number of hypotheses, which could be a limitation in small datasets or those with low alternative proportions.
6. Presentation Issues: Frequent typos, notational inconsistencies, and imprecise claims (e.g., the definition of p-values) hinder readability and undermine the paper's credibility.
Suggestions for Improvement:
1. Address the restrictive assumptions, particularly independence and the non-increasing alternative distribution, to enhance applicability to real-world datasets.
2. Provide a clearer exposition of the algorithm, including detailed descriptions of cross-validation, hyperparameter choices, and robustness experiments.
3. Compare NeuralFDR with simpler parametric models to justify the necessity of neural networks.
4. Conduct experiments to demonstrate the stability of results across different cross-validation folds and hypothesis counts.
5. Improve the manuscript's presentation by correcting typos, clarifying notations, and ensuring precise claims.
Recommendation:
While the paper presents a novel and promising approach, its reliance on unrealistic assumptions, lack of clarity, and insufficient robustness experiments limit its impact. I recommend major revisions to address these concerns before acceptance.