The paper introduces a neural network-based approach for generating saliency masks, designed to be fast and capable of processing multiple images per second. The authors propose a masking model that learns to manipulate classifier scores by masking salient regions of an image, achieving real-time performance. The method is evaluated on CIFAR-10 and ImageNet datasets, demonstrating competitive results in weakly supervised object localization and introducing a novel saliency metric. While the paper addresses an important problem in explainable AI and offers a promising solution, several limitations and areas for improvement are evident.
Strengths:
1. Novelty and Relevance: The proposed approach is innovative in its use of a trainable masking model to generate saliency maps in a single forward pass. This is a significant improvement over iterative methods, which are computationally expensive.
2. Real-time Capability: The ability to generate over 100 saliency masks per second makes this method suitable for real-time applications, such as video saliency detection and autonomous systems.
3. Empirical Results: The model outperforms existing weakly supervised methods on the ImageNet localization task and achieves competitive results under the newly proposed saliency metric.
4. Generalizability: The method is tested on multiple datasets (ImageNet and CIFAR-10) and demonstrates adaptability to different resolutions and architectures.
Weaknesses:
1. Saliency Metric Limitations: The proposed saliency metric, while novel, introduces artifacts due to cropping and rescaling, which can bias results toward smaller salient regions. These limitations are not adequately discussed in the paper.
2. Weakly Supervised Localization: The reliance on weakly supervised localization as a proxy for saliency quality is problematic. Saliency and localization are not equivalent, especially when object context is crucial for classification.
3. Architecture Dependence: The masking model's dependence on the U-Net architecture is not explored thoroughly. Experiments with alternative architectures are missing, raising questions about the general applicability of the approach.
4. Classifier Scale Invariance: The saliency metric assumes scale invariance in classifiers, limiting its applicability to certain networks and domains. This contradicts the claim of general applicability to black-box classifiers.
5. Clarity Issues: Results in Table 1 lack sufficient explanation, and the LRP variant and parameter settings used for comparison are not specified, making it difficult to reproduce the experiments.
Suggestions for Improvement:
1. Discuss the limitations of the saliency metric and its potential biases in greater detail.
2. Provide experiments with alternative masking architectures to evaluate the robustness of the approach.
3. Clarify the relationship between saliency and weakly supervised localization, and explore additional evaluation metrics.
4. Specify the LRP variant and parameter settings to improve reproducibility.
5. Address the masking model's potential biases and how they might influence the generated saliency maps.
Recommendation:
The paper is borderline. While it presents a novel and impactful approach, the limitations, particularly regarding the saliency metric and architecture dependence, need to be addressed in detail. Publication is acceptable only if these concerns are adequately discussed and clarified in the final version.