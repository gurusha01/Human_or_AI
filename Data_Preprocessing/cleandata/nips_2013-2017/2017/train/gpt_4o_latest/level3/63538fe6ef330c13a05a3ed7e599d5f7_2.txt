The paper presents a significant advancement in the field of greedy optimization methods by addressing optimization over the conic hull of an infinite atom set, a problem that bridges the gap between Matching Pursuit (MP) and Frank-Wolfe (FW) algorithms. This work introduces novel non-negative MP algorithms with explicit convergence guarantees, filling a critical gap in the literature where existing MP variants for conic hulls lacked theoretical guarantees and often failed to converge. The authors also propose corrective variants, including away-step, pairwise, and fully corrective MP, which achieve linear convergence under specific conditions. These contributions are supported by rigorous theoretical analysis and empirical validation.
Strengths:
1. Novelty and Originality: The paper tackles an intermediate optimization domain—conic hulls—that has been largely unexplored in the context of MP and FW algorithms. The proposed algorithms generalize existing methods and provide a unified framework for optimization over conic constraints.
2. Theoretical Contributions: The authors derive sublinear and linear convergence rates for their algorithms, addressing scenarios where the atom set lacks alignment with descent directions. This is a substantial theoretical contribution, as it relaxes assumptions that limited prior work.
3. Algorithmic Innovations: The introduction of corrective variants (away-step, pairwise, and fully corrective MP) is a significant improvement over standard MP, addressing issues like zig-zagging and slow convergence.
4. Empirical Validation: The algorithms are tested on diverse tasks, including synthetic data, non-negative matrix factorization, and non-negative garrote logistic regression. The results demonstrate competitive or superior performance compared to established baselines, showcasing the practical utility of the proposed methods.
Weaknesses:
1. Clarity: While the paper is mathematically rigorous, some sections, particularly those detailing the geometric concepts (e.g., cone width, pyramidal directional width), are dense and may be challenging for readers unfamiliar with these notions. A more intuitive explanation or visual aids could improve accessibility.
2. Computational Complexity: The corrective variants, especially the fully corrective MP, involve additional computational overhead due to multiple linear minimization oracle (LMO) queries and weight updates. While the authors discuss this, a more detailed complexity analysis and comparison with baselines would strengthen the paper.
3. Empirical Scope: Although the experiments are diverse, they focus primarily on smooth convex objectives. Extending the evaluation to non-smooth or non-convex settings could broaden the applicability of the proposed methods.
Arguments for Acceptance:
- The paper addresses a well-motivated and challenging problem, making a substantial theoretical and practical contribution to the field.
- The proposed algorithms are innovative, with clear improvements over existing methods in terms of convergence guarantees and empirical performance.
- The work is relevant to a wide range of applications, including matrix factorization, model selection, and signal processing, making it significant for both researchers and practitioners.
Arguments Against Acceptance:
- The paper's clarity could be improved, particularly in its presentation of geometric concepts and algorithmic details.
- The computational cost of the corrective variants may limit their scalability for very large-scale problems, which is not fully explored in the experiments.
Conclusion:
Overall, this paper represents a high-quality contribution to the field of optimization and machine learning. Its theoretical rigor, algorithmic innovations, and empirical validation make it a strong candidate for acceptance. However, the authors should consider revising the manuscript to improve clarity and provide a more detailed discussion of computational trade-offs.