The paper presents a novel exploration of optimization over conic hulls, bridging the gap between the linear span and convex hull parameterizations addressed by traditional Matching Pursuit (MP) and Frank-Wolfe (FW) algorithms. This intermediate domain is particularly relevant for applications requiring non-negative solutions, such as unmixing problems and matrix/tensor factorizations. The authors introduce the first principled non-negative MP algorithms with explicit convergence guarantees, including sublinear and linear rates for smooth and strongly convex objectives, respectively. They also propose three algorithmic variants—Non-Negative MP (NNMP), Away-steps MP (AMP), and Pairwise MP (PWMP)—and a fully corrective MP (FCMP) variant, inspired by FW extensions. These contributions address the limitations of existing MP methods, which fail to converge in conic domains due to alignment assumptions.
Strengths:
1. Novelty: The paper introduces a new optimization framework for conic hulls, a domain that has been underexplored in the MP literature. The proposed algorithms generalize MP to a broader class of problems and relax restrictive assumptions.
2. Theoretical Contributions: The authors provide rigorous convergence analyses, including explicit sublinear and linear rates, which depend on geometric properties like the cone width. These results are a significant advancement over prior work, which lacked guarantees for conic domains.
3. Algorithmic Design: The introduction of corrective variants (AMP, PWMP, and FCMP) to mitigate issues like zig-zagging and improve convergence speed is well-motivated and supported by theoretical guarantees.
4. Relevance: The work has potential applications in diverse fields, including non-negative matrix factorization, logistic regression, and signal unmixing, making it broadly impactful.
Weaknesses:
1. Experimental Analysis: While the paper demonstrates empirical performance on three tasks, the experimental settings and result analyses lack sufficient detail. For instance, the choice of parameters, dataset preprocessing, and the impact of algorithmic variants on convergence behavior are not thoroughly discussed.
2. Computational Considerations: The paper does not adequately address the computational overhead of the proposed algorithms, especially the fully corrective variant, which involves solving a cone-constrained problem at each iteration. Including computational time as an evaluation criterion would strengthen the analysis.
3. Algorithm Selection: Although three variants are proposed, the paper does not provide clear guidance on selecting the most suitable algorithm for specific problem settings or objectives. A comparative analysis under varying conditions would enhance practical utility.
4. Trade-off Analysis: The authors highlight a trade-off involving the parameter τ but do not explore this trade-off in depth. A more detailed discussion or empirical evaluation would clarify its practical implications.
Recommendation:
The paper makes significant theoretical and algorithmic contributions to the field of greedy optimization and conic domains. However, the experimental evaluation and practical considerations require improvement. I recommend acceptance, provided the authors address the weaknesses, particularly by expanding the experimental analysis and offering more detailed guidance on algorithm selection and computational trade-offs.
Arguments for Acceptance:
- Novel and theoretically rigorous contributions to conic optimization.
- General applicability to a wide range of learning problems.
- Introduction of corrective variants with improved convergence guarantees.
Arguments against Acceptance:
- Insufficient experimental detail and computational analysis.
- Lack of practical guidance for algorithm selection and parameter tuning.
Overall, the paper advances the state of the art in greedy optimization and is a valuable contribution to the conference, but additional refinements would improve its impact.