This paper presents a novel framework for error detection and targeted error correction in connectomics, leveraging multiscale 3D convolutional neural networks (CNNs) to optimize human proofreading time. The authors address a critical bottleneck in neuronal segmentation pipelines by decomposing the problem into two tasks: error detection and object mask pruning. The key observation that detecting errors is easier than correcting them underpins the proposed methodology, which combines an error-detecting module with an error-correcting module to achieve significant computational and accuracy improvements.
The strengths of the paper lie in its well-motivated problem formulation and its integration of error detection and correction into a unified framework. The use of a multiscale 3D CNN for error detection, coupled with overlapping grid-based inference, is a thoughtful design choice that ensures high precision and recall. The error-correcting module, which reconstructs objects using k-dimensional vector fields transformed into binary masks via an exponential transform, is an innovative approach that blurs the line between semantic and instance segmentation. The authors also provide a detailed performance analysis, including per-object variation of information (VI) scores, which is commendable and adds rigor to the evaluation.
However, the paper has several weaknesses that need to be addressed. First, the choice of the exponential transform and the value of k used in the error correction module are not well-justified, and experimental evidence supporting these design decisions is missing. Similarly, the losses used to train the networks, particularly for the k-dimensional vector-based error correction module, are not described, making it difficult to assess the training process. The confidence computation and termination condition in Section 5 lack sufficient detail and justification. Furthermore, while the paper claims to handle both split and merge errors, it is unclear how merge errors are addressed at different levels, and this requires clarification. Additionally, the optimizer parameters (e.g., Adam) are not explicitly mentioned, which is a critical omission for reproducibility.
The paper also suffers from some clarity issues. Figure 1 is difficult to interpret, and the data flow direction is ambiguous. The claim in Line 48 that deep learning is prohibited by agglomeration overhead is inaccurate, as prior work has successfully applied deep learning to this problem. Finally, the non-consecutive layer IDs in Appendix A Table 4 need clarification regarding their intentionality.
In conclusion, this paper addresses an important problem in connectomics and proposes a promising framework that combines error detection and correction. While the results are impressive and the approach is novel, the paper requires additional clarifications and justifications to strengthen its technical rigor and reproducibility. Pros: Novel framework, strong performance analysis, and significant computational savings. Cons: Missing training details, unclear design choices, and some inaccuracies in claims. Recommendation: Accept with major revisions.