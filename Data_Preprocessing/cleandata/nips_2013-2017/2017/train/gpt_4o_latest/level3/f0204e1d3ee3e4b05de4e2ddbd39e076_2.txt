This paper presents a novel framework that integrates adaptive multi-armed bandit (MAB) algorithms with online false discovery rate (FDR) control, addressing critical limitations in traditional A/B/n testing. The authors propose replacing static A/B/n tests with adaptive "better-arm identification" algorithms, introducing a variant of the LUCB algorithm tailored for this purpose. By leveraging anytime p-values and online FDR procedures, the framework achieves continuous FDR control while maintaining low sample complexity and high statistical power. The paper is well-supported by theoretical guarantees and extensive experiments, including simulations and real-world data from the New Yorker Cartoon Caption Contest.
Strengths:
1. Originality: The paper introduces a novel combination of adaptive sampling (MAB) and online FDR control, which has not been explored in prior work. This integration is both theoretically and practically significant, offering a fresh perspective on sequential hypothesis testing.
2. Technical Soundness: Theoretical guarantees for mFDR control and power are rigorously derived. The proposed modifications to the LUCB algorithm are well-motivated and effectively address the asymmetry between control and treatment arms in hypothesis testing.
3. Practical Relevance: The framework is highly applicable to real-world scenarios, such as clinical trials and online A/B testing, where continuous monitoring and efficient resource allocation are critical.
4. Experimental Validation: The experiments convincingly demonstrate the advantages of the proposed framework over traditional A/B testing and naive MAB approaches. The results highlight significant improvements in sample efficiency, power, and FDR control.
5. Clarity: The paper is well-organized, with clear explanations of the challenges, proposed solutions, and experimental results. The inclusion of a meta-algorithm and a concrete procedure enhances reproducibility.
Weaknesses:
1. Complexity of Presentation: While the paper is technically sound, some sections (e.g., the derivation of always-valid p-values and the interaction between MAB and FDR) are dense and may be challenging for readers unfamiliar with the underlying concepts. Simplifying these sections or providing additional intuition would improve accessibility.
2. Limited Discussion of Limitations: The paper does not sufficiently discuss potential limitations, such as the computational overhead of adaptive sampling or the scalability of the framework to very large-scale problems.
3. Typos: Minor typographical errors ("testing multiple" → "multiple testing" on line 37, "samplesas" → "samples as" on line 153) should be corrected.
Arguments for Acceptance:
- The paper addresses a critical problem in sequential hypothesis testing with a novel and impactful approach.
- Theoretical contributions are robust, and the experimental results strongly support the proposed methods.
- The framework has broad applicability and potential to influence both research and practice.
Arguments Against Acceptance:
- The dense presentation of some technical sections may limit accessibility to a broader audience.
- The discussion of limitations and computational trade-offs could be more thorough.
Recommendation:
I recommend accepting this paper, as its contributions are significant, well-supported, and highly relevant to the conference's scope. Minor revisions to improve clarity and correct typographical errors are suggested.