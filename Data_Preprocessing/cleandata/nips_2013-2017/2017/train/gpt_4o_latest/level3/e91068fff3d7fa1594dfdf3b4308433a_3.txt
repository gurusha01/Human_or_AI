Review
This paper introduces a novel variance reduction technique for the reparameterized gradient estimator of the Evidence Lower Bound (ELBO) in variational inference. The authors propose removing the score function term from the gradient computation, resulting in an unbiased estimator whose variance approaches zero as the variational posterior approaches the true posterior. The method is implemented as a simple modification to automatic differentiation frameworks, making it computationally efficient and easy to adopt. The authors extend the approach to more complex models, such as mixture and importance-weighted posteriors, and provide experimental validation on MNIST and Omniglot datasets.
Strengths:
1. Technical Contribution: The paper provides a clear decomposition of the ELBO gradient into path derivative and score function terms, offering a solid theoretical foundation for the proposed variance reduction technique. The insight that the score function term can be removed without biasing the gradient estimator is both elegant and impactful.
2. Implementation Simplicity: The proposed modification is straightforward to implement in existing autodiff frameworks, which lowers the barrier for adoption by practitioners.
3. Generalizability: The method is extended to richer variational families, including mixture distributions and importance-weighted autoencoders, demonstrating its flexibility.
4. Empirical Validation: Experimental results show modest but consistent improvements in negative log-likelihood (NLL) across most settings, particularly for deeper models and more complex variational families. The computational efficiency of the method is also highlighted.
Weaknesses:
1. Limited Novelty: While the variance reduction technique is useful, its novelty is somewhat incremental. Similar ideas, such as control variates and variance reduction in stochastic optimization, have been explored in prior work (e.g., Ranganath et al., 2014; Ruiz et al., 2016). The paper could better position its contribution relative to these works.
2. Unclear Discussion on Control Variates: The discussion on the role of the score function as a control variate and the choice of scale \( c \) is unclear and occasionally contradictory. For instance, the claim that \( c = 1 \) is optimal when the posterior is exact is not well-justified, and the practical implications of this choice are underexplored.
3. Marginal Empirical Gains: The experimental results show only modest improvements in NLL, with some cases (e.g., MNIST with \( k=50 \)) showing worse performance. This raises questions about the practical significance of the method, especially given the already low variance of reparameterized gradients.
4. Limited Scope of Experiments: While MNIST and Omniglot are standard benchmarks, they are relatively simple datasets. Testing the method on more challenging tasks or larger-scale datasets would strengthen the empirical claims.
Pro/Con Arguments for Acceptance:
- Pro: The paper provides a theoretically sound and computationally efficient variance reduction technique that is easy to implement and generalizable to various models.
- Con: The novelty is incremental, and the empirical improvements are modest, limiting the overall impact of the contribution.
Suggestions for Improvement:
1. Clarify the discussion on control variates and the choice of scale \( c \), providing more rigorous theoretical or empirical justification.
2. Expand the experimental evaluation to include more challenging datasets or real-world applications to better demonstrate the method's utility.
3. Strengthen the positioning of the work relative to prior contributions, particularly in the context of control variates and generalized reparameterization gradients.
Recommendation:
While the paper provides a useful and theoretically sound contribution, the limited novelty and marginal empirical gains suggest that it may not meet the bar for acceptance at a top-tier conference like NeurIPS. I recommend weak rejection, but encourage the authors to refine the discussion on control variates, expand the experiments, and better position their work in the context of prior research.