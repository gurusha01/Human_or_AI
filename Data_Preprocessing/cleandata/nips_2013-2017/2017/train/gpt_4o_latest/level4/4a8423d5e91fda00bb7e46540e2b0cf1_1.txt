The paper introduces a practical approach to incorporating selective classification capabilities into existing neural networks. The proposed method involves the following steps:  
1. Selecting a score function to quantify the network's confidence in its predictions. The paper evaluates MC-dropout scores for networks trained with dropout and the maximum softmax score for networks with softmax outputs, with the latter empirically demonstrating superior performance.  
2. Specifying the desired confidence level and target error rate.  
3. Employing a binomial search to determine a score threshold such that, with the specified confidence level, the classifier's error rate on the samples it chooses to classify remains below the desired threshold.  
The approach leverages an established bound on the true error rate of a classifier derived from a small sample estimate (Lemma 3.1) and applies binomial search with a Bonferroni correction to the confidence level (Algorithm 1) to identify the appropriate score threshold.  
Experimental results support the validity of the method, demonstrating strong alignment between the desired error rate specified in the algorithm and the observed empirical error rates on a test set.  
The paper's strengths lie in its practical applicability—particularly with the softmax response score function, which can be seamlessly applied to any pretrained neural network—and the straightforward specification of the desired confidence level and error rate, modeled after ref [5]. While the work builds on established concepts, its meticulous validation of these concepts significantly enhances its value.  
However, the paper lacks simple baseline comparisons that could highlight the necessity of using the binomial search and the classifier error rate bound. Specifically, it would be insightful to examine what happens if the score threshold is chosen as the lowest value for which the error rate on a given tuning set falls below the specified target. Would the results differ substantially from those obtained using the bound from Lemma 3.1? Including such a baseline would better justify the advanced techniques employed in the paper and would positively influence my evaluation of the work.  
Minor issue: Algorithm 1 references an uninitialized variable, r*.