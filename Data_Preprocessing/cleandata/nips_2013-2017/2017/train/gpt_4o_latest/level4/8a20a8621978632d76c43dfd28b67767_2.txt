The paper presents a unified framework for interpreting model predictions on individual inputs. Within the class of additive feature importance methods, there exists a unique solution that adheres to a specified set of desirable properties. The authors propose efficient approximation techniques for computing SHAP values.
The authors address a highly significant problem that has garnered substantial attention in recent years. The paper is well-written and enjoyable to read. The proposed properties for desirable methods are intuitive, although the local accuracy criterion appears overly restrictive. The use of Shapley values and the associated theoretical properties is highly innovative. A notable sanity check is that the method should return the original model when it is inherently interpretable, such as when features are binary (0/1). However, based on Corollary 1, this does not seem to hold since E[x_j] is nonzero. Could the authors provide further clarification on this point? Additionally, offering more details regarding the computational cost (e.g., runtime) of DeepSHAP would help practitioners better understand the method's practical applicability.