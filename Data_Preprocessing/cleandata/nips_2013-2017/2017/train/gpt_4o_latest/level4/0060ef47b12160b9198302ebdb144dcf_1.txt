The paper introduces a method for learning saliency masks. This method leverages a neural network and is capable of processing multiple images per second, demonstrating its computational efficiency.
In my opinion, the paper is borderline. I would neither strongly oppose its rejection nor its acceptance. I appreciate the concept of learning to explain a model and recognize that the paper presents some promising ideas.
While there are no glaring errors, there are notable limitations:  
- Saliency is only evaluated indirectly, either through weakly supervised localization or the proposed saliency metric. Both approaches have evident shortcomings, and I believe these limitations should be explicitly addressed in the paper.
The weakly supervised localization metric is not an ideal measure. If contextual information surrounding an object is critical for determining its class, object localization may not necessarily align with saliency quality. Although the results on weakly supervised localization are intriguing, there is a significant caveat in using this as a saliency quality metric.
The saliency metric itself has limitations due to its application. The salient region is cropped and then rescaled to the original image size while maintaining the aspect ratio. This process could introduce two potential artifacts. First, altering the aspect ratio might affect the classifier's ability to correctly identify the object. Second, the proposed metric favors smaller salient regions. When a small region is heavily scaled up for re-classification, the scale at which the object is presented to the classifier might not be optimal. While convolutional networks are generally translation-invariant, their scale invariance must be learned, and this invariance has practical limits.
Another aspect that remains unexplored is the dependence of the masking model on the architecture used for learning the masks. Did the authors experiment with different architectures, and if so, how did this impact the results?
Minor Comments:
- Are the results in Table 1 reported for all classes or only for the correct class?  
- Please specify which LRP variant and parameter settings were used for comparison. LRP has multiple variants, such as epsilon and alpha-beta, with associated parameters.
---
Post-Rebuttal Comments:
The effectiveness of the proposed saliency metric is heavily dependent on the classifier's quality and scale invariance, which significantly restricts the method's applicability. Specifically:  
- The method cannot be applied to models during the training phase or to models lacking scale invariance.  
- This limits its applicability to other domains, such as spectrogram analysis using CNNs.  
- The method is not universally applicable to black-box classifiers, contrary to the claim made in the title.
Additionally, the authors' response suggests a strong reliance on the masking network.  
- Consequently, it is unclear whether the saliency being visualized pertains to the U-network or the masking network.
If these limitations and dependencies are thoroughly discussed in the paper, I believe it would be balanced enough for publication. However, if these issues remain unaddressed, I do not think the paper should be accepted.