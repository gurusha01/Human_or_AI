The paper investigates kernel regression within the high-dimensional setting. Its foundation lies in the "additive model," which assumes regressors of the form  
f = sump fp(X_p),  
where correlations across dimensions are disregarded. Recognizing the limitations of ignoring such correlations, the authors extend this to the "group additive model," where dimensions are grouped to account for correlations within groups. The paper provides a formal analysis of this framework and proposes a set of (somewhat) ad hoc algorithms to identify optimal groupings. Results are demonstrated on small synthetic datasets and real-world examples.
In my view, the primary issue with the paper is its inadequate discussion of related work, making it challenging for me (as a non-expert) to assess the true novelty of the contributions. For instance, the task of identifying optimal groups in data is also explored in areas like "structured sparsity" and in the context of learning graphical models or Bayesian networks. However, the authors fail to reference these fields. Similarly, the problem can be framed as a form of "feature selection," yet this is not addressed either. The discussion of related work is essentially limited to a single KDD-2015 paper [8], which is insufficient for me to fully evaluate the originality of the work.
That said, the theoretical contributions appear to be novel. The authors define a straightforward complexity measure for groupings (favoring many small groups), derived as an upper bound on the covering number. This approach seems reasonable. However, a drawback is that the proposed measure is not easily optimized. The authors suggest either an exhaustive search (which is computationally expensive) or a greedy approach (similar to forward feature selection). While I understand that optimizing discrete functions, such as those describing optimal groupings, is inherently challenging, I was somewhat disappointed that the authors did not develop a more efficient optimization method beyond cross-validation. Although they mention "investigating and comparing different measures" (line 174), they provide no additional details, leaving it difficult to assess the appropriateness of the chosen measure.
On the experimental side, the authors validate their framework using simple synthetic examples and apply it to the Boston Housing dataset. However, they do not include any baselines or comparisons with other methods. As a result, it is difficult to gauge the quality of the presented results without a point of reference.
== Post rebuttal ==  
The authors addressed some of my concerns in their rebuttal. Nonetheless, I still find the experimental evaluation insufficient and believe the discussion of related work remains unacceptably weak, particularly in connecting their ideas to broader machine learning literature. Despite these shortcomings, I acknowledge that the paper makes valid contributions, and I have adjusted my score upward. I strongly recommend that the authors significantly enhance their discussion of related work prior to publication.