This paper presents the deep dynamic Poisson factorization model, which extends traditional PF by incorporating temporal dependencies. Unlike prior work on dynamic PF, the authors employ a simplified recurrent neural network variant to capture long-term dependencies. Variational inference is used for parameter estimation, with an additional optimization step for the neural network parameters. The model is evaluated on five real-world datasets.
Overall, I find the proposed idea potentially promising, but I believe the paper requires significant improvements in its execution to meet the standards of a conference like NIPS. Below are my detailed comments:
+ The structure in Eq. 4 does not align with a typical RNN framework, as h_t^{(n)} depends solely on the top-layer memory vectors and not on previous time steps within the same layer. Could the authors clarify the rationale behind this simplified structure?
+ In Section 2, several model equations are missing. For instance, it is unclear how the Gamma distribution in Eq. 4 is parameterized or what distribution generates theta_t in Eq. 3.
+ I disagree with the discussion in lines 110-118 regarding "implicit distributions." Equations 9 and 10 are explicit, as they represent Gamma distributions with specified shapes and rates. Since the distribution of theta_tk (Eq. 9) can be derived in closed form given h^{(0)}, it cannot be classified as implicit. The same critique applies to h in Eq. 10.
+ Lines 30-31: The statement, "This method may have weak points in analyzing other data with different pattern long-time dependence, such as fanatical data and disaster data," is unclear. Could the authors elaborate?
+ The subsection in lines 133-155 is difficult to follow. What exactly is the "loss function" referenced in Eq. 15?
+ MSE/PMSE is generally not an appropriate metric for PF-like models. The authors should include additional metrics, such as predictive log-likelihood, to better evaluate the model's performance.
+ The value of K used in the experiments (line 207) appears too small. I recommend testing with larger values, such as K=100 or higher.
+ The discussion in lines 224-232 does not clearly connect to Fig. 3. Further clarification is needed.
+ The update equations for the variational inference procedure (Eqs. 11-14) could be moved to the supplementary material for conciseness.
+ The caption for Fig. 4 is difficult to read and should be revised for clarity.
+ I strongly recommend adhering to general writing guidelines, particularly regarding the overuse of passive voice (notably in the abstract).
+ The paper's writing quality is subpar and contains numerous typos. Below are some examples:
  - Line 15: "high-dimensional"
  - Line 22: "factorize"
  - Line 24: "property of the"
  - Lines 29, 34: "Dirichlet"
  - Line 34: "nested"
  - Fig. 1: "visual representation"
  - Fig. 1: "transmission" (this term may not be appropriate in this context)
  - Incomplete sentences (e.g., line 49)
  - Missing articles (e.g., "Although Dirichlet distribution is often used as prior distribution")