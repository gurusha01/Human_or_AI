The paper addresses the challenge of variance reduction in scenarios where individual examples may undergo random perturbations (e.g., for images, such perturbations could include small rotations, scalings, noise addition, etc.). The proposed method builds upon the MISO/Finito algorithms, employing a surrogate function for each (perturbed) example that is represented as a moving average of quadratic lower bounds. However, due to the permutations, these lower bounds are approximate, as they reflect the lower bound for the specific current instance of the permutation applied to the example, rather than the expectation over all possible permutations. The authors demonstrate that, unlike SGD, the convergence rate of their algorithm is influenced solely by the variance arising from the permutations (\(\sigma_{\rho}\)) at the optimum, rather than the total variance, which also includes contributions from the sampling of examples. The paper concludes with a compelling set of experiments.
Although the algorithm itself feels somewhat incremental, the problem setting is significant, the algorithm is intuitive, and the results are thorough, offering both strong theoretical guarantees and robust experimental validation.
One critique pertains to the presentation of the plots: the font sizes in the legends are too small, the yellow curve lacks sufficient contrast against the white background, and the curves are distinguished solely by color rather than by symbols or line styles, making them difficult (or impossible) to interpret in black-and-white print.