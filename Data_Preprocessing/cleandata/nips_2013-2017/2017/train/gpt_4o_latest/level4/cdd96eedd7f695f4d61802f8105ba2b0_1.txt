This paper introduces an unsupervised framework for network embedding learning. The key contributions are: a) formulating an objective function grounded in matrix tri-factorization, which simultaneously preserves both the graph's proximity and its global node ranking; b) providing comprehensive theoretical derivations to support the proposed objective function; and c) evaluating the quality of node embeddings, obtained by optimizing the objective function through a neural network, on three real-world datasets and multiple data mining tasks.
Pros:
- The paper demonstrates strong theoretical underpinnings, and the loss function is well-justified from the perspectives of proximity preservation and global ranking preservation.
- The experimental results are robust across all datasets and tasks.
Cons:
- The paper allocates excessive focus to theoretical derivations while dedicating insufficient attention to experiments. Some lemmas, such as Lemma 3.5 and Lemma 3.6, are relatively trivial and could either be omitted or presented more concisely.
- The section from Line 169 to Line 184 is not directly relevant to the final objective function. Specifically, maximizing modularity is a special case of Equation (6) when alpha = 1, but this function is not incorporated into the final loss function, making this part tangential to the main framework.
- Incorporating node ranking information into the framework appears relatively straightforward. A simple approach, such as adding a secondary objective (as done in this paper), achieves this, and while the experimental results indicate performance improvement, this aspect could be further refined.
- The writing could be improved in several areas. For instance, experimental results under different evaluation metrics should be presented separately. Additionally, the authors are encouraged to include one more baseline, such as GCN (Kipf and Welling, ICLR 2017), which is a strong method for node embedding learning based on graph convolution networks.