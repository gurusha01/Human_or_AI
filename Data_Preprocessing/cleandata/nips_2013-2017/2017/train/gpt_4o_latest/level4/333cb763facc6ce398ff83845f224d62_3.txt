The paper presents a novel covariance structure for multi-output Gaussian Processes (GPs), which extends the spectral approach (Bochner Theorem) for kernel construction as introduced by A. G. Adams and R. P. Adams. A notable advantage of the proposed method is that its parameters are interpretable, enabling insights such as the delay between outputs or phase differences.
Defining covariance structures for multi-output GPs is a challenging area with relatively few existing approaches. The authors' proposed method is grounded in solid theoretical foundations, and its efficacy is demonstrated across multiple datasets.
The method is clearly articulated in a well-written manuscript, and the chosen illustrations appear appropriate and relevant. Assuming parameter learning does not pose significant challenges (though the paper provides limited information on this aspect), I anticipate that this method could become a standard approach for multi-output GPs.
Questions:  
* How does the method perform when the training dataset is sparse?  
* (A curiosity) In cases where one channel has a large length-scale and another has a small length-scale, the two channels cannot exhibit high correlation. How is this scenario represented in your model?
Comments:  
* In the synthetic example (Section 4.1), please specify the number of training points used.
Minor remarks: It seems a word is missing in lines 74 and 140.