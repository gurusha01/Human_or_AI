Paraphrased Review:
Summary: The authors investigate the online Isotonic regression problem within the framework of the random permutation model. In this setting, the adversary preselects the set of instances \( x1, \ldots, xn \) in advance and reveals them in a random order. At each round \( t \), the instance \( x{it} \) is disclosed, and the algorithm provides a prediction \( \hat{y}{it} \). Subsequently, the adversary reveals the true label \( y{it} \), and the algorithm incurs a squared loss of \( (\hat{y}{it} - y{it})^2 \). The objective is to minimize regret.
Prior work has established that, in the case of an arbitrary sequence of instances, the regret can grow linearly with the number of rounds. That same work also analyzed the fixed design model, where the sequence of instances is predetermined and known to the algorithm in advance, and proposed an algorithm achieving an optimal regret of approximately \( \tilde{T}^{1/3} \).
In the present study, the authors extend these results to the more general random permutation model. They propose a (computationally inefficient) algorithm that achieves the optimal regret of approximately \( \tilde{T}^{1/3} \). Additionally, they demonstrate that a broad class of efficient algorithms, referred to as Forward Algorithms, achieve a regret of approximately \( \tilde{T}^{1/2} \) in the general case, but can achieve the optimal \( \tilde{T}^{1/3} \) regret when the revealed labels are isotonic.
Opinion: I find the problem of online Isotonic regression to be both intriguing and significant, and the authors have provided strong results in a natural and compelling model (especially given that the fully adversarial model is intractable). While the efficient algorithms presented do not attain optimal regret bounds, the authors have made a meaningful contribution by analyzing the performance of a large class of algorithms and providing strong regret guarantees. Furthermore, their conjecture regarding an efficient optimal algorithm is a valuable direction for future work. I believe the techniques introduced in this paper will be instrumental for advancing research in this area.
I recommend acceptance.
One concern: I would appreciate it if the authors could elaborate on why this particular notion of regret is natural. Since the algorithm/learner is not restricted to producing isotonic outputs, it seems to me that the current definition of regret could potentially be negative.
Edit: After reviewing the authors' feedback, my evaluation remains unchanged.