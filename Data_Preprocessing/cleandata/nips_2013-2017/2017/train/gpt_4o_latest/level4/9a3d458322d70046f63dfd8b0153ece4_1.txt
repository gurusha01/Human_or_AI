The authors introduce the concept of generalized Hamming distance (GHD) to provide insights into the effectiveness of Batch Normalization (BN) and ReLU activation functions.
However, after thoroughly reading the paper, I remain unclear about its primary contribution. The authors assert that GHD offers a more comprehensive understanding of BN and ReLUs, dedicating two paragraphs on pages 4 and 5 to explain this. The explanation for BN is summarized in the following statement:
"It turns out BN is indeed attempting to compensate for deficiencies in neuron outputs with respect to GHD. This surprising observation indeed adheres to our conjecture that an optimized neuron should faithfully measure the GHD between inputs and weights."
I fail to see how this statement elucidates the effects or performance of Batch Normalization.
Subsequently, the authors propose a generalized Hamming network (GHN) and claim that it "demystified and confirmed the effectiveness of practical techniques such as batch normalization and ReLU." 
In summary, the paper is poorly written, lacks significant technical contributions or novelty, and fails to provide theoretical insights into the effectiveness of BN or ReLUs. Beyond the unclear novelty and technical merit, the manuscript is riddled with numerous typos, grammatical errors, and syntax issues (a list of which is provided below, based on the abstract and introduction).
This paper is a clear rejection.
Typos and grammar/syntax issues:
Abstract:  
- "generalized hamming network (GNN)"  
  → "generalized hamming network (GHN)"  
- "GHN not only lends itself to rigiour analysis"  
  → "GHN not only lends itself to rigorous analysis"  
- "but also demonstrates superior performances"  
  → "but also demonstrates superior performance"  
Introduction:  
- "computational neutral networks"  
  → "computational neural networks"  
- "has given birth"  
  → "have given birth"  
- "to rectifying misunderstanding of neural computing"  
  → Unclear phrasing; the intended meaning is ambiguous.  
- "Once the appropriate rectification is applied ,"  
  → "Once the appropriate rectification is applied,"  
- "the ill effects of internal covariate shift is automatically eradicated"  
  → "the ill effects of internal covariate shift are automatically eradicated"  
- "The resulted learning process"  
  → "The resulting learning process"  
- "lends itself to rigiour analysis"  
  → "lends itself to rigorous analysis"  
- "the flexaible knowledge"  
  → "the flexible knowledge"  
- "are equivalent and convertible with other"  
  → "are equivalent and convertible with others" or "other architectures?"  
- "successful applications of FNN"  
  → "successful applications of FNNs"