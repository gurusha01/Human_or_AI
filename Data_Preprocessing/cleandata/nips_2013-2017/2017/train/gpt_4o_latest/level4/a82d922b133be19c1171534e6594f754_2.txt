This paper introduces an efficiently computable approximation of leave-one-out cross-validation (LOOCV) tailored for parametric learning problems, alongside an algorithm designed for the joint optimization of regularization parameters and model parameters. The proposed methods appear to be both novel and broadly applicable.
The paper begins with a clear and accessible exposition, although it might benefit from dedicating slightly less space to foundational material. This adjustment could allow for a more detailed treatment of the later sections, where the notation becomes particularly dense.
Could you provide more insights into the comparison between the proposed approximation (ALOOCV) and LOOCV computed on a subset of data points, as mentioned in lines 137-140? Specifically, how do they compare in terms of computational cost and approximation accuracy?
Additional comments:
- Line 75: Are you referring to PRESS? If so, please explicitly name it.
- Line 90: The phrase "no assumptions on the distribution"—does this imply the absence of a prior distribution?
- Definition 7: The displayed equation seems to be part of the "such that" clause in the preceding sentence. Consider integrating it into the same sentence for clarity. Additionally, the definition seems restrictive—why would an analytic function fail to satisfy it due to the "there exists one and only one" condition? For instance, what about a two-dimensional function with non-differentiabilities in its upper-right quadrant, where it remains analytic along certain cross-sections?
- Lines 186-187: In light of the remarks on Definition 7, the phrasing here feels slightly awkward. A more precise formulation might be, "We remark that the theory could be extended to ..."
- Line 250: Are you implying that the regularization parameter is not jointly learned in the second example? If Section 4's material does not apply in this case, I may have missed the explanation—please clarify this point in that section.
Typographic suggestions:
- Line 200: Replace "few" with "a few."
- References: Ensure proper capitalization of terms like "Bayes" by using curly braces (e.g., `{}`) in the bibliography.