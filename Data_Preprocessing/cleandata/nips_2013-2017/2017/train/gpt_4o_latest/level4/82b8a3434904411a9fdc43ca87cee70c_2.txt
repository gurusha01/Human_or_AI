The paper introduces a method tailored for optimization problems commonly encountered in machine learning applications. The general loss function to be minimized is expressed as a sum of smooth-convex functions combined with a convex regularization term. The proposed method specifically addresses scenarios where perturbations are introduced into the data. Since data sampling inherently introduces stochasticity, Stochastic Gradient Descent (SGD) typically requires modifications to mitigate gradient variance [14,28]. However, in the presence of perturbed data, this variance becomes even more pronounced. The authors argue that existing modifications to SGD for variance reduction are often impractical for online training because they necessitate storing either the full gradients or dual variables. The proposed SGD variant (S-MIMO) addresses these limitations while retaining the accelerated properties of SCG variants used in batch processing.
My primary concern with the paper is that, in recent years, numerous SGD variants have been proposed, making it challenging to assess whether the presented comparisons are comprehensive and fair. To illustrate, I suggest a potential experiment that is absent from the current work (among others).
The SVRG method [14] involves computing the full gradient after every m stochastic iterations, which assumes access to the entire dataset. This is the authors' main argument for asserting that SVRG is unsuitable for online training. However, if we consider the case of finite data, each perturbed instance can effectively be treated as new data. It would be interesting to evaluate SVRG in this context by employing an epoch-based strategy (where each epoch uses different perturbations) and comparing its performance against S-MIMO. A similar argument could be made for using SVRG in batch processing, where the (full) gradient is updated after each batch.
Now, if the outlined approach for adapting SVRG to optimization problems of the form (2) proves effective, does it justify a new paper proposing this "new method"? In my opinion, it does notâ€”certainly not at a conference like NeurIPS. This is precisely the type of "variant" that contributes to the saturation of the literature.
In summary, the authors should strive to compare their algorithm against as many variants as possible, even if this requires implementing seemingly trivial modifications (such as the one sketched above).
Remark: I did not verify the algebra in all the proofs provided in the supplementary material. However, I was able to follow the text, and the arguments appear to be correct.