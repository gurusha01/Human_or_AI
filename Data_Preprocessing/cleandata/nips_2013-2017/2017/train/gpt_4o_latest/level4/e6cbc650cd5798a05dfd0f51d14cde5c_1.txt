This paper introduces a recurrent network for sparse estimation, drawing inspiration from sparse Bayesian learning (SBL). The authors demonstrate that a recurrent architecture can realize a variant of SBL and use simulations to reveal that different quantities exhibit distinct temporal dynamics. This observation motivates the incorporation of ideas from recurrent-network design to refine the architecture. The resulting recurrent network appears to outperform optimization-based methods in simulations and two specific applications.
Strengths: The concept of leveraging a recurrent network for sparse estimation holds significant potential impact. The paper is exceptionally well written, with the authors providing detailed justifications for their design choices. The numerical experiments are comprehensive and suggest that the proposed approach is effective for tackling challenging sparse-decomposition problems.
Weaknesses: Many implementation details regarding the method and experiments are relegated to the supplementary material, leaving the main paper somewhat lacking in specificity. However, this is understandable given the constraints on paper length.