This paper addresses the L1-regularized ERM problem, proposing a novel algorithm that integrates several established techniques: greedy coordinate descent, SVRG, and acceleration. The authors aim to combine Katyusha (an accelerated SVRG method that randomizes over a minibatch of examples \(n\)) with greedy coordinate descent (which updates a subset of the \(d\) feature vectors in a "greedy" manner). The approach taken in this paper is both innovative and surprisingly simple, yielding an effective solution.
The authors note (citing prior work) that in the absence of L1 regularization and in the batch setting, greedy coordinate descent can be interpreted as a gradient descent step if the L1 norm is used in the upper bound instead of the standard L2 norm (with adjustments to the scaling/Lipschitz constant). However, when the L1 regularizer is introduced, this property no longer holds, and only a subset of variables may be updated. Despite this, the resulting method can still be viewed as a variant of greedy coordinate descent. By combining this strategy with Katyusha, the authors develop a method that is accelerated (via Katyusha momentum), stochastic (over \(n\)), and greedy (over \(d\)). They demonstrate that, in certain scenarios, the proposed method achieves better complexity than Katyusha itself.
A critical component of the proposed method is the efficient resolution of the subproblems involved, particularly subproblem (3). The authors introduce a novel and efficient method called SOTOPO to solve this. Their approach begins with a variational reformulation of the squared L1 norm as a convex minimization problem over the unit simplex. By rewriting the problem as a min-min problem over the original and auxiliary variables and switching the order of minimization, they derive an efficient solution for (3). This contribution appears to have independent value, which is commendable.
Overall, I find this paper to be well-written and compelling. It introduces interesting and novel ideas, results in an efficient algorithm, and demonstrates practical effectiveness across various regimes (notably for both \(n \gg d\) and \(n \ll d\), though the latter warrants further investigation). Additionally, the proposed method improves complexity for the L1-regularized ERM problem in specific settings.
Comments:
1. Line 31: There are earlier contributions to accelerated randomized coordinate descent than [11, 20]. The first is by Nesterov [2012], though it suffered from expensive iterations. This issue was addressed by Lee and Sidford [arXiv:1305.1922] and Fercoq & Richtarik [arXiv:1312.5799]. Further advancements were made with the introduction of nonuniform probabilities into accelerated randomized coordinate descent by Qu and Richtarik [arXiv:1412.8060], which was later extended to the strongly convex setting by Allen-Zhu, Qu, Richtarik, and Yuan [arXiv:1512.09103], and independently by Nesterov and Stich [2016].
2. The setup of this paper is reminiscent of a similar synthesis of two methods: SVRG and randomized coordinate descent, as presented in Konecny, Qu, and Richtarik [arXiv:1412.6293]. However, their method is not accelerated (as Katyusha had not been introduced at the time) and uses randomized rather than greedy coordinate descent. It would be interesting to explore the connections between these approaches.
3. Regarding experiments, the APPROX method by Fercoq and Richtarik [arXiv:1312.5799] should be included. While it is a batch method in \(n\), it can randomize over subsets of the \(d\) variables and leverage sparsity in the data. This method is likely to perform well in the high-\(d\), low-\(n\) regime.
4. The effect of \(\eta\) on the sparsity level in subproblem (3)—even when \(\lambda = 0\)—should be clarified. If \(\eta\) is sufficiently small, the bound used effectively upper bounds the standard quadratic approximation, rendering SOTOPO unnecessary and allowing Katyusha to be applied directly. A discussion of the interplay between L1 and L2 norms in this context would be valuable.
Minor Comments:
1. What are (???) in Step 1 of Algorithm 1?  
2. Lines 19 and 20: "are referred to" → "refer to"  
3. Line 19: "that uses some algebra trick to" → "using an elusive algebra trick to"  
4. Line 20: "samples" → "sample"  
5. Line 27: "resulted" → "resulting" (this issue recurs throughout the paper, e.g., lines 51, 56, etc.)  
6. Line 29: "reduces" → "reduce"  
7. Line 38: "preferable than" → "preferable to"  
8. Line 40: "GSD has much" → "GCD to have much"  
9. Line 50: "entries" → "entry"  
10. Line 55: "sqoximation" → "approximation"  
11. Line 88: "is" → "are"  
12. Line 99: "While" → "Since"  
13. Line 121: "of the" → "of"  
Post-Rebuttal Feedback:
I am maintaining my decision.