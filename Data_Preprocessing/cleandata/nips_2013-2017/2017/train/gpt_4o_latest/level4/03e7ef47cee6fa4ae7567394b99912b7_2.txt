Review:
This paper establishes upper and lower bounds on the query complexity of clustering based on noiseless pairwise comparisons, incorporating random side-information for each pair. While I am somewhat familiar with the related literature, my understanding is not exhaustive, making it challenging to fully assess the significance of the contributions. Additionally, the paper is dense, and I was unable to dedicate as much time as I would have liked to verify the correctness of the results—particularly the lengthy proof of the upper bound.
My overall impression of this paper, as well as the accompanying one on noisy queries without side information, is that the contributions appear valuable (assuming correctness). However, the writing requires substantial improvement. While I recognize that the contributions are more critical than the presentation, the numerous writing issues leave my recommendation on the borderline. Another round of reviews to verify suggested revisions would have been helpful, but I understand this is not permitted for NIPS.
For this paper specifically, there are several relevant works that were not cited:
- The idea of generalizing Bernoulli(p) and Bernoulli(q) to a broader distribution in the stochastic block model is not novel. A search for "labeled [or labelled] stochastic block model" or "weighted stochastic block model" reveals several papers exploring similar generalizations.
- At least one paper examines the stochastic block model (SBM) with an active learning component: "Active Learning for Community Detection in Stochastic Block Models" (Gadde et al., ISIT 2016). Although it uses a different querying model (querying a single node to obtain its label), for fixed k (e.g., k=2 or k=100) and linear-sized communities, this is effectively equivalent to the pairwise querying model. By quickly identifying one node from each community via random sampling, the label of any new node can be determined using pairwise queries. At first glance, your lower bound seems to contradict their sublinear-sample upper bound, but this might be because your lower bound assumes k → ∞ (see below).
In light of these works, I recommend the authors revise or remove statements such as "we initiate a rigorous theoretical study," "significantly generalizes them," "This is the first work that...," "generalize them in a significant way," and "There is no systematic theoretical study."
Additional comments:
- The model/problem should be presented more clearly. It appears the paper focuses on minimax bounds, but this is not explicitly stated. Furthermore, does the minimax model impose any restrictions on cluster sizes? For example, does it allow k-1 clusters of size 1 and one cluster of size n-k+1?
- Theorem 2, as stated, seems incorrect. For the SBM with k=2 (or likely any k=O(1)), it is known that no queries are required in certain cases where the Hellinger distance scales as log(n)/n. Part of the issue seems to be that the proof assumes k → ∞, which is not mentioned in the theorem statement (this must be explicitly stated). Please carefully verify whether Theorem 2 more broadly contradicts cases where clustering is possible with Q=0.
- The numerical section is of limited value, as it does not compare against existing works and only benchmarks against trivial baselines. Are your methods truly the only ones that can be considered or implemented?
- Several sentences are unclear or confusing, such as "assume, otherwise the clustering is done" (is there missing text after "assume"?) and "the theorem is already proved from the nk lower bound" (doesn't this lower bound apply only when there is no side information?).
- The paper contains numerous grammar issues, typos, and awkward phrasing. Errors in capitalization, plurals, spacing, and the use of articles (a/an/the) are frequent. Commas are often misused (e.g., they should not typically follow phrases like "let," "we have," "this means," "assume that," "since," "while," or "note that," and rarely appear before equations). Sentences should not begin with "And," "Or," or "Plus." The word "else" is used oddly (often "otherwise" would be better). Footnotes should begin with a capital letter and end with a period. This list is not exhaustive—regardless of the decision, I strongly encourage the authors to thoroughly proofread the paper.
Minor comments:
- The abstract is overly long, and more generally, the paper spends three pages before discussing its contributions.
- Is the use of "Monte Carlo" and "Las Vegas" terminology standard? When "Las Vegas" is first mentioned on page 4, it should be explicitly tied to average query complexity (the word "average" is missing).
- Footnote 1: Should the "1-" really appear after p=?
- In the formal problem statement, "find Q subset of V x V" makes it seem like the algorithm is non-adaptive.
- I disagree with the phrase "clearly exhibiting" in the final sentence of the Simulations section.
- Many brackets throughout the appendix are too small.
[Post-Author Feedback Comments]
The authors clarified several points in their responses, and I have updated my recommendation to acceptance. However, I strongly urge a careful revision of the final version to address the comments above. While I was the only reviewer to raise significant concerns about the writing, I believe these issues could impact many NIPS readers, especially those from different academic backgrounds.
Specific comments:
- The authors seem to misunderstand if they believe "issues like capitalization and misplaced commas" were decisive in my review. These were mentioned as areas for improvement, not as reasons for the borderline recommendation.
- Thank you for clarifying the lack of contradiction with Gadde's paper.
- It is critical that theorems and lemmas are stated precisely. For example, if a result holds only for sufficiently large k, this must be explicitly stated in the theorem, not just in the proof.
- Regarding grammar, I still recommend revising the use of "Else," "And," "Or," "Plus," and the sentence "assume, otherwise...". I remain convinced that these are either grammatically incorrect or inappropriate for an academic paper (the authors may disagree).