The paper addresses an important yet relatively underexplored topic in connectomics: error detection and targeted error correction. This is a critical area of research, as such methods are essential for optimizing the allocation of human proofreading efforts. The authors highlight the observation that humans find it significantly easier to detect segmentation errors than to correct them, and they propose automating this process.
The authors specifically introduce an error detection module implemented as a multi-scale 3D CNN. This network takes a binary object mask as input and predicts whether it corresponds to an object in the ground truth segmentation. During inference, the network is applied to overlapping windows arranged on a grid to detect and localize segmentation errors.
Additionally, the paper presents an error correction module, which is also a 3D CNN. This module reconstructs the object containing the central pixel, drawing inspiration from flood-filling networks (FFNs), which are cited as related work. Unlike FFNs, which predict binary masks, the authors propose predicting a k-dimensional vector for each voxel, where voxels belonging to the same object share similar vectors, while those from different objects do not. This vector field is subsequently converted into a binary mask using an exponential transform. The stated motivation for this approach is to reduce reliance on the precise location of the central object. However, the authors should provide additional justification for their choice of the exponential transform, whether alternative forms were considered, the specific value of k used in their experiments, and experimental evidence demonstrating that this approach outperforms direct binary encoding of the output.
The paper lacks details regarding the loss functions used to train the network, which is particularly critical for the error correction module. Since the k-dimensional vectors are arbitrary and cannot be fully defined by the training data, this omission is notable.
In Section 5, the confidence threshold requires further clarification. How was this confidence computed, and what specific threshold was used? The text also mentions a termination condition based on either achieving an error-free state as predicted by the error detector or performing two corrections per iteration. The rationale behind this condition should be elaborated. Would applying the network more than twice lead to improved segmentation results? Furthermore, would such a process converge to a stable segmentation state?
It should also be explicitly stated whether the error correction module handles both split and merge errors, or only split errors. If merge errors are addressed, the paper should clarify how these are managed both at the supervoxel graph level and within individual supervoxels.
In Section 6.3, the parameters of the Adam optimizer should be explicitly reported.
The paper provides a thorough performance analysis of the proposed systems. The authors deserve recognition for computing per-object VI scores, which enhance the interpretability of the metrics.
Technical comments on the text:
- Figure 1 is difficult to interpret, and the role of the nodes is unclear. While the caption refers to horizontal layers, the data flow does not appear to follow a vertical direction.
- Line 48 states that "the overhead of agglomeration prohibits the use of deep learning." This claim seems inaccurate, as deep learning has been successfully applied to agglomeration tasks. For example, see [https://papers.nips.cc/paper/6595-combinatorial-energy-learning-for-image-segmentation.pdf](https://papers.nips.cc/paper/6595-combinatorial-energy-learning-for-image-segmentation.pdf) for a relevant example.
- Appendix A, Table 4: The layer IDs are non-consecutive. If this is intentional, the meaning of these IDs should be clarified.