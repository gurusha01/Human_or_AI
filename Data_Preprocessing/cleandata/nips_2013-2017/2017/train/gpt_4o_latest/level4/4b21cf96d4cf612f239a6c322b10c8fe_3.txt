This paper introduces and evaluates two variations of a prior on the latent space of a VAE for image captioning. Both approaches utilize a Gaussian mixture model (GMM) prior on the latent space, with the second, more effective variant encouraging the clusters to correspond to objects within a given image. In this approach, any image is generated as a linear combination of samples from clusters associated with the objects it contains.
Detailed comments:
* The manuscript is well-written and appears to be thoroughly evaluated against established baselines. While the core idea is relatively straightforward and might not constitute a standalone contribution, the experimental results seem robust and demonstrate state-of-the-art performance when compared to the online MSCOCO baseline dataset. That said, I am curious why the CGAN was not included as a benchmark, particularly given the availability of techniques like the Gumbel-Softmax trick for sentence generation in GAN models.
* It could be worthwhile to explore combining the GMM latent space model with a determinantal point process (DPP) prior over the cluster centers to further promote diversity in the representations. Additionally, investigating a hierarchical latent space might provide interesting insights. However, I strongly believe that the performance of such models, especially on smaller datasets, is heavily influenced by how closely the implicit prior—determined by the choice of latent structure and mapping—aligns with the true data-generating distribution. In this context, the AG-CVAE may already be approaching optimality.