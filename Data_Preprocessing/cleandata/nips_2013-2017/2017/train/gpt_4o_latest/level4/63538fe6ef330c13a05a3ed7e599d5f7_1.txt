%%%% Summary  
The authors address constrained convex optimization problems characterized by conic constraints defined by a bounded set of atoms. They introduce a linear oracle-based approach inspired by the Frank-Wolfe algorithm and Matching Pursuit techniques. The core algorithm, Non-Negative Matching Pursuit, is supplemented with several active set variants. The paper provides convergence analyses for all proposed algorithms under different conditions, demonstrating sublinear convergence rates for general objectives and linear rates for strongly convex objectives. The linear rates hinge on a novel geometric concept, the cone width. Finally, the authors validate their algorithm's utility through experiments on various machine learning tasks and datasets.
%%%% Main Comments  
I was unable to evaluate the affine-invariant algorithms and their analyses presented in the appendix.  
The paper presents intriguing and novel contributions to linear oracle-based optimization methods. However, the technical exposition has several shortcomings:  
- Theorem 2 is poorly presented and fails to offer a robust convergence guarantee.  
- The linear convergence rates depend on Theorem 8, which is relegated to the appendix, and its proof lacks sufficient clarity.  
- The lower bounds on the number of successful steps for each algorithm are not rigorously established, as they rely on an argument akin to "it works similarly in a related setting."  
The numerical experiments are extensive and persuasive, but the authors should provide empirical evidence demonstrating that the computational costs are comparable to those of competing methods for the experiments conducted.  
%%%% Details on the Main Comments  
%% Theorem 2  
The presentation and formulation of Theorem 2 (and the sublinear rates throughout the paper) follow this structure:  
- A fixed horizon \( T \) is given.  
- A bound \( \rho \) on the iterates \( x0, \dots, xT \) is assumed.  
- For all \( t > 0 \), the suboptimality is claimed to be of the order \( c / t \), where \( c \) depends on \( \rho \).  
Firstly, the proof cannot hold for all \( t > 0 \) but only for \( 0 < t \leq T \), as Equation (16) in the proof depends on the \( \rho \)-bound for \( x_t \), which is only guaranteed for \( t \leq T \).  
Secondly, the numerator involves \( \rho^2 \). If \( T \) increases, \( \rho \) could also grow, meaning the bound might not necessarily approach zero.  
This formulation is problematic. One potential solution is to impose a priori conditions (e.g., coercivity) to ensure that the sequence of iterates remains within a compact set, thereby enabling an upper bound independent of the horizon \( T \).  
In the proof, the statement "The reason being that \( f \) is convex, therefore, for \( t > 0 \), we have \( f(x_t) \leq f(0) \)" is unclear to me.  
%% Lemma 7 and Theorem 8  
Lemma 7  
I found Lemma 7 difficult to interpret. The equation is presented without explanation, leaving its meaning ambiguous. Is the equation defining \( K' \)? Or is \( K' \) chosen to satisfy this equation? Does it serve another purpose?  
Lemma 7 applies only to \( g \)-faces that are polytopes. Is this always the case? What happens if \( K \) is not a polytope? Can this assumption be made without loss of generality, or is it a typographical error?  
Theorem 8  
The presentation of Theorem 8 is problematic. In Lemma 7, \( r \) is not a feasible direction, while in Theorem 8, \( r \) is the gradient of \( f \) at \( x_t \). Theorem 8 states, "using the notation from Lemma 7," but the proof begins with "if \( r \) is a feasible direction." This inconsistency makes the argument difficult to follow.  
The notations from Lemma 7 are not consistently applied:  
- What is \( e \)? In Lemma 7, \( e \) is a variable defining a maximum, not a fixed quantity. This recurring misuse of notation complicates the proofs.  
- What is \( K \)? \( K \) is defined in Lemma 7 but not in Theorem 8.  
- Is \( K \) assumed to be a polytope? This should be clarified.  
The statement "As \( x \) is not optimal, by convexity we have \( \langle r, e \rangle > 0 \)" is unclear. Where is it assumed that \( x \) is not optimal, and how does this assumption lead to the inequality?  
The phrase "We then project \( r \) on the faces of cone(\( A \)) containing \( x \) until it is a feasible direction" is ambiguous. Does this mean projecting onto an intersection of faces, projecting onto each face iteratively, or something else? It would be clearer to state, "the projection is a feasible direction," as \( r \) is fixed as the gradient of \( f \). Allowing \( r \) to change algorithmically within the proof makes it difficult to verify the argument's correctness.  
Additionally, what prevents the resulting \( r \) from being zero? If \( r \) becomes null, the subsequent equation would be invalid.  
The proof then uses Lemma 7, which assumes \( r \) is not a feasible direction. This contradicts the earlier paragraph, leaving the argument unclear. At this point, I was completely lost and unable to follow the proof further.  
What is \( r' \) on line 723 and in the preceding equation?  
The proof seems to involve a recursive process, but the final statement is not adequately justified.  
%% Further Comments  
- Line 220: "max" should be replaced with "argmax."  
- I did not fully understand the non-negative matrix factorization experiment. Since the resulting approximation is of rank 10, does this imply that the authors ran their algorithm for only 10 steps?