The paper presents a novel framework, MAB-FDR, that integrates multi-armed bandit (MAB) algorithms with online false discovery rate (FDR) control to address key limitations in traditional A/B testing. The authors propose replacing sequences of A/B tests with sequences of best-arm MAB instances, enabling adaptive sampling and continuous monitoring while maintaining rigorous FDR control. The main contributions include (i) defining null hypotheses for MAB instances, (ii) deriving always-valid sequential p-values for continuous monitoring, and (iii) demonstrating that using online FDR rejection thresholds as confidence levels for MAB algorithms achieves low sample complexity, high power, and low FDR. Extensive simulations and real-world experiments, such as those using data from the New Yorker Cartoon Caption Contest, validate the framework's effectiveness.
Strengths
1. Innovative Framework: The integration of MAB algorithms with online FDR control is novel and addresses significant limitations in A/B testing, such as inefficiency in sample allocation and the risk of false discoveries due to continuous monitoring.
2. Theoretical Guarantees: The paper provides rigorous theoretical guarantees for both FDR control and power, supported by detailed proofs in the appendices.
3. Practical Applicability: The framework is highly relevant for real-world applications, such as clinical trials and online experimentation, where adaptive sampling and sequential decision-making are critical.
4. Extensive Evaluation: The authors conduct thorough experiments on both synthetic and real-world datasets, demonstrating the framework's advantages in terms of sample efficiency, power, and FDR control compared to baseline methods like AB-FDR and MAB-IND.
5. Modularity: The framework is flexible, allowing the use of different MAB algorithms and online FDR procedures, which makes it extensible to future improvements in either domain.
Weaknesses
1. Complexity of Implementation: While the theoretical contributions are strong, the practical implementation of the framework, especially the interaction between MAB and FDR components, may be challenging for practitioners without significant expertise.
2. Limited Discussion of Real-World Challenges: Although the framework is validated on real-world data, the paper does not deeply explore potential challenges, such as non-stationary environments or computational overhead, which could arise in large-scale deployments.
3. Dependence on Parameter Choices: The performance of the framework heavily depends on parameters like the FDR control rate (α) and the choice of the online FDR procedure (e.g., LORD). A more detailed discussion of parameter sensitivity would strengthen the paper.
4. Scalability: While the authors highlight the sample efficiency of MAB-FDR, the computational scalability of the framework for very large numbers of arms or experiments is not fully addressed.
Arguments for Acceptance
- The paper makes a significant contribution by combining two previously disparate areas—adaptive sampling and online FDR control—into a unified framework with strong theoretical guarantees.
- The proposed method has clear practical relevance and demonstrates superior performance in experiments compared to baseline approaches.
- The work opens up new avenues for research, as improvements in MAB or FDR methods can directly enhance the framework.
Arguments Against Acceptance
- The complexity of the framework and its implementation may limit its immediate adoption by practitioners.
- The paper could benefit from a more detailed discussion of real-world challenges and scalability concerns.
Recommendation
Overall, this paper represents a substantial and innovative contribution to the field. While there are some limitations, the strengths far outweigh the weaknesses. I recommend acceptance, with minor revisions to address practical implementation challenges and scalability concerns.