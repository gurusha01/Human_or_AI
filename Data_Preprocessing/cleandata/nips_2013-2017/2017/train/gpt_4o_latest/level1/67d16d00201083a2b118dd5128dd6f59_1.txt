This paper presents a novel approach to measuring distances between distributions while encoding invariance to additive symmetric noise, addressing a critical issue in nonparametric two-sample testing and learning on distributions. The authors propose two methods: (1) leveraging the asymmetry in paired differences for hypothesis testing, and (2) using phase functions to construct invariant features for robust learning algorithms. These methods aim to isolate the true underlying processes from irrelevant noise, a significant contribution to the field of kernel embeddings and distribution learning.
The proposed phase discrepancy (PhD) metric and phase features are particularly innovative, as they extend the utility of kernel embeddings by introducing invariance to symmetric noise. The authors demonstrate that phase features can be used for both hypothesis testing and learning tasks, providing robustness to noise impairments. The experimental results are compelling, showing that the proposed methods outperform traditional approaches like Maximum Mean Discrepancy (MMD) in scenarios with noise. For example, the Symmetric Mean Embedding (SME) test effectively controls Type I error under various noise conditions, and phase features demonstrate robustness in regression tasks on noisy datasets like Aerosol and Dark Matter.
Strengths:
1. Technical Soundness: The paper is technically rigorous, with well-supported theoretical foundations and detailed proofs in the appendices. The connection between phase functions and invariance to symmetric noise is clearly articulated.
2. Originality: The work introduces novel metrics and feature representations (PhD and phase features) that extend existing methods like MMD and kernel embeddings. The focus on invariance to noise is a fresh perspective in the field.
3. Significance: The methods address a practical and important problem in real-world data analysis, where noise often obscures meaningful differences. The experimental results demonstrate the utility of these methods in both hypothesis testing and learning tasks.
4. Clarity: The paper is well-organized, with a logical flow from problem formulation to theoretical contributions and experimental validation. The inclusion of synthetic and real-world datasets strengthens the applicability of the methods.
Weaknesses:
1. Complexity for Practitioners: While the theoretical contributions are strong, the methods may be challenging for practitioners to implement without significant expertise. Simplifying implementation details or providing open-source code would enhance usability.
2. PhD Test Limitations: The PhD test exhibits inflated Type I error rates under high noise levels, which the authors acknowledge. This limitation warrants further investigation or mitigation strategies.
3. Limited Exploration of Alternatives: While the paper compares its methods to MMD and related tests, a broader comparison with other state-of-the-art noise-robust methods could strengthen the evaluation.
Arguments for Acceptance:
- The paper addresses a critical gap in nonparametric testing and learning by introducing noise-invariant methods.
- The theoretical contributions are novel and significant, with potential to influence future research in kernel methods and distribution learning.
- The experimental results are robust and demonstrate clear advantages over existing methods.
Arguments Against Acceptance:
- The PhD test's limitations under high noise levels may reduce its reliability in certain applications.
- The methods' complexity could hinder adoption by practitioners, limiting their immediate impact.
Recommendation:
Overall, this paper makes a strong scientific contribution to the field of machine learning and kernel methods. While there are some limitations, the strengths far outweigh the weaknesses. I recommend acceptance, with minor revisions to address the PhD test's limitations and improve accessibility for practitioners.