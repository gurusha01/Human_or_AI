This paper introduces a novel randomized coordinate descent method, termed SMART-CD, for solving a broad class of composite convex optimization problems. The proposed method integrates four key techniques: smoothing, acceleration, homotopy, and non-uniform coordinate sampling. The authors establish rigorous convergence rate guarantees, achieving an \(O(n/k)\) rate, which is the best known for the problem template under consideration. They also provide numerical experiments to validate the theoretical results, comparing SMART-CD against state-of-the-art algorithms in applications such as brain imaging, support vector machines, and degenerate linear programming.
Strengths:
1. Technical Contributions: The paper addresses a significant gap in the literature by extending randomized coordinate descent methods to a general three-composite convex optimization problem. The incorporation of homotopy strategies to adaptively adjust the smoothness parameter is particularly innovative and reduces the complexity from \(O(n^2/k)\) to \(O(n/k)\).
2. Theoretical Rigor: The convergence guarantees are well-supported by detailed analysis, including special cases such as constrained optimization problems and separable structures. The results are clearly articulated and benchmarked against existing methods.
3. Practical Relevance: The algorithm demonstrates strong empirical performance on large-scale machine learning problems, including fMRI-based regression and SVMs. The inclusion of a restart strategy further enhances practical utility, particularly in settings with restricted strong convexity.
4. Clarity in Comparisons: The numerical experiments are comprehensive, comparing SMART-CD with a wide range of algorithms. The results effectively highlight the advantages of SMART-CD, particularly in terms of scalability and convergence behavior.
Weaknesses:
1. Clarity of Presentation: While the theoretical contributions are significant, the paper is dense and challenging to follow, particularly for readers unfamiliar with advanced convex optimization techniques. Simplifying some of the derivations or providing more intuitive explanations could improve accessibility.
2. Limited Discussion of Limitations: The paper does not sufficiently discuss potential limitations of SMART-CD, such as its dependence on problem-specific parameters (e.g., smoothness and sampling distributions) or scenarios where it might underperform compared to other methods.
3. Experimental Scope: While the experiments are compelling, they focus primarily on machine learning applications. Expanding the scope to include other domains, such as operations research or signal processing, could demonstrate broader applicability.
Arguments for Acceptance:
- The paper makes a significant theoretical contribution by extending randomized coordinate descent methods to a more general problem class with rigorous convergence guarantees.
- The empirical results are robust and demonstrate the practical utility of the proposed method in real-world applications.
- The combination of techniques (smoothing, acceleration, homotopy, and non-uniform sampling) is novel and well-justified.
Arguments Against Acceptance:
- The dense presentation may limit the accessibility of the paper to a broader audience.
- The discussion of limitations and potential drawbacks is insufficient, leaving some questions about the generalizability of the method.
Recommendation:
Overall, this paper represents a strong contribution to the field of convex optimization and machine learning. While the presentation could be improved, the theoretical and empirical results are compelling. I recommend acceptance, with minor revisions to improve clarity and expand the discussion of limitations.