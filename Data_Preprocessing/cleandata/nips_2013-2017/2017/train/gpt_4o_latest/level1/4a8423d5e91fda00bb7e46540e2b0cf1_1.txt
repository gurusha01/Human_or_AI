Review of "Selective Classification for Deep Neural Networks with Guaranteed Risk Control"
This paper addresses the problem of selective classification (or the reject option) in the context of deep neural networks (DNNs), proposing a method to construct a selective classifier that guarantees a desired error rate with high probability while maximizing coverage. The authors present a novel algorithm, Selection with Guaranteed Risk (SGR), which learns a rejection function \( g \) for a pre-trained classifier \( f \). The method is demonstrated on CIFAR-10, CIFAR-100, and ImageNet datasets using VGG-16 and RESNET-50 architectures. The empirical results show that the proposed approach achieves unprecedented levels of guaranteed risk control, such as 2% top-5 error on ImageNet with 60% coverage and 99.9% confidence. The paper also explores two confidence-rate functions—softmax response (SR) and Monte Carlo dropout (MC-dropout)—and demonstrates their effectiveness in selective classification.
Strengths
1. Novelty and Originality: The paper introduces selective classification techniques to DNNs, a largely unexplored area. While selective classification has been studied for other models (e.g., SVMs and boosting), its application to DNNs is novel and timely, given the increasing deployment of DNNs in mission-critical applications.
2. Technical Soundness: The proposed SGR algorithm is well-grounded in theory, with rigorous guarantees on risk control. The use of numerical bounds (e.g., Gascuel and Caraux's bound) ensures tight generalization guarantees.
3. Empirical Validation: The extensive experiments on multiple datasets and architectures convincingly demonstrate the effectiveness of the method. The results show that the proposed approach can significantly reduce error rates with minimal coverage trade-offs.
4. Practical Relevance: The work has clear applications in safety-critical domains, such as autonomous driving and medical diagnosis, where controlled risk is essential.
5. Clarity: The paper is well-organized and clearly written, with sufficient details provided to reproduce the results. The risk-coverage trade-offs and the role of confidence-rate functions are well-explained.
Weaknesses
1. Limited Exploration of Joint Training: While the authors acknowledge that jointly training \( f \) and \( g \) could yield better results, this aspect is not explored. The current approach assumes a pre-trained classifier, which may limit the method's optimality.
2. Dependence on Confidence-Rate Functions: The performance of the method heavily relies on the choice of confidence-rate functions (e.g., SR and MC-dropout). While SR performs well empirically, the paper does not provide a theoretical justification for its superiority over MC-dropout.
3. Scalability: The computational cost of the SGR algorithm, particularly for large-scale datasets like ImageNet, is not thoroughly discussed. The binary search and repeated evaluations of the rejection function could be computationally expensive.
4. Limited Scope of Loss Functions: The method is restricted to 0/1 loss, and its applicability to other loss functions or regression tasks is not explored, despite the authors mentioning this as future work.
Arguments for Acceptance
- The paper addresses an important and underexplored problem in DNNs, with significant implications for real-world applications.
- The theoretical guarantees and empirical results are strong and demonstrate the method's effectiveness.
- The work is a valuable contribution to the field, providing a foundation for future research on selective classification in DNNs.
Arguments Against Acceptance
- The lack of exploration of joint training for \( f \) and \( g \) limits the method's potential.
- The reliance on specific confidence-rate functions without deeper theoretical justification may raise concerns about generalizability.
Recommendation
I recommend acceptance of this paper. While there are areas for improvement, the paper makes a significant contribution to the field of selective classification for DNNs, providing both theoretical insights and practical results. It is likely to stimulate further research in this direction.