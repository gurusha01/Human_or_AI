The paper introduces Population Matching Discrepancy (PMD), a novel method for estimating the distance between two distributions based on samples, and demonstrates its advantages over Maximum Mean Discrepancy (MMD). PMD is defined as the minimum weight matching of sample populations from two distributions, and the authors prove that it is a strongly consistent estimator of the first Wasserstein metric. The paper further proposes an algorithm to use PMD as a training objective for learning distribution parameters. The authors apply PMD to domain adaptation and generative modeling tasks, showing that it outperforms MMD in terms of both performance and convergence speed.
This work builds on prior research on statistical divergence estimation (e.g., MMD) and Wasserstein metrics, which have been widely used in deep learning tasks such as generative modeling and domain adaptation. PMD addresses key limitations of MMD, including its sensitivity to kernel bandwidth, weak gradients, and the need for large mini-batch sizes. The paper also draws connections to Wasserstein GANs (WGANs) but highlights PMD's advantages, such as being parameter-free and not requiring a separate critic network.
Strengths:
1. Technical Soundness: The paper provides a rigorous theoretical foundation for PMD, including proofs of its consistency with the Wasserstein metric and empirical validation of its advantages over MMD.
2. Practical Relevance: PMD is demonstrated to be effective in real-world tasks like domain adaptation and generative modeling, achieving better performance and faster convergence than MMD.
3. Clarity: The paper is well-organized, with clear explanations of PMD, its theoretical properties, and its implementation. The pseudocode and empirical analysis are particularly helpful.
4. Originality: PMD is a novel contribution that combines ideas from optimal transport and sample-based divergence estimation, offering a new perspective on distribution distance estimation.
5. Significance: The results suggest that PMD could become a valuable tool for tasks requiring distribution comparison, with potential for broader adoption in deep learning.
Weaknesses:
1. Computational Complexity: While PMD improves on MMD in several aspects, its reliance on solving a minimum weight matching problem introduces higher computational costs (O(N³) for exact matching or O(N²) for approximate matching). This may limit its scalability to very large datasets.
2. Blurry Generative Outputs: In generative modeling tasks, the generated images using PMD are sometimes blurry, particularly on datasets like SVHN and LFW. This suggests that the L1 distance used in PMD may not be optimal for natural image generation.
3. Limited Scope of Applications: While the paper evaluates PMD on domain adaptation and generative modeling, additional experiments on other tasks (e.g., model criticism or metric learning) could strengthen its generalizability.
4. Comparison with WGANs: Although PMD is compared to MMD extensively, its comparison with WGANs is less detailed. A more thorough empirical evaluation against WGANs would provide a clearer picture of PMD's relative strengths and weaknesses.
Recommendation:
I recommend acceptance of this paper, as it makes a significant contribution to the field by addressing key limitations of MMD and providing a theoretically sound and practically effective alternative. However, the authors are encouraged to explore ways to reduce the computational cost of PMD and improve its performance in generative modeling tasks. Additionally, extending the empirical evaluation to include comparisons with WGANs and other divergence estimation methods would further enhance the paper's impact.
Arguments for Acceptance:
- Strong theoretical foundation and novel contribution.
- Demonstrated empirical advantages over MMD in two important tasks.
- Clear writing and well-structured presentation.
Arguments Against Acceptance:
- Higher computational cost compared to MMD.
- Limited evaluation on tasks beyond domain adaptation and generative modeling.
- Blurry generative outputs on some datasets.
Overall, the strengths of the paper outweigh its weaknesses, making it a valuable contribution to the field.