The paper presents a novel model, Deep Dynamic Poisson Factorization Analysis (DDPFA), for analyzing sequential count data. The primary contributions are the integration of recurrent neural networks (RNNs) to capture short-term dependencies and a deep hierarchical structure to model long-term dependencies in sequential data. The authors employ variational inference for parameter estimation and demonstrate the model's effectiveness through experiments on synthetic and real-world datasets, comparing it against existing methods like PGDS, LSTM, and PFA.
Strengths:
1. Novelty and Originality: The combination of Poisson Factor Analysis with deep and dynamic structures is innovative. The use of RNNs to model short-term dependencies and hierarchical latent layers for long-term dependencies addresses limitations in existing models like PGDS.
2. Technical Soundness: The model is well-grounded in Bayesian principles, and the use of variational inference for parameter estimation is appropriate. The derivation of the loss function and the integration of neural networks are clearly explained.
3. Empirical Validation: The experiments on both synthetic and real-world datasets are comprehensive. The results demonstrate that DDPFA outperforms baseline models in most cases, particularly in capturing complex temporal dependencies.
4. Interpretability: The paper highlights the interpretability of the learned factors, such as identifying long-term trends in the ICEWS dataset, which is a valuable feature for real-world applications.
5. Clarity: The paper is well-organized, with detailed explanations of the model, inference process, and experimental setup. Figures and tables effectively support the claims.
Weaknesses:
1. Limited Discussion of Limitations: While the authors acknowledge issues like "pruning" and the limited utility of additional layers, these discussions are brief. A deeper exploration of these challenges and potential solutions would strengthen the paper.
2. Scalability Concerns: The computational complexity of the model, particularly with increasing layers and dimensions, is not thoroughly addressed. This could be a concern for large-scale datasets.
3. Performance on ICEWS: The model underperforms in the ICEWS prediction task compared to PGDS. The authors attribute this to the smoothing effect of PGDS but do not explore how DDPFA could be adapted to handle such cases.
4. Reproducibility: While the paper provides sufficient theoretical details, practical implementation details (e.g., hyperparameter tuning, initialization strategies) are sparse, which may hinder reproducibility.
Suggestions for Improvement:
1. Provide a more detailed analysis of the "pruning" issue and explore alternative inference methods to mitigate it.
2. Discuss the computational efficiency of DDPFA and propose strategies to scale the model for larger datasets.
3. Investigate why DDPFA struggles with certain datasets like ICEWS and consider incorporating elements of PGDS (e.g., transition matrices) to improve performance.
4. Include an appendix with implementation details or release code to facilitate reproducibility.
Recommendation:
Overall, the paper makes a significant contribution to the field of sequential count data analysis by introducing a novel and effective model. While there are some areas for improvement, the strengths outweigh the weaknesses. I recommend acceptance with minor revisions to address the identified concerns.