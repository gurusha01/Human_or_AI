The paper presents a novel extension of Matching Pursuit (MP) algorithms to optimization over the conic hull of a generic atom set, addressing a significant gap in the literature. The authors propose Non-Negative Matching Pursuit (NNMP) and its corrective variants, such as Away-steps MP (AMP), Pairwise MP (PWMP), and Fully Corrective MP (FCMP), and provide theoretical guarantees for their convergence. The key contributions include sublinear and linear convergence rates for general smooth convex objectives, applicability to infinite atom sets, and a unifying framework that connects the proposed algorithms to existing MP and Frank-Wolfe (FW) methods. The empirical results demonstrate the effectiveness of these algorithms across diverse applications, including synthetic data, non-negative matrix factorization, and non-negative garrote logistic regression.
Strengths:
1. Novelty and Theoretical Contributions: The paper addresses an important intermediate case between linear span and convex hull optimization, which has been largely unexplored. The proposed algorithms are the first to provide explicit convergence guarantees for optimization over conic hulls, filling a critical theoretical gap.
2. Generality: The algorithms are applicable to a wide range of smooth convex objectives and do not require restrictive assumptions on the atom set, making them broadly useful in various learning settings.
3. Comprehensive Analysis: The authors provide rigorous theoretical guarantees, including sublinear and linear convergence rates, and relate their work to existing MP and FW literature. The introduction of geometric constants like Cone Width is a significant contribution.
4. Empirical Validation: The experiments demonstrate the practical utility of the proposed methods, showing competitive or superior performance compared to state-of-the-art baselines across multiple tasks and datasets.
5. Clarity in Algorithm Design: The corrective variants (AMP, PWMP, FCMP) are well-motivated and address limitations such as zig-zagging, leading to improved convergence rates.
Weaknesses:
1. Computational Complexity: While the algorithms are theoretically sound, the additional computational burden of corrective steps (e.g., dual LMO queries in AMP/PWMP or solving cone problems in FCMP) may limit scalability to very large-scale problems. A more detailed discussion of trade-offs between computational cost and convergence speed would be helpful.
2. Empirical Scope: Although the experiments are illustrative, they are limited in scope. For example, the paper could include more real-world applications or comparisons with additional baselines, particularly in domains like hyperspectral unmixing or tensor factorization.
3. Practical Implementation Details: The paper lacks sufficient discussion on practical implementation challenges, such as the choice of approximate LMO or computational efficiency of the atomic norm. These details are crucial for practitioners.
Pro Acceptance Arguments:
- The paper makes a significant theoretical contribution by extending MP algorithms to conic hull optimization with convergence guarantees.
- The proposed methods are general and applicable to a wide range of problems, with empirical results supporting their effectiveness.
- The work bridges gaps between MP and FW literature, offering a unified perspective.
Con Acceptance Arguments:
- The computational overhead of corrective variants may hinder practical adoption.
- The empirical evaluation, while promising, could be more extensive to demonstrate broader applicability.
Recommendation: Accept with minor revisions. The paper is a strong theoretical contribution to the field of greedy optimization algorithms, with practical potential. However, addressing the computational complexity and expanding the empirical evaluation would further strengthen its impact.