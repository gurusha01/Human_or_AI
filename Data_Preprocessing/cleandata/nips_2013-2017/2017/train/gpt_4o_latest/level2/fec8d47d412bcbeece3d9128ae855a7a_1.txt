The paper introduces NeuralFDR, a novel algorithm for multiple hypotheses testing that leverages neural networks to dynamically learn discovery thresholds based on hypothesis-specific features. Unlike traditional methods such as Benjamini-Hochberg (BH) or Independent Hypothesis Weighting (IHW), which either ignore features or impose restrictive assumptions about their structure, NeuralFDR flexibly handles multi-dimensional, continuous, and discrete features. The authors provide theoretical guarantees for false discovery rate (FDR) control, demonstrate the algorithm's efficacy on synthetic and real-world datasets, and highlight its interpretability.
Strengths:
1. Novelty and Significance: NeuralFDR addresses a critical gap in multiple hypotheses testing by incorporating rich, multi-dimensional features into the decision-making process. This represents a significant advancement over existing methods like IHW, which struggle with high-dimensional feature spaces.
2. Theoretical Guarantees: The paper rigorously proves that NeuralFDR controls the false discovery proportion (FDP) with high probability and asymptotically under weak dependence. This is a strong contribution to the field, ensuring the reliability of the proposed method.
3. Empirical Validation: The authors provide extensive experiments on both synthetic and real datasets, demonstrating that NeuralFDR consistently makes more discoveries while maintaining FDR control. The results are compelling, particularly in high-dimensional feature settings where traditional methods falter.
4. Interpretability: The learned discovery thresholds are interpretable and align with domain-specific knowledge, as illustrated in the GTEx and RNA-Seq datasets. This is a valuable feature for practitioners in fields like genomics.
5. Scalability: The use of neural networks allows the algorithm to handle large-scale datasets and complex feature spaces efficiently, which is crucial for modern applications.
Weaknesses:
1. Dependence on Large Datasets: NeuralFDR performs best when the number of hypotheses and the alternative proportion are large. Its performance on small datasets or datasets with sparse alternatives is less robust, as acknowledged by the authors.
2. Architectural Sensitivity: The algorithm relies on a relatively deep neural network (10 layers) for optimal performance. A more detailed exploration of how network architecture impacts results would strengthen the paper.
3. Limited Discussion of Computational Complexity: While the method is scalable, the paper does not provide a detailed analysis of its computational overhead compared to simpler methods like BH or IHW, which could be a concern for practitioners with limited resources.
4. Assumptions on Independence: The theoretical guarantees rely on assumptions of independence or weak dependence, which may not hold in some real-world scenarios. While the authors address weak dependence, a more detailed discussion of limitations in strongly dependent settings would be beneficial.
Recommendation:
I recommend acceptance of this paper. NeuralFDR is a significant contribution to the field of multiple hypotheses testing, offering both theoretical rigor and practical utility. While there are areas for improvement, such as performance on small datasets and a deeper analysis of computational costs, the strengths of the paper far outweigh its weaknesses. The method's ability to handle complex, multi-dimensional features and its demonstrated superiority over existing approaches make it a valuable addition to the NIPS community.
Pro and Con Arguments:
Pros:
- Novel and impactful approach to multiple hypotheses testing.
- Strong theoretical guarantees for FDR control.
- Demonstrated empirical superiority over state-of-the-art methods.
- Interpretability of learned thresholds enhances practical utility.
Cons:
- Performance is less robust on small datasets or sparse alternatives.
- Sensitivity to neural network architecture requires further exploration.
- Limited discussion of computational complexity and strong dependence scenarios.
Overall, the paper is well-written, technically sound, and highly relevant to the NIPS audience.