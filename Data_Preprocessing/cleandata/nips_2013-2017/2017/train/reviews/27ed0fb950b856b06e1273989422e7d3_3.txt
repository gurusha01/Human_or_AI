The paper deals with incorporating long range temporal dependence in a Poisson factorization model with deep structure. As opposed to the previous works on dynamic PF, this paper employs a recurrent neural network like structure for modeling the long-term dependency. Finally, the inference is carried out using variational inference with some optimization routines for finding the parameters of the neural network. The paper has good technical contents but is also plagued with some grammatical and factual errors. These are listed below:
1. The statement made about modeling nonnegative numbers on lines 86-87 is incorrect. It's the Poisson Randomized Gamma distribution that is used for modeling the nonnegative numbers.
2. Please make the best results bold in Table 2. 
3. Held-out perplexity should have been a stronger indicator in the experiments in Section 4.2, though MSE/PMSE are okay.
4. The limitations in the existing works for modeling the long-range dependency (reference 1,2) are adequately addressed in this paper. However, to illustrate the utility of the proposed method with multiple levels of hierarchy, a comparison with dynamic PF with one level deep architecture could have been useful. The comparison with LSTM is useful, but the learning algorithms are different. Therefore, this comparison does not truly justify the need for multiple levels of hierarchy in the proposed method. 
5. There are several grammatical errors and typos as listed below that make the paper little difficult to read:
-- "unit the data" 
-- "Noticing the lack of capturing .."
-- "PFA factorized a count matrix" (the tense of this sentence is incongruent with the tense in other sentences in the same paragraph)
-- "other data with different pattern long-time dependence .."
-- "Examples for this including .."
-- "shows excellent results on predict and .."
-- "However, it is rough for them .."
-- "V-dimesnion sequentially .."
-- "K-dimension latent variable .."
-- "due to the including of feature-wise"
-- "recommend systems" etc.