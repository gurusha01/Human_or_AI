The paper looks at continuous improvement using a sequence of A/B tests, and proposes instead to implement adaptive testing such as 
 multi-armed bandit problem while controlling the false discovery rate. This is an important problem discussed in statistical literature, but still unsolved.
 The approach proposed in this paper seems to apparently solve the issues. This is a very interesting paper, that despite minor concerns listed below, could lead to a potentially new avenue of research.
 
 Lines 24-37: There are well-known issues, and it would be desirable to add citations. Although authors clearly focus on CS/ML literature, there is also a relevant body of literature in biometrics, see e.g. survey by Villar, Bowden and Wason (Statistical Science 2015), the references therein and the more recent papers citing this survey.
 Line 37: "testing multiple literature" -> "multiple testing literature" 
 Line 38-47: A similar concept exists in biometrics, called "platform trials" - please describe how your concept differs
 Line 112: "and and" -> "and"
 Line 115: please provide reference for and description of LUCB
 Line 153: "samplesas" -> "samples as"
 Line 260: "are ran" -> ?
 Line 273: It is not clear what "truncation time" is and why it is introduced - it seems to have a huge effect on the results in Figure 2
 Line 288-291: While this motivation is interesting, it seems to be mentioned at an inappropriate place in the paper - why not to do it in the introduction, alongside website management and clinical trials?