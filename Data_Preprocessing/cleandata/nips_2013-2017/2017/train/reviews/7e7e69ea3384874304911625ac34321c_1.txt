Update after rebuttal: I believe the paper can be accepted as a poster. I advise the authors to polish the writing to better highlight their contributions, motivation and design choices. This could make the work attractive and rememberable, not "yet another hybrid generative model". 
-----
The paper proposes PixelGAN autocencoder - a generative model which is a hybrid of an adversarial autoencoder and a PixelCNN autoencoder. The authors provide a theoretical justification of the approach based on a decomposition of variational evidence lower bound (ELBO). The authors provide qualitative results with different priors on the hidden distribution, and quantitative results on semi-supervised learning on MNIST, SVHN and NORB.
The paper is closely related to Adversarial autoencoders (Makhzani et al. ICLR 2016 Workshop), which, as far as I know, have only been published on arxiv and as a Workshop contribution to ICLR. Yet, the work is well known and widely cited. The novelty of the present submission significantly depends on Adversarial autoencoders being considered existing approach or not. This is a complicated situation, which, I assume, ACs and PCs are better qualified to judge about.
Now to some more detailed comments.
Pros:
1) Good results on semi-supervised learning on MNIST, SVHN and NORB, and unsupervised clustering on MNIST. It is difficult to say if the results are state-of-the-art since many numbers for the baselines are missing, but at least they are close to the state of the art.
2) A clear discussion of an ELBO decomposition and related architectural choices.
Cons:
1) If Adversarial autoencoders are considered existing work, then novelty is somewhat limited - it's yet another paper which combines two existing generative models. What makes exactly this combination especially interesting?
2) Lack of results on actual image generation. I understand that image generation is difficult to evaluate, but still some likelihood bounds (are these even computable?), Inception scores and images would be nice to see, at least in the Appendix.
3) It is somewhat confusing that two versions of the approach - with location-dependent and location-independent biases - are used in experiments interchangeably, but are not directly compared to each other. I appreciate the authors mentioning this in lines 153-157, but a more in-depth analysis would be useful.
4) A more detailed discussion of relation to existing approaches, such as VLAE and PixelVAE (both published at ICLR 2017), would be helpful. Lines 158-163 are helpful, but do not quite clear highlight the differences, and strengths and weaknesses of different approaches.
5) Some formulations are not quite clear, such as "limited stochasticity" vs "powerful decoder" in lines 88 and 96. Also the statement in line 111 about "approximately optimizing the KL divergence" and the corresponding footnote looks a bit too abstract - so do the authors optimize it or not?
6) In the bibliography the authors tend to ignore the ICLR conference and list many officially published papers as arxiv.
7) Putting a whole section on cross-domain relations to the appendix is not good practice at all. I realize it's difficult to fit all content to 8 pages, but it's the job of the authors to organize the paper in such a way that all important contributions fit into the main paper.
Overall, I am in the borderline mode. The results are quite good, but the novelty seems limited.