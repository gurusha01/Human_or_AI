The paper presents an implicit variational inference method for likelihood-free inference. This approach builds on previous work and particularly on Hierarchical Variational Inference and Implicit Variational Bayes. 
The key trick used in the paper is the subtraction of the log empirical distribution log q(xn) and the transformation of the ELBO in the form given by eq. 4, which suggests the use of log density ratio estimation as a tool for likelihood-free variational inference. The rest methodological details of the papers are based on standard tools, such as log density 
ratio estimation, reparametrization and hierarchical variational distributions. 
While I found the trick to deal with likelihood intractability very interesting, it requires log density ratio estimation in high-dimensional spaces (in the joint space of data xn and latent variable zn). This is very challenging since log density ratio estimation in high dimensions is an extremely difficult problem and there is no clear evidence that the authors provide a stable algorithm to deal that. For instance, the fact that the authors have not applied their method to a standard GAN (for generating high dimensional data such as images) but instead they have constructed this rather weird Bayesian GAN for classification (see page 7) indicates that the current algorithm is very unstable. In fact it is hard to see how to stabilize the proposed 
algorithm since initially the "variational joint" will be very different from the "real joint" and it is precisely this situation that makes log density ratio estimation completely unreliable, leading to very biased gradients in the early crucial iterations of the optimization.