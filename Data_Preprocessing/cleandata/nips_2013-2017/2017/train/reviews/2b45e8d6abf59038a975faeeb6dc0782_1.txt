The paper defines Population Matching Discrepancy between two distributions
as the Wasserstein distance between two minibatches from the distributions.
The Wasserstein distance is computed by an exact O(N^3) or an approximate O(N^2) algorithm.
Pros:
- It is interesting to see the experiments with this computation of the Wasserstein distance.
The generated images are not as good as from Wasserstein GAN.
Cons:
- The proposed distance would need large N to estimate the Wasserstein distance between two diverse multimodal distributions.
I suspect that problems would be already visible, if trying to match a mixture of Gaussians (including learning the variances).
- If N is not large enough, the optimization may have the global minimum at a point different from the true distribution.
For example, the learned distribution may have less entropy.
The SVHN samples in Figure 4 seem to have low diversity. Digit 8 appears frequently there.
Minor typos:
- Line 141: s/usally/usually/
Update:
I have read the rebuttal. Thanks for the extra experiments.
The authors should clarity the limitation of PMD and MMD.
MMD is OK with batch_size=2.
MMD can be trained with SGD, 
if using the unbiased estimator of MMD from the original "A Kernel Two-Sample Test" paper.
So MMD can converge to the right distribution if using small minibatches.
On the other hand, PMD does not have a known unbiased estimator of the gradient.