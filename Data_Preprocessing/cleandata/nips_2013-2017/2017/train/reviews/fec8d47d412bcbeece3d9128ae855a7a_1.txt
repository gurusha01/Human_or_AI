The paper describes a new method for FDR control for p-values with additional information. 
For each hypothesis, there is a p-value pi, and there is also a feature vector Xi. 
The method learns the optimal threshold for each hypothesis, as a function of the features vector X_i. The idea seems interesting and novel, and overall the paper is explained quite clearly. In several simulated and real data example, the authors show that their method can use the additional information to increase the number of rejections, for a given FDR control threshold. 
It seems to me to be important that the Xi's were not used to calculate the Pi, 
otherwise we get a problem of circularity. The authors mention this in an example, but there 
is no formal treatment of this - it is not clear what should be the probabilistic relationship between the Xi's and the pi's. On the one hand, both the pi's and the Xi's are likely to be dependent on the correctness of the null vs. alternative hypothesis, but on the other hand, if the Xi's were already used to calculate the pi's, then they should not improve the decision boundary. 
The fact that X is multidimensional should not immediately rule out non-parametric methods as the authors claim - for example nearest-neighbours regression can still adapt to the 'true' intrinsic dimension of the regression function, even if the dimension of X is large. 
It is not clear to me how immune to overfitting is the cross-validation procedure proposed by the authors. The settings is not a standard supervised learning approach, since the 'label' FDR is unknown and is replaced by an estimator. It would be good to emphasize and elaborate this point more clearly. Then, since the estimator of FDR is noisy, this may yield to my understanding higher FDR for the test set. 
The authors do show in Theorem 1 a bound which grows with the number of folds in the cross-validation procedure. 
The mirror estimator proposed by the authors may have little bias but large variance if t(x) is small, since very few p-values will be between 1-t(x) and 1. This issue comes up in Story's approach where lambda parameter is chosen such that the null proportion, estimated using the interval [lambda, 1] should balance variance and bias. 
 
Minor:
======
Line 136: 'this' -> 'these'