The paper build and auto-encoder with pixelCNN decoder and adversarial cost on latent between uniform prior and inference distribution. With the right network design the networks separate global input information stored in the latent and local one captured by pixelCNN when trained on MNIST dataset. With categorical distribution of latents the network learns to capture very close to class information in unsupervised way. The networks perform well in semisupervised settings. The paper is yet another combination of VAE/AdvNet/PixelCNN. The paper has a nice set of experiments and discussion. The model is most closely related to VAE-pixelCNN combination with VAE loss (KL) on latents replaced by adversarial loss (even though they discuss the mathematical difference) and it would be good to run the same experiments (scaling latent loss) with that and compare.
More details: 
- In the Figure 2c I would rather see VAE-pixelCNN combination with the same networks and different scaling of KL term. While there is a mathematical description of the difference, in the end both are some terms penalizing latents, both wanting latents to be unit gaussians. 
- Line 98: That's not necessarily the case, depending on function approximations. The network can decide to put information into latents or keep them in the input. But yes, it is harder for it be in the latents since latents are noisy and the posterior is approximate.
- Do you get any clear unsupervised separation as in Figure 6 for SVHN and NORB?