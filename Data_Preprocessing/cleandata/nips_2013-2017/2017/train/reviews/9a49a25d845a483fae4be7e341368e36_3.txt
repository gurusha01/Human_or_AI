The authors propose a dataset model that is the solution of a convex problem, incorporating constraints that limit discrimination w.r.t. a selected sensitive property. The constraints are such that enforce statistical parity both in the joint distribution, as is usual in the literature, but also suggesting quadratically many (in the value outcomes) extra constraints that limit the discriminatory effect per value of the protected attribute. Additional constraints limit individual (point-wise) discrimination, while retaining as close as possible a distribution to the original data. The model can be used to principally limit discrimination from training data, as well as to appropriately transform unseen, test data.
The claims are theoretically grounded and what is more in a way that different distance/similarity measures may be incorporated into the constraints. For a selection of these settings, experiments are provided on representative datasets, which demonstrate that their method successfully avoids discrimination, also compared against alternatives in the literature.
In the extensive Supplementary Material, proofs are provided that support their theoretical claims, accompanied by insightful discussion about the datasets used (alongside the recently released COMPASS dataset), further compared to the resulting datasets of their algorithm.
One further positive aspect is a novel mention of a bound on the utility of their method, in case that the dataset probabilities are not exact but instead estimated using the maximum likelihood estimate, as is usually the case. Unsurprisingly, the tigthness of the bound is subject to sufficiently well-behaving distributions.
The authors carefully position their proposal with regard to existing methods in the ecosystem of discrimination-aware ML/DM, and give a good overview of the relevant literature.
Overall I am positive of this work, yet there are points that could be improved upon, though, including the following.
i) For the distribution similarity (Eq. 3) they choose a not well-motivated measure, that of the probability ratio, which may unevenly penalise differences when the target distribution is very low.
ii) The experimentally used distance (distortion) measures are not thoroughly explained (use of 10^4 penalisation in the case of COMPASS data in the case of more than 1 category jumps), although the high value seems reasonable.
iii) Experimental results in the Adult dataset are failing behind than the LFR method of Zemer.
iv) The experimental section could benefit from more case studies that show a more general trend (e.g. German credit, Heritage Health Prize, etc)
v) Value is put in the generality of their framework, which must be solved using a general convex solver. Owing further to the variety of configurations, it becomes difficult to provide reasonably generalisable timings of their proposed optimisation problem. However, it still seems that the submission would be more complete by reporting timing measurements for the provided experiments.
Although the reviewer has not thoroughly verified the correctness of the proofs in the supplementary material, the claims made are reasonable, some are novel and all are well motivated, in a way that unifies advances in the area. The reviewer is confident that this submission extends significantly the area of discrimination-aware machine learning, and is confident that the publication of this work would definitely benefit the community.