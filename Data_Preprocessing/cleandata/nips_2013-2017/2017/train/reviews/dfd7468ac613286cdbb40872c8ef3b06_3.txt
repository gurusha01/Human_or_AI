GANs have received a lot of attention lately. They generate sharp samples but this performance comes with the cost of optimization difficulties. An alternative to GANs that relies on two-sample hypothesis testing is the so called Generative Moment Matching Networks (GMMN). Although GMMNs are more stable, they generate worse samples than GANs. They also require a large batch size during training. This paper proposes to improve the efficiency of the GMMN and its architecture for better performance. The approach consists in using feature matching in the kernel definition and learning the parameters of this feature map jointly with the parameters of the generator in a minimax problem. I liked the paper and have highlighted some remarks below:
1. The reason why adversarial learning of the kernel leads to higher test power was not thoroughly discussed. This is important.
2. The experiment section -- including the complexity analysis -- is very well carried through.
3. The paper can benefit from a thorough editing. There were many typos that tend to distract from the message being portrayed in the paper.
REBUTTAL:
I acknowledge the rebuttal