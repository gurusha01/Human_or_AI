The paper proposes a method for optimization problems often found in machine learning tasks. The general loss function to minimize is of the form of a sum of smooth-convex functions associated with a convex regularization potential. The method is designed for the case of perturbation introduced in the data. Since the data sampling introduces a stochastic component Stochastic Gradient Descent (SGD) need of modifications for reducing the gradient variance [14,28]. In the case of perturbed data, such variance is magnified. The authors claim that the reported modifications to SGD for variance reductions limit their applicability for inline training because they requires of storing the full gradients or the dual variables. The reported SGD variant (S-MIMO) overcomes the mentioned limitations and preserves the accelerated characteristics of the SCG variants for batch processing. 
My main comment of the paper is that, in recent years, is has been reported many variants of SGD and it is hard to evaluate if the presented comparison is fair. Let me explain a possible experiment that is not included (among others). 
The method SVRG [14] requires of computing the full gradient after some m Stochastic Iterations, that assumes to have available all the data. That is the principal argument of the authors to say that it SVSG not be used for an inline training. However, is we conside the case of finite data., then each perturbed data can be seen as a new data. It could be interesting try with SVRS to train a problem using a epochs based strategy (each epoch uses different perturbations), and to compare its performance with S-MIMO. The same argument could be justify to use SVRG is a batch processing where the (full) gradient is updated after each batch. 
Now, suppose that the sketched idea for using SVRG in the optimization problems of the form (2) works; it justify a new paper proposing the "new method"? Do not in my opinion, do not in NIPS. Well this is the kind "variants" that saturate the literature.
As resume, the authors should make an effort to compare their algorithm with more variants as possible, even if trivial modifications are required (as the sketched). 
Remark. I did not check the algebra of all the proof in the supplementary material, I could follow the text and seems correct.