This paper proposes to perform estimation of a point process using the Wasserstein-GAN approach.
More precisely, given data that has been generated by a point process on the real line, the goal is to build a model of this point process. Instead of using maximum likelihood, the authors proposed to use WGAN.
This requires to:
- define a distance between 2 realizations of a point process
- define a family of Lipschitz functions with respect to this distance
- define a generative model which transforms "noise" into a point process
The contribution of the paper is to propose a particular way of addressing these three points and thus demonstrate how to use WGAN in this setting.
The resulting approach is compared on a variety of point processes (both synthetic and real) with maximum likelihood approaches and shown to compare favorably (especially when the underlying intensity model is unknown).
I must admit that I am not very familiar with estimation of point processes and the corresponding applications and thus cannot judge the potential impact and relevance of the proposed method. However, I feel that the adaptation of WGAN (which is becoming increasingly popular in a variety of domains) to 
the estimation of point processes is not so obvious and the originality of the contribution comes from proposing a reasonable approach to do this adaptation, along with some insights regarding the implementation of the Lipschitz constraint which I find interesting.
One aspect that could be further clarified is regarding the modeling of the generator function: from the definition in equation (7) there is no guarantee
that the generated sequence t_i will be increasing. It is the case that the weights are constrained to be positive for example? or is it the case that the algorithm works even when the generated sequence is not increasing since the discriminator function would discriminate against such sequences and
thus encourage the generator to produce increasing ones?