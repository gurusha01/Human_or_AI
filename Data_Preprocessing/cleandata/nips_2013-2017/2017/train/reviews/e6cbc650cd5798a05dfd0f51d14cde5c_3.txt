The paper presents an idea of casting the sparse Bayesian learning as a recurrent neural network structure, which enables the learning of the functions without having to hand-craft the iterations.
The paper is well written and clearly presented. The presented idea is interesting and aligns with some recent works presented in the literature on establishing links between sparse representation and deep neural networks, such as sparse encoder, LISTA, etc.
The experiments on DOA estimation and 3D geometry reconstruction are interesting and show the diversity of the potential applications of this technique.