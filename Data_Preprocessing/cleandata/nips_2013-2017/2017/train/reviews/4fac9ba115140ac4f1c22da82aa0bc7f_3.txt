The authors present a novel algorithm to learn ensembles of deep decision (or regression) trees that optimize both prediction accuracy and feature cost. The resulting prediction system is adaptive in the sense that for different inputs different features sets of features will be acquired/evaluated thus resulting in a reduced cost while mainitaing prediction accuracy. 
The authors approach is an iterative algorithm that extends gradient tree boosting with a cost-sentive objective function. The algorithm iteretavely adds decision trees to the ensemble. Each new candidate tree is trained to approximately optimize the cost of the entire ensemble. To accomplish individual tree learning given the cost-constrains w.r.t the existing ensemble, the authors introduce a cost-aware impurity function.
The authors demonstrate that their algorithm outperforms existing methods in cost-aware ensemble learning on several real datasets.
Overall, I think the paper is well written, the algorithm derivations are interesting and novel, and the problem being addressed is highly relevant to many domains.