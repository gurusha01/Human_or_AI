This paper proposed a model powered approach to conduct conditional independent tests for iid data. The basic idea is to use nearest neighbor bootstrap to generate samples which follow a distribution close to the f^{CI} and a classifier is trained and tested to see if it is able to distinguish the observation distribution and the nearest neighbor bootstrapped distribution. If the classification performance is close to the random guess, one fails to reject the null hypothesis that data follows conditional independence otherwise one accept the null hypothesis.
Authors developped some bounds on the closeness of the nn bootstrapped distribution and f^{CI} in term of total variantional distance and bounds on empirical risks under ideal classification settings and for near-Independent samples.
In general, the paper is trying to address an important problem and the paper is presented in a clear way.
Detail comments:
Major:
1. It seems that the whole method can be decoupled into two major components. One is to generate samples that mimic the f_{CI} and the other one is to use a classifier for determination. My question is whether we can replace any one step by existing solutionsfrom literature. For example, we used the permutation based method proposed in [7] and then the classification based approach to solve the problem. Or we use the nn bootstrap and the kernel two sample test approach together to solve the problem. I am couriois about the performances.
2. The nearest neighbor bootstrap distribution is close to f_{CI} in the finite sample size setting. In this case, if the groundtruth is x and y are weakly dependent given z, how the proposed method is going to tell?
3. Is the method totally symmetric with respect to x and y? In the causal perspective, x and y can be dependent given z due to two different causal models: x causes y or y causes x. In this two different scenarios, shall we need to determine which variable to sample. Authors did not consider this problem.
4.I am seriously concerned about how to choose the parameter $\tau$ in algorithms 2 and 3.
Minor:
In algorithm 2 and 3, it seems that the empirical risk should be devided by the sample size.