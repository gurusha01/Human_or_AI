This paper aims to solve L1 regularized ERM problem. The developments in this paper seem to be motivated by the desire to combine several successful techniques into a single algorithm: greedy coordinate descent, SVRG and acceleration. Accelerated SVRG is known as Katyusha and hence the main task is to combine Katyusha (which would randomize over a minibatch of examples n) with greedy coordinate descent (which would update a subset of the d feature vectors in a "greedy" fashion). The way this is done in this paper is interesting as the solution is surprisingly simple and effective. 
The authors observe (by citing older literature) that without L1 regularization, and in the batch setting, greedy coordinate descent can be expressed as a gradient descent step if instead of the standard L2 norm in the upper bound one used the L1 norm (one also needs to change the scaling/Lipschitz constant). By adding the L1 regularizer, this property is lost, and a subset of variables might be updated. However, the resulting method could still be interpreted as a variant of greedy coordinate descent. This strategy is then combined with Katyusha and the result is an accelerated (via Katyusha momentum), stochastic (over n) and greedy (over d) method. The authors show that in some settings, the resulting complexity can beat that of Katyusha itself.
It is important the the authors are able to devise a fast method for solving the subproblems involved. The key subproblem, (3), is solved via a novel, nontrivial and efficient method called SOTOPO. The starting point here is a variational reformulation of the squared L1 norm as a convex minimization problem over the unit simplex. The authors then write the problem as a min-min problem in the original and auxiliary variables. Switching the order of taking the min ultimately leads to an efficient method for solving (3). This seems of independent interest, which is good.
I like the paper. It is well written. It presents some interesting novel ideas, leads to an efficient method, works in practice in several regimes (interestingly, for both n > > d and n < < d regimes, although this should be investigated in more detail), and also leads to improved complexity for the L1 regularized ERM problem in certain regimes.
Some comments:
1)	Line 31: There are some earlier contributions to accelerated randomized coordinate descent than [11, 20]. The first is due to tNesterov [2012], but suffered from expensive iterations. This was remedied by Lee and Sidford [arXiv: 1305.1922] and Fercoq & Richtarik [arXiv: 1312.5799]. Further improvements were made with the introduction of nonuniform probabilities into accelerated randomized coordinate descent. This was done by Qu and Richtarik [arXiv: 1412.8060] and then extended to strongly convex setting by Allen-Zhu, Qu, Richtarik and Yuan [arXiv: 1512.09103], and later independently by Nesterov and Stich [2016].
2)	The setup of this paper reminds me of a similar synthesis of two methods: SVRG and randomized coordinate descent. This was done in Konecny, Qu & Richtarik [arXiv:1412.6293]. The difference here is that their method is not accelerated (Katyusha did not exist then), and instead of greedy, they use randomized coordinate descent. I am wondering what the connections are.
3)	Regarding experiments: the APPROX method of Fercoq and Richtarik [arXiv:1312.5799] should be included. This is a batch method in n, but capable to randomize over subsets of the d variables, and capable of utilizing sparsity in the data. This method should do very well in the high d and low n regime.
4)	Explain the effect of \eta on the sparsity level in subproblem (3) – even with lambda = 0. Clearly, if eta is small enough, the bound used upper bounds the standard quadratic approximation. In such a case, SOTOPO is not needed; and Katyusha applies directly. There is a thin line here: it will be useful to comment on L1 vs L2 and so on in light of this.
Some minor comments:
1)	What are (???) in Step 1 of Alg 1?
2)	19 and 20: are referred to -> refer to
3)	19: that uses some algebra trick to -> using an elusive algebra trick to
4)	20: samples -> sample
5)	27: resulted -> resulting {this appears in many places in the paper, such as lines 51, 56, …}
6)	29: reduces -> reduce
7)	38: preferable than -> preferable to
8)	40: GSD has much -> GCD to have much
9)	50: entries -> entry
10)	55: sqoximation -> approximation
11)	88: is -> are
12)	99: While -> Since
13)	121: of the -> of
=== post rebuttal feedback ===
I am keeping my decision.