This paper presents a double sampling strategy to improve the multiclass classification approach in [16]. The authors present both theoretical and empirical analysis of their proposed approach. Experiments conducted on text data set shows the proposed approach can handle multi-class classification problem with a large number of classes. 
Pros:
- The authors conduct comprehensive experimental comparisons with several baseline methods. Results show that the proposed approach achieves high performance with shorter training time on several datasets. 
- The extreme classification problem is an important direction of research and have many applications in practice. 
Cons:
- The paper is mostly based on [16]. Despite there are two main improvements: 1) proposed the double sampling strategy and 2) a new generalization bounds based on local Rademacher Complexities, the novelty is relatively thin. 
- Despite the proposed approach shorten the training time, it still requires long prediction time compared with other approaches. It is arguably the prediction time is more important in practice. 
Comments:
- It is unclear how to interoperate the generalization bound presented in the paper. How the generation bound compared with other approaches?
- Some methods presented in the experiments are batch learning algorithms and some are online learning algorithms. Therefore, the memory usages are very different.