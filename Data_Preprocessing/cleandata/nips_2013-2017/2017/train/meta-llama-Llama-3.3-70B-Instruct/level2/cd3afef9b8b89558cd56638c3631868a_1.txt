This paper revisits the problem of online isotonic regression, which involves fitting monotonic functions to best explain the data in an online setting. The authors develop a more practical random permutation model, where the data instances and labels are chosen adversarially before the game begins, but then presented to the learner in a random order. They show that the regret is bounded above by the excess leave-one-out loss and develop efficient algorithms and matching lower bounds.
The paper's main contributions are: (1) introducing the random permutation model, which is more practical than the fixed design model; (2) developing an online-to-batch conversion that relates the fixed design model to the random permutation model; and (3) analyzing the class of forward algorithms, which are popular and practical, and showing that they achieve a decent regret rate in all cases and match the optimal rate in special cases.
The paper is well-written, and the authors provide a clear and concise introduction to the problem and the related work. The technical sections are also well-organized, and the proofs are detailed and easy to follow. The authors also provide a thorough discussion of the implications of their results and the potential future directions.
The strengths of the paper are:
* The introduction of the random permutation model, which is a more practical and realistic setting for online isotonic regression.
* The development of an online-to-batch conversion, which allows for the transportation of results from the fixed design model to the random permutation model.
* The analysis of the class of forward algorithms, which are popular and practical, and the showing that they achieve a decent regret rate in all cases and match the optimal rate in special cases.
The weaknesses of the paper are:
* The paper assumes that the data instances and labels are chosen adversarially, which may not be realistic in all scenarios.
* The paper does not provide a complete analysis of the forward algorithms, and some of the results are based on conjectures or numerical experiments.
Overall, the paper is well-written, and the authors provide a clear and concise introduction to the problem and the related work. The technical sections are also well-organized, and the proofs are detailed and easy to follow. The paper makes a significant contribution to the field of online learning and isotonic regression, and it has the potential to impact the development of practical algorithms for online isotonic regression.
Arguments for acceptance:
* The paper introduces a new and practical model for online isotonic regression.
* The paper develops an online-to-batch conversion that relates the fixed design model to the random permutation model.
* The paper analyzes the class of forward algorithms and shows that they achieve a decent regret rate in all cases and match the optimal rate in special cases.
Arguments against acceptance:
* The paper assumes that the data instances and labels are chosen adversarially, which may not be realistic in all scenarios.
* The paper does not provide a complete analysis of the forward algorithms, and some of the results are based on conjectures or numerical experiments.
Rating: 8/10
Recommendation: Accept with minor revisions. The paper is well-written, and the authors provide a clear and concise introduction to the problem and the related work. The technical sections are also well-organized, and the proofs are detailed and easy to follow. The paper makes a significant contribution to the field of online learning and isotonic regression, and it has the potential to impact the development of practical algorithms for online isotonic regression. However, the paper could benefit from some minor revisions to address the weaknesses mentioned above.