This paper proposes a novel algorithm, NeuralFDR, for multiple hypotheses testing with multi-dimensional features. The main claim of the paper is that NeuralFDR can learn a discovery threshold as a function of hypothesis features, leading to more discoveries while controlling the false discovery rate (FDR). The authors support this claim with theoretical guarantees, simulations, and real-world experiments.
The paper is well-written, and the authors provide a clear overview of the problem, related work, and their contributions. The proposed algorithm is based on a neural network that learns a nonlinear mapping from hypothesis features to a discovery threshold. The authors also introduce a mirroring technique to estimate false discoveries, which is a key component of the algorithm.
The strengths of the paper include:
* The authors provide a clear and concise introduction to the problem of multiple hypotheses testing and the limitations of existing methods.
* The proposed algorithm, NeuralFDR, is novel and has the potential to improve the state-of-the-art in multiple hypotheses testing.
* The authors provide theoretical guarantees for the algorithm, including FDR control and asymptotic FDR control under weak dependence.
* The simulations and real-world experiments demonstrate the effectiveness of NeuralFDR in making more discoveries while controlling FDR.
The weaknesses of the paper include:
* The algorithm requires a large number of hypotheses and a significant alternative proportion to perform well, which may limit its applicability to smaller datasets.
* The choice of network architecture and hyperparameters may require careful tuning, which can be time-consuming and require significant expertise.
* The authors do not provide a detailed comparison with other state-of-the-art methods, such as SABHA and AdaPT, which may have similar performance characteristics.
Overall, the paper is well-written, and the proposed algorithm has the potential to make a significant contribution to the field of multiple hypotheses testing. However, the authors should address the limitations of the algorithm and provide more detailed comparisons with other state-of-the-art methods to further demonstrate its effectiveness.
Arguments for acceptance:
* The paper proposes a novel algorithm with theoretical guarantees and demonstrates its effectiveness in simulations and real-world experiments.
* The algorithm has the potential to improve the state-of-the-art in multiple hypotheses testing and make a significant contribution to the field.
* The paper is well-written, and the authors provide a clear overview of the problem, related work, and their contributions.
Arguments for rejection:
* The algorithm requires a large number of hypotheses and a significant alternative proportion to perform well, which may limit its applicability to smaller datasets.
* The choice of network architecture and hyperparameters may require careful tuning, which can be time-consuming and require significant expertise.
* The authors do not provide a detailed comparison with other state-of-the-art methods, which may have similar performance characteristics.