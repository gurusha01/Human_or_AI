This paper introduces hierarchical implicit models (HIMs), a new class of Bayesian hierarchical models that combine the idea of implicit densities with hierarchical Bayesian modeling. The authors also develop likelihood-free variational inference (LFVI), a scalable variational inference algorithm for HIMs. The paper demonstrates the effectiveness of HIMs and LFVI on several applications, including a large-scale physical simulator for predator-prey populations, a Bayesian generative adversarial network for discrete data, and a deep implicit model for text generation.
The main claims of the paper are well-supported by theoretical analysis and experimental results. The authors provide a clear and well-organized presentation of their work, making it easy to follow and understand. The paper is technically sound, and the authors are careful and honest about evaluating both the strengths and weaknesses of their work.
The paper is original and significant, as it presents a new class of models and a new algorithm for inference. The authors provide a comprehensive review of related work and demonstrate how their approach differs from previous contributions. The paper is well-written, and the authors provide enough information for the expert reader to reproduce their results.
The strengths of the paper include:
* The introduction of a new class of models (HIMs) that combines the flexibility of implicit densities with the interpretability of hierarchical Bayesian modeling.
* The development of a scalable variational inference algorithm (LFVI) for HIMs, which allows for accurate and efficient inference in large-scale applications.
* The demonstration of the effectiveness of HIMs and LFVI on several applications, including a large-scale physical simulator, a Bayesian generative adversarial network, and a deep implicit model for text generation.
The weaknesses of the paper include:
* The requirement for differentiable global variables and reparameterizable global approximations, which may limit the applicability of LFVI to certain models.
* The potential instability of the ratio estimator, which may require careful tuning of hyperparameters and initialization of parameters.
Overall, the paper is well-written, technically sound, and presents a significant contribution to the field of machine learning. The authors provide a clear and well-organized presentation of their work, and the paper is easy to follow and understand. The strengths of the paper outweigh its weaknesses, and the paper is a valuable contribution to the field.
Arguments pro acceptance:
* The paper introduces a new class of models (HIMs) that combines the flexibility of implicit densities with the interpretability of hierarchical Bayesian modeling.
* The paper develops a scalable variational inference algorithm (LFVI) for HIMs, which allows for accurate and efficient inference in large-scale applications.
* The paper demonstrates the effectiveness of HIMs and LFVI on several applications, including a large-scale physical simulator, a Bayesian generative adversarial network, and a deep implicit model for text generation.
Arguments con acceptance:
* The requirement for differentiable global variables and reparameterizable global approximations may limit the applicability of LFVI to certain models.
* The potential instability of the ratio estimator may require careful tuning of hyperparameters and initialization of parameters.
Recommendation: Accept. The paper is well-written, technically sound, and presents a significant contribution to the field of machine learning. The strengths of the paper outweigh its weaknesses, and the paper is a valuable contribution to the field.