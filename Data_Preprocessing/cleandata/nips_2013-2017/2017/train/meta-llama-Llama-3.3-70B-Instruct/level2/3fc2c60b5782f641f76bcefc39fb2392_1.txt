This paper proposes an end-to-end approach for learning probabilistic machine learning models in the context of stochastic programming, where the goal is to minimize some expected cost over the models' probabilistic predictions, subject to some constraints. The authors argue that traditional model learning approaches, which focus on minimizing the log-likelihood of observed data, may not be optimal for tasks where the true distribution is unknown or complex. Instead, they propose to train a probabilistic model to directly capture the task-based objective, by computing derivatives through the solution to the stochastic programming problem.
The paper presents three experimental evaluations of the proposed approach: a classical inventory stock problem, a real-world electrical grid scheduling task, and a real-world energy storage arbitrage task. The results show that the proposed approach can outperform traditional modeling and purely black-box policy optimization approaches in these applications.
The strengths of the paper include:
* The proposal of a novel end-to-end approach for learning probabilistic models in stochastic programming, which can handle complex tasks with unknown or uncertain distributions.
* The presentation of a clear and well-motivated problem formulation, which highlights the limitations of traditional model learning approaches.
* The inclusion of three experimental evaluations, which demonstrate the effectiveness of the proposed approach in different domains.
The weaknesses of the paper include:
* The lack of a comprehensive comparison with other state-of-the-art methods, which makes it difficult to assess the relative performance of the proposed approach.
* The limited discussion of the computational complexity and scalability of the proposed approach, which may be a concern for large-scale applications.
* The absence of a detailed analysis of the robustness and sensitivity of the proposed approach to different types of uncertainty and noise in the data.
Overall, the paper presents a promising approach for learning probabilistic models in stochastic programming, and the experimental results demonstrate its potential in different domains. However, further research is needed to fully explore the capabilities and limitations of the proposed approach, and to compare it with other state-of-the-art methods.
Arguments for acceptance:
* The paper proposes a novel and well-motivated approach for learning probabilistic models in stochastic programming.
* The experimental results demonstrate the effectiveness of the proposed approach in different domains.
* The paper has the potential to contribute to the development of more robust and efficient methods for stochastic programming.
Arguments against acceptance:
* The paper lacks a comprehensive comparison with other state-of-the-art methods.
* The computational complexity and scalability of the proposed approach are not fully discussed.
* The robustness and sensitivity of the proposed approach to different types of uncertainty and noise in the data are not fully analyzed.