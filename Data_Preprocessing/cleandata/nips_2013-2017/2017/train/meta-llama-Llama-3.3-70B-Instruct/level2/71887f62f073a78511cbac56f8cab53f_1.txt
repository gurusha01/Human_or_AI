This paper proposes a new randomized coordinate descent method, called SMART-CD, for solving a convex optimization template with broad applications. The authors combine four key techniques: smoothing, acceleration, homotopy, and randomized coordinate descent, to achieve the best known O(1/k) convergence rate for the nonsmooth template. The paper provides a detailed analysis of the algorithm, including its convergence rate guarantees, and demonstrates its effectiveness through numerical experiments on various applications, including brain imaging, support vector machines, and linear programming.
The main claims of the paper are:
1. The proposed SMART-CD algorithm achieves the best known O(1/k) convergence rate for the nonsmooth template.
2. The algorithm can be efficiently implemented using a partial update strategy, reducing the per-iteration cost.
3. The algorithm is robust and can handle various applications, including those with non-smooth objectives and constraints.
The support for these claims is provided through:
1. A detailed theoretical analysis of the algorithm, including its convergence rate guarantees.
2. Numerical experiments on various applications, demonstrating the algorithm's effectiveness and robustness.
3. Comparisons with other state-of-the-art algorithms, showing that SMART-CD outperforms them in many cases.
The usefulness of the paper is high, as it provides a new and efficient algorithm for solving a wide range of convex optimization problems. The algorithm's ability to handle non-smooth objectives and constraints makes it particularly useful for many machine learning and signal processing applications.
The paper's field knowledge is excellent, as it demonstrates a thorough understanding of the relevant literature and techniques in convex optimization. The authors provide a clear and concise overview of the related work and demonstrate how their algorithm improves upon existing methods.
The novelty of the paper is high, as it proposes a new and innovative algorithm that combines multiple techniques to achieve state-of-the-art performance. The paper's contributions are significant, as they provide a new tool for solving convex optimization problems and demonstrate its effectiveness in various applications.
The completeness of the paper is good, as it provides a detailed analysis of the algorithm and its applications. However, some of the proofs and technical details are relegated to the supplementary document, which may make it difficult for some readers to follow.
The limitations of the paper are acknowledged by the authors, who note that the algorithm's performance may be affected by the choice of parameters and the specific application. However, the authors provide guidance on how to choose the parameters and demonstrate the algorithm's robustness through numerical experiments.
Overall, this is a well-written and well-structured paper that makes significant contributions to the field of convex optimization. The paper's strengths include its novelty, usefulness, and field knowledge, while its weaknesses are minor and do not detract from its overall impact.
Arguments for acceptance:
* The paper proposes a new and innovative algorithm that achieves state-of-the-art performance.
* The paper provides a detailed analysis of the algorithm and its applications.
* The paper demonstrates the algorithm's effectiveness and robustness through numerical experiments.
* The paper's contributions are significant and make a substantial impact on the field of convex optimization.
Arguments against acceptance:
* Some of the proofs and technical details are relegated to the supplementary document, which may make it difficult for some readers to follow.
* The paper's performance may be affected by the choice of parameters and the specific application.