This paper presents a novel formulation of non-negative matching pursuit (NNMP) algorithms for optimization over the convex cone, parametrized as the conic hull of a generic atom set. The authors provide a comprehensive convergence analysis, including sublinear and linear convergence rates, and introduce corrective variants with linear convergence guarantees. The paper is well-written, and the authors demonstrate the effectiveness of their algorithms through numerical experiments on various tasks, including synthetic data, non-negative matrix factorization, and non-negative garrote.
The main claims of the paper are:
1. The authors propose a novel formulation of NNMP, which is guaranteed to converge, and provide explicit convergence rates.
2. The authors introduce corrective variants of NNMP, including away-steps and pairwise MP, which achieve linear convergence.
3. The authors demonstrate the effectiveness of their algorithms through numerical experiments on various tasks.
The support for these claims is strong, with a thorough convergence analysis and numerical experiments that verify the convergence rates. The authors also provide a clear discussion of the limitations of their algorithms and the potential for future work.
The usefulness of the ideas presented in the paper is high, as they provide a new framework for optimization over convex cones, which is a common problem in many fields, including machine learning and signal processing. The authors demonstrate the applicability of their algorithms to various tasks, including non-negative matrix factorization and non-negative garrote.
The paper reflects common knowledge in the field, with a clear understanding of the existing literature on matching pursuit and Frank-Wolfe algorithms. The authors provide a thorough review of related work and demonstrate how their algorithms improve upon existing methods.
The novelty of the paper is high, as it presents a new formulation of NNMP and introduces corrective variants with linear convergence guarantees. The authors also provide a comprehensive convergence analysis, which is a significant contribution to the field.
The completeness of the paper is good, with a clear presentation of the algorithms, convergence analysis, and numerical experiments. The authors provide sufficient details for reproducibility, including pseudocode for the algorithms and a discussion of the computational complexity.
The limitations of the paper are acknowledged by the authors, including the potential for slow convergence in certain cases and the need for further work to improve the algorithms.
Overall, I would recommend accepting this paper, as it presents a significant contribution to the field of optimization and machine learning. The paper is well-written, and the authors demonstrate the effectiveness of their algorithms through numerical experiments.
Arguments pro acceptance:
* The paper presents a novel formulation of NNMP, which is guaranteed to converge, and provides explicit convergence rates.
* The authors introduce corrective variants of NNMP, including away-steps and pairwise MP, which achieve linear convergence.
* The authors demonstrate the effectiveness of their algorithms through numerical experiments on various tasks.
* The paper reflects common knowledge in the field, with a clear understanding of the existing literature on matching pursuit and Frank-Wolfe algorithms.
Arguments con acceptance:
* The paper may require some background knowledge in optimization and machine learning to fully understand the contributions.
* The authors could provide more discussion on the potential applications of their algorithms in other fields.
* The paper could benefit from more numerical experiments to further demonstrate the effectiveness of the algorithms.