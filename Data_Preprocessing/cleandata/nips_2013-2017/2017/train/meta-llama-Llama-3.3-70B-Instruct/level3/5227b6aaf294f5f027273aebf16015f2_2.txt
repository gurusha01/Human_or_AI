This paper introduces a novel architecture called SphereNet, which replaces traditional dot product with geodesic distance in convolution operators and fully-connected layers. The use of spherical operations in SphereNet is a significant contribution to the literature, as most existing works focus on using angular similarity for Softmax or loss functions, not for convolution. The spherical operations in SphereNet achieve faster convergence rate and better accuracy performance, while also mitigating the vanishing/exploding gradients problem in deep networks.
The paper is well-written and clearly organized, making it easy to follow and understand the concepts presented. The authors provide a thorough analysis of the SphereNet architecture and its benefits, including a detailed explanation of the geodesic distance and its application in convolution operators. The experimental results demonstrate the effectiveness of SphereNet in achieving superior performance in terms of accuracy and convergence rate.
However, the paper has room for improvement, including adding bias back to the angular Softmax equation to calibrate output for imbalanced datasets, and explaining the root cause of the accuracy drop in baseline methods. Additionally, the lack of support for angular operators in fast matrix multiplication libraries may limit the applicability of SphereNet in certain scenarios.
The strengths of the paper include its originality, technical soundness, and significance. The use of spherical operations in SphereNet is a novel approach that has not been explored before, and the authors provide a thorough analysis of its benefits and limitations. The paper is well-organized and clearly written, making it easy to follow and understand the concepts presented.
The weaknesses of the paper include the need for further improvement in certain areas, such as adding bias to the angular Softmax equation and explaining the root cause of the accuracy drop in baseline methods. Additionally, the lack of support for angular operators in fast matrix multiplication libraries may limit the applicability of SphereNet in certain scenarios.
Overall, I would recommend accepting this paper for publication, as it presents a novel and significant contribution to the field of deep learning. The paper is well-written, technically sound, and provides a thorough analysis of the SphereNet architecture and its benefits.
Arguments pro acceptance:
* The paper presents a novel and significant contribution to the field of deep learning.
* The use of spherical operations in SphereNet is a novel approach that has not been explored before.
* The paper is well-organized and clearly written, making it easy to follow and understand the concepts presented.
* The experimental results demonstrate the effectiveness of SphereNet in achieving superior performance in terms of accuracy and convergence rate.
Arguments con acceptance:
* The paper has room for improvement in certain areas, such as adding bias to the angular Softmax equation and explaining the root cause of the accuracy drop in baseline methods.
* The lack of support for angular operators in fast matrix multiplication libraries may limit the applicability of SphereNet in certain scenarios.