This paper proposes a novel unbiased estimator for the variational evidence lower bound (ELBO) that has zero variance when the variational approximation is exact. The authors provide a simple and general implementation of this trick in terms of a single change to the computation graph operated on by standard automatic differentiation packages. They also generalize their gradient estimator to mixture and importance-weighted lower bounds and discuss extensions to flow-based approximate posteriors.
The paper is well-structured and easy to follow, with clear explanations of the proposed method and its advantages. The authors provide a thorough analysis of the behavior of the proposed gradient estimator and demonstrate its efficacy through experimental results on MNIST and Omniglot datasets using variational and importance-weighted autoencoders.
However, the paper lacks citations to relevant works, including those on labeled stochastic block models and active learning for community detection. The model and problem statement need to be presented more clearly, including whether the minimax model has any restrictions on cluster sizes. Additionally, Theorem 2 appears to be incorrect as stated, and the proof assumes k -> Infinity, which is not stated in the theorem.
The numerical section is not valuable due to the lack of comparison with existing works and only comparing with trivial baselines. The paper has many confusing and unclear sentences, grammar mistakes, typos, and strange wording that need to be addressed. The authors' response clarified some issues, but a careful revision is still recommended to address the comments and improve the paper's clarity and readability.
The strengths of the paper include its novel contribution to the field of variational inference, its clear and well-structured presentation, and its thorough analysis of the proposed method. The weaknesses of the paper include its lack of citations to relevant works, its unclear model and problem statement, and its poorly written numerical section.
Arguments pro acceptance:
* The paper proposes a novel and useful method for reducing the variance of the ELBO gradient estimator.
* The method is simple and easy to implement, making it a valuable contribution to the field.
* The paper provides a thorough analysis of the behavior of the proposed gradient estimator and demonstrates its efficacy through experimental results.
Arguments con acceptance:
* The paper lacks citations to relevant works, which may indicate a lack of understanding of the existing literature.
* The model and problem statement need to be presented more clearly, which may indicate a lack of clarity in the authors' thinking.
* The numerical section is poorly written and lacks comparison with existing works, which may indicate a lack of rigor in the authors' evaluation of their method.
Overall, I recommend a careful revision of the paper to address the comments and improve its clarity and readability. With revisions, the paper has the potential to be a valuable contribution to the field of variational inference. 
Quality: 7
Clarity: 6
Originality: 8
Significance: 7
Recommendation: Accept with major revisions.