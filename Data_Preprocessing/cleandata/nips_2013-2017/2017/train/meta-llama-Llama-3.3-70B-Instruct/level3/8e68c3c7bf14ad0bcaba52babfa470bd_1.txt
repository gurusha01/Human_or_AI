This paper presents a novel framework for image captioning using Reinforcement Learning (RL) with human feedback. The authors propose a two-stage approach, where a feedback network simulates human feedback and an RL model is trained to optimize the captioning task. However, the novelty of this approach is unclear, as the two-stage batch mode of human labeling is a common approach in many RL settings. Furthermore, the use of RL to optimize non-differentiable metrics is not new.
The experimental results on the COCO dataset show a minor improvement of less than 0.5% in BLEU-4 score when using feedback, which may not be statistically significant. Additionally, the baseline performance is far from state-of-the-art, which raises questions about the effectiveness of the proposed approach. The paper also lacks detailed analysis and examples to demonstrate how feedback helps in the RL framework, such as comparing the errors made by the RL baseline and the model with feedback.
In terms of quality, the paper is technically sound, but the claims are not well-supported by theoretical analysis or experimental results. The paper is well-organized and clearly written, but it lacks clarity in explaining the significance of the proposed approach and its contributions to the field. The originality of the paper is also questionable, as the ideas presented are not significantly different from previous contributions.
The significance of the paper is also limited, as the results are not important or impactful, and other people are unlikely to use these ideas or build on them. The paper does not address a difficult problem in a better way than previous research, and it does not advance the state of the art in a demonstrable way.
Arguments for acceptance:
* The paper presents a novel framework for image captioning using RL with human feedback.
* The experimental results show some improvement in performance when using feedback.
Arguments against acceptance:
* The novelty of the approach is unclear, and the two-stage batch mode of human labeling is a common approach in many RL settings.
* The experimental results are not statistically significant, and the baseline performance is far from state-of-the-art.
* The paper lacks detailed analysis and examples to demonstrate how feedback helps in the RL framework.
* The paper is not original, and the ideas presented are not significantly different from previous contributions.
* The significance of the paper is limited, and the results are not important or impactful.