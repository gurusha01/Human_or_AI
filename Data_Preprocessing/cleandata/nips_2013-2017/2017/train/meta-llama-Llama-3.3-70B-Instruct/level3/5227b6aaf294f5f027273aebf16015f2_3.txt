This paper proposes a novel unbiased estimator for the variational evidence lower bound (ELBO) that has zero variance when the variational approximation is exact. The authors provide a simple and general implementation of this trick in terms of a single change to the computation graph operated on by standard automatic differentiation packages. They also generalize their gradient estimator to mixture and importance-weighted lower bounds and discuss extensions to flow-based approximate posteriors.
The paper is well-written, and the authors provide a clear explanation of the background and the proposed method. The experimental results on MNIST and Omniglot datasets using variational and importance-weighted autoencoders demonstrate the efficacy of the proposed trick. The authors also provide a detailed comparison with existing methods and discuss the potential applications of their approach.
However, there are some concerns that need to be addressed. The choice of the ELBO estimator is crucial, and the authors suggest that using equation (1) is preferred when the variational approximation is exact. However, it is not clear how to choose the best estimator in practice. The authors also mention that the score function term has expectation zero, but it is not clear how this term affects the variance of the gradient estimator.
The proposed method is specific to variational inference, but the authors suggest that similar unbiased but high-variance terms might exist in other stochastic optimization settings. It would be interesting to explore these possibilities in future work.
In terms of the conference guidelines, the paper meets the criteria for quality, clarity, originality, and significance. The paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. The paper is clearly written, and the organization is good. The proposed method is novel and has the potential to make a significant impact in the field of variational inference.
Arguments pro acceptance:
* The paper proposes a novel unbiased estimator for the ELBO that has zero variance when the variational approximation is exact.
* The authors provide a simple and general implementation of the proposed trick.
* The experimental results demonstrate the efficacy of the proposed method.
* The paper is well-written, and the authors provide a clear explanation of the background and the proposed method.
Arguments con acceptance:
* The choice of the ELBO estimator is crucial, and it is not clear how to choose the best estimator in practice.
* The score function term has expectation zero, but it is not clear how this term affects the variance of the gradient estimator.
* The proposed method is specific to variational inference, and it is not clear how to extend it to other stochastic optimization settings.
Overall, I recommend accepting the paper, but the authors should address the concerns mentioned above to improve the clarity and impact of the paper.