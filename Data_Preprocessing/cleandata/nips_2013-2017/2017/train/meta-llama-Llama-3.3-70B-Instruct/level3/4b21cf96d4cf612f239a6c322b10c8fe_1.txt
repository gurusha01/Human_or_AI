This paper proposes a novel approach to image-conditioned caption generation using deep generative models, specifically a variational auto-encoder (VAE) framework with a data-dependent latent variable. The authors introduce a data-dependent additive Gaussian prior to address the limited representation power in caption generation, resulting in diverse and accurate sentence generation.
The proposed AG-CVAE method achieves more accurate performance than the LSTM baseline and other CVAE baselines, although the improvements are not very significant. The paper provides a thorough evaluation of the method, including runtime, quality of kernel estimates, and predictive accuracies on standard benchmark sequence datasets.
The strengths of the paper include its novel approach to caption generation, its ability to handle large values of k and m, and its state-of-the-art classification performance. However, the paper also has some weaknesses, such as the lack of strong evidence to support the claims of AG-CVAE's advantages over CVAE/GMM-CVAE, and the unclear diversity evaluation of AG-CVAE.
To improve the paper, I suggest providing more detailed comparisons between AG-CVAE and other methods, including side-by-side comparisons and ablation studies. Additionally, the authors could explore learnable data-dependent priors to boost performance and provide more insights into the diversity evaluation of AG-CVAE.
Overall, the paper is well-written and provides a significant contribution to the field of sequence classification and caption generation. With some revisions to address the weaknesses, the paper has the potential to be a strong candidate for acceptance.
Arguments pro acceptance:
* Novel approach to caption generation using VAE framework with data-dependent latent variable
* State-of-the-art classification performance on benchmark datasets
* Ability to handle large values of k and m
Arguments con acceptance:
* Lack of strong evidence to support claims of AG-CVAE's advantages over CVAE/GMM-CVAE
* Unclear diversity evaluation of AG-CVAE
* Limited comparisons with other methods
Rating: 7/10
Recommendation: Accept with minor revisions. The authors should provide more detailed comparisons between AG-CVAE and other methods, explore learnable data-dependent priors, and clarify the diversity evaluation of AG-CVAE.