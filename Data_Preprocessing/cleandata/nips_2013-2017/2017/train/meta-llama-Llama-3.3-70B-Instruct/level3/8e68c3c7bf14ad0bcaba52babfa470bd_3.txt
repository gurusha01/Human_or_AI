This paper proposes a novel framework for image captioning by incorporating human feedback in natural language using reinforcement learning. The authors argue that human feedback is more valuable than additional caption annotations and demonstrate the effectiveness of their approach through comprehensive experiments. The paper addresses a well-motivated aspect of learning, human feedback, and shows that it can be used to improve the model's performance.
The authors effectively collect human feedback in a least ambiguous way to fine-tune the model later, using a phrase-based captioning model. The experiments are comprehensive, with different ablations to prove the effectiveness of human feedback. However, the paper lacks human evaluation on caption quality, which is a significant weakness. Additionally, there are potential errors in tables and figures, and the descriptions of the training procedure and decoding method are unclear.
The paper's use of reinforcement learning and human feedback is compared to other works, such as [34], which uses deep reinforcement learning for visual dialog agents. The review questions the small size of the testing dataset, which is almost 1/20th of the training dataset, and suggests that it may not be representative.
The strengths of the paper include its novel approach to incorporating human feedback in image captioning, its comprehensive experiments, and its potential to improve the model's performance. The weaknesses include the lack of human evaluation, potential errors in tables and figures, and unclear descriptions of the training procedure and decoding method.
To improve the paper, the authors should consider adding human evaluation on caption quality, clarifying the training procedure and decoding method, and correcting typos and inconsistencies. Additionally, the authors should provide more details on the reinforcement learning algorithm used and its hyperparameters.
Overall, the paper has the potential to make a significant contribution to the field of image captioning, but it requires further refinement and evaluation to demonstrate its effectiveness. The authors should address the weaknesses mentioned above and provide more comprehensive evaluations to support their claims. 
Arguments pro acceptance:
- Novel approach to incorporating human feedback in image captioning
- Comprehensive experiments to prove the effectiveness of human feedback
- Potential to improve the model's performance
Arguments con acceptance:
- Lack of human evaluation on caption quality
- Potential errors in tables and figures
- Unclear descriptions of the training procedure and decoding method
- Small size of the testing dataset.