This paper proposes a novel attention mechanism that learns high-order correlations between various data modalities, which is demonstrated to be effective in visual question answering (VQA) tasks. The authors provide a thorough review of related work on attention mechanisms, highlighting the limitations of existing approaches and the need for a more general and flexible attention mechanism.
The proposed attention mechanism is based on a probabilistic model that learns unary, pairwise, and ternary potentials to capture correlations between different data modalities. The authors demonstrate the effectiveness of their approach on the VQA dataset, achieving state-of-the-art performance with a relatively simple model.
The paper is well-written, and the authors provide a clear and concise explanation of their approach. The experimental results are thorough, and the authors provide a detailed analysis of the performance of their model.
Strengths:
* The paper proposes a novel and generally applicable attention mechanism that can learn high-order correlations between various data modalities.
* The authors provide a thorough review of related work on attention mechanisms, highlighting the limitations of existing approaches.
* The experimental results demonstrate the effectiveness of the proposed approach on the VQA dataset, achieving state-of-the-art performance with a relatively simple model.
Weaknesses:
* The paper assumes that the data modalities are independent, which may not always be the case in practice.
* The authors do not provide a detailed analysis of the computational complexity of their approach, which may be a limitation in practice.
* The paper focuses primarily on the VQA task, and it is unclear how well the proposed attention mechanism will generalize to other tasks and datasets.
Arguments pro acceptance:
* The paper proposes a novel and effective attention mechanism that can learn high-order correlations between various data modalities.
* The experimental results demonstrate the effectiveness of the proposed approach on the VQA dataset, achieving state-of-the-art performance with a relatively simple model.
* The paper provides a thorough review of related work on attention mechanisms, highlighting the limitations of existing approaches.
Arguments con acceptance:
* The paper assumes that the data modalities are independent, which may not always be the case in practice.
* The authors do not provide a detailed analysis of the computational complexity of their approach, which may be a limitation in practice.
* The paper focuses primarily on the VQA task, and it is unclear how well the proposed attention mechanism will generalize to other tasks and datasets.
Overall, the paper is well-written, and the authors provide a clear and concise explanation of their approach. The experimental results demonstrate the effectiveness of the proposed attention mechanism, and the paper provides a thorough review of related work on attention mechanisms. However, the paper has some limitations, including the assumption of independent data modalities and the lack of a detailed analysis of computational complexity. Therefore, I would recommend accepting the paper with minor revisions to address these limitations. 
Quality: 8/10
The paper is well-written, and the authors provide a clear and concise explanation of their approach. The experimental results demonstrate the effectiveness of the proposed attention mechanism.
Clarity: 9/10
The paper is well-organized, and the authors provide a clear and concise explanation of their approach.
Originality: 8/10
The paper proposes a novel attention mechanism that learns high-order correlations between various data modalities.
Significance: 8/10
The paper demonstrates the effectiveness of the proposed attention mechanism on the VQA dataset, achieving state-of-the-art performance with a relatively simple model. However, the paper has some limitations, including the assumption of independent data modalities and the lack of a detailed analysis of computational complexity.