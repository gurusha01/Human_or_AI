This paper revisits the problem of online isotonic regression, which involves fitting monotonic functions to best explain the data in an online setting. The authors develop a new perspective on this problem by studying the random permutation model, which is a more practical and realistic setting than the previously studied fixed design model. The main contribution of the paper is the development of efficient algorithms and matching lower bounds for online isotonic regression in the random permutation model.
The paper starts by introducing the problem of online isotonic regression and its importance in various applications. The authors then discuss the limitations of the fixed design model and motivate the study of the random permutation model. They develop a novel online-to-batch conversion that relates the fixed design model to the random permutation model, which allows them to transport the optimal regret result from the fixed design model to the random permutation model.
The authors also analyze the class of forward algorithms, which are popular and practical algorithms for online isotonic regression. They show that forward algorithms achieve a decent regret rate in all cases and match the optimal rate in special cases. Additionally, they propose a new algorithm called Heavy-γ, which is a modification of the forward algorithm that uses a weighted label estimate.
The paper is well-written, and the authors provide a clear and concise introduction to the problem and the related work. The technical sections are also well-organized, and the proofs are detailed and easy to follow. The authors provide a thorough analysis of the algorithms and their performance, and they discuss the implications of their results for practice.
The strengths of the paper include:
* The development of a new perspective on online isotonic regression by studying the random permutation model
* The development of efficient algorithms and matching lower bounds for online isotonic regression in the random permutation model
* The analysis of the class of forward algorithms and their performance in different settings
* The proposal of a new algorithm called Heavy-γ, which has the potential to achieve the optimal regret rate
The weaknesses of the paper include:
* The paper assumes that the data is generated from a random permutation model, which may not always be the case in practice
* The analysis of the algorithms is mostly theoretical, and it would be useful to see some empirical evaluations of the algorithms
* The paper does not provide a complete solution to the problem of online isotonic regression on arbitrary partial orders, which is an important open problem
Overall, the paper makes a significant contribution to the field of online learning and isotonic regression, and it provides a new perspective on the problem that has the potential to lead to more practical and efficient algorithms.
Arguments for acceptance:
* The paper develops a new perspective on online isotonic regression by studying the random permutation model
* The paper provides efficient algorithms and matching lower bounds for online isotonic regression in the random permutation model
* The paper analyzes the class of forward algorithms and their performance in different settings
* The paper proposes a new algorithm called Heavy-γ, which has the potential to achieve the optimal regret rate
Arguments against acceptance:
* The paper assumes that the data is generated from a random permutation model, which may not always be the case in practice
* The analysis of the algorithms is mostly theoretical, and it would be useful to see some empirical evaluations of the algorithms
* The paper does not provide a complete solution to the problem of online isotonic regression on arbitrary partial orders, which is an important open problem.