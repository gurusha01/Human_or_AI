This paper proposes a new randomized coordinate descent method for solving a convex optimization template with broad applications. The authors combine four key techniques: smoothing, acceleration, homotopy, and randomized coordinate descent, to achieve the best known O(1/k) convergence rate for the nonsmooth template. The paper is well-written, and the authors provide a clear and detailed explanation of their approach.
The paper relates to previous work at NIPS and elsewhere, particularly in the area of coordinate descent methods. The authors cite several relevant papers, including [1-6], and discuss how their method differs from and improves upon existing approaches. The paper also provides a comprehensive review of the literature, highlighting the strengths and weaknesses of different methods.
The strengths of the paper include:
* The authors propose a new and efficient algorithm for solving a general convex optimization template, which has many applications in machine learning and other fields.
* The paper provides a rigorous theoretical analysis of the algorithm, including convergence rate guarantees and bounds on the complexity of the algorithm.
* The authors demonstrate the effectiveness of their algorithm through numerical experiments on several benchmark datasets, including brain imaging and support vector machines applications.
* The paper is well-organized and easy to follow, with clear explanations of the algorithm and its analysis.
The weaknesses of the paper include:
* The algorithm and its analysis are quite technical, and may be difficult for non-experts to follow.
* The paper assumes a certain level of background knowledge in convex optimization and machine learning, which may limit its accessibility to a broader audience.
* Some of the numerical experiments are limited to specific datasets and applications, and it is not clear how well the algorithm will perform on other problems.
Arguments for acceptance:
* The paper proposes a new and efficient algorithm for solving a general convex optimization template, which has many applications in machine learning and other fields.
* The paper provides a rigorous theoretical analysis of the algorithm, including convergence rate guarantees and bounds on the complexity of the algorithm.
* The authors demonstrate the effectiveness of their algorithm through numerical experiments on several benchmark datasets.
Arguments against acceptance:
* The algorithm and its analysis are quite technical, and may be difficult for non-experts to follow.
* The paper assumes a certain level of background knowledge in convex optimization and machine learning, which may limit its accessibility to a broader audience.
* Some of the numerical experiments are limited to specific datasets and applications, and it is not clear how well the algorithm will perform on other problems.
Overall, I believe that the paper is well-written and makes a significant contribution to the field of convex optimization and machine learning. The authors provide a clear and detailed explanation of their approach, and demonstrate its effectiveness through numerical experiments. While the paper has some limitations, I believe that it is a strong candidate for acceptance at NIPS. 
Quality: 8/10
The paper is technically sound, and the authors provide a rigorous theoretical analysis of the algorithm. The numerical experiments are well-designed and demonstrate the effectiveness of the algorithm.
Clarity: 8/10
The paper is well-organized and easy to follow, with clear explanations of the algorithm and its analysis. However, the technical level of the paper may be challenging for non-experts.
Originality: 9/10
The paper proposes a new and efficient algorithm for solving a general convex optimization template, which has many applications in machine learning and other fields. The combination of smoothing, acceleration, homotopy, and randomized coordinate descent is novel and effective.
Significance: 9/10
The paper makes a significant contribution to the field of convex optimization and machine learning, and has the potential to impact a wide range of applications. The algorithm is efficient and effective, and the authors demonstrate its usefulness through numerical experiments.