This paper proposes a novel approach to multiple hypotheses testing, called NeuralFDR, which leverages the power of neural networks to learn a discovery threshold as a function of hypothesis features. The main idea is to model the decision threshold using a multilayer perceptron (MLP), which enables flexible handling of multi-dimensional discrete and continuous features. The authors demonstrate that NeuralFDR controls the false discovery rate (FDR) and makes more discoveries than state-of-the-art methods on both synthetic and real datasets.
The paper is well-written, and the authors provide a clear and concise introduction to the problem of multiple hypotheses testing and the limitations of existing methods. The proposed approach is thoroughly motivated, and the technical details are well-explained. The empirical results are impressive, showing that NeuralFDR outperforms other methods in various settings.
The strengths of the paper include:
* The proposal of a novel and flexible approach to multiple hypotheses testing, which can handle multi-dimensional features.
* The demonstration of the effectiveness of NeuralFDR in controlling FDR and making more discoveries than other methods.
* The provision of a clear and concise introduction to the problem and the proposed approach.
* The thorough evaluation of the method on various datasets, including synthetic and real-world data.
The weaknesses of the paper include:
* The requirement for a large number of hypotheses and a large alternative proportion for NeuralFDR to perform well.
* The lack of a clear understanding of which network architectures optimally capture signal in the data.
* The potential for overfitting, which is mitigated by the use of cross-validation, but may still be a concern in some cases.
Overall, the paper presents a significant contribution to the field of multiple hypotheses testing, and the proposed approach has the potential to be widely applicable in various domains. The authors have demonstrated the effectiveness of NeuralFDR in various settings, and the method is likely to be of interest to researchers and practitioners in the field.
Arguments for acceptance:
* The paper proposes a novel and flexible approach to multiple hypotheses testing, which can handle multi-dimensional features.
* The method is thoroughly evaluated on various datasets, including synthetic and real-world data.
* The results demonstrate that NeuralFDR controls FDR and makes more discoveries than other methods.
* The paper is well-written, and the authors provide a clear and concise introduction to the problem and the proposed approach.
Arguments against acceptance:
* The method requires a large number of hypotheses and a large alternative proportion to perform well.
* The lack of a clear understanding of which network architectures optimally capture signal in the data may limit the applicability of the method.
* The potential for overfitting may be a concern in some cases, although the use of cross-validation mitigates this risk.