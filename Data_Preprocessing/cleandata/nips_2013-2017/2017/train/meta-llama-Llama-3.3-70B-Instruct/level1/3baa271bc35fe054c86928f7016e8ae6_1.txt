This paper proposes a robust submodular streaming algorithm, STAR-T, which addresses the problem of maximizing a monotone submodular function subject to a cardinality constraint in a streaming setting with potential removals of elements. The algorithm makes one pass over the data and retains a small set of elements in memory, ensuring robustness against the removal of up to m elements. The authors also propose a simple greedy algorithm, STAR-T-GREEDY, which runs on the remaining elements after removal and achieves a constant-factor approximation guarantee.
The paper is well-written, and the authors provide a clear and concise introduction to the problem and their approach. The technical sections are thorough, and the analysis is sound. The experimental results demonstrate the effectiveness of the proposed algorithm in two different data summarization tasks, outperforming existing greedy and streaming methods.
The strengths of the paper include:
* The proposal of a novel partitioning structure and an exponentially decreasing thresholding rule, which enables the algorithm to achieve a constant-factor approximation guarantee.
* The provision of a thorough analysis of the algorithm's performance, including a proof of the approximation guarantee.
* The demonstration of the algorithm's effectiveness in practice through experimental results on two different datasets.
The weaknesses of the paper include:
* The assumption that the submodular function is normalized and monotone, which may not always be the case in practice.
* The requirement for a single pass over the data, which may not be feasible in all scenarios.
* The lack of comparison with other robust submodular optimization algorithms, which would provide a more comprehensive understanding of the proposed algorithm's performance.
Arguments for acceptance:
* The paper proposes a novel and effective algorithm for robust submodular streaming, which addresses a significant problem in machine learning.
* The analysis is thorough, and the experimental results demonstrate the algorithm's effectiveness in practice.
* The paper is well-written, and the authors provide a clear and concise introduction to the problem and their approach.
Arguments against acceptance:
* The assumption that the submodular function is normalized and monotone may limit the algorithm's applicability in practice.
* The requirement for a single pass over the data may not be feasible in all scenarios.
* The lack of comparison with other robust submodular optimization algorithms may limit the understanding of the proposed algorithm's performance.
Overall, I recommend accepting the paper, as it proposes a novel and effective algorithm for robust submodular streaming, and the analysis and experimental results demonstrate its effectiveness in practice. However, the authors should consider addressing the limitations and weaknesses of the paper in future work. 
Quality: 8/10
The paper is technically sound, and the analysis is thorough. However, the assumption that the submodular function is normalized and monotone may limit the algorithm's applicability in practice.
Clarity: 9/10
The paper is well-written, and the authors provide a clear and concise introduction to the problem and their approach.
Originality: 8/10
The paper proposes a novel partitioning structure and an exponentially decreasing thresholding rule, which enables the algorithm to achieve a constant-factor approximation guarantee. However, the idea of robust submodular optimization is not new, and the paper builds upon existing work in this area.
Significance: 9/10
The paper addresses a significant problem in machine learning, and the proposed algorithm has the potential to be widely applicable in practice. The experimental results demonstrate the algorithm's effectiveness in two different data summarization tasks.