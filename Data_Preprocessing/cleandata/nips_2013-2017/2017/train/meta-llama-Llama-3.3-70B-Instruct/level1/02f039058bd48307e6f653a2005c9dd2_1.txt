This paper proposes a novel approach to non-parametric Conditional Independence (CI) testing for continuous random variables by converting the problem into a binary classification task. The authors introduce a nearest-neighbor bootstrap procedure to generate samples that mimic the conditionally independent distribution, allowing them to leverage powerful classifiers like gradient-boosted trees and deep neural networks. The paper provides theoretical guarantees on the bootstrapped samples and generalization bounds for the classification problem under non-i.i.d near-independent samples.
The paper is well-written, and the authors provide a clear and concise introduction to the problem of CI testing and its significance in various statistical and learning problems. The proposed approach is innovative, and the use of binary classification to solve the CI testing problem is a clever idea. The theoretical results, including Theorem 1 and Theorem 2, provide a solid foundation for the proposed method.
The empirical evaluation of the proposed algorithm, CCIT, shows promising results, outperforming state-of-the-art algorithms like KCIT and RCIT in both synthetic and real-world experiments. The results on the flow-cytometry dataset are particularly impressive, demonstrating the effectiveness of CCIT in verifying CI relations in a real-world setting.
The paper has several strengths:
1. Originality: The paper proposes a novel approach to CI testing, which is a significant contribution to the field.
2. Theoretical guarantees: The authors provide rigorous theoretical results, including bounds on the total variational distance between the bootstrapped samples and the conditionally independent distribution.
3. Empirical evaluation: The paper includes a thorough empirical evaluation of the proposed algorithm, demonstrating its effectiveness in various settings.
However, there are some potential weaknesses:
1. Computational complexity: The nearest-neighbor bootstrap procedure may be computationally expensive, particularly for large datasets.
2. Choice of classifier: The paper uses gradient-boosted trees and deep neural networks as classifiers, but the choice of classifier may affect the performance of the algorithm.
3. Assumptions: The theoretical results rely on certain assumptions about the underlying distribution, which may not always hold in practice.
Overall, the paper is well-written, and the proposed approach is innovative and effective. The theoretical results provide a solid foundation for the method, and the empirical evaluation demonstrates its potential in various settings.
Arguments for acceptance:
1. The paper proposes a novel and innovative approach to CI testing.
2. The theoretical results provide a solid foundation for the proposed method.
3. The empirical evaluation demonstrates the effectiveness of the algorithm in various settings.
Arguments against acceptance:
1. The computational complexity of the nearest-neighbor bootstrap procedure may be a concern.
2. The choice of classifier may affect the performance of the algorithm.
3. The assumptions underlying the theoretical results may not always hold in practice.
Suggestions for improvement:
1. Provide more details on the computational complexity of the nearest-neighbor bootstrap procedure.
2. Investigate the effect of different classifiers on the performance of the algorithm.
3. Consider relaxing the assumptions underlying the theoretical results to make the method more robust.