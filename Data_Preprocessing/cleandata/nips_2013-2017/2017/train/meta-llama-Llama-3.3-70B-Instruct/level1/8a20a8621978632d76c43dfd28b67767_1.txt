This paper presents a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations), which assigns each feature an importance value for a particular prediction. The authors identify a new class of additive feature importance measures and provide theoretical results showing that there is a unique solution in this class with desirable properties. The paper unifies six existing methods, including LIME, DeepLIFT, and layer-wise relevance propagation, and shows that they are all additive feature attribution methods.
The strengths of the paper include its ability to provide a unified framework for interpreting predictions, its identification of a unique solution with desirable properties, and its provision of new methods that show improved computational performance and/or better consistency with human intuition than previous approaches. The paper is well-written, well-organized, and provides a clear explanation of the methods and results.
The weaknesses of the paper include the fact that the authors do not provide a comprehensive evaluation of the methods on a wide range of datasets and models. Additionally, the paper assumes that the features are independent, which may not always be the case in practice. The authors also do not provide a clear discussion of the limitations of the methods and the potential biases that may arise.
Arguments pro acceptance:
* The paper provides a unified framework for interpreting predictions, which is a significant contribution to the field.
* The authors identify a unique solution with desirable properties, which provides a strong foundation for the development of future methods.
* The paper provides new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.
* The paper is well-written, well-organized, and provides a clear explanation of the methods and results.
Arguments con acceptance:
* The authors do not provide a comprehensive evaluation of the methods on a wide range of datasets and models.
* The paper assumes that the features are independent, which may not always be the case in practice.
* The authors do not provide a clear discussion of the limitations of the methods and the potential biases that may arise.
* The paper may not be suitable for models with complex interactions between features.
Overall, I believe that the paper is a significant contribution to the field and provides a strong foundation for the development of future methods. However, I also believe that the authors should provide a more comprehensive evaluation of the methods and discuss the limitations and potential biases of the methods more clearly. 
Quality: 8/10
The paper is technically sound, and the claims are well-supported by theoretical analysis and experimental results. However, the authors could provide more comprehensive evaluations of the methods.
Clarity: 9/10
The paper is clearly written, well-organized, and provides a clear explanation of the methods and results.
Originality: 9/10
The paper provides a unified framework for interpreting predictions, which is a significant contribution to the field. The authors also identify a unique solution with desirable properties.
Significance: 9/10
The paper provides a strong foundation for the development of future methods, and the results are likely to be used by other researchers and practitioners. However, the authors could provide more comprehensive evaluations of the methods and discuss the limitations and potential biases of the methods more clearly.