This paper proposes a novel framework for controlling false alarms when multiple A/B tests are run over time, leveraging recent advances in adaptive sampling and online false discovery rate (FDR) control. The authors introduce a meta-algorithm that combines best-arm multi-armed bandit (MAB) algorithms with online FDR procedures, allowing for continuous monitoring and adaptive sampling. The framework addresses several shortcomings of traditional A/B testing, including the lack of adaptivity, inefficient sampling, and inadequate control of false discoveries.
The paper's main contributions include: (i) proposing reasonable definitions of a null hypothesis for MAB instances, (ii) deriving an always-valid sequential p-value for continuous monitoring, and (iii) demonstrating that using rejection thresholds of online-FDR algorithms as confidence levels for MAB algorithms results in sample-optimality, high power, and low FDR control.
The authors provide a concrete procedure, MAB-LORD, which combines a best-arm MAB algorithm with the LORD online FDR procedure. They prove theoretical guarantees for MAB-LORD, including mFDR control and power guarantees. The paper also presents extensive simulations on both artificial and real-world data, demonstrating the advantages of MAB-FDR over competing procedures in terms of sample complexity and power.
Strengths of the paper include:
* The authors address a significant problem in multiple testing, providing a novel and effective solution.
* The paper is well-organized, and the authors provide clear explanations of the proposed framework and its components.
* The theoretical guarantees and simulations demonstrate the effectiveness of the proposed approach.
Weaknesses of the paper include:
* The paper assumes that the arm means are independent and sub-Gaussian, which may not always be the case in practice.
* The authors do not provide a detailed comparison with other online FDR procedures, which would be useful for understanding the relative advantages of MAB-LORD.
Arguments pro acceptance:
* The paper proposes a novel and effective solution to a significant problem in multiple testing.
* The authors provide clear explanations and theoretical guarantees for the proposed framework.
* The simulations demonstrate the advantages of MAB-FDR over competing procedures.
Arguments con acceptance:
* The paper's assumptions about arm means may not always be realistic.
* The authors could provide more comparisons with other online FDR procedures to better understand the relative advantages of MAB-LORD.
Overall, the paper makes a significant contribution to the field of multiple testing and online FDR control, and the proposed framework has the potential to improve the efficiency and accuracy of A/B testing in various applications. With some minor revisions to address the weaknesses mentioned above, the paper is ready for publication.