This paper proposes a novel approach to estimate the distance between two probability distributions based on samples, called Population Matching Discrepancy (PMD). PMD is defined as the minimum weight matching between two random populations from the distributions. The authors prove that PMD is a strongly consistent estimator of the first Wasserstein metric and propose a stochastic gradient descent algorithm to learn parameters of the distributions using PMD.
The paper is well-written, and the ideas are clearly presented. The authors provide a thorough analysis of the relationship between PMD and the Wasserstein metric, as well as its advantages over the popular Maximum Mean Discrepancy (MMD) method. The experimental results demonstrate the effectiveness of PMD in domain adaptation and generative modeling tasks, outperforming MMD in terms of performance and convergence speed.
The strengths of the paper include:
* The proposal of a novel and theoretically sound approach to estimate the distance between two probability distributions.
* A thorough analysis of the relationship between PMD and the Wasserstein metric.
* The demonstration of the advantages of PMD over MMD in terms of fewer hyper-parameters, stronger gradients, and smaller mini-batch size.
* The application of PMD to domain adaptation and generative modeling tasks, with promising results.
The weaknesses of the paper include:
* The computational cost of PMD, which may be high for large population sizes.
* The lack of finite-sample error bounds for PMD, which would provide a more complete understanding of its theoretical properties.
* The limited experimental evaluation, which only considers two tasks and does not provide a comprehensive comparison with other methods.
Arguments for acceptance:
* The paper proposes a novel and theoretically sound approach to estimate the distance between two probability distributions.
* The experimental results demonstrate the effectiveness of PMD in domain adaptation and generative modeling tasks.
* The paper provides a thorough analysis of the relationship between PMD and the Wasserstein metric, which is a significant contribution to the field.
Arguments against acceptance:
* The computational cost of PMD may be high for large population sizes, which could limit its applicability.
* The lack of finite-sample error bounds for PMD may raise concerns about its theoretical properties.
* The limited experimental evaluation may not provide a comprehensive understanding of the strengths and weaknesses of PMD.
Overall, I recommend accepting the paper, as it proposes a novel and theoretically sound approach to estimate the distance between two probability distributions, with promising results in domain adaptation and generative modeling tasks. However, the authors should address the limitations of the paper, including the computational cost and the lack of finite-sample error bounds, in future work.