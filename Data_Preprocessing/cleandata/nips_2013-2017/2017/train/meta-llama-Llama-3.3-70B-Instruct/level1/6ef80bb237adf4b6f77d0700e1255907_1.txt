This paper proposes an accelerated first-order method for geodesically convex optimization on Riemannian manifolds, which is a generalization of Nesterov's accelerated gradient descent method from Euclidean space to nonlinear Riemannian space. The authors derive two equations and obtain two nonlinear operators for geodesically convex optimization, and provide a global convergence analysis of their accelerated algorithms. The paper also presents a specific iterative scheme for matrix Karcher mean problems and validates the theoretical results with experiments.
The paper is well-written and well-organized, and the authors provide a clear and detailed explanation of their methodology and results. The paper is related to previous work on geodesically convex optimization, such as [31], and the authors provide a thorough discussion of the differences and similarities between their approach and existing methods.
The strengths of the paper include:
* The authors provide a novel and efficient algorithm for geodesically convex optimization on Riemannian manifolds, which improves the convergence rate of existing methods.
* The paper provides a thorough and detailed analysis of the convergence properties of the proposed algorithm, including a discussion of the global convergence rate and the conditions under which the algorithm converges.
* The authors provide a specific iterative scheme for matrix Karcher mean problems, which is a important application of geodesically convex optimization.
The weaknesses of the paper include:
* The paper assumes that the geodesically convex function is smooth and strongly convex, which may not be the case in all applications.
* The paper does not provide a comparison with other existing methods for geodesically convex optimization, such as [25] and [11].
* The experimental results are limited to a specific application (matrix Karcher mean problems) and do not provide a comprehensive evaluation of the proposed algorithm.
Arguments for acceptance:
* The paper provides a novel and efficient algorithm for geodesically convex optimization on Riemannian manifolds, which improves the convergence rate of existing methods.
* The paper provides a thorough and detailed analysis of the convergence properties of the proposed algorithm.
* The authors provide a specific iterative scheme for matrix Karcher mean problems, which is an important application of geodesically convex optimization.
Arguments against acceptance:
* The paper assumes that the geodesically convex function is smooth and strongly convex, which may not be the case in all applications.
* The paper does not provide a comparison with other existing methods for geodesically convex optimization.
* The experimental results are limited to a specific application and do not provide a comprehensive evaluation of the proposed algorithm.
Overall, I recommend accepting the paper, as it provides a novel and efficient algorithm for geodesically convex optimization on Riemannian manifolds, and the authors provide a thorough and detailed analysis of the convergence properties of the proposed algorithm. However, the authors should be encouraged to address the weaknesses of the paper, such as providing a comparison with other existing methods and evaluating the proposed algorithm on a wider range of applications.