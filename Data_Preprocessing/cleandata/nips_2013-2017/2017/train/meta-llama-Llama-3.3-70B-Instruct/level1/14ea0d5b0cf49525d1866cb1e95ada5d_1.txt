This paper proposes a novel approach to multi-class classification problems with a large number of classes. The authors introduce a double sampling strategy on top of a multi-class to binary reduction strategy, which transforms the original multi-class problem into a binary classification problem over pairs of examples. The sampling strategy aims to overcome the curse of long-tailed class distributions and reduce the number of pairs of examples in the expanded data.
The paper is well-written, and the authors provide a clear and concise introduction to the problem and their proposed solution. The related work section is thorough, and the authors provide a good overview of existing approaches to multi-class classification. The proposed approach is well-motivated, and the authors provide a detailed description of their method, including the double sampling strategy and the binary reduction technique.
The theoretical analysis of the proposed approach is sound, and the authors provide generalization error bounds that suggest the empirical risk minimization principle over the transformation of the sampled training set remains consistent. The experimental evaluation is thorough, and the authors compare their approach to several state-of-the-art methods on popular datasets.
The strengths of the paper include:
* The proposed approach is novel and well-motivated, and the authors provide a clear and concise description of their method.
* The theoretical analysis is sound, and the authors provide generalization error bounds that suggest the empirical risk minimization principle over the transformation of the sampled training set remains consistent.
* The experimental evaluation is thorough, and the authors compare their approach to several state-of-the-art methods on popular datasets.
The weaknesses of the paper include:
* The paper assumes that the classes are mutually exclusive, which may not always be the case in real-world applications.
* The authors do not provide a detailed analysis of the computational complexity of their approach, which may be important for large-scale applications.
* The paper could benefit from a more detailed discussion of the hyperparameters and their tuning, as well as a more thorough analysis of the sensitivity of the approach to different hyperparameter settings.
Overall, the paper is well-written, and the proposed approach is novel and well-motivated. The theoretical analysis is sound, and the experimental evaluation is thorough. However, the paper could benefit from a more detailed analysis of the computational complexity and the sensitivity of the approach to different hyperparameter settings.
Arguments pro acceptance:
* The proposed approach is novel and well-motivated, and the authors provide a clear and concise description of their method.
* The theoretical analysis is sound, and the authors provide generalization error bounds that suggest the empirical risk minimization principle over the transformation of the sampled training set remains consistent.
* The experimental evaluation is thorough, and the authors compare their approach to several state-of-the-art methods on popular datasets.
Arguments con acceptance:
* The paper assumes that the classes are mutually exclusive, which may not always be the case in real-world applications.
* The authors do not provide a detailed analysis of the computational complexity of their approach, which may be important for large-scale applications.
* The paper could benefit from a more detailed discussion of the hyperparameters and their tuning, as well as a more thorough analysis of the sensitivity of the approach to different hyperparameter settings.
Quality: 8/10
Clarity: 9/10
Originality: 8/10
Significance: 8/10
Overall, I would recommend accepting this paper, but with some revisions to address the weaknesses mentioned above.