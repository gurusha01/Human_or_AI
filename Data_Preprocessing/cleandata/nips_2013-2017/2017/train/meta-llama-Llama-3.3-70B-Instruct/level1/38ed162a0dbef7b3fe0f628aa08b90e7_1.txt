This paper presents a theoretical study of deep signal representations that are near-invariant to groups of transformations and stable to the action of diffeomorphisms. The authors generalize the multilayer kernel introduced in the context of convolutional kernel networks and study the geometry of the corresponding reproducing kernel Hilbert space. They show that the signal representation is stable and that models from this functional space, such as a large class of convolutional neural networks, may enjoy the same stability.
The paper is well-written and provides a clear overview of the main ideas and contributions. The authors relate their work to previous research in the field, including the scattering transform and convolutional neural networks. The technical content is sound, and the proofs are relegated to the appendix, making the paper easy to follow.
The strengths of the paper include:
* A clear and concise introduction to the problem and the main contributions
* A thorough review of related work, including the scattering transform and convolutional neural networks
* A sound and well-organized technical presentation
* A clear explanation of the implications of the results for convolutional neural networks
The weaknesses of the paper include:
* The paper assumes a high level of mathematical background, which may make it difficult for some readers to follow
* Some of the notation and terminology may be unfamiliar to readers without a strong background in functional analysis and signal processing
* The paper could benefit from more concrete examples and illustrations to help readers understand the practical implications of the results
Overall, the paper is well-written and provides a significant contribution to the field of signal processing and machine learning. The results have important implications for the design and analysis of convolutional neural networks, and the paper provides a clear and concise overview of the main ideas and contributions.
Arguments pro acceptance:
* The paper presents a significant contribution to the field of signal processing and machine learning
* The results have important implications for the design and analysis of convolutional neural networks
* The paper is well-written and provides a clear overview of the main ideas and contributions
Arguments con acceptance:
* The paper assumes a high level of mathematical background, which may make it difficult for some readers to follow
* The paper could benefit from more concrete examples and illustrations to help readers understand the practical implications of the results
Quality: 8/10
Clarity: 8/10
Originality: 9/10
Significance: 9/10
Overall, I would recommend accepting the paper, as it presents a significant contribution to the field and has important implications for the design and analysis of convolutional neural networks. However, the authors could benefit from revising the paper to make it more accessible to a broader audience and providing more concrete examples and illustrations to help readers understand the practical implications of the results.