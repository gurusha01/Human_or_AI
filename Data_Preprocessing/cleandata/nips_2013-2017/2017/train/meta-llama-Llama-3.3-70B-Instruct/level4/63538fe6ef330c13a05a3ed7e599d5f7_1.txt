Here is a paraphrased version of the review:
Summary
The authors address constrained convex optimization problems with conic constraints defined by a bounded set of atoms. They propose a linear oracle-based method, building upon the Frank-Wolfe algorithm and Matching Pursuit techniques. The main algorithm, Non-Negative Matching Pursuit, is presented along with several active set variants. The paper provides convergence analysis for all algorithms under various scenarios, yielding sublinear convergence rates for general objectives and linear rates for strongly convex objectives. The linear rates involve a new geometric quantity, the cone width. The authors demonstrate the algorithm's relevance on several machine learning tasks and datasets.
Main Comments
Unfortunately, I did not have the opportunity to review the affine-invariant algorithms and analyses presented in the appendix. While the paper contains interesting and novel ideas for linear oracle-based optimization methods, the technical presentation has some weaknesses. Specifically, Theorem 2's presentation is problematic and does not provide a meaningful convergence guarantee. The linear convergence rates rely on Theorem 8, which is buried in the appendix and has a proof that lacks clarity. Additionally, the lower bounds on the number of good steps for each algorithm are not rigorously proven, relying on arguments that are not fully convincing. The numerical experiments are numerous and convincing, but I believe the authors should provide empirical evidence demonstrating that the computational costs are comparable to those of competing methods.
Details on Main Comments
Theorem 2
The presentation and statement of Theorem 2, as well as the sublinear rates throughout the paper, have a problematic form. The theorem is stated for a fixed horizon T, with a bound rho on the iterates x0 to xT. However, the proof only holds for 0 < t <= T, and the numerator of the bound contains rho^2, which may increase with T. To fix this, the authors could provide a priori conditions, such as coercivity, to ensure the sequence of iterates remains in a compact set, allowing for a horizon-independent bound. I also found the sentence "The reason being that f is convex, therefore, for t > 0 we have f(x_t) <= f(0)" unclear.
Lemma 7 and Theorem 8
I struggled to understand Lemma 7, which lacks explanatory comments. The equation is presented without context, making it difficult to comprehend its meaning or purpose. Additionally, Lemma 7 only considers g-faces that are polytopes, but it is unclear if this is always the case or if K can be a non-polytope. Theorem 8's presentation is also problematic, with inconsistent notation and unclear assumptions. The proof of Theorem 8 references Lemma 7, but the notation is not properly used, and the variable e is not fixed. The sentence "As x is not optimal by convexity, we have that <r, e> > 0" assumes x is not optimal without clear justification. The projection of r onto the faces of cone(A) containing x is also unclear, and I suspect the resulting r could be null, rendering the subsequent equation meaningless.
Further Comments
On line 220, "max" should be replaced with "argmax." I found the non-negative matrix factorization experiment unclear, particularly regarding the number of steps the algorithm was run for.