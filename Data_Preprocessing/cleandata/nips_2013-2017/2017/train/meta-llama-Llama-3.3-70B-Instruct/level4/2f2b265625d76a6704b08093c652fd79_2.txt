I appreciate the opportunity to review this paper, which presents an intriguing information geometric (IG) perspective on the f-GAN algorithm.
The authors propose that f-GAN converges in parameter space by leveraging the 1-1 mapping between f-divergence and chi-divergence, as well as a Bregman divergence result. They also discuss a suitable implementation of f-GAN and provide a factorization result for the deep neural network representation, highlighting the 1-1 mapping between the choice of activation functions and the chi (or f) function. Although I did not thoroughly examine every detail in the appendix, the proofs appear to be correct, with the exception of Theorem 8, which I did not have time to review prior to submission.
In my opinion, this paper is highly dense and contains numerous novel results that could be of significant interest to the machine learning and information theory communities. I am particularly impressed by the exposition of Theorem 4, which effectively conveys the IG aspect of f-GAN. Therefore, I believe this paper is a clear accept.
However, I also think that this paper may be challenging for readers without a strong background in the connections between information theory (IT) and information geometry (IG), particularly those familiar with the simplest mappings, such as the KL divergence for an exponential family to Bregman divergence, and Fenchel duality. Many deep learning engineers, who are the primary audience for a GAN paper, may fall into this category. To improve the paper's clarity, I suggest the following:
1. Consider relocating Figure 1 from the appendix to the main text, as it effectively illustrates the connections between IT and IG in the context of f-GAN.
2. It would be beneficial to provide a clear statement at the beginning of the paper explaining why considering the IG view is helpful. My understanding is that the geometry in the parameter space can be used to discuss the behavior of optimization, which is briefly mentioned on page 7, but could be introduced earlier.
3. I am unsure how Section 5 relates to f-GAN, as it appears to use the deformed exponential family to explain the distribution that a deep neural network can represent, rather than being a consequence of f-GAN optimization results. Although I agree that v, f, and chi have a 1-1 correspondence, it is not clear how this result can be used to design the f-GAN game, such as selecting an f-divergence or determining which f-GAN objective works best for a given activation function.
4. I do not understand why phi_l can be viewed as "deep sufficient statistics" in Theorem 6, as equation (13) does not appear to be in the form of a deformed exponential family.
5. It might be helpful to relocate lines 257-269 to a different section, and consider removing the utility theory paragraph, as it seems unrelated to the IG view, to free up space to explain the main results.
6. I feel that the experiments are not directly related to the main points claimed in the paper. For example, the results from Section 5 could be used to discuss point (A) without requiring the IG view of f-GAN. Similarly, point (B) only requires an understanding of Section 4, which is not closely related to the IG view of f-GAN. The inclusion of WGAN results may be distracting and confusing, as this paper primarily focuses on f-GANs.
In summary, while this paper presents many useful results and dense derivations, I believe that the material could be organized in a clearer and more coherent manner. The paper appears to be a compilation of results from multiple papers condensed into an 8-page NIPS submission. Although I support acceptance, I think that editing is necessary to make the claims clearer and more concise.