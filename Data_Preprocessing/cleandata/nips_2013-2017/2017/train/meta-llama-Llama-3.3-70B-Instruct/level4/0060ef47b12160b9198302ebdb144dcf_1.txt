The paper presents a neural network-based approach for learning saliency masks, capable of processing multiple images per second, thus demonstrating a notable level of efficiency. In my assessment, the paper falls into a borderline category, where neither acceptance nor rejection would be objectionable. The concept of learning to explain a model resonates, and the paper contributes some valuable ideas to this endeavor.
Upon examination, no glaring errors are evident, but several limitations are apparent. Notably, saliency measurement is indirect, relying on either weakly supervised localization or a proposed saliency metric, both of which have inherent limitations that warrant discussion within the paper.
Weakly supervised localization, as a measure, is imperfect. When an object's context is crucial for class determination, object localization may not correlate with saliency quality. Although the results from weakly supervised localization are intriguing, they should be viewed with caution as a quality metric for saliency due to potential caveats.
The proposed saliency metric also has its drawbacks, primarily stemming from its application method. The process of cropping the estimated salient region and then rescaling it to the original image size, while maintaining the aspect ratio, can introduce artifacts. Firstly, changes in the aspect ratio could affect classification performance. Secondly, the metric's preference for smaller salient regions, which are significantly enlarged for re-classification, might not present the object to the classifier at an optimal scale. Given that convolutional neural networks (CNNs) are generally translation-invariant but require learning for scale invariance, there are likely limits to this adaptability.
An aspect not explored in the paper is the degree to which the masking model's performance depends on the architecture used for learning the masks. It would be beneficial to know if the authors experimented with different architectures and how these influenced the outcomes.
Minor points to consider include specifying whether the results in Table 1 pertain to all classes or only the correct class, and detailing the specific LRP variant and parameter setting used for comparison, given the existence of multiple variants (e.g., epsilon, alpha-beta) with adjustable parameters.
Following the rebuttal, it becomes clear that the efficacy of the saliency metric is heavily contingent upon the classifier's quality and scale invariance, significantly limiting the method's applicability. This means the approach can only be applied to networks that exhibit such invariance, restricting its use to specific scenarios. Key implications include the inability to use the method with models during the training phase or with those lacking scale invariance, limiting its applicability across different domains (such as spectrogram analysis with CNNs), and contradicting the claim of general applicability to black-box classifiers as stated in the title.
Moreover, the response suggests a strong dependence on the masking network, raising questions about whether the saliency of the U-network or the masking network is being visualized. If these limitations and dependencies are thoroughly discussed in the paper, it could be considered balanced enough for publication. Otherwise, publication would not be recommended.