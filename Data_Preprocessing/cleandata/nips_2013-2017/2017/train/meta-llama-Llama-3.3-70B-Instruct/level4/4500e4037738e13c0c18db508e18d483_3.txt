The manuscript addresses the crucial, yet relatively underinvestigated, topic of error detection and targeted correction in connectomics, where the development of such methods is essential for optimizing the use of human proofreading time. The authors astutely observe that detecting segmentation errors is significantly easier for humans than correcting them and propose an automated solution.
The authors suggest designing an error detection module using a multi-scale 3D CNN, which takes a binary object mask as input and predicts its accuracy relative to the ground truth segmentation. During inference, the network is applied to overlapping windows on a grid to identify and localize segmentation errors.
Additionally, the paper proposes an error correction module, utilizing a 3D CNN to reconstruct the object containing the central pixel, similar to flood-filling networks (FFNs). Instead of predicting a binary mask, the authors propose predicting a k-dimensional vector for each output point, such that voxels within the same object have similar vectors and different objects have distinct vectors. This vector field is then converted into a binary mask using an exponential transform. However, it would be beneficial for the authors to provide more context on the choice of this specific transform and whether alternative forms were considered. Furthermore, details on the value of k used in experiments and any supporting data demonstrating the improvement of this approach over direct binary encoding would be valuable.
A notable omission in the paper is the specification of the losses used to train the network, particularly for the error correction module, where the k-dimensional vectors are arbitrary and cannot be fully defined by the training data.
In Section 5, a more detailed explanation of the confidence threshold is necessary, including how it was computed and the threshold value used. The termination condition, defined as an error-free state predicted by the error detector or two corrections per iteration, warrants further explanation. It is also unclear whether applying the network more than two times would yield a better segmentation and whether such a process would converge to a stable segmentation state.
Clarification is needed on whether the error corrector addresses both split and merge errors or only split errors. If merge errors are handled, it should be specified how they are managed at the supervoxel graph level and within supervoxels.
In Section 6.3, the parameters of the Adam optimizer should be explicitly stated.
The paper provides a comprehensive analysis of the system's performance, and the authors are commended for calculating per-object VI scores to enhance the interpretability of the metrics.
Several technical aspects of the manuscript require attention:
- Figure 1 is challenging to understand, with unclear node representations. The caption references horizontal layers, but the data flow appears to be vertical.
- The statement on Line 48 that the "overhead of agglomeration prohibits the use of deep learning" is misleading, as deep learning has been applied to agglomeration, as seen in recent studies.
- In Appendix A, Table 4, the non-consecutive layer IDs are puzzling, and if intentional, their meaning should be explained.