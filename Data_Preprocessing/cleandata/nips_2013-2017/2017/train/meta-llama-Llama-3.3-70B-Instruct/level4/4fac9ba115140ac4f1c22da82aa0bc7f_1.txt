1. Summary of paper
This manuscript presents a novel approach to learning gradient boosted regression tree ensembles, where the technique is sensitive to both feature costs and the cost of evaluating splits within the tree. The work bears similarities to the research conducted by Xu et al. in 2012, with key distinctions including input-specific feature and evaluation costs, an evaluation cost that varies with the number of tree splits, a unique optimization strategy based on the Taylor expansion around T_{k-1} as outlined in the XGBoost paper, and the utilization of best-first growth to expand trees up to a maximum number of splits rather than a predefined depth. The authors demonstrate the efficacy of their setup in scenarios where either feature cost or evaluation cost dominates, supporting their claims with experimental results.
2. High-level subjective evaluation
The paper is well-structured and clearly written, despite introducing a substantial amount of notation that may require close attention from the reader. The contribution, however, seems somewhat incremental given the foundational work of XGBoost and GreedyMiser. The experimental section is comprehensive, comparing the proposed method with existing work and examining the impact of model parameters on performance. One potential area for further exploration, which could necessitate an additional experiment, is highlighted below. The model could hold particular interest for practitioners working in time-constrained classification settings.
3. High-level technical evaluation
A point of ambiguity arises in the interpretation of Figures 2a and 2b, specifically how the cost is measured for each method to generate the Precision versus Cost curves. It appears that for CEGB, costs are measured on a per-input and per-split basis, whereas other methods assess costs per tree. This discrepancy could introduce unfair comparisons. To ensure a fair evaluation, it would be beneficial to standardize the cost measurement across all methods, even if it deviates from the original measurement approaches in their respective papers. The removal of Figure 1 and its replacement with a detailed comparison of trees generated by CEGB, GreedyMiser, and BudgetPrune for the Yahoo! Learning to Rank dataset could provide valuable insights into the performance differences. Moreover, explicitly outlining the innovations over GreedyMiser that lead to CEGB, potentially through a step-by-step notation comparison and a figure illustrating the improvement in the Precision vs. Cost curve with each innovation, would strengthen the paper. The distinction between evaluation and feature costs, particularly in the context of GreedyMiser and BudgetPrune's applicability, requires further clarification.
4. Low-level technical evaluation
Several technical aspects warrant closer examination: 
- The rationale behind the placement of \lambda solely in front of the first cost term in equation 7 needs clarification.
- Equation 12 seems to omit a term with \lambda in the denominators of the first three terms, similar to the formulation in the XGBoost paper.
- The term 'levels' in Figure 4b lacks a clear definition.
- Redefining \beta_m at Line 205 and \alpha at Line 213 would enhance readability, as these definitions may not be immediately recalled by readers.
5. Summary of review
While the paper proposes a novel method for cost-efficient learning that reportedly outperforms state-of-the-art approaches and operates in previously unsuitable settings, uncertainties regarding the measurement of cost and the classification of certain costs as evaluation rather than feature costs temper the assessment. Until these ambiguities are addressed, the paper falls slightly below the acceptance threshold for NIPS.