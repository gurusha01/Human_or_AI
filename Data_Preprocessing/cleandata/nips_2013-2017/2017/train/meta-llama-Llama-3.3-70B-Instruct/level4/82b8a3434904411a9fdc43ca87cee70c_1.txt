This paper addresses the issue of variance reduction in scenarios where individual examples may be subject to random perturbations, such as image rotations, scaling, or noise addition. The proposed algorithm builds upon the MISO/Finito framework, utilizing a surrogate function for each perturbed example that represents a moving average of quadratic lower bounds. However, due to the introduction of permutations, these lower bounds are approximate, as they are specific to the current permutation instance rather than the expected value across all permutations. The authors demonstrate that their algorithm's convergence rate differs from SGD in that it depends solely on the variance attributed to permutations (σρ) at the optimum, rather than the overall variance, which also encompasses the variance resulting from example sampling. The paper concludes with a compelling series of experimental results.
Although the algorithm may appear somewhat incremental, the problem setting is significant, the approach is intuitive, and the findings are comprehensive, providing both robust theoretical and experimental validation.
One criticism concerns the visual presentation: the legend font sizes are excessively small, the yellow curve is overly bright and lacks sufficient contrast with the white background, and the curves are distinguished solely by color, rather than by symbols or dashes, making them difficult or impossible to discern in black and white.