This paper proposes a double sampling strategy to enhance the multiclass classification approach outlined in [16], providing both theoretical and empirical analyses of the methodology. Experimental results on a text dataset demonstrate the effectiveness of the proposed approach in handling multiclass classification problems with a large number of classes.
Strengths:
- The authors undertake thorough experimental comparisons with multiple baseline methods, yielding results that showcase the proposed approach's high performance and shorter training times across several datasets.
- The investigation of extreme classification problems represents a crucial research direction with numerous practical applications.
Weaknesses:
- The paper builds heavily upon [16], with the primary innovations being the introduction of a double sampling strategy and new generalization bounds based on local Rademacher complexities. However, the overall novelty of the work is somewhat limited.
- Although the proposed approach reduces training time, it still incurs lengthy prediction times compared to other methods. In practical scenarios, prediction time is often a more critical consideration.
Suggestions:
- Clarification is needed on the interpretation of the generalization bound presented in the paper, including a comparison with existing approaches to contextualize its significance.
- The experimental comparison involves both batch and online learning algorithms, which have vastly different memory requirements. This disparity should be acknowledged and considered in the evaluation of the proposed method's efficiency.