The authors present a dataset model that solves a convex problem, incorporating constraints to limit discrimination with respect to a chosen sensitive attribute. These constraints enforce statistical parity in both the joint distribution, consistent with existing literature, and introduce additional constraints that quadratically limit discriminatory effects per value of the protected attribute. Furthermore, individual point-wise discrimination is restricted while maintaining a distribution close to the original data, enabling the model to mitigate discrimination in training data and transform unseen test data effectively.
The theoretical foundations of the claims are sound, and notably, the framework allows for the incorporation of various distance and similarity measures into the constraints. Experimental results on representative datasets demonstrate the method's success in avoiding discrimination, outperforming alternative approaches in the literature. The extensive supplementary material provides proofs supporting the theoretical claims, accompanied by insightful discussions on the datasets used, including the recently released COMPASS dataset, and comparisons with the resulting datasets from their algorithm.
A notable positive aspect is the introduction of a bound on the utility of their method when dataset probabilities are estimated using the maximum likelihood estimate, a common scenario. Although the tightness of the bound depends on well-behaved distributions, this contribution is significant. The authors also carefully position their proposal within the existing landscape of discrimination-aware machine learning and data mining, providing a comprehensive overview of relevant literature.
Overall, this work is commendable, but there are areas for improvement. Firstly, the choice of distribution similarity measure (Eq. 3) lacks motivation, potentially leading to uneven penalization of differences when the target distribution is low. Secondly, the experimentally used distance measures are not thoroughly explained, such as the use of a 10^4 penalization in the COMPASS dataset for more than one category jump. Thirdly, the experimental results on the Adult dataset fall behind the LFR method of Zemer. Additionally, the experimental section could benefit from more case studies to demonstrate a broader trend, such as including the German credit and Heritage Health Prize datasets. Lastly, while the framework's generality is valued, solving it requires a general convex solver, making it challenging to provide generalizable timings for the proposed optimization problem. Reporting timing measurements for the provided experiments would enhance the submission's completeness.
Although the proofs in the supplementary material have not been thoroughly verified, the claims are reasonable, novel, and well-motivated, contributing to the unification of advances in the area. The reviewer is confident that this submission significantly extends the field of discrimination-aware machine learning and believes that its publication would greatly benefit the community.