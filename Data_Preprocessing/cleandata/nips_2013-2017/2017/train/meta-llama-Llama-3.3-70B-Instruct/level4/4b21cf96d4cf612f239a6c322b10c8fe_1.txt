This paper explores the application of deep generative models to image-conditioned caption generation, proposing an approach that enhances the representation by incorporating an additional data-dependent latent variable. By formulating the problem within the variational auto-encoder (VAE) framework and maximizing the variational lower bound as the training objective, the authors introduce a data-dependent additive Gaussian prior to address the limited representation power of VAEs in caption generation. The empirical results indicate that the proposed method can generate more diverse and accurate sentences compared to a pure LSTM baseline.
== Qualitative Assessment ==
The motivation behind adding a stochastic latent variable to the caption generation framework is commendable. Although augmenting the prior of VAE is not a novel contribution, its application to the caption generation task demonstrates some novelty. In terms of performance, the proposed AG-CVAE achieves more accurate results than both the LSTM baseline and other CVAE baselines, as shown in Table 2. The paper also provides an analysis of the diversity of the generated captions in comparison to the pure LSTM-based approach, as illustrated in Figure 5. Overall, the paper is well-written, with sufficient experimental details.
However, considering the additive Gaussian prior as the primary contribution, the current version of the paper does not entirely convince me. I would be willing to reconsider my score if the authors can address my concerns in their rebuttal.
* Is there any strong evidence demonstrating the advantages of AG-CVAE over CVAE/GMM-CVAE? The improvements shown in Table 2 are not substantial. For qualitative results, such as Figure 5 and other figures in the supplementary materials, side-by-side comparisons between AG-CVAE and CVAE/GMM-CVAE are lacking. It is unclear whether AG-CVAE truly adds more representation power compared to CVAE/GMM-CVAE. I would appreciate it if the authors could comment on this in their rebuttal and include such comparisons in the final version of the paper or supplementary materials.
* Regarding diversity evaluation, it is unclear why AG-CVAE performs worse than CVAE. Additionally, there is no explanation for the performance gap between different variations of AG-CVAE. Given that CVAE is a stochastic generative model, I wonder if evaluating the top 10 sentences is sufficient for diversity assessments. The results would be more convincing if the authors provided a curve illustrating the diversity measure against the number of sentences, with the diversity measure on the y-axis and the number of sentences on the x-axis.
Additional comments:
* The pre-defined means of clusters for GMM-CVAE and AG-CVAE (Line 183) are noteworthy. It is not surprising that the authors did not achieve better results when the means of clusters uk are free variables, as it is possible to learn duplicate representations without constraints on uk or c_k. I encourage the authors to explore this direction further in the future, as learnable data-dependent priors may potentially boost performance.