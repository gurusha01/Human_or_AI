This paper presents a unified framework for interpreting model predictions on individual inputs, focusing on additive feature importance measures. Notably, the authors identify a unique solution that fulfills a specific set of desirable properties, and propose efficient approximation methods for SHAP values.
The topic addressed is of significant interest and has garnered substantial attention in recent years. The manuscript is well-structured and enjoyable to read. The proposed properties for desirable methods are logical, although the local accuracy criterion appears overly restrictive. The utilization of Shapley values and their associated theoretical properties is a novel contribution. A key validation check is that when the original model is inherently interpretable, such as when features are binary, the method should ideally return the original model. However, Corollary 1 suggests this may not hold, as E[x_j] is non-zero, warranting further clarification from the authors. Additionally, providing more detailed information on the computational cost, specifically the time complexity of DeepSHAP, would be beneficial in setting practical expectations for its application.