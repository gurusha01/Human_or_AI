This paper proposes a novel implicit variational inference approach for likelihood-free inference, drawing on existing methodologies such as Hierarchical Variational Inference and Implicit Variational Bayes. The core innovation lies in the subtraction of the log empirical distribution log q(xn) and the transformation of the Evidence Lower Bound (ELBO) as expressed in equation 4, which implies the utility of log density ratio estimation for likelihood-free variational inference. The method's technical details rely on conventional techniques, including log density ratio estimation, reparametrization, and hierarchical variational distributions.
Although the strategy for addressing likelihood intractability is intriguing, it necessitates log density ratio estimation in high-dimensional spaces, specifically the joint space of data xn and latent variable zn. This poses significant challenges, as high-dimensional log density ratio estimation is notoriously difficult, and the authors do not provide clear evidence of a stable algorithm to overcome this issue. Notably, the authors' decision to apply their method to a bespoke Bayesian GAN for classification, rather than a standard GAN for generating high-dimensional data like images, raises concerns about the algorithm's stability. Indeed, stabilizing the proposed algorithm appears to be problematic, given that the initial "variational joint" will likely differ substantially from the "real joint", rendering log density ratio estimation unreliable and leading to biased gradients in the critical early iterations of optimization.