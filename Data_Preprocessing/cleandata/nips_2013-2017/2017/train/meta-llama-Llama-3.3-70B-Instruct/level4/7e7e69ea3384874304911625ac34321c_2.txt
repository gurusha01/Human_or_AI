This paper proposes an auto-encoder architecture that utilizes a pixelCNN decoder and adversarial cost on the latent space, positioned between a uniform prior and inference distribution. When properly designed, the network effectively disentangles global input information, stored in the latent space, from local information captured by the pixelCNN, as demonstrated on the MNIST dataset. Notably, the model learns to extract class information in an unsupervised manner, achieving impressive results, particularly in semi-supervised settings. Although the paper presents another iteration of combining VAE, Adversarial Networks, and pixelCNN, it offers a compelling set of experiments and discussions. The model bears a strong resemblance to the VAE-pixelCNN combination, where the VAE loss (KL) on latents is replaced by an adversarial loss, and a comparative analysis with this baseline, including experiments on scaling the latent loss, would be beneficial.
Further examination reveals several key points:
- Figure 2c would benefit from the inclusion of a VAE-pixelCNN combination using the same networks but with varying scales of the KL term, providing a more direct comparison.
- The statement on Line 98 oversimplifies the network's behavior, as the distribution of information between latents and the input depends on function approximations, with the network capable of placing information in either, though the noisy and approximate nature of latents presents a challenge.
- It remains unclear whether the model achieves clear unsupervised separation, as seen in Figure 6 for MNIST, when applied to datasets like SVHN and NORB, warranting further investigation.