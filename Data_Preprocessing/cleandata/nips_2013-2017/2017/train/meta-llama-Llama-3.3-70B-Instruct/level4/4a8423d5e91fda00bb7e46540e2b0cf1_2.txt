This paper addresses the problem of selective classification, where a classifier must decide whether to classify a data example or abstain due to low confidence in its prediction. Unlike previous methods that assign a cost to abstaining, this work proposes a post-hoc approach that thresholds the classifier's confidence to guarantee a certain error rate with high probability. The key contribution is the introduction of the SGR algorithm and its associated theory, which relies on an ideal confidence function. Since this function is not available in practice, the authors evaluate two alternative methods, SR and MC-dropout, and report promising results with low test error and reasonably high coverage.
A notable aspect of this paper is its technical novelty, particularly in the development of the SGR algorithm. However, some technical details, such as the solution to Equation (4), could be clarified; it appears to involve a simple line search, but explicit confirmation would be helpful. Additionally, the computational complexity of the procedure seems to be O(m log m), but this should be explicitly stated.
The comparison of SR and MC-dropout methods yields interesting results, with MC-dropout performing worse on Imagenet. The authors may want to provide insight into this discrepancy and consider visualizing the confidence functions for a given model to better understand the differences. It is suggested that both methods could be tested and the better-performing one selected for practical applications.
The evaluation methodology raises some concerns, particularly regarding the use of validation sets for CIFAR-10 and CIFAR-100. Since there is no explicit validation set, it is unclear whether the test set was split or the last batch of the training set was used for Sm. A more rigorous approach would involve using a portion of the training set as validation and evaluating on the full test set. Similarly, the evaluation procedure for Imagenet could be clarified, as it appears that the validation set was split in half.
A minor typo is noted in section 5.3, referring to "mageNet" instead of "ImageNet".
One weakness of the empirical results is the lack of comparison with other approaches, such as those that assign a small cost for abstaining. This cost could be tuned to achieve a desired coverage or error rate, and it is unclear whether the post-hoc approach is superior. Although the proposed method may be less expensive overall, a direct comparison would strengthen the paper's conclusions.
Overall, this paper presents a practical and interesting idea that opens up new avenues for future research. The concept of selective classification is well-motivated, and the proposed SGR algorithm shows promise. With some clarifications and additional comparisons, this work has the potential to make a significant contribution to the field.