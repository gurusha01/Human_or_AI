This paper presents an examination of the convergence of maximum likelihood estimates in relation to sample complexities for both generative and discriminative models, a topic that I find intriguing. The manuscript is well-structured and clearly written, although there are opportunities for enhancement in terms of explanatory clarity.
The authors' key finding is that under specific sparsity conditions, particularly when the sample size is limited and the data dimensionality is high, generative models can surpass discriminative methods in performance. They claim that their theoretical analysis is novel and has the potential to significantly impact the resolution of real-world problems over time. To illustrate their points, the authors use logistic regression as a representative discriminative model and Gaussian and Gaussian Graphical models as examples of generative models. Notably, they have managed to present complex theoretical concepts in a manner that remains engaging for a broad audience in machine learning, which is a commendable achievement for a theoretical paper.
I have several recommendations for further improvement:
(1) Consider including a visual aid, such as a figure, to elucidate the concept of separability as defined in Definition 1, to enhance reader understanding.
(2) The reasoning preceding Corollary 5, specifically the comparison between Corollary 3 and 4, was not entirely clear to me and could benefit from additional explanation or clarification.
(3) There are a few instances of notation errors that should be corrected to maintain the precision and consistency of the manuscript.
Additionally, it might be worthwhile to consider expanding the paper with more comprehensive simulations and subsequently making the extended version available on platforms like ArXiv, which could further enrich the contribution of this work.