The authors propose a innovative approach to learning ensembles of deep decision or regression trees, balancing prediction accuracy and feature cost. The developed predictive system is adaptive, as it selectively acquires and evaluates different feature sets for various inputs, thereby minimizing cost while preserving accuracy.
The methodology employed is an iterative process that builds upon gradient tree boosting by incorporating a cost-sensitive objective function. This algorithm incrementally adds decision trees to the ensemble, with each new tree trained to optimize the overall ensemble cost. To facilitate individual tree learning under existing ensemble cost constraints, the authors introduce a cost-aware impurity measure.
Empirical evaluations demonstrate the superiority of the proposed algorithm over existing cost-aware ensemble learning methods on multiple real-world datasets. Overall, the paper is well-structured, the algorithmic derivations are noteworthy and original, and the addressed problem has significant implications for numerous fields, making it a valuable contribution.