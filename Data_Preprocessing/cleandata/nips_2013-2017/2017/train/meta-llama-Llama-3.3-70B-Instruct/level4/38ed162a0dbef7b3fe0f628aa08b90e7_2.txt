The paper primarily focuses on Convolutional Kernel Networks (CKNs) [13, 14], analyzing the stability of the representation formed by CKNs with respect to C^1 diffeomorphisms, such as translation, as defined in Eq. (4). The authors demonstrate that stability holds for norm-preserving and non-expansive kernels [(A1-A2) in line 193] when using appropriately chosen patch sizes [(A3)]. Additionally, the manuscript outlines an extension of the concept from (R^d,+) to locally compact groups in Section 4.
The organization and clarity of the paper are commendable, and the technical soundness is evident in its combination of ideas from deep networks and kernels, making it a valuable contribution to the field. The stability result has the potential to be of significant interest to the machine learning community.
However, the submission could benefit from a more detailed motivation for the stability analysis. Currently, the motivation is limited to a single sentence (line 56-57), which mentions the importance of Lipschitz stability in deep predictive models for robustness against adversarial examples [7].
Furthermore, there are a few areas that require attention. The use of the \kappa notation in (A3) [line 193] may cause confusion due to its overlap with the function defining kernel K in Eq. (10). In the equation between lines 384 and 385, the second part ('and \forall v...') is redundant, as it is identical to the first constraint ('\forall u ...') due to the symmetry of kernel k.
Additionally, the definition of \phi is missing and should be introduced in Eq. (10) as <\phi(z),\phi(z')>_{H(K)}. In lines 427-428, the inequality under '=' appears to also hold with equality, suggesting that | ||z|| - ||z|| |^2 should be | ||z|| - ||z'|| |^2.
References [3,6,8,13,14,18,25-27,30,31] lack page information, while references [9], [17], and [19] have been updated with the correct publication details. Reference [32] has been accepted and is available at https://2017.icml.cc/Conferences/2017/Schedule?type=Poster.