This paper extends prior research on ell-infinity recovery in high-dimensional models, broadening the scope from linear regression to general loss functions. While earlier results are limited to linear settings, the authors' contribution lies in generalizing these findings. Although a thorough examination of the proofs was not feasible within the given timeframe, they appear to be correct. However, the writing could be improved, as some sections seem disjointed, and the authors should prioritize refining the presentation.
To enhance the paper, several aspects warrant attention. Firstly, a more in-depth discussion on the proposed connections to incoherence is necessary. Incoherence, a stronger assumption in linear settings for establishing ell-infinity bounds, prompts the question of whether analogous concepts can be developed in this generalized context.
The work of Ren et al. on asymptotic normality and optimality in estimating large Gaussian graphical models provides a valuable contrast to ell-infinity bounds and optimal rates, as well as assumptions for precision matrix recovery. Incorporating this comparison could strengthen the authors' arguments.
Furthermore, the text following Corollary 3 lacks clarity. For instance, under isotropic Gaussian design, the relationship between ell-infinity control for classification and the identification of support with minimal samples (n > log p) is not clearly linked to generative versus discriminative models. Elucidating this connection would improve the paper's readability and comprehension.
Lastly, statements suggesting that one method requires more samples than another (such as on line 218) should be phrased more cautiously, as they are not supported by lower bounds. Softening these remarks would enhance the paper's accuracy and credibility.