This manuscript integrates multiple approaches from large-scale optimization, including smoothing, acceleration, homotopy, and non-uniform sampling, to address a problem involving three convex functions and a linear operator, represented as f(x) + g(x) + h(Ax), where f is characterized by its smoothness. The authors employ a smoothing technique, originally developed by Nesterov [reference], to regularize the term h(Ax), followed by the application of a block-wise forward-backward splitting method. This method updates a single, randomly selected block at each iteration. Furthermore, the authors incorporate acceleration and homotopy techniques to enhance the convergence speed of the algorithm. Essentially, the proposed algorithm operates as a primal method, leveraging the proximal gradient on the smoothed function. 
The numerical experiments presented in the manuscript demonstrate the efficacy of the proposed algorithm in comparison to existing methodologies. 
Note: A reference is missing on line 165.