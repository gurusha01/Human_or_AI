Here is a paraphrased version of the review:
POST-REBUTTAL:
The authors have adequately addressed my concerns and will provide clarification on the point of confusion, leading me to revise my evaluation from a marginal accept to an accept.
OLD REVIEW:
Summary of the Paper:
This paper introduces a "safe" algorithm for contextual linear bandits, which builds upon the concept of a baseline policy for action selection. The algorithm ensures that it only deviates from the baseline policy's recommended action if the new action yields a higher expected reward, with a guarantee that holds with high probability (at least 1 - δ).
Summary of Review:
The paper is well-written and easy to follow, demonstrating a novel approach to the problem setting. The authors provide sufficient theoretical and empirical justifications to support the viability of their proposed method. However, I have several questions that require clarification, and I recommend at least a weak acceptance, with the potential for a stronger acceptance pending resolution of these points.
Questions:
1. Definition 1 outlines a desirable performance constraint, but the high-probability nature of this constraint should be explicitly stated. Notably, line 135 does not mention that equation (3) must hold with high probability, which should be clarified.
2. The statement of how equation (3) must hold is crucial, as the current wording is ambiguous. Initially, it appears that equation (3) must hold with probability 1 - δ, but this is not actually achieved by the algorithm. If I understand correctly, the algorithm ensures that equation (3) holds with high probability at each individual time step, rather than simultaneously across all time steps. This can be represented as:
∀t ∈ {1, ..., T}, Pr (∑[rb^i - ra^i] from i=1 to t ≤ α ∑[r_b^i] from i=1 to t)
Rather than:
Pr (∀t ∈ {1, ..., T}, ∑[rb^i - ra^i] from i=1 to t ≤ α ∑[r_b^i] from i=1 to t)
The current wording suggests the latter, which I believe is not satisfied by the algorithm. Please clarify which guarantee the algorithm actually provides.
3. If the algorithm only satisfies the per-time-step guarantee, the motivation for the paper may be undermined. This could be addressed by acknowledging the limitations of this approach in the introduction without altering the content.
Consider the actual guarantee provided in the empirical study, where the algorithm is run for 40,000 time steps with δ = 0.001. The algorithm is intended to guarantee that it performs at least as well as the baseline with high probability. However, the guarantee only ensures that the probability of playing a worse action is at most 0.001 at each individual time step. This means that the probability of playing a worse action at some point is at most 1 - (0.999)^40000 ≈ 1, which is not a meaningful bound. This should be discussed.
For now, I would appreciate the authors' thoughts on why a per-step high-probability guarantee is important for systems with large numbers of time steps. If a single failure is critical, then a high-probability guarantee that holds simultaneously for all time steps is necessary. If a single failure is not critical, but rather the amortized cost over thousands of time steps is what matters, then why is there a focus on achieving per-time-step high-probability guarantees?