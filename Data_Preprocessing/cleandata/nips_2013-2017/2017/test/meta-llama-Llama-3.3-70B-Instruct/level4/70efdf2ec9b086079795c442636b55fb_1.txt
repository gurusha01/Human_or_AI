This paper presents a novel approach to parameter sharing in RNNs, utilizing convolution within an LSTM cell for unstructured input sequences, where tensors serve as convolution kernels and feature maps. Additionally, the method introduces depth to the model by delaying the output target for a specified number of time steps.
The concept is intriguing and appears to be original. The authors provide a clear, albeit complex, formulation of their method and accompany it with experimental results. When applied to a real-world dataset, such as the Wikipedia language model, the approach yields performance comparable to the state-of-the-art, achieving this with roughly half the number of parameters.
However, several concerns arise with this methodology:
- The feasibility of generating meaningful high-dimensional feature maps for most problems is questionable, which raises doubts about the scalability of this approach to high-dimensional tensors, particularly given that the authors only experiment with dimensions up to 3.
- The introduction of "depth in time" through delayed output targets may not be suitable for real-time or streaming applications, such as speech processing, due to the inherent delay.
- For high-dimensional tensors, the number of hyperparameters can become excessively large, potentially complicating the model's tuning and application.
A minor correction is also noted:
- On line 242, the reference to "Fig.3" should be corrected to "Table 3" to ensure accuracy in citation.