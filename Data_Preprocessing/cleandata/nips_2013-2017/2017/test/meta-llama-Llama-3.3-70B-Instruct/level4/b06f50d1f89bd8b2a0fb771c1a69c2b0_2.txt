This manuscript presents a novel approach to multitask bandit learning, building upon the foundations established by Valko et al. (2013) in kernelised contextual bandits and Evgueniou and Pontil (2004) in regularized multitask learning. A key contribution of this work is the development of a method to estimate task similarities, a crucial aspect for real-world applications where such information is often unavailable.
The strengths of this paper include:
- The significance of the problem it addresses, which has far-reaching implications for various practical applications, such as recommendation systems;
- The mathematical analysis, which appears to be sound based on the reviewer's examination;
- The numerical simulation results, which are persuasive and support the authors' claims.
However, several limitations are noteworthy:
- The contribution, while valuable, seems incremental, and the novelty could be more effectively highlighted. For example, implementing Valko et al.'s (2013) work with multitask kernels might yield an algorithm similar to the one proposed here, raising questions about the distinctiveness of the current approach.
- The computational complexity associated with the expanding kernel matrix K_{t-1} is a concern that warrants discussion.
- The proof of the regret, specifically Theorem 4.1, references algorithms SupKMTL-UCB and BaseKMTL-UCB, which are only detailed in the supplementary material. It would be beneficial for the authors to outline these algorithms in the main text to facilitate a clearer understanding of the theorem.
In conclusion, the paper tackles an intriguing problem but is not without its drawbacks, primarily related to the incremental nature of the contribution, certain algorithmic aspects (such as the handling of the growing kernel matrix), and the presentation of key theoretical results.