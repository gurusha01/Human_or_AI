This paper introduces TrajGRU, an extension of convolutional LSTM/GRU that learns location-dependent filter support for each hidden state location, generating a flow field to warp previous hidden states. The authors evaluate TrajGRU on video generation tasks using MovingMNIST and HKO-7 datasets, where it outperforms its convolutional counterpart.
The paper is technically sound, and the proposed model is novel and original. The experiments demonstrate the effectiveness of TrajGRU in video generation tasks. However, the comparison with ConvGRU having a larger support than just a 5x5 kernel is questionable, and the computational cost of TrajGRU due to its warping operation is a concern.
The clarity of the paper can be improved by specifying the warp method and providing more details on the HKO-7 dataset. Additionally, the authors could compare TrajGRU to other approaches, such as the Spatio-temporal video autoencoder with differentiable memory, to further demonstrate its significance.
The significance of the paper lies in its proposal of a novel model that learns filter support in addition to filter weight. However, its applicability to more traditional video tasks, such as human action classification, needs to be explored. The paper's contributions are notable, and the results are promising, but further research is needed to fully understand the potential of TrajGRU.
Arguments pro acceptance:
- Novel and original model that learns location-dependent filter support
- Effective in video generation tasks
- Technically sound paper
Arguments con acceptance:
- Limited comparison with other models
- Computational cost of TrajGRU is a concern
- Clarity of the paper can be improved
- Applicability to traditional video tasks needs to be explored
Overall, the paper is well-written, and the proposed model is innovative. With some revisions to address the concerns mentioned above, the paper has the potential to be a valuable contribution to the field.