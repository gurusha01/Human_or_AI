This paper proposes a novel Pose Guided Person Generation Network (PG2) that synthesizes person images in arbitrary poses based on a reference image and a target pose. The authors employ a two-stage approach, where the first stage generates a coarse image with the target pose using a U-Net-like network, and the second stage refines the image using a conditional DCGAN. The authors also propose a pose mask loss to alleviate the influence of background changes on person image synthesis.
The paper is well-written and clearly explains the proposed method, including the network architecture and loss functions. The authors provide extensive experimental results on two person datasets, demonstrating the effectiveness of their approach in generating high-quality person images with convincing details. The results show that the proposed method outperforms other approaches, including a one-stage model and a model using a different pose embedding method.
The strengths of the paper include:
* The proposal of a novel task of conditioning image generation on a reference image and a target pose, which has many potential applications in computer vision and graphics.
* The use of a two-stage approach, which allows for the generation of high-quality images with both global structure and detailed appearance.
* The proposal of a pose mask loss, which effectively alleviates the influence of background changes on person image synthesis.
The weaknesses of the paper include:
* The lack of direct comparison with other state-of-the-art methods, as the proposed task is novel and there are no existing methods for direct comparison.
* The potential for mode collapse in the second stage of the generation process, which may lead to limited diversity in the generated images.
* The need for a large amount of training data to achieve good results, which may be a limitation for some applications.
Overall, the paper is well-written and presents a novel and effective approach to person image synthesis. The proposed method has many potential applications and is a significant contribution to the field of computer vision and graphics.
Arguments pro acceptance:
* The paper proposes a novel task and approach that has many potential applications.
* The experimental results demonstrate the effectiveness of the proposed method.
* The paper is well-written and clearly explains the proposed method.
Arguments con acceptance:
* The lack of direct comparison with other state-of-the-art methods.
* The potential for mode collapse in the second stage of the generation process.
* The need for a large amount of training data to achieve good results.
Rating: 8/10
Recommendation: Accept with minor revisions. The authors should address the weaknesses mentioned above, including providing more direct comparisons with other methods and discussing the potential limitations of the proposed approach. Additionally, the authors should consider providing more details on the implementation and training of the model, including the hyperparameters used and the computational resources required.