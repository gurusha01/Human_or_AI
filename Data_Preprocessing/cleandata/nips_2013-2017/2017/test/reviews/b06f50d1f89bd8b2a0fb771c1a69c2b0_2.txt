This paper introduces a multitask bandit learning approach. It takes after two existing contributions: Valko et al. 2013 on kernelised contextual bandits, Evgueniou and Pontil, 2004 on regularized multitask learning. The authors of the present paper provide a way to estimate the similarities between the tasks if it is not given, which is essential for real-world data.
Pros of the paper:
- the problem of learning multitask contextual bandits is of importance for many practical problems (e.g. recommendation);
- the mathematical anaylsis, as far as I have checked, is correct;
- results from numerical simulations are convincing.
Cons:
- I would point out that the paper provides an incremental contribution and/or that the novelty is not well sold. For instance, it seems a lot of the work provided here is similar to the work of Valko et al 2013. What if that work is implemented with multitask kernels ? Would the resulting algorithm be very different from that proposed in the present paper ?
- there is the question of the computational complexity induced by the growing kernel matrix K_{t-1}: something should be said here.
- there is the frustrating proof fo the regret that mentions two algorithms SupKMTL-UCB and BaseKMTL-UCB that are only given in the supplementary material: the authors should at least provide the main lines of these algorithms in the main text. Otherwise, Theorem 4.1 cannot be understood.
All in all, the paper addresses an interesting problem. However, there is some drawbacks regarding 1) the incrementality of the contribution, 2) some algorithmic points (e.g. growing kernel matrix) and 3) the presentation of Theorem 4.1.