This computational neuroscience paper proposes a bottom-up visual feature saliency model combined modified by dynamical systems modelling that aims at capturing the dynamics of scanpaths. I enjoyed reading this paper, it has a set of nice of ideas
in defining "affordances" (curiosity, brightness invariance) that drive the scan-path, as well as the idea of the Least Action Principle. These "affordances" are albeit perhaps a bit adhoc postulated and not further motivated.
In the context of the Least Action Principle and its derivation in this context it would have been interesting to related it to actual work
in eye movement research such as past and recent work by the Wolpert lab. While the lack of biological motivation is in itself alone a minor issue in the era of benchmark-busting deep learning models of (static) visual salience, the issue with this model is the mixed performance it achieves with respect to these models is poor. Given that the model claims to capture biological eye movement dynamics, it would have been intersting to see in the main paper actual figures characterising the generated scan paths, not only in terms of their overall statics at matching eye movem