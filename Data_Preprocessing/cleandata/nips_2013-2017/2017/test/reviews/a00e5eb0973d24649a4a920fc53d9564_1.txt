This papers covers some theoretical limitations on variance-reduced stochastic algorithms
for finite sum problems (SAG, SDCA, SAGA, SVRG etc.). Such algorithms have had some important
impact in machine learning & convex optimization as they have been shown to reach a linear convergence
for strongly convex problems with lipschitz gradient (log term) while having a factor in $n + \kappa$ (and not as $n\kappa$).
A first result of this paper is that the sequential iterative algorithm needs to know
which individual function has been returned by the oracle to reach the linear convergence
rate. Typically SAG or SAGA need this knowledge to update the gradient memory buffer
so it is not terribly surprising that knowing the function index is necessary.
It is then argued that such variance-reduced methods cannot be used with data augmentation
during learning. This is only true if the data augmentation is stochastic and if there is
not a finite set of augmented samples.
A second result concerns the possibility to accelerate in the "Nesterov sense" such
variance-reduced algorithm (go from $\kappa$ to $\sqrt{\kappa}}$). It is shown that
"oblivious" algorithms whose update rules are (on average) fixed for any iteration
cannot be accelerated.
A practical consequence of the first result in 3.2 is that knowing the value of the
strong convexity parameter is necessary to obtain an accelerated convergence
when the algorithm is stationary.
Such oblivious algorithms are further analysed using
restarts which are well known techniques to alleviate the non-adaptive nature of
accelerated algorithms in the presence of unknown local conditionning.
The paper is overhaul well written with some pedagogy.
Minor:
CLI is first defined in Def 2 but is used before.
Typo: L224 First, let us we describe -> First, let us describe