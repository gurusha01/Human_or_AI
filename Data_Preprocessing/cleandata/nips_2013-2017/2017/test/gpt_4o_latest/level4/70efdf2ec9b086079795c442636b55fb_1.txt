The paper introduces a novel approach to parameter sharing in RNNs by incorporating convolution operations within an LSTM cell for processing unstructured input sequences, leveraging tensors as both convolution kernels and feature maps. Additionally, the method increases model depth by delaying the output target by a specified number of steps.
The proposed idea is intriguing and appears to be original based on my assessment. The authors present a clear, albeit somewhat complex, formulation and support their claims with experimental results. On a real-world dataset (Wikipedia language modeling), the approach achieves performance comparable to the state-of-the-art while utilizing approximately half the number of parameters.
However, I have the following concerns regarding this approach:
- It is unclear whether meaningful high-dimensional feature maps can be effectively generated for most problems, raising doubts about the scalability of the method to higher-dimensional tensors (the experiments only extend to dimension 3).
- The use of "depth in time" introduces a delay, making the method unsuitable for streaming applications such as speech processing.
- For high-dimensional tensors, the number of hyperparameters could grow significantly, potentially complicating optimization.
Minor issue:
- On line 242, "Fig.3" should be corrected to "Table 3."