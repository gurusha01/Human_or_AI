This paper investigates the convergence rate of a method referred to as the min-sum splitting approach for solving the average consensus problem. Overall, the paper is written reasonably well, but the improvement in the results appears to be marginal. Specific comments are as follows:
(1) The paper states, "This rate is optimal for graphs with good expansion properties, such as the complete graph. In this case, the convergence time, i.e., the number of iterations required to reach a prescribed level of error accuracy in the… of the dimension of the problem, as…." However, for complete graphs, the linear rate is effectively 0 since all nodes converge to the average in a single step. Additionally, complete graphs are too specific to serve as representative examples. For which broader class of graphs does the complexity remain independent of the dimension (number of nodes)? What general category of graphs is considered "good"?
(2) In the same paragraph (as noted in comment 1), the literature review should include the paper "Linear Time Average Consensus on Fixed Graphs and Implications for Decentralized Optimization and Multi-Agent Control" by Olshevsky. Its convergence rate should be appropriately reported (see further elaboration in comment 8). The referenced work achieves a competitive, if not superior, bound compared to the results presented in this submission.
(3) At the beginning of page 2, the discussion on consensus optimization is missing key references, such as:  
- "On the Linear Convergence of the ADMM in Decentralized Consensus Optimization" by Shi, Ling, Kun, Wu, and Yin,  
- "Optimal algorithms for smooth and strongly convex distributed optimization in networks" by Scaman, Bach, Bubeck, Lee, and Massoulié.  
The authors should also provide an overview of state-of-the-art algorithms for consensus optimization and their corresponding (linear) convergence rates.
(4) When discussing lifted graphs and Markov chains, the paper overlooks a closely related work: "Markov Chain Lifting and Distributed ADMM" by Franca and Bento.
(5) The content in the last paragraph of page 5 is a well-established result. The authors should reference "Generalized consensus computation in networked systems with erasure links" by Rabbat, Nowak, and Bucklew. Furthermore, the connection between these variants and Heavy Ball/Nesterov/Polyak methods is already known in the field.
(6) Several critical references on consensus optimization have been omitted, such as:  
- "Extra: An exact first-order algorithm for decentralized consensus optimization" by Shi, Ling, Wu, and Yin,  
- "Fast distributed gradient methods" by Jakovetic, J Xavier, and Moura.
(7) Proposition 3 appears to be trivial and serves as a supplementary contribution.
(8) The convergence rate achieved in this paper, \( D \log(D/\epsilon) \), does not represent a significant improvement over the rate \( D \log(1/\epsilon) \) established in "Linear Time Average Consensus on Fixed Graphs and Implications for Decentralized Optimization and Multi-Agent Control" (see comment 2). In the worst-case scenario (valid for all graphs), where \( D \sim n \), the bound is even less favorable than that achieved in the referenced work.
(9) The paper "Linear Time Average Consensus..." improves the bound using Nesterov's acceleration. The reviewer suspects that the proposed "Auxiliary message-passing scheme" in this submission is essentially another application of Nesterov's acceleration to the min-sum algorithm. While this is acceptable, the analysis is conducted for the consensus problem, which reduces to analyzing a linear system and is not particularly challenging. Consequently, the contribution of the paper remains unclear in this context.
(10) The minor improvement in the results may stem from a careful treatment of the spectral gap of graphs. However, the worst-case bound remains \( O(n) \), as \( O(n) = O(D) \) for the set of all graphs with \( n \) nodes.
(11) Line 243 on page 6: The graph is described as simple, but the authors use directed edges, which is confusing.
(12) Typographical error on line 220 of page 6: "Laplacian" should be corrected to "Lagrangian."
After rebuttal:  
The reviewer acknowledges the authors' responses and is satisfied with the clarifications provided. However, the evaluation score remains unchanged.