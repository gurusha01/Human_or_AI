This paper investigates the theoretical limitations of variance-reduction and acceleration schemes for finite sum optimization problems, focusing on the interplay between algorithmic design and problem structure. The authors present three key contributions: (1) demonstrating that the finite sum structure alone is insufficient for achieving the optimal complexity bound of \( \tilde{O}((n + L/\mu) \ln(1/\epsilon)) \) without knowing the identity of the individual function accessed by the oracle, (2) proving that accelerated rates (\( \tilde{O}((n + \sqrt{nL/\mu}) \ln(1/\epsilon)) \)) are unattainable without explicit knowledge of the strong convexity parameter, and (3) establishing lower bounds on iteration complexity for smooth and convex finite sums, particularly for oblivious algorithms.
Strengths
1. Theoretical Rigor: The paper provides a thorough and mathematically rigorous analysis of the limitations of variance-reduction and acceleration techniques. The use of information-theoretic tools and polynomial approximation arguments is well-grounded and insightful.
2. Novel Insights: The results on the necessity of knowing the individual function identity and the strong convexity parameter are novel and challenge common assumptions in the design of finite sum optimization algorithms.
3. Comprehensive Framework: The introduction of the framework for oblivious CLI algorithms is a valuable contribution, enabling a unified analysis of a broad class of optimization methods, including SAG, SAGA, SVRG, and SDCA.
4. Practical Implications: The findings have clear implications for real-world applications, such as data augmentation scenarios, where the lack of explicit enumeration of samples can degrade algorithmic performance.
Weaknesses
1. Clarity and Accessibility: While the paper is mathematically rigorous, it is dense and may be difficult for non-experts to follow. The presentation could benefit from more intuitive explanations, diagrams, or examples to complement the formal derivations.
2. Empirical Validation: The paper is purely theoretical, and while this is appropriate for its scope, some empirical results or simulations could help illustrate the practical impact of the theoretical findings.
3. Limited Scope of Algorithms: The focus on oblivious algorithms, while interesting, may limit the generality of the results. It would be useful to discuss whether these limitations extend to non-oblivious or adaptive algorithms.
4. Related Work: Although the paper references relevant prior work, the discussion could be expanded to better contextualize the contributions within the broader landscape of optimization research.
Pro and Con Arguments for Acceptance
Pro:
- The paper addresses a fundamental question in optimization theory and provides novel, impactful results.
- The theoretical contributions are rigorous and advance the understanding of finite sum optimization.
Con:
- The dense presentation may limit accessibility to a broader audience.
- The lack of empirical validation leaves open questions about the practical significance of the results.
Recommendation
Overall, this paper makes significant theoretical contributions to the field of optimization and variance-reduction methods. While the presentation could be improved for clarity and accessibility, the novelty and rigor of the results make it a strong candidate for acceptance. I recommend acceptance with minor revisions, focusing on improving clarity and expanding the discussion of related work and practical implications.