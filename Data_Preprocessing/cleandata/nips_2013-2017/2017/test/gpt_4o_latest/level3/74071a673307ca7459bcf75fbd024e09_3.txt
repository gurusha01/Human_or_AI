The paper introduces a novel closed-form screening rule for \( l1 \)-regularized Ising model estimation, providing a necessary and sufficient condition for identifying blockwise structures in the solution. This screening rule, derived from the Karush-Kuhn-Tucker (KKT) conditions, is both elegant and computationally efficient, offering a significant advancement in the understanding of \( l1 \)-regularized maximum likelihood estimation (MLE) for discrete graphical models. The authors demonstrate that the rule can drastically reduce the dimensionality of the problem, enabling efficient computation for large-scale datasets while maintaining interpretability by focusing on moderate-sized clusters of variables.
Strengths:  
The paper's primary contribution lies in its simplicity and rigor. The screening rule is mathematically elegant and theoretically sound, as evidenced by the proofs provided. It bridges a notable gap in the literature by addressing the absence of screening rules for generative models with discrete variables, a critical need in high-dimensional exploratory data analysis. The authors also provide a clear connection between the screening rule and existing methods for Gaussian graphical models, highlighting its novelty and relevance. The empirical results are compelling, demonstrating substantial speedups in both synthetic and real-world datasets. The scalability of the approach, particularly when combined with parallel computation, is a significant practical contribution. Furthermore, the paper acknowledges the NP-hardness of the underlying problem, presenting the screening rule as a meaningful step forward rather than a complete solution.
Weaknesses:  
One concern is the sensitivity of the method to the choice of the regularization parameter (\(\lambda\)). While the authors discuss the implications of \(\lambda\) and provide heuristics for its selection, low values of \(\lambda\) could negate the computational benefits of the screening rule by failing to induce sufficient sparsity. This limitation warrants further clarification and empirical exploration. Additionally, while the paper demonstrates the utility of the screening rule in combination with inexact methods like node-wise logistic regression and pseudolikelihood estimation, it does not fully address the conditions under which the rule can be combined with these methods without loss of accuracy. A more detailed theoretical analysis in this regard would strengthen the paper.
Pro/Con Arguments for Acceptance:  
- Pro: The paper addresses a critical gap in the literature, introduces a novel and theoretically sound method, and demonstrates its practical utility with strong empirical results.  
- Con: The sensitivity to \(\lambda\) and the lack of comprehensive analysis of the interplay between the screening rule and inexact methods leave some questions unanswered.
Recommendation:  
The paper is a significant contribution to the field of sparse graphical model learning and is well-suited for publication at NeurIPS. While the concerns about \(\lambda\) and inexact methods should be addressed in future work, they do not detract from the overall quality and impact of the current contribution.