This paper presents a novel approach to clustering data points via crowdsourcing, leveraging similarity queries to recover original labels. The authors frame the problem as equivalent to locally encodable source coding, a concept rooted in information theory, and derive theoretical bounds on the number of queries required for both exact and approximate recovery under noisy and noiseless conditions. The paper's main contributions include new lower bounds for query complexity, a demonstration of the limitations of traditional "same cluster" (XOR) queries, and the introduction of AND queries, which are shown to be more efficient in many scenarios. The theoretical results are validated through empirical simulations and a real-world crowdsourcing experiment.
Strengths:
1. Theoretical Contributions: The paper provides rigorous theoretical bounds on query complexity, advancing the understanding of clustering via crowdsourcing. The connection to locally encodable source coding is novel and well-motivated, offering a fresh perspective on the problem.
2. Clarity and Accessibility: The authors effectively explain the connection to information theory, making the theoretical results accessible to a general machine learning audience. The inclusion of detailed proofs and intuitive explanations enhances the paper's clarity.
3. Practical Relevance: The introduction of AND queries is a significant contribution, as these queries are shown to outperform XOR queries in both theoretical and experimental settings. The real-world crowdsourcing experiment further substantiates the practical applicability of the proposed methods.
4. Empirical Validation: The experimental results align well with theoretical predictions, demonstrating the robustness of the proposed algorithms. The use of a real dataset and crowdsourcing platform adds credibility to the findings.
Weaknesses:
1. AND Queries and Crowdsourcing Motivation: While AND queries are shown to be theoretically superior, their practical necessity in a crowdsourcing context is not fully justified. The authors should clarify why workers would naturally perform AND operations instead of simpler "same cluster" queries, which are more intuitive.
2. Complexity of Theoretical Bounds: The bounds presented in Theorems 1-4 are mathematically dense and could benefit from simplification or additional intuitive explanations to enhance readability for non-specialists.
3. Experimental Scope: The experiments focus solely on AND queries, leaving the comparative performance of XOR queries under similar conditions less explored. This omission raises questions about the generalizability of the results.
Recommendation:
Overall, the paper makes a strong theoretical and practical contribution to the field of clustering via crowdsourcing. The connection to information theory is innovative, and the introduction of AND queries addresses key limitations of existing methods. While the concerns about the practical motivation for AND queries and the complexity of theoretical bounds warrant further clarification, the authors' responses to these issues are satisfactory. I recommend the paper for acceptance, as it advances the state of the art and provides a solid foundation for future research in this area.
Arguments for Acceptance:
- Novel theoretical insights and bounds.
- Clear connection to information theory, making the work broadly relevant.
- Empirical validation on real-world and synthetic datasets.
- Practical improvements in query efficiency through AND queries.
Arguments Against Acceptance:
- Lack of clarity on the practical necessity of AND queries in crowdsourcing.
- Theoretical bounds could be simplified for better accessibility.
- Limited experimental focus on XOR queries for comparative analysis. 
Despite these minor concerns, the paper is a valuable contribution and merits inclusion in the conference.