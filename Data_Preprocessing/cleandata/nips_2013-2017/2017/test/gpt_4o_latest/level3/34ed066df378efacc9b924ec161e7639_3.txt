The paper presents the Pose Guided Person Generation Network (PG2), a two-stage framework for synthesizing person images in arbitrary poses, conditioned on a reference image and a target pose. The authors employ a U-Net-like architecture for pose integration in Stage-I and a Deep Convolutional GAN (DCGAN) variant for image refinement in Stage-II. The proposed method introduces a novel task of pose-guided person generation and explores innovative techniques such as pose mask loss to focus on the human body while mitigating background interference. Experiments on two datasets, Market-1501 and DeepFashion, demonstrate the model's ability to generate pose-consistent images, with qualitative and quantitative evaluations provided.
Strengths:
The paper addresses an interesting and challenging problem in computer vision with potential applications in areas like movie production, pose estimation, and data augmentation. The divide-and-conquer strategy, splitting the task into two stages, is a logical and effective approach. The use of pose heatmaps as input and the introduction of pose mask loss are innovative contributions that improve the focus on human body synthesis. The writing is clear, and the methodology is well-documented, allowing for reproducibility. The qualitative results, particularly on the DeepFashion dataset, show that the proposed method can generate pose-consistent images with reasonable detail. The authors also provide a comprehensive comparison with related work, highlighting the advantages of their approach.
Weaknesses:
Despite its conceptual strengths, the paper has significant shortcomings in both quantitative evaluation and visual quality. The lack of robust quantitative metrics, such as user studies or perceptual scores, undermines the claims of generating high-quality images. While the authors report SSIM and Inception Scores, these metrics are insufficient for evaluating the realism of generated images, especially in the presence of artifacts. Additionally, the generated images often exhibit noticeable errors, such as blurry textures, unnatural boundaries, and low resolution, particularly on the more challenging Market-1501 dataset. These issues detract from the practical applicability of the method. The rebuttal did not adequately address these concerns, leaving the impression that the work is not yet mature enough for a top-tier venue like NeurIPS.
Recommendation:
While the paper introduces an interesting idea and demonstrates some promise, the lack of convincing quantitative evaluation and the subpar visual quality of the generated images make it unsuitable for acceptance at this stage. To improve, the authors should focus on enhancing image quality, incorporating higher-resolution outputs, and conducting user studies to validate the realism of the generated images. Furthermore, addressing failure cases and providing more diverse examples would strengthen the work's overall impact.
Pro: Novel task and approach, clear writing, innovative use of pose mask loss.  
Con: Poor visual quality, lack of robust quantitative evaluation, insufficient rebuttal response.  
Final Decision: Reject.