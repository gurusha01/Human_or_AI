The paper introduces a novel attention module for action recognition and human-object interaction tasks, which is both simple and computationally efficient. The authors claim that their method significantly improves performance on three standard benchmarks (MPII, HICO, and HMDB51) and establishes a new state-of-the-art on the MPII dataset with a 12.5% relative improvement. The attention mechanism is framed as a low-rank approximation of second-order pooling, offering a unique perspective on action recognition as a fine-grained classification problem. Additionally, the paper explores the integration of human pose as a regularizer for attention maps, particularly benefiting video datasets.
Strengths:
1. Novelty and Contribution: The paper presents a novel formulation of attention as low-rank second-order pooling, bridging the gap between attention mechanisms and bilinear pooling methods. This is an innovative perspective that could inspire further research.
2. Practical Impact: The proposed attention module is computationally efficient, requiring minimal additional parameters, making it a practical enhancement to existing architectures.
3. Comprehensive Evaluation: The method is evaluated on diverse datasets (still images and videos), demonstrating its versatility. The results show significant improvements over baselines and prior state-of-the-art methods.
4. Mathematical Rigor: The derivation of the attention module is well-grounded in mathematical theory, and the connection to bilinear pooling is clearly articulated.
5. Visualization and Analysis: The paper includes insightful visualizations of attention maps and provides detailed ablation studies, including the effects of pose regularization and rank approximations.
Weaknesses:
1. Comparative Baselines: While the paper compares its method to prior work, some comparisons (e.g., with more recent multi-stream or transformer-based models) are missing, especially given the rapid advancements in action recognition.
2. Limited Dataset Scope: Although the method performs well on the chosen datasets, its applicability to larger-scale or more diverse datasets (e.g., Kinetics or AVA) remains unexplored.
3. Pose Regularization: While pose-regularized attention improves performance on HMDB51, its impact is marginal on other datasets. The paper could better clarify when and why pose regularization is beneficial.
4. Reproducibility: While the method is described in detail, the paper does not provide sufficient implementation details (e.g., hyperparameters, training schedules) to ensure reproducibility.
Pro and Con Arguments:
Pro: The paper introduces a simple yet effective attention mechanism that is computationally efficient and achieves state-of-the-art results on multiple benchmarks. Its theoretical contributions and practical applicability make it a strong candidate for acceptance.  
Con: The lack of experiments on larger datasets and comparisons with more recent methods slightly limits the generalizability and impact of the work.
Recommendation:
Overall, this paper is a strong contribution to the field of action recognition. Its novel formulation of attention, rigorous analysis, and competitive results make it a valuable addition to the literature. I recommend acceptance, with minor revisions to address the reproducibility concerns and provide additional comparisons with recent methods.