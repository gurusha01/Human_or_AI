This paper presents novel mechanisms for the repeated collection of counter data under the local differential privacy (LDP) model, addressing a critical limitation of existing LDP algorithms: their rapid degradation of privacy guarantees in continuous data collection scenarios. The authors propose mechanisms for mean and histogram estimation that maintain formal privacy guarantees over arbitrarily long periods of data collection, achieving comparable or even superior accuracy to single-round LDP mechanisms. The paper introduces three key contributions: (1) simplified 1-bit response mechanisms for single-round data collection, (2) a novel α-point rounding technique for memoization to prevent privacy leakage in repeated data collection, and (3) deployment of these mechanisms by Microsoft to collect telemetry data across millions of devices. Theoretical results are validated through empirical evaluations on real-world datasets, demonstrating the mechanisms' practical utility and robustness.
Strengths:
1. Technical Novelty: The paper addresses a significant gap in the LDP literature by proposing mechanisms that extend privacy guarantees to repeated data collection scenarios. The α-point rounding technique is particularly innovative, borrowing ideas from approximation algorithms to balance privacy and accuracy effectively.
2. Theoretical Rigor: The privacy guarantees are well-defined, with clear formulations of the LDP properties for repeated data collection. The authors provide proofs and bounds for the accuracy and privacy of their mechanisms, ensuring a solid theoretical foundation.
3. Practical Relevance: The deployment of the proposed mechanisms by Microsoft highlights their real-world applicability and scalability. The mechanisms are shown to work effectively in large-scale settings, such as telemetry data collection across millions of devices.
4. Empirical Validation: Extensive experiments on both real-world and synthetic datasets demonstrate the mechanisms' accuracy and robustness across various distributions and parameter settings. The results consistently show that the proposed methods outperform or are comparable to state-of-the-art single-round LDP mechanisms.
Weaknesses:
1. Clarity: While the paper is technically sound, some sections, particularly those describing the α-point rounding and memoization techniques, are dense and challenging to follow. Simplifying the exposition or providing additional illustrative examples could improve accessibility.
2. Limited Scope of Evaluation: The empirical evaluation focuses primarily on app usage telemetry data. While this is a relevant use case, broader evaluations across other domains (e.g., healthcare or financial data) would strengthen the generalizability of the results.
3. Privacy-Utility Trade-off: The paper acknowledges that the privacy guarantees for repeated data collection are weaker than those for single-round collection. However, the implications of this trade-off, especially in adversarial settings with auxiliary information, could be explored in greater depth.
Arguments for Acceptance:
- The paper addresses a critical and underexplored problem in the LDP domain, making a significant contribution to the field.
- The proposed mechanisms are theoretically sound, empirically validated, and practically deployed, demonstrating both academic and industrial impact.
- The work advances the state of the art by providing mechanisms that balance privacy and utility in challenging repeated data collection scenarios.
Arguments Against Acceptance:
- The dense presentation of some technical sections may hinder comprehension for a broader audience.
- The evaluation could benefit from broader application scenarios to demonstrate generalizability.
Recommendation:
Overall, this paper makes a strong contribution to the field of differential privacy, particularly in the context of repeated data collection. While there are minor concerns regarding clarity and scope, the strengths far outweigh the weaknesses. I recommend acceptance with minor revisions to improve clarity and expand the discussion on privacy-utility trade-offs.