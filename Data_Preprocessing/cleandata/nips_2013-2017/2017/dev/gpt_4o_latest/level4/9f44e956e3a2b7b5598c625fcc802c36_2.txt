The paper addresses the problem of active hypothesis testing under constraints of limited information. Specifically, it considers the probability of 'correct indication,' denoted as q(j,w), where j represents the true hypothesis and w the chosen action. The authors assume that q(j,w) is bounded below by \alpha(w) for all j, with \alpha(w) being known to the controller. They begin by analyzing the incomplete-Bayesian (IB) update rule, where all q's are substituted with \alpha's, resulting in an approximation. They demonstrate that under this IB update rule, achieving a posterior error probability of (1-\delta) requires at least O(log(1/\delta)) samples. Subsequently, they establish that their gradient-based policy achieves an order-wise optimal sample complexity.
I have several technical questions:
On the upper bound: The authors assert that the upper bound is derived by considering the worst-case scenario where q(w,j) = \alpha(w) for all w when j is the true hypothesis. If this is the case, how does the analysis in this paper differ from that of the Bayesian update case? (If my interpretation is correct, q(w,j) = \alpha(w) would imply that the IB update rule is equivalent to the Bayesian update rule.) Additionally, in practical scenarios, it is possible for q(w,j) to approach 1 while \alpha(w) approaches 1/2. Under such conditions, does the upper bound still provide any meaningful guarantees?
On the lower bound: Does the derived lower bound recover the existing lower bounds for the case of complete information?
On simulation results: It would be beneficial if the authors could include the lower and upper bounds on E[T] and compare these theoretical results with their simulation outcomes.