This paper introduces a novel approach called "reach subgame solving" to enhance decision-making in the context of imperfect information, two-player zero-sum games. The core concept leverages the disparity in payoffs received by the opponent when choosing paths that lead into versus away from a given information set. Additionally, the authors propose a modification to generalize the method for application across multiple independent subgames.
The manuscript is well-structured overall, and the authors provide theoretical evidence demonstrating the method's low exploitability, defined as the deviation from the Nash equilibrium value (noting that, in zero-sum games, this value is uniquely determined, eliminating ambiguity about which Nash equilibrium to use for comparison). Empirical results are also presented, showcasing improvements over existing approaches. While the standard baseline, the unsafe subgame solving method, performs competitively on all but one benchmark, it lacks theoretical guarantees. Notably, the paper asserts that this is the first method to outperform four human players in heads-up no-limit Texas hold'em poker.
I am curious whether the concepts introduced in this work could have broader applicability if exploitability were redefined in terms of alternative solution concepts, such as (coarse) correlated equilibria. Furthermore, could this method be adapted to handle non-zero-sum settings, such as general bimatrix games?