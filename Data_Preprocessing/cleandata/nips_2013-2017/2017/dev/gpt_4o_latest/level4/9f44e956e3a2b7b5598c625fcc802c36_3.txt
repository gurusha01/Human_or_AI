This paper addresses the problem of active hypothesis testing under a setting where the algorithm receives only indirect feedback. It introduces a method based on an incomplete Bayesian update, which selects actions at each step by greedily maximizing a lower bound on the expected posterior probability of the true hypothesis. The paper establishes matching upper and lower bounds on the number of samples required as a function of the confidence parameter, denoted by delta.
The paper is well-written, and I find its results to be correct (though I did not verify the appendix). It introduces a novel model and proposes an algorithm that is new, albeit bearing some resemblance to existing methods in [11] and [13].
My primary concern lies with the motivation for this work. While the paper introduces a new model for active hypothesis testing, it provides limited justification for its relevance. Although an example is presented in Section 5 (which I suggest relocating to Section 1 or 2 for better context), the example itself feels somewhat contrived. For instance, why not simply allow the workers to output the labels directly? Additionally, how can the quality of the workers be reliably assessed?
Another limitation is the scope of the analysis:
1. The upper and lower bounds are derived only with respect to delta. It would be valuable to understand how the sample complexity depends on other parameters, such as |J|, |W|, or other relevant quantities.
2. The paper does not theoretically compare the sample complexity of the proposed method against other approaches, such as the Chernoff algorithm, the GBS algorithm, or a naive passive method. While numerical results are provided, theoretical comparisons would strengthen the paper's contributions.