This paper addresses predictive learning, specifically video prediction, utilizing a recurrent neural network (RNN) architecture. It introduces a novel variation of LSTM, termed ST-LSTM, which incorporates recurrent connections beyond the standard forward time direction.
The predictive framework is constructed using ST-LSTM blocks. Each block resembles a convolutional LSTM unit but includes modifications to accommodate an additional input. This extra input originates from the last layer of the previous time step and is fed into the first layer of the current time step, subsequently propagating through the layers within the same time step.
The resulting ST-LSTM architecture can be interpreted as a combination of two independent LSTM units interacting via the concatenation of their memory states (as depicted in Figure 2, left).
The loss function is not explicitly defined in the paper (the closest reference appears to be Equation 1). I assume the loss is based on mean squared error (MSE), but this should be explicitly clarified, as alternative loss formulations are possible.
Experimental results are presented on the Moving MNIST (synthetic) and KTH (natural) datasets, reporting both PSNR/SSIM metrics and generated predictions. The authors compare their PredRNN model with baseline approaches, demonstrating superior performance on these datasets. On Moving MNIST, a comparison of various LSTM configurations shows that ST-LSTM achieves the best results, which is a notable outcome.
However, the experimental section could be strengthened by including additional datasets. The two datasets used in the paper have relatively low ambiguity in their future predictions. It would be valuable to evaluate the model on more complex datasets, such as Sports1M, UCF101, or the Google "Push" dataset, to assess its performance in less constrained scenarios. While the paper proposes a sophisticated and seemingly effective predictive structure, the loss function is scarcely discussed. As highlighted by works such as [17] and [19], a simple loss function like MSE may not perform well when the future distribution is multimodal. Additionally, the paper would benefit from comparisons with non-LSTM-based methods, such as those mentioned in Section 1.2. In particular, approaches like VPNs and GANs appear to be strong alternatives worth considering.
Notes:
- Figure 1: While the figure is generally clear, the meaning of the orange arrows is unclear compared to the black arrows.
- Figure 2 (right): Based on my understanding, each W box should also include an Xt input, not just W1.