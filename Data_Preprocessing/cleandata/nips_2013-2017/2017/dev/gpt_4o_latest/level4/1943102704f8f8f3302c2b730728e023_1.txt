[UPDATE AFTER AUTHOR RESPONSE]
The authors' response reinforces my initial assessment â€“ this is a valuable paper. I remain optimistic that they will address both my concerns and those raised by the other reviewers in their revision.
---
[ORIGINAL REVIEW]
This paper introduces YASS: Yet Another Spike Sorter, a well-designed pipeline for processing multi-electrode array (MEA) recordings. The methodology is robust, integrating several state-of-the-art techniques into a cohesive pipeline. The manuscript is well-written, follows a logical structure, and provides compelling evidence that the proposed work advances the state of the art in sorting retinal MEA data.
While the paper is already a significant contribution in its current form, I believe it has the potential to be even more impactful if the authors address the following issues. My primary concerns are summarized as:
(1) the absence of publicly available code,  
(2) insufficient detail regarding the neural network detection method,  
(3) challenges in applying the pipeline to cortical data.
Details:
(1) Code availability. The manuscript does not provide a URL for accessing the code, and it appears that the code is not publicly available. Since spike sorting is predominantly an engineering challenge (albeit a complex one), a description of the approach alone is far less valuable without access to the implementation. I strongly encourage the authors to make the code publicly available to maximize the utility and reproducibility of their work.
(2) Neural network spike detection. This component appears to be the most novel aspect of the pipeline (as the other components have been previously described or employed). However, the manuscript does not clearly explain how the authors generated their training data. Section C.2 outlines various methods for generating training data, but it is unclear which specific method (or combination of methods) the authors used.
(a) Pre-existing sorts.  
Most labs transitioning to dense MEAs lack properly sorted data because they do not have a pipeline capable of handling such recordings, as the authors themselves note. Additionally, it is unclear how pre-existing sorts would contribute to training a more robust neural network for spike detection. Did the authors manually inspect each waveform snippet to label it as clean or not? If not, what algorithm was used to determine which snippets were clean? Why was it necessary to train a neural network instead of directly using this algorithm? How did the authors address potential misalignments that could introduce label noise?  
If pre-existing sorts were used, the authors need to provide detailed information on how this was done and why it is effective. Without this information, the work cannot be reproduced.
(b) Synthetic training data.  
The authors mention generating synthetic training data by superimposing waveform templates on background noise. While this could be a reasonable approach, it is unclear whether this method was used for data augmentation or simply described as a potential alternative. What evidence supports the utility of this approach? Synthetic data may not accurately reflect real recordings, and this limitation should be addressed.
(3) Generalization to cortical data. While I am confident that the pipeline performs well for retinal data, I am skeptical about its applicability to cortical data. This limitation should be explicitly discussed and acknowledged in the abstract, introduction, and conclusions.
(a) Waveform drift.  
In cortical recordings, waveform drift is a significant challenge, particularly in non-chronic recordings. Chronic high-density MEAs are still largely unproven. Addressing waveform drift is crucial for recordings longer than a few minutes, and this issue is not adequately addressed in the manuscript.
(b) Training data for cortical recordings.  
Obtaining high-quality training data for the neural network detection method is more challenging for cortical recordings. Reliable ground truth or well-validated data (such as that described in Appendix I) is not readily available. Additionally, generating synthetic data as described in Section C.2 may not be realistic for cortical recordings, as background noise often includes spikes, and neurons frequently fire in highly correlated patterns. These factors could undermine the validity of the synthetic data approach.
Minor comments:
- Figure 3 (bottom panel): The Y-axis labeling is unclear. Does "1^-x" mean "10^-x"? Additionally, the plot exaggerates minor accuracy differences between 0.99 and 0.999, where both methods are effectively perfect.  
- The authors mention using spatially whitened data (Section 2.1), but the manuscript or supplement does not provide a description of the spatial whitening procedure.