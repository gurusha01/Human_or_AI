Review of the Paper
This paper addresses the problem of multitask learning for Weighted Finite Automata (WFAs) by introducing the novel concept of vector-valued WFAs (vv-WFAs) and proposing a spectral learning algorithm for this model. The authors formalize a notion of task relatedness through shared feature representations and demonstrate the benefits of their multitask approach both theoretically and empirically. The work is a significant contribution to the intersection of multitask learning and automata theory, with potential applications in natural language processing, computational biology, and reinforcement learning.
Strengths:
1. Novelty and Originality: The introduction of vv-WFAs is a novel contribution that extends the classical WFA framework to multitask learning. The paper also provides a formal definition of task relatedness, which is a valuable conceptual addition to the field.
2. Theoretical Rigor: The authors establish a solid theoretical foundation for their approach, including proofs of key results such as the vector-valued Fliess theorem and the benefits of multitask spectral learning in terms of subspace estimation.
3. Practical Relevance: The proposed algorithm is computationally efficient and scales well with the number of tasks. The inclusion of a dimension-reduction step to minimize noise and redundancy is a practical enhancement.
4. Empirical Validation: The experiments on both synthetic and real-world datasets convincingly demonstrate the advantages of the multitask approach, particularly in low-data regimes. The results on the Universal Dependencies dataset highlight the method's applicability to real-world problems.
Weaknesses:
1. Baseline Comparison: While the authors compare their method to single-task spectral learning (SL), they do not include a baseline where data from all tasks are aggregated and treated as a single task (SL-bagging). This would provide a more comprehensive evaluation of the multitask approach.
2. Post-Processing Evaluation: The contribution of the projection step is not explicitly evaluated. Including results for the algorithm without this step (MT-SL-noproj) would clarify its impact on performance.
3. Task Weighting: The algorithm assumes equal weights for all tasks, which may not be optimal for datasets with varying task sizes. Exploring weighted approaches could improve performance in such scenarios.
4. Clarity of Applications: While the paper mentions potential applications, a more detailed discussion of specific use cases (e.g., natural language modeling in different contexts) would strengthen the paper's practical relevance.
5. Minor Issue: Line 93 should clarify whether including the empty string in prefixes or suffixes is necessary, as this could affect the completeness of the Hankel matrix.
Arguments for Acceptance:
- The paper introduces a novel and theoretically sound approach to multitask learning for WFAs, which is a relatively unexplored area.
- The empirical results demonstrate clear benefits over single-task learning, particularly in data-scarce scenarios.
- The proposed method is computationally efficient and has broad applicability across multiple domains.
Arguments Against Acceptance:
- The lack of comparison to SL-bagging and evaluation of the projection step leaves some questions about the method's relative advantages unanswered.
- The assumption of equal task weights may limit the algorithm's effectiveness in certain scenarios.
Final Verdict:
Overall, this paper makes a strong contribution to the field of multitask learning and automata theory. The theoretical insights, combined with promising empirical results, justify its acceptance. Addressing the baseline comparison and task weighting concerns in future work would further enhance the impact of this research. I recommend acceptance.