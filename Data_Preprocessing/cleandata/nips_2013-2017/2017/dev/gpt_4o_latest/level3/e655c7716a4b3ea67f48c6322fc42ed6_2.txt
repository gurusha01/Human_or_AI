The paper addresses the problem of multitask learning for weighted finite automata (WFAs) by introducing vector-valued WFAs (vv-WFAs) and proposing a spectral learning algorithm for this new model. The authors define a notion of relatedness between WFAs based on shared feature representations and leverage the Hankel tensor's rank factorization to jointly learn multiple tasks. The paper claims theoretical advantages of this multitask approach and demonstrates its performance on synthetic and real-world datasets.
Strengths:
1. Relevance and Scope: The paper tackles a meaningful problem in multitask learning, particularly for sequence data, which has applications in NLP, computational biology, and reinforcement learning. The extension of spectral learning to multitask settings is a valuable contribution.
2. Theoretical Foundation: The authors provide a solid theoretical framework, including a generalization of the Fliess theorem to vector-valued functions, and analyze the computational complexity of the proposed method. The use of asymmetric bounds for singular subspace estimation is a novel angle.
3. Experimental Validation: The experiments on synthetic and real-world datasets, including the Universal Dependencies dataset, provide empirical evidence for the method's effectiveness under certain conditions. The comparison with single-task learning (SL) and naive baselines is thorough.
4. Clarity in Algorithm Design: The multitask spectral learning (MT-SL) algorithm is clearly described, and the projection step to reduce redundancy is well-motivated.
Weaknesses:
1. Novelty Concerns: The novelty of the Hankel tensor factorization technique is questionable. While the extension to multitask settings is interesting, the core spectral learning approach relies heavily on existing methods, and the novelty appears incremental.
2. Unclear Relatedness Measure: The definition and purpose of the relatedness measure "tau" are not sufficiently clear. Its connection to other quantities and its practical utility in guiding the algorithm are underexplored.
3. Lack of Evident Benefits: The paper claims advantages of multitask learning, but these are not consistently demonstrated. For example, when tasks are minimally related (e.g., dS = dT), MT-SL offers no clear improvement over single-task learning (SL). Additionally, the computational complexity of MT-SL appears worse than estimating individual WFAs separately, especially as the number of tasks grows.
4. Ambiguity in Error Analysis: The claim that estimation error improves with "enough" tasks (O(T^2) vs. O(T)) is confusing, particularly for T â‰¤ 1. This raises questions about the practical implications of the theoretical results.
5. Limited Exploration of Task Relatedness: The paper does not explore how performance varies when tasks are minimally vs. maximally related. A more general version of Theorem 5 could clarify this distinction.
Pro and Con Arguments for Acceptance:
- Pro: The paper introduces a novel multitask framework for WFAs, supported by theoretical insights and experiments. It addresses a relevant problem and demonstrates potential benefits in specific scenarios.
- Con: The novelty is limited, and the practical advantages of the method are not consistently evident. Key concepts, such as the relatedness measure and computational trade-offs, require further clarification.
Recommendation: While the paper offers an interesting extension of spectral learning to multitask settings, the concerns about novelty, clarity, and practical benefits temper its impact. I recommend acceptance only if the authors address the unclear aspects of the relatedness measure, computational complexity, and error analysis in a revised version.