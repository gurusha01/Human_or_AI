This paper investigates the connections between discrete and continuous approaches for decomposable submodular function minimization (DSFM), providing both theoretical improvements and systematic experimental comparisons. The authors improve the worst-case complexity bounds of state-of-the-art continuous optimization methods by a factor of \( r \) (the number of functions in the decomposition) and simplify the arguments using combinatorial insights. They also present experimental results that highlight trade-offs between discrete and continuous methods, particularly in the context of level-0 and level-1 algorithms.
Strengths:
1. Theoretical Contributions: The paper provides a significant improvement in the complexity bounds for continuous methods, leveraging combinatorial arguments. This not only advances the state-of-the-art but also simplifies the proofs compared to prior work.
2. Experimental Design: The authors make a clear distinction between level-0 and level-1 algorithms, enabling a fair comparison of different approaches. This methodological rigor is commendable.
3. Practical Insights: The experimental results reveal important trade-offs. For small cliques, discrete methods like IBFS outperform gradient methods, but for larger cliques, gradient methods combined with approximate level-0 subroutines are more efficient.
4. Clarity in Results: The paper provides detailed running time analyses and explicitly defines parameters like \(\kappa^\) and \(\ell^\), which are crucial for understanding the convergence rates of the algorithms.
Weaknesses:
1. Comparison with State-of-the-Art: While the paper improves the complexity bounds for continuous methods, it does not fully clarify how these bounds compare quantitatively with the best-known discrete methods. For instance, in line 73, the significance of the results could be better contextualized against the state-of-the-art.
2. Algorithm Presentation: The algorithms are presented in plain text rather than using proper \(\texttt{algorithm}\) environments, which detracts from readability and reproducibility.
3. Applicability of Bounds: In line 140, it is unclear whether the improved bounds apply only to integer-valued functions or more general cases. Additionally, the distinction between weakly and strongly polynomial algorithms is not explicitly addressed.
4. Terminology Definition: The term "\(\epsilon\)-approximate" is used in Corollary 3.4 without an explicit definition, which may confuse readers unfamiliar with the context.
5. Experimental Limitations: The experiments rely on specific potentials and datasets, which may limit the generalizability of the findings. Moreover, the use of a modified Fujishige-Wolfe algorithm for large cliques raises questions about the accuracy of the solutions.
Suggestions for Improvement:
1. In line 73, explicitly compare the improved bounds with those of discrete methods to clarify the significance of the results.
2. Use proper \(\texttt{algorithm}\) environments to present the algorithms in a structured and clear manner.
3. In line 140, clarify whether the bounds are restricted to integer-valued functions and explicitly state whether the algorithms are weakly or strongly polynomial.
4. Define "\(\epsilon\)-approximate" explicitly in Corollary 3.4 to ensure clarity.
5. Expand the experimental evaluation to include more diverse datasets and potential functions to enhance the robustness of the conclusions.
Recommendation:
This paper makes a meaningful contribution to the field of submodular optimization by improving theoretical bounds and providing practical insights into the trade-offs between discrete and continuous methods. However, it requires revisions to address clarity issues, improve algorithm presentation, and better contextualize its results. I recommend acceptance with minor revisions.