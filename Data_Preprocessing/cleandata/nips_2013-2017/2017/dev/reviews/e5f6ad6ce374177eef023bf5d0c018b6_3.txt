This paper introduces a novel convolutional LSTM based architecture for next frame video prediction. The difference with previous attempts is that spatial and temporal variations are gathered in a single memory pool.
 
Comments
The paper is mostly well written, proposes a new approach that appears to be fruitful on two relatively simple datasets.
Providing generated videos for such paper submission would be appreciated.
The results of the paper seem good but the evaluation of the proposed approach to real natural images would be more convincing.
The KTH dataset is described as a dataset of "natural images sequences" but remain very simple to analyse: very low resolution, uniform foreground and background... As the proposed approach is claimed to be memory efficient, it shouldn't be a problem.
Could you provide an idea of the training time?
l.84-86 the authors describe the applications of video prediction as a fact in numerous domains, without citing any references. The reader is therefore curious if these applications are already happening in this case, the authors should provide references, or might happen later, in this case the authors should rephrase (finds -> could find)
l. 105-106 I don't understand the introduction of the deconvolution operator, since it seems unused in the equations and the rest of the paper.
Minor:
l.47 no comma
l 57-58 they ... always -> they always
l 57 the next one -> the next
l. 135 no comma
l 141 in in -> in
l 135-137 I don't understand this sentence
l 154 : We -> we
l 242: ignores -> ignore
[9] {LSTM} ICML 15
[15] ICLR workshop 16
[19]: ICLR 16
[23] {SVM}
[24] ICLR 15
please check other references