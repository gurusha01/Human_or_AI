This work proposes a new technique "reach subgame solving" to better inform decision making in an imperfect information, two player zero-sum game setting. The main idea is to exploit the knowledge about the difference in payoffs received by the opponent when following paths leading into and away from the information set. The authors also suggest an adaptation that extends the method to multiple independent subgames. 
The paper is generally well-written, and results have been proved about the low exploitability of the method, or the discrepancy relative to the Nash equilibrium value (in a zero-sum game this value is unique, so the issue of which Nash equilibrium to compare to does not arise). Empirical results have also been provided to substantiate the gains over existing methods - a standard baseline, the unsafe subgame solving method, seems to be performing quite well on all but one benchmarks, but does not come with any theoretical guarantees. The paper also claims to be the first method to have bested four human subjects in heads-up no limit Texas hold'em poker. 
I wonder if the ideas introduced here could be useful if exploitability were defined not with respect to Nash equilibrium, but some other notions such as (coarse) correlated equilibria? Also, do you think the method could be adapted to non-zero sum (bimatrix games)?