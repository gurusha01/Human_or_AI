In my opinion this paper is quite good, although I do not consider myself an expert on point processes, which should be taken into account when reading this review. I consider it in the top 50% of NIPS papers as a lower bound, admitting that I do not know enough to evaluated it further. I have asked the committee to ensure that at least one person who can judge the proofs sufficiently be assigned to this paper and they promised me this would be the case. I do hope if is published as I would like to try using it. Overall I think the main issue with this paper is that it would more comfortably fit in about 20 pages. 
Here are my detailed comments within the scope of my expertise: 
Coming from a background of modeling user activity as someone who interprets time series regarding heart rate and accelerators, this paper was not what I expected based on the title. To some extent I think the paper would have been better titled "HYBRID: a framework that provides an unbiased estimator of the probability mass function of point processes," but I do see why you called it this after reading the paper.
There are many contributions to in this paper that comprise the framework: the reformulation of the prediction problem using a conditional expectation that incorporates history, allowing sample efficiency for prediction due to a lower variance in the new estimator, the derivation of the differential-difference equation to compute the conditional estimator and both a theoretical evaluation of the framework on synthetic data as well as two evaluations on real world data. Overall, the paper seems quite good and well supported. It is also well written. 
Prior Art: My one comment on the prior art is that one cluster of author (the authors of 5,7,8,9,11,12,24,25,26,27 and 31) does seem to dominate the references. These citations are necessary as the authors of this document do need to reference this material, however, for the datasets used it would be more appropriate to cite the original authors who contributed the data rather than simply 12. 
Demetris Antoniades and Constantine Dovrolis. Co-evolutionary dynamics in social networks: A case study of twitter. Computational Social Networks, 2(1):14, 2015.
My guess is that since there is so much material here and 12 does need to be cited as well the authors were trying to save space, this would be a more appropriate citation for the dataset. Similarly, I believe this paper:
 
Yehia Elkhatib ; Mu Mu ; Nicholas Race "Dataset on usage of a live & VoD P2P IPTV service" P2P, London, UK 2014 
is a more appropriate citation for one of the datasets data used in Section 6.1.2 cited as "the datasets used in [24] The other dataset "used in [24]" seems to be also the Antoniades and Dovrolis set. It would be better to reference these directly. Also, it would be great to know if this area of research is really restricted primarily to this one group or if other groups are actively pursuing these topics. Again, I feel it is a likely space limitation issue so perhaps this is more a comment for a journal version of the paper. 
Solution Overview (Section 3)
With respect to the claim to generalizability, could the authors please give an example of a point process that is not covered by prior art (e.g not represented by a reinforced Poisson process or a Hawkes Process) as a person not overly familiar with point processes, this would help me understand better the impact of this work. This was done nicely in lines 31 and 31 for why the generalization of the function is important.
In general I think this is well presented, your contribution is a more general framework that can preserves the stochasticity of the function and yet requires fewer samples than MC methods. 
With respect to the claim of a new random variable, g(Htminus), the idea of a conditional intensity function, conditioned on the history of the intensity function is not new, it seems to be a known concept based on a few quick web searches. I have to assume that you mean that using it as a random variable for prediction is a new idea. 
The closest similar work I found to this is the use of a "mark-specific conditional intensity function" in "Marked Temporal Dynamics Modeling based on Recurrent Neural Network" by 
Yongqing Wang, Shenghua Liu, Huawei Shen, Xueqi Cheng on arXiv: (https://arxiv.org/pdf/1701.03918.pdf). Again unfortunately by the method of google searching as I am not expert in this area. If you think it is similar you can reference it, if not you can ignore this. Again, it seems related from my point of view, but my expertise is lacking in this area.
With respect to the proof contained in Appendix C: It looks good to me. I had to look up taking the expectation of a conditional random variable, http://www.baskent.edu.tr/~mudogan/eem611/ConditionalExpectation.pdf and the conditions under which a variance could be negative and I believe that you proved your point well. It can't negative or zero because it right progressing and there is an impulse at t(0) which makes it non-constant and therefore non-zero if I understand you correctly. I am hoping supplemental material will be included in the proceedings. 
With respect to the contribution of the formulation of the novel transport equation, this does seem novel and useful. I could find nothing similar. The closest match I found was:
"Probability approximation of point processes with Papangelou conditional intensity," by Giovanni Luca Torris forthcoming in the Bernoulli sociaty (http://www.bernoulli-society.org/index.php/publications/bernoulli-journal/bernoulli-journal-papers) again based on a web search and not my knowledge, so take it as a paper of potential interest for you not a challenge to your novelty.
With respect to the mass transport equation:
This does seem like a very good idea. Intrinsically i am understanding that as intensity process generates events these contribute to that mass and that the accumulated mass is modeled as decreasing over time on absence of new events. I understand that the authors used tools from numerical methods for approximating the integration of the probability mass function and in the end solved their equation with ode45 from Matlab. Everything Matlab says about the method is consistent with what is presented here. 
"ODE23 and ODE45 are functions for the numerical solution of ordinary differential equations. They employ variable step size Runge-Kutta integration methods. ODE23 uses a simple 2nd and 3rd order pair of formulas for medium accuracy and ODE45 uses a 4th and 5th order pair for higher accuracy."
 
I cannot comment with much expertise on the proof in Appendix A. I get the general idea and it seems plausible. I looked up the fundamental lemma of the calculus of variations and tried to follow the math, but I cannot guarantee that I did not miss something as I am not vary familiar with numerical methods.
I found Figure 2 very helpful for getting an intuitive understanding for what was being described by the equations.
I found the section on event information fairly compelling with respect to understanding why they are able to reduce the samples used for the estimate (increased sample efficiency). 
For the experiments int Figure 3. Did you train on 70% and test on 30% or did you use a train,test and hold-out set (e.g. 70/15/15)?
Overall this looks like quite a promising and solid idea and framework, so I would recommend inclusion at NIPS based on my understanding of the content.
 
 
Writing: here are some type-os I noticed as I was reading the paper.
10: "state-of-arts" -> "the state of the art" is better
36 "adversely influence" -> "adversely influences"
64: "the phenomena of interests" -> "the phenomena of interest"
75: The root mean square error (RMSE) is defines as -> is defined as