Summary: Considers solving two-player zero-sum games of imperfect 
information, like poker. Proposes, I think, two new ideas. (1) "Reach" allows the algorithm to make use of any bonus or "gift" that it got at prior steps in the game where the opponent made a mistake. (2) "Nested" proposes to re-solve subgames "on the fly" using more detailed information. That is, the originally solved game may be an abstraction, so when we reach a particular small subgame, maybe we can solve it more exactly in real time.
Opinion: I don't know the game-solving and poker-playing type literature very well. The paper seems to me well-written and to advance some interesting and important ideas for that literature. A weakness is relatively little explanation and discussion of the contributions of new techniques except at a technical level, which made it hard for me to evaluate.
The "ace in the hole" for the paper is that these techniques recently contributed to the first defeating of top human players in no-limit hold-'em, which is a pretty big landmark for AI in general.
Comments: I didn't really get an intuition for why "Reach" helps, i.e. why knowing that P1 made a mistake earlier in the game tree allows us to improve in a certain subgame. I would love to get intuition for this since it seems like a key point.
----
After author response: I found the intuition for "reach" helpful, thanks.