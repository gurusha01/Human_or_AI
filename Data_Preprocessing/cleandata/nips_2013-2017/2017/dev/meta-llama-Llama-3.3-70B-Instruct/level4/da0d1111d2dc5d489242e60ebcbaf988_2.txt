This paper explores online convex optimization with constraints that are revealed online, attempting to bypass the linear regret lower bound established by Mannor et al [17] for adaptively chosen constraints. By considering stochastically generated constraints, the paper achieves superior results for related problems, such as OCO with long-term constraints.
The paper provides a thorough introduction to previous work, effectively contextualizing its contributions. The main algorithm presented is a first-order online algorithm that utilizes instantaneous penalty and constraint functions for optimization. This formulation bears resemblance to the classical Zinkevich's OGD update rule, with the addition of a term incorporating new constraint functions introduced at each time step. The algorithm also employs an adaptive, time-varying regularization parameter, referred to as a "virtual queue," for constraint terms. As demonstrated by Lemma 1, solving this formulation is equivalent to a projected gradient descent (PGD)-style step, where the notion of "gradient" encompasses constraint function subgradients. The virtual queue values are updated to maintain lower bounds on the total constraint violation incurred up to that point.
The theoretical analysis appears to be straightforward, with the exception of the novel drift analysis and its adaptation to the ||Q(t)|| terms, as presented in Lemma 7. The paper includes an experimental application of the algorithm to a distributed job scheduling problem, where it achieves comparable throughput to the REACT approach while reducing costs by approximately 10%.
To further enhance the paper, it would be beneficial to explicitly discuss the challenges associated with extending the PGD framework to accommodate time-varying constraints. The majority of the arguments seem routine after appropriate choices have been made for virtual queue values, with the exception of the drift analysis.
Additionally, providing intuition behind the form of the virtual queue values (equation 3) would be helpful. While it appears to serve as a lower bound on cumulative violation, further explanation would be appreciated.
It would also be interesting to explore whether the results presented in the paper can be extended to online mirrored descent, as no obvious obstacles are apparent. Some commentary on this topic would be welcome.
Finally, the experimental work presented is somewhat limited, and expanding on this aspect would strengthen the paper.