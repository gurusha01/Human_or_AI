[UPDATE AFTER AUTHOR RESPONSE]
The authors' response has reaffirmed my initial assessment, and I remain convinced that this is a valuable contribution to the field. I am hopeful that the authors will successfully address the concerns raised by myself and other reviewers in their revised manuscript.
[ORIGINAL REVIEW]
This paper presents YASS: Yet Another Spike Sorter, a meticulously designed pipeline for sorting multi-electrode array (MEA) recordings. By integrating multiple state-of-the-art approaches, the authors have created a comprehensive pipeline. The manuscript is well-structured and clearly written, providing compelling evidence that the work represents a significant advancement in the field of sorting retinal MEA data.
Although the paper is already a notable contribution in its current form, I believe it has the potential to be even more impactful if the authors address several key issues outlined below. My primary concerns can be summarized as follows:
(1) the absence of publicly accessible code,
(2) the inadequate description of the neural network-based detection method,
(3) the limitations of applying the pipeline to cortical data.
Detailed discussion:
(1) The manuscript does not provide access to the code, which is a significant limitation. As spike sorting has become largely an engineering challenge, a detailed description of the approach is only half as valuable as the actual implementation. Therefore, I strongly encourage the authors to make the code publicly available to enhance the paper's value.
(2) The neural network-based spike detection method is the most innovative aspect of the pipeline, but its description is unclear. Specifically, the authors do not provide sufficient information on how they generated the training data. Section C.2 outlines various methods for generating training data, but it is unclear which approach (or combination thereof) was used.
(a) Utilizing pre-existing sorted data raises several concerns. Firstly, most laboratories lack properly sorted data when transitioning to dense MEAs, as they often do not have a suitable pipeline for sorting such data. Secondly, it is unclear how existing sorts can be used to train a more robust neural network for detection. The authors should provide more information on their methodology, including how they labeled waveform snippets as clean or not, and how they addressed potential misalignments and label noise.
(b) Generating synthetic training data by superimposing waveform templates on background noise is an alternative approach. However, it is unclear whether this method is used for data augmentation or simply described as a potential alternative. The authors should provide evidence supporting the effectiveness of this approach and address concerns regarding the representativeness of synthetic data.
(3) The pipeline's generalizability to cortical data is a concern. While it may perform well on retinal data, I doubt its effectiveness on cortical data due to the following reasons:
(a) Waveform drift is a significant issue in non-chronic cortical recordings, and modeling drift is essential for longer recordings.
(b) Obtaining good training data for the neural network-based detection method is more challenging. Generating synthetic data may not be realistic due to the complex nature of background noise and correlated neural activity.
Minor comments:
- The y-axis in the bottom panel of Figure 3 is unusual, and the notation "1^-x" is unclear. Additionally, the figure exaggerates minor accuracy differences between 0.99 and 0.999, where both methods are essentially perfect.
- The authors mention using spatially whitened data (Section 2.1), but a detailed description of the spatial whitening procedure is not provided in the manuscript or supplement.