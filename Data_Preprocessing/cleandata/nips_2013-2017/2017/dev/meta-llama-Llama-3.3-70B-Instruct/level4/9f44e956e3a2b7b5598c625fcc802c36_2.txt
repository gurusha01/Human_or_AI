This paper investigates the issue of active hypothesis testing under conditions of limited information. Specifically, it considers a scenario where the probability of 'correct indication', denoted as q(j,w), is bounded below by α(w) for all j, given that the true hypothesis is j and the chosen action is w, with α(w) being available to the controller. The authors initially examine the incomplete-Bayesian update rule, which approximates q's with α's, and demonstrate that achieving a (1-δ) posterior error probability using this rule requires at least O(log(1/δ)) samples. Furthermore, they show that their gradient-based policy achieves an order-wise optimal sample complexity.
Several technical questions arise from this work. 
Regarding the upper bound: The authors assert that the upper bound is derived by assuming the worst-case scenario where q(w,j) equals α(w) for every w when j is the true hypothesis. However, this raises the question of how the analysis in this paper differs from that of the Bayesian update case, given that q(w,j) = α(w) seems to imply that the incomplete-Bayesian update rule is equivalent to the Bayesian update rule. Additionally, in realistic scenarios where q(w,j) approaches 1 and α(w) approaches 1/2, it is unclear whether the upper bound provides any meaningful guarantees.
Concerning the lower bound: It would be beneficial to know whether this bound can recover existing lower bounds for the case of complete information. 
Regarding the simulation results: It would be insightful if the authors could present the lower and upper bounds on E[T] and compare them with the simulation results to provide a more comprehensive understanding of the policy's performance.