In this manuscript, the authors propose an approach to estimate m weighted automata using spectral learning algorithms applied to the associated Hankel tensor, specifically employing rank factorization via SVD. This factorization is then utilized to learn individual functions. The following points warrant discussion: 
Is the application of SVD-based factorization to the Hankel tensor a novel contribution of this work?
The introduction of the relatedness measure tau in Definition 2 lacks clarity. What motivated this specific definition, and how does it relate to other quantities within the paper? Elucidation on the purpose of defining tau, particularly in relation to the choice of common rank R, would be beneficial.
It was anticipated that the benefits of jointly estimating multiple functions would be evident through the dependence of error measures on tau, potentially in an expanded version of Theorem 5 or in terms of computational complexity. However, the computational complexity appears to be worse than estimating individual WFAs separately. Can the relatedness between WFAs not be leveraged to improve this? A more general version of Theorem 5 would be enlightening, especially to explore how minimal relatedness between WFAs impacts performance. In simulations, scenarios where dS is 0 or less than dT could provide valuable insights. It is concerning that even when commonality exists, if dS and dT are equal, MT-SL offers no benefit over simple SL.
Regarding the benefits of multiple learning for maximally related WFAs, the authors note that the estimation error for a sufficient number of tasks would be O(T^2) compared to O(T) for individual learning, where T is || E ||F/sR(H). However, it is unclear why O(T^2) would be considered an improvement over O(T); is it implied that T is less than or equal to 1?