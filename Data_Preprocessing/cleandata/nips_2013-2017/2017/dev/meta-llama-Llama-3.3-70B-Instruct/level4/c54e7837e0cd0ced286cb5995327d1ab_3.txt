This study represents a significant advancement in enhancing the SGD training of Neural Networks.
One observation worth noting is that the composition of the renormalizing moving-average affine transformation A(r,d) and the output affine transformation A(beta,gamma), as outlined in Algorithm 1 on page 4, itself constitutes an affine transformation. Consequently, it is possible to encapsulate the (r,d) transformation within a redefined (beta, gamma), effectively rendering the renormalization as a modification to the training algorithm for (beta, gamma).