This manuscript introduces a novel memory-augmented generative model that facilitates stochastic, discrete memory addressing by treating the memory as a non-parametric conditional mixture distribution. The proposed variational memory addressing framework enables the integration of discrete memory addressing variables with continuous latent variables, allowing for effective sample generation even with limited memory samples, which is particularly beneficial for few-shot learning scenarios. The authors have implemented a Variational Autoencoder (VAE) version of their model and evaluated its performance on few-shot recognition tasks using the Omniglot dataset, where it demonstrates significant superiority over the existing Generative Matching Networks, a memory-augmented network model. Further examination reveals that the proposed model successfully accesses the relevant portions of the memory even when confronted with hundreds of unseen instances.
Strengths:
- The concept of performing discrete, stochastic memory addressing for memory-augmented generative models is innovative and well-founded, with the authors providing a compelling rationale for its superiority over the soft attention approach.
- The proposed variational addressing scheme has been shown to be effective in few-shot learning scenarios, outperforming existing soft-attention models in cases where they fail.
- The method of interpreting memory usage through KL divergence appears to be a useful tool.
Weaknesses:
- A limitation of the study is that the experimental analysis is confined to character data, albeit on standard datasets. The inclusion of experimental results on other data types, such as images, and comparisons or integrations with recent generative models like Generative Adversarial Networks (GANs) would enhance the paper.
In summary, this is a well-crafted paper that presents a novel and functional idea, effectively addressing the shortcomings of existing soft-attention memory addressing models and demonstrating its efficacy in few-shot learning. Therefore, I recommend accepting this paper.
- Noted typos and suggestions for correction:
Line 104: "unconditioneal" should be replaced with "unconditional".
Line 135: The word "of" is missing between "context" and "supervised".
Line 185: "eachieving" should be corrected to "achieving".
Table 1 requires a label "number of shots" for the values 1, 2, 3, 4, 5, 10, and 19.