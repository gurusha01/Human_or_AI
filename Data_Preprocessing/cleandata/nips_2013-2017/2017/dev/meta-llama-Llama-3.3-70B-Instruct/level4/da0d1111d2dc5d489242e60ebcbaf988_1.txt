This manuscript explores online convex optimization in the presence of time-varying constraints, aiming to minimize regret while maintaining a well-bounded average violation of stochastic constraints. The authors tackle this problem in both fixed and stochastic settings, deriving optimal bounds of $\sqrt{T} \log T$ on regret and constraint violation under mild conditions, thus improving upon the existing $T^{3/4}$ bound on constraint violation. Preliminary experiments on a stochastic job scheduler support their theoretical findings.
The addressed problem is intriguing and well-motivated, despite being previously explored in various forms. However, this work demonstrates significant advancements over current bounds on regret and constraint violation. The paper's presentation is generally clear, and the contributions are contextualized within the existing literature, with a suitable survey of related work. The writing quality is reasonable, with a well-structured narrative and appropriate language use. From a technical standpoint, the paper appears sound, with proofs seeming correct based on initial sanity checks, although a more thorough examination of the appendix is warranted during the rebuttal period.
In summary, this work offers a novel perspective on online linear optimization with constraints, necessitating a distinct analytical approach. While the feedback setup could benefit from additional motivation, the core idea of analyzing long-term constraint violations as an alternative to costly projections in online learning is sufficiently interesting and motivated, presenting a compelling contribution to the field.