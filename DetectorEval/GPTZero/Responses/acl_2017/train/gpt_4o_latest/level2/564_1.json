{
    "version": "2025-01-09-base",
    "scanId": "8894e2be-8a39-4b70-8b32-d7a3a307cda5",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999995231628418,
                    "sentence": "Review of the Paper: \"Grid Beam Search (GBS) for Lexically Constrained Decoding\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999997019767761,
                    "sentence": "Summary and Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999999463558197,
                    "sentence": "This paper introduces Grid Beam Search (GBS), a novel extension of beam search that incorporates pre-specified lexical constraints into sequence generation tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999991655349731,
                    "sentence": "The proposed method is model-agnostic and can be applied to any system that generates sequences token-by-token, such as neural machine translation (NMT), automatic summarization, and dialog generation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982714653015,
                    "sentence": "The key contributions of the paper are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998152256012,
                    "sentence": "1. Algorithmic Innovation: GBS organizes decoding into a grid structure, enabling the inclusion of lexical constraints without modifying model parameters or training data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "This is a significant advancement over traditional beam search.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999989867210388,
                    "sentence": "2. Practical Applications: The paper demonstrates the utility of GBS in two scenarios: (a) interactive post-editing for machine translation (MT), where user corrections are incorporated iteratively, and (b) domain adaptation, where domain-specific terminology is enforced during decoding.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999991655349731,
                    "sentence": "3. Experimental Results: The authors show that GBS achieves substantial improvements in BLEU scores across multiple language pairs in both interactive and domain adaptation settings, with gains exceeding 20 BLEU points in iterative post-editing and up to 14 BLEU points in domain adaptation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999992251396179,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999993443489075,
                    "sentence": "1. Generality and Flexibility: The method is highly generalizable, as it can be applied to any sequence generation model without requiring architectural changes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998927116394,
                    "sentence": "This makes it widely applicable across various NLP tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999991655349731,
                    "sentence": "2. Significant Performance Gains: The experimental results are compelling, demonstrating substantial improvements in translation quality, particularly in interactive settings and domain adaptation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999985694885254,
                    "sentence": "The use of automatically generated terminologies further highlights the practicality of the approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999990463256836,
                    "sentence": "3. Reproducibility: The paper provides detailed pseudo-code for the GBS algorithm and outlines the experimental setup, making the work reproducible.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999992251396179,
                    "sentence": "4. Novelty: The approach is innovative, as it extends beam search to handle arbitrary multi-token constraints, a feature not present in existing decoding methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999989867210388,
                    "sentence": "The ability to handle discontinuous lexical constraints and subword units is particularly noteworthy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999994039535522,
                    "sentence": "5. Efficiency Considerations: The authors address the computational complexity of GBS and propose parallelization strategies to mitigate the increased runtime, which demonstrates thoughtful engineering.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999992251396179,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999999463558197,
                    "sentence": "1. Limited Scope of Evaluation: While the paper focuses on MT, it lacks experiments on other sequence generation tasks such as summarization or dialog generation, despite claiming general applicability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998927116394,
                    "sentence": "This limits the demonstrated impact of the method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998160600662231,
                    "sentence": "2. Scalability Concerns: The runtime complexity of GBS (O(ktc)) is higher than standard beam search (O(kt)), and while parallelization is suggested, no empirical runtime analysis is provided.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999194741249084,
                    "sentence": "This raises concerns about scalability for large-scale applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998506307601929,
                    "sentence": "3. Baseline Comparisons: The paper does not compare GBS against other recent methods for constrained decoding, such as soft constraint-aware models or prefix-based decoding.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994938373565674,
                    "sentence": "This omission makes it difficult to assess the relative advantages of GBS.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998756647109985,
                    "sentence": "4. User Simulation Assumptions: The interactive post-editing experiments rely on simulated user inputs, which may not fully capture real-world user behavior.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997330904006958,
                    "sentence": "This could affect the generalizability of the results to practical settings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99759840965271,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995995163917542,
                    "sentence": "1. Have you considered evaluating GBS on tasks beyond MT, such as summarization or dialog generation, to validate its general applicability?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.998640239238739,
                    "sentence": "2. Can you provide a runtime analysis or empirical benchmarks to demonstrate the efficiency of GBS compared to standard beam search?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9977770447731018,
                    "sentence": "3. How does GBS perform when compared to other constrained decoding methods, such as prefix-based decoding or soft constraint-aware models?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.997866153717041,
                    "sentence": "Additional Comments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984914064407349,
                    "sentence": "Overall, this paper presents a significant contribution to the field of constrained decoding.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9962124228477478,
                    "sentence": "While the method is innovative and shows strong results in MT, broader evaluation and runtime analysis would strengthen its impact.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974575638771057,
                    "sentence": "I encourage the authors to explore additional tasks and provide more comprehensive comparisons in future work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 0.9984800378301695,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984800378301695,
                "mixed": 0.0015199621698304396
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984800378301695,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984800378301695,
                    "human": 0,
                    "mixed": 0.0015199621698304396
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Review of the Paper: \"Grid Beam Search (GBS) for Lexically Constrained Decoding\"\nSummary and Contributions\nThis paper introduces Grid Beam Search (GBS), a novel extension of beam search that incorporates pre-specified lexical constraints into sequence generation tasks. The proposed method is model-agnostic and can be applied to any system that generates sequences token-by-token, such as neural machine translation (NMT), automatic summarization, and dialog generation. The key contributions of the paper are:\n1. Algorithmic Innovation: GBS organizes decoding into a grid structure, enabling the inclusion of lexical constraints without modifying model parameters or training data. This is a significant advancement over traditional beam search.\n2. Practical Applications: The paper demonstrates the utility of GBS in two scenarios: (a) interactive post-editing for machine translation (MT), where user corrections are incorporated iteratively, and (b) domain adaptation, where domain-specific terminology is enforced during decoding.\n3. Experimental Results: The authors show that GBS achieves substantial improvements in BLEU scores across multiple language pairs in both interactive and domain adaptation settings, with gains exceeding 20 BLEU points in iterative post-editing and up to 14 BLEU points in domain adaptation.\nStrengths\n1. Generality and Flexibility: The method is highly generalizable, as it can be applied to any sequence generation model without requiring architectural changes. This makes it widely applicable across various NLP tasks.\n2. Significant Performance Gains: The experimental results are compelling, demonstrating substantial improvements in translation quality, particularly in interactive settings and domain adaptation. The use of automatically generated terminologies further highlights the practicality of the approach.\n3. Reproducibility: The paper provides detailed pseudo-code for the GBS algorithm and outlines the experimental setup, making the work reproducible.\n4. Novelty: The approach is innovative, as it extends beam search to handle arbitrary multi-token constraints, a feature not present in existing decoding methods. The ability to handle discontinuous lexical constraints and subword units is particularly noteworthy.\n5. Efficiency Considerations: The authors address the computational complexity of GBS and propose parallelization strategies to mitigate the increased runtime, which demonstrates thoughtful engineering.\nWeaknesses\n1. Limited Scope of Evaluation: While the paper focuses on MT, it lacks experiments on other sequence generation tasks such as summarization or dialog generation, despite claiming general applicability. This limits the demonstrated impact of the method.\n2. Scalability Concerns: The runtime complexity of GBS (O(ktc)) is higher than standard beam search (O(kt)), and while parallelization is suggested, no empirical runtime analysis is provided. This raises concerns about scalability for large-scale applications.\n3. Baseline Comparisons: The paper does not compare GBS against other recent methods for constrained decoding, such as soft constraint-aware models or prefix-based decoding. This omission makes it difficult to assess the relative advantages of GBS.\n4. User Simulation Assumptions: The interactive post-editing experiments rely on simulated user inputs, which may not fully capture real-world user behavior. This could affect the generalizability of the results to practical settings.\nQuestions to Authors\n1. Have you considered evaluating GBS on tasks beyond MT, such as summarization or dialog generation, to validate its general applicability?\n2. Can you provide a runtime analysis or empirical benchmarks to demonstrate the efficiency of GBS compared to standard beam search?\n3. How does GBS perform when compared to other constrained decoding methods, such as prefix-based decoding or soft constraint-aware models?\nAdditional Comments\nOverall, this paper presents a significant contribution to the field of constrained decoding. While the method is innovative and shows strong results in MT, broader evaluation and runtime analysis would strengthen its impact. I encourage the authors to explore additional tasks and provide more comprehensive comparisons in future work."
        }
    ]
}