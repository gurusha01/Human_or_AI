{
    "version": "2025-01-09-base",
    "scanId": "640e74bc-6283-4d80-9efa-d7b8dbced635",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999873638153076,
                    "sentence": "Review of the Submission",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999836683273315,
                    "sentence": "Summary and Contributions:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999984085559845,
                    "sentence": "This paper introduces an adversarial multi-criteria learning framework for Chinese Word Segmentation (CWS), leveraging shared knowledge across heterogeneous segmentation criteria.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999871850013733,
                    "sentence": "The authors propose three shared-private models (parallel, stacked, and skip-layer architectures) under a multi-task learning paradigm and incorporate adversarial training to enforce the extraction of criteria-invariant features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999745488166809,
                    "sentence": "The study is validated on eight datasets, representing the largest number of heterogeneous corpora used simultaneously for CWS.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999849796295166,
                    "sentence": "The results demonstrate significant improvements over baseline methods, with adversarial training providing additional performance gains.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999818801879883,
                    "sentence": "The paper also explores the transferability of shared features between simplified and traditional Chinese, showing modest improvements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999879002571106,
                    "sentence": "Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958872795105,
                    "sentence": "1. Innovative Multi-Criteria Learning Approach:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999957084655762,
                    "sentence": "The introduction of adversarial multi-criteria learning for CWS is novel and addresses the challenge of leveraging heterogeneous segmentation criteria.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960660934448,
                    "sentence": "The use of adversarial training to enforce criteria-invariant feature extraction is particularly promising and demonstrates the potential for cross-dataset generalization.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958276748657,
                    "sentence": "2. Empirical Performance Gains:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999945163726807,
                    "sentence": "The proposed models achieve consistent improvements across eight datasets, with notable gains in F-measure scores and out-of-vocabulary (OOV) word handling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999902844429016,
                    "sentence": "The inclusion of adversarial training further enhances performance, particularly in cases where shared parameters might otherwise introduce noise.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999905824661255,
                    "sentence": "3. Comprehensive Experimental Setup:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999942183494568,
                    "sentence": "The study employs eight diverse datasets, making it one of the most extensive evaluations of CWS methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999924302101135,
                    "sentence": "The detailed error analysis and investigation into the interplay between simplified and traditional Chinese add depth to the evaluation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967217445374,
                    "sentence": "Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999950528144836,
                    "sentence": "1. Lack of Comparison with CWS-Specific Models:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999883770942688,
                    "sentence": "The reliance on baseline methods (Bi-LSTM and stacked Bi-LSTM) designed for part-of-speech (POS) and named entity (NE) tagging is a significant limitation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999465346336365,
                    "sentence": "The absence of comparisons with state-of-the-art CWS-specific models undermines the claim of superiority and leaves the broader impact of the proposed approach unclear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999533295631409,
                    "sentence": "2. Unclear Experimental Purpose in Section 6.4:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999266266822815,
                    "sentence": "The methodology in Section 6.4, where shared parameters are fixed after training on simplified Chinese datasets, is not well-justified.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999150633811951,
                    "sentence": "The rationale for fixing parameters and its implications for model performance are inadequately explained, raising concerns about the validity of the reported improvements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999175071716309,
                    "sentence": "3. Limited Discussion on Adversarial Training Limitations:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999225735664368,
                    "sentence": "While adversarial training is shown to improve performance, the paper lacks a thorough discussion on why its impact varies across datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999657154083252,
                    "sentence": "For instance, the gains are modest in some cases, and the potential trade-offs (e.g., increased training time) are not sufficiently addressed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999299645423889,
                    "sentence": "Questions to Authors:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999880790710449,
                    "sentence": "1. Why were comparisons with state-of-the-art CWS-specific models omitted?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999899864196777,
                    "sentence": "Could such comparisons provide a clearer picture of the proposed method's effectiveness?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999865293502808,
                    "sentence": "2. In Section 6.4, why were shared parameters fixed after training on simplified Chinese datasets?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999867081642151,
                    "sentence": "How does this approach align with the goal of multi-criteria learning?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999577403068542,
                    "sentence": "3. Could the authors elaborate on why adversarial training does not consistently enhance performance across datasets?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999687075614929,
                    "sentence": "Are there specific characteristics of certain datasets that limit its effectiveness?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999433159828186,
                    "sentence": "Conclusion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999839663505554,
                    "sentence": "This paper presents a novel and promising approach to multi-criteria learning for CWS, supported by extensive experimentation and performance improvements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999975860118866,
                    "sentence": "However, the lack of comparisons with CWS-specific baselines and unclear methodological choices in some sections weaken the overall impact.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999653697013855,
                    "sentence": "Addressing these issues could significantly strengthen the paper's contributions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 0.9954476479514417,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9954476479514417,
                "mixed": 0.004552352048558421
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9954476479514417,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9954476479514417,
                    "human": 0,
                    "mixed": 0.004552352048558421
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Review of the Submission\nSummary and Contributions: \nThis paper introduces an adversarial multi-criteria learning framework for Chinese Word Segmentation (CWS), leveraging shared knowledge across heterogeneous segmentation criteria. The authors propose three shared-private models (parallel, stacked, and skip-layer architectures) under a multi-task learning paradigm and incorporate adversarial training to enforce the extraction of criteria-invariant features. The study is validated on eight datasets, representing the largest number of heterogeneous corpora used simultaneously for CWS. The results demonstrate significant improvements over baseline methods, with adversarial training providing additional performance gains. The paper also explores the transferability of shared features between simplified and traditional Chinese, showing modest improvements.\nStrengths: \n1. Innovative Multi-Criteria Learning Approach: \n The introduction of adversarial multi-criteria learning for CWS is novel and addresses the challenge of leveraging heterogeneous segmentation criteria. The use of adversarial training to enforce criteria-invariant feature extraction is particularly promising and demonstrates the potential for cross-dataset generalization.\n2. Empirical Performance Gains: \n The proposed models achieve consistent improvements across eight datasets, with notable gains in F-measure scores and out-of-vocabulary (OOV) word handling. The inclusion of adversarial training further enhances performance, particularly in cases where shared parameters might otherwise introduce noise.\n3. Comprehensive Experimental Setup: \n The study employs eight diverse datasets, making it one of the most extensive evaluations of CWS methods. The detailed error analysis and investigation into the interplay between simplified and traditional Chinese add depth to the evaluation.\nWeaknesses: \n1. Lack of Comparison with CWS-Specific Models: \n The reliance on baseline methods (Bi-LSTM and stacked Bi-LSTM) designed for part-of-speech (POS) and named entity (NE) tagging is a significant limitation. The absence of comparisons with state-of-the-art CWS-specific models undermines the claim of superiority and leaves the broader impact of the proposed approach unclear.\n2. Unclear Experimental Purpose in Section 6.4: \n The methodology in Section 6.4, where shared parameters are fixed after training on simplified Chinese datasets, is not well-justified. The rationale for fixing parameters and its implications for model performance are inadequately explained, raising concerns about the validity of the reported improvements.\n3. Limited Discussion on Adversarial Training Limitations: \n While adversarial training is shown to improve performance, the paper lacks a thorough discussion on why its impact varies across datasets. For instance, the gains are modest in some cases, and the potential trade-offs (e.g., increased training time) are not sufficiently addressed.\nQuestions to Authors: \n1. Why were comparisons with state-of-the-art CWS-specific models omitted? Could such comparisons provide a clearer picture of the proposed method's effectiveness? \n2. In Section 6.4, why were shared parameters fixed after training on simplified Chinese datasets? How does this approach align with the goal of multi-criteria learning? \n3. Could the authors elaborate on why adversarial training does not consistently enhance performance across datasets? Are there specific characteristics of certain datasets that limit its effectiveness?\nConclusion: \nThis paper presents a novel and promising approach to multi-criteria learning for CWS, supported by extensive experimentation and performance improvements. However, the lack of comparisons with CWS-specific baselines and unclear methodological choices in some sections weaken the overall impact. Addressing these issues could significantly strengthen the paper's contributions."
        }
    ]
}