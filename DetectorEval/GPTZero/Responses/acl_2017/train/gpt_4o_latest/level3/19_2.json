{
    "version": "2025-01-09-base",
    "scanId": "d990b5bb-40b8-49ee-9b5c-a0dbdba40132",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999774694442749,
                    "sentence": "Review of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999966621398926,
                    "sentence": "Summary and Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999875426292419,
                    "sentence": "This paper addresses the challenge of zero pronoun (ZP) resolution in Chinese by proposing a novel approach that generates large-scale pseudo training data from unlabeled documents, inspired by cloze-style reading comprehension tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999876022338867,
                    "sentence": "The authors integrate this data into an attention-based neural network (NN) architecture and employ a two-step training mechanism\"\"pre-training on pseudo data followed by fine-tuning on task-specific data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999797940254211,
                    "sentence": "The proposed method achieves state-of-the-art results, with a 3.1% improvement in F-score on the OntoNotes 5.0 dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999873638153076,
                    "sentence": "Key contributions include:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999733567237854,
                    "sentence": "1. A novel data generation approach for ZP resolution that does not rely on annotated corpora, making it scalable and cost-effective.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999415874481201,
                    "sentence": "2. A two-step training mechanism that bridges the gap between pseudo and real data, leveraging the strengths of both.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999653697013855,
                    "sentence": "3. The application of an attention-based NN model tailored for ZP resolution, outperforming prior feature-engineering-based methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999752640724182,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999824166297913,
                    "sentence": "1. Novelty and Scalability: The proposed pseudo-data generation approach is innovative and eliminates the reliance on expensive annotated datasets, making it a scalable solution for ZP resolution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999880194664001,
                    "sentence": "2. State-of-the-Art Results: The method achieves significant improvements over existing systems, demonstrating its effectiveness across multiple domains.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999733567237854,
                    "sentence": "3. Two-Step Training Mechanism: The pre-training-then-adaptation framework is well-motivated and empirically validated, showcasing its ability to leverage both pseudo and task-specific data effectively.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999805092811584,
                    "sentence": "4. Attention-Based Model: The use of attention mechanisms aligns well with the task's requirements, enabling the model to focus on relevant parts of the document.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999855756759644,
                    "sentence": "5. Comprehensive Evaluation: The paper provides detailed analyses of domain-specific performance, the impact of unknown word (UNK) processing, and the benefits of domain adaptation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999877214431763,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999963641166687,
                    "sentence": "1. Linguistic Motivation: The linguistic framing of the task is unconvincing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999465942382812,
                    "sentence": "Treating ZP resolution as a cloze-style reading comprehension problem oversimplifies the linguistic nuances of ZPs, such as their dependency on discourse-level context.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999260902404785,
                    "sentence": "2. Pseudo-Data Quality: The generated pseudo-data may not accurately represent true anaphoric ZP (AZP) instances and likely encodes selectional preferences, which could limit generalizability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999534487724304,
                    "sentence": "3. Interpretation of Results: The discussion of results lacks depth.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.998299241065979,
                    "sentence": "For example, the reasons for performance drops in the BN and TC domains are only superficially addressed, and no concrete solutions are proposed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986005425453186,
                    "sentence": "4. Proofreading and Terminology: The paper contains grammatical errors (e.g., lines 064\"\"068, line 565) and inconsistent terminology (e.g., AZP abbreviation in Section 3.3).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996359944343567,
                    "sentence": "These issues detract from the paper's overall clarity and professionalism.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989141821861267,
                    "sentence": "5. Evaluation on Gold-Annotated Data: The reliance on gold mentions for evaluation (lines 487\"\"489) is problematic, as it does not reflect real-world scenarios.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9971421360969543,
                    "sentence": "Experiments with system-generated mentions should be included for a more realistic assessment.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9962164759635925,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986697435379028,
                    "sentence": "1. How does the pseudo-data generation process ensure that the generated ZPs and antecedents are linguistically valid and representative of real-world ZP resolution tasks?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988308548927307,
                    "sentence": "2. Can the authors provide a more detailed analysis of the performance drops in the BN and TC domains?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9979496002197266,
                    "sentence": "For instance, how do the characteristics of these domains (e.g., oral style, longer documents) affect the model's attention mechanism?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990549087524414,
                    "sentence": "3. How does the model handle cases where the antecedent of a ZP is not explicitly mentioned in the document but is implied by the broader discourse context?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9912907481193542,
                    "sentence": "Additional Comments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986829161643982,
                    "sentence": "- Line 91: The term \"antecedent\" is misused and should be corrected for accuracy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9976126551628113,
                    "sentence": "- Line 506: The meaning of the dagger symbol (\" ) should be clarified, and statistical significance should be confirmed across all domains.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9978344440460205,
                    "sentence": "- References: Several entries contain capitalization errors and should be revised.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9978352189064026,
                    "sentence": "- The abbreviation AZP should be introduced early in the paper and used consistently throughout.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9965765476226807,
                    "sentence": "Recommendation",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986827969551086,
                    "sentence": "While the paper presents a novel and effective approach to ZP resolution, the weaknesses in linguistic motivation, pseudo-data quality, and result interpretation need to be addressed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987608194351196,
                    "sentence": "Additionally, proofreading and evaluation on system mentions are necessary for improving the paper's clarity and robustness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985125660896301,
                    "sentence": "I recommend acceptance with major revisions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 0.992329959936083,
            "class_probabilities": {
                "human": 0,
                "ai": 0.992329959936083,
                "mixed": 0.007670040063917
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.992329959936083,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.992329959936083,
                    "human": 0,
                    "mixed": 0.007670040063917
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Review of the Paper\nSummary and Contributions\nThis paper addresses the challenge of zero pronoun (ZP) resolution in Chinese by proposing a novel approach that generates large-scale pseudo training data from unlabeled documents, inspired by cloze-style reading comprehension tasks. The authors integrate this data into an attention-based neural network (NN) architecture and employ a two-step training mechanism\"\"pre-training on pseudo data followed by fine-tuning on task-specific data. The proposed method achieves state-of-the-art results, with a 3.1% improvement in F-score on the OntoNotes 5.0 dataset. Key contributions include:\n1. A novel data generation approach for ZP resolution that does not rely on annotated corpora, making it scalable and cost-effective.\n2. A two-step training mechanism that bridges the gap between pseudo and real data, leveraging the strengths of both.\n3. The application of an attention-based NN model tailored for ZP resolution, outperforming prior feature-engineering-based methods.\nStrengths\n1. Novelty and Scalability: The proposed pseudo-data generation approach is innovative and eliminates the reliance on expensive annotated datasets, making it a scalable solution for ZP resolution.\n2. State-of-the-Art Results: The method achieves significant improvements over existing systems, demonstrating its effectiveness across multiple domains.\n3. Two-Step Training Mechanism: The pre-training-then-adaptation framework is well-motivated and empirically validated, showcasing its ability to leverage both pseudo and task-specific data effectively.\n4. Attention-Based Model: The use of attention mechanisms aligns well with the task's requirements, enabling the model to focus on relevant parts of the document.\n5. Comprehensive Evaluation: The paper provides detailed analyses of domain-specific performance, the impact of unknown word (UNK) processing, and the benefits of domain adaptation.\nWeaknesses\n1. Linguistic Motivation: The linguistic framing of the task is unconvincing. Treating ZP resolution as a cloze-style reading comprehension problem oversimplifies the linguistic nuances of ZPs, such as their dependency on discourse-level context.\n2. Pseudo-Data Quality: The generated pseudo-data may not accurately represent true anaphoric ZP (AZP) instances and likely encodes selectional preferences, which could limit generalizability.\n3. Interpretation of Results: The discussion of results lacks depth. For example, the reasons for performance drops in the BN and TC domains are only superficially addressed, and no concrete solutions are proposed.\n4. Proofreading and Terminology: The paper contains grammatical errors (e.g., lines 064\"\"068, line 565) and inconsistent terminology (e.g., AZP abbreviation in Section 3.3). These issues detract from the paper's overall clarity and professionalism.\n5. Evaluation on Gold-Annotated Data: The reliance on gold mentions for evaluation (lines 487\"\"489) is problematic, as it does not reflect real-world scenarios. Experiments with system-generated mentions should be included for a more realistic assessment.\nQuestions to Authors\n1. How does the pseudo-data generation process ensure that the generated ZPs and antecedents are linguistically valid and representative of real-world ZP resolution tasks?\n2. Can the authors provide a more detailed analysis of the performance drops in the BN and TC domains? For instance, how do the characteristics of these domains (e.g., oral style, longer documents) affect the model's attention mechanism?\n3. How does the model handle cases where the antecedent of a ZP is not explicitly mentioned in the document but is implied by the broader discourse context?\nAdditional Comments\n- Line 91: The term \"antecedent\" is misused and should be corrected for accuracy.\n- Line 506: The meaning of the dagger symbol (\" ) should be clarified, and statistical significance should be confirmed across all domains.\n- References: Several entries contain capitalization errors and should be revised.\n- The abbreviation AZP should be introduced early in the paper and used consistently throughout.\nRecommendation\nWhile the paper presents a novel and effective approach to ZP resolution, the weaknesses in linguistic motivation, pseudo-data quality, and result interpretation need to be addressed. Additionally, proofreading and evaluation on system mentions are necessary for improving the paper's clarity and robustness. I recommend acceptance with major revisions."
        }
    ]
}