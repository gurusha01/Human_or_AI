{
    "version": "2025-01-09-base",
    "scanId": "759d51c3-e06d-4c2d-b2ab-393994d4a75e",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999896287918091,
                    "sentence": "Review of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999972581863403,
                    "sentence": "Summary and Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "This paper introduces a novel framework for Cross-Context Lexical Analysis (CCLA), which facilitates the study of term meaning and representation across varying contexts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973773956299,
                    "sentence": "The authors demonstrate the generality of their framework by applying it to three distinct tasks: (1) semantic change detection, (2) comparative lexical analysis over context, and (3) word embedding stability evaluation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999948740005493,
                    "sentence": "The framework is flexible, allowing for the use of any context definition, similarity function, or word annotation type, making it broadly applicable across NLP tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999959468841553,
                    "sentence": "The authors also provide publicly available code and datasets, which enhances reproducibility.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999901652336121,
                    "sentence": "The primary contributions of the paper, as I see them, are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994158744812,
                    "sentence": "1. General Framework for Cross-Context Analysis: The paper formalizes a flexible and general-purpose framework for analyzing lexical variation across contexts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999937415122986,
                    "sentence": "This is a significant contribution as it unifies multiple tasks under a single methodology.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999921321868896,
                    "sentence": "2. Applications to Diverse Tasks: The authors demonstrate the utility of CCLA in three distinct areas\"\"semantic change detection, context-sensitive term analysis, and word embedding stability evaluation\"\"highlighting the versatility of the framework.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999968409538269,
                    "sentence": "3. Evaluation of Word Embedding Stability: The paper introduces a novel approach to measure the stability of word embeddings across different random initializations using normalized discounted cumulative gain (NDCG).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999920725822449,
                    "sentence": "This is particularly useful for understanding the robustness of embedding methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963641166687,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967813491821,
                    "sentence": "1. Generality and Flexibility: The proposed framework is highly general and adaptable, accommodating various definitions of context, scoring functions, and word annotations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999949336051941,
                    "sentence": "This flexibility sets it apart from prior work, which often focuses on specific tasks or assumptions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999968409538269,
                    "sentence": "2. Comprehensive Experiments: The authors conduct thorough experiments across multiple datasets (e.g., IMDB, Yelp, COHA) and tasks, providing strong empirical evidence for the framework's utility.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999962449073792,
                    "sentence": "The inclusion of both qualitative and quantitative results enhances the paper's credibility.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973773956299,
                    "sentence": "3. Novel Insights into Word Embedding Stability: The use of CCLA to evaluate embedding stability is innovative and provides actionable insights, such as the potential for using stability as an early-stopping criterion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973177909851,
                    "sentence": "4. Reproducibility: The availability of code and datasets is a major strength, ensuring that the work can be easily reproduced and extended by the community.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967813491821,
                    "sentence": "5. Clarity of Presentation: The paper is well-structured, with clear explanations of the framework, its applications, and experimental results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999939203262329,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997260570526123,
                    "sentence": "1. Limited Novelty in Individual Applications: While the framework itself is novel, some of the individual applications (e.g., semantic change detection) rely on existing methods and do not introduce significant methodological advancements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999589204788208,
                    "sentence": "2. Scalability Concerns: The framework's reliance on nearest-neighbor computations and other similarity measures may pose scalability challenges for large datasets or high-dimensional embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988906383514404,
                    "sentence": "This is not addressed in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991496205329895,
                    "sentence": "3. Evaluation of Framework Generality: Although the framework is claimed to be general, the experiments focus on a narrow set of tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986233115196228,
                    "sentence": "Additional applications (e.g., framing bias analysis or event detection) would strengthen the claim of generality.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991300106048584,
                    "sentence": "4. Comparative Baselines: The paper does not compare CCLA directly against other general-purpose frameworks for lexical analysis, which makes it difficult to assess its relative advantages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993556141853333,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993789196014404,
                    "sentence": "1. How does the framework scale to larger datasets or higher-dimensional embeddings, particularly in terms of computational efficiency?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9982900023460388,
                    "sentence": "2. Can the framework handle contexts with highly imbalanced data distributions (e.g., one context having significantly more data than another)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999091625213623,
                    "sentence": "3. Have you considered extending the framework to multilingual or cross-lingual lexical analysis?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974751472473145,
                    "sentence": "If so, what challenges do you foresee?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9977347254753113,
                    "sentence": "Additional Comments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992246031761169,
                    "sentence": "The paper is a strong contribution to the field, particularly for its generality and flexibility.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995274543762207,
                    "sentence": "Addressing the scalability and generality concerns in future work would further enhance its impact.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984393119812012,
                    "sentence": "Overall, I recommend acceptance, provided the authors address the weaknesses and questions raised.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 0.9984800378301695,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984800378301695,
                "mixed": 0.0015199621698304396
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984800378301695,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984800378301695,
                    "human": 0,
                    "mixed": 0.0015199621698304396
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Review of the Paper\nSummary and Contributions\nThis paper introduces a novel framework for Cross-Context Lexical Analysis (CCLA), which facilitates the study of term meaning and representation across varying contexts. The authors demonstrate the generality of their framework by applying it to three distinct tasks: (1) semantic change detection, (2) comparative lexical analysis over context, and (3) word embedding stability evaluation. The framework is flexible, allowing for the use of any context definition, similarity function, or word annotation type, making it broadly applicable across NLP tasks. The authors also provide publicly available code and datasets, which enhances reproducibility.\nThe primary contributions of the paper, as I see them, are:\n1. General Framework for Cross-Context Analysis: The paper formalizes a flexible and general-purpose framework for analyzing lexical variation across contexts. This is a significant contribution as it unifies multiple tasks under a single methodology.\n2. Applications to Diverse Tasks: The authors demonstrate the utility of CCLA in three distinct areas\"\"semantic change detection, context-sensitive term analysis, and word embedding stability evaluation\"\"highlighting the versatility of the framework.\n3. Evaluation of Word Embedding Stability: The paper introduces a novel approach to measure the stability of word embeddings across different random initializations using normalized discounted cumulative gain (NDCG). This is particularly useful for understanding the robustness of embedding methods.\nStrengths\n1. Generality and Flexibility: The proposed framework is highly general and adaptable, accommodating various definitions of context, scoring functions, and word annotations. This flexibility sets it apart from prior work, which often focuses on specific tasks or assumptions.\n2. Comprehensive Experiments: The authors conduct thorough experiments across multiple datasets (e.g., IMDB, Yelp, COHA) and tasks, providing strong empirical evidence for the framework's utility. The inclusion of both qualitative and quantitative results enhances the paper's credibility.\n3. Novel Insights into Word Embedding Stability: The use of CCLA to evaluate embedding stability is innovative and provides actionable insights, such as the potential for using stability as an early-stopping criterion.\n4. Reproducibility: The availability of code and datasets is a major strength, ensuring that the work can be easily reproduced and extended by the community.\n5. Clarity of Presentation: The paper is well-structured, with clear explanations of the framework, its applications, and experimental results.\nWeaknesses\n1. Limited Novelty in Individual Applications: While the framework itself is novel, some of the individual applications (e.g., semantic change detection) rely on existing methods and do not introduce significant methodological advancements.\n2. Scalability Concerns: The framework's reliance on nearest-neighbor computations and other similarity measures may pose scalability challenges for large datasets or high-dimensional embeddings. This is not addressed in the paper.\n3. Evaluation of Framework Generality: Although the framework is claimed to be general, the experiments focus on a narrow set of tasks. Additional applications (e.g., framing bias analysis or event detection) would strengthen the claim of generality.\n4. Comparative Baselines: The paper does not compare CCLA directly against other general-purpose frameworks for lexical analysis, which makes it difficult to assess its relative advantages.\nQuestions to Authors\n1. How does the framework scale to larger datasets or higher-dimensional embeddings, particularly in terms of computational efficiency?\n2. Can the framework handle contexts with highly imbalanced data distributions (e.g., one context having significantly more data than another)?\n3. Have you considered extending the framework to multilingual or cross-lingual lexical analysis? If so, what challenges do you foresee?\nAdditional Comments\nThe paper is a strong contribution to the field, particularly for its generality and flexibility. Addressing the scalability and generality concerns in future work would further enhance its impact. Overall, I recommend acceptance, provided the authors address the weaknesses and questions raised."
        }
    ]
}