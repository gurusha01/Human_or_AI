{
    "version": "2025-01-09-base",
    "scanId": "f6b95ce3-1d3a-4e3a-84ec-2f90ea764270",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9979794025421143,
                    "sentence": "This paper introduces a neural sequence-to-sequence model designed to encode dialog contexts and subsequently decode system responses in open-domain conversations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974550604820251,
                    "sentence": "The authors propose a conditional variational autoencoder (CVAE), a deep neural network-based generative model, to learn latent variables that describe responses conditioned on dialog contexts and dialog acts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9983776211738586,
                    "sentence": "The proposed models demonstrate superior performance compared to the baseline RNN encoder-decoder model without latent variables, as evidenced by both quantitative and qualitative evaluations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999103844165802,
                    "sentence": "The paper is well-written, with clear explanations, theoretically grounded concepts, appropriate comparisons, and thorough analyses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987114667892456,
                    "sentence": "I have only a few minor comments, as outlined below:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994896054267883,
                    "sentence": "- Could the authors provide statistical significance testing for the results of the proposed models compared to the baseline in the quantitative evaluation?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995102882385254,
                    "sentence": "For some metrics, the differences appear relatively small.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992159605026245,
                    "sentence": "- Given the importance of dialog acts in the kgCVAE model, the performance of the DA tagging process likely impacts the quality of the final results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9982423782348633,
                    "sentence": "Would it be possible to achieve further improvements by employing a more advanced DA tagger?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9977213740348816,
                    "sentence": "Recent deep learning models have outperformed SVMs in DA tagging tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9971480369567871,
                    "sentence": "- Have the authors considered incorporating human evaluation as part of the qualitative analysis?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9958718419075012,
                    "sentence": "While potentially costly, this could provide a more pragmatic perspective on the results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9947777986526489,
                    "sentence": "- As a potential future direction, it might be interesting to explore the application of the kgCVAE model to task-oriented human-machine conversations, which typically offer richer linguistic features compared to open-domain conversations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9950040578842163,
                    "sentence": "- In Table 1, the term 'BLUE-1 recall' should be corrected to 'BLEU-1 recall'.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper introduces a neural sequence-to-sequence model designed to encode dialog contexts and subsequently decode system responses in open-domain conversations. The authors propose a conditional variational autoencoder (CVAE), a deep neural network-based generative model, to learn latent variables that describe responses conditioned on dialog contexts and dialog acts. The proposed models demonstrate superior performance compared to the baseline RNN encoder-decoder model without latent variables, as evidenced by both quantitative and qualitative evaluations.\nThe paper is well-written, with clear explanations, theoretically grounded concepts, appropriate comparisons, and thorough analyses. I have only a few minor comments, as outlined below:\n- Could the authors provide statistical significance testing for the results of the proposed models compared to the baseline in the quantitative evaluation? For some metrics, the differences appear relatively small.\n- Given the importance of dialog acts in the kgCVAE model, the performance of the DA tagging process likely impacts the quality of the final results. Would it be possible to achieve further improvements by employing a more advanced DA tagger? Recent deep learning models have outperformed SVMs in DA tagging tasks.\n- Have the authors considered incorporating human evaluation as part of the qualitative analysis? While potentially costly, this could provide a more pragmatic perspective on the results.\n- As a potential future direction, it might be interesting to explore the application of the kgCVAE model to task-oriented human-machine conversations, which typically offer richer linguistic features compared to open-domain conversations.\n- In Table 1, the term 'BLUE-1 recall' should be corrected to 'BLEU-1 recall'."
        }
    ]
}