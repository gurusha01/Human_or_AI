{
    "version": "2025-01-09-base",
    "scanId": "25a6358d-dcc0-4d5a-9d20-fdcdbfbd4a48",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9676902294158936,
                    "sentence": "This paper introduces a graph-based method for generating sense-disambiguated synonym sets from a collection of undisambiguated synonym sets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9424567818641663,
                    "sentence": "The authors validate their approach by deriving these synonym sets from Wiktionary and a collection of Russian dictionaries, subsequently evaluating pairwise synonymy relations (using precision, recall, and F1 scores) against WordNet and BabelNet for English synonym sets, and RuThes and Yet Another RussNet for Russian synonym sets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9458063840866089,
                    "sentence": "The paper is well-written and well-structured.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9376505613327026,
                    "sentence": "The experiments and evaluations, particularly their narrative descriptions, are straightforward to follow.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9021568894386292,
                    "sentence": "The proposed methodology is sound, and the analysis of the results is well-reasoned.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9383941888809204,
                    "sentence": "I appreciated that concerns I had while reading the paperᅳsuch as the vocabulary mismatch between the synonym dictionaries and gold standardsᅳwere addressed or resolved in the latter sections.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9207886457443237,
                    "sentence": "However, a significant concern is that the authors appear to have misunderstood some prior work, which undermines the stated motivation for their research.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.917818009853363,
                    "sentence": "The first instance of this misunderstanding occurs in the paragraph starting on line 064, where OmegaWiki is grouped with Wiktionary and Wikipedia as resources that are \"not formally structured\" and contain \"undisambiguated synonyms.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9090840220451355,
                    "sentence": "In reality, OmegaWiki differs from the other two by employing a formal structure (a relational database) based on word senses rather than orthographic forms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7588754892349243,
                    "sentence": "Consequently, translations, synonyms, and other semantic annotations in OmegaWiki are unambiguous.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8871789574623108,
                    "sentence": "The second, more critical misunderstanding appears in the paragraphs beginning on lines 092, 108, and 120.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8827089071273804,
                    "sentence": "The paper asserts that both BabelNet and UBY \"rely on English WordNet as a pivot for mapping existing resources\" and critiques this mapping as \"error-prone.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8566135764122009,
                    "sentence": "While it is accurate that BabelNet uses WordNet as a pivot, UBY does not.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9104164838790894,
                    "sentence": "UBY is a general-purpose framework for representing lexical-semantic resources and their interconnections.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8771512508392334,
                    "sentence": "It operates independently of any specific lexical-semantic resource (including WordNet) or alignment methodology (including those based on \"similarity of dictionary definitions\" or \"cross-lingual links\").",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7299522161483765,
                    "sentence": "UBY-compliant databases can include various lexical-semantic resources aligned using diverse methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7113746404647827,
                    "sentence": "While UBY databases can be queried for synsets, UBY itself does not generate them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6779319643974304,
                    "sentence": "Users can create their own databases by importing resources and alignments suited to their needs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7662692666053772,
                    "sentence": "Thus, the criticisms of UBY on lines 120-125 are misplaced.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.47856101393699646,
                    "sentence": "Moreover, at least one of the criticisms directed at BabelNet seems unwarranted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.4657112658023834,
                    "sentence": "The authors suggest that Watset may outperform BabelNet due to BabelNet's error-prone mapping and reliance on machine translation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7822874784469604,
                    "sentence": "This implies that Watset's method is error-free or significantly less error-prone, a claim that is overly ambitious and unsupported by the authors' own similarity-based sense linking and graph clustering algorithms, let alone by their experimental results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7330265045166016,
                    "sentence": "This critique should be moderated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.25522342324256897,
                    "sentence": "Additionally, the third criticism (BabelNet's reliance on WordNet as a pivot) misses the more pertinent issue: the key concern is not that the pivot is English, but that its synsets are already manually sense-annotated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.04572749137878418,
                    "sentence": "I recommend substantial revisions to the last paragraph of §1 and the first two paragraphs of §2.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.16436296701431274,
                    "sentence": "These sections should emphasize the general challenge of generating synsets through sense-level alignment or translation of lexical-semantic resources (see Gurevych et al., 2016 for a survey) rather than focusing narrowly on BabelNet (which employs specific methods) and UBY (which aggregates results from various methods).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.32832205295562744,
                    "sentence": "It would also be helpful to note that while alignment/translation methods can produce or enrich synsets, this is not always their explicit goalᅳsometimes it is merely a byproduct of aligning resources with differing granularities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6783419847488403,
                    "sentence": "Finally, the paper critiques the \"synsets\" of TWSI and JoBimText (lines 153, 433) for including hypernyms, co-hypernyms, etc., rather than synonyms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9105086922645569,
                    "sentence": "However, it is unclear whether this issue is unique to TWSI and JoBimText.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9885473847389221,
                    "sentence": "How frequently do hypernyms, co-hypernyms, etc., appear in Watset's output?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9581568241119385,
                    "sentence": "The comparison between Tables 3 and 5 provides only a vague sense of this.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9717356562614441,
                    "sentence": "If Watset is indeed better at filtering out non-synonymous relations, quantitative evidence should be provided.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9808380603790283,
                    "sentence": "Additional minor issues to address:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9886199831962585,
                    "sentence": "- Lines 047-049: The mention of Kiselev et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9915816187858582,
                    "sentence": "(2015) seems uninformative.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9810774922370911,
                    "sentence": "If their analysis is referenced, its findings should be briefly summarized.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9935019612312317,
                    "sentence": "- Line 091: The connection between \"wat\" and \"discover the correct word sense\" is unclear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.994389533996582,
                    "sentence": "If this is a pun on \"what,\" consider rewording the sentence for clarity or renaming the approach to something like \"Whatset.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.997887909412384,
                    "sentence": "- Figure 2: The font size is too small to read comfortably.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.997473418712616,
                    "sentence": "Please enlarge the text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9982178807258606,
                    "sentence": "- Tables 3, 4, and 5: These tables are also difficult to read due to their small font size.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9975426197052002,
                    "sentence": "Consider using a larger font and abbreviating headers (e.g., \"P,\" \"R,\" \"F1\").",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9973503351211548,
                    "sentence": "Reporting scores in the range 0-100 instead of 0-1 could save space by eliminating leading zeros.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9926300644874573,
                    "sentence": "- Lines 517-522: Since Wiktionary is a dynamic resource, specify the date of the database dump used to facilitate replication and comparison.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9821611642837524,
                    "sentence": "- Throughout: The inconsistent use of Times and Computer Modern fonts is distracting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.023892493918538094,
                    "sentence": "This issue stems from the ACL 2017 LaTeX style file but is exacerbated by the authors' use of math mode for numbers in running text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.01292679738253355,
                    "sentence": "To resolve this, replace",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.010184968821704388,
                    "sentence": "```latex",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.005283108912408352,
                    "sentence": "\\usepackage{times}",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.005906283855438232,
                    "sentence": "```",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.006039010360836983,
                    "sentence": "with either",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.013842086307704449,
                    "sentence": "```latex",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.003701453097164631,
                    "sentence": "\\usepackage{newtxtext}",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.005465943366289139,
                    "sentence": "\\usepackage{newtxmath}",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.0021377296652644873,
                    "sentence": "```",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.03484779968857765,
                    "sentence": "or",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.005522625520825386,
                    "sentence": "```latex",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.008332590572535992,
                    "sentence": "\\usepackage{mathptmx}",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.003104445291683078,
                    "sentence": "```",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.010252212174236774,
                    "sentence": "References:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.008095046505331993,
                    "sentence": "I. Gurevych, J. Eckle-Kohler, and M. Matuschek, 2016.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.004675670992583036,
                    "sentence": "Linked Lexical Knowledge Bases: Foundations and Applications, volume 34 of Synthesis Lectures on Human Language Technologies, chapter 3: Linking Algorithms, pages 29-44.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.002958254422992468,
                    "sentence": "Morgan & Claypool.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.0022521731443703175,
                    "sentence": "---",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.0036029936745762825,
                    "sentence": "I have reviewed the author response.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.45887534985363754
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 9,
                    "completely_generated_prob": 0.049853377340576883
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.00010005932717626924
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.6535213355143276
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.07332528267997859
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 59,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 63,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 64,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.759957522329871,
            "class_probabilities": {
                "human": 0.06761514067091441,
                "ai": 0.759957522329871,
                "mixed": 0.17242733699921445
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.759957522329871,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.759957522329871,
                    "human": 0.06761514067091441,
                    "mixed": 0.17242733699921445
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper introduces a graph-based method for generating sense-disambiguated synonym sets from a collection of undisambiguated synonym sets. The authors validate their approach by deriving these synonym sets from Wiktionary and a collection of Russian dictionaries, subsequently evaluating pairwise synonymy relations (using precision, recall, and F1 scores) against WordNet and BabelNet for English synonym sets, and RuThes and Yet Another RussNet for Russian synonym sets.\nThe paper is well-written and well-structured. The experiments and evaluations, particularly their narrative descriptions, are straightforward to follow. The proposed methodology is sound, and the analysis of the results is well-reasoned. I appreciated that concerns I had while reading the paper—such as the vocabulary mismatch between the synonym dictionaries and gold standards—were addressed or resolved in the latter sections.\nHowever, a significant concern is that the authors appear to have misunderstood some prior work, which undermines the stated motivation for their research.\nThe first instance of this misunderstanding occurs in the paragraph starting on line 064, where OmegaWiki is grouped with Wiktionary and Wikipedia as resources that are \"not formally structured\" and contain \"undisambiguated synonyms.\" In reality, OmegaWiki differs from the other two by employing a formal structure (a relational database) based on word senses rather than orthographic forms. Consequently, translations, synonyms, and other semantic annotations in OmegaWiki are unambiguous.\nThe second, more critical misunderstanding appears in the paragraphs beginning on lines 092, 108, and 120. The paper asserts that both BabelNet and UBY \"rely on English WordNet as a pivot for mapping existing resources\" and critiques this mapping as \"error-prone.\" While it is accurate that BabelNet uses WordNet as a pivot, UBY does not. UBY is a general-purpose framework for representing lexical-semantic resources and their interconnections. It operates independently of any specific lexical-semantic resource (including WordNet) or alignment methodology (including those based on \"similarity of dictionary definitions\" or \"cross-lingual links\"). UBY-compliant databases can include various lexical-semantic resources aligned using diverse methods. While UBY databases can be queried for synsets, UBY itself does not generate them. Users can create their own databases by importing resources and alignments suited to their needs. Thus, the criticisms of UBY on lines 120–125 are misplaced.\nMoreover, at least one of the criticisms directed at BabelNet seems unwarranted. The authors suggest that Watset may outperform BabelNet due to BabelNet's error-prone mapping and reliance on machine translation. This implies that Watset's method is error-free or significantly less error-prone, a claim that is overly ambitious and unsupported by the authors' own similarity-based sense linking and graph clustering algorithms, let alone by their experimental results. This critique should be moderated. Additionally, the third criticism (BabelNet's reliance on WordNet as a pivot) misses the more pertinent issue: the key concern is not that the pivot is English, but that its synsets are already manually sense-annotated.\nI recommend substantial revisions to the last paragraph of §1 and the first two paragraphs of §2. These sections should emphasize the general challenge of generating synsets through sense-level alignment or translation of lexical-semantic resources (see Gurevych et al., 2016 for a survey) rather than focusing narrowly on BabelNet (which employs specific methods) and UBY (which aggregates results from various methods). It would also be helpful to note that while alignment/translation methods can produce or enrich synsets, this is not always their explicit goal—sometimes it is merely a byproduct of aligning resources with differing granularities.\nFinally, the paper critiques the \"synsets\" of TWSI and JoBimText (lines 153, 433) for including hypernyms, co-hypernyms, etc., rather than synonyms. However, it is unclear whether this issue is unique to TWSI and JoBimText. How frequently do hypernyms, co-hypernyms, etc., appear in Watset's output? The comparison between Tables 3 and 5 provides only a vague sense of this. If Watset is indeed better at filtering out non-synonymous relations, quantitative evidence should be provided.\nAdditional minor issues to address:\n- Lines 047–049: The mention of Kiselev et al. (2015) seems uninformative. If their analysis is referenced, its findings should be briefly summarized.\n- Line 091: The connection between \"wat\" and \"discover the correct word sense\" is unclear. If this is a pun on \"what,\" consider rewording the sentence for clarity or renaming the approach to something like \"Whatset.\"\n- Figure 2: The font size is too small to read comfortably. Please enlarge the text.\n- Tables 3, 4, and 5: These tables are also difficult to read due to their small font size. Consider using a larger font and abbreviating headers (e.g., \"P,\" \"R,\" \"F1\"). Reporting scores in the range 0–100 instead of 0–1 could save space by eliminating leading zeros.\n- Lines 517–522: Since Wiktionary is a dynamic resource, specify the date of the database dump used to facilitate replication and comparison.\n- Throughout: The inconsistent use of Times and Computer Modern fonts is distracting. This issue stems from the ACL 2017 LaTeX style file but is exacerbated by the authors' use of math mode for numbers in running text. To resolve this, replace\n ```latex\n \\usepackage{times}\n ```\n with either\n ```latex\n \\usepackage{newtxtext}\n \\usepackage{newtxmath}\n ```\n or\n ```latex\n \\usepackage{mathptmx}\n ```\nReferences:\nI. Gurevych, J. Eckle-Kohler, and M. Matuschek, 2016. Linked Lexical Knowledge Bases: Foundations and Applications, volume 34 of Synthesis Lectures on Human Language Technologies, chapter 3: Linking Algorithms, pages 29–44. Morgan & Claypool.\n---\nI have reviewed the author response."
        }
    ]
}