{
    "version": "2025-01-09-base",
    "scanId": "3d61f5ee-fcbe-46e2-adaa-5e14ed225f2c",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9743642807006836,
                    "sentence": "- Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9522818326950073,
                    "sentence": "This paper introduces an iterative approach for inducing bilingual word embeddings from large monolingual corpora, starting with minimal (or automatically derived numeral) mappings between two languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8934341669082642,
                    "sentence": "In comparison to state-of-the-art methods that rely on larger bilingual dictionaries or parallel/comparable corpora, the proposed method achieves remarkable and impressive results while requiring little to no manually curated input.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9467370510101318,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8578835725784302,
                    "sentence": "The paper would benefit from a discussion of the method's errors and a consideration of potential adjustments to address these shortcomings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.984943151473999,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8772508502006531,
                    "sentence": "Does the frequency of the seed words in the monolingual corpora influence the results?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9157890677452087,
                    "sentence": "It would be valuable to observe the intermediate stages (e.g., after n iterations) of the mapping evolution between words in the two languages, particularly for a few specific examples.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8900303244590759,
                    "sentence": "How does the method handle different translations of the same word (e.g., words with multiple senses)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9113032221794128,
                    "sentence": "A notable distinction between German and English is the frequent use of compounds in German.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9386159777641296,
                    "sentence": "How are these compounds handled by the method?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8597056865692139,
                    "sentence": "What are they mapped to?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.927126407623291,
                    "sentence": "Would a preprocessing step, such as splitting compounds (potentially using corpus-internal unigram information), improve the results?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9224832057952881,
                    "sentence": "What is the theoretical upper bound for this approach?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8767982125282288,
                    "sentence": "An analysis of errors\"\"such as words that are mapped far from their counterparts in the other language\"\"would be highly insightful.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7409027814865112,
                    "sentence": "Additionally, a discussion on the origins of these errors and whether the proposed method could be adapted to mitigate them would enhance the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.45887534985363754
                }
            ],
            "completely_generated_prob": 0.706120647383059,
            "class_probabilities": {
                "human": 0.29372542799595996,
                "ai": 0.706120647383059,
                "mixed": 0.0001539246209811207
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.706120647383059,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.706120647383059,
                    "human": 0.29372542799595996,
                    "mixed": 0.0001539246209811207
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "- Strengths: \nThis paper introduces an iterative approach for inducing bilingual word embeddings from large monolingual corpora, starting with minimal (or automatically derived numeral) mappings between two languages. In comparison to state-of-the-art methods that rely on larger bilingual dictionaries or parallel/comparable corpora, the proposed method achieves remarkable and impressive results while requiring little to no manually curated input.\n- Weaknesses: \nThe paper would benefit from a discussion of the method's errors and a consideration of potential adjustments to address these shortcomings.\n- General Discussion: \nDoes the frequency of the seed words in the monolingual corpora influence the results? \nIt would be valuable to observe the intermediate stages (e.g., after n iterations) of the mapping evolution between words in the two languages, particularly for a few specific examples. \nHow does the method handle different translations of the same word (e.g., words with multiple senses)? \nA notable distinction between German and English is the frequent use of compounds in German. How are these compounds handled by the method? What are they mapped to? Would a preprocessing step, such as splitting compounds (potentially using corpus-internal unigram information), improve the results? \nWhat is the theoretical upper bound for this approach? An analysis of errors\"\"such as words that are mapped far from their counterparts in the other language\"\"would be highly insightful. Additionally, a discussion on the origins of these errors and whether the proposed method could be adapted to mitigate them would enhance the paper."
        }
    ]
}