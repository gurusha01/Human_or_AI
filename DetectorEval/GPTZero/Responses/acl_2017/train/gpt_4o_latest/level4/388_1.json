{
    "version": "2025-01-09-base",
    "scanId": "82667b1d-c07a-47e8-9eb8-9b24299eb01a",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9153217077255249,
                    "sentence": "This paper presents an intriguing and ambitious effort: the automated transformation of Universal Dependency (UD) grammar structures into what the authors term semantic logical form representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8688306212425232,
                    "sentence": "Essentially, the approach assigns a corresponding logical form construction to each UD construct and defines a conversion procedure that operates 'inside-out,' utilizing an intermediate representation to ensure proper nesting of substructures within their encapsulating structures.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7902582883834839,
                    "sentence": "The authors conduct two evaluations: one comparing the output to gold-standard lambda structures and another assessing the utility of the resulting lambda expressions in answering questions from two QA datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7416351437568665,
                    "sentence": "The limited space of the paper makes it difficult to fully describe the work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8092057704925537,
                    "sentence": "While the authors have made an effort to cover the key components, several important details are missing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.72959965467453,
                    "sentence": "A longer version of the paper would be highly desirable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7057295441627502,
                    "sentence": "In particular, the discussion of QA results feels underdeveloped; it would have been valuable to know which types of questions are not handled or answered incorrectly, along with explanations for these shortcomings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7135108113288879,
                    "sentence": "Such insights would provide a clearer understanding of the limitations of the proposed logical form representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6189417839050293,
                    "sentence": "This brings me to my primary concern.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7358018159866333,
                    "sentence": "The logical form representation proposed in the paper cannot be considered a truly semantic one.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5294216871261597,
                    "sentence": "It is essentially a close reformatting of the input dependency structure, with some commendable steps toward semanticization, such as the introduction of lambda operators, the explicit inclusion of dropped arguments (via enhancement), and the addition of appropriate types/units for constructions like eventive adjectives and nouns (e.g., \"running horse\" or \"president in 2009\").",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6110436320304871,
                    "sentence": "However, many fundamental aspects of semantics are either missing or incorrect.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.4911632537841797,
                    "sentence": "Missing elements include quantification (e.g., \"every\" or \"all\"), numerical expressions (e.g., \"20\" or \"just over 1000\"), various forms of reference (e.g., \"he,\" \"that man,\" or \"what I said before\"), negation and modals (which significantly alter semantics), and inter-event relationships (e.g., the subevent relationship in \"the vacation was nice, but traveling was a pain\").",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5892977714538574,
                    "sentence": "While one could superficially address these issues by treating such elements as unusual words and assigning simple lambda formulas, they require more nuanced handling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5755699872970581,
                    "sentence": "For instance, numerical expressions necessitate creating separate set objects in the representation, complete with canonical variables to enable proper referential binding (e.g., \"one of them\").",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.544501781463623,
                    "sentence": "Similarly, representing differing perspectives on an event (e.g., Person A's vs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.977573812007904,
                    "sentence": "Person B's interpretation) requires distinct symbols for the event, along with mechanisms to map and couple them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9856581687927246,
                    "sentence": "Temporal indexing of events and states is another critical aspect that is absent.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9875863790512085,
                    "sentence": "Addressing these challenges is non-trivial, as demonstrated by frameworks like DRT, which show the complexities of quantifier and referential scoping.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9902809262275696,
                    "sentence": "While it may seem unfair to criticize the paper for not addressing every possible semantic aspect, it is equally important to avoid making fundamental errors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9916813373565674,
                    "sentence": "A particularly troubling issue is the paper's treatment of event relations as strictly parallel to the syntactic roles of verbs or nouns.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9923892021179199,
                    "sentence": "For example, the semantic roles of \"he\" and \"the window\" in \"he broke the window\" and \"the window broke\" cannot be considered equivalent.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9941220283508301,
                    "sentence": "The paper's dismissal of this issue as something to be handled in subsequent semantic processing is unsatisfactory.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.980089545249939,
                    "sentence": "This problem requires proper acknowledgment and at least a preliminary solution, even within the scope of this work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9815036654472351,
                    "sentence": "For me, this is the critical flaw of the paper and a decisive factor in determining whether I would advocate for its acceptance at the conference.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9854016900062561,
                    "sentence": "I would have been more inclined to support the paper if the authors had explicitly acknowledged this limitation and outlined a plan for addressing it in future work, perhaps by referencing resources like FrameNet and its semantic role requirements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9772112369537354,
                    "sentence": "On a more positive note, the notation conversion procedure is relatively clear and well-explained.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9934934973716736,
                    "sentence": "I appreciate that it is cleaner and simpler than its predecessor (based on Stanford dependencies).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9901842474937439,
                    "sentence": "Additionally, I commend the authors for submitting non-neural work to ACL, particularly in an era dominated by enthusiasm for neural approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9951624870300293,
                    "sentence": "This demonstrates a refreshing commitment to exploring alternative methodologies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.45887534985363754
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.0022792978668507114
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 11,
                    "completely_generated_prob": 1.155233377079189e-05
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 7,
                    "completely_generated_prob": 0.9103421900070616
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                }
            ],
            "completely_generated_prob": 0.6901468531159954,
            "class_probabilities": {
                "human": 0.3045187780479302,
                "ai": 0.6901468531159954,
                "mixed": 0.005334368836074327
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.6901468531159954,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.6901468531159954,
                    "human": 0.3045187780479302,
                    "mixed": 0.005334368836074327
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents an intriguing and ambitious effort: the automated transformation of Universal Dependency (UD) grammar structures into what the authors term semantic logical form representations. Essentially, the approach assigns a corresponding logical form construction to each UD construct and defines a conversion procedure that operates 'inside-out,' utilizing an intermediate representation to ensure proper nesting of substructures within their encapsulating structures. The authors conduct two evaluations: one comparing the output to gold-standard lambda structures and another assessing the utility of the resulting lambda expressions in answering questions from two QA datasets.\nThe limited space of the paper makes it difficult to fully describe the work. While the authors have made an effort to cover the key components, several important details are missing. A longer version of the paper would be highly desirable. In particular, the discussion of QA results feels underdeveloped; it would have been valuable to know which types of questions are not handled or answered incorrectly, along with explanations for these shortcomings. Such insights would provide a clearer understanding of the limitations of the proposed logical form representations.\nThis brings me to my primary concern. The logical form representation proposed in the paper cannot be considered a truly semantic one. It is essentially a close reformatting of the input dependency structure, with some commendable steps toward semanticization, such as the introduction of lambda operators, the explicit inclusion of dropped arguments (via enhancement), and the addition of appropriate types/units for constructions like eventive adjectives and nouns (e.g., \"running horse\" or \"president in 2009\"). However, many fundamental aspects of semantics are either missing or incorrect. Missing elements include quantification (e.g., \"every\" or \"all\"), numerical expressions (e.g., \"20\" or \"just over 1000\"), various forms of reference (e.g., \"he,\" \"that man,\" or \"what I said before\"), negation and modals (which significantly alter semantics), and inter-event relationships (e.g., the subevent relationship in \"the vacation was nice, but traveling was a pain\"). While one could superficially address these issues by treating such elements as unusual words and assigning simple lambda formulas, they require more nuanced handling. For instance, numerical expressions necessitate creating separate set objects in the representation, complete with canonical variables to enable proper referential binding (e.g., \"one of them\"). Similarly, representing differing perspectives on an event (e.g., Person A's vs. Person B's interpretation) requires distinct symbols for the event, along with mechanisms to map and couple them. Temporal indexing of events and states is another critical aspect that is absent. Addressing these challenges is non-trivial, as demonstrated by frameworks like DRT, which show the complexities of quantifier and referential scoping.\nWhile it may seem unfair to criticize the paper for not addressing every possible semantic aspect, it is equally important to avoid making fundamental errors. A particularly troubling issue is the paper's treatment of event relations as strictly parallel to the syntactic roles of verbs or nouns. For example, the semantic roles of \"he\" and \"the window\" in \"he broke the window\" and \"the window broke\" cannot be considered equivalent. The paper's dismissal of this issue as something to be handled in subsequent semantic processing is unsatisfactory. This problem requires proper acknowledgment and at least a preliminary solution, even within the scope of this work. For me, this is the critical flaw of the paper and a decisive factor in determining whether I would advocate for its acceptance at the conference. I would have been more inclined to support the paper if the authors had explicitly acknowledged this limitation and outlined a plan for addressing it in future work, perhaps by referencing resources like FrameNet and its semantic role requirements.\nOn a more positive note, the notation conversion procedure is relatively clear and well-explained. I appreciate that it is cleaner and simpler than its predecessor (based on Stanford dependencies). Additionally, I commend the authors for submitting non-neural work to ACL, particularly in an era dominated by enthusiasm for neural approaches. This demonstrates a refreshing commitment to exploring alternative methodologies."
        }
    ]
}