{
    "version": "2025-01-09-base",
    "scanId": "103a18b0-9700-42dc-ae59-3b85462ea104",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9993263483047485,
                    "sentence": "This paper presents a rule-based method for extracting time expressions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9983171224594116,
                    "sentence": "The core idea is that time expressions are generally short and include at least one time-related token.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985616207122803,
                    "sentence": "The approach begins by identifying time tokens using a combination of dictionary lookups, regular expressions, and part-of-speech (POS) tagging.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.998134970664978,
                    "sentence": "It then expands the identified time segment in both directions from the time token based on a set of heuristic rules.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9980710744857788,
                    "sentence": "Finally, the method consolidates the expanded segments into a single time expression using another set of rules.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.998275637626648,
                    "sentence": "The evaluation of this approach against both rule-based and machine learning (ML) systems across three datasets demonstrates notable improvements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999233603477478,
                    "sentence": "- Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987872838973999,
                    "sentence": "The paper is well-written and clearly structured.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9977811574935913,
                    "sentence": "The proposed rules are grounded in empirical observations of the data and appear well-justified, as evidenced by the evaluation results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990018606185913,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989297986030579,
                    "sentence": "Some aspects of the methodology are underspecified, making it challenging to reproduce the results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991899728775024,
                    "sentence": "Specific details are outlined below.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996719360351562,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986960887908936,
                    "sentence": "* Section 4.1: Why are there five seasons?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984720349311829,
                    "sentence": "How are cases like Ramadan month or Holiday Season handled?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985297322273254,
                    "sentence": "* Section 5.1: Should \"two benchmark datasets\" be corrected to \"three datasets\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9983091950416565,
                    "sentence": "* Section 5.2: Including an example of a time expression without a time token would be helpful.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985579252243042,
                    "sentence": "* Section 5.2: Considering that 93% of time expressions contain a time token and the system achieves 92% recall, how do you plan to improve performance further, given the approach is nearing its performance ceiling?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987360835075378,
                    "sentence": "* Is there any intention to release the complete set of rules or the software used?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a rule-based method for extracting time expressions. The core idea is that time expressions are generally short and include at least one time-related token. The approach begins by identifying time tokens using a combination of dictionary lookups, regular expressions, and part-of-speech (POS) tagging. It then expands the identified time segment in both directions from the time token based on a set of heuristic rules. Finally, the method consolidates the expanded segments into a single time expression using another set of rules. The evaluation of this approach against both rule-based and machine learning (ML) systems across three datasets demonstrates notable improvements.\n- Strengths:\nThe paper is well-written and clearly structured. The proposed rules are grounded in empirical observations of the data and appear well-justified, as evidenced by the evaluation results.\n- Weaknesses:\nSome aspects of the methodology are underspecified, making it challenging to reproduce the results. Specific details are outlined below.\n- General Discussion:\n* Section 4.1: Why are there five seasons? How are cases like Ramadan month or Holiday Season handled? \n* Section 5.1: Should \"two benchmark datasets\" be corrected to \"three datasets\"? \n* Section 5.2: Including an example of a time expression without a time token would be helpful. \n* Section 5.2: Considering that 93% of time expressions contain a time token and the system achieves 92% recall, how do you plan to improve performance further, given the approach is nearing its performance ceiling? \n* Is there any intention to release the complete set of rules or the software used?"
        }
    ]
}