{
    "version": "2025-01-09-base",
    "scanId": "79871c7a-142b-4a39-93fc-ef98c4d69074",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9882985353469849,
                    "sentence": "This paper presents a straightforward extension to left-to-right beam search, enabling it to incorporate lexical constraints in the form of word sequences that must appear in the MT output.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9688911437988281,
                    "sentence": "The proposed algorithm is demonstrated to be effective for applications such as interactive translation and domain adaptation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.958392322063446,
                    "sentence": "While the extension itself is quite simple, the paper makes a valuable contribution by formalizing it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8810303211212158,
                    "sentence": "It is also noteworthy that NMT performs well with a set of unordered constraints that lack explicit alignment information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.915394127368927,
                    "sentence": "The technique described here appears to have potential applications beyond those explored in the paper, such as enhancing NMT's ability to handle non-compositional constructions\"\"an area where traditional SMT may still have an advantage.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8631740212440491,
                    "sentence": "The primary limitation of the paper lies in the somewhat restricted scope of the experiments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9281953573226929,
                    "sentence": "Although the interactive MT simulation confirms that the method functions as intended, it is challenging to assess the degree of success\"\"for example, how often the constraints were incorporated in an acceptable manner (the substantial BLEU score improvements provide only indirect evidence).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9437938332557678,
                    "sentence": "Likewise, the domain adaptation experiments would have been more robust if they included a comparison against the standard \"fine-tuning\" baseline, which could have been conducted relatively easily on the 100K Autodesk corpus.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8632311224937439,
                    "sentence": "Despite this limitation, I believe the paper represents a solid contribution and merits publication.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7950872182846069,
                    "sentence": "Additional comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8476134538650513,
                    "sentence": "- Line 422: The term \"coverage vector\" may be misleading given its common usage in PBMT.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7222698926925659,
                    "sentence": "A more appropriate term might be \"coverage set,\" as this better reflects the underlying data structure.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7164177298545837,
                    "sentence": "- Table 2: It would be helpful to include information on the number of constraints per source sentence in the test corpora, as this would provide context for interpreting the BLEU improvements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.3063829682933457
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.8923758534658037,
            "class_probabilities": {
                "human": 0.10626570421472266,
                "ai": 0.8923758534658037,
                "mixed": 0.00135844231947367
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8923758534658037,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8923758534658037,
                    "human": 0.10626570421472266,
                    "mixed": 0.00135844231947367
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a straightforward extension to left-to-right beam search, enabling it to incorporate lexical constraints in the form of word sequences that must appear in the MT output. The proposed algorithm is demonstrated to be effective for applications such as interactive translation and domain adaptation.\nWhile the extension itself is quite simple, the paper makes a valuable contribution by formalizing it. It is also noteworthy that NMT performs well with a set of unordered constraints that lack explicit alignment information. The technique described here appears to have potential applications beyond those explored in the paper, such as enhancing NMT's ability to handle non-compositional constructions\"\"an area where traditional SMT may still have an advantage.\nThe primary limitation of the paper lies in the somewhat restricted scope of the experiments. Although the interactive MT simulation confirms that the method functions as intended, it is challenging to assess the degree of success\"\"for example, how often the constraints were incorporated in an acceptable manner (the substantial BLEU score improvements provide only indirect evidence). Likewise, the domain adaptation experiments would have been more robust if they included a comparison against the standard \"fine-tuning\" baseline, which could have been conducted relatively easily on the 100K Autodesk corpus.\nDespite this limitation, I believe the paper represents a solid contribution and merits publication.\nAdditional comments:\n- Line 422: The term \"coverage vector\" may be misleading given its common usage in PBMT. A more appropriate term might be \"coverage set,\" as this better reflects the underlying data structure.\n- Table 2: It would be helpful to include information on the number of constraints per source sentence in the test corpora, as this would provide context for interpreting the BLEU improvements."
        }
    ]
}