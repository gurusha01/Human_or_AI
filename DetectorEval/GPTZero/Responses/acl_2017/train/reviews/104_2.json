{
    "version": "2025-01-09-base",
    "scanId": "6625111d-e302-41a9-9b73-2e993ad1d68d",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.07054045796394348,
                    "sentence": "This paper addresses the problem of disambiguating/linking textual entity",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05939596891403198,
                    "sentence": "mentions into a given background knowledge base (in this case, English",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05446531996130943,
                    "sentence": "Wikipedia).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.055872973054647446,
                    "sentence": "(Its title and introduction are a little overblown/misleading,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07147979736328125,
                    "sentence": "since there is a lot more to bridging text and knowledge than the EDL task, but",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1200670599937439,
                    "sentence": "EDL is a core part of the overall task nonetheless.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09945318102836609,
                    "sentence": "The method is to perform",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1109929233789444,
                    "sentence": "this bridging via an intermediate layer of representation, namely mention",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09679262340068817,
                    "sentence": "senses, thus following two steps: (1) mention to mention sense, and (2) mention",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09728781133890152,
                    "sentence": "sense to entity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0835224986076355,
                    "sentence": "Various embedding representations are learned for the words,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07664599269628525,
                    "sentence": "the mention senses, and the entities, which are then jointly trained to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11938251554965973,
                    "sentence": "maximize a single overall objective function that maximizes all three types of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12342086434364319,
                    "sentence": "embedding equally.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09945687651634216,
                    "sentence": "Technically the approach is fairly clear and conforms to the current deep",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12488190829753876,
                    "sentence": "processing fashion and known best practices regarding embeddings; while one can",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1292826235294342,
                    "sentence": "suggest all kinds of alternatives, it's not clear they would make a material",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.253277450799942,
                    "sentence": "difference.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19778719544410706,
                    "sentence": "Rather, my comments focus on the basic approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09315463155508041,
                    "sentence": "It is not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15606628358364105,
                    "sentence": "explained, however, exactly why a two-step process, involving the mention",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.20076382160186768,
                    "sentence": "senses, is better than a simple direct one-step mapping from word mentions to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19123230874538422,
                    "sentence": "their entities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2155207097530365,
                    "sentence": "(This is the approach of Yamada et al., in what is called here",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2311175912618637,
                    "sentence": "the ALIGN algorithm.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17973293364048004,
                    "sentence": "Table 2 shows that the two-step MPME (and even its",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21263203024864197,
                    "sentence": "simplification SPME) do better.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1572154015302658,
                    "sentence": "By why, exactly?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09913457930088043,
                    "sentence": "What is the exact",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15466198325157166,
                    "sentence": "difference, and additional information, that the mention senses have compare4ed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1089470237493515,
                    "sentence": "to the entities?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07032517343759537,
                    "sentence": "To understand, please check if the following is correct (and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11273324489593506,
                    "sentence": "perhaps update the paper to make it exactly clear what is going on).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10751789063215256,
                    "sentence": "For entities: their profiles consist of neighboring entities in a relatedness",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05759059265255928,
                    "sentence": "graph.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10256122052669525,
                    "sentence": "This graph is built (I assume) by looking at word-level",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1434183120727539,
                    "sentence": "relatedness of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10644055902957916,
                    "sentence": "the entity definitions (pages in Wikipedia).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09592312574386597,
                    "sentence": "The profiles are (extended",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11079877614974976,
                    "sentence": "skip-gram-based) embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12771214544773102,
                    "sentence": "For words: their profiles are the standard distributional semantics approach,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09451811015605927,
                    "sentence": "without sense disambiguation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13399362564086914,
                    "sentence": "For mention senses: their profiles are the standard distributional semantics",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11191944777965546,
                    "sentence": "approach, but WITH sense disambiguation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13596628606319427,
                    "sentence": "Sense disambiguation is performed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07695356011390686,
                    "sentence": "using a sense-based profile ('language model') from local context words and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10878811776638031,
                    "sentence": "neighboring mentions, as mentioned briefly just before Section 4, but without",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18268664181232452,
                    "sentence": "details.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11056528240442276,
                    "sentence": "This is a problem point in the approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11691401153802872,
                    "sentence": "How exactly are the senses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07684340327978134,
                    "sentence": "created and differentiated?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13224835693836212,
                    "sentence": "Who defines how many senses a mention string can",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08470691740512848,
                    "sentence": "have?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15812531113624573,
                    "sentence": "If this is done by looking at the knowledge base, then we get a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3632570505142212,
                    "sentence": "bijective mapping between mention senses and entities -\"\" that is, there is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.29120418429374695,
                    "sentence": "exactly one entity for each mention sense (even if there may be more entities).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2452312409877777,
                    "sentence": "In that case, are the sense collection's definitional profiles built",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09669934213161469,
                    "sentence": "starting with entity text as 'seed words'?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4034528136253357,
                    "sentence": "If so, what",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2591072916984558,
                    "sentence": "information",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3829580843448639,
                    "sentence": "is used",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.39954379200935364,
                    "sentence": "at the mention sense level that is NOT used at the entity level?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.26181113719940186,
                    "sentence": "Just and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2901376187801361,
                    "sentence": "exactly the words in the texts that reliably associate with the mention sense,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.22444982826709747,
                    "sentence": "but that do NOT occur in the equivalent entity webpage in Wikipedia?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5141491889953613,
                    "sentence": "How many",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.39360204339027405,
                    "sentence": "such words are there, on average, for a mention sense?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.22063252329826355,
                    "sentence": "That is,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.41620689630508423,
                    "sentence": "how",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4467369616031647,
                    "sentence": "powerful/necessary is it to keep this extra differentiation information in a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2620062232017517,
                    "sentence": "separate space (the mention sense space) as opposed to just loading these",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.42760035395622253,
                    "sentence": "additional words into the Entity space (by adding these words into the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.29380738735198975,
                    "sentence": "Wikipedia entity pages)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.32886645197868347,
                    "sentence": "If the above understanding is essentially correct, please update Section 5 of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4802606999874115,
                    "sentence": "the paper to say so, for (to me) it is the main new information in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.34178608655929565,
                    "sentence": "It is not true, as the paper says in Section 6, that \"\"¦this is the first",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5399675369262695,
                    "sentence": "work to deal with mention ambiguity in the integration of text and knowledge",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4050610363483429,
                    "sentence": "representations, so there is no exact baselines for comparison\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5824184417724609,
                    "sentence": "The TAC KBP",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4537714123725891,
                    "sentence": "evaluations for the past two years have hosted EDL tasks, involving eight or",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3340033292770386,
                    "sentence": "nine systems, all performing exactly this task, albeit against Freebase, which",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4481567144393921,
                    "sentence": "is considerably larger and more noisy than Wikipedia.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2632763981819153,
                    "sentence": "Please see",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12369850277900696,
                    "sentence": "http://nlp.cs.rpi.edu/kbp/2016/.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4881744384765625,
                    "sentence": "On a positive note: I really liked the idea of the smoothing parameter in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2948392927646637,
                    "sentence": "Section 6.4.2.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.49076932668685913,
                    "sentence": "Post-response: I have read the authors' responses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4099552035331726,
                    "sentence": "I am not really satisfied",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4805164337158203,
                    "sentence": "with their reply about the KBP evaluation not being relevant, but that they are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5915917754173279,
                    "sentence": "interested in the goodness of the embeddings instead.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5404622554779053,
                    "sentence": "In fact, the only way to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.41420501470565796,
                    "sentence": "evaluate such 'goodness' is through an application.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.47693270444869995,
                    "sentence": "No-one really cares how",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.48879891633987427,
                    "sentence": "conceptually elegant an embedding is, the question is: does it perform better?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 59,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 63,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 64,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 66,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 68,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 69,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 70,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 71,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 72,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 73,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 74,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 75,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 76,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 77,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 79,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 80,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 81,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 83,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 84,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 85,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 86,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 88,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 89,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 91,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 93,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.24245896627697372,
            "class_probabilities": {
                "human": 0.7570192175920558,
                "ai": 0.24245896627697372,
                "mixed": 0.0005218161309705781
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.7570192175920558,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.24245896627697372,
                    "human": 0.7570192175920558,
                    "mixed": 0.0005218161309705781
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper addresses the problem of disambiguating/linking textual entity\nmentions into a given background knowledge base (in this case, English\nWikipedia). (Its title and introduction are a little overblown/misleading,\nsince there is a lot more to bridging text and knowledge than the EDL task, but\nEDL is a core part of the overall task nonetheless.) The method is to perform\nthis bridging via an intermediate layer of representation, namely mention\nsenses, thus following two steps: (1) mention to mention sense, and (2) mention\nsense to entity. Various embedding representations are learned for the words,\nthe mention senses, and the entities, which are then jointly trained to\nmaximize a single overall objective function that maximizes all three types of\nembedding equally. \nTechnically the approach is fairly clear and conforms to the current deep\nprocessing fashion and known best practices regarding embeddings; while one can\nsuggest all kinds of alternatives, it's not clear they would make a material\ndifference. Rather, my comments focus on the basic approach. It is not\nexplained, however, exactly why a two-step process, involving the mention\nsenses, is better than a simple direct one-step mapping from word mentions to\ntheir entities. (This is the approach of Yamada et al., in what is called here\nthe ALIGN algorithm.) Table 2 shows that the two-step MPME (and even its\nsimplification SPME) do better. By why, exactly? What is the exact\ndifference, and additional information, that the mention senses have compare4ed\nto the entities? To understand, please check if the following is correct (and\nperhaps update the paper to make it exactly clear what is going on). \nFor entities: their profiles consist of neighboring entities in a relatedness\ngraph. This graph is built (I assume) by looking at word-level\nrelatedness of\nthe entity definitions (pages in Wikipedia). The profiles are (extended\nskip-gram-based) embeddings. \nFor words: their profiles are the standard distributional semantics approach,\nwithout sense disambiguation. \nFor mention senses: their profiles are the standard distributional semantics\napproach, but WITH sense disambiguation. Sense disambiguation is performed\nusing a sense-based profile ('language model') from local context words and\nneighboring mentions, as mentioned briefly just before Section 4, but without\ndetails. This is a problem point in the approach. How exactly are the senses\ncreated and differentiated? Who defines how many senses a mention string can\nhave? If this is done by looking at the knowledge base, then we get a\nbijective mapping between mention senses and entities -\"\" that is, there is\nexactly one entity for each mention sense (even if there may be more entities).\n In that case, are the sense collection's definitional profiles built\nstarting with entity text as 'seed words'? If so, what\ninformation\nis used\nat the mention sense level that is NOT used at the entity level? Just and\nexactly the words in the texts that reliably associate with the mention sense,\nbut that do NOT occur in the equivalent entity webpage in Wikipedia? How many\nsuch words are there, on average, for a mention sense? That is,\nhow\npowerful/necessary is it to keep this extra differentiation information in a\nseparate space (the mention sense space) as opposed to just loading these\nadditional words into the Entity space (by adding these words into the\nWikipedia entity pages)? \nIf the above understanding is essentially correct, please update Section 5 of\nthe paper to say so, for (to me) it is the main new information in the paper. \nIt is not true, as the paper says in Section 6, that \"\"¦this is the first\nwork to deal with mention ambiguity in the integration of text and knowledge\nrepresentations, so there is no exact baselines for comparison\". The TAC KBP\nevaluations for the past two years have hosted EDL tasks, involving eight or\nnine systems, all performing exactly this task, albeit against Freebase, which\nis considerably larger and more noisy than Wikipedia. Please see\nhttp://nlp.cs.rpi.edu/kbp/2016/ . \nOn a positive note: I really liked the idea of the smoothing parameter in\nSection 6.4.2.\nPost-response: I have read the authors' responses. I am not really satisfied\nwith their reply about the KBP evaluation not being relevant, but that they are\ninterested in the goodness of the embeddings instead. In fact, the only way to\nevaluate such 'goodness' is through an application. No-one really cares how\nconceptually elegant an embedding is, the question is: does it perform better?"
        }
    ]
}