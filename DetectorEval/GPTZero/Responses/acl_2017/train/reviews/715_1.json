{
    "version": "2025-01-09-base",
    "scanId": "22f3ca69-fa6f-4c89-b93e-b076f6199867",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.02880258671939373,
                    "sentence": "- Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023710820823907852,
                    "sentence": "*- Task",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11515326797962189,
                    "sentence": "*- Simple model, yet the best results on SQuAD (single model0",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01654166914522648,
                    "sentence": "*- Evaluation and comparison",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09786386787891388,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04646418243646622,
                    "sentence": "*- Analysis of errors/results (See detailed comments below)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1830844283103943,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06578505784273148,
                    "sentence": "In this paper the authors present a method for directly querying Wikipedia to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04989807307720184,
                    "sentence": "answer open domain questions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06700146943330765,
                    "sentence": "The system consist of two components - a module",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.042882323265075684,
                    "sentence": "to query/fetch wikipedia articles and a module to answer the question given the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05860724672675133,
                    "sentence": "fetched set of wikipedia articles.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08283453434705734,
                    "sentence": "The document retrieval system is a traditional IR system relying on term",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014058726839721203,
                    "sentence": "frequency models and ngram counts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027207503095269203,
                    "sentence": "The answering system uses a feature",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017898062244057655,
                    "sentence": "representation for paragraphs that consists of word embeddings, indicator",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019199762493371964,
                    "sentence": "features to determine whether a paragraph word occurs in a question,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01708410121500492,
                    "sentence": "token-level features including POS, NER etc and a soft feature for capturing",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025170480832457542,
                    "sentence": "similarity between question and paragraph tokens in embedding space.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02491755224764347,
                    "sentence": "A combined",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04502594470977783,
                    "sentence": "feature representation is used as an input to a bi-direction LSTM RNN for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.028175542131066322,
                    "sentence": "encoding.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04734324291348457,
                    "sentence": "For questions an RNN that works on the word embeddings is used.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04297151416540146,
                    "sentence": "These are then used to train an overall classifier independently for start and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05762302130460739,
                    "sentence": "end spans of sentences within a paragraph to answer questions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.053105227649211884,
                    "sentence": "The system has been trained using different Open Domain QA datasets such as",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06434058398008347,
                    "sentence": "SQuAD and WebQuestions by modifying the training data to include articles",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04899912327528,
                    "sentence": "fetched by the IR engine instead of just the actual correct document/passage.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.043067555874586105,
                    "sentence": "Overall, an easy to follow interesting paper but I had a few questions:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06947048753499985,
                    "sentence": "1) The IR system has a Accuracy@5 of over 75 %, and individually the document",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.024644723162055016,
                    "sentence": "reader performs well and can beat the best single models on SquAD.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011047148145735264,
                    "sentence": "What",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.015649262815713882,
                    "sentence": "explains the significant drop in Table 6.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01274122204631567,
                    "sentence": "The authors mention that instead of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017505429685115814,
                    "sentence": "the fetched results, if they test using the best paragraph the accuracy reaches",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017874106764793396,
                    "sentence": "just 0.49 (from 0.26) but that is still significantly below the 0.78-79 in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.047156527638435364,
                    "sentence": "SQuAD task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.024855181574821472,
                    "sentence": "So, presumably the error is this large because the neural network",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022726625204086304,
                    "sentence": "for matching isnt doing as good a job in learning the answers when using the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022794244810938835,
                    "sentence": "modified training set (which includes fetched articles) instead of the case",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019297322258353233,
                    "sentence": "when training and testing is done for the document understanding task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008741223253309727,
                    "sentence": "Some",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022010190412402153,
                    "sentence": "analysis of whats going on here should be provided.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01905643753707409,
                    "sentence": "What was the training",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025060147047042847,
                    "sentence": "accuracy in the both cases?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018545038998126984,
                    "sentence": "What can be done to improve it?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.045210689306259155,
                    "sentence": "To be fair, the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.028805896639823914,
                    "sentence": "authors to allude to this in the conclusion but I think it still needs to be",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022792989388108253,
                    "sentence": "part of the paper to provide some meaningful insights.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019270826131105423,
                    "sentence": "2) I understand the authors were interested in treating this as a pure machine",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018201012164354324,
                    "sentence": "comprehension task and therefore did not want to rely on external sources such",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.016199516132473946,
                    "sentence": "as Freebase which could have helped with entity typing but that would have",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017707059159874916,
                    "sentence": "been interesting to use.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.015696223825216293,
                    "sentence": "Tying back to my first question -- if the error is due",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025276798754930496,
                    "sentence": "to highly relevant topical sentences as the authors mention, could entity",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02810768224298954,
                    "sentence": "typing have helped?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022931482642889023,
                    "sentence": "The authors should also refer to QuASE (Sun et.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01883542723953724,
                    "sentence": "al 2015 at WWW2015) and similar",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.020254645496606827,
                    "sentence": "systems in their related work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026601850986480713,
                    "sentence": "QuASE is also an Open domain QA system that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.016741985455155373,
                    "sentence": "answers using fetched passages - but it relies on the web instead of just",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02527480572462082,
                    "sentence": "Wikipedia.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.04094257758090865,
            "class_probabilities": {
                "human": 0.9587663676756332,
                "ai": 0.04094257758090865,
                "mixed": 0.0002910547434582826
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9587663676756332,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.04094257758090865,
                    "human": 0.9587663676756332,
                    "mixed": 0.0002910547434582826
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "- Strengths:\n*- Task\n*- Simple model, yet the best results on SQuAD (single model0\n*- Evaluation and comparison\n- Weaknesses:\n*- Analysis of errors/results (See detailed comments below)\n- General Discussion:\nIn this paper the authors present a method for directly querying Wikipedia to\nanswer open domain questions. The system consist of two components - a module\nto query/fetch wikipedia articles and a module to answer the question given the\nfetched set of wikipedia articles. \nThe document retrieval system is a traditional IR system relying on term\nfrequency models and ngram counts. The answering system uses a feature\nrepresentation for paragraphs that consists of word embeddings, indicator\nfeatures to determine whether a paragraph word occurs in a question,\ntoken-level features including POS, NER etc and a soft feature for capturing\nsimilarity between question and paragraph tokens in embedding space. A combined\nfeature representation is used as an input to a bi-direction LSTM RNN for\nencoding. For questions an RNN that works on the word embeddings is used. \nThese are then used to train an overall classifier independently for start and\nend spans of sentences within a paragraph to answer questions.\nThe system has been trained using different Open Domain QA datasets such as\nSQuAD and WebQuestions by modifying the training data to include articles\nfetched by the IR engine instead of just the actual correct document/passage.\nOverall, an easy to follow interesting paper but I had a few questions:\n1) The IR system has a Accuracy@5 of over 75 %, and individually the document\nreader performs well and can beat the best single models on SquAD. What\nexplains the significant drop in Table 6. The authors mention that instead of\nthe fetched results, if they test using the best paragraph the accuracy reaches\njust 0.49 (from 0.26) but that is still significantly below the 0.78-79 in the\nSQuAD task. So, presumably the error is this large because the neural network\nfor matching isnt doing as good a job in learning the answers when using the\nmodified training set (which includes fetched articles) instead of the case\nwhen training and testing is done for the document understanding task. Some\nanalysis of whats going on here should be provided. What was the training\naccuracy in the both cases? What can be done to improve it? To be fair, the\nauthors to allude to this in the conclusion but I think it still needs to be\npart of the paper to provide some meaningful insights.\n2) I understand the authors were interested in treating this as a pure machine\ncomprehension task and therefore did not want to rely on external sources such\nas Freebase which could have helped with entity typing but that would have\nbeen interesting to use. Tying back to my first question -- if the error is due\nto highly relevant topical sentences as the authors mention, could entity\ntyping have helped?\nThe authors should also refer to QuASE (Sun et. al 2015 at WWW2015) and similar\nsystems in their related work. QuASE is also an Open domain QA system that\nanswers using fetched passages - but it relies on the web instead of just\nWikipedia."
        }
    ]
}