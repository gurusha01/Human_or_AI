{
    "version": "2025-01-09-base",
    "scanId": "2e01fbc6-e5f7-483c-b008-ee9f205f068b",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9995343089103699,
                    "sentence": "The paper analyzes the story endings (last sentence of a 5-sentence story) in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9996999502182007,
                    "sentence": "the corpus built for the story cloze task (Mostafazadeh et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9992717504501343,
                    "sentence": "2016), and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9995909929275513,
                    "sentence": "proposes a model based on character and word n-grams to classify story endings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9991884231567383,
                    "sentence": "The paper also shows better performance on the story cloze task proper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9994403719902039,
                    "sentence": "(distinguishing between \"right\" and \"wrong\" endings) than prior work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9998173117637634,
                    "sentence": "Whereas style analysis is an interesting area and you show better results than",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9998912811279297,
                    "sentence": "prior work on the story cloze task, there are several issues with the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.999843180179596,
                    "sentence": "First, how do you define \"style\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999018907546997,
                    "sentence": "Also, the paper needs to be restructured (for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9998462200164795,
                    "sentence": "instance, your section",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9998798370361328,
                    "sentence": "\"Results\" actually mixes some results and new experiments) and clarified (see",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999319911003113,
                    "sentence": "below for questions/comments): right now, it is quite difficult for the reader",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9998739957809448,
                    "sentence": "to follow what data is used for the different experiments, and what data the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999068379402161,
                    "sentence": "discussion refers to.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999063611030579,
                    "sentence": "(1) More details about the data used is necessary in order to assess the claim",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9998859167098999,
                    "sentence": "that \"subtle writing task [...] imposes different styles on the author\" (lines",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.999859631061554,
                    "sentence": "729-732).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999391436576843,
                    "sentence": "How many stories are you looking at, written by how many different",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999632835388184,
                    "sentence": "persons?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999610781669617,
                    "sentence": "And how many stories are there per person?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9998940229415894,
                    "sentence": "From your description of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999339580535889,
                    "sentence": "the post-analysis of coherence, only pairs of stories written by the same",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999420642852783,
                    "sentence": "person in which one was judged as \"coherent\" and the other one as \"neutral\" are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999597668647766,
                    "sentence": "chosen.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.999947190284729,
                    "sentence": "Can you confirm that this is the case?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999667406082153,
                    "sentence": "So perhaps your claim is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999450445175171,
                    "sentence": "justified for your \"Experiment 1\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999374151229858,
                    "sentence": "However my understanding is that in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999539852142334,
                    "sentence": "experiment 2 where you compare \"original\" vs. \"right\" or \"original\" vs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999304413795471,
                    "sentence": "\"wrong\", we do not have the same writers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9998955130577087,
                    "sentence": "So I am not convinced lines 370-373",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.020537344738841057,
                    "sentence": "are correct.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.030580181628465652,
                    "sentence": "(2) A lot in the paper is simply stated without any justifications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012575420551002026,
                    "sentence": "For",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0235125795006752,
                    "sentence": "instance how are the \"five frequent\" POS and words chosen?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011846281588077545,
                    "sentence": "Are they the most",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022722696885466576,
                    "sentence": "frequent words/POS?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025601759552955627,
                    "sentence": "(Also theses tables are puzzling: why two bars in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06558242440223694,
                    "sentence": "legend for each category?).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.038317516446113586,
                    "sentence": "Why character 4-grams?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01944224163889885,
                    "sentence": "Did you tune that on the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06377501785755157,
                    "sentence": "development set?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021628636866807938,
                    "sentence": "If these were not the most frequent features, but some that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022199654951691628,
                    "sentence": "you chose among frequent POS and words, you need to justify this choice and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.024228110909461975,
                    "sentence": "especially link the choice to \"style\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.028051700443029404,
                    "sentence": "How are these features reflecting",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0215500146150589,
                    "sentence": "\"style\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03133906424045563,
                    "sentence": "(3) I don't understand how the section \"Design of NLP tasks\" connects to the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02368200197815895,
                    "sentence": "rest of the paper, and to your results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012301938608288765,
                    "sentence": "But perhaps this is because I am lost",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013902908191084862,
                    "sentence": "in what \"training\" and \"test\" sets refer to here.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02422609180212021,
                    "sentence": "(4) It is difficult to understand how your model differs from previous work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.033581219613552094,
                    "sentence": "How do we reconcile lines 217-219 (\"These results suggest that real",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.036210037767887115,
                    "sentence": "understanding of text is required in order to solve the task\") with your",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05310019850730896,
                    "sentence": "approach?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.029544247314333916,
                    "sentence": "(5) The terminology of \"right\" and \"wrong\" endings is coming from Mostafazadeh",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.037851687520742416,
                    "sentence": "et al., but this is a very bad choice of terms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02857173979282379,
                    "sentence": "What exactly does a \"right\" or",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027007728815078735,
                    "sentence": "\"wrong\" ending mean (\"right\" as in \"coherent\" or \"right\" as in \"morally good\")?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.034218497574329376,
                    "sentence": "I took a quick look, but couldn't find the exact prompts given to the Turkers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.038244180381298065,
                    "sentence": "I think this needs to be clarified: as it is, the first paragraph of your",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03088439628481865,
                    "sentence": "section \"Story cloze task\" (lines 159-177) is not understandable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02950173243880272,
                    "sentence": "Other questions/comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.054764196276664734,
                    "sentence": "Table 1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.029589280486106873,
                    "sentence": "Why does the \"original\" story differ from the coherent and incoherent",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0013360370649024844,
                    "sentence": "one?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006753908819518983,
                    "sentence": "From your description of the corpus, it seems that one Turker saw the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010583606781437993,
                    "sentence": "first 4 sentences of the original story and was then ask to write one sentence",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006554133142344654,
                    "sentence": "ending the story in a \"right\" way (or did they ask to provide a \"coherent\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.000622202642261982,
                    "sentence": "ending?)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005060741095803678,
                    "sentence": "and one sentence ending the story in a \"wrong\" way (or did they ask to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00040644477121531963,
                    "sentence": "provide an \"incoherent\" ending)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00045085162855684757,
                    "sentence": "I don't find the last sentence of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003072216350119561,
                    "sentence": "\"incoherent\" story that incoherent...",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004676221578847617,
                    "sentence": "If the only shoes that Kathy finds great",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004557310603559017,
                    "sentence": "are $300, I can see how Kathy doesn't like buying shoes;-) This led me to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004095563490409404,
                    "sentence": "wonder how many Turkers judged the coherence of the story/ending and how",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003326826845295727,
                    "sentence": "variable the judgements were.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005030363681726158,
                    "sentence": "What criterion was used to judge a story coherent",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005476541700772941,
                    "sentence": "or incoherent?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005469169118441641,
                    "sentence": "Also does one Turker judge the coherence of both the \"right\" and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004063442174810916,
                    "sentence": "\"wrong\" endings, making it a relative judgement?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006777844973839819,
                    "sentence": "Or was this an absolute",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006261667585931718,
                    "sentence": "judgement?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006850645877420902,
                    "sentence": "This would have huge implications on the ratings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001150387804955244,
                    "sentence": "Lines 380-383: What does \"We randomly sample 5 original sets\" mean?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0011824136599898338,
                    "sentence": "Line 398: \"Virtually all sentences\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00046202752855606377,
                    "sentence": "Can you quantify this?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010357400169596076,
                    "sentence": "Table 5: Could we see the weights of the features?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010485175298526883,
                    "sentence": "Line 614: \"compared to ending an existing task\": the Turkers are not ending a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009039567084982991,
                    "sentence": "\"task\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009635991300456226,
                    "sentence": "Line 684-686: \"made sure each pair of endings was written by the same author\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006887503550387919,
                    "sentence": "-> this is true for the \"right\"/\"wrong\" pairs, but not for the \"original\"-\"new\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.000754515640437603,
                    "sentence": "pairs, according to your description.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009841378778219223,
                    "sentence": "Line 694: \"shorter text spans\": text about what?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010631605982780457,
                    "sentence": "This is unclear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0014288602396845818,
                    "sentence": "Lines 873-875: where is this published?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 59,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 63,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 64,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 66,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 68,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 69,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 70,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 72,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 74,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 76,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 77,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 78,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 80,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 82,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 84,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 86,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 87,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 89,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 90,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 91,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 92,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 93,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 94,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 95,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 97,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.2425855513307985,
            "class_probabilities": {
                "human": 0.7574144486692015,
                "ai": 0.2425855513307985,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.7574144486692015,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.2425855513307985,
                    "human": 0.7574144486692015,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper analyzes the story endings (last sentence of a 5-sentence story) in\nthe corpus built for the story cloze task (Mostafazadeh et al. 2016), and\nproposes a model based on character and word n-grams to classify story endings.\nThe paper also shows better performance on the story cloze task proper\n(distinguishing between \"right\" and \"wrong\" endings) than prior work.\nWhereas style analysis is an interesting area and you show better results than\nprior work on the story cloze task, there are several issues with the paper.\nFirst, how do you define \"style\"? Also, the paper needs to be restructured (for\ninstance, your section\n\"Results\" actually mixes some results and new experiments) and clarified (see\nbelow for questions/comments): right now, it is quite difficult for the reader\nto follow what data is used for the different experiments, and what data the\ndiscussion refers to.\n(1) More details about the data used is necessary in order to assess the claim\nthat \"subtle writing task [...] imposes different styles on the author\" (lines\n729-732). How many stories are you looking at, written by how many different\npersons? And how many stories are there per person? From your description of\nthe post-analysis of coherence, only pairs of stories written by the same\nperson in which one was judged as \"coherent\" and the other one as \"neutral\" are\nchosen. Can you confirm that this is the case? So perhaps your claim is\njustified for your \"Experiment 1\". However my understanding is that in\nexperiment 2 where you compare \"original\" vs. \"right\" or \"original\" vs.\n\"wrong\", we do not have the same writers. So I am not convinced lines 370-373\nare correct.\n(2) A lot in the paper is simply stated without any justifications. For\ninstance how are the \"five frequent\" POS and words chosen? Are they the most\nfrequent words/POS? (Also theses tables are puzzling: why two bars in the\nlegend for each category?). Why character 4-grams? Did you tune that on the\ndevelopment set? If these were not the most frequent features, but some that\nyou chose among frequent POS and words, you need to justify this choice and\nespecially link the choice to \"style\". How are these features reflecting\n\"style\"?\n(3) I don't understand how the section \"Design of NLP tasks\" connects to the\nrest of the paper, and to your results. But perhaps this is because I am lost\nin what \"training\" and \"test\" sets refer to here.\n(4) It is difficult to understand how your model differs from previous work.\nHow do we reconcile lines 217-219 (\"These results suggest that real\nunderstanding of text is required in order to solve the task\") with your\napproach?\n(5) The terminology of \"right\" and \"wrong\" endings is coming from Mostafazadeh\net al., but this is a very bad choice of terms. What exactly does a \"right\" or\n\"wrong\" ending mean (\"right\" as in \"coherent\" or \"right\" as in \"morally good\")?\nI took a quick look, but couldn't find the exact prompts given to the Turkers.\nI think this needs to be clarified: as it is, the first paragraph of your\nsection \"Story cloze task\" (lines 159-177) is not understandable.\nOther questions/comments:\nTable 1. Why does the \"original\" story differ from the coherent and incoherent\none? From your description of the corpus, it seems that one Turker saw the\nfirst 4 sentences of the original story and was then ask to write one sentence\nending the story in a \"right\" way (or did they ask to provide a \"coherent\"\nending?) and one sentence ending the story in a \"wrong\" way (or did they ask to\nprovide an \"incoherent\" ending)? I don't find the last sentence of the\n\"incoherent\" story that incoherent... If the only shoes that Kathy finds great\nare $300, I can see how Kathy doesn't like buying shoes ;-) This led me to\nwonder how many Turkers judged the coherence of the story/ending and how\nvariable the judgements were. What criterion was used to judge a story coherent\nor incoherent? Also does one Turker judge the coherence of both the \"right\" and\n\"wrong\" endings, making it a relative judgement? Or was this an absolute\njudgement? This would have huge implications on the ratings.\nLines 380-383: What does \"We randomly sample 5 original sets\" mean?\nLine 398: \"Virtually all sentences\"? Can you quantify this?\nTable 5: Could we see the weights of the features? \nLine 614: \"compared to ending an existing task\": the Turkers are not ending a\n\"task\"\nLine 684-686: \"made sure each pair of endings was written by the same author\"\n-> this is true for the \"right\"/\"wrong\" pairs, but not for the \"original\"-\"new\"\npairs, according to your description.\nLine 694: \"shorter text spans\": text about what? This is unclear.\nLines 873-875: where is this published?"
        }
    ]
}