{
    "version": "2025-01-09-base",
    "scanId": "10e3b15c-ecdd-47e8-a0d2-c6613a3ab212",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.16614696383476257,
                    "sentence": "Summary: The paper proposes a neural model for predicting Python syntax trees",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09825297445058823,
                    "sentence": "from text descriptions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13480161130428314,
                    "sentence": "Guided by the actual Python grammar, the model",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13056255877017975,
                    "sentence": "generates tree nodes sequentially in a depth-first fashion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09419528394937515,
                    "sentence": "Key ideas include",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08011941611766815,
                    "sentence": "injecting the information from the parent node as part of the LSTM input, a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07678651809692383,
                    "sentence": "pointer network for copying the terminals, and unary closure which collapses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1033889427781105,
                    "sentence": "chains of unary productions to reduce the tree size.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14308393001556396,
                    "sentence": "The model is evaluated on",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0856037437915802,
                    "sentence": "three datasets from different domains and outperforms almost all previous work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07494674623012543,
                    "sentence": "Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13406968116760254,
                    "sentence": "The paper is overall very well-written.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1822907030582428,
                    "sentence": "The explanation of system is clear, and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.20330990850925446,
                    "sentence": "the analysis is thorough.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2026120275259018,
                    "sentence": "The system itself is a natural extension of various ideas.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3567591607570648,
                    "sentence": "The most similar",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.24774187803268433,
                    "sentence": "work include tree-based generation with parent feeding (Dong and Lapata, 2016)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.25641068816185,
                    "sentence": "and various RNN-based semantic parsing with copy mechanism (Jia and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14728470146656036,
                    "sentence": "Liang, 2016; Ling et al., 2016).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2259216010570526,
                    "sentence": "[The guidance of parsing based on grammar is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16070525348186493,
                    "sentence": "also explored in Chen Liang et al., 2016 (https://arxiv.org/abs/1611.00020)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1815016120672226,
                    "sentence": "where a code-assist system is used to ensure that the code",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05557948723435402,
                    "sentence": "is valid.]",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1626727283000946,
                    "sentence": "Nevertheless, the model is this paper stands out as it is able to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12118170410394669,
                    "sentence": "generate much longer and more complex programs than most previous work",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18509414792060852,
                    "sentence": "mentioned.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11414434015750885,
                    "sentence": "Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21542975306510925,
                    "sentence": "The evaluation is done on code accuracy (exact match) and BLEU score.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09710612148046494,
                    "sentence": "These",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.24055862426757812,
                    "sentence": "metrics (especially BLEU) might not be the best metrics for evaluating the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.20792871713638306,
                    "sentence": "correctness of programs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.32312479615211487,
                    "sentence": "For instance, the first example in Table 5 shows that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023237034678459167,
                    "sentence": "while the first two lines in boxes A and B are different, they have the same",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.020580876618623734,
                    "sentence": "semantics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02821389026939869,
                    "sentence": "Another example is that variable names can be different.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0209286380559206,
                    "sentence": "Evaluation",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03510364890098572,
                    "sentence": "based on what the code does (e.g., using test cases or static code analysis)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013163569383323193,
                    "sentence": "would be more convincing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.028376858681440353,
                    "sentence": "Another point about evaluation: other systems (e.g., NMT baseline) may generate",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07858488708734512,
                    "sentence": "code with syntactic error.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.030162077397108078,
                    "sentence": "Would it be possible to include the result on the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.036764152348041534,
                    "sentence": "highest-scoring well-formed code (e.g., using beam search) that these baseline",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09616599977016449,
                    "sentence": "systems generate?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03319511190056801,
                    "sentence": "This would give a fairer comparison since these system can",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04375014454126358,
                    "sentence": "choose to prune malformed code.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02499159425497055,
                    "sentence": "General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021557388827204704,
                    "sentence": "* Lines 120-121: some approaches that use domain-specific languages were also",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021947070956230164,
                    "sentence": "guided by a grammar.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027480904012918472,
                    "sentence": "One example is Berant and Liang, 2014, which uses a pretty",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0275945533066988,
                    "sentence": "limited grammar for logical forms (Table 1).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01268047746270895,
                    "sentence": "In addition to comparing to that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025720730423927307,
                    "sentence": "line of work, emphasizing that the grammar in this paper is much larger than",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017595693469047546,
                    "sentence": "most previous work would make this work stronger.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021550072357058525,
                    "sentence": "* Lines 389-397: For the parent feeding mechanism, is the child index being",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04625081270933151,
                    "sentence": "used?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019931841641664505,
                    "sentence": "In other words, is p_t different when generating a first child versus a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.048183586448431015,
                    "sentence": "second child?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019843531772494316,
                    "sentence": "In Seq2Tree (Dong and Lapata, 2016) the two non-terminals would",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023609058931469917,
                    "sentence": "have different hidden states.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02764524705708027,
                    "sentence": "* Line 373: Are the possible tokens embedded?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03374249488115311,
                    "sentence": "Is it assumed that the set of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.061859726905822754,
                    "sentence": "possible tokens is known beforehand?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.029393179342150688,
                    "sentence": "* The examples in the appendix are nice.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01950160227715969,
                    "sentence": "---",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07148139923810959,
                    "sentence": "I have read the author response.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 59,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 63,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 64,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.07286165202115429,
            "class_probabilities": {
                "human": 0.9268225467824988,
                "ai": 0.07286165202115429,
                "mixed": 0.0003158011963468892
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9268225467824988,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.07286165202115429,
                    "human": 0.9268225467824988,
                    "mixed": 0.0003158011963468892
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary: The paper proposes a neural model for predicting Python syntax trees\nfrom text descriptions. Guided by the actual Python grammar, the model\ngenerates tree nodes sequentially in a depth-first fashion. Key ideas include\ninjecting the information from the parent node as part of the LSTM input, a\npointer network for copying the terminals, and unary closure which collapses\nchains of unary productions to reduce the tree size. The model is evaluated on\nthree datasets from different domains and outperforms almost all previous work.\nStrengths:\nThe paper is overall very well-written. The explanation of system is clear, and\nthe analysis is thorough.\nThe system itself is a natural extension of various ideas. The most similar\nwork include tree-based generation with parent feeding (Dong and Lapata, 2016)\nand various RNN-based semantic parsing with copy mechanism (Jia and\nLiang, 2016; Ling et al., 2016). [The guidance of parsing based on grammar is\nalso explored in Chen Liang et al., 2016 (https://arxiv.org/abs/1611.00020)\nwhere a code-assist system is used to ensure that the code\nis valid.] Nevertheless, the model is this paper stands out as it is able to\ngenerate much longer and more complex programs than most previous work\nmentioned. \nWeaknesses:\nThe evaluation is done on code accuracy (exact match) and BLEU score. These\nmetrics (especially BLEU) might not be the best metrics for evaluating the\ncorrectness of programs. For instance, the first example in Table 5 shows that\nwhile the first two lines in boxes A and B are different, they have the same\nsemantics. Another example is that variable names can be different. Evaluation\nbased on what the code does (e.g., using test cases or static code analysis)\nwould be more convincing.\nAnother point about evaluation: other systems (e.g., NMT baseline) may generate\ncode with syntactic error. Would it be possible to include the result on the\nhighest-scoring well-formed code (e.g., using beam search) that these baseline\nsystems generate? This would give a fairer comparison since these system can\nchoose to prune malformed code.\nGeneral Discussion:\n* Lines 120-121: some approaches that use domain-specific languages were also\nguided by a grammar. One example is Berant and Liang, 2014, which uses a pretty\nlimited grammar for logical forms (Table 1). In addition to comparing to that\nline of work, emphasizing that the grammar in this paper is much larger than\nmost previous work would make this work stronger.\n* Lines 389-397: For the parent feeding mechanism, is the child index being\nused? In other words, is p_t different when generating a first child versus a\nsecond child? In Seq2Tree (Dong and Lapata, 2016) the two non-terminals would\nhave different hidden states.\n* Line 373: Are the possible tokens embedded? Is it assumed that the set of\npossible tokens is known beforehand?\n* The examples in the appendix are nice.\n---\nI have read the author response."
        }
    ]
}