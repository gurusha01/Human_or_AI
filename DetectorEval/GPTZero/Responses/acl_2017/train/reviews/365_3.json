{
    "version": "2025-01-09-base",
    "scanId": "f1a04fcd-9c03-4ff1-a755-768e826e733f",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.07019487768411636,
                    "sentence": "- Strengths: well written, solid experimental setup and intriguing qualitative",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10774848610162735,
                    "sentence": "analysis",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07817193120718002,
                    "sentence": "- Weaknesses: except for the qualitative analysis, the paper may belong better",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1060558557510376,
                    "sentence": "to the applications area, since the models are not particularly new but the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06927875429391861,
                    "sentence": "application itself is most of its novelty",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04406971111893654,
                    "sentence": "- General Discussion: This paper presents a \"sequence-to-sequence\" model with",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07408969849348068,
                    "sentence": "attention mechanisms and an auxiliary phonetic prediction task to tackle",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06389674544334412,
                    "sentence": "historical text normalization.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04111851006746292,
                    "sentence": "None of the used models or techniques are new by",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05689413845539093,
                    "sentence": "themselves, but they seem to have never been used in this problem before,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07263902574777603,
                    "sentence": "showing and improvement over the state-of-the-art.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06102770194411278,
                    "sentence": "Most of the paper seem like a better fit for the applications track, except for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10700555145740509,
                    "sentence": "the final analysis where the authors link attention with multi-task learning,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04607965052127838,
                    "sentence": "claiming that the two produce similar effects.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04360264539718628,
                    "sentence": "The hypothesis is intriguing,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.037808857858181,
                    "sentence": "and it's supported with a wealth of evidence, at least for the presented task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01959635503590107,
                    "sentence": "I do have some questions on this analysis though:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03126934915781021,
                    "sentence": "1) In Section 5.1, aren't you assuming that the hidden layer spaces of the two",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05482064187526703,
                    "sentence": "models are aligned?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1647612303495407,
                    "sentence": "Is it safe to do so?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.032629527151584625,
                    "sentence": "2) Section 5.2, I don't get what you mean by the errors that each of the models",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04788058623671532,
                    "sentence": "resolve independently of each other.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14144474267959595,
                    "sentence": "This is like symmetric-difference?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.028209298849105835,
                    "sentence": "That",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07398620247840881,
                    "sentence": "is, if we combine the two models these errors are not resolved anymore?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07641012221574783,
                    "sentence": "On a different vein, 3) Why is there no comparison with Azawi's model?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.329456090927124,
                    "sentence": "========",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0641881600022316,
                    "sentence": "After reading the author's response.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06595998257398605,
                    "sentence": "I'm feeling more concerned than I was before about your claims of alignment in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02969917468726635,
                    "sentence": "the hidden space of the two models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08895756304264069,
                    "sentence": "If accepted, I would strongly encourage the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23731230199337006,
                    "sentence": "authors to make clear",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05679687485098839,
                    "sentence": "in the paper the discussion you have shared with us for why you think that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05171828344464302,
                    "sentence": "alignment holds in practice.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.06042626278398002,
            "class_probabilities": {
                "human": 0.9395737372160199,
                "ai": 0.06042626278398002,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9395737372160199,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.06042626278398002,
                    "human": 0.9395737372160199,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "- Strengths: well written, solid experimental setup and intriguing qualitative\nanalysis\n- Weaknesses: except for the qualitative analysis, the paper may belong better\nto the applications area, since the models are not particularly new but the\napplication itself is most of its novelty\n- General Discussion: This paper presents a \"sequence-to-sequence\" model with\nattention mechanisms and an auxiliary phonetic prediction task to tackle\nhistorical text normalization. None of the used models or techniques are new by\nthemselves, but they seem to have never been used in this problem before,\nshowing and improvement over the state-of-the-art. \nMost of the paper seem like a better fit for the applications track, except for\nthe final analysis where the authors link attention with multi-task learning,\nclaiming that the two produce similar effects. The hypothesis is intriguing,\nand it's supported with a wealth of evidence, at least for the presented task. \nI do have some questions on this analysis though:\n1) In Section 5.1, aren't you assuming that the hidden layer spaces of the two\nmodels are aligned? Is it safe to do so?\n2) Section 5.2, I don't get what you mean by the errors that each of the models\nresolve independently of each other. This is like symmetric-difference? That\nis, if we combine the two models these errors are not resolved anymore?\nOn a different vein, 3) Why is there no comparison with Azawi's model?\n========\nAfter reading the author's response.\nI'm feeling more concerned than I was before about your claims of alignment in\nthe hidden space of the two models. If accepted, I would strongly encourage the\nauthors to make clear\nin the paper the discussion you have shared with us for why you think that\nalignment holds in practice."
        }
    ]
}