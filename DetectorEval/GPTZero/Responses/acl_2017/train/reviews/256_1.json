{
    "version": "2025-01-09-base",
    "scanId": "655ef2f3-429c-4358-9951-9310b5b1079e",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.43812108039855957,
                    "sentence": "Review, ACL 2017, paper 256:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1667914241552353,
                    "sentence": "This paper extends the line of work which models generation in dialogue as a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3945861756801605,
                    "sentence": "sequence to sequence generation problem, where the past N-1 utterances (the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2888256311416626,
                    "sentence": "'dialogue context') are encoded into a context vector (plus potential",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3033744990825653,
                    "sentence": "other, hand-crafted features), which is then decoded into a response: the Nth",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5205912590026855,
                    "sentence": "turn in the dialogue.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10633204877376556,
                    "sentence": "As it stands, such models tend to suffer from lack of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.28145402669906616,
                    "sentence": "diversity, specificity and local coherence in the kinds of response they tend",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.46093422174453735,
                    "sentence": "to produce when trained over large dialogue datasets containing many topics",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2767249047756195,
                    "sentence": "(e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.80450040102005,
                    "sentence": "Cornell, Opensubtitles, Ubuntu, etc.).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.25529518723487854,
                    "sentence": "Rather than attempting to produce",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4755591154098511,
                    "sentence": "diverse responses using the decoder, e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5410619974136353,
                    "sentence": "through word-by-word beam search",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3514702022075653,
                    "sentence": "(which has been shown not to work very well, even lose crucial information",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3900279998779297,
                    "sentence": "about grammar and valid sequences), or via a different objective function (such",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6505510210990906,
                    "sentence": "as in Li et.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.45732834935188293,
                    "sentence": "al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.37979763746261597,
                    "sentence": "'s work) the authors introduce a latent variable, z, over",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.44709286093711853,
                    "sentence": "which a probability distribution is induced as part of the network.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7322351932525635,
                    "sentence": "At",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4924071729183197,
                    "sentence": "prediction time, after encoding utterances 1 to k, a context z is sampled, and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.45793893933296204,
                    "sentence": "the decoder is greedily used to generate a response from this.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.40142807364463806,
                    "sentence": "The evaluation",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.45047295093536377,
                    "sentence": "shows small improvements in BLEU scores over a vanilla seq2seq model that does",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4381779432296753,
                    "sentence": "not involve learning a probability distribution over contexts and sampling from",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.40904101729393005,
                    "sentence": "this.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.30346474051475525,
                    "sentence": "The paper is certainly impressive from a technical point of view, i.e.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3368988335132599,
                    "sentence": "in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4319803714752197,
                    "sentence": "application of deep learning methods, specifically conditioned variational auto",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.377545565366745,
                    "sentence": "encoders, to the problem of response generation, and its attendant difficulties",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5625113248825073,
                    "sentence": "in training such models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.579855740070343,
                    "sentence": "Their use of Information-Retrieval techniques to get",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5470569133758545,
                    "sentence": "more than one reference response is also interesting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3325386643409729,
                    "sentence": "I have some conceptual comments on the introduction and the motivations behind",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5635207295417786,
                    "sentence": "the work, some on the model architecture, and the evaluation which I write",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7386425137519836,
                    "sentence": "below in turn:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.819849967956543,
                    "sentence": "Comments on the introduction and motivations\"Â¦.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7741013765335083,
                    "sentence": "The authors seem not fully aware of the long history of this field, and its",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04904443770647049,
                    "sentence": "various facets, whether from a theoretical perspective, or from an applied one.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.042735934257507324,
                    "sentence": "1. \"[the dialogue manager] typically takes a new utterance and the dialogue",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03193693235516548,
                    "sentence": "context as input, and generates discourse level decisions.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022337689995765686,
                    "sentence": "This is not accurate.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08171695470809937,
                    "sentence": "Traditionally at least, the job of the dialogue",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0825471431016922,
                    "sentence": "manager is to select actions (dialogue acts) in a particular dialogue context.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05192216858267784,
                    "sentence": "The action chosen is then passed to a separate generation",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06334380805492401,
                    "sentence": "module",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07708600163459778,
                    "sentence": "for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.059230171144008636,
                    "sentence": "realisation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09310360252857208,
                    "sentence": "Dialogue management is usually done in the context of task-based",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03693230077624321,
                    "sentence": "systems which are goal driven.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06687693297863007,
                    "sentence": "The dialogue manager is to choose actions which",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01439602393656969,
                    "sentence": "are optimal in some sense, e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021004565060138702,
                    "sentence": "reach a goal (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021066488698124886,
                    "sentence": "book a restaurant) in as few",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00235861842520535,
                    "sentence": "steps as possible.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019988343119621277,
                    "sentence": "See publications from Lemon & Pietquin, 2012, Rieser, Keizer",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021158915013074875,
                    "sentence": "and colleagues, and various publications from Steve Young, Milica Gasic and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01037637796252966,
                    "sentence": "colleagues for an overview of the large literature on Reinforcement Learning",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027187835425138474,
                    "sentence": "and MDP models for task-based dialogue systems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1589837223291397,
                    "sentence": "2. The authors need to make a clear distinction between task-based,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09374866634607315,
                    "sentence": "goal-oriented dialogue, and chatbots/social bots, the latter being usually no",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06193527579307556,
                    "sentence": "more than a language model, albeit a sophisticated one (though see Wen et.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06217013671994209,
                    "sentence": "al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10445767641067505,
                    "sentence": "2016).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11462800204753876,
                    "sentence": "What is required from these two types of system is usually distinct.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04793800413608551,
                    "sentence": "Whereas the former is required to complete a task, the latter is, perhaps only",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0908120647072792,
                    "sentence": "required to keep the user engaged.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02504311501979828,
                    "sentence": "Indeed the data-driven methods that have",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08051300048828125,
                    "sentence": "been used to build such systems are usually very different.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025452570989727974,
                    "sentence": "3. The authors refer to 'open-domain' conversation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05662882328033447,
                    "sentence": "I would suggest that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.028100810945034027,
                    "sentence": "there is no such thing as open-domain conversation - conversation is always in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022486509755253792,
                    "sentence": "the context of some activity and for doing/achieving something specific in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013881513848900795,
                    "sentence": "world.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04035021364688873,
                    "sentence": "And it is this overarching goal, the overarching activity, this",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09829190373420715,
                    "sentence": "overarching genre, which determines the outward shape of dialogues and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10164663940668106,
                    "sentence": "determines what sorts of dialogue structure are coherent.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07139885425567627,
                    "sentence": "Coherence itself is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03264722228050232,
                    "sentence": "activity/context-specific.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03435097634792328,
                    "sentence": "Indeed a human is not capable of open-domain",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0496935173869133,
                    "sentence": "dialogue: if they are faced with a conversational topic or genre that they have",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04377951845526695,
                    "sentence": "never participated in, they would embarrass themselves with utterances that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023229777812957764,
                    "sentence": "would look incoherent and out of place to others already familiar with it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025851834565401077,
                    "sentence": "(think of a random person on the street trying to follow the conversations at",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0726647898554802,
                    "sentence": "some coffee break at ACL).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.044073667377233505,
                    "sentence": "This is the fundamental problem I see with systems",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07807598263025284,
                    "sentence": "that attempt to use data from an EXTREMELY DIVERSE, open-ended set of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02469615265727043,
                    "sentence": "conversational genres (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.045866042375564575,
                    "sentence": "movie subtitles) in order to train one model,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04648897051811218,
                    "sentence": "mushing everything together so that what emerges at the other end is just very",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04053556174039841,
                    "sentence": "good grammatical structure.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06486788392066956,
                    "sentence": "Or very generic responses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0734863430261612,
                    "sentence": "Comments on the model architecture:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.042856983840465546,
                    "sentence": "Rather than generate from a single encoded context, the authors induce a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05065179616212845,
                    "sentence": "distribution over possible contexts, sample from this, and generate greedily",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11310479044914246,
                    "sentence": "with the decoder.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.055075790733098984,
                    "sentence": "It seems to me that this general model is counter intuitive,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03735619783401489,
                    "sentence": "and goes against evidence from the Linguistic/Psycholinguistic literature on",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04819649085402489,
                    "sentence": "dialogue: this literature shows that people tend to resolve potential problems",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021251799538731575,
                    "sentence": "in understanding and acceptance very locally - i.e.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05581571161746979,
                    "sentence": "make sure they agree on",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03205278515815735,
                    "sentence": "what the context of the conversation is - and only then move on with the rest",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03965285047888756,
                    "sentence": "of the conversation, so that at any given point, there is little uncertainty",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08867507427930832,
                    "sentence": "about the current context of the conversation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08088609576225281,
                    "sentence": "The massive diversity one sees",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09058360010385513,
                    "sentence": "results from the diversity in what the conversation is actually trying to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06344851851463318,
                    "sentence": "achieve (see above), diversity in topics and contexts etc, so that in a given,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06150014325976372,
                    "sentence": "fixed context, there is a multitude of possible next actions, all coherent, but",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06573432683944702,
                    "sentence": "leading the conversation down a different path.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0791158527135849,
                    "sentence": "It therefore seems strange to me at least to shift the burden of explaining",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07277345657348633,
                    "sentence": "diversity and coherence in follow-up actions to that of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05787346139550209,
                    "sentence": "linguistic/verbal/surface contexts in which they are uttered, though of course,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06554721295833588,
                    "sentence": "uncertainty here can also arise as a result of mismatches in vocabulary,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08511824905872345,
                    "sentence": "grammars, concepts, people's backgrounds etc.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17888551950454712,
                    "sentence": "But this probably wouldn't",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6287110447883606,
                    "sentence": "explain much of the variation in follow-up response.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6963541507720947,
                    "sentence": "In fact, at least as far as task-based Dialogue systems are concerned, the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6948757767677307,
                    "sentence": "challenge is to capture synonymy of contexts, i.e.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8639194965362549,
                    "sentence": "dialogues that are distinct",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5595784783363342,
                    "sentence": "on the surface, but lead to the same or similar context, either in virtue of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7085129618644714,
                    "sentence": "interactional and syntactic equivalence relations, or synonymy relations that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5052794218063354,
                    "sentence": "might hold in a particular domain between words or sequences of words (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4802703559398651,
                    "sentence": "\"what is your destination?\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5665501952171326,
                    "sentence": "= \"where would you like to go?\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.32490578293800354,
                    "sentence": "in a flight",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.29970234632492065,
                    "sentence": "booking domain).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4170219600200653,
                    "sentence": "See e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5262516736984253,
                    "sentence": "Bordes & Weston, 2016; and Kalatzis, Eshghi & Lemon,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.477594256401062,
                    "sentence": "2016 - the latter use a grammar to cluster semantically similar dialogues.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2649454176425934,
                    "sentence": "Comments on the evaluation:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3591776192188263,
                    "sentence": "The authors seek to show that their model can generate more coherent, and more",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.39067623019218445,
                    "sentence": "diverse responses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3458230495452881,
                    "sentence": "The evaluation method, though very interesting, seems to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.34619563817977905,
                    "sentence": "address coherence but not diversity, despite what they say in section 5.2:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3846290707588196,
                    "sentence": "The precision and recall metrics measure distance between ground truth",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.43108871579170227,
                    "sentence": "utterances and the ones the model generates, but not that between the generated",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5431137084960938,
                    "sentence": "utterances themselves (unless I'm misunderstanding the evaluation method).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14683833718299866,
                    "sentence": "See e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5238765478134155,
                    "sentence": "Li et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.45702049136161804,
                    "sentence": "who measure diversity by counting the number distinct",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.610550045967102,
                    "sentence": "n-grams in the generated responses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5638813376426697,
                    "sentence": "Furthermore, I'm not sure that the increase in BLEU scores are meaningful:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4804006516933441,
                    "sentence": "they are very small.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.48296794295310974,
                    "sentence": "In the qualitative assessment of the generated responses,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5613362789154053,
                    "sentence": "one certainly sees more diversity, and more contentful utterances in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4580515921115875,
                    "sentence": "examples provided.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6211525201797485,
                    "sentence": "But I can't see how frequent such cases in fact are.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7554770112037659,
                    "sentence": "Also, it would have made for a stronger, more meaningful paper if the authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.645436704158783,
                    "sentence": "had compared their results with other work, (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9034109711647034,
                    "sentence": "Li et.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7673250436782837,
                    "sentence": "al) that use very",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7745329737663269,
                    "sentence": "different methods to promote diversity (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8615387082099915,
                    "sentence": "by using a different objective",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9168362617492676,
                    "sentence": "function).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8409087061882019,
                    "sentence": "The authors in fact do not mention this, or characterise it",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.043642085045576096,
                    "sentence": "properly, despite actually referring to Li et.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03836832195520401,
                    "sentence": "al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0691666230559349,
                    "sentence": "2015.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.07332528267997859
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 59,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 64,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 66,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 67,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 69,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 70,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 72,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 73,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 74,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 76,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 77,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 79,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 81,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 82,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 83,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 84,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 85,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 87,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 88,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 90,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 91,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 93,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 94,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 95,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 96,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 98,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 99,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 100,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 102,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 103,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 104,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 106,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 107,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 108,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 109,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 110,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 111,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 112,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 113,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 114,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 116,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 117,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 118,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.3063829682933457
                },
                {
                    "start_sentence_index": 120,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 121,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 122,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 123,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 126,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 129,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 130,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 131,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 132,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 134,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 135,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 136,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 137,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 138,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 141,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 142,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 143,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 145,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 146,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 148,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 149,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.07332528267997859
                },
                {
                    "start_sentence_index": 152,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.3063829682933457
                },
                {
                    "start_sentence_index": 154,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 156,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                }
            ],
            "completely_generated_prob": 0.1519714707116977,
            "class_probabilities": {
                "human": 0.847975265147624,
                "ai": 0.1519714707116977,
                "mixed": 5.326414067820469e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.847975265147624,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.1519714707116977,
                    "human": 0.847975265147624,
                    "mixed": 5.326414067820469e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Review, ACL 2017, paper 256:\nThis paper extends the line of work which models generation in dialogue as a\nsequence to sequence generation problem, where the past N-1 utterances (the\n'dialogue context') are encoded into a context vector (plus potential\nother, hand-crafted features), which is then decoded into a response: the Nth\nturn in the dialogue. As it stands, such models tend to suffer from lack of\ndiversity, specificity and local coherence in the kinds of response they tend\nto produce when trained over large dialogue datasets containing many topics\n(e.g. Cornell, Opensubtitles, Ubuntu, etc.). Rather than attempting to produce\ndiverse responses using the decoder, e.g. through word-by-word beam search\n(which has been shown not to work very well, even lose crucial information\nabout grammar and valid sequences), or via a different objective function (such\nas in Li et. al.'s work) the authors introduce a latent variable, z, over\nwhich a probability distribution is induced as part of the network. At\nprediction time, after encoding utterances 1 to k, a context z is sampled, and\nthe decoder is greedily used to generate a response from this. The evaluation\nshows small improvements in BLEU scores over a vanilla seq2seq model that does\nnot involve learning a probability distribution over contexts and sampling from\nthis.\nThe paper is certainly impressive from a technical point of view, i.e. in the\napplication of deep learning methods, specifically conditioned variational auto\nencoders, to the problem of response generation, and its attendant difficulties\nin training such models. Their use of Information-Retrieval techniques to get\nmore than one reference response is also interesting. \nI have some conceptual comments on the introduction and the motivations behind\nthe work, some on the model architecture, and the evaluation which I write\nbelow in turn:\nComments on the introduction and motivations\"Â¦. \nThe authors seem not fully aware of the long history of this field, and its\nvarious facets, whether from a theoretical perspective, or from an applied one.\n1. \"[the dialogue manager] typically takes a new utterance and the dialogue\ncontext as input, and generates discourse level decisions.\" \n This is not accurate. Traditionally at least, the job of the dialogue\nmanager is to select actions (dialogue acts) in a particular dialogue context.\nThe action chosen is then passed to a separate generation\nmodule\nfor\nrealisation. Dialogue management is usually done in the context of task-based\nsystems which are goal driven. The dialogue manager is to choose actions which\nare optimal in some sense, e.g. reach a goal (e.g. book a restaurant) in as few\nsteps as possible. See publications from Lemon & Pietquin, 2012, Rieser, Keizer\nand colleagues, and various publications from Steve Young, Milica Gasic and\ncolleagues for an overview of the large literature on Reinforcement Learning\nand MDP models for task-based dialogue systems.\n2. The authors need to make a clear distinction between task-based,\ngoal-oriented dialogue, and chatbots/social bots, the latter being usually no\nmore than a language model, albeit a sophisticated one (though see Wen et. al.\n2016). What is required from these two types of system is usually distinct.\nWhereas the former is required to complete a task, the latter is, perhaps only\nrequired to keep the user engaged. Indeed the data-driven methods that have\nbeen used to build such systems are usually very different. \n3. The authors refer to 'open-domain' conversation. I would suggest that\nthere is no such thing as open-domain conversation - conversation is always in\nthe context of some activity and for doing/achieving something specific in the\nworld. And it is this overarching goal, the overarching activity, this\noverarching genre, which determines the outward shape of dialogues and\ndetermines what sorts of dialogue structure are coherent. Coherence itself is\nactivity/context-specific. Indeed a human is not capable of open-domain\ndialogue: if they are faced with a conversational topic or genre that they have\nnever participated in, they would embarrass themselves with utterances that\nwould look incoherent and out of place to others already familiar with it.\n(think of a random person on the street trying to follow the conversations at\nsome coffee break at ACL). This is the fundamental problem I see with systems\nthat attempt to use data from an EXTREMELY DIVERSE, open-ended set of\nconversational genres (e.g. movie subtitles) in order to train one model,\nmushing everything together so that what emerges at the other end is just very\ngood grammatical structure. Or very generic responses. \nComments on the model architecture:\nRather than generate from a single encoded context, the authors induce a\ndistribution over possible contexts, sample from this, and generate greedily\nwith the decoder. It seems to me that this general model is counter intuitive,\nand goes against evidence from the Linguistic/Psycholinguistic literature on\ndialogue: this literature shows that people tend to resolve potential problems\nin understanding and acceptance very locally - i.e. make sure they agree on\nwhat the context of the conversation is - and only then move on with the rest\nof the conversation, so that at any given point, there is little uncertainty\nabout the current context of the conversation. The massive diversity one sees\nresults from the diversity in what the conversation is actually trying to\nachieve (see above), diversity in topics and contexts etc, so that in a given,\nfixed context, there is a multitude of possible next actions, all coherent, but\nleading the conversation down a different path.\nIt therefore seems strange to me at least to shift the burden of explaining\ndiversity and coherence in follow-up actions to that of the\nlinguistic/verbal/surface contexts in which they are uttered, though of course,\nuncertainty here can also arise as a result of mismatches in vocabulary,\ngrammars, concepts, people's backgrounds etc. But this probably wouldn't\nexplain much of the variation in follow-up response. \nIn fact, at least as far as task-based Dialogue systems are concerned, the\nchallenge is to capture synonymy of contexts, i.e. dialogues that are distinct\non the surface, but lead to the same or similar context, either in virtue of\ninteractional and syntactic equivalence relations, or synonymy relations that\nmight hold in a particular domain between words or sequences of words (e.g.\n\"what is your destination?\" = \"where would you like to go?\" in a flight\nbooking domain). See e.g. Bordes & Weston, 2016; and Kalatzis, Eshghi & Lemon,\n2016 - the latter use a grammar to cluster semantically similar dialogues.\nComments on the evaluation:\nThe authors seek to show that their model can generate more coherent, and more\ndiverse responses. The evaluation method, though very interesting, seems to\naddress coherence but not diversity, despite what they say in section 5.2:\nThe precision and recall metrics measure distance between ground truth\nutterances and the ones the model generates, but not that between the generated\nutterances themselves (unless I'm misunderstanding the evaluation method).\nSee e.g. Li et al. who measure diversity by counting the number distinct\nn-grams in the generated responses.\nFurthermore, I'm not sure that the increase in BLEU scores are meaningful:\nthey are very small. In the qualitative assessment of the generated responses,\none certainly sees more diversity, and more contentful utterances in the\nexamples provided. But I can't see how frequent such cases in fact are.\nAlso, it would have made for a stronger, more meaningful paper if the authors\nhad compared their results with other work, (e.g. Li et. al) that use very\ndifferent methods to promote diversity (e.g. by using a different objective\nfunction). The authors in fact do not mention this, or characterise it\nproperly, despite actually referring to Li et. al. 2015."
        }
    ]
}