{
    "version": "2025-01-09-base",
    "scanId": "baaf7ea3-98ca-4962-80fb-fba22aee77a2",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.007752901408821344,
                    "sentence": "This paper presents a gated attention mechanism for machine reading.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01964281126856804,
                    "sentence": "A key idea is to extend Attention Sum Reader (Kadlec et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014671862125396729,
                    "sentence": "2016) to multi-hop",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018053259700536728,
                    "sentence": "reasoning by fine-grained gated filter.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012772643938660622,
                    "sentence": "It's interesting and intuitive for machine reading.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012759979814291,
                    "sentence": "I like the idea along with significant improvement on benchmark datasets, but",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013212249614298344,
                    "sentence": "also have major concerns to get it published in ACL.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014481456018984318,
                    "sentence": "- The proposed GA mechanism looks promising, but not enough to convince the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013776687905192375,
                    "sentence": "importance of this technique over other state-of-the-art systems, because",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.016962051391601562,
                    "sentence": "engineering tricks presented 3.1.4 boost a lot on accuracy and are blended in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010103948414325714,
                    "sentence": "the result.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014372880570590496,
                    "sentence": "- Incomplete bibliography: Nearly all published work in reference section",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014776390045881271,
                    "sentence": "refers arxiv preprint version.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007707373704761267,
                    "sentence": "This makes me (and future readers) suspicious if this work thoroughly compares",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019654346629977226,
                    "sentence": "with prior work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010348651558160782,
                    "sentence": "Please make them complete if the published version is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013707596808671951,
                    "sentence": "available.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027173873037099838,
                    "sentence": "- Result from unpublished work (GA): GA baseline in table 1 and 3 is mentioned",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014401273801922798,
                    "sentence": "as previous work that is unpublished preprint.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00975222047418356,
                    "sentence": "I don't think this is necessary at all.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01069829985499382,
                    "sentence": "Alternately, I would like the author to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01926855742931366,
                    "sentence": "replace it with vanilla GA (or variant of the proposed model for baseline).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012445766478776932,
                    "sentence": "It doesn't make sense that result from the preprint which will end up being the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01271100714802742,
                    "sentence": "same as this ACL submission is presented in the same manuscript.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022031059488654137,
                    "sentence": "For fair blind-review, I didn't search on arvix archive though.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02222278155386448,
                    "sentence": "- Conflict on table 1 and 2: GA-- (table 1) is the same as K=1(AS) in table 2,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026752730831503868,
                    "sentence": "and GA (fix L(w)) is for K=3 in table 2.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013863163068890572,
                    "sentence": "Does this mean that GA-- is actually AS Reader?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02202308550477028,
                    "sentence": "It's not clear that GA-- is re-implementation of AS.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03135625272989273,
                    "sentence": "I assumed K=1 (AS) in table 2 uses also GloVe initialization and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02790622040629387,
                    "sentence": "token-attention, but it doesn't seem in GA--.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025129586458206177,
                    "sentence": "- I wish the proposed method compared with prior work in related work section",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008541074581444263,
                    "sentence": "(i.e.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022583261132240295,
                    "sentence": "what's differ from related work).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.020671728998422623,
                    "sentence": "- Fig 2 shows benefit of gated attention (which translates multi-hop",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017481498420238495,
                    "sentence": "architecture), and it's very impressive.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013189664110541344,
                    "sentence": "It would be great to see any",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.041828952729701996,
                    "sentence": "qualitative example with comparison.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.039839419682113825,
            "class_probabilities": {
                "human": 0.9601605803178862,
                "ai": 0.039839419682113825,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9601605803178862,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.039839419682113825,
                    "human": 0.9601605803178862,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a gated attention mechanism for machine reading. \nA key idea is to extend Attention Sum Reader (Kadlec et al. 2016) to multi-hop\nreasoning by fine-grained gated filter. \nIt's interesting and intuitive for machine reading. \nI like the idea along with significant improvement on benchmark datasets, but\nalso have major concerns to get it published in ACL.\n- The proposed GA mechanism looks promising, but not enough to convince the\nimportance of this technique over other state-of-the-art systems, because\nengineering tricks presented 3.1.4 boost a lot on accuracy and are blended in\nthe result.\n- Incomplete bibliography: Nearly all published work in reference section\nrefers arxiv preprint version. \nThis makes me (and future readers) suspicious if this work thoroughly compares\nwith prior work. Please make them complete if the published version is\navailable. \n- Result from unpublished work (GA): GA baseline in table 1 and 3 is mentioned\nas previous work that is unpublished preprint. \nI don't think this is necessary at all. Alternately, I would like the author to\nreplace it with vanilla GA (or variant of the proposed model for baseline). \nIt doesn't make sense that result from the preprint which will end up being the\nsame as this ACL submission is presented in the same manuscript. \nFor fair blind-review, I didn't search on arvix archive though.\n- Conflict on table 1 and 2: GA-- (table 1) is the same as K=1(AS) in table 2,\nand GA (fix L(w)) is for K=3 in table 2. \nDoes this mean that GA-- is actually AS Reader? \nIt's not clear that GA-- is re-implementation of AS. \nI assumed K=1 (AS) in table 2 uses also GloVe initialization and\ntoken-attention, but it doesn't seem in GA--. \n- I wish the proposed method compared with prior work in related work section\n(i.e. what's differ from related work).\n- Fig 2 shows benefit of gated attention (which translates multi-hop\narchitecture), and it's very impressive. It would be great to see any\nqualitative example with comparison."
        }
    ]
}