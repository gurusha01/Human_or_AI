{
    "version": "2025-01-09-base",
    "scanId": "01c36a55-f67b-4c54-9936-350f884d50b9",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.005083913914859295,
                    "sentence": "26: An End-to-End Model for Question Answering over Knowledge Base with",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006021926179528236,
                    "sentence": "Cross-Attention Combining Global Knowledge",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0069048465229570866,
                    "sentence": "This paper presents an approach for factoid question answering over a knowledge",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006104666739702225,
                    "sentence": "graph (Freebase), by using a neural model that attempts to learn a semantic",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0032415387686342,
                    "sentence": "correlation/correspondence between various \"aspects\" of the candidate answer",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004957803059369326,
                    "sentence": "(e.g., answer type, relation to question entity, answer semantic, etc.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007664650911465287,
                    "sentence": "and a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005260498728603125,
                    "sentence": "subset of words of the question.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005150008946657181,
                    "sentence": "A separate correspondence component is learned",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004941299557685852,
                    "sentence": "for each \"aspect\" of the candidate answers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008246848359704018,
                    "sentence": "The two key contributions of this",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006532242987304926,
                    "sentence": "work are: (1) the creation of separate components to capture different aspects",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0049475072883069515,
                    "sentence": "of the candidate answer, rather than relying on a single semantic",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004722593817859888,
                    "sentence": "representation, and (2) incorporating global context (from the KB) of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009953120723366737,
                    "sentence": "candidate answers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005183136090636253,
                    "sentence": "The most interesting aspect of this work, in my opinion, is the separation of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008319852873682976,
                    "sentence": "candidate answer representation into distinct aspects, which gives us (the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009524191729724407,
                    "sentence": "neural model developer) a little more control over guiding the NN models",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011677385307848454,
                    "sentence": "towards information that would be more beneficial in its decision making.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01075669564306736,
                    "sentence": "It",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008785405196249485,
                    "sentence": "sort of harkens to the more traditional algorithms that rely on feature",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007044059224426746,
                    "sentence": "engineering.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004345600493252277,
                    "sentence": "But in this case the \"feature engineering\" (i.e., aspects) is more",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01381772756576538,
                    "sentence": "subtle, and less onerous.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009808799251914024,
                    "sentence": "I encourage the authors to continue refining this",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012058706022799015,
                    "sentence": "system along these lines.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00931170117110014,
                    "sentence": "While the high-level idea is fairly clear to a reasonably informed reader, the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021004147827625275,
                    "sentence": "devil in the details would make it hard for some audience to immediately grasp",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.024391790851950645,
                    "sentence": "key insights from this work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01613912358880043,
                    "sentence": "Some parts of the paper could benefit from more",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013220572844147682,
                    "sentence": "explanation...",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.015408854000270367,
                    "sentence": "Specifically:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009879034012556076,
                    "sentence": "(1) Context aspect of candidate answers (e_c) is not clearly explained in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019240427762269974,
                    "sentence": "paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013904137536883354,
                    "sentence": "Therefore, the last two sentences of Section 3.2.2 seem unclear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00722399540245533,
                    "sentence": "(2) Mention of OOV in the abstract and introduction need more explanation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012860138900578022,
                    "sentence": "As",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005308639723807573,
                    "sentence": "such, I think the current exposition in the paper assumes a deep understanding",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004908897448331118,
                    "sentence": "of prior work by the reader.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005726204719394445,
                    "sentence": "(3) The experiments conducted in this paper restrict comparison to IR-based",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005678580608218908,
                    "sentence": "system -- and the reasoning behind this decision is reasonable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007868984714150429,
                    "sentence": "But it is not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008055944927036762,
                    "sentence": "clear then why the work of Yang et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006770622916519642,
                    "sentence": "(2014) -- which is described to be",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00399483647197485,
                    "sentence": "SP-based -- is part of the comparison.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012272532097995281,
                    "sentence": "While, I am all for including more",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009580504149198532,
                    "sentence": "systems in the comparison, there seem to be some inconsistencies in what should",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011242877691984177,
                    "sentence": "and should not be compared.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012881537899374962,
                    "sentence": "Additionally, I see not harm in also mentioning the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013504687696695328,
                    "sentence": "comparable performance numbers for the best SP-based systems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03133862838149071,
                    "sentence": "I observe in the paper that the embeddings are learned entirely from the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16497370600700378,
                    "sentence": "training data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017223447561264038,
                    "sentence": "I wonder how much impact the random initialization of these",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0268898643553257,
                    "sentence": "embeddings has on the end performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02122957818210125,
                    "sentence": "It would be interesting to determine",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012319598346948624,
                    "sentence": "(and list) the variance if any.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02129519358277321,
                    "sentence": "Additionally, if we were to start with",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03616943582892418,
                    "sentence": "pre-trained embeddings (e.g., from word2vec) instead of the randomly",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.030831728130578995,
                    "sentence": "initialized ones, would that have any impact?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.024671951308846474,
                    "sentence": "As I read the paper, one possible direction of future work that occurred to me",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018402885645627975,
                    "sentence": "was to possibly include structured queries (from SP-based methods) as part of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018308449536561966,
                    "sentence": "the cross-attention mechanism.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013668765313923359,
                    "sentence": "In other words, in addition to using the various",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02623745985329151,
                    "sentence": "aspects of the candidate answers as features, one could include structured",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026508469134569168,
                    "sentence": "queries that generate the produce that candidate answer as an additional aspect",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025528928264975548,
                    "sentence": "of the candidate answer.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0384371317923069,
                    "sentence": "An attention mechanism could then also focus on",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019026275724172592,
                    "sentence": "various parts of the structured query, and its (semantic) matches to the input",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0271541066467762,
                    "sentence": "question as an additional signal for the NN model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04398784041404724,
                    "sentence": "Just a thought.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010200110264122486,
                    "sentence": "Some notes regarding the positioning of the paper:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005271667614579201,
                    "sentence": "I hesitate to call the model proposed here \"attention\" models, because (per my",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007574204821139574,
                    "sentence": "admittedly limited understanding) attention mechanisms apply to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004256421234458685,
                    "sentence": "\"encoder-decoder\" situations, where semantics expressed in one structured form",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004823888652026653,
                    "sentence": "(e.g., image, sentence in one language, natural language question, etc.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00828239694237709,
                    "sentence": "are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0037171603180468082,
                    "sentence": "encoded into an abstract representation, and then generated into another",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006770829204469919,
                    "sentence": "structured form (e.g., caption, sentence in another language, structured query,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0019850516691803932,
                    "sentence": "etc.).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005870339926332235,
                    "sentence": "The attention mechanism allows the \"encoder\" to jump around and attend",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008500694297254086,
                    "sentence": "to different parts of the input (instead of sequentially) as the output is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010981579311192036,
                    "sentence": "being generated by the decoder.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02156519703567028,
                    "sentence": "This paper does not appear to fit this notion,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0183078795671463,
                    "sentence": "and may be confusing to a broader audience.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023976529017090797,
                    "sentence": "------",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03046581894159317,
                    "sentence": "Thank you for clarifications in the author response.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 59,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 63,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 64,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 65,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 67,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 68,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 70,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 71,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 72,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 73,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 74,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 76,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 77,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 78,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 80,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 81,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 83,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 84,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 85,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.0375246461941804,
            "class_probabilities": {
                "human": 0.9624347023880775,
                "ai": 0.0375246461941804,
                "mixed": 4.065141774218333e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9624347023880775,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.0375246461941804,
                    "human": 0.9624347023880775,
                    "mixed": 4.065141774218333e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "26: An End-to-End Model for Question Answering over Knowledge Base with\nCross-Attention Combining Global Knowledge\nThis paper presents an approach for factoid question answering over a knowledge\ngraph (Freebase), by using a neural model that attempts to learn a semantic\ncorrelation/correspondence between various \"aspects\" of the candidate answer\n(e.g., answer type, relation to question entity, answer semantic, etc.) and a\nsubset of words of the question. A separate correspondence component is learned\nfor each \"aspect\" of the candidate answers. The two key contributions of this\nwork are: (1) the creation of separate components to capture different aspects\nof the candidate answer, rather than relying on a single semantic\nrepresentation, and (2) incorporating global context (from the KB) of the\ncandidate answers.\nThe most interesting aspect of this work, in my opinion, is the separation of\ncandidate answer representation into distinct aspects, which gives us (the\nneural model developer) a little more control over guiding the NN models\ntowards information that would be more beneficial in its decision making. It\nsort of harkens to the more traditional algorithms that rely on feature\nengineering. But in this case the \"feature engineering\" (i.e., aspects) is more\nsubtle, and less onerous. I encourage the authors to continue refining this\nsystem along these lines.\nWhile the high-level idea is fairly clear to a reasonably informed reader, the\ndevil in the details would make it hard for some audience to immediately grasp\nkey insights from this work. Some parts of the paper could benefit from more\nexplanation... Specifically:\n(1) Context aspect of candidate answers (e_c) is not clearly explained in the\npaper. Therefore, the last two sentences of Section 3.2.2 seem unclear.\n(2) Mention of OOV in the abstract and introduction need more explanation. As\nsuch, I think the current exposition in the paper assumes a deep understanding\nof prior work by the reader.\n(3) The experiments conducted in this paper restrict comparison to IR-based\nsystem -- and the reasoning behind this decision is reasonable. But it is not\nclear then why the work of Yang et al. (2014) -- which is described to be\nSP-based -- is part of the comparison. While, I am all for including more\nsystems in the comparison, there seem to be some inconsistencies in what should\nand should not be compared. Additionally, I see not harm in also mentioning the\ncomparable performance numbers for the best SP-based systems.\nI observe in the paper that the embeddings are learned entirely from the\ntraining data. I wonder how much impact the random initialization of these\nembeddings has on the end performance. It would be interesting to determine\n(and list) the variance if any. Additionally, if we were to start with\npre-trained embeddings (e.g., from word2vec) instead of the randomly\ninitialized ones, would that have any impact?\nAs I read the paper, one possible direction of future work that occurred to me\nwas to possibly include structured queries (from SP-based methods) as part of\nthe cross-attention mechanism. In other words, in addition to using the various\naspects of the candidate answers as features, one could include structured\nqueries that generate the produce that candidate answer as an additional aspect\nof the candidate answer. An attention mechanism could then also focus on\nvarious parts of the structured query, and its (semantic) matches to the input\nquestion as an additional signal for the NN model. Just a thought.\nSome notes regarding the positioning of the paper:\nI hesitate to call the model proposed here \"attention\" models, because (per my\nadmittedly limited understanding) attention mechanisms apply to\n\"encoder-decoder\" situations, where semantics expressed in one structured form\n(e.g., image, sentence in one language, natural language question, etc.) are\nencoded into an abstract representation, and then generated into another\nstructured form (e.g., caption, sentence in another language, structured query,\netc.). The attention mechanism allows the \"encoder\" to jump around and attend\nto different parts of the input (instead of sequentially) as the output is\nbeing generated by the decoder. This paper does not appear to fit this notion,\nand may be confusing to a broader audience.\n------\nThank you for clarifications in the author response."
        }
    ]
}