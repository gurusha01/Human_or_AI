{
    "version": "2025-01-09-base",
    "scanId": "b26ca1f7-49f2-4a08-871e-1fbaa860f271",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.024824900552630424,
                    "sentence": "- Strengths: A nice, solid piece of work that builds on previous studies in a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05061713606119156,
                    "sentence": "productive way.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02298448421061039,
                    "sentence": "Well-written and clear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03418080136179924,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0213429294526577,
                    "sentence": "Very few--possibly avoid some relatively \"empty\" statements:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027727987617254257,
                    "sentence": "191: For example, if our task is to identify words used similarly across",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03124941512942314,
                    "sentence": "contexts, our scoring function can be specified to give high scores to terms",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05648324638605118,
                    "sentence": "whose usage is similar across the contexts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04200487583875656,
                    "sentence": "537: It is educational to study how annotations drawn from the same data are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03826507553458214,
                    "sentence": "similar or different.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05666188523173332,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.038217198103666306,
                    "sentence": "In the first sections I was not sure that much was being done that was new or",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03508792817592621,
                    "sentence": "interesting, as the methods seemed very reminiscent of previous methods used",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.033383291214704514,
                    "sentence": "over the past 25 years to measure similarity, albeit with a few new statistical",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.031126948073506355,
                    "sentence": "twists, but conceptually in the same vein.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.024502268061041832,
                    "sentence": "Section 5, however, describes an",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02605820819735527,
                    "sentence": "interesting and valuable piece of work that will be useful for future studies",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.015538724139332771,
                    "sentence": "on the topic.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03177729249000549,
                    "sentence": "In retrospect, the background provided in sections 2-4 is useful,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022827409207820892,
                    "sentence": "if not necessary, to support the experiments in section 5.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.030815038830041885,
                    "sentence": "In short, the work and results described will be useful to others working in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.041166581213474274,
                    "sentence": "this area, and the paper is worthy of presentation at ACL.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03170701116323471,
                    "sentence": "Minor comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.029636047780513763,
                    "sentence": "Word, punctuation missing?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04961125925183296,
                    "sentence": "264: For word annotations, we used PPMI, SVD, and SGNS (skipgram with negative",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.045613113790750504,
                    "sentence": "sampling from Mikolov et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0422712005674839,
                    "sentence": "(2013b)) word vectors released by Hamilton et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.028803309425711632,
                    "sentence": "(2016).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023722024634480476,
                    "sentence": "Unclear what \"multiple methods\" refers to:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07937151193618774,
                    "sentence": "278: some words were detected by multiple methods with CCLA",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.060423759254479424,
            "class_probabilities": {
                "human": 0.9395348095964596,
                "ai": 0.060423759254479424,
                "mixed": 4.1431149060857404e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9395348095964596,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.060423759254479424,
                    "human": 0.9395348095964596,
                    "mixed": 4.1431149060857404e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "- Strengths: A nice, solid piece of work that builds on previous studies in a\nproductive way. Well-written and clear. \n- Weaknesses:\n Very few--possibly avoid some relatively \"empty\" statements:\n191 : For example, if our task is to identify words used similarly across\ncontexts, our scoring function can be specified to give high scores to terms\nwhose usage is similar across the contexts.\n537 : It is educational to study how annotations drawn from the same data are\nsimilar or different.\n- General Discussion:\nIn the first sections I was not sure that much was being done that was new or\ninteresting, as the methods seemed very reminiscent of previous methods used\nover the past 25 years to measure similarity, albeit with a few new statistical\ntwists, but conceptually in the same vein. Section 5, however, describes an\ninteresting and valuable piece of work that will be useful for future studies\non the topic. In retrospect, the background provided in sections 2-4 is useful,\nif not necessary, to support the experiments in section 5. \nIn short, the work and results described will be useful to others working in\nthis area, and the paper is worthy of presentation at ACL.\nMinor comments:\nWord, punctuation missing?\n264 : For word annotations, we used PPMI, SVD, and SGNS (skipgram with negative\nsampling from Mikolov et al. (2013b)) word vectors released by Hamilton et al.\n(2016).\nUnclear what \"multiple methods\" refers to :\n278 : some words were detected by multiple methods with CCLA"
        }
    ]
}