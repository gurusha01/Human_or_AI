{
    "version": "2025-01-09-base",
    "scanId": "f4151519-b353-4487-b881-d9a53c2d62c3",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.7886095643043518,
                    "sentence": "- Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8579379320144653,
                    "sentence": "1. The proposed models are shown to lead to rather substantial and consistent",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.882122278213501,
                    "sentence": "improvements over reasonable baselines on two different tasks (word similarity",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7955225706100464,
                    "sentence": "and word analogy), which not only serves to demonstrate the effectiveness of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7873557806015015,
                    "sentence": "the models but also highlights the potential utility of incorporating sememe",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8500620126724243,
                    "sentence": "information from available knowledge resources for improving word",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6783555150032043,
                    "sentence": "representation learning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.778053879737854,
                    "sentence": "2. The paper contributes to ongoing efforts in the community to account for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6753367185592651,
                    "sentence": "polysemy in word representation learning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7751248478889465,
                    "sentence": "It builds nicely on previous work and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7075518369674683,
                    "sentence": "proposes some new ideas and improvements that could be of interest to the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7675760984420776,
                    "sentence": "community, such as applying an attention scheme to incorporate a form of soft",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6717846989631653,
                    "sentence": "word sense disambiguation into the learning procedure.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7617647647857666,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7873502969741821,
                    "sentence": "1. Presentation and clarity: important details with respect to the proposed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7813618183135986,
                    "sentence": "models are left out or poorly described (more details below).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7573466300964355,
                    "sentence": "Otherwise, the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8028357625007629,
                    "sentence": "paper generally reads fairly well; however, the manuscript would need to be",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7651286125183105,
                    "sentence": "improved if accepted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7232414484024048,
                    "sentence": "2. The evaluation on the word analogy task seems a bit unfair given that the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8310098052024841,
                    "sentence": "semantic relations are explicitly encoded by the sememes, as the authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8893475532531738,
                    "sentence": "themselves point out (more details below).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9720979928970337,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.896163284778595,
                    "sentence": "1. The authors stress the importance of accounting for polysemy and learning",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8368582725524902,
                    "sentence": "sense-specific representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9268988370895386,
                    "sentence": "While polysemy is taken into account by",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9106580018997192,
                    "sentence": "calculating sense distributions for words in particular contexts in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9306771159172058,
                    "sentence": "learning procedure, the evaluation tasks are entirely context-independent,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9372056126594543,
                    "sentence": "which means that, ultimately, there is only one vector per word -- or at least",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9289249181747437,
                    "sentence": "this is what is evaluated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9596173763275146,
                    "sentence": "Instead, word sense disambiguation and sememe",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9388129711151123,
                    "sentence": "information are used for improving the learning of word representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9805245995521545,
                    "sentence": "This",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.958712100982666,
                    "sentence": "needs to be clarified in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9448654651641846,
                    "sentence": "2. It is not clear how the sememe embeddings are learned and the description of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9565995931625366,
                    "sentence": "the SSA model seems to assume the pre-existence of sememe embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9493246078491211,
                    "sentence": "This is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10008633136749268,
                    "sentence": "important for understanding the subsequent models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1054302304983139,
                    "sentence": "Do the SAC and SAT models",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05557128041982651,
                    "sentence": "require pre-training of sememe embeddings?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022772401571273804,
                    "sentence": "3. It is unclear how the proposed models compare to models that only consider",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05250382795929909,
                    "sentence": "different senses but not sememes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07376819849014282,
                    "sentence": "Perhaps the MST baseline is an example of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.039344388991594315,
                    "sentence": "such a model?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027038753032684326,
                    "sentence": "If so, this is not sufficiently described (emphasis is instead",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04559487849473953,
                    "sentence": "put on soft vs. hard word sense disambiguation).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04301336407661438,
                    "sentence": "The paper would be stronger",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06905584037303925,
                    "sentence": "with the inclusion of more baselines based on related work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05444750189781189,
                    "sentence": "4. A reasonable argument is made that the proposed models are particularly",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08396217226982117,
                    "sentence": "useful for learning representations for low-frequency words (by mapping words",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11391707509756088,
                    "sentence": "to a smaller set of sememes that are shared by sets of words).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02224060334265232,
                    "sentence": "Unfortunately,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.054178886115550995,
                    "sentence": "no empirical evidence is provided to test the hypothesis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.056404124945402145,
                    "sentence": "It would have been",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21207642555236816,
                    "sentence": "interesting for the authors to look deeper into this.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09529715776443481,
                    "sentence": "This aspect also does not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06410068273544312,
                    "sentence": "seem to explain the improvements much since, e.g., the word similarity data",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15735717117786407,
                    "sentence": "sets contain frequent word pairs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06490550935268402,
                    "sentence": "5. Related to the above point, the improvement gains seem more attributable to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07318897545337677,
                    "sentence": "the incorporation of sememe information than word sense disambiguation in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0871739462018013,
                    "sentence": "learning procedure.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.054807838052511215,
                    "sentence": "As mentioned earlier, the evaluation involves only the use",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2236970067024231,
                    "sentence": "of context-independent word representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.053561851382255554,
                    "sentence": "Even if the method allows for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08894475549459457,
                    "sentence": "learning sememe- and sense-specific representations, they would have to be",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10437022149562836,
                    "sentence": "aggregated to carry out the evaluation task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11654873937368393,
                    "sentence": "6. The example illustrating HowNet (Figure 1) is not entirely clear, especially",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05675439164042473,
                    "sentence": "the modifiers of \"computer\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10485222190618515,
                    "sentence": "7. It says that the models are trained using their best parameters.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0651501789689064,
                    "sentence": "How exactly",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06908997148275375,
                    "sentence": "are these determined?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11490970104932785,
                    "sentence": "It is also unclear how K is set -- is it optimized for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14020085334777832,
                    "sentence": "each model or is it randomly chosen for each target word observation?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0609244629740715,
                    "sentence": "Finally,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.24199368059635162,
                    "sentence": "what is the motivation for setting K' to 2?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 59,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 64,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 65,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 66,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 67,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 68,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 70,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 72,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 74,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.49776035834266513,
            "class_probabilities": {
                "human": 0.5022396416573348,
                "ai": 0.49776035834266513,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.5022396416573348,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.49776035834266513,
                    "human": 0.5022396416573348,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "- Strengths:\n1. The proposed models are shown to lead to rather substantial and consistent\nimprovements over reasonable baselines on two different tasks (word similarity\nand word analogy), which not only serves to demonstrate the effectiveness of\nthe models but also highlights the potential utility of incorporating sememe\ninformation from available knowledge resources for improving word\nrepresentation learning.\n2. The paper contributes to ongoing efforts in the community to account for\npolysemy in word representation learning. It builds nicely on previous work and\nproposes some new ideas and improvements that could be of interest to the\ncommunity, such as applying an attention scheme to incorporate a form of soft\nword sense disambiguation into the learning procedure.\n- Weaknesses:\n1. Presentation and clarity: important details with respect to the proposed\nmodels are left out or poorly described (more details below). Otherwise, the\npaper generally reads fairly well; however, the manuscript would need to be\nimproved if accepted.\n2. The evaluation on the word analogy task seems a bit unfair given that the\nsemantic relations are explicitly encoded by the sememes, as the authors\nthemselves point out (more details below).\n- General Discussion:\n1. The authors stress the importance of accounting for polysemy and learning\nsense-specific representations. While polysemy is taken into account by\ncalculating sense distributions for words in particular contexts in the\nlearning procedure, the evaluation tasks are entirely context-independent,\nwhich means that, ultimately, there is only one vector per word -- or at least\nthis is what is evaluated. Instead, word sense disambiguation and sememe\ninformation are used for improving the learning of word representations. This\nneeds to be clarified in the paper.\n2. It is not clear how the sememe embeddings are learned and the description of\nthe SSA model seems to assume the pre-existence of sememe embeddings. This is\nimportant for understanding the subsequent models. Do the SAC and SAT models\nrequire pre-training of sememe embeddings?\n3. It is unclear how the proposed models compare to models that only consider\ndifferent senses but not sememes. Perhaps the MST baseline is an example of\nsuch a model? If so, this is not sufficiently described (emphasis is instead\nput on soft vs. hard word sense disambiguation). The paper would be stronger\nwith the inclusion of more baselines based on related work.\n4. A reasonable argument is made that the proposed models are particularly\nuseful for learning representations for low-frequency words (by mapping words\nto a smaller set of sememes that are shared by sets of words). Unfortunately,\nno empirical evidence is provided to test the hypothesis. It would have been\ninteresting for the authors to look deeper into this. This aspect also does not\nseem to explain the improvements much since, e.g., the word similarity data\nsets contain frequent word pairs.\n5. Related to the above point, the improvement gains seem more attributable to\nthe incorporation of sememe information than word sense disambiguation in the\nlearning procedure. As mentioned earlier, the evaluation involves only the use\nof context-independent word representations. Even if the method allows for\nlearning sememe- and sense-specific representations, they would have to be\naggregated to carry out the evaluation task.\n6. The example illustrating HowNet (Figure 1) is not entirely clear, especially\nthe modifiers of \"computer\".\n7. It says that the models are trained using their best parameters. How exactly\nare these determined? It is also unclear how K is set -- is it optimized for\neach model or is it randomly chosen for each target word observation? Finally,\nwhat is the motivation for setting K' to 2?"
        }
    ]
}