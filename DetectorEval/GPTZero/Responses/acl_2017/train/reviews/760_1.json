{
    "version": "2025-01-09-base",
    "scanId": "0b23ca09-acfe-4ee7-8c80-23abc16151f5",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.07590636610984802,
                    "sentence": "The paper proposes a recurrent neural architecture that can skip irrelevant",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17596811056137085,
                    "sentence": "input units.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.043710216879844666,
                    "sentence": "This is achieved by specifying R (of words to read at each",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.035796068608760834,
                    "sentence": "\"skim\"), K (max jump size), and N (max of jumps allowed).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06675943732261658,
                    "sentence": "An LSTM processes R",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04218192771077156,
                    "sentence": "words, predicts the jump size k in {0, 1...K} (0 signals stop), skips the next",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0937008261680603,
                    "sentence": "k-1 words and continues until either the number of jumps reaches N or the model",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15323583781719208,
                    "sentence": "reaches the last word.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11180838197469711,
                    "sentence": "While the model is not differentiable, it can be trained",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09247563779354095,
                    "sentence": "by standard policy gradient.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019285153597593307,
                    "sentence": "The work seems to have been heavily influenced by",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.044244833290576935,
                    "sentence": "Shen et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03202534839510918,
                    "sentence": "(2016) who apply a similar reinforcement learning approach",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02044139988720417,
                    "sentence": "(including the same variance stabilization) to multi-pass machine reading.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04985285550355911,
                    "sentence": "- Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014898384921252728,
                    "sentence": "The work simulates an intuitive \"skimming\" behavior of a reader, mirroring Shen",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012867294251918793,
                    "sentence": "et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02544187195599079,
                    "sentence": "who simulate (self-terminated) repeated reading.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03247328847646713,
                    "sentence": "A major attribute of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.028302956372499466,
                    "sentence": "this work is its simplicity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.037785306572914124,
                    "sentence": "Despite the simplicity, the approach yields",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010980688966810703,
                    "sentence": "favorable results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02599375508725643,
                    "sentence": "In particular, the authors show through a well-designed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05347920209169388,
                    "sentence": "synthetic experiment that the model is indeed able to learn to skip when given",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0449460968375206,
                    "sentence": "oracle jump signals.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.039365701377391815,
                    "sentence": "In text classification using real-world datasets, the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04207388311624527,
                    "sentence": "model is able to perform competitively with the non-skimming model while being",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026964494958519936,
                    "sentence": "clearly faster.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02909129671752453,
                    "sentence": "The proposed model can potentially have meaningful practical implications: for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07680447399616241,
                    "sentence": "tasks in which skimming suffices (e.g., sentiment classification), it suggests",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11236733198165894,
                    "sentence": "that we can obtain equivalent results without consuming all data in a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.243078351020813,
                    "sentence": "completely automated fashion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08746765553951263,
                    "sentence": "To my knowledge this is a novel finding.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4080228805541992,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07944007217884064,
                    "sentence": "It's a bit mysterious on what basis the model determines its jumping behavior",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09231468290090561,
                    "sentence": "so effectively (other than the synthetic dataset).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06585244089365005,
                    "sentence": "I'm thinking of a case where",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0937667191028595,
                    "sentence": "the last part of the given sentence is a crucial evidence, for instance:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12088842689990997,
                    "sentence": "\"The movie was so so and boring to the last minute but then its ending blew me",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10753283649682999,
                    "sentence": "away.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.129977285861969,
                    "sentence": "In this example, the model may decide to skip the rest of the sentence after",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.119244784116745,
                    "sentence": "reading \"so so and boring\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10110430419445038,
                    "sentence": "But by doing so it'll miss the turning point",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11718560755252838,
                    "sentence": "\"ending blew me away\" and mislabel the instance as negative.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08589596301317215,
                    "sentence": "For such cases a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11216975748538971,
                    "sentence": "solution can be running the skimming model in both directions as the authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09583467245101929,
                    "sentence": "suggest as future work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06084512546658516,
                    "sentence": "But in general the model may require more sophisticated",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12538006901741028,
                    "sentence": "architecture for controlling skimming.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04688484966754913,
                    "sentence": "It seems one can achieve improved skimming by combining it with multi-pass",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06205252185463905,
                    "sentence": "reading (presumably in reverse directions).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07984034717082977,
                    "sentence": "That's how humans read to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06949139386415482,
                    "sentence": "understand text that can't be digested in one skim; indeed, that's how I read",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.044057298451662064,
                    "sentence": "this draft.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10706940293312073,
                    "sentence": "Overall, the work raises an interesting problem and provides an effective but",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10435765981674194,
                    "sentence": "intuitive solution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.05924693143200553,
            "class_probabilities": {
                "human": 0.9404634541111649,
                "ai": 0.05924693143200553,
                "mixed": 0.0002896144568295141
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9404634541111649,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.05924693143200553,
                    "human": 0.9404634541111649,
                    "mixed": 0.0002896144568295141
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper proposes a recurrent neural architecture that can skip irrelevant\ninput units. This is achieved by specifying R (of words to read at each\n\"skim\"), K (max jump size), and N (max of jumps allowed). An LSTM processes R\nwords, predicts the jump size k in {0, 1...K} (0 signals stop), skips the next\nk-1 words and continues until either the number of jumps reaches N or the model\nreaches the last word. While the model is not differentiable, it can be trained\nby standard policy gradient. The work seems to have been heavily influenced by\nShen et al. (2016) who apply a similar reinforcement learning approach\n(including the same variance stabilization) to multi-pass machine reading. \n- Strengths:\nThe work simulates an intuitive \"skimming\" behavior of a reader, mirroring Shen\net al. who simulate (self-terminated) repeated reading. A major attribute of\nthis work is its simplicity. Despite the simplicity, the approach yields\nfavorable results. In particular, the authors show through a well-designed\nsynthetic experiment that the model is indeed able to learn to skip when given\noracle jump signals. In text classification using real-world datasets, the\nmodel is able to perform competitively with the non-skimming model while being\nclearly faster. \nThe proposed model can potentially have meaningful practical implications: for\ntasks in which skimming suffices (e.g., sentiment classification), it suggests\nthat we can obtain equivalent results without consuming all data in a\ncompletely automated fashion. To my knowledge this is a novel finding. \n- Weaknesses:\nIt's a bit mysterious on what basis the model determines its jumping behavior\nso effectively (other than the synthetic dataset). I'm thinking of a case where\nthe last part of the given sentence is a crucial evidence, for instance: \n\"The movie was so so and boring to the last minute but then its ending blew me\naway.\" \nIn this example, the model may decide to skip the rest of the sentence after\nreading \"so so and boring\". But by doing so it'll miss the turning point\n\"ending blew me away\" and mislabel the instance as negative. For such cases a\nsolution can be running the skimming model in both directions as the authors\nsuggest as future work. But in general the model may require more sophisticated\narchitecture for controlling skimming.\nIt seems one can achieve improved skimming by combining it with multi-pass\nreading (presumably in reverse directions). That's how humans read to\nunderstand text that can't be digested in one skim; indeed, that's how I read\nthis draft. \nOverall, the work raises an interesting problem and provides an effective but\nintuitive solution."
        }
    ]
}