{
    "version": "2025-01-09-base",
    "scanId": "402bc306-0f8d-49a8-8eea-59d1bea07464",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.07646169513463974,
                    "sentence": "- Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.060696035623550415,
                    "sentence": "a) The paper presents a Bayesian learning approach for recurrent neural network",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05012991279363632,
                    "sentence": "language model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1568649560213089,
                    "sentence": "The method outperforms standard SGD with dropout on three",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2003052532672882,
                    "sentence": "tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15968777239322662,
                    "sentence": "b) The idea of using Bayesian learning with RNNs appears to be novel.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1441642940044403,
                    "sentence": "c) The computationally efficient Bayesian algorithm for RNN would be of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12497028708457947,
                    "sentence": "interest to the NLP community for various applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.32242563366889954,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.186579629778862,
                    "sentence": "Primary concern is about evaluation:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.43420594930648804,
                    "sentence": "Sec 5.1: The paper reports the performance of difference types of architectures",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3127078413963318,
                    "sentence": "(LSTM/GRU/vanilla RNN) on character LM task while comparing the learning",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4815656840801239,
                    "sentence": "algorithms on the Penn Treebank task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5866590142250061,
                    "sentence": "Furthermore, RMSprop and pSGLD are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4805572032928467,
                    "sentence": "compared for the character LM while SGD +/- dropout is compared with SGLD +/-",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3629741966724396,
                    "sentence": "dropout on word language model task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5602386593818665,
                    "sentence": "This is inconsistent!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.380285382270813,
                    "sentence": "I would suggest",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17957966029644012,
                    "sentence": "reporting both these dimensions (i.e.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4201797544956207,
                    "sentence": "architectures and the exact same learning",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4495285749435425,
                    "sentence": "algorithms) on both character and word LM tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.36558598279953003,
                    "sentence": "It would be useful to know if",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6051750183105469,
                    "sentence": "the results from the proposed Bayesian learning approaches are portable across",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5118493437767029,
                    "sentence": "both these tasks and data sets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3033774495124817,
                    "sentence": "L529: The paper states that 'the performance gain mainly comes from adding",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.38054296374320984,
                    "sentence": "gradient noise and model averaging'.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.20795659720897675,
                    "sentence": "This statement is not justified",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.26542413234710693,
                    "sentence": "empirically.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.33979204297065735,
                    "sentence": "To arrive at this conclusion, an A/B experiment with/without",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1943054050207138,
                    "sentence": "adding gradient noise and/or model averaging needs to be done.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2856348752975464,
                    "sentence": "L724: Gal's dropout is run on the sentence classification task but not on",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.31113722920417786,
                    "sentence": "language model/captions task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.41609013080596924,
                    "sentence": "Since Gal's dropout is not specific to sentence",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3695063889026642,
                    "sentence": "classification, I would suggest reporting the performance of this method on",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4066397547721863,
                    "sentence": "all three tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2905101478099823,
                    "sentence": "This would allow the readers to fully assess the utility of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3175029456615448,
                    "sentence": "the proposed algorithms relative to all existing dropout approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.20053638517856598,
                    "sentence": "L544: Is there any sort order for the samples?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.26627179980278015,
                    "sentence": "(\\theta1,..., \\thetaK)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12198695540428162,
                    "sentence": "e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23505450785160065,
                    "sentence": "are samples with higher posterior probabilities likely to be at higher indices?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23640897870063782,
                    "sentence": "Why not report the result of randomly selecting K out of S samples, as an",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17791271209716797,
                    "sentence": "additional alternative?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3311099708080292,
                    "sentence": "Regular RNN LMs are known to be expensive to train and evaluate.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2259068787097931,
                    "sentence": "It would be",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.32495325803756714,
                    "sentence": "very useful to compare the training/evaluation times for the proposed Bayesian",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3406800627708435,
                    "sentence": "learning algorithms with SGD+ dropout.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.29323819279670715,
                    "sentence": "That would allow the readers to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2691853940486908,
                    "sentence": "trade-off improvements versus increase in training/run times.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2877182960510254,
                    "sentence": "Clarifications:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.39860042929649353,
                    "sentence": "L346: What does \\theta_s refer to?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.46660736203193665,
                    "sentence": "Is this a MAP estimate of parameters based",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5142737030982971,
                    "sentence": "on only the sample s?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3352454900741577,
                    "sentence": "L453-454: Clarify what \\theta means in the context of dropout/dropconnect.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3926604986190796,
                    "sentence": "Typos:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.41291341185569763,
                    "sentence": "L211: output",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.47739163041114807,
                    "sentence": "L738: RMSProp",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.04148363016684409,
            "class_probabilities": {
                "human": 0.9576304380595639,
                "ai": 0.04148363016684409,
                "mixed": 0.0008859317735921093
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9576304380595639,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.04148363016684409,
                    "human": 0.9576304380595639,
                    "mixed": 0.0008859317735921093
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "- Strengths:\na) The paper presents a Bayesian learning approach for recurrent neural network\nlanguage model. The method outperforms standard SGD with dropout on three\ntasks. \nb) The idea of using Bayesian learning with RNNs appears to be novel. \nc) The computationally efficient Bayesian algorithm for RNN would be of\ninterest to the NLP community for various applications.\n- Weaknesses:\nPrimary concern is about evaluation:\nSec 5.1: The paper reports the performance of difference types of architectures\n(LSTM/GRU/vanilla RNN) on character LM task while comparing the learning\nalgorithms on the Penn Treebank task. Furthermore, RMSprop and pSGLD are\ncompared for the character LM while SGD +/- dropout is compared with SGLD +/-\ndropout on word language model task. This is inconsistent! I would suggest\nreporting both these dimensions (i.e. architectures and the exact same learning\nalgorithms) on both character and word LM tasks. It would be useful to know if\nthe results from the proposed Bayesian learning approaches are portable across\nboth these tasks and data sets.\nL529: The paper states that 'the performance gain mainly comes from adding\ngradient noise and model averaging'. This statement is not justified\nempirically. To arrive at this conclusion, an A/B experiment with/without\nadding gradient noise and/or model averaging needs to be done. \nL724: Gal's dropout is run on the sentence classification task but not on\nlanguage model/captions task. Since Gal's dropout is not specific to sentence\nclassification, I would suggest reporting the performance of this method on\nall three tasks. This would allow the readers to fully assess the utility of\nthe proposed algorithms relative to all existing dropout approaches.\nL544: Is there any sort order for the samples? (\\theta1, ..., \\thetaK)? e.g.\nare samples with higher posterior probabilities likely to be at higher indices?\nWhy not report the result of randomly selecting K out of S samples, as an\nadditional alternative?\nRegular RNN LMs are known to be expensive to train and evaluate. It would be\nvery useful to compare the training/evaluation times for the proposed Bayesian\nlearning algorithms with SGD+ dropout. That would allow the readers to\ntrade-off improvements versus increase in training/run times.\nClarifications:\nL346: What does \\theta_s refer to? Is this a MAP estimate of parameters based\non only the sample s?\nL453-454: Clarify what \\theta means in the context of dropout/dropconnect. \nTypos:\nL211: output\nL738: RMSProp"
        }
    ]
}