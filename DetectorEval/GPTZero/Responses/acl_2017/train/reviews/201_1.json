{
    "version": "2025-01-09-base",
    "scanId": "31e59a1f-3fd0-4d5a-b404-5005b684a33f",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0022046451922506094,
                    "sentence": "- Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004141409881412983,
                    "sentence": "This paper presents a 2 x 2 x 3 x 10 array of accuracy results based on",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0022020023316144943,
                    "sentence": "systematically changing the parameters of embeddings models:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0028511646669358015,
                    "sentence": "(context type, position sensitive, embedding model, task), accuracy",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0023677130229771137,
                    "sentence": "- context type â^^ {Linear, Syntactic}",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002058492973446846,
                    "sentence": "- position sensitive â^^ {True, False}",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0034483373165130615,
                    "sentence": "- embedding model â^^ {Skip Gram, BOW, GLOVE}",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0031980155035853386,
                    "sentence": "- task â^^ {Word Similarity, Analogies, POS, NER, Chunking, 5 text classific.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001829996588639915,
                    "sentence": "tasks}",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0028396793641149998,
                    "sentence": "The aim of these experiments was to investigate the variation in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0026458590291440487,
                    "sentence": "performance as these parameters are changed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0027438735123723745,
                    "sentence": "The goal of the study itself",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002290792064741254,
                    "sentence": "is interesting for the ACL community and similar papers have appeared",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0022424201015383005,
                    "sentence": "before as workshop papers and have been well cited, such as Nayak et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003504264634102583,
                    "sentence": "'s",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0012173757422715425,
                    "sentence": "paper mentioned below.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0039561111479997635,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002823091112077236,
                    "sentence": "Since this paper essentially presents the effect of systematically changing the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0019925772212445736,
                    "sentence": "context types and position sensitivity, I will focus on the execution of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0014807020779699087,
                    "sentence": "investigation and the analysis of the results, which I am afraid is not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003064323216676712,
                    "sentence": "satisfactory.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0015629486879333854,
                    "sentence": "A) The lack of hyper-parameter tuning is worrisome.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001702699693851173,
                    "sentence": "E.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004335902631282806,
                    "sentence": "- 395 Unless otherwise notes, the number of word embedding dimension is set",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0033296553883701563,
                    "sentence": "to 500.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0048225317150354385,
                    "sentence": "- 232 It still enlarges the context vocabulary about 5 times in practice.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0037196693010628223,
                    "sentence": "- 385 Most hyper-parameters are the same as Levy et al' best configuration.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0022761665750294924,
                    "sentence": "This is worrisome because lack of hyperparameter tuning makes it difficult to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004130976274609566,
                    "sentence": "make statements like method A is better than method B. E.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00940681155771017,
                    "sentence": "bound methods may",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005727242678403854,
                    "sentence": "perform better with a lower dimensionality than unbound models, since their",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00673725875094533,
                    "sentence": "effective context vocabulary size is larger.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004923218861222267,
                    "sentence": "B) The paper sometimes presents strange explanations for its results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004076044075191021,
                    "sentence": "E.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004987439606338739,
                    "sentence": "- 115 \"Experimental results suggest that although it's hard to find any",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007092265412211418,
                    "sentence": "universal insight, the characteristics of different contexts on different",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0048451535403728485,
                    "sentence": "models are concluded according to specific tasks.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0027508088387548923,
                    "sentence": "What does this sentence even mean?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004425015300512314,
                    "sentence": "- 580 Sequence labeling tasks tend to classify words with the same syntax",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005539754405617714,
                    "sentence": "to the same category.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0029175300151109695,
                    "sentence": "The ignorance of syntax for word embeddings which are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0031451997347176075,
                    "sentence": "learned by bound representation becomes beneficial.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0037340079434216022,
                    "sentence": "These two sentences are contradictory, if a sequence labeling task",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002731987042352557,
                    "sentence": "classified words with \"same syntax\" to same category then syntx becomes",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004137034993618727,
                    "sentence": "a ver valuable feature.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0035582140553742647,
                    "sentence": "Bound representation's ignorance of syntax",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0031834582332521677,
                    "sentence": "should cause a drop in performance just like other tasks which does not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014406030997633934,
                    "sentence": "happen.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008364833891391754,
                    "sentence": "C) It is not enough to merely mention Lai et.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012895825318992138,
                    "sentence": "al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006756803952157497,
                    "sentence": "2016 who have also done a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012119060382246971,
                    "sentence": "systematic study of the word embeddings, and similarly the paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9922009706497192,
                    "sentence": "\"Evaluating Word Embeddings Using a Representative Suite of Practical",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9974550604820251,
                    "sentence": "Tasks\", Nayak, Angeli, Manning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9980729818344116,
                    "sentence": "appeared at the repeval workshop at",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9957387447357178,
                    "sentence": "ACL 2016. should have been cited.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9968075752258301,
                    "sentence": "I understand that the focus of Nayak",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9969263076782227,
                    "sentence": "et al's paper is not exactly the same as this paper, however they",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9973154664039612,
                    "sentence": "provide recommendations about hyperparameter tuning and experiment",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9861733317375183,
                    "sentence": "design and even provide a web interface for automatically running",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9923713207244873,
                    "sentence": "tagging experiments using neural networks instead of the \"simple linear",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9984329342842102,
                    "sentence": "classifiers\" used in the current paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9954298734664917,
                    "sentence": "D) The paper uses a neural BOW words classifier for the text classification",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9881972074508667,
                    "sentence": "tasks",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9945545792579651,
                    "sentence": "but a simple linear classifier for the sequence labeling tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.994207501411438,
                    "sentence": "What is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.997136652469635,
                    "sentence": "the justification for this choice of classifiers?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.997810423374176,
                    "sentence": "Why not use a simple",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9976375699043274,
                    "sentence": "neural classifier for the tagging tasks as well?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9958679676055908,
                    "sentence": "I raise this point,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9977062344551086,
                    "sentence": "since the tagging task seems to be the only task where bound",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9968059062957764,
                    "sentence": "representations are consistently beating the unbound representations,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9971125721931458,
                    "sentence": "which makes this task the odd one out.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9995467066764832,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9986558556556702,
                    "sentence": "Finally, I will make one speculative suggestion to the authors regarding",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.99881511926651,
                    "sentence": "the analysis of the data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9991296529769897,
                    "sentence": "As I said earlier, this paper's main contribution is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9995628595352173,
                    "sentence": "an",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9987655282020569,
                    "sentence": "analysis of the following table.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9989762902259827,
                    "sentence": "(context type, position sensitive, embedding model, task, accuracy)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9984065294265747,
                    "sentence": "So essentially there are 120 accuracy values that we want to explain in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9994128942489624,
                    "sentence": "terms of the aspects of the model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9992349743843079,
                    "sentence": "It may be beneficial to perform",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9994365572929382,
                    "sentence": "factor analysis or some other pattern mining technique on this 120 sample data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 59,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 63,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 64,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 66,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 68,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 70,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 71,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 72,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 73,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 74,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 75,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 77,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 78,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 79,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 80,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 81,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 83,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.39821528165086445,
            "class_probabilities": {
                "human": 0.6017847183491355,
                "ai": 0.39821528165086445,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.6017847183491355,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.39821528165086445,
                    "human": 0.6017847183491355,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "- Strengths:\nThis paper presents a 2 x 2 x 3 x 10 array of accuracy results based on\nsystematically changing the parameters of embeddings models:\n(context type, position sensitive, embedding model, task), accuracy\n- context type âˆˆ {Linear, Syntactic}\n- position sensitive âˆˆ {True, False}\n- embedding model âˆˆ {Skip Gram, BOW, GLOVE}\n- task âˆˆ {Word Similarity, Analogies, POS, NER, Chunking, 5 text classific.\ntasks}\nThe aim of these experiments was to investigate the variation in\nperformance as these parameters are changed. The goal of the study itself\nis interesting for the ACL community and similar papers have appeared\nbefore as workshop papers and have been well cited, such as Nayak et al.'s\npaper mentioned below.\n- Weaknesses:\nSince this paper essentially presents the effect of systematically changing the\ncontext types and position sensitivity, I will focus on the execution of the\ninvestigation and the analysis of the results, which I am afraid is not \nsatisfactory.\nA) The lack of hyper-parameter tuning is worrisome. E.g.\n - 395 Unless otherwise notes, the number of word embedding dimension is set\nto 500.\n - 232 It still enlarges the context vocabulary about 5 times in practice.\n - 385 Most hyper-parameters are the same as Levy et al' best configuration.\n This is worrisome because lack of hyperparameter tuning makes it difficult to\nmake statements like method A is better than method B. E.g. bound methods may\nperform better with a lower dimensionality than unbound models, since their\neffective context vocabulary size is larger.\nB) The paper sometimes presents strange explanations for its results. E.g.\n - 115 \"Experimental results suggest that although it's hard to find any \nuniversal insight, the characteristics of different contexts on different\nmodels are concluded according to specific tasks.\"\n What does this sentence even mean? \n - 580 Sequence labeling tasks tend to classify words with the same syntax \nto the same category. The ignorance of syntax for word embeddings which are\nlearned by bound representation becomes beneficial. \n These two sentences are contradictory, if a sequence labeling task\n classified words with \"same syntax\" to same category then syntx becomes\n a ver valuable feature. Bound representation's ignorance of syntax\n should cause a drop in performance just like other tasks which does not\n happen.\nC) It is not enough to merely mention Lai et. al. 2016 who have also done a\n systematic study of the word embeddings, and similarly the paper \n \"Evaluating Word Embeddings Using a Representative Suite of Practical\n Tasks\", Nayak, Angeli, Manning. appeared at the repeval workshop at \n ACL 2016. should have been cited. I understand that the focus of Nayak\n et al's paper is not exactly the same as this paper, however they\n provide recommendations about hyperparameter tuning and experiment\n design and even provide a web interface for automatically running\n tagging experiments using neural networks instead of the \"simple linear\n classifiers\" used in the current paper.\nD) The paper uses a neural BOW words classifier for the text classification\ntasks\n but a simple linear classifier for the sequence labeling tasks. What is\n the justification for this choice of classifiers? Why not use a simple\n neural classifier for the tagging tasks as well? I raise this point,\n since the tagging task seems to be the only task where bound\n representations are consistently beating the unbound representations,\n which makes this task the odd one out. \n- General Discussion:\nFinally, I will make one speculative suggestion to the authors regarding\nthe analysis of the data. As I said earlier, this paper's main contribution is\nan\nanalysis of the following table.\n(context type, position sensitive, embedding model, task, accuracy)\nSo essentially there are 120 accuracy values that we want to explain in\nterms of the aspects of the model. It may be beneficial to perform\nfactor analysis or some other pattern mining technique on this 120 sample data."
        }
    ]
}