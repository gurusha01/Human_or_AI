{
    "version": "2025-01-09-base",
    "scanId": "a1be4c18-e6bf-4625-b673-abc98718accb",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.004126275423914194,
                    "sentence": "Review: Multimodal Word Distributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003791507799178362,
                    "sentence": "- Strengths: Overall a very strong paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004000443033874035,
                    "sentence": "- Weaknesses: The comparison against similar approaches could be extended.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014150988310575485,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004452728200703859,
                    "sentence": "The main focus of this paper is the introduction of a new model for learning",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010134750045835972,
                    "sentence": "multimodal word distributions formed from Gaussian mixtures for multiple word",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007065818645060062,
                    "sentence": "meanings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007987266406416893,
                    "sentence": "i. e. representing a word by a set of many Gaussian distributions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007857452146708965,
                    "sentence": "The approach, extend the model introduced by Vilnis and McCallum (2014) which",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008881872519850731,
                    "sentence": "represented word as unimodal Gaussian distribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00820881687104702,
                    "sentence": "By using a multimodal, the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.015536230057477951,
                    "sentence": "current approach attain the problem of polysemy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01573931984603405,
                    "sentence": "Overall, a very strong paper, well structured and clear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005050972569733858,
                    "sentence": "The experimentation is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010159672237932682,
                    "sentence": "correct and the qualitative analysis made in table 1 shows results as expected",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010261999443173409,
                    "sentence": "from the approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008425484411418438,
                    "sentence": "There's not much that can be faulted and all my comments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008618190884590149,
                    "sentence": "below are meant to help the paper gain additional clarity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021006273105740547,
                    "sentence": "Some comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00404932489618659,
                    "sentence": "_ It may be interesting to include a brief explanation of the differences",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010032977908849716,
                    "sentence": "between the approach from Tian et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004894324578344822,
                    "sentence": "2014 and the current one.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01841861382126808,
                    "sentence": "Both split",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007252141833305359,
                    "sentence": "single word representation into multiple prototypes by using a mixture model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0066580697894096375,
                    "sentence": "_ There are some missing citations that could me mentioned in related work as:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006697759032249451,
                    "sentence": "Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00822308287024498,
                    "sentence": "Space Neelakantan, A., Shankar.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009156797081232071,
                    "sentence": "J. Passos, A., McCallum.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00556927639991045,
                    "sentence": "EMNLP 2014",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005203497130423784,
                    "sentence": "Do Multi-Sense Embeddings Improve Natural Language Understanding?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.020124539732933044,
                    "sentence": "Li and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011417261324822903,
                    "sentence": "Jurafsky, EMNLP 2015",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00662740133702755,
                    "sentence": "Topical Word Embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009609472937881947,
                    "sentence": "Liu Y., Liu Z., Chua T.,Sun M. AAAI 2015",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005260326433926821,
                    "sentence": "_ Also, the inclusion of the result from those approaches in tables 3 and 4",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005183156579732895,
                    "sentence": "could be interesting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006152046378701925,
                    "sentence": "_ A question to the authors: What do you attribute the loss of performance of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009639897383749485,
                    "sentence": "w2gm against w2g in the analysis of SWCS?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00608828803524375,
                    "sentence": "I have read the response.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.024462635563563526,
            "class_probabilities": {
                "human": 0.9755373644364365,
                "ai": 0.024462635563563526,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9755373644364365,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.024462635563563526,
                    "human": 0.9755373644364365,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Review: Multimodal Word Distributions\n- Strengths: Overall a very strong paper.\n- Weaknesses: The comparison against similar approaches could be extended.\n- General Discussion:\nThe main focus of this paper is the introduction of a new model for learning\nmultimodal word distributions formed from Gaussian mixtures for multiple word\nmeanings. i. e. representing a word by a set of many Gaussian distributions. \nThe approach, extend the model introduced by Vilnis and McCallum (2014) which\nrepresented word as unimodal Gaussian distribution. By using a multimodal, the\ncurrent approach attain the problem of polysemy.\nOverall, a very strong paper, well structured and clear. The experimentation is\ncorrect and the qualitative analysis made in table 1 shows results as expected\nfrom the approach. There's not much that can be faulted and all my comments\nbelow are meant to help the paper gain additional clarity. \nSome comments: \n_ It may be interesting to include a brief explanation of the differences\nbetween the approach from Tian et al. 2014 and the current one. Both split\nsingle word representation into multiple prototypes by using a mixture model. \n_ There are some missing citations that could me mentioned in related work as :\nEfficient Non-parametric Estimation of Multiple Embeddings per Word in Vector\nSpace Neelakantan, A., Shankar. J. Passos, A., McCallum. EMNLP 2014\nDo Multi-Sense Embeddings Improve Natural Language Understanding? Li and\nJurafsky, EMNLP 2015\nTopical Word Embeddings. Liu Y., Liu Z., Chua T.,Sun M. AAAI 2015\n_ Also, the inclusion of the result from those approaches in tables 3 and 4\ncould be interesting. \n_ A question to the authors: What do you attribute the loss of performance of\nw2gm against w2g in the analysis of SWCS?\nI have read the response."
        }
    ]
}