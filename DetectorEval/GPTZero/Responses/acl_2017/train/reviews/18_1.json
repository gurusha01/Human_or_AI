{
    "version": "2025-01-09-base",
    "scanId": "523b87ca-12af-4563-93c2-8297c1123b5a",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.5357249975204468,
                    "sentence": "- Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.45404887199401855,
                    "sentence": "-- A well-motivated approach, with a clear description and solid results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5159720778465271,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3388746678829193,
                    "sentence": "-- Nothing substantial other than the comments below.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6751662492752075,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6541102528572083,
                    "sentence": "The paper describes a new method called attention-over-attention for reading",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7492870092391968,
                    "sentence": "comprehension.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.550524115562439,
                    "sentence": "First layers of the network compute a vector for each query word",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6492490768432617,
                    "sentence": "and document word, resulting in a \"Q\"xK matrix for the query and a \"D\"xK for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6103068590164185,
                    "sentence": "the document.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5250982046127319,
                    "sentence": "Since the answer is a document word, an attention mechanism is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5611811280250549,
                    "sentence": "used for assigning weights to each word, depending on their interaction with",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8432190418243408,
                    "sentence": "query words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5221807956695557,
                    "sentence": "In this work, the authors deepen a traditional attention mechanism",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5290648937225342,
                    "sentence": "by computing a weight for each query word through a separate attention and then",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.602618932723999,
                    "sentence": "using that to weight the main attention over document words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4641435742378235,
                    "sentence": "Evaluation is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5975581407546997,
                    "sentence": "properly conducted on benchmark datasets, and various insights are presented",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.535064160823822,
                    "sentence": "through an analysis of the results as well as a comparison to prior work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3313175439834595,
                    "sentence": "I",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5270200967788696,
                    "sentence": "think this is a solid piece of work on an important problem, and the method is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6389155387878418,
                    "sentence": "well-motivated and clearly described, so that researchers can easily reproduce",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5522674322128296,
                    "sentence": "results and apply the same techniques to other similar tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7575539946556091,
                    "sentence": "- Other remarks:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6515903472900391,
                    "sentence": "-- p4, Equation 12: I am assuming i is iterating over training set and p(w) is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6006614565849304,
                    "sentence": "referring to P(w\"D,Q) in the previous equation?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4120984375476837,
                    "sentence": "Please clarify to avoid",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7892294526100159,
                    "sentence": "confusion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3545207977294922,
                    "sentence": "-- I am wondering whether you explored/discussed initializing word embeddings",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022163264453411102,
                    "sentence": "with existing vectors such as Google News or Glove?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03284961357712746,
                    "sentence": "Is there a reason to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01562757045030594,
                    "sentence": "believe the general-purpose word semantics would not be useful in this task?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.020182494074106216,
                    "sentence": "-- p6 L589-592: It is not clear what the authors are referring to when they say",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022800689563155174,
                    "sentence": "'letting the model explicitly learn weights between individual attentions'?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.043543603271245956,
                    "sentence": "Is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027000702917575836,
                    "sentence": "this referring to their own architecture, more specifically the GRU output",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.030912121757864952,
                    "sentence": "indirectly affecting how much attention will be applied to each query and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.044015657156705856,
                    "sentence": "document word?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03122800402343273,
                    "sentence": "Clarifying that would be useful.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00912999827414751,
                    "sentence": "Also, I think the improvement",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03147975355386734,
                    "sentence": "on validation is not 4.1, rather 4.0 (72.2-68.2).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011418238282203674,
                    "sentence": "-- p7 Table 5: why do you think the weight for local LM is relatively higher",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012279127724468708,
                    "sentence": "for the CN task while the benefit of adding it is less?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00873923022300005,
                    "sentence": "Since you included the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014177734032273293,
                    "sentence": "table, I think it'll be nice to provide some insights to the reader.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010493316687643528,
                    "sentence": "-- I would have liked to see the software released as part of this submission.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013937702402472496,
                    "sentence": "-- Typo p2 L162 right column: \"is not that effective than expected\" --> \"is not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019930100068449974,
                    "sentence": "as effective as expected\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00797380693256855,
                    "sentence": "-- Typo p7 L689 right column: \"appear much frequent\" --> \"appears more",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0157757755368948,
                    "sentence": "frequently\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00983649492263794,
                    "sentence": "-- Typo p8 L719-721 left column: \"the model is hard to\" --> \"it is hard for the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.016882695257663727,
                    "sentence": "model to\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012001391500234604,
                    "sentence": "& \"hard to made\" --> \"hard to make\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.3063829682933457
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                }
            ],
            "completely_generated_prob": 0.24245896627697372,
            "class_probabilities": {
                "human": 0.7570192175920558,
                "ai": 0.24245896627697372,
                "mixed": 0.0005218161309705781
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.7570192175920558,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.24245896627697372,
                    "human": 0.7570192175920558,
                    "mixed": 0.0005218161309705781
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "- Strengths:\n-- A well-motivated approach, with a clear description and solid results.\n- Weaknesses:\n-- Nothing substantial other than the comments below. \n- General Discussion:\nThe paper describes a new method called attention-over-attention for reading\ncomprehension. First layers of the network compute a vector for each query word\nand document word, resulting in a \"Q\"xK matrix for the query and a \"D\"xK for\nthe document. Since the answer is a document word, an attention mechanism is\nused for assigning weights to each word, depending on their interaction with\nquery words. In this work, the authors deepen a traditional attention mechanism\nby computing a weight for each query word through a separate attention and then\nusing that to weight the main attention over document words. Evaluation is\nproperly conducted on benchmark datasets, and various insights are presented\nthrough an analysis of the results as well as a comparison to prior work. I\nthink this is a solid piece of work on an important problem, and the method is\nwell-motivated and clearly described, so that researchers can easily reproduce\nresults and apply the same techniques to other similar tasks.\n- Other remarks:\n-- p4, Equation 12: I am assuming i is iterating over training set and p(w) is\nreferring to P(w\"D,Q) in the previous equation? Please clarify to avoid\nconfusion.\n-- I am wondering whether you explored/discussed initializing word embeddings\nwith existing vectors such as Google News or Glove? Is there a reason to\nbelieve the general-purpose word semantics would not be useful in this task?\n-- p6 L589-592: It is not clear what the authors are referring to when they say\n'letting the model explicitly learn weights between individual attentions'? Is\nthis referring to their own architecture, more specifically the GRU output\nindirectly affecting how much attention will be applied to each query and\ndocument word? Clarifying that would be useful. Also, I think the improvement\non validation is not 4.1, rather 4.0 (72.2-68.2).\n-- p7 Table 5: why do you think the weight for local LM is relatively higher\nfor the CN task while the benefit of adding it is less? Since you included the\ntable, I think it'll be nice to provide some insights to the reader.\n-- I would have liked to see the software released as part of this submission.\n-- Typo p2 L162 right column: \"is not that effective than expected\" --> \"is not\nas effective as expected\"?\n-- Typo p7 L689 right column: \"appear much frequent\" --> \"appears more\nfrequently\"?\n-- Typo p8 L719-721 left column: \"the model is hard to\" --> \"it is hard for the\nmodel to\"? & \"hard to made\" --> \"hard to make\"?"
        }
    ]
}