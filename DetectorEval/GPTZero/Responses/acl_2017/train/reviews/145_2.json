{
    "version": "2025-01-09-base",
    "scanId": "c5e5f418-7cb3-4f2b-8069-f99c3552e22e",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.4132733643054962,
                    "sentence": "This work uses Gaussian mixtures to represent words and demonstrates its",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.38151174783706665,
                    "sentence": "potential in capturing multiple word meanings for polysemy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.22435812652111053,
                    "sentence": "The training",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3029361963272095,
                    "sentence": "process is done based on a max-margin objective.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3384888768196106,
                    "sentence": "The expected likelihood kernel",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.39325109124183655,
                    "sentence": "is used as the similarity between two words' distributions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.25853970646858215,
                    "sentence": "Experiment results",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.36603155732154846,
                    "sentence": "on word similarity and entailment tasks show the effectiveness of the proposed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.22783422470092773,
                    "sentence": "work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16416668891906738,
                    "sentence": "- Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1151621863245964,
                    "sentence": "The problem is clearly motivated and defined.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10063359141349792,
                    "sentence": "Gaussian mixtures are much more",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13887441158294678,
                    "sentence": "expressive than deterministic vector representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06686652451753616,
                    "sentence": "It can potentially",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09457964450120926,
                    "sentence": "capture different word meanings by its modes, along with probability mass and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1503678858280182,
                    "sentence": "uncertainty around those modes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08487170189619064,
                    "sentence": "This work represents an important contribution",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17448288202285767,
                    "sentence": "to word embedding.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1290397047996521,
                    "sentence": "This work propose a max-margin learning objective with closed-form similarity",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10967598110437393,
                    "sentence": "measurement for efficient training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15901727974414825,
                    "sentence": "This paper is mostly well written.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.24126216769218445,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14020195603370667,
                    "sentence": "See below for some questions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.20626018941402435,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.100184366106987,
                    "sentence": "In the Gaussian mixture models, the number of gaussian components (k) is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12645938992500305,
                    "sentence": "usually an important parameter.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10811145603656769,
                    "sentence": "In the experiments of this paper, k is set to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06623125076293945,
                    "sentence": "2. What is your criteria to select k?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10043727606534958,
                    "sentence": "Does the increase of k hurt the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06356536597013474,
                    "sentence": "performance of this model?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12629638612270355,
                    "sentence": "What does the learned distribution look like for a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11024748533964157,
                    "sentence": "word that only has one popular meaning?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08476704359054565,
                    "sentence": "I notice that you use the spherical case in all the experiments (the covariance",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.24642615020275116,
                    "sentence": "matrix reduces to a single number).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1506851464509964,
                    "sentence": "Is this purely for computation efficiency?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.181148499250412,
                    "sentence": "I wonder what's the performance of using a general diagonal covariance matrix.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18717294931411743,
                    "sentence": "Since in this more general case, the gaussian mixture defines different degrees",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.175325408577919,
                    "sentence": "of uncertainty along different directions in the semantic space, which seems",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.20498120784759521,
                    "sentence": "more interesting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19578541815280914,
                    "sentence": "Minor comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18546998500823975,
                    "sentence": "Table 4 is not referred to in the text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3611249625682831,
                    "sentence": "In reference, Luong et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.26240652799606323,
                    "sentence": "lacks the publication year.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19330906867980957,
                    "sentence": "I have read the response.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.1811847138956969,
            "class_probabilities": {
                "human": 0.8163665537528971,
                "ai": 0.1811847138956969,
                "mixed": 0.00244873235140598
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.8163665537528971,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.1811847138956969,
                    "human": 0.8163665537528971,
                    "mixed": 0.00244873235140598
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This work uses Gaussian mixtures to represent words and demonstrates its\npotential in capturing multiple word meanings for polysemy. The training\nprocess is done based on a max-margin objective. The expected likelihood kernel\nis used as the similarity between two words' distributions. Experiment results\non word similarity and entailment tasks show the effectiveness of the proposed\nwork.\n- Strengths:\nThe problem is clearly motivated and defined. Gaussian mixtures are much more\nexpressive than deterministic vector representations. It can potentially\ncapture different word meanings by its modes, along with probability mass and\nuncertainty around those modes. This work represents an important contribution\nto word embedding. \nThis work propose a max-margin learning objective with closed-form similarity\nmeasurement for efficient training.\nThis paper is mostly well written. \n- Weaknesses:\nSee below for some questions. \n- General Discussion:\nIn the Gaussian mixture models, the number of gaussian components (k) is\nusually an important parameter. In the experiments of this paper, k is set to\n2. What is your criteria to select k? Does the increase of k hurt the\nperformance of this model? What does the learned distribution look like for a\nword that only has one popular meaning?\nI notice that you use the spherical case in all the experiments (the covariance\nmatrix reduces to a single number). Is this purely for computation efficiency?\nI wonder what's the performance of using a general diagonal covariance matrix.\nSince in this more general case, the gaussian mixture defines different degrees\nof uncertainty along different directions in the semantic space, which seems\nmore interesting.\nMinor comments:\nTable 4 is not referred to in the text.\nIn reference, Luong et al. lacks the publication year.\nI have read the response."
        }
    ]
}