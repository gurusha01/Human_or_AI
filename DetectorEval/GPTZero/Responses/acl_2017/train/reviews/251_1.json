{
    "version": "2025-01-09-base",
    "scanId": "73adb56a-7dda-4881-9e5b-f803977c0624",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.3706277906894684,
                    "sentence": "This paper delves into the mathematical properties of the skip-gram model,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1725044846534729,
                    "sentence": "explaining the reason for its success on the analogy task and for the general",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4422093331813812,
                    "sentence": "superiority of additive composition models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.31545352935791016,
                    "sentence": "It also establishes a link between",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5215867757797241,
                    "sentence": "skip-gram and Sufficient Dimensionality Reduction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.015167951583862305,
                    "sentence": "I liked the focus of this paper on explaining the properties of skip-gram, and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.016507606953382492,
                    "sentence": "generally found it inspiring to read.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019057031720876694,
                    "sentence": "I very much appreciate the effort to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006497908849269152,
                    "sentence": "understand the assumptions of the model, and the way it affects (or is affected",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005848318804055452,
                    "sentence": "by) the composition operations that it is used to perform.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004540569614619017,
                    "sentence": "In that respect, I",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011091737076640129,
                    "sentence": "think it is a very worthwhile read for the community.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004148166161030531,
                    "sentence": "My main criticism is however that the paper is linguistically rather naive.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002895072801038623,
                    "sentence": "The",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0021944772452116013,
                    "sentence": "authors' use of 'compositionality' (as an operation that takes a set of words",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005789920687675476,
                    "sentence": "and returns another with the same meaning) is extremely strange.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0030491501092910767,
                    "sentence": "Two words can",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004561098758131266,
                    "sentence": "of course be composed and produce a vector that is a) far away from both; b)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004699703771620989,
                    "sentence": "does not correspond to any other concept in the space; c) still has meaning",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004970954731106758,
                    "sentence": "(productivity wouldn't exist otherwise!)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0068497261963784695,
                    "sentence": "Compositionality in linguistic terms",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009219554252922535,
                    "sentence": "simply refers to the process of combining linguistic constituents to produce",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011092807166278362,
                    "sentence": "higher-level constructs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003614430781453848,
                    "sentence": "It does not assume any further constraint, apart from",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0036618246231228113,
                    "sentence": "some vague (and debatable) notion of semantic transparency.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0044924854300916195,
                    "sentence": "The paper's",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002065167995169759,
                    "sentence": "implication (l254) that composition takes place over sets is also wrong:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0014407791895791888,
                    "sentence": "ordering matters hugely (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004070649389177561,
                    "sentence": "'sugar cane' is not 'cane sugar').",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0015458131674677134,
                    "sentence": "This is a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0036150615196675062,
                    "sentence": "well-known shortcoming of additive composition.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001446293550543487,
                    "sentence": "Another important aspect is that there are pragmatic factors that make humans",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0031983950175344944,
                    "sentence": "prefer certain phrases to single words in particular contexts (and the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004185879603028297,
                    "sentence": "opposite), naturally changing the underlying distribution of words in a large",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006004483439028263,
                    "sentence": "corpus.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003958079032599926,
                    "sentence": "For instance, talking of a 'male royalty' rather than a 'king' or",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005630311090499163,
                    "sentence": "'prince' usually has implications with regard to the intent of the speaker",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008338610641658306,
                    "sentence": "(here, perhaps highlighting a gender difference).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0042293802835047245,
                    "sentence": "This means that the equation",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9955667853355408,
                    "sentence": "in l258 (or for that matter the KL-divergence modification) does not hold, not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9961106181144714,
                    "sentence": "because of noise in the data, but because of fundamental linguistic processes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9973839521408081,
                    "sentence": "This point may be addressed by the section on SDR, but I am not completely sure",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9977572560310364,
                    "sentence": "(see my comments below).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9953811764717102,
                    "sentence": "In a nutshell, I think the way that the authors present composition is flawed,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9955080151557922,
                    "sentence": "but the paper convinces me that this is indeed what happens in skip-gram, and I",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9943557977676392,
                    "sentence": "think this is an interesting contribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9964194893836975,
                    "sentence": "The part about Sufficient Dimensionality Reduction seems a little disconnected",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9977238178253174,
                    "sentence": "from the previous argument as it stands.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.994957447052002,
                    "sentence": "I'm afraid I wasn't able to fully",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9913418292999268,
                    "sentence": "follow the argument, and I would be grateful for some clarification in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9949197769165039,
                    "sentence": "authors' response.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9900727272033691,
                    "sentence": "If I understand it well, the argument is that skip-gram",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9925051927566528,
                    "sentence": "produces a model where a word's neighbours follow some exponential",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9940952062606812,
                    "sentence": "parametrisation of a categorical distribution, but it is unclear whether this",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9947823882102966,
                    "sentence": "actually reflects the distribution of the corpus (as opposed to what happens",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.994249701499939,
                    "sentence": "in, say, a pure count-based model).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9959415197372437,
                    "sentence": "The fact that skip-gram performs well",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9974363446235657,
                    "sentence": "despite not reflecting the data is that it implements some form of SDR, which",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9981587529182434,
                    "sentence": "does not need to make any assumption about the underlying form of the data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9664703011512756,
                    "sentence": "But",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.997730016708374,
                    "sentence": "then, is it fair to say that the resulting representations are optimised for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9981598854064941,
                    "sentence": "tasks where geometrical regularities are important, regardless of the actual",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9989640116691589,
                    "sentence": "pattern of the data?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9984893202781677,
                    "sentence": "I.e.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9988502264022827,
                    "sentence": "there some kind of denoising going on?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9978176355361938,
                    "sentence": "Minor comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9957205653190613,
                    "sentence": "- The abstract is unusually long and could, I think, be shortened.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9973567128181458,
                    "sentence": "- para starting l71: I think it would be misconstrued to see circularity here.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.998183012008667,
                    "sentence": "Firth observed that co-occurrence effects were correlated with similarity",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9953804016113281,
                    "sentence": "judgements, but those judgements are the very cognitive processes that we are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9980596303939819,
                    "sentence": "trying to model with statistical methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9984112977981567,
                    "sentence": "Co-occurrence effects and vector",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9967314600944519,
                    "sentence": "space word representations are in some sense 'the same thing', modelling an",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03750315681099892,
                    "sentence": "underlying linguistic process we do not have direct observations for.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019544027745723724,
                    "sentence": "So",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02901209518313408,
                    "sentence": "pair-wise similarity is not there to break any circularity, it is there because",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021131712943315506,
                    "sentence": "it better models the kind of judgements humans known to make.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0159503985196352,
                    "sentence": "- l296: I think 'paraphrase' would be a better word than 'synonym' here, given",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025612005963921547,
                    "sentence": "that we are comparing a set of words with a unique lexical item.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.024099111557006836,
                    "sentence": "- para starting l322: this is interesting, and actually, a lot of the zipfian",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.029840268194675446,
                    "sentence": "distribution (the long tail) is fairly uniform.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.015611553564667702,
                    "sentence": "- l336: it is probably worth pointing out that the analogy relation does not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022682562470436096,
                    "sentence": "hold so well in practice and requires to 'ignore' the first returned neighbour",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022822212427854538,
                    "sentence": "of the analogy computation (which is usually one of the observed terms).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.015935199335217476,
                    "sentence": "- para starting l343: I don't find it so intuitive to say that 'man' would be a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019717184826731682,
                    "sentence": "synonym/paraphrase of anything involving 'woman'.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02664441429078579,
                    "sentence": "The subtraction involved in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023561134934425354,
                    "sentence": "the analogy computation is precisely not a straightforward composition",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018962029367685318,
                    "sentence": "operation, as it involves an implicit negation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01909574121236801,
                    "sentence": "- A last, tiny general comment.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02016407437622547,
                    "sentence": "It is usual to write p(w\"c) to mean the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02118060365319252,
                    "sentence": "probability of a word given a context, but in the paper 'w' is actually the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.029144836589694023,
                    "sentence": "context and 'c' the target word.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03471308574080467,
                    "sentence": "It makes reading a little bit harder...",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027915004640817642,
                    "sentence": "Perhaps change the notation?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.052303798496723175,
                    "sentence": "Literature:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03902357071638107,
                    "sentence": "The claim that Arora (2016) is the only work to try and understand vector",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08069489151239395,
                    "sentence": "composition is a bit strong.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.046529002487659454,
                    "sentence": "For instance, see the work by Paperno & Baroni on",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04858563840389252,
                    "sentence": "explaining the success of addition as a composition method over PMI-weighted",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0707051157951355,
                    "sentence": "vectors:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05021543800830841,
                    "sentence": "D. Paperno and M. Baroni.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03988472372293472,
                    "sentence": "2016. When the whole is less than the sum of its",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05397195369005203,
                    "sentence": "parts: How composition affects PMI values in distributional semantic vectors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09111063182353973,
                    "sentence": "Computational Linguistics 42(2): 345-350.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026258181780576706,
                    "sentence": "*",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09269754588603973,
                    "sentence": "I thank the authors for their response and hope to see this paper accepted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 65,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 66,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 67,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 68,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 69,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 70,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 72,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 73,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 75,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 76,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 77,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 78,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 79,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 80,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 81,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 82,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 83,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 84,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 85,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 87,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 88,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 89,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 91,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 92,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 94,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 95,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 96,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 97,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 99,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 100,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 101,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 103,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 104,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 105,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 106,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.22778574767484971,
            "class_probabilities": {
                "human": 0.7716823288576541,
                "ai": 0.22778574767484971,
                "mixed": 0.0005319234674962524
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.7716823288576541,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.22778574767484971,
                    "human": 0.7716823288576541,
                    "mixed": 0.0005319234674962524
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper delves into the mathematical properties of the skip-gram model,\nexplaining the reason for its success on the analogy task and for the general\nsuperiority of additive composition models. It also establishes a link between\nskip-gram and Sufficient Dimensionality Reduction.\nI liked the focus of this paper on explaining the properties of skip-gram, and\ngenerally found it inspiring to read. I very much appreciate the effort to\nunderstand the assumptions of the model, and the way it affects (or is affected\nby) the composition operations that it is used to perform. In that respect, I\nthink it is a very worthwhile read for the community.\nMy main criticism is however that the paper is linguistically rather naive. The\nauthors' use of 'compositionality' (as an operation that takes a set of words\nand returns another with the same meaning) is extremely strange. Two words can\nof course be composed and produce a vector that is a) far away from both; b)\ndoes not correspond to any other concept in the space; c) still has meaning\n(productivity wouldn't exist otherwise!) Compositionality in linguistic terms\nsimply refers to the process of combining linguistic constituents to produce\nhigher-level constructs. It does not assume any further constraint, apart from\nsome vague (and debatable) notion of semantic transparency. The paper's\nimplication (l254) that composition takes place over sets is also wrong:\nordering matters hugely (e.g. 'sugar cane' is not 'cane sugar'). This is a\nwell-known shortcoming of additive composition. \nAnother important aspect is that there are pragmatic factors that make humans\nprefer certain phrases to single words in particular contexts (and the\nopposite), naturally changing the underlying distribution of words in a large\ncorpus. For instance, talking of a 'male royalty' rather than a 'king' or\n'prince' usually has implications with regard to the intent of the speaker\n(here, perhaps highlighting a gender difference). This means that the equation\nin l258 (or for that matter the KL-divergence modification) does not hold, not\nbecause of noise in the data, but because of fundamental linguistic processes.\nThis point may be addressed by the section on SDR, but I am not completely sure\n(see my comments below).\nIn a nutshell, I think the way that the authors present composition is flawed,\nbut the paper convinces me that this is indeed what happens in skip-gram, and I\nthink this is an interesting contribution. \nThe part about Sufficient Dimensionality Reduction seems a little disconnected\nfrom the previous argument as it stands. I'm afraid I wasn't able to fully\nfollow the argument, and I would be grateful for some clarification in the\nauthors' response. If I understand it well, the argument is that skip-gram\nproduces a model where a word's neighbours follow some exponential\nparametrisation of a categorical distribution, but it is unclear whether this\nactually reflects the distribution of the corpus (as opposed to what happens\nin, say, a pure count-based model). The fact that skip-gram performs well\ndespite not reflecting the data is that it implements some form of SDR, which\ndoes not need to make any assumption about the underlying form of the data. But\nthen, is it fair to say that the resulting representations are optimised for\ntasks where geometrical regularities are important, regardless of the actual\npattern of the data? I.e. there some kind of denoising going on?\nMinor comments:\n- The abstract is unusually long and could, I think, be shortened.\n- para starting l71: I think it would be misconstrued to see circularity here.\nFirth observed that co-occurrence effects were correlated with similarity\njudgements, but those judgements are the very cognitive processes that we are\ntrying to model with statistical methods. Co-occurrence effects and vector\nspace word representations are in some sense 'the same thing', modelling an\nunderlying linguistic process we do not have direct observations for. So\npair-wise similarity is not there to break any circularity, it is there because\nit better models the kind of judgements humans known to make.\n- l296: I think 'paraphrase' would be a better word than 'synonym' here, given\nthat we are comparing a set of words with a unique lexical item.\n- para starting l322: this is interesting, and actually, a lot of the zipfian\ndistribution (the long tail) is fairly uniform.\n- l336: it is probably worth pointing out that the analogy relation does not\nhold so well in practice and requires to 'ignore' the first returned neighbour\nof the analogy computation (which is usually one of the observed terms).\n- para starting l343: I don't find it so intuitive to say that 'man' would be a\nsynonym/paraphrase of anything involving 'woman'. The subtraction involved in\nthe analogy computation is precisely not a straightforward composition\noperation, as it involves an implicit negation. \n- A last, tiny general comment. It is usual to write p(w\"c) to mean the\nprobability of a word given a context, but in the paper 'w' is actually the\ncontext and 'c' the target word. It makes reading a little bit harder...\nPerhaps change the notation?\nLiterature:\nThe claim that Arora (2016) is the only work to try and understand vector\ncomposition is a bit strong. For instance, see the work by Paperno & Baroni on\nexplaining the success of addition as a composition method over PMI-weighted\nvectors:\nD. Paperno and M. Baroni. 2016. When the whole is less than the sum of its\nparts: How composition affects PMI values in distributional semantic vectors.\nComputational Linguistics 42(2): 345-350.\n*\nI thank the authors for their response and hope to see this paper accepted."
        }
    ]
}