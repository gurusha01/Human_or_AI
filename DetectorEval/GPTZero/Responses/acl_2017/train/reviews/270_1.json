{
    "version": "2025-01-09-base",
    "scanId": "3dda0e31-ef64-4fbd-9bd7-08ce4a3779ce",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.08628469705581665,
                    "sentence": "This paper presents a purpose-built neural network architecture for textual",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11085528880357742,
                    "sentence": "entailment/NLI based on a three step process of encoding, attention-based",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1407550722360611,
                    "sentence": "matching, and aggregation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08747577667236328,
                    "sentence": "The model has two variants, one based on TreeRNNs",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10888641327619553,
                    "sentence": "and the other based on sequential BiLSTMs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1380845457315445,
                    "sentence": "The sequential model outperforms all",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11611467599868774,
                    "sentence": "published results, and an ensemble with the tree model does better still.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1550135314464569,
                    "sentence": "The paper is clear, the model is well motivated, and the results are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3694927394390106,
                    "sentence": "impressive.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21147453784942627,
                    "sentence": "Everything in the paper is solidly incremental, but I nonetheless",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17731231451034546,
                    "sentence": "recommend acceptance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21054401993751526,
                    "sentence": "Major issues that I'd like discussed in the response:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10971039533615112,
                    "sentence": "- You suggest several times that your system can serve as a new baseline for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2252262532711029,
                    "sentence": "future work on NLI.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05523514747619629,
                    "sentence": "This isn't an especially helpful or meaningful claimᅳit",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17355984449386597,
                    "sentence": "could be said of just about any model for any task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19076520204544067,
                    "sentence": "You could argue that your",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1390385925769806,
                    "sentence": "model is unusually simple or elegant, but I don't think that's really a major",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.32573723793029785,
                    "sentence": "selling point of the model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.131390780210495,
                    "sentence": "- Your model architecture is symmetric in some ways that seem like",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09642899036407471,
                    "sentence": "overkillᅳyou compute attention across sentences in both directions, and run a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09318247437477112,
                    "sentence": "separate inference composition (aggregation) network for each direction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09195765107870102,
                    "sentence": "This",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11456519365310669,
                    "sentence": "presumably nearly doubles the run time of your model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09299643337726593,
                    "sentence": "Is this really necessary",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11568598449230194,
                    "sentence": "for the very asymmetric task of NLI?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11296795308589935,
                    "sentence": "Have you done ablation studies on this?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21607932448387146,
                    "sentence": "- You present results for the full sequential model (ESIM) and the ensemble",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19445182383060455,
                    "sentence": "of that model and the tree-based model (HIM).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001597217284142971,
                    "sentence": "Why don't you present results for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0018647308461368084,
                    "sentence": "the tree-based model on its own?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001692666788585484,
                    "sentence": "Minor issues:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002022991655394435,
                    "sentence": "- I don't think the Barker and Jacobson quote means quite what you want it to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0024680616334080696,
                    "sentence": "mean.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00201405119150877,
                    "sentence": "In context, it's making a specific and not-settled point about direct",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0037195743061602116,
                    "sentence": "compositionality in formal grammar.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002299280371516943,
                    "sentence": "You'd probably be better off with a more",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0030837764497846365,
                    "sentence": "general claim about the widely accepted principle of compositionality.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002109551802277565,
                    "sentence": "- The vector difference feature that you use (which has also appeared in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001474604126997292,
                    "sentence": "prior work) is a bit odd, since it gives the model redundant parameters.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002772881183773279,
                    "sentence": "Any",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0019107593689113855,
                    "sentence": "model that takes vectors a, b, and (a - b) as input to some matrix",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0019515996100381017,
                    "sentence": "multiplication is exactly equivalent to some other model that takes in just a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002393275499343872,
                    "sentence": "and b and has a different matrix parameter.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0017943044658750296,
                    "sentence": "There may be learning-related",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0015016463585197926,
                    "sentence": "reasons why using this feature still makes sense, but it's worth commenting on.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0028707715682685375,
                    "sentence": "- How do you implement the tree-structured components of your model?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0012305108830332756,
                    "sentence": "Are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0021277382038533688,
                    "sentence": "there major issues with speed or scalability there?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0026543852873146534,
                    "sentence": "- Typo: (Klein and D. Manning, 2003)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0022485163062810898,
                    "sentence": "- Figure 3: Standard tree-drawing packages like (tikz-)qtree produce much",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0035812132991850376,
                    "sentence": "more readable parse trees without crossing lines.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002589175943285227,
                    "sentence": "I'd suggest using them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004688612651079893,
                    "sentence": "---",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0029691196978092194,
                    "sentence": "Thanks for the response!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002627986017614603,
                    "sentence": "I still solidly support publication.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002681524958461523,
                    "sentence": "This work is not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0032363131176680326,
                    "sentence": "groundbreaking, but it's novel in places, and the results are surprising enough",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0029802401550114155,
                    "sentence": "to bring some value to the conference.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.039839419682113825,
            "class_probabilities": {
                "human": 0.9601605803178862,
                "ai": 0.039839419682113825,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9601605803178862,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.039839419682113825,
                    "human": 0.9601605803178862,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a purpose-built neural network architecture for textual\nentailment/NLI based on a three step process of encoding, attention-based\nmatching, and aggregation. The model has two variants, one based on TreeRNNs\nand the other based on sequential BiLSTMs. The sequential model outperforms all\npublished results, and an ensemble with the tree model does better still.\nThe paper is clear, the model is well motivated, and the results are\nimpressive. Everything in the paper is solidly incremental, but I nonetheless\nrecommend acceptance. \nMajor issues that I'd like discussed in the response:\n– You suggest several times that your system can serve as a new baseline for\nfuture work on NLI. This isn't an especially helpful or meaningful claim—it\ncould be said of just about any model for any task. You could argue that your\nmodel is unusually simple or elegant, but I don't think that's really a major\nselling point of the model.\n– Your model architecture is symmetric in some ways that seem like\noverkill—you compute attention across sentences in both directions, and run a\nseparate inference composition (aggregation) network for each direction. This\npresumably nearly doubles the run time of your model. Is this really necessary\nfor the very asymmetric task of NLI? Have you done ablation studies on this?\n– You present results for the full sequential model (ESIM) and the ensemble\nof that model and the tree-based model (HIM). Why don't you present results for\nthe tree-based model on its own?\nMinor issues:\n– I don't think the Barker and Jacobson quote means quite what you want it to\nmean. In context, it's making a specific and not-settled point about direct\ncompositionality in formal grammar. You'd probably be better off with a more\ngeneral claim about the widely accepted principle of compositionality.\n– The vector difference feature that you use (which has also appeared in\nprior work) is a bit odd, since it gives the model redundant parameters. Any\nmodel that takes vectors a, b, and (a - b) as input to some matrix\nmultiplication is exactly equivalent to some other model that takes in just a\nand b and has a different matrix parameter. There may be learning-related\nreasons why using this feature still makes sense, but it's worth commenting on.\n– How do you implement the tree-structured components of your model? Are\nthere major issues with speed or scalability there?\n– Typo: (Klein and D. Manning, 2003) \n– Figure 3: Standard tree-drawing packages like (tikz-)qtree produce much\nmore readable parse trees without crossing lines. I'd suggest using them.\n---\nThanks for the response! I still solidly support publication. This work is not\ngroundbreaking, but it's novel in places, and the results are surprising enough\nto bring some value to the conference."
        }
    ]
}