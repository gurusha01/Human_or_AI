{
    "version": "2025-01-09-base",
    "scanId": "c4a81827-4a38-4bbb-9ecd-68ec7e6d66b5",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.2828258275985718,
                    "sentence": "This paper proposes a novel strategy for zero-resource translation where",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.22304029762744904,
                    "sentence": "(source, pivot) and (pivot, target) parallel corpora are available.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23990599811077118,
                    "sentence": "A teacher",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.24716785550117493,
                    "sentence": "model for p(target\"pivot) is first trained on the (pivot, target) corpus, then",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.33117642998695374,
                    "sentence": "a student model for p(target\"source) is trained to minimize relative entropy",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.22507113218307495,
                    "sentence": "with respect to the teacher on the (source, pivot) corpus.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5017913579940796,
                    "sentence": "When using",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3528403341770172,
                    "sentence": "word-level relative entropy over samples from the teacher, this approach is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5982041358947754,
                    "sentence": "shown to outperform previous variants on standard pivoting, as well as other",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.34405481815338135,
                    "sentence": "zero-resource strategies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21256811916828156,
                    "sentence": "This is a good contribution: a novel idea, clearly explained, and with",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2094767540693283,
                    "sentence": "convincing empirical support.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2881178855895996,
                    "sentence": "Unlike some previous work, it makes fairly",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.36530545353889465,
                    "sentence": "minimal assumptions about the nature of the NMT systems involved, and hence",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3459402918815613,
                    "sentence": "should be widely applicable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13682255148887634,
                    "sentence": "I have only a few suggestions for further experiments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05993153899908066,
                    "sentence": "First, it would be",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12138272821903229,
                    "sentence": "interesting to see how robust this approach is to more dissimilar source and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2018798440694809,
                    "sentence": "pivot languages, where intuitively the true p(target\"source) and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07048828899860382,
                    "sentence": "p(target\"pivot) will be further apart.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.25247809290885925,
                    "sentence": "Second, given the success of introducing",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2743045389652252,
                    "sentence": "word-based diversity, it was surprising not to see a sentence n-best or",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17293748259544373,
                    "sentence": "sentence-sampling experiment.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1400897055864334,
                    "sentence": "This would be more costly, but not much more so",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.24459658563137054,
                    "sentence": "since you're already doing beam search with the teacher.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06900128722190857,
                    "sentence": "Finally, related to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2161768525838852,
                    "sentence": "the previous, it might be interesting to explore transition from word-based",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14059129357337952,
                    "sentence": "diversity to sentence-based as the student converges and no longer needs the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05757814273238182,
                    "sentence": "signal from low-probability words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12476115673780441,
                    "sentence": "Some further comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11178795248270035,
                    "sentence": "line 241: Despite its simplicity -> Due to its simplicity",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1258365511894226,
                    "sentence": "277: target sentence y -> target word y",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09666555374860764,
                    "sentence": "442: I assume that K=1 and K=5 mean that you compare probabilities of the most",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09881523251533508,
                    "sentence": "probable and 5 most probable words in the current context.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12517300248146057,
                    "sentence": "If so, how is the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13041584193706512,
                    "sentence": "current context determined - greedily or with a beam?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10870933532714844,
                    "sentence": "Section 4.2.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15220585465431213,
                    "sentence": "The comparison with an essentially uniform distribution doesn't",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10738842189311981,
                    "sentence": "seem very informative here: it would be extremely surprising if p(y\"z) were not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11375103145837784,
                    "sentence": "significantly closer to p(y\"x) than to uniform.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13289573788642883,
                    "sentence": "It would be more interesting to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11587017774581909,
                    "sentence": "know to what extent p(y\"z) still provides a useful signal as p(y\"x) gets",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09768610447645187,
                    "sentence": "better.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13164211809635162,
                    "sentence": "This would be easy to measure by comparing p(y\"z) to models for p(y\"x)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1643964797258377,
                    "sentence": "trained on different amounts of data or for different numbers of iterations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06985719501972198,
                    "sentence": "Another useful thing to explore in this section would be the effect of the mode",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11486601829528809,
                    "sentence": "approximation compared to n-best for sentence-level scores.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07805760949850082,
                    "sentence": "555: It's odd that word beam does worse than word greedy, since word beam",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08019425719976425,
                    "sentence": "should be closer to word sampling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.043019264936447144,
                    "sentence": "Do you have an explanation for this?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11761707067489624,
                    "sentence": "582: The claimed advantage of sent-beam here looks like it may just be noise,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12060001492500305,
                    "sentence": "given the high variance of these curves.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.07286165202115429,
            "class_probabilities": {
                "human": 0.9268225467824988,
                "ai": 0.07286165202115429,
                "mixed": 0.0003158011963468892
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9268225467824988,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.07286165202115429,
                    "human": 0.9268225467824988,
                    "mixed": 0.0003158011963468892
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes a novel strategy for zero-resource translation where\n(source, pivot) and (pivot, target) parallel corpora are available. A teacher\nmodel for p(target\"pivot) is first trained on the (pivot, target) corpus, then\na student model for p(target\"source) is trained to minimize relative entropy\nwith respect to the teacher on the (source, pivot) corpus. When using\nword-level relative entropy over samples from the teacher, this approach is\nshown to outperform previous variants on standard pivoting, as well as other\nzero-resource strategies.\nThis is a good contribution: a novel idea, clearly explained, and with\nconvincing empirical support. Unlike some previous work, it makes fairly\nminimal assumptions about the nature of the NMT systems involved, and hence\nshould be widely applicable.\nI have only a few suggestions for further experiments. First, it would be\ninteresting to see how robust this approach is to more dissimilar source and\npivot languages, where intuitively the true p(target\"source) and\np(target\"pivot) will be further apart. Second, given the success of introducing\nword-based diversity, it was surprising not to see a sentence n-best or\nsentence-sampling experiment. This would be more costly, but not much more so\nsince you're already doing beam search with the teacher. Finally, related to\nthe previous, it might be interesting to explore transition from word-based\ndiversity to sentence-based as the student converges and no longer needs the\nsignal from low-probability words.\nSome further comments:\nline 241: Despite its simplicity -> Due to its simplicity\n277: target sentence y -> target word y\n442: I assume that K=1 and K=5 mean that you compare probabilities of the most\nprobable and 5 most probable words in the current context. If so, how is the\ncurrent context determined - greedily or with a beam?\nSection 4.2. The comparison with an essentially uniform distribution doesn't\nseem very informative here: it would be extremely surprising if p(y\"z) were not\nsignificantly closer to p(y\"x) than to uniform. It would be more interesting to\nknow to what extent p(y\"z) still provides a useful signal as p(y\"x) gets\nbetter. This would be easy to measure by comparing p(y\"z) to models for p(y\"x)\ntrained on different amounts of data or for different numbers of iterations.\nAnother useful thing to explore in this section would be the effect of the mode\napproximation compared to n-best for sentence-level scores.\n555: It's odd that word beam does worse than word greedy, since word beam\nshould be closer to word sampling. Do you have an explanation for this?\n582: The claimed advantage of sent-beam here looks like it may just be noise,\ngiven the high variance of these curves."
        }
    ]
}