{
    "version": "2025-01-09-base",
    "scanId": "be2fca66-5faa-46fd-9e3c-ec824c68e03e",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0027175373397767544,
                    "sentence": "- Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007227557711303234,
                    "sentence": "The authors propose a selective encoding model as extension to the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0034435929264873266,
                    "sentence": "sequence-to-sequence framework for abstractive sentence summarization.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011153032071888447,
                    "sentence": "The",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005676195491105318,
                    "sentence": "paper is very well written and the methods are clearly described.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013237298466265202,
                    "sentence": "The proposed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005392586812376976,
                    "sentence": "methods are evaluated on standard benchmarks and comparison to other",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002572392811998725,
                    "sentence": "state-of-the-art tools are presented, including significance scores.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004195755813270807,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004390951711684465,
                    "sentence": "There are some few details on the implementation and on the systems to which",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004067499190568924,
                    "sentence": "the authors compared their work that need to be better explained.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0034126632381230593,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005173212382942438,
                    "sentence": "* Major review:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0021912490483373404,
                    "sentence": "- I wonder if the summaries obtained using the proposed methods are indeed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0018817826639860868,
                    "sentence": "abstractive.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0025364989414811134,
                    "sentence": "I understand that the target vocabulary is build out of the words",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0020880685187876225,
                    "sentence": "which appear in the summaries in the training data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0034876109566539526,
                    "sentence": "But given the example shown",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0035620841663330793,
                    "sentence": "in Figure 4, I have the impression that the summaries are rather extractive.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003389839781448245,
                    "sentence": "The authors should choose a better example for Figure 4 and give some",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003147735493257642,
                    "sentence": "statistics on the number of words in the output sentences which were not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004225770011544228,
                    "sentence": "present in the input sentences for all test sets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0029999660328030586,
                    "sentence": "- page 2, lines 266-272: I understand the mathematical difference between the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002733174478635192,
                    "sentence": "vector hi and s, but I still have the feeling that there is a great overlap",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0019496673485264182,
                    "sentence": "between them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001596000511199236,
                    "sentence": "Both \"represent the meaning\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0035951153840869665,
                    "sentence": "Are both indeed necessary?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0034268947783857584,
                    "sentence": "Did you",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003074380336329341,
                    "sentence": "trying using only one of them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001700682914815843,
                    "sentence": "- Which neural network library did the authors use for implementing the system?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003207579255104065,
                    "sentence": "There is no details on the implementation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002104806015267968,
                    "sentence": "- page 5, section 44: Which training data was used for each of the systems that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0027985626365989447,
                    "sentence": "the authors compare to?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0020071822218596935,
                    "sentence": "Diy you train any of them yourselves?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0015285415574908257,
                    "sentence": "* Minor review:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0016187827568501234,
                    "sentence": "- page 1, line 44: Although the difference between abstractive and extractive",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0017964295111596584,
                    "sentence": "summarization is described in section 2, this could be moved to the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0015918239951133728,
                    "sentence": "introduction section.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0036520652938634157,
                    "sentence": "At this point, some users might no be familiar with this",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0018819989636540413,
                    "sentence": "concept.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0018117085564881563,
                    "sentence": "- page 1, lines 93-96: please provide a reference for this passage: \"This",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0017268264200538397,
                    "sentence": "approach achieves huge success in tasks like neural machine translation, where",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002221488393843174,
                    "sentence": "alignment between all parts of the input and output are required.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0032087734434753656,
                    "sentence": "- page 2, section 1, last paragraph: The contribution of the work is clear but",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001848003827035427,
                    "sentence": "I think the authors should emphasize that such a selective encoding model has",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0031189434230327606,
                    "sentence": "never been proposed before (is this true?).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0033334202598780394,
                    "sentence": "Further, the related work section",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0024674558080732822,
                    "sentence": "should be moved to before the methods section.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0037021322641521692,
                    "sentence": "- Figure 1 vs. Table 1: the authors show two examples for abstractive",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0025095101445913315,
                    "sentence": "summarization but I think that just one of them is enough.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006581850815564394,
                    "sentence": "Further, one is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007180490531027317,
                    "sentence": "called a figure while the other a table.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10522959381341934,
                    "sentence": "- Section 3.2, lines 230-234 and 234-235: please provide references for the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09606102854013443,
                    "sentence": "following two passages: \"In the sequence-to-sequence machine translation (MT)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12320579588413239,
                    "sentence": "model, the encoder and decoder are responsible for encoding input sentence",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12507832050323486,
                    "sentence": "information and decoding the sentence representation to generate an output",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10378517955541611,
                    "sentence": "sentence\"; \"Some previous works apply this framework to summarization",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08120496571063995,
                    "sentence": "generation tasks.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.031598079949617386,
                    "sentence": "- Figure 2: What is \"MLP\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07017911225557327,
                    "sentence": "It seems not to be described in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.031671952456235886,
                    "sentence": "- page 3, lines 289-290: the sigmoid function and the element-wise",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.055625032633543015,
                    "sentence": "multiplication are not defined for the formulas in section 3.1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.058148596435785294,
                    "sentence": "- page 4, first column: many elements of the formulas are not defined: b",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03616824373602867,
                    "sentence": "(equation 11), W (equation 12, 15, 17) and U (equation 12, 15), V (equation",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012904209084808826,
                    "sentence": "15).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04236502945423126,
                    "sentence": "- page 4, line 326: the readout state rt is not depicted in Figure 2",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009567848406732082,
                    "sentence": "(workflow).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.030124884098768234,
                    "sentence": "- Table 2: what does \"(ref)\" mean?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07771692425012589,
                    "sentence": "- Section 4.3, model parameters and training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.043330784887075424,
                    "sentence": "Explain how you achieved the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04150025174021721,
                    "sentence": "values to the many parameters: word embedding size, GRU hidden states, alpha,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.031099362298846245,
                    "sentence": "beta 1 and 2, epsilon, beam size.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018523620441555977,
                    "sentence": "- Page 5, line 450: remove \"the\" word in this line?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.032708603888750076,
                    "sentence": "\"SGD as our optimizing",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023418640717864037,
                    "sentence": "algorithms\" instead of \"SGD as our the optimizing algorithms.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03121037781238556,
                    "sentence": "- Page 5, beam search: please include a reference for beam search.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05955026298761368,
                    "sentence": "- Figure 4: Is there a typo in the true sentence?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05460459366440773,
                    "sentence": "\"council of europe again",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0459575392305851,
                    "sentence": "slams french prison conditions\" (again or against?)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.036967191845178604,
                    "sentence": "- typo \"supper script\" -> \"superscript\" (4 times)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 63,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 64,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 65,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 66,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 67,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 68,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 70,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 71,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 72,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 74,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 75,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 76,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 78,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 79,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.05846869506377007,
            "class_probabilities": {
                "human": 0.9414903775918344,
                "ai": 0.05846869506377007,
                "mixed": 4.092734439546067e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9414903775918344,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.05846869506377007,
                    "human": 0.9414903775918344,
                    "mixed": 4.092734439546067e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "- Strengths:\nThe authors propose a selective encoding model as extension to the\nsequence-to-sequence framework for abstractive sentence summarization. The\npaper is very well written and the methods are clearly described. The proposed\nmethods are evaluated on standard benchmarks and comparison to other\nstate-of-the-art tools are presented, including significance scores. \n- Weaknesses:\nThere are some few details on the implementation and on the systems to which\nthe authors compared their work that need to be better explained. \n- General Discussion:\n* Major review:\n- I wonder if the summaries obtained using the proposed methods are indeed\nabstractive. I understand that the target vocabulary is build out of the words\nwhich appear in the summaries in the training data. But given the example shown\nin Figure 4, I have the impression that the summaries are rather extractive.\nThe authors should choose a better example for Figure 4 and give some\nstatistics on the number of words in the output sentences which were not\npresent in the input sentences for all test sets.\n- page 2, lines 266-272: I understand the mathematical difference between the\nvector hi and s, but I still have the feeling that there is a great overlap\nbetween them. Both \"represent the meaning\". Are both indeed necessary? Did you\ntrying using only one of them.\n- Which neural network library did the authors use for implementing the system?\nThere is no details on the implementation.\n- page 5, section 44: Which training data was used for each of the systems that\nthe authors compare to? Diy you train any of them yourselves?\n* Minor review:\n- page 1, line 44: Although the difference between abstractive and extractive\nsummarization is described in section 2, this could be moved to the\nintroduction section. At this point, some users might no be familiar with this\nconcept.\n- page 1, lines 93-96: please provide a reference for this passage: \"This\napproach achieves huge success in tasks like neural machine translation, where\nalignment between all parts of the input and output are required.\"\n- page 2, section 1, last paragraph: The contribution of the work is clear but\nI think the authors should emphasize that such a selective encoding model has\nnever been proposed before (is this true?). Further, the related work section\nshould be moved to before the methods section.\n- Figure 1 vs. Table 1: the authors show two examples for abstractive\nsummarization but I think that just one of them is enough. Further, one is\ncalled a figure while the other a table.\n- Section 3.2, lines 230-234 and 234-235: please provide references for the\nfollowing two passages: \"In the sequence-to-sequence machine translation (MT)\nmodel, the encoder and decoder are responsible for encoding input sentence\ninformation and decoding the sentence representation to generate an output\nsentence\"; \"Some previous works apply this framework to summarization\ngeneration tasks.\"\n- Figure 2: What is \"MLP\"? It seems not to be described in the paper.\n- page 3, lines 289-290: the sigmoid function and the element-wise\nmultiplication are not defined for the formulas in section 3.1.\n- page 4, first column: many elements of the formulas are not defined: b\n(equation 11), W (equation 12, 15, 17) and U (equation 12, 15), V (equation\n15).\n- page 4, line 326: the readout state rt is not depicted in Figure 2\n(workflow).\n- Table 2: what does \"(ref)\" mean?\n- Section 4.3, model parameters and training. Explain how you achieved the\nvalues to the many parameters: word embedding size, GRU hidden states, alpha,\nbeta 1 and 2, epsilon, beam size.\n- Page 5, line 450: remove \"the\" word in this line? \"SGD as our optimizing\nalgorithms\" instead of \"SGD as our the optimizing algorithms.\"\n- Page 5, beam search: please include a reference for beam search.\n- Figure 4: Is there a typo in the true sentence? \"council of europe again\nslams french prison conditions\" (again or against?)\n- typo \"supper script\" -> \"superscript\" (4 times)"
        }
    ]
}