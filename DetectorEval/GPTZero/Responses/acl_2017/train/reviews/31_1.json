{
    "version": "2025-01-09-base",
    "scanId": "2304d4c3-84b6-48db-b7fa-2a11957ceba5",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0003229629364795983,
                    "sentence": "Update after author response:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003034219262190163,
                    "sentence": "1. My major concern about the optimization of model's hyperparameter (which are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00023552338825538754,
                    "sentence": "numerous) has not been addressed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003226278640795499,
                    "sentence": "This is very important, considering that you",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00033574787084944546,
                    "sentence": "report results from folded cross-validation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003238312783651054,
                    "sentence": "2. The explanation that benefits of their method are experimentally confirmed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003577325842343271,
                    "sentence": "with 2% difference -- while evaluating via 5-fold CV on 200 examples -- is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0002120447752531618,
                    "sentence": "quite unconvincing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00019029520626645535,
                    "sentence": "========================================================================",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0002730677369982004,
                    "sentence": "Summary:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003533920389600098,
                    "sentence": "In this paper authors present a complex neural model for detecting factuality",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004719510325230658,
                    "sentence": "of event mentions in text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00031293524079956114,
                    "sentence": "The authors combine the following in their complex",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003695896011777222,
                    "sentence": "model: (1) a set of traditional classifiers for detecting",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008511284831911325,
                    "sentence": "event",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004638198879547417,
                    "sentence": "mentions,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00041754983249120414,
                    "sentence": "factuality sources, and source introducing predicates (SIPs), (2) A",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005714999279007316,
                    "sentence": "bidirectional attention-based LSTM model that learns latent representations for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.000417315517552197,
                    "sentence": "elements on different dependency paths used as input, (2) A CNN that uses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003903870820067823,
                    "sentence": "representations from the LSTM and performs two output predictions (one to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003172030847053975,
                    "sentence": "detect specific from underspecified cases and another to predict the actual",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0002542830479796976,
                    "sentence": "factuality class).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0002916254161391407,
                    "sentence": "From the methodological point of view, the authors are combining a reasonably",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003053409745916724,
                    "sentence": "familiar methods (att-BiLSTM and CNN) into a fairly complex model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00026612068177200854,
                    "sentence": "However,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0002377252239966765,
                    "sentence": "this model does not take raw text (sequence of word embeddings) as input, but",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00033405053545720875,
                    "sentence": "rather hand-crafted features (e.g., different dependency paths combining",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003909589722752571,
                    "sentence": "factuality concepts, e.g., sources, SIPs, and clues).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003130427794530988,
                    "sentence": "The usage of hand-crafted",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00034201229573227465,
                    "sentence": "features is somewhat surprising if coupled with complex deep model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006774935754947364,
                    "sentence": "The",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005079880938865244,
                    "sentence": "evaluation seems a bit tainted as the authors report the results from folded",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004890870186500251,
                    "sentence": "cross-validation but do not report how they optimized the hyperparameters of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.000566550123039633,
                    "sentence": "the model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00027507278718985617,
                    "sentence": "Finally, the results are not too convincing -- considering the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0003786421148106456,
                    "sentence": "complexity of the model and the amount of preprocessing required (extraction of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005358090274967253,
                    "sentence": "event mentions, SIPs, and clues), a 2% macro-average gain over the rule-based",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004112883470952511,
                    "sentence": "baseline and overall 44% performance seems modest, at best (looking at",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005029707681387663,
                    "sentence": "Micro-average, the proposed model doesn't outperform simple MaxEnt classifier).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00044134899508208036,
                    "sentence": "The paper is generally well-written and fairly easy to understand.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00035255905822850764,
                    "sentence": "Altogether,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004100367659702897,
                    "sentence": "I find this paper to be informative to an extent, but in it's current form not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005004603299312294,
                    "sentence": "a great read for a top-tier conference.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005062638083472848,
                    "sentence": "Remarks:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001019897754304111,
                    "sentence": "1. You keep mentioning that the LSTM and CNN in your model are combined",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007231078343465924,
                    "sentence": "\"properly\" -- what does that actually mean?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005758770275861025,
                    "sentence": "How does this \"properness\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006556574953719974,
                    "sentence": "manifest?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0020116919185966253,
                    "sentence": "What would be the improper way to combine the models?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01414552703499794,
                    "sentence": "2. I find the motivation/justification for the two output design rather weak:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.020892484113574028,
                    "sentence": "- the first argument that it allows for later addition of cues (i.e",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014722286723554134,
                    "sentence": "manually-designed features) kind of beats the \"learning representations\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021698342636227608,
                    "sentence": "advantage of using deep models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.015391924418509007,
                    "sentence": "- the second argument about this design tackling the imbalance in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011988402344286442,
                    "sentence": "training set is kind of hand-wavy as there is no experimental support for this",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.029421085491776466,
                    "sentence": "claim.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019975997507572174,
                    "sentence": "3. You first motivate the usage of your complex DL architecture with learning",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021173706278204918,
                    "sentence": "latent representations and avoiding manual design and feature computation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006876435596495867,
                    "sentence": "And",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01514030247926712,
                    "sentence": "then you define a set of manually designed features (several dependency paths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019400613382458687,
                    "sentence": "and lexical features) as input for the model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019343385472893715,
                    "sentence": "Do you notice the discrepancy?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026444274932146072,
                    "sentence": "4. The LSTMs (bidirectional, and also with attention) have by now already",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.055950384587049484,
                    "sentence": "become a standard model for various NLP tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022442275658249855,
                    "sentence": "Thus I find the detailed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.028677742928266525,
                    "sentence": "description of the attention-based bidirectional LSTM unnecessary.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0358794704079628,
                    "sentence": "5. What you present as a baseline in Section 3 is also part of your model (as",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03115551359951496,
                    "sentence": "it generates input to your model).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02918495610356331,
                    "sentence": "Thus, I think that calling it a baseline",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03218559920787811,
                    "sentence": "undermines the understandability of the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.050580158829689026,
                    "sentence": "6. The results reported originate from a 5-fold CV.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.029318612068891525,
                    "sentence": "However, the model contains",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03364948183298111,
                    "sentence": "numerous hyperparameters that need to be optimized (e.g., number of filters and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08340278267860413,
                    "sentence": "filter sizes for CNNs).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.050825849175453186,
                    "sentence": "How do you optimize these values?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03493240848183632,
                    "sentence": "Reporting results",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05051508545875549,
                    "sentence": "from a folded cross-validation doesn't allow for a fair optimization of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06942290812730789,
                    "sentence": "hypeparameters: either you're not optimizing the model's hyperparameters at",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06265261024236679,
                    "sentence": "all, or you're optimizing their values on the test set (which is unfair).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04577545076608658,
                    "sentence": "7. \"Notice that some values are non-application (NA) grammatically, e.g., PRu,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0658360943198204,
                    "sentence": "PSu, U+/-\" -- why is underspecification in ony one dimension (polarity or",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0728629007935524,
                    "sentence": "certainty) not an option?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09155658632516861,
                    "sentence": "I can easily think of a case where it is clear the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10109257698059082,
                    "sentence": "event is negative, but it is not specified whether the absence of an event is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09232918173074722,
                    "sentence": "certain, probable, or possible.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2992357015609741,
                    "sentence": "Language & style:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23017360270023346,
                    "sentence": "1. \"to a great degree\" -> \"great degree\" is an unusual construct, use either",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16622614860534668,
                    "sentence": "\"great extent\" or \"large degree\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23762695491313934,
                    "sentence": "2. \"events that can not\" -> \"cannot\" or \"do not\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.27530884742736816,
                    "sentence": "3. \"describes out networks...in details shown in Figure 3.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.20442765951156616,
                    "sentence": "-> \"...shown in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2964990735054016,
                    "sentence": "Figure 3 in details.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 59,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 63,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 65,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 66,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 67,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 69,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 70,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 72,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 73,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 76,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 77,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 78,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 79,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 80,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 81,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 83,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 84,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 85,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 86,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 87,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 88,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 89,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 91,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.028777713072366838,
            "class_probabilities": {
                "human": 0.9696407975999475,
                "ai": 0.028777713072366838,
                "mixed": 0.0015814893276857615
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9696407975999475,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.028777713072366838,
                    "human": 0.9696407975999475,
                    "mixed": 0.0015814893276857615
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Update after author response: \n1. My major concern about the optimization of model's hyperparameter (which are\nnumerous) has not been addressed. This is very important, considering that you\nreport results from folded cross-validation. \n2. The explanation that benefits of their method are experimentally confirmed\nwith 2% difference -- while evaluating via 5-fold CV on 200 examples -- is\nquite unconvincing.\n========================================================================\nSummary:\nIn this paper authors present a complex neural model for detecting factuality\nof event mentions in text. The authors combine the following in their complex\nmodel: (1) a set of traditional classifiers for detecting\nevent\nmentions,\nfactuality sources, and source introducing predicates (SIPs), (2) A\nbidirectional attention-based LSTM model that learns latent representations for\nelements on different dependency paths used as input, (2) A CNN that uses\nrepresentations from the LSTM and performs two output predictions (one to\ndetect specific from underspecified cases and another to predict the actual\nfactuality class). \nFrom the methodological point of view, the authors are combining a reasonably\nfamiliar methods (att-BiLSTM and CNN) into a fairly complex model. However,\nthis model does not take raw text (sequence of word embeddings) as input, but\nrather hand-crafted features (e.g., different dependency paths combining\nfactuality concepts, e.g., sources, SIPs, and clues). The usage of hand-crafted\nfeatures is somewhat surprising if coupled with complex deep model. The\nevaluation seems a bit tainted as the authors report the results from folded\ncross-validation but do not report how they optimized the hyperparameters of\nthe model. Finally, the results are not too convincing -- considering the\ncomplexity of the model and the amount of preprocessing required (extraction of\nevent mentions, SIPs, and clues), a 2% macro-average gain over the rule-based\nbaseline and overall 44% performance seems modest, at best (looking at\nMicro-average, the proposed model doesn't outperform simple MaxEnt classifier).\nThe paper is generally well-written and fairly easy to understand. Altogether,\nI find this paper to be informative to an extent, but in it's current form not\na great read for a top-tier conference. \nRemarks:\n1. You keep mentioning that the LSTM and CNN in your model are combined\n\"properly\" -- what does that actually mean? How does this \"properness\"\nmanifest? What would be the improper way to combine the models?\n2. I find the motivation/justification for the two output design rather weak: \n - the first argument that it allows for later addition of cues (i.e\nmanually-designed features) kind of beats the \"learning representations\"\nadvantage of using deep models. \n - the second argument about this design tackling the imbalance in the\ntraining set is kind of hand-wavy as there is no experimental support for this\nclaim. \n3. You first motivate the usage of your complex DL architecture with learning\nlatent representations and avoiding manual design and feature computation. And\nthen you define a set of manually designed features (several dependency paths\nand lexical features) as input for the model. Do you notice the discrepancy? \n4. The LSTMs (bidirectional, and also with attention) have by now already\nbecome a standard model for various NLP tasks. Thus I find the detailed\ndescription of the attention-based bidirectional LSTM unnecessary. \n5. What you present as a baseline in Section 3 is also part of your model (as\nit generates input to your model). Thus, I think that calling it a baseline\nundermines the understandability of the paper. \n6. The results reported originate from a 5-fold CV. However, the model contains\nnumerous hyperparameters that need to be optimized (e.g., number of filters and\nfilter sizes for CNNs). How do you optimize these values? Reporting results\nfrom a folded cross-validation doesn't allow for a fair optimization of the\nhypeparameters: either you're not optimizing the model's hyperparameters at\nall, or you're optimizing their values on the test set (which is unfair). \n7. \"Notice that some values are non-application (NA) grammatically, e.g., PRu,\nPSu, U+/-\" -- why is underspecification in ony one dimension (polarity or\ncertainty) not an option? I can easily think of a case where it is clear the\nevent is negative, but it is not specified whether the absence of an event is\ncertain, probable, or possible. \nLanguage & style:\n1. \"to a great degree\" -> \"great degree\" is an unusual construct, use either\n\"great extent\" or \"large degree\"\n2. \"events that can not\" -> \"cannot\" or \"do not\"\n3. \"describes out networks...in details shown in Figure 3.\" -> \"...shown in\nFigure 3 in details.\""
        }
    ]
}