{
    "version": "2025-01-09-base",
    "scanId": "3409b187-bde4-481d-9069-f581bee53bfe",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.06521371752023697,
                    "sentence": "- Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.056718502193689346,
                    "sentence": "The deviation between \"vocal\" users and \"average users\" is an interesting",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13990779221057892,
                    "sentence": "discovery that could be applied as a way to identify different types of users.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14636105298995972,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13026832044124603,
                    "sentence": "I see it as an initial work on a new topic that should be expanded in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19755366444587708,
                    "sentence": "future.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13007470965385437,
                    "sentence": "A possible comparison between matrix factorization and similar topics",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08956655114889145,
                    "sentence": "in distributional semantics (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2052556872367859,
                    "sentence": "latent semantic analysis) would be useful.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1330418586730957,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10818752646446228,
                    "sentence": "In this paper, the authors describe an approach for modeling the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11825426667928696,
                    "sentence": "stance/sentiment of Twitter users about topics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07822959870100021,
                    "sentence": "In particular, they address the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04006980359554291,
                    "sentence": "task of inter-topic preferences modeling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03703790530562401,
                    "sentence": "This task consists of measuring the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1206011101603508,
                    "sentence": "degree to which the stances about different topics are mutually related.This",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09220201522111893,
                    "sentence": "work is claimed to advance state of the art in this task, since previous works",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09038238972425461,
                    "sentence": "were case studies, while the proposed one is about unlimited topics on",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04879942536354065,
                    "sentence": "real-world data.The adopted approach consists of the following steps: A set of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06830760836601257,
                    "sentence": "linguistic patterns was manually created and, through them, a large number of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0776170939207077,
                    "sentence": "tweets expressing stance towards various topics was collected.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.029472965747117996,
                    "sentence": "Next, the texts",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09168548136949539,
                    "sentence": "were expressed as triples containing user, topic, and evaluation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023008260875940323,
                    "sentence": "The",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0883326455950737,
                    "sentence": "relationships represented by the tuples were arranged as a sparse matrix.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2741634249687195,
                    "sentence": "After",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05720607563853264,
                    "sentence": "matrix factorization, a low-rank approximation was performed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23915661871433258,
                    "sentence": "The optimal rank",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11460424214601517,
                    "sentence": "was identified as 100.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14318981766700745,
                    "sentence": "The definition of cosine similarity is used to measure",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16807261109352112,
                    "sentence": "the similarity between topics and, thus, detect latent preferences not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10326298326253891,
                    "sentence": "represented in the original sparse matrix.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19441454112529755,
                    "sentence": "Finally, cosine similarity is also",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2077089101076126,
                    "sentence": "used to detect inter-topic preferences.A preliminary empirical evaluation shows",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18035677075386047,
                    "sentence": "that the model predicts missing topics preferences.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14898718893527985,
                    "sentence": "Moreover, predicted",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15920259058475494,
                    "sentence": "inter-topic preferences moderately correlate with the corresponding values from",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03934970125555992,
                    "sentence": "a crowdsourced gold-standard collection of preferences.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03372463211417198,
                    "sentence": "According to the overview discussed in the related work section, there are no",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019236674532294273,
                    "sentence": "previous systems to be compared in the latter task (i.e.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026521531865000725,
                    "sentence": "prediction of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01944568380713463,
                    "sentence": "inter-topic preferences) and, for this reason, it is promising.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04450210928916931,
                    "sentence": "I listed some specific comments below.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.028405290096998215,
                    "sentence": "- Rows 23 and 744, \"high-quality\": What makes them high-quality?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04673022776842117,
                    "sentence": "If not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.029345348477363586,
                    "sentence": "properly defined, I would remove all the occurrences of \"high-quality\" in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.033814433962106705,
                    "sentence": "paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03209657222032547,
                    "sentence": "- Row 181 and caption of Figure 1: I would remove the term \"generic.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02608437091112137,
                    "sentence": "- Row 217, \"This section collect\": -> \"We collected\" or \"This section explains",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01916935294866562,
                    "sentence": "how we collected\"- Row 246: \"ironies\" -> \"irony\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03371046483516693,
                    "sentence": "- Row 269, \"I support TPP\": Since the procedure can detect various patterns",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021658804267644882,
                    "sentence": "such as \"to A\" or \"this is A,\" maybe the author should explain that all",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04555502533912659,
                    "sentence": "possible patterns containing the topic are collected, and next manually",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04831813648343086,
                    "sentence": "filtered?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.032766371965408325,
                    "sentence": "- Rows 275 and 280, \"unuseful\": -> useless",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.040380820631980896,
                    "sentence": "- Row 306, \"including\": -> are including",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02713964506983757,
                    "sentence": "- Row 309: \"of\" or \"it\" are not topics but, I guess, terms retrieved by",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.029091879725456238,
                    "sentence": "mistakes as topics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03469004109501839,
                    "sentence": "- Rows 317-319: I would remove the first sentence and start with \"Twitter",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023903876543045044,
                    "sentence": "user...\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04964838922023773,
                    "sentence": "- Rows 419-439: \"I like the procedure used to find the optimal k. In previous",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06317460536956787,
                    "sentence": "works, this number is often assumed, while it is useful to find it",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03107711300253868,
                    "sentence": "empirically.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04322202503681183,
                    "sentence": "- Row 446, \"let\": Is it \"call\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 59,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 63,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.06633669730667867,
            "class_probabilities": {
                "human": 0.9336633026933213,
                "ai": 0.06633669730667867,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9336633026933213,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.06633669730667867,
                    "human": 0.9336633026933213,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "- Strengths:\nThe deviation between \"vocal\" users and \"average users\" is an interesting\ndiscovery that could be applied as a way to identify different types of users.\n- Weaknesses:\nI see it as an initial work on a new topic that should be expanded in the\nfuture. A possible comparison between matrix factorization and similar topics \nin distributional semantics (e.g. latent semantic analysis) would be useful. \n- General Discussion:\nIn this paper, the authors describe an approach for modeling the\nstance/sentiment of Twitter users about topics. In particular, they address the\ntask of inter-topic preferences modeling. This task consists of measuring the\ndegree to which the stances about different topics are mutually related.This\nwork is claimed to advance state of the art in this task, since previous works\nwere case studies, while the proposed one is about unlimited topics on\nreal-world data.The adopted approach consists of the following steps: A set of\nlinguistic patterns was manually created and, through them, a large number of\ntweets expressing stance towards various topics was collected. Next, the texts\nwere expressed as triples containing user, topic, and evaluation. The\nrelationships represented by the tuples were arranged as a sparse matrix. After\nmatrix factorization, a low-rank approximation was performed. The optimal rank\nwas identified as 100. The definition of cosine similarity is used to measure\nthe similarity between topics and, thus, detect latent preferences not\nrepresented in the original sparse matrix. Finally, cosine similarity is also\nused to detect inter-topic preferences.A preliminary empirical evaluation shows\nthat the model predicts missing topics preferences. Moreover, predicted\ninter-topic preferences moderately correlate with the corresponding values from\na crowdsourced gold-standard collection of preferences. \nAccording to the overview discussed in the related work section, there are no\nprevious systems to be compared in the latter task (i.e. prediction of\ninter-topic preferences) and, for this reason, it is promising.\nI listed some specific comments below.\n- Rows 23 and 744, \"high-quality\": What makes them high-quality? If not\nproperly defined, I would remove all the occurrences of \"high-quality\" in the\npaper.\n- Row 181 and caption of Figure 1: I would remove the term \"generic.\"\n- Row 217, \"This section collect\": -> \"We collected\" or \"This section explains\nhow we collected\"- Row 246: \"ironies\" -> \"irony\"\n- Row 269, \"I support TPP\": Since the procedure can detect various patterns\nsuch as \"to A\" or \"this is A,\" maybe the author should explain that all\npossible patterns containing the topic are collected, and next manually\nfiltered?\n- Rows 275 and 280, \"unuseful\": -> useless\n- Row 306, \"including\": -> are including\n- Row 309: \"of\" or \"it\" are not topics but, I guess, terms retrieved by\nmistakes as topics. \n- Rows 317-319: I would remove the first sentence and start with \"Twitter\nuser...\"\n- Rows 419-439: \"I like the procedure used to find the optimal k. In previous\nworks, this number is often assumed, while it is useful to find it\nempirically.\"\n- Row 446, \"let\": Is it \"call\"?"
        }
    ]
}