{
    "version": "2025-01-09-base",
    "scanId": "360c5228-dd22-4984-9344-a4560a35f025",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.04171863943338394,
                    "sentence": "The work describes a joint neural approach to argumentation mining.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026985198259353638,
                    "sentence": "There are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.043980248272418976,
                    "sentence": "several approaches explored including:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.032999321818351746,
                    "sentence": "1) casting the problem as a dependency parsing problem (trying several",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03981981426477432,
                    "sentence": "different parsers)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02970602735877037,
                    "sentence": "2) casting the problem as a sequence labeling problem",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018128808587789536,
                    "sentence": "3) multi task learning (based on sequence labeling model underneath)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02860824018716812,
                    "sentence": "4) an out of the box neural model for labeling entities and relations (LSTM-ER)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01983809284865856,
                    "sentence": "5) ILP based state-of-the art models",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0366521030664444,
                    "sentence": "All the approaches are evaluated using F1 defined on concepts and relations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.015889976173639297,
                    "sentence": "Dependency based solutions do not work well, seq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011767087504267693,
                    "sentence": "labeling solutions are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019445987418293953,
                    "sentence": "effective.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019391346722841263,
                    "sentence": "The out-of-the-box LSTM-ER model performs very well.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.030883442610502243,
                    "sentence": "Especially on paragraph",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02629801630973816,
                    "sentence": "level.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0479571670293808,
                    "sentence": "The Seq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013636991381645203,
                    "sentence": "labeling and LSTM-ER models both outperform the ILP approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01648261770606041,
                    "sentence": "A very comprehensive supplement was given, with all the technicalities of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013599169440567493,
                    "sentence": "training",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013984998688101768,
                    "sentence": "the models, optimizing hyper-parameters etc.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02387150749564171,
                    "sentence": "It was also shown that sequence labeling models can be greatly improved by the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02901506796479225,
                    "sentence": "multitask",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02057221718132496,
                    "sentence": "approach (with the claim task helping more than the relation task).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022203177213668823,
                    "sentence": "The aper is a very thorough investigation of neural based approaches to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04573025926947594,
                    "sentence": "end-to-end argumentation mining.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10666483640670776,
                    "sentence": "- Major remarks",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0986471027135849,
                    "sentence": "- my one concern is with the data set, i'm wondering if it's a problem that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09978514164686203,
                    "sentence": "essays in the train set and in the test set might",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.052261464297771454,
                    "sentence": "be on the same topics, consequently writers might use the same or similar",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08939893543720245,
                    "sentence": "arguments in both essays, leading to information",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.055562809109687805,
                    "sentence": "leakage from the train to the test set.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.044530078768730164,
                    "sentence": "In turn, this might give overly",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07930043339729309,
                    "sentence": "optimistic performance estimates.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04094432294368744,
                    "sentence": "Though, i think the same",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0760999470949173,
                    "sentence": "issues are present for the ILP models, so your model does not have an unfair",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12871654331684113,
                    "sentence": "advantage.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004835427273064852,
                    "sentence": "Still, this may be something to discuss.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006934640929102898,
                    "sentence": "- my other concern is that one of your best models LSTM-ER is acutally just a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007136639207601547,
                    "sentence": "an out-of-the box application of a model from related",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0056027923710644245,
                    "sentence": "work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008110280148684978,
                    "sentence": "However, given the relative success of sequence based models and all",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006820427719503641,
                    "sentence": "the experiments and useful lessons learned, I think this",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0056988149881362915,
                    "sentence": "work deserves to be published.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004733750130981207,
                    "sentence": "- Minor remarks and questions:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009111801162362099,
                    "sentence": "222 - 226 - i guess you are arguing that it's possible to reconstruct the full",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01420864462852478,
                    "sentence": "graph once you get a tree as output?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009221642278134823,
                    "sentence": "Still, this part is not quite clear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006636294536292553,
                    "sentence": "443-444 The ordering in this section is seq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009231862612068653,
                    "sentence": "tagging -> dependency based -> MTL",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011262254789471626,
                    "sentence": "using seq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0059806122444570065,
                    "sentence": "tagging, it would be much easier to follow if the order of the first",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005456881131976843,
                    "sentence": "two were",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006391339469701052,
                    "sentence": "reversed (by the time I got here i'd forgotten what STag_T",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005194143392145634,
                    "sentence": "stood for)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003660584567114711,
                    "sentence": "455 - What does it mean that it de-couples them but jointly models them (isn't",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004780684132128954,
                    "sentence": "coupling them required to jointly model them?)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0047726319171488285,
                    "sentence": "- i checked Miwa and Bansal and I couldn't find it",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004058816470205784,
                    "sentence": "477 - 479 - It's confusing when you say your system de-couples relation info",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003234204137697816,
                    "sentence": "from entity info, my best guess is that you mean it",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002727523911744356,
                    "sentence": "learns some tasks as \"the edges of the tree\" and some",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0042836968787014484,
                    "sentence": "other tasks as \"the labels on those edges\", thus decoupling them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005229415837675333,
                    "sentence": "In any case, I recommend you make this part clearer",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011823941022157669,
                    "sentence": "Are the F1 scores in the paragraph and essay settings comparable?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01220875047147274,
                    "sentence": "In particular",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012965644709765911,
                    "sentence": "for the relation tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012729971669614315,
                    "sentence": "I'm wondering if paragraph based",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008751512505114079,
                    "sentence": "models might miss some cross paragraph relations by default, because they will",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013088666833937168,
                    "sentence": "never consider them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 59,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 63,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 65,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 67,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 68,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.06631762963797466,
            "class_probabilities": {
                "human": 0.9333949326468816,
                "ai": 0.06631762963797466,
                "mixed": 0.0002874377151437875
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9333949326468816,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.06631762963797466,
                    "human": 0.9333949326468816,
                    "mixed": 0.0002874377151437875
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The work describes a joint neural approach to argumentation mining. There are\nseveral approaches explored including:\n 1) casting the problem as a dependency parsing problem (trying several\ndifferent parsers)\n 2) casting the problem as a sequence labeling problem\n3) multi task learning (based on sequence labeling model underneath)\n4) an out of the box neural model for labeling entities and relations (LSTM-ER)\n5) ILP based state-of-the art models\nAll the approaches are evaluated using F1 defined on concepts and relations. \nDependency based solutions do not work well, seq. labeling solutions are\neffective.\nThe out-of-the-box LSTM-ER model performs very well. Especially on paragraph\nlevel.\nThe Seq. labeling and LSTM-ER models both outperform the ILP approach.\nA very comprehensive supplement was given, with all the technicalities of\ntraining\nthe models, optimizing hyper-parameters etc.\nIt was also shown that sequence labeling models can be greatly improved by the\nmultitask\napproach (with the claim task helping more than the relation task).\nThe aper is a very thorough investigation of neural based approaches to\nend-to-end argumentation mining.\n- Major remarks \n - my one concern is with the data set, i'm wondering if it's a problem that\nessays in the train set and in the test set might\n be on the same topics, consequently writers might use the same or similar\narguments in both essays, leading to information\n leakage from the train to the test set. In turn, this might give overly\noptimistic performance estimates. Though, i think the same\n issues are present for the ILP models, so your model does not have an unfair\nadvantage. Still, this may be something to discuss.\n - my other concern is that one of your best models LSTM-ER is acutally just a\nan out-of-the box application of a model from related\n work. However, given the relative success of sequence based models and all\nthe experiments and useful lessons learned, I think this \n work deserves to be published.\n- Minor remarks and questions:\n222 - 226 - i guess you are arguing that it's possible to reconstruct the full\ngraph once you get a tree as output? Still, this part is not quite clear.\n443-444 The ordering in this section is seq. tagging -> dependency based -> MTL\nusing seq. tagging, it would be much easier to follow if the order of the first\ntwo were\n reversed (by the time I got here i'd forgotten what STag_T\nstood for)\n455 - What does it mean that it de-couples them but jointly models them (isn't\ncoupling them required to jointly model them?)\n - i checked Miwa and Bansal and I couldn't find it\n477 - 479 - It's confusing when you say your system de-couples relation info\nfrom entity info, my best guess is that you mean it\n learns some tasks as \"the edges of the tree\" and some\nother tasks as \"the labels on those edges\", thus decoupling them. \n In any case, I recommend you make this part clearer\nAre the F1 scores in the paragraph and essay settings comparable? In particular\nfor the relation tasks. I'm wondering if paragraph based \nmodels might miss some cross paragraph relations by default, because they will\nnever consider them."
        }
    ]
}