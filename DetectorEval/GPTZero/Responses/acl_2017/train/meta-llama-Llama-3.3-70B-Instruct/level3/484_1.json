{
    "version": "2025-01-09-base",
    "scanId": "e54801ff-f521-41e0-825a-3f2bcff7d404",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9994097352027893,
                    "sentence": "This paper proposes a joint CTC-attention end-to-end ASR system, but the provided text does not match this description.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996042251586914,
                    "sentence": "Instead, it appears to be a paper on keyphrase extraction using a generative model with an encoder-decoder framework.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996544718742371,
                    "sentence": "The paper's main contribution is the proposal of a deep keyphrase generation model that can effectively capture the semantic meaning of content and generate keyphrases based on this understanding.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999274730682373,
                    "sentence": "The model is evaluated on six datasets and achieves significant performance boosts in extracting keyphrases that appear in the source text, as well as generating absent keyphrases based on the semantic meaning of the text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995922446250916,
                    "sentence": "The strengths of this paper include its comprehensive comparison with six important baselines on a broad range of datasets, demonstrating the effectiveness of the proposed model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993411302566528,
                    "sentence": "The use of a copy mechanism in the RNN model enables it to predict unknown words based on contextual features, which is a significant improvement over previous approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999646782875061,
                    "sentence": "However, there are some weaknesses in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995322823524475,
                    "sentence": "The title is too general and does not clearly represent the main contribution of the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999612033367157,
                    "sentence": "The introduction does not clearly state the original contribution and builds upon someone else's proposal without adding significant extensions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999284744262695,
                    "sentence": "The experimental results could be improved by explaining the specific problems addressed in the keyphrase extraction tasks, such as handling multiple possible outputs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994664788246155,
                    "sentence": "The paper should cite the official IEEE ICASSP conference version of Kim et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993334412574768,
                    "sentence": "(2016) instead of the pre-published arXiv version.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999771118164062,
                    "sentence": "Additionally, the paper's similarity to previous work by Kim et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999485015869141,
                    "sentence": "(2016) is not clearly explained, which raises concerns about the novelty of the proposed approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999359250068665,
                    "sentence": "Overall, the paper demonstrates the effectiveness of the proposed deep keyphrase generation model, but there are areas that need improvement, such as clarifying the original contribution, providing more detailed explanations of the experimental results, and addressing the similarity to previous work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999598503112793,
                    "sentence": "Questions to authors:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999168515205383,
                    "sentence": "1. Can you provide more details on how the proposed model handles multiple possible outputs in the keyphrase extraction tasks?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998698830604553,
                    "sentence": "2. How does the proposed model address the issue of out-of-vocabulary words, and what are the limitations of the current approach?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998846054077148,
                    "sentence": "3. Can you provide a more detailed comparison with the previous work by Kim et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999168515205383,
                    "sentence": "(2016) and explain how the proposed model improves upon their approach?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9997847017652333,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997847017652333,
                "mixed": 0.00021529823476680056
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997847017652333,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997847017652333,
                    "human": 0,
                    "mixed": 0.00021529823476680056
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes a joint CTC-attention end-to-end ASR system, but the provided text does not match this description. Instead, it appears to be a paper on keyphrase extraction using a generative model with an encoder-decoder framework. \nThe paper's main contribution is the proposal of a deep keyphrase generation model that can effectively capture the semantic meaning of content and generate keyphrases based on this understanding. The model is evaluated on six datasets and achieves significant performance boosts in extracting keyphrases that appear in the source text, as well as generating absent keyphrases based on the semantic meaning of the text.\nThe strengths of this paper include its comprehensive comparison with six important baselines on a broad range of datasets, demonstrating the effectiveness of the proposed model. The use of a copy mechanism in the RNN model enables it to predict unknown words based on contextual features, which is a significant improvement over previous approaches.\nHowever, there are some weaknesses in the paper. The title is too general and does not clearly represent the main contribution of the paper. The introduction does not clearly state the original contribution and builds upon someone else's proposal without adding significant extensions. The experimental results could be improved by explaining the specific problems addressed in the keyphrase extraction tasks, such as handling multiple possible outputs.\nThe paper should cite the official IEEE ICASSP conference version of Kim et al. (2016) instead of the pre-published arXiv version. Additionally, the paper's similarity to previous work by Kim et al. (2016) is not clearly explained, which raises concerns about the novelty of the proposed approach.\nOverall, the paper demonstrates the effectiveness of the proposed deep keyphrase generation model, but there are areas that need improvement, such as clarifying the original contribution, providing more detailed explanations of the experimental results, and addressing the similarity to previous work. \nQuestions to authors: \n1. Can you provide more details on how the proposed model handles multiple possible outputs in the keyphrase extraction tasks?\n2. How does the proposed model address the issue of out-of-vocabulary words, and what are the limitations of the current approach?\n3. Can you provide a more detailed comparison with the previous work by Kim et al. (2016) and explain how the proposed model improves upon their approach?"
        }
    ]
}