{
    "version": "2025-01-09-base",
    "scanId": "76b5c039-3b26-4ee0-9a5b-144bd9a8d199",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999960660934448,
                    "sentence": "This research paper proposes a novel approach to learn bilingual word embeddings using a self-learning framework.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961853027344,
                    "sentence": "The method leverages a small seed dictionary to learn a mapping between two languages and then iteratively updates the dictionary and the mapping until convergence.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958872795105,
                    "sentence": "The paper claims that this approach can learn high-quality bilingual embeddings from as little as 25 word pairs or even an automatically generated list of numerals.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999951720237732,
                    "sentence": "The main contributions of this work are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963045120239,
                    "sentence": "1. A simple self-learning framework for learning bilingual word embeddings that can work with minimal bilingual evidence.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999969601631165,
                    "sentence": "2. The proposed method is able to learn high-quality bilingual embeddings that are competitive with state-of-the-art systems using much richer bilingual resources.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999969005584717,
                    "sentence": "3. The approach is language-agnostic and can be applied to any language pair.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999943971633911,
                    "sentence": "The strengths of this paper are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999975562095642,
                    "sentence": "1. The proposed method is able to learn high-quality bilingual embeddings from minimal bilingual evidence, which is a significant advantage over existing methods that require large parallel corpora or dictionaries.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999974370002747,
                    "sentence": "2. The approach is simple and efficient, making it suitable for large-scale applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967813491821,
                    "sentence": "3. The paper provides a detailed analysis of the optimization objective and shows that the proposed method is implicitly optimizing a meaningful objective function.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999975323677063,
                    "sentence": "The weaknesses of this paper are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999853372573853,
                    "sentence": "1. The paper suffers from poor English usage, making it hard to read and understand.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999662041664124,
                    "sentence": "2. The main machine learning problem is poorly described, with unclear classification tasks and dataset descriptions that lack relevant information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999902069568634,
                    "sentence": "3. The paper's motivation for enriching the graph is unclear, and alternative methods are not considered.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999554753303528,
                    "sentence": "4. The datasets are from a biomedical domain, but no domain-specific tools have been leveraged, which is a significant weakness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999818801879883,
                    "sentence": "5. The evaluation metrics used are unclear, and accuracy is a potentially poor measure due to unclear class distribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9982755780220032,
                    "sentence": "Questions to authors:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995009899139404,
                    "sentence": "1. Can you provide more details on the optimization objective and how it is related to the self-learning framework?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990934133529663,
                    "sentence": "2. How do you plan to extend this work to learn bilingual word embeddings without any bilingual evidence at all?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995739459991455,
                    "sentence": "3. Can you provide more information on the datasets used and the experimental settings?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991673231124878,
                    "sentence": "4. How do you plan to address the poor English usage and unclear descriptions in the paper?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989361763000488,
                    "sentence": "5. Can you provide more details on the alternative methods considered and why they were not used?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This research paper proposes a novel approach to learn bilingual word embeddings using a self-learning framework. The method leverages a small seed dictionary to learn a mapping between two languages and then iteratively updates the dictionary and the mapping until convergence. The paper claims that this approach can learn high-quality bilingual embeddings from as little as 25 word pairs or even an automatically generated list of numerals.\nThe main contributions of this work are:\n1. A simple self-learning framework for learning bilingual word embeddings that can work with minimal bilingual evidence.\n2. The proposed method is able to learn high-quality bilingual embeddings that are competitive with state-of-the-art systems using much richer bilingual resources.\n3. The approach is language-agnostic and can be applied to any language pair.\nThe strengths of this paper are:\n1. The proposed method is able to learn high-quality bilingual embeddings from minimal bilingual evidence, which is a significant advantage over existing methods that require large parallel corpora or dictionaries.\n2. The approach is simple and efficient, making it suitable for large-scale applications.\n3. The paper provides a detailed analysis of the optimization objective and shows that the proposed method is implicitly optimizing a meaningful objective function.\nThe weaknesses of this paper are:\n1. The paper suffers from poor English usage, making it hard to read and understand.\n2. The main machine learning problem is poorly described, with unclear classification tasks and dataset descriptions that lack relevant information.\n3. The paper's motivation for enriching the graph is unclear, and alternative methods are not considered.\n4. The datasets are from a biomedical domain, but no domain-specific tools have been leveraged, which is a significant weakness.\n5. The evaluation metrics used are unclear, and accuracy is a potentially poor measure due to unclear class distribution.\nQuestions to authors:\n1. Can you provide more details on the optimization objective and how it is related to the self-learning framework?\n2. How do you plan to extend this work to learn bilingual word embeddings without any bilingual evidence at all?\n3. Can you provide more information on the datasets used and the experimental settings?\n4. How do you plan to address the poor English usage and unclear descriptions in the paper?\n5. Can you provide more details on the alternative methods considered and why they were not used?"
        }
    ]
}