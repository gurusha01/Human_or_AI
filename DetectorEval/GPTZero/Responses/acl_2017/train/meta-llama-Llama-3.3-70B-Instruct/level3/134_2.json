{
    "version": "2025-01-09-base",
    "scanId": "c9c02e17-0e8c-45cd-ad37-3cb5acb4e44a",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.1489371657371521,
                    "sentence": "This paper presents a thorough investigation of neural-based approaches to end-to-end argumentation mining.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10699544101953506,
                    "sentence": "The authors explore several approaches, including dependency parsing, sequence labeling, multi-task learning, and out-of-the-box neural models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3259658217430115,
                    "sentence": "The main contributions of this work are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1524646282196045,
                    "sentence": "1. The presentation of the first neural end-to-end solutions to computational argumentation mining.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.24552680552005768,
                    "sentence": "2. The demonstration that several of these solutions perform better than the state-of-the-art joint ILP model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3426415026187897,
                    "sentence": "3. The finding that a framing of argumentation mining as a token-based dependency parsing problem is ineffective, while a standard neural sequence tagging model performs robustly in different environments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.47790053486824036,
                    "sentence": "The strengths of this paper include the comprehensive evaluation of different approaches, the use of a multi-task learning setup to improve performance, and the achievement of state-of-the-art results on the PE dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4288254678249359,
                    "sentence": "The sequence labeling and out-of-the-box LSTM-ER models perform particularly well, especially on paragraph-level tasks, and outperform the ILP approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6096711754798889,
                    "sentence": "The supplement provides a detailed overview of the technicalities of training and optimizing the models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7173824310302734,
                    "sentence": "However, there are some weaknesses to this paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9901040196418762,
                    "sentence": "One concern is the potential for information leakage from the train set to the test set due to similar topics and arguments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9793928861618042,
                    "sentence": "Additionally, the use of an out-of-the-box LSTM-ER model may not be entirely novel, and the paper could benefit from more detailed explanations of certain sections, such as the ordering of models and the meaning of decoupling relation information from entity information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9786455035209656,
                    "sentence": "Some questions to the authors include: How do the F1 scores in paragraph and essay settings compare, particularly for relation tasks?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9878414869308472,
                    "sentence": "Can the authors provide more insight into the impact of multi-task learning on the performance of the sequence labeling models?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9579527974128723,
                    "sentence": "How do the results of this paper relate to other work in the field of argumentation mining, and what are the implications for future research in this area?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9899854063987732,
                    "sentence": "Overall, this paper presents a significant contribution to the field of argumentation mining, and its findings have important implications for the development of more effective argumentation mining systems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9781492352485657,
                    "sentence": "Despite some minor weaknesses, the paper is well-written and provides a thorough evaluation of different approaches to argumentation mining.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.45887534985363754
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.49429992948366375,
            "class_probabilities": {
                "human": 0.5048920708297422,
                "ai": 0.49429992948366375,
                "mixed": 0.0008079996865940609
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.5048920708297422,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.49429992948366375,
                    "human": 0.5048920708297422,
                    "mixed": 0.0008079996865940609
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a thorough investigation of neural-based approaches to end-to-end argumentation mining. The authors explore several approaches, including dependency parsing, sequence labeling, multi-task learning, and out-of-the-box neural models. The main contributions of this work are: \n1. The presentation of the first neural end-to-end solutions to computational argumentation mining.\n2. The demonstration that several of these solutions perform better than the state-of-the-art joint ILP model.\n3. The finding that a framing of argumentation mining as a token-based dependency parsing problem is ineffective, while a standard neural sequence tagging model performs robustly in different environments.\nThe strengths of this paper include the comprehensive evaluation of different approaches, the use of a multi-task learning setup to improve performance, and the achievement of state-of-the-art results on the PE dataset. The sequence labeling and out-of-the-box LSTM-ER models perform particularly well, especially on paragraph-level tasks, and outperform the ILP approach. The supplement provides a detailed overview of the technicalities of training and optimizing the models.\nHowever, there are some weaknesses to this paper. One concern is the potential for information leakage from the train set to the test set due to similar topics and arguments. Additionally, the use of an out-of-the-box LSTM-ER model may not be entirely novel, and the paper could benefit from more detailed explanations of certain sections, such as the ordering of models and the meaning of decoupling relation information from entity information.\nSome questions to the authors include: How do the F1 scores in paragraph and essay settings compare, particularly for relation tasks? Can the authors provide more insight into the impact of multi-task learning on the performance of the sequence labeling models? How do the results of this paper relate to other work in the field of argumentation mining, and what are the implications for future research in this area? \nOverall, this paper presents a significant contribution to the field of argumentation mining, and its findings have important implications for the development of more effective argumentation mining systems. Despite some minor weaknesses, the paper is well-written and provides a thorough evaluation of different approaches to argumentation mining."
        }
    ]
}