{
    "version": "2025-01-09-base",
    "scanId": "a3bbc72c-b1da-4276-b622-c64f7b0781ed",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999555349349976,
                    "sentence": "This research paper proposes a novel approach to identifying patients with mild cognitive impairment using Natural Language Processing (NLP) techniques applied to speech transcripts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999965488910675,
                    "sentence": "The authors claim to have achieved an accuracy rate of 60% to 85% in their experiments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999396204948425,
                    "sentence": "While the message is encouraging, the conclusion is less optimistic than the introduction, which may indicate some limitations in the study.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999765157699585,
                    "sentence": "The dataset used in this study is limited, consisting of only 20 healthy patients and 20 control participants.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999662637710571,
                    "sentence": "Furthermore, the dataset is not understandable for non-Portuguese speakers, which makes it difficult to replicate or understand the results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999718070030212,
                    "sentence": "This limitation raises concerns about the generalizability of the findings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999679327011108,
                    "sentence": "The paper lacks technological details, such as examples of short transcripts translated to English and sample networks with embeddings, which would help clarify the methodology used.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999758005142212,
                    "sentence": "The introduction and review of relevant work are too detailed and include unnecessary references, which can be omitted or shortened to focus on the paper's topic.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999590516090393,
                    "sentence": "The use of word embeddings and networks is unclear, with questions raised about the source of continuous word representations and the training data used.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99997478723526,
                    "sentence": "The study's focus on Portuguese is interesting, but the text needs revision to shorten sections, add explanations, and clarify technical details.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999968945980072,
                    "sentence": "The paper requires technical corrections, including grammar and formatting errors, such as incorrect punctuation, repeated words, and inconsistent formatting in tables and references.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999799728393555,
                    "sentence": "The main contributions of this work are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999833106994629,
                    "sentence": "1. The proposal of a self-learning framework to learn bilingual word embedding mappings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999867081642151,
                    "sentence": "2. The ability to learn high-quality bilingual embeddings from small seed dictionaries.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999816417694092,
                    "sentence": "3. The achievement of competitive results with state-of-the-art systems using much richer bilingual resources.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999555349349976,
                    "sentence": "The strengths of this paper are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999734163284302,
                    "sentence": "1. The simplicity and efficiency of the proposed self-learning framework.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999797344207764,
                    "sentence": "2. The ability to learn bilingual word embeddings without any real bilingual data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999695420265198,
                    "sentence": "3. The competitive results achieved in bilingual lexicon induction and cross-lingual word similarity tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999299049377441,
                    "sentence": "The weaknesses of this paper are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999965250492096,
                    "sentence": "1. The limited dataset used in the study.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999459981918335,
                    "sentence": "2. The lack of technological details and unclear use of word embeddings and networks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999739527702332,
                    "sentence": "3. The need for technical corrections and revisions to improve clarity and readability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998788833618164,
                    "sentence": "Questions to the authors:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999529123306274,
                    "sentence": "1. How do you plan to address the limitation of the dataset and improve the generalizability of the findings?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999265074729919,
                    "sentence": "2. Can you provide more technological details and examples to clarify the methodology used?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999557137489319,
                    "sentence": "3. How do you plan to improve the clarity and readability of the paper, and what revisions do you propose to make?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This research paper proposes a novel approach to identifying patients with mild cognitive impairment using Natural Language Processing (NLP) techniques applied to speech transcripts. The authors claim to have achieved an accuracy rate of 60% to 85% in their experiments. While the message is encouraging, the conclusion is less optimistic than the introduction, which may indicate some limitations in the study.\nThe dataset used in this study is limited, consisting of only 20 healthy patients and 20 control participants. Furthermore, the dataset is not understandable for non-Portuguese speakers, which makes it difficult to replicate or understand the results. This limitation raises concerns about the generalizability of the findings.\nThe paper lacks technological details, such as examples of short transcripts translated to English and sample networks with embeddings, which would help clarify the methodology used. The introduction and review of relevant work are too detailed and include unnecessary references, which can be omitted or shortened to focus on the paper's topic.\nThe use of word embeddings and networks is unclear, with questions raised about the source of continuous word representations and the training data used. The study's focus on Portuguese is interesting, but the text needs revision to shorten sections, add explanations, and clarify technical details.\nThe paper requires technical corrections, including grammar and formatting errors, such as incorrect punctuation, repeated words, and inconsistent formatting in tables and references.\nThe main contributions of this work are:\n1. The proposal of a self-learning framework to learn bilingual word embedding mappings.\n2. The ability to learn high-quality bilingual embeddings from small seed dictionaries.\n3. The achievement of competitive results with state-of-the-art systems using much richer bilingual resources.\nThe strengths of this paper are:\n1. The simplicity and efficiency of the proposed self-learning framework.\n2. The ability to learn bilingual word embeddings without any real bilingual data.\n3. The competitive results achieved in bilingual lexicon induction and cross-lingual word similarity tasks.\nThe weaknesses of this paper are:\n1. The limited dataset used in the study.\n2. The lack of technological details and unclear use of word embeddings and networks.\n3. The need for technical corrections and revisions to improve clarity and readability.\nQuestions to the authors:\n1. How do you plan to address the limitation of the dataset and improve the generalizability of the findings?\n2. Can you provide more technological details and examples to clarify the methodology used?\n3. How do you plan to improve the clarity and readability of the paper, and what revisions do you propose to make?"
        }
    ]
}