{
    "version": "2025-01-09-base",
    "scanId": "8e1c0f97-b75c-4f73-963b-c736dedf95e6",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9977781772613525,
                    "sentence": "This paper presents an innovative approach to word embedding methods by generating representations for phrases and concepts that correspond to words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9930390119552612,
                    "sentence": "The proposed method involves assigning a unique identifier to groups of phrases, words, and concepts that denote the same concept, replacing occurrences of these phrases and words with the identifier in the training corpus to create a \"tagged\" corpus, and then combining the tagged corpus with the original corpus for training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9894779920578003,
                    "sentence": "The concept, phrase, and word sets are derived from an ontology, with a focus on biomedical applications utilizing relevant corpora and ontologies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9919872283935547,
                    "sentence": "Notably, the researchers have also developed a novel test dataset for assessing word similarity and relatedness for real-world entities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9942754507064819,
                    "sentence": "The paper is well-written, and the technique, although straightforward, is not particularly groundbreaking.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.990379273891449,
                    "sentence": "The contribution is somewhat limited in scope due to its focused evaluation within the biomedical domain.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9933258891105652,
                    "sentence": "A more in-depth discussion of the generated test resource would be beneficial, as it potentially represents the most significant contribution of the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986816644668579,
                    "sentence": "One minor technical issue was identified.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9968189597129822,
                    "sentence": "In Equation 8, the authors attempt to define the MAP calculation, which is a good idea.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9955710768699646,
                    "sentence": "However, instead of ranking the entire vocabulary, a natural cut-off could be defined.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9969564080238342,
                    "sentence": "Furthermore, Equation 8 does not define a probability, even if the vocabulary size is infinite, which can be easily demonstrated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9964633584022522,
                    "sentence": "Therefore, the explanation should be revised to omit references to probability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9953712821006775,
                    "sentence": "Additionally, a small correction is suggested: on line 556, \"most concepts has\" should be changed to \"most concepts have\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997847017652333,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997847017652333,
                "mixed": 0.00021529823476680056
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997847017652333,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997847017652333,
                    "human": 0,
                    "mixed": 0.00021529823476680056
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents an innovative approach to word embedding methods by generating representations for phrases and concepts that correspond to words. The proposed method involves assigning a unique identifier to groups of phrases, words, and concepts that denote the same concept, replacing occurrences of these phrases and words with the identifier in the training corpus to create a \"tagged\" corpus, and then combining the tagged corpus with the original corpus for training. The concept, phrase, and word sets are derived from an ontology, with a focus on biomedical applications utilizing relevant corpora and ontologies. Notably, the researchers have also developed a novel test dataset for assessing word similarity and relatedness for real-world entities.\nThe paper is well-written, and the technique, although straightforward, is not particularly groundbreaking. The contribution is somewhat limited in scope due to its focused evaluation within the biomedical domain. A more in-depth discussion of the generated test resource would be beneficial, as it potentially represents the most significant contribution of the paper.\nOne minor technical issue was identified. In Equation 8, the authors attempt to define the MAP calculation, which is a good idea. However, instead of ranking the entire vocabulary, a natural cut-off could be defined. Furthermore, Equation 8 does not define a probability, even if the vocabulary size is infinite, which can be easily demonstrated. Therefore, the explanation should be revised to omit references to probability.\nAdditionally, a small correction is suggested: on line 556, \"most concepts has\" should be changed to \"most concepts have\"."
        }
    ]
}