{
    "version": "2025-01-09-base",
    "scanId": "d3d75733-ed36-4a56-80f1-2714ca206e98",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.999945342540741,
                    "sentence": "Review: Multimodal Word Distributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999560713768005,
                    "sentence": "- Strengths: This paper presents a robust and well-structured approach to learning multimodal word distributions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999467134475708,
                    "sentence": "- Weaknesses: A more comprehensive comparison with similar methods would further enhance the paper's validity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999504089355469,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999377727508545,
                    "sentence": "This paper introduces a novel model for representing multimodal word distributions using Gaussian mixtures, effectively capturing multiple word meanings as a set of Gaussian distributions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999361634254456,
                    "sentence": "Building upon the unimodal Gaussian distribution model proposed by Vilnis and McCallum (2014), the current approach addresses the issue of polysemy by utilizing a multimodal representation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998030066490173,
                    "sentence": "The paper is well-organized, clear, and supported by thorough experimentation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997760057449341,
                    "sentence": "The qualitative analysis in Table 1 yields expected results, demonstrating the effectiveness of the approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992667436599731,
                    "sentence": "The following comments are intended to provide suggestions for further clarification and improvement.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994858503341675,
                    "sentence": "Some key points to consider:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997606873512268,
                    "sentence": "* A brief discussion highlighting the differences between the current approach and that of Tian et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997340440750122,
                    "sentence": "(2014) would be beneficial, as both methods employ mixture models to split single word representations into multiple prototypes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995580911636353,
                    "sentence": "* The related work section could be enhanced by incorporating citations from relevant studies, such as:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998533725738525,
                    "sentence": "Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space by Neelakantan et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998724460601807,
                    "sentence": "(EMNLP 2014),",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999910831451416,
                    "sentence": "Do Multi-Sense Embeddings Improve Natural Language Understanding?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997363090515137,
                    "sentence": "by Li and Jurafsky (EMNLP 2015), and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997520446777344,
                    "sentence": "Topical Word Embeddings by Liu et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998023509979248,
                    "sentence": "(AAI 2015).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996967911720276,
                    "sentence": "* Including results from these approaches in Tables 3 and 4 could provide additional insights.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995562434196472,
                    "sentence": "* A question for the authors: What factors contribute to the performance difference between w2gm and w2g in the SWCS analysis?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995170831680298,
                    "sentence": "I have taken into account the authors' response.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Review: Multimodal Word Distributions\n- Strengths: This paper presents a robust and well-structured approach to learning multimodal word distributions.\n- Weaknesses: A more comprehensive comparison with similar methods would further enhance the paper's validity.\n- General Discussion:\nThis paper introduces a novel model for representing multimodal word distributions using Gaussian mixtures, effectively capturing multiple word meanings as a set of Gaussian distributions. Building upon the unimodal Gaussian distribution model proposed by Vilnis and McCallum (2014), the current approach addresses the issue of polysemy by utilizing a multimodal representation.\nThe paper is well-organized, clear, and supported by thorough experimentation. The qualitative analysis in Table 1 yields expected results, demonstrating the effectiveness of the approach. The following comments are intended to provide suggestions for further clarification and improvement.\nSome key points to consider:\n* A brief discussion highlighting the differences between the current approach and that of Tian et al. (2014) would be beneficial, as both methods employ mixture models to split single word representations into multiple prototypes.\n* The related work section could be enhanced by incorporating citations from relevant studies, such as:\nEfficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space by Neelakantan et al. (EMNLP 2014),\nDo Multi-Sense Embeddings Improve Natural Language Understanding? by Li and Jurafsky (EMNLP 2015), and\nTopical Word Embeddings by Liu et al. (AAI 2015).\n* Including results from these approaches in Tables 3 and 4 could provide additional insights.\n* A question for the authors: What factors contribute to the performance difference between w2gm and w2g in the SWCS analysis?\nI have taken into account the authors' response."
        }
    ]
}