{
    "version": "2025-01-09-base",
    "scanId": "b7fc7999-f78a-407e-bab9-c2d706e4ba59",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9930533766746521,
                    "sentence": "Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9864543080329895,
                    "sentence": "This manuscript presents a compelling approach to integrating neural models (LSTM) with linguistic insights (sentiment lexicon, negation, and intensity), yielding a straightforward yet efficacious method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9781414866447449,
                    "sentence": "The proposed technique achieves state-of-the-art performance on the Movie Review dataset and remains competitive with top-performing models on the SST dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9924427270889282,
                    "sentence": "Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9638316035270691,
                    "sentence": "A similar concept has been explored in previous work (Teng et al., 2016), although the current framework exhibits more elegance in design and mathematical formulation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9597684144973755,
                    "sentence": "However, the experimental comparison with Teng et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9735990762710571,
                    "sentence": "(2016) is less convincing than the comparisons with other methods, as the authors only report re-implementation results for the sentence-level experiment on SST and omit their own phrase-level results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9827427268028259,
                    "sentence": "Certain details are not adequately explained, as discussed below.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9860330820083618,
                    "sentence": "General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9797554612159729,
                    "sentence": "The reviewer poses the following questions and suggestions regarding this work:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9598910212516785,
                    "sentence": "1. Given the SST dataset's phrase-level annotations, it would be beneficial to provide statistics on the frequency of negation or intensity words actually influencing the outcome.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.941927969455719,
                    "sentence": "For instance, the number of times the word \"nothing\" appears and the number of times it alters the context's polarity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8893544673919678,
                    "sentence": "2. In Section 4.5, bi-LSTM is utilized for regularization.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8869228959083557,
                    "sentence": "Is bi-LSTM also employed for predicting sentiment labels?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9328174591064453,
                    "sentence": "3. The authors claim to only use sentence-level annotations to avoid expensive phrase-level annotations, one of their primary objectives.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9000387191772461,
                    "sentence": "Nevertheless, the reviewer recommends including these results, which could be reported during the rebuttal phase if possible.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9427340030670166,
                    "sentence": "4. The parameter sc is stated to be optimized but can also be fixed using prior knowledge.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9560863375663757,
                    "sentence": "However, the reviewer could not find a specific definition of sc in the experiment section.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.948441743850708,
                    "sentence": "Is it learned or fixed, and what is the learned or fixed value?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9398552179336548,
                    "sentence": "5. As suggested in Sections 5.4 and 5.5, conducting an additional experiment on a subset of the SST dataset containing only phrases with negation or intensity words could be more convincing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9486667513847351,
                    "sentence": "Reporting the results on this sub-dataset with and without the corresponding regularizer would provide further insight.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.8128347701425863,
            "class_probabilities": {
                "human": 0.18698804302060604,
                "ai": 0.8128347701425863,
                "mixed": 0.00017718683680779119
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8128347701425863,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8128347701425863,
                    "human": 0.18698804302060604,
                    "mixed": 0.00017718683680779119
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Strengths:\nThis manuscript presents a compelling approach to integrating neural models (LSTM) with linguistic insights (sentiment lexicon, negation, and intensity), yielding a straightforward yet efficacious method. The proposed technique achieves state-of-the-art performance on the Movie Review dataset and remains competitive with top-performing models on the SST dataset.\nWeaknesses:\nA similar concept has been explored in previous work (Teng et al., 2016), although the current framework exhibits more elegance in design and mathematical formulation. However, the experimental comparison with Teng et al. (2016) is less convincing than the comparisons with other methods, as the authors only report re-implementation results for the sentence-level experiment on SST and omit their own phrase-level results. Certain details are not adequately explained, as discussed below.\nGeneral Discussion:\nThe reviewer poses the following questions and suggestions regarding this work:\n1. Given the SST dataset's phrase-level annotations, it would be beneficial to provide statistics on the frequency of negation or intensity words actually influencing the outcome. For instance, the number of times the word \"nothing\" appears and the number of times it alters the context's polarity.\n2. In Section 4.5, bi-LSTM is utilized for regularization. Is bi-LSTM also employed for predicting sentiment labels?\n3. The authors claim to only use sentence-level annotations to avoid expensive phrase-level annotations, one of their primary objectives. Nevertheless, the reviewer recommends including these results, which could be reported during the rebuttal phase if possible.\n4. The parameter sc is stated to be optimized but can also be fixed using prior knowledge. However, the reviewer could not find a specific definition of sc in the experiment section. Is it learned or fixed, and what is the learned or fixed value?\n5. As suggested in Sections 5.4 and 5.5, conducting an additional experiment on a subset of the SST dataset containing only phrases with negation or intensity words could be more convincing. Reporting the results on this sub-dataset with and without the corresponding regularizer would provide further insight."
        }
    ]
}