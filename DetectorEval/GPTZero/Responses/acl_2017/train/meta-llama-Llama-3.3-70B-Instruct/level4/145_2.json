{
    "version": "2025-01-09-base",
    "scanId": "ae4eba82-daf1-4a5d-b2a9-d85db780fa92",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999334216117859,
                    "sentence": "This study leverages Gaussian mixtures to model words, showcasing their capability in capturing multiple meanings of polysemous words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998112320899963,
                    "sentence": "The training process employs a max-margin objective, utilizing the expected likelihood kernel to measure the similarity between word distributions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998886585235596,
                    "sentence": "Experimental results on word similarity and entailment tasks demonstrate the efficacy of the proposed approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997917413711548,
                    "sentence": "- Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987358450889587,
                    "sentence": "The problem statement is well-defined and clearly motivated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9969877600669861,
                    "sentence": "The use of Gaussian mixtures offers a more expressive representation compared to deterministic vector models, potentially capturing distinct word meanings through their modes, along with the associated probability mass and uncertainty.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9972583055496216,
                    "sentence": "This work constitutes a significant contribution to the field of word embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9957589507102966,
                    "sentence": "The proposed max-margin learning objective, accompanied by a closed-form similarity measurement, enables efficient training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9957351684570312,
                    "sentence": "The paper is generally well-written, contributing to its overall clarity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9983471632003784,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9938102960586548,
                    "sentence": "Please refer to the questions posed below for further discussion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9982954263687134,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9967055320739746,
                    "sentence": "A crucial parameter in Gaussian mixture models is the number of components (k).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9952910542488098,
                    "sentence": "In the experiments presented, k is fixed at 2.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9949061274528503,
                    "sentence": "It would be beneficial to understand the criteria used to select this value.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9932082891464233,
                    "sentence": "Does increasing k adversely affect the model's performance?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9948843121528625,
                    "sentence": "Furthermore, it would be interesting to visualize the learned distribution for a word with a single dominant meaning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9925097227096558,
                    "sentence": "The spherical case is used in all experiments, where the covariance matrix simplifies to a single value.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9963167905807495,
                    "sentence": "Is this choice primarily driven by computational efficiency?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9967852234840393,
                    "sentence": "The performance of using a general diagonal covariance matrix, which allows the Gaussian mixture to define varying degrees of uncertainty along different directions in the semantic space, seems worthy of exploration.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9935177564620972,
                    "sentence": "Minor comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9938847422599792,
                    "sentence": "Table 4 is not referenced in the main text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9918932914733887,
                    "sentence": "Additionally, the reference to Luong et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9949145317077637,
                    "sentence": "is missing the publication year.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9945127964019775,
                    "sentence": "The response to the initial review has been considered.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997847017652333,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997847017652333,
                "mixed": 0.00021529823476680056
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997847017652333,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997847017652333,
                    "human": 0,
                    "mixed": 0.00021529823476680056
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This study leverages Gaussian mixtures to model words, showcasing their capability in capturing multiple meanings of polysemous words. The training process employs a max-margin objective, utilizing the expected likelihood kernel to measure the similarity between word distributions. Experimental results on word similarity and entailment tasks demonstrate the efficacy of the proposed approach.\n- Strengths:\nThe problem statement is well-defined and clearly motivated. The use of Gaussian mixtures offers a more expressive representation compared to deterministic vector models, potentially capturing distinct word meanings through their modes, along with the associated probability mass and uncertainty. This work constitutes a significant contribution to the field of word embeddings. \nThe proposed max-margin learning objective, accompanied by a closed-form similarity measurement, enables efficient training. The paper is generally well-written, contributing to its overall clarity.\n- Weaknesses:\nPlease refer to the questions posed below for further discussion.\n- General Discussion:\nA crucial parameter in Gaussian mixture models is the number of components (k). In the experiments presented, k is fixed at 2. It would be beneficial to understand the criteria used to select this value. Does increasing k adversely affect the model's performance? Furthermore, it would be interesting to visualize the learned distribution for a word with a single dominant meaning.\nThe spherical case is used in all experiments, where the covariance matrix simplifies to a single value. Is this choice primarily driven by computational efficiency? The performance of using a general diagonal covariance matrix, which allows the Gaussian mixture to define varying degrees of uncertainty along different directions in the semantic space, seems worthy of exploration.\nMinor comments:\nTable 4 is not referenced in the main text. Additionally, the reference to Luong et al. is missing the publication year.\nThe response to the initial review has been considered."
        }
    ]
}