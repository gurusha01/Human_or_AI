{
    "version": "2025-01-09-base",
    "scanId": "5b6c2bbd-1bb9-4506-bc63-16457ea95a62",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9998200535774231,
                    "sentence": "This paper presents a novel approach to training models for Chinese word segmentation (CWS) using datasets with multiple segmentation criteria.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999308586120605,
                    "sentence": "- Key advantages:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999643087387085,
                    "sentence": "1. The concept of multi-criteria learning is both intriguing and shows promise.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994872808456421,
                    "sentence": "2. The proposed model is also noteworthy, yielding significant improvements over baseline models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999080896377563,
                    "sentence": "- Limitations:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995336532592773,
                    "sentence": "1. The proposed method lacks comparison with existing CWS models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996442794799805,
                    "sentence": "The baseline model, Bi-LSTM, originates from [1] and [2], which were actually designed for POS tagging and NE tagging, not CWS.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994380474090576,
                    "sentence": "The claim in Section 2 that \"we employ the state-of-the-art architecture\" is misleading.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998810887336731,
                    "sentence": "2. The objective of the experiments in Section 6.4 is unclear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999254941940308,
                    "sentence": "While the section aims to explore how datasets in traditional Chinese and simplified Chinese can complement each other, the experimental setup involves separate training on simplified Chinese and traditional Chinese, with shared parameters fixed after training on simplified Chinese.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999107718467712,
                    "sentence": "It is unclear what is expected to be achieved by fixing these shared parameters.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999619126319885,
                    "sentence": "- Overall assessment:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999004602432251,
                    "sentence": "The paper would be more compelling with a more in-depth discussion on the datasets where adversarial multi-criteria learning fails to enhance performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998774528503418,
                    "sentence": "References:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995224475860596,
                    "sentence": "[1] Zhiheng Huang, Wei Xu, and Kai Yu.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994296431541443,
                    "sentence": "2015. Bidirectional lstm-crf models for sequence tagging.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996753334999084,
                    "sentence": "arXiv preprint arXiv:1508.01991.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991724491119385,
                    "sentence": "[2] Xuezhe Ma and Eduard Hovy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974663257598877,
                    "sentence": "2016. End-to-end sequence labeling via bi-directional lstm-cnns-crf.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990040063858032,
                    "sentence": "arXiv preprint arXiv:1603.01354.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a novel approach to training models for Chinese word segmentation (CWS) using datasets with multiple segmentation criteria.\n- Key advantages:\n1. The concept of multi-criteria learning is both intriguing and shows promise.\n2. The proposed model is also noteworthy, yielding significant improvements over baseline models.\n- Limitations:\n1. The proposed method lacks comparison with existing CWS models. The baseline model, Bi-LSTM, originates from [1] and [2], which were actually designed for POS tagging and NE tagging, not CWS. The claim in Section 2 that \"we employ the state-of-the-art architecture\" is misleading.\n2. The objective of the experiments in Section 6.4 is unclear. While the section aims to explore how datasets in traditional Chinese and simplified Chinese can complement each other, the experimental setup involves separate training on simplified Chinese and traditional Chinese, with shared parameters fixed after training on simplified Chinese. It is unclear what is expected to be achieved by fixing these shared parameters.\n- Overall assessment:\nThe paper would be more compelling with a more in-depth discussion on the datasets where adversarial multi-criteria learning fails to enhance performance.\nReferences:\n[1] Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional lstm-crf models for sequence tagging. arXiv preprint arXiv:1508.01991.\n[2] Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via bi-directional lstm-cnns-crf. arXiv preprint arXiv:1603.01354."
        }
    ]
}