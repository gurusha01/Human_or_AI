{
    "version": "2025-01-09-base",
    "scanId": "22f4f987-cbce-46d8-abc8-dd29aad99b76",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999648332595825,
                    "sentence": "This paper presents a methodology for distinguishing between literal and metaphoric adjective-noun pairs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999945342540741,
                    "sentence": "The approach involves constructing a word-context matrix for adjectives and nouns, where each matrix element represents the Pointwise Mutual Information (PMI) score.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999375343322754,
                    "sentence": "The authors then apply various dimensionality reduction techniques to this matrix, resulting in vector representations for each noun and adjective.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999293684959412,
                    "sentence": "These vector representations, along with their geometric properties and normalized versions, serve as features for training a regression model to classify the pairs as either literal or metaphorical expressions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998916983604431,
                    "sentence": "The performance of this approach is comparable to previous studies that have learned vector representations for adjectives.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997165203094482,
                    "sentence": "Regarding supervision and zero-shot learning, the authors claim that their methodology requires less supervision and is capable of zero-shot learning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998422265052795,
                    "sentence": "However, this assertion seems misleading, as the proposed approach is essentially a supervised classification task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998118281364441,
                    "sentence": "The model is trained on vector representations derived from co-occurrence statistics and gold-standard labels, and while it can be tested on unseen words, it does not learn from them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999764084815979,
                    "sentence": "Furthermore, these unseen words are not entirely novel, as the model still requires a pre-existing vector representation for them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998795986175537,
                    "sentence": "The interpretation of the results is also noteworthy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999860405921936,
                    "sentence": "Although the authors provide a comprehensive overview of prior work on metaphors, the intuition behind their approach, particularly the use of geometric properties such as vector length to identify metaphors, is not entirely clear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997881650924683,
                    "sentence": "For instance, the inclusion of normalized vectors does not appear to enhance performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998757839202881,
                    "sentence": "Moreover, the most predictive feature is found to be the noun vector, which the authors attribute to the data collection process.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998794794082642,
                    "sentence": "This raises concerns about the approach's suitability and generalizability, both from a theoretical perspective, where its implications for metaphor processing theories are unclear, and from a practical standpoint, where its comparability to compositional models is uncertain.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999816358089447,
                    "sentence": "Finally, the novelty of the proposed approach is questionable, as the method for representing noun and adjective vectors bears a strong resemblance to that of Agres et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998417496681213,
                    "sentence": "The primary contribution of the paper appears to be the application of geometric properties for vector classification, which may not be sufficiently innovative to distinguish it from existing work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a methodology for distinguishing between literal and metaphoric adjective-noun pairs. The approach involves constructing a word-context matrix for adjectives and nouns, where each matrix element represents the Pointwise Mutual Information (PMI) score. The authors then apply various dimensionality reduction techniques to this matrix, resulting in vector representations for each noun and adjective. These vector representations, along with their geometric properties and normalized versions, serve as features for training a regression model to classify the pairs as either literal or metaphorical expressions. The performance of this approach is comparable to previous studies that have learned vector representations for adjectives.\nRegarding supervision and zero-shot learning, the authors claim that their methodology requires less supervision and is capable of zero-shot learning. However, this assertion seems misleading, as the proposed approach is essentially a supervised classification task. The model is trained on vector representations derived from co-occurrence statistics and gold-standard labels, and while it can be tested on unseen words, it does not learn from them. Furthermore, these unseen words are not entirely novel, as the model still requires a pre-existing vector representation for them.\nThe interpretation of the results is also noteworthy. Although the authors provide a comprehensive overview of prior work on metaphors, the intuition behind their approach, particularly the use of geometric properties such as vector length to identify metaphors, is not entirely clear. For instance, the inclusion of normalized vectors does not appear to enhance performance. Moreover, the most predictive feature is found to be the noun vector, which the authors attribute to the data collection process. This raises concerns about the approach's suitability and generalizability, both from a theoretical perspective, where its implications for metaphor processing theories are unclear, and from a practical standpoint, where its comparability to compositional models is uncertain.\nFinally, the novelty of the proposed approach is questionable, as the method for representing noun and adjective vectors bears a strong resemblance to that of Agres et al. The primary contribution of the paper appears to be the application of geometric properties for vector classification, which may not be sufficiently innovative to distinguish it from existing work."
        }
    ]
}