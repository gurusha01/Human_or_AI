{
    "version": "2025-01-09-base",
    "scanId": "051cb65e-e862-4344-bf1f-fabd7795c1eb",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999987483024597,
                    "sentence": "This paper proposes a novel method for jointly learning concept, phrase, and word embeddings from an unlabeled text corpus, using representative phrases for ontology concepts as distant supervision.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "The main contributions of this work are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "1. Joint embedding of concepts, phrases, and words: The authors propose a method to jointly embed concepts, phrases, and words into a shared vector space, which allows for the capture of semantic relationships between them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980330467224,
                    "sentence": "2. Distant supervision using ontology concepts: The authors use representative phrases for ontology concepts as distant supervision to train the embeddings, which eliminates the need for manual annotation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999985694885254,
                    "sentence": "3. Competitive performance on similarity and relatedness tasks: The authors demonstrate that their embeddings achieve competitive performance on similarity and relatedness tasks, compared to existing methods that require manual annotation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982118606567,
                    "sentence": "The strengths of this paper are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "1. Novel approach to concept embedding: The authors propose a new approach to concept embedding that leverages distant supervision and joint embedding of concepts, phrases, and words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986290931702,
                    "sentence": "2. Large-scale evaluation: The authors evaluate their method on a large-scale dataset, demonstrating its effectiveness on a wide range of concepts and phrases.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "3. Competitive performance: The authors demonstrate that their method achieves competitive performance on similarity and relatedness tasks, compared to existing methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979138374329,
                    "sentence": "The weaknesses of this paper are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986290931702,
                    "sentence": "1. Lack of explicit modeling of concept relationships: The authors do not explicitly model the relationships between concepts, which may limit the ability of their method to capture complex semantic relationships.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983310699463,
                    "sentence": "2. Dependence on ontology quality: The authors rely on the quality of the ontology to provide accurate representative phrases for concepts, which may be a limitation if the ontology is incomplete or inaccurate.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979734420776,
                    "sentence": "3. Need for hyperparameter tuning: The authors require hyperparameter tuning to achieve optimal performance, which may be time-consuming and require significant computational resources.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999937415122986,
                    "sentence": "Questions to authors:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973773956299,
                    "sentence": "1. How do the authors plan to address the issue of concept relationships, which are not explicitly modeled in their current approach?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999972581863403,
                    "sentence": "2. How do the authors plan to evaluate the quality of the ontology and its impact on the performance of their method?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961256980896,
                    "sentence": "3. Can the authors provide more details on the hyperparameter tuning process and the computational resources required to achieve optimal performance?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes a novel method for jointly learning concept, phrase, and word embeddings from an unlabeled text corpus, using representative phrases for ontology concepts as distant supervision. The main contributions of this work are:\n1. Joint embedding of concepts, phrases, and words: The authors propose a method to jointly embed concepts, phrases, and words into a shared vector space, which allows for the capture of semantic relationships between them.\n2. Distant supervision using ontology concepts: The authors use representative phrases for ontology concepts as distant supervision to train the embeddings, which eliminates the need for manual annotation.\n3. Competitive performance on similarity and relatedness tasks: The authors demonstrate that their embeddings achieve competitive performance on similarity and relatedness tasks, compared to existing methods that require manual annotation.\nThe strengths of this paper are:\n1. Novel approach to concept embedding: The authors propose a new approach to concept embedding that leverages distant supervision and joint embedding of concepts, phrases, and words.\n2. Large-scale evaluation: The authors evaluate their method on a large-scale dataset, demonstrating its effectiveness on a wide range of concepts and phrases.\n3. Competitive performance: The authors demonstrate that their method achieves competitive performance on similarity and relatedness tasks, compared to existing methods.\nThe weaknesses of this paper are:\n1. Lack of explicit modeling of concept relationships: The authors do not explicitly model the relationships between concepts, which may limit the ability of their method to capture complex semantic relationships.\n2. Dependence on ontology quality: The authors rely on the quality of the ontology to provide accurate representative phrases for concepts, which may be a limitation if the ontology is incomplete or inaccurate.\n3. Need for hyperparameter tuning: The authors require hyperparameter tuning to achieve optimal performance, which may be time-consuming and require significant computational resources.\nQuestions to authors:\n1. How do the authors plan to address the issue of concept relationships, which are not explicitly modeled in their current approach?\n2. How do the authors plan to evaluate the quality of the ontology and its impact on the performance of their method?\n3. Can the authors provide more details on the hyperparameter tuning process and the computational resources required to achieve optimal performance?"
        }
    ]
}