{
    "version": "2025-01-09-base",
    "scanId": "a3b536d7-04c6-4fe5-932c-0dcb9ea3ed28",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.999996542930603,
                    "sentence": "This paper proposes a novel task called rare entity prediction, which involves predicting missing entities in web articles by leveraging external knowledge in the form of lexical resources.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999943971633911,
                    "sentence": "The authors introduce a new dataset, Wikilinks Rare Entity Prediction, and propose two models, Double Encoder (DOUBENC) and Hierarchical Double Encoder (HIERENC), to solve this task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999957084655762,
                    "sentence": "The main contributions of this work are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999995231628418,
                    "sentence": "1. Introduction of the rare entity prediction task: The authors propose a new task that requires models to predict missing entities in web articles, which is a challenging problem due to the diversity of language styles and the large number of rare entities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994695186615,
                    "sentence": "2. Development of the Wikilinks Rare Entity Prediction dataset: The authors create a significantly enhanced version of the Wikilinks dataset, which provides a large-scale benchmark for evaluating models on the rare entity prediction task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999946355819702,
                    "sentence": "3. Proposal of the Double Encoder and Hierarchical Double Encoder models: The authors introduce two models that leverage external knowledge in the form of lexical resources to solve the rare entity prediction task, achieving significant performance improvements over baseline models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967813491821,
                    "sentence": "The strengths of this paper are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999995768070221,
                    "sentence": "1. Novel task proposal: The authors propose a new task that addresses a significant challenge in natural language processing, which is the ability to predict rare entities in web articles.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999791383743286,
                    "sentence": "2. Large-scale dataset creation: The authors create a large-scale dataset that provides a benchmark for evaluating models on the rare entity prediction task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999289512634277,
                    "sentence": "3. Effective model proposals: The authors propose two models that achieve significant performance improvements over baseline models, demonstrating the effectiveness of leveraging external knowledge in solving the rare entity prediction task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998326897621155,
                    "sentence": "The weaknesses of this paper are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999363422393799,
                    "sentence": "1. Limited evaluation metrics: The authors only evaluate their models using accuracy, which may not be sufficient to fully capture the performance of the models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999670386314392,
                    "sentence": "2. Lack of comparison to state-of-the-art models: The authors do not compare their models to state-of-the-art models on related tasks, which makes it difficult to assess the relative performance of their models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999101758003235,
                    "sentence": "3. Limited analysis of the results: The authors do not provide a detailed analysis of the results, which makes it difficult to understand the strengths and weaknesses of their models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9957879781723022,
                    "sentence": "Questions to authors:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986287355422974,
                    "sentence": "1. How do the authors plan to extend their work to incorporate other types of external knowledge, such as relational information between entities?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994182586669922,
                    "sentence": "2. How do the authors plan to evaluate their models using more comprehensive evaluation metrics, such as precision, recall, and F1-score?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994890093803406,
                    "sentence": "3. How do the authors plan to compare their models to state-of-the-art models on related tasks, such as entity recognition and disambiguation?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997847017652333,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997847017652333,
                "mixed": 0.00021529823476680056
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997847017652333,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997847017652333,
                    "human": 0,
                    "mixed": 0.00021529823476680056
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes a novel task called rare entity prediction, which involves predicting missing entities in web articles by leveraging external knowledge in the form of lexical resources. The authors introduce a new dataset, Wikilinks Rare Entity Prediction, and propose two models, Double Encoder (DOUBENC) and Hierarchical Double Encoder (HIERENC), to solve this task. The main contributions of this work are:\n1. Introduction of the rare entity prediction task: The authors propose a new task that requires models to predict missing entities in web articles, which is a challenging problem due to the diversity of language styles and the large number of rare entities.\n2. Development of the Wikilinks Rare Entity Prediction dataset: The authors create a significantly enhanced version of the Wikilinks dataset, which provides a large-scale benchmark for evaluating models on the rare entity prediction task.\n3. Proposal of the Double Encoder and Hierarchical Double Encoder models: The authors introduce two models that leverage external knowledge in the form of lexical resources to solve the rare entity prediction task, achieving significant performance improvements over baseline models.\nThe strengths of this paper are:\n1. Novel task proposal: The authors propose a new task that addresses a significant challenge in natural language processing, which is the ability to predict rare entities in web articles.\n2. Large-scale dataset creation: The authors create a large-scale dataset that provides a benchmark for evaluating models on the rare entity prediction task.\n3. Effective model proposals: The authors propose two models that achieve significant performance improvements over baseline models, demonstrating the effectiveness of leveraging external knowledge in solving the rare entity prediction task.\nThe weaknesses of this paper are:\n1. Limited evaluation metrics: The authors only evaluate their models using accuracy, which may not be sufficient to fully capture the performance of the models.\n2. Lack of comparison to state-of-the-art models: The authors do not compare their models to state-of-the-art models on related tasks, which makes it difficult to assess the relative performance of their models.\n3. Limited analysis of the results: The authors do not provide a detailed analysis of the results, which makes it difficult to understand the strengths and weaknesses of their models.\nQuestions to authors:\n1. How do the authors plan to extend their work to incorporate other types of external knowledge, such as relational information between entities?\n2. How do the authors plan to evaluate their models using more comprehensive evaluation metrics, such as precision, recall, and F1-score?\n3. How do the authors plan to compare their models to state-of-the-art models on related tasks, such as entity recognition and disambiguation?"
        }
    ]
}