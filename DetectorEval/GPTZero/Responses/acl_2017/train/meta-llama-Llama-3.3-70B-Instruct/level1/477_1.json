{
    "version": "2025-01-09-base",
    "scanId": "4e3dc1bd-ca26-4580-8a22-75bcf0649fb1",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999920129776001,
                    "sentence": "This paper presents a comprehensive comparison of word representation models with varying levels of morphological awareness across languages with different morphological typologies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999954104423523,
                    "sentence": "The main contributions of this work are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999868869781494,
                    "sentence": "1. Systematic comparison of subword units and composition functions: The authors compare ten different models, varying subword units (characters, character trigrams, morphs) and composition functions (addition, bi-LSTMs, CNNs) to determine the most effective combination for language modeling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999989926815033,
                    "sentence": "2. Evaluation across multiple languages and morphological typologies: The authors perform experiments on ten languages, covering four broad categories of morphological typologies (fusional, agglutinative, root and pattern, and reduplication), to assess the effectiveness of different models across languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999915361404419,
                    "sentence": "3. Analysis of the interaction between morphology and orthography: The authors investigate how character-level models capture morphological regularities and how they interact with languages of different morphological typologies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999951720237732,
                    "sentence": "The strengths of this paper are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999995231628418,
                    "sentence": "1. Comprehensive experimentation: The authors perform a thorough comparison of different models, subword units, and composition functions, providing a detailed analysis of the results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999966621398926,
                    "sentence": "2. Use of multiple languages and datasets: The authors use a diverse set of languages and datasets, allowing for a more comprehensive understanding of the effectiveness of different models across languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998713135719299,
                    "sentence": "3. Qualitative analysis: The authors provide a qualitative analysis of the results, including an examination of the nearest neighbors of reduplicated words, to gain insights into how the models capture morphological regularities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999068379402161,
                    "sentence": "The weaknesses of this paper are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999922513961792,
                    "sentence": "1. Limited analysis of the results: While the authors provide a detailed analysis of the results, they could have delved deeper into the implications of the findings and the potential reasons behind the performance differences between models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999946117401123,
                    "sentence": "2. Lack of discussion on the limitations of the models: The authors could have discussed the limitations of the models and the potential biases in the datasets, which could have affected the results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998899698257446,
                    "sentence": "3. No clear conclusion on the best model: The authors do not provide a clear conclusion on the best model or combination of subword units and composition functions, which could have been helpful for practitioners.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9982476830482483,
                    "sentence": "Questions to authors:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995844960212708,
                    "sentence": "1. How do the authors plan to address the limitations of the models and the potential biases in the datasets in future work?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989559054374695,
                    "sentence": "2. Can the authors provide more insights into the qualitative analysis of the results, particularly with regards to the nearest neighbors of reduplicated words?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992887377738953,
                    "sentence": "3. How do the authors think the results would change if they used a different evaluation metric, such as accuracy or F1-score, instead of perplexity?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997847017652333,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997847017652333,
                "mixed": 0.00021529823476680056
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997847017652333,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997847017652333,
                    "human": 0,
                    "mixed": 0.00021529823476680056
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a comprehensive comparison of word representation models with varying levels of morphological awareness across languages with different morphological typologies. The main contributions of this work are:\n1. Systematic comparison of subword units and composition functions: The authors compare ten different models, varying subword units (characters, character trigrams, morphs) and composition functions (addition, bi-LSTMs, CNNs) to determine the most effective combination for language modeling.\n2. Evaluation across multiple languages and morphological typologies: The authors perform experiments on ten languages, covering four broad categories of morphological typologies (fusional, agglutinative, root and pattern, and reduplication), to assess the effectiveness of different models across languages.\n3. Analysis of the interaction between morphology and orthography: The authors investigate how character-level models capture morphological regularities and how they interact with languages of different morphological typologies.\nThe strengths of this paper are:\n1. Comprehensive experimentation: The authors perform a thorough comparison of different models, subword units, and composition functions, providing a detailed analysis of the results.\n2. Use of multiple languages and datasets: The authors use a diverse set of languages and datasets, allowing for a more comprehensive understanding of the effectiveness of different models across languages.\n3. Qualitative analysis: The authors provide a qualitative analysis of the results, including an examination of the nearest neighbors of reduplicated words, to gain insights into how the models capture morphological regularities.\nThe weaknesses of this paper are:\n1. Limited analysis of the results: While the authors provide a detailed analysis of the results, they could have delved deeper into the implications of the findings and the potential reasons behind the performance differences between models.\n2. Lack of discussion on the limitations of the models: The authors could have discussed the limitations of the models and the potential biases in the datasets, which could have affected the results.\n3. No clear conclusion on the best model: The authors do not provide a clear conclusion on the best model or combination of subword units and composition functions, which could have been helpful for practitioners.\nQuestions to authors:\n1. How do the authors plan to address the limitations of the models and the potential biases in the datasets in future work?\n2. Can the authors provide more insights into the qualitative analysis of the results, particularly with regards to the nearest neighbors of reduplicated words?\n3. How do the authors think the results would change if they used a different evaluation metric, such as accuracy or F1-score, instead of perplexity?"
        }
    ]
}