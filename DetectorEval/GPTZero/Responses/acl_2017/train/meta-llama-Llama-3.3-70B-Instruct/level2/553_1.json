{
    "version": "2025-01-09-base",
    "scanId": "cbf5e67b-c7c9-4fe9-9f10-b2fccc14e8c0",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999340176582336,
                    "sentence": "Summary of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999178647994995,
                    "sentence": "The paper proposes a general framework for performing cross-context lexical analysis, which enables the comparison of term meanings and representations across different contexts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999364614486694,
                    "sentence": "The framework, called Cross-Context Lexical Analysis (CCLA), is flexible and can accommodate various notions of context, similarity functions, and word annotations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998314380645752,
                    "sentence": "The authors demonstrate the applicability of CCLA to three distinct tasks: semantic change detection, comparative lexical analysis over context, and word embedding stability evaluation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999382495880127,
                    "sentence": "Main Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999944567680359,
                    "sentence": "1. CCLA Framework: The paper introduces a novel framework for cross-context lexical analysis, which provides a unified approach to comparing term meanings and representations across different contexts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967813491821,
                    "sentence": "2. Semantic Change Detection: The authors apply CCLA to detect semantic changes in word meanings over time, demonstrating its effectiveness in identifying words with shifting meanings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999959468841553,
                    "sentence": "3. Comparative Lexical Analysis: CCLA is used to compare term meanings across different contexts, such as sentiment analysis datasets, to identify context-sensitive and context-insensitive terms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973177909851,
                    "sentence": "4. Word Embedding Stability Evaluation: The framework is applied to evaluate the stability of word embeddings across different runs of the same algorithm, providing insights into the consistency of word vector representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999951124191284,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999951720237732,
                    "sentence": "1. Flexibility: CCLA's flexibility in accommodating various notions of context, similarity functions, and word annotations makes it a versatile framework for cross-context lexical analysis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999948740005493,
                    "sentence": "2. Effectiveness: The authors demonstrate the effectiveness of CCLA in detecting semantic changes, comparing term meanings, and evaluating word embedding stability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999964237213135,
                    "sentence": "3. Interpretability: The framework provides interpretable results, allowing for insights into the similarities and differences in term meanings across contexts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999950528144836,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963045120239,
                    "sentence": "1. Computational Complexity: The paper does not provide a detailed analysis of the computational complexity of CCLA, which may be a concern for large-scale applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999921917915344,
                    "sentence": "2. Context Definition: The framework relies on a clear definition of context, which may be challenging to determine in certain applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999995231628418,
                    "sentence": "3. Evaluation Metrics: The authors use various evaluation metrics, but a more comprehensive evaluation of the framework's performance across different tasks and datasets is necessary.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999266266822815,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999821782112122,
                    "sentence": "1. How do the authors plan to address the computational complexity of CCLA for large-scale applications?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999580979347229,
                    "sentence": "2. Can the authors provide more guidance on defining context in different applications, particularly in cases where the context is ambiguous or nuanced?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999778270721436,
                    "sentence": "3. How do the authors intend to evaluate the performance of CCLA across different tasks and datasets to ensure its generalizability and robustness?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997847017652333,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997847017652333,
                "mixed": 0.00021529823476680056
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997847017652333,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997847017652333,
                    "human": 0,
                    "mixed": 0.00021529823476680056
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary of the Paper\nThe paper proposes a general framework for performing cross-context lexical analysis, which enables the comparison of term meanings and representations across different contexts. The framework, called Cross-Context Lexical Analysis (CCLA), is flexible and can accommodate various notions of context, similarity functions, and word annotations. The authors demonstrate the applicability of CCLA to three distinct tasks: semantic change detection, comparative lexical analysis over context, and word embedding stability evaluation.\nMain Contributions\n1. CCLA Framework: The paper introduces a novel framework for cross-context lexical analysis, which provides a unified approach to comparing term meanings and representations across different contexts.\n2. Semantic Change Detection: The authors apply CCLA to detect semantic changes in word meanings over time, demonstrating its effectiveness in identifying words with shifting meanings.\n3. Comparative Lexical Analysis: CCLA is used to compare term meanings across different contexts, such as sentiment analysis datasets, to identify context-sensitive and context-insensitive terms.\n4. Word Embedding Stability Evaluation: The framework is applied to evaluate the stability of word embeddings across different runs of the same algorithm, providing insights into the consistency of word vector representations.\nStrengths\n1. Flexibility: CCLA's flexibility in accommodating various notions of context, similarity functions, and word annotations makes it a versatile framework for cross-context lexical analysis.\n2. Effectiveness: The authors demonstrate the effectiveness of CCLA in detecting semantic changes, comparing term meanings, and evaluating word embedding stability.\n3. Interpretability: The framework provides interpretable results, allowing for insights into the similarities and differences in term meanings across contexts.\nWeaknesses\n1. Computational Complexity: The paper does not provide a detailed analysis of the computational complexity of CCLA, which may be a concern for large-scale applications.\n2. Context Definition: The framework relies on a clear definition of context, which may be challenging to determine in certain applications.\n3. Evaluation Metrics: The authors use various evaluation metrics, but a more comprehensive evaluation of the framework's performance across different tasks and datasets is necessary.\nQuestions to Authors\n1. How do the authors plan to address the computational complexity of CCLA for large-scale applications?\n2. Can the authors provide more guidance on defining context in different applications, particularly in cases where the context is ambiguous or nuanced?\n3. How do the authors intend to evaluate the performance of CCLA across different tasks and datasets to ensure its generalizability and robustness?"
        }
    ]
}