{
    "version": "2025-01-09-base",
    "scanId": "5556e7ce-2844-4684-bd3e-004226170dc3",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9901484251022339,
                    "sentence": "Summary of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9834086894989014,
                    "sentence": "The paper proposes a self-learning framework to learn bilingual word embedding mappings using a small seed dictionary.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.981443464756012,
                    "sentence": "The method iteratively updates the dictionary and the embedding mapping until convergence, exploiting the structural similarity of independently trained embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9714822173118591,
                    "sentence": "The authors evaluate their approach on bilingual lexicon induction and cross-lingual word similarity tasks, achieving competitive results with state-of-the-art systems that use richer bilingual resources.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9800676107406616,
                    "sentence": "Main Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.993596613407135,
                    "sentence": "1. Self-learning framework: The paper introduces a simple yet effective self-learning framework that can be combined with any dictionary-based mapping technique.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9948168992996216,
                    "sentence": "2. Small seed dictionary: The method can work with as little as 25 word pairs or an automatically generated list of numerals, making it possible to learn bilingual word embeddings without significant bilingual data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99144446849823,
                    "sentence": "3. Competitive results: The authors demonstrate that their approach achieves competitive results with state-of-the-art systems on bilingual lexicon induction and cross-lingual word similarity tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9666635990142822,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9911297559738159,
                    "sentence": "1. Efficient use of limited resources: The self-learning framework makes efficient use of limited bilingual resources, achieving good results with small seed dictionaries.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999973475933075,
                    "sentence": "2. Simple and effective: The proposed method is simple to implement and effective in practice, making it a promising approach for bilingual word embedding learning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999707341194153,
                    "sentence": "3. Robustness to language pairs: The authors demonstrate that their method is robust to different language pairs, including distant languages like English-Finnish.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999719262123108,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999608993530273,
                    "sentence": "1. Limited analysis of optimization objective: While the authors provide some analysis of the optimization objective, a more detailed investigation of the objective function and its properties could be beneficial.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999507069587708,
                    "sentence": "2. Dependence on initial solution: The self-learning framework relies on a good initial solution to avoid getting stuck in poor local optima, which may limit its applicability in certain scenarios.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999259114265442,
                    "sentence": "3. Limited exploration of non-linear transformations: The authors mention the potential of exploring non-linear transformations but do not investigate this direction in the current work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998894929885864,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999849200248718,
                    "sentence": "1. Can you provide more insight into the optimization objective and its properties, and how it relates to the self-learning framework?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999686479568481,
                    "sentence": "2. How do you plan to address the dependence on the initial solution, and what strategies could be employed to improve the robustness of the method?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999858736991882,
                    "sentence": "3. What are the potential applications of the proposed method in other NLP tasks, such as machine translation or cross-lingual information retrieval?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997847017652333,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997847017652333,
                "mixed": 0.00021529823476680056
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997847017652333,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997847017652333,
                    "human": 0,
                    "mixed": 0.00021529823476680056
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary of the Paper\nThe paper proposes a self-learning framework to learn bilingual word embedding mappings using a small seed dictionary. The method iteratively updates the dictionary and the embedding mapping until convergence, exploiting the structural similarity of independently trained embeddings. The authors evaluate their approach on bilingual lexicon induction and cross-lingual word similarity tasks, achieving competitive results with state-of-the-art systems that use richer bilingual resources.\nMain Contributions\n1. Self-learning framework: The paper introduces a simple yet effective self-learning framework that can be combined with any dictionary-based mapping technique.\n2. Small seed dictionary: The method can work with as little as 25 word pairs or an automatically generated list of numerals, making it possible to learn bilingual word embeddings without significant bilingual data.\n3. Competitive results: The authors demonstrate that their approach achieves competitive results with state-of-the-art systems on bilingual lexicon induction and cross-lingual word similarity tasks.\nStrengths\n1. Efficient use of limited resources: The self-learning framework makes efficient use of limited bilingual resources, achieving good results with small seed dictionaries.\n2. Simple and effective: The proposed method is simple to implement and effective in practice, making it a promising approach for bilingual word embedding learning.\n3. Robustness to language pairs: The authors demonstrate that their method is robust to different language pairs, including distant languages like English-Finnish.\nWeaknesses\n1. Limited analysis of optimization objective: While the authors provide some analysis of the optimization objective, a more detailed investigation of the objective function and its properties could be beneficial.\n2. Dependence on initial solution: The self-learning framework relies on a good initial solution to avoid getting stuck in poor local optima, which may limit its applicability in certain scenarios.\n3. Limited exploration of non-linear transformations: The authors mention the potential of exploring non-linear transformations but do not investigate this direction in the current work.\nQuestions to Authors\n1. Can you provide more insight into the optimization objective and its properties, and how it relates to the self-learning framework?\n2. How do you plan to address the dependence on the initial solution, and what strategies could be employed to improve the robustness of the method?\n3. What are the potential applications of the proposed method in other NLP tasks, such as machine translation or cross-lingual information retrieval?"
        }
    ]
}