{
    "version": "2025-01-09-base",
    "scanId": "90ff77e9-1781-4d1d-920d-9486a58cb953",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9985414147377014,
                    "sentence": "Summary of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9961811304092407,
                    "sentence": "The paper presents a novel approach to interpreting Long-Short Term Memory (LSTM) neural networks by treating them as input-output devices and crafting stimuli that systematically vary along a dimension of interest.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985840320587158,
                    "sentence": "The authors apply this approach to a dataset of essays from a values affirmation intervention, exploring whether the model has learned about gender differences in writing styles.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989798665046692,
                    "sentence": "The results suggest that the LSTM model has learned to recognize differences in writing styles between male and female students, with female students more likely to use other-focused justifications and male students more likely to use self-focused justifications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995962381362915,
                    "sentence": "Main Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997814297676086,
                    "sentence": "1. Novel approach to interpreting LSTMs: The paper introduces a new method for understanding LSTM predictions by treating the model as an input-output device and crafting stimuli that vary along a dimension of interest.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998044967651367,
                    "sentence": "2. Application to values affirmation dataset: The authors apply this approach to a dataset of essays from a values affirmation intervention, exploring gender differences in writing styles.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999281167984009,
                    "sentence": "3. Insights into gender differences in writing styles: The results provide evidence for gender differences in writing styles, with female students more likely to use other-focused justifications and male students more likely to use self-focused justifications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997352361679077,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999117851257324,
                    "sentence": "1. Innovative approach to interpreting LSTMs: The paper presents a novel and creative approach to understanding LSTM predictions, which has the potential to be applied to a wide range of domains.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999694228172302,
                    "sentence": "2. Well-motivated application to values affirmation dataset: The authors provide a clear motivation for applying this approach to the values affirmation dataset, and the results provide insights into gender differences in writing styles.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999619126319885,
                    "sentence": "3. Strong empirical evaluation: The paper includes a thorough empirical evaluation of the approach, including a comparison to a baseline model and an analysis of the results using Bayesian modeling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999853372573853,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999803900718689,
                    "sentence": "1. Limited scope: The paper focuses on a specific application of the approach to a values affirmation dataset, and it is unclear how widely applicable the approach is to other domains.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999895691871643,
                    "sentence": "2. Lack of theoretical analysis: The paper does not provide a detailed theoretical analysis of the approach, which may limit its applicability to other domains.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999880790710449,
                    "sentence": "3. Dependence on high-quality data: The approach relies on high-quality data, and the results may not generalize to datasets with lower quality or different characteristics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998676776885986,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999719262123108,
                    "sentence": "1. How do you plan to extend this approach to other domains, and what are the potential challenges and limitations?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999602437019348,
                    "sentence": "2. Can you provide more details on the theoretical analysis of the approach, and how it relates to existing work on interpreting neural networks?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999704957008362,
                    "sentence": "3. How do you plan to address the potential dependence on high-quality data, and what are the implications for applying this approach to datasets with lower quality or different characteristics?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9984800378301695,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984800378301695,
                "mixed": 0.0015199621698304396
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984800378301695,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984800378301695,
                    "human": 0,
                    "mixed": 0.0015199621698304396
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary of the Paper\nThe paper presents a novel approach to interpreting Long-Short Term Memory (LSTM) neural networks by treating them as input-output devices and crafting stimuli that systematically vary along a dimension of interest. The authors apply this approach to a dataset of essays from a values affirmation intervention, exploring whether the model has learned about gender differences in writing styles. The results suggest that the LSTM model has learned to recognize differences in writing styles between male and female students, with female students more likely to use other-focused justifications and male students more likely to use self-focused justifications.\nMain Contributions\n1. Novel approach to interpreting LSTMs: The paper introduces a new method for understanding LSTM predictions by treating the model as an input-output device and crafting stimuli that vary along a dimension of interest.\n2. Application to values affirmation dataset: The authors apply this approach to a dataset of essays from a values affirmation intervention, exploring gender differences in writing styles.\n3. Insights into gender differences in writing styles: The results provide evidence for gender differences in writing styles, with female students more likely to use other-focused justifications and male students more likely to use self-focused justifications.\nStrengths\n1. Innovative approach to interpreting LSTMs: The paper presents a novel and creative approach to understanding LSTM predictions, which has the potential to be applied to a wide range of domains.\n2. Well-motivated application to values affirmation dataset: The authors provide a clear motivation for applying this approach to the values affirmation dataset, and the results provide insights into gender differences in writing styles.\n3. Strong empirical evaluation: The paper includes a thorough empirical evaluation of the approach, including a comparison to a baseline model and an analysis of the results using Bayesian modeling.\nWeaknesses\n1. Limited scope: The paper focuses on a specific application of the approach to a values affirmation dataset, and it is unclear how widely applicable the approach is to other domains.\n2. Lack of theoretical analysis: The paper does not provide a detailed theoretical analysis of the approach, which may limit its applicability to other domains.\n3. Dependence on high-quality data: The approach relies on high-quality data, and the results may not generalize to datasets with lower quality or different characteristics.\nQuestions to Authors\n1. How do you plan to extend this approach to other domains, and what are the potential challenges and limitations?\n2. Can you provide more details on the theoretical analysis of the approach, and how it relates to existing work on interpreting neural networks?\n3. How do you plan to address the potential dependence on high-quality data, and what are the implications for applying this approach to datasets with lower quality or different characteristics?"
        }
    ]
}