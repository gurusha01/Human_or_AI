{
    "version": "2025-01-09-base",
    "scanId": "31a84d38-d567-4165-bccf-e804927d4c17",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999986886978149,
                    "sentence": "Summary of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961256980896,
                    "sentence": "The paper proposes a novel Multi-Prototype Mention Embedding model to address the ambiguity of entity mentions in a unified semantic space.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961853027344,
                    "sentence": "The model learns multiple sense embeddings for each mention by jointly modeling words from textual contexts and entities derived from a knowledge base.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999995231628418,
                    "sentence": "An efficient language model-based approach is also designed to disambiguate each mention to a specific sense.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999921321868896,
                    "sentence": "The authors evaluate their model using entity linking as a study case and achieve state-of-the-art results on a benchmark dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999577403068542,
                    "sentence": "Main Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960660934448,
                    "sentence": "1. A novel Multi-Prototype Mention Embedding model that learns multiple sense embeddings for each mention.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999924898147583,
                    "sentence": "2. An efficient language model-based approach to disambiguate entity mentions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999993622303009,
                    "sentence": "3. State-of-the-art results on a benchmark dataset for entity linking.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999889135360718,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999901652336121,
                    "sentence": "1. The paper addresses a significant challenge in integrating text and knowledge into a unified semantic space, namely the ambiguity of entity mentions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999920129776001,
                    "sentence": "2. The proposed Multi-Prototype Mention Embedding model is novel and shows promising results in learning multiple sense embeddings for each mention.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999921917915344,
                    "sentence": "3. The authors provide a thorough evaluation of their model using both qualitative and quantitative analysis, demonstrating the high quality of the word, entity, and multi-prototype mention embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999943971633911,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999962449073792,
                    "sentence": "1. The paper could benefit from a more detailed discussion of the limitations of the proposed model, such as its scalability and applicability to other tasks beyond entity linking.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960064888,
                    "sentence": "2. The authors assume that the knowledge base used to derive entities is accurate and complete, which may not always be the case in real-world scenarios.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999966025352478,
                    "sentence": "3. The paper could provide more insights into the efficiency of the language model-based approach to disambiguate entity mentions, such as its computational complexity and potential bottlenecks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999679923057556,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999947547912598,
                    "sentence": "1. How do the authors plan to address the scalability of the proposed model to larger datasets and more complex entity linking tasks?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958276748657,
                    "sentence": "2. Can the authors provide more details on the knowledge base used to derive entities and its potential limitations?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961256980896,
                    "sentence": "3. How do the authors envision the proposed model being applied to other tasks beyond entity linking, such as question answering or text summarization?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary of the Paper\nThe paper proposes a novel Multi-Prototype Mention Embedding model to address the ambiguity of entity mentions in a unified semantic space. The model learns multiple sense embeddings for each mention by jointly modeling words from textual contexts and entities derived from a knowledge base. An efficient language model-based approach is also designed to disambiguate each mention to a specific sense. The authors evaluate their model using entity linking as a study case and achieve state-of-the-art results on a benchmark dataset.\nMain Contributions\n1. A novel Multi-Prototype Mention Embedding model that learns multiple sense embeddings for each mention.\n2. An efficient language model-based approach to disambiguate entity mentions.\n3. State-of-the-art results on a benchmark dataset for entity linking.\nStrengths\n1. The paper addresses a significant challenge in integrating text and knowledge into a unified semantic space, namely the ambiguity of entity mentions.\n2. The proposed Multi-Prototype Mention Embedding model is novel and shows promising results in learning multiple sense embeddings for each mention.\n3. The authors provide a thorough evaluation of their model using both qualitative and quantitative analysis, demonstrating the high quality of the word, entity, and multi-prototype mention embeddings.\nWeaknesses\n1. The paper could benefit from a more detailed discussion of the limitations of the proposed model, such as its scalability and applicability to other tasks beyond entity linking.\n2. The authors assume that the knowledge base used to derive entities is accurate and complete, which may not always be the case in real-world scenarios.\n3. The paper could provide more insights into the efficiency of the language model-based approach to disambiguate entity mentions, such as its computational complexity and potential bottlenecks.\nQuestions to Authors\n1. How do the authors plan to address the scalability of the proposed model to larger datasets and more complex entity linking tasks?\n2. Can the authors provide more details on the knowledge base used to derive entities and its potential limitations?\n3. How do the authors envision the proposed model being applied to other tasks beyond entity linking, such as question answering or text summarization?"
        }
    ]
}