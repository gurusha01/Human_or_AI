{
    "version": "2025-01-09-base",
    "scanId": "2de42cb5-58df-4d43-b231-10921ff4674c",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999868273735046,
                    "sentence": "Summary of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999802112579346,
                    "sentence": "The paper introduces a new deep learning model for semantic role labeling (SRL) that achieves state-of-the-art results on the CoNLL 2005 and CoNLL 2012 datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999649524688721,
                    "sentence": "The model uses a deep highway BiLSTM architecture with constrained decoding and incorporates recent advances in training deep recurrent neural networks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999577403068542,
                    "sentence": "The authors also provide an in-depth error analysis to understand the strengths and limitations of the model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999716877937317,
                    "sentence": "Main Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999228715896606,
                    "sentence": "1. A new state-of-the-art deep network for end-to-end SRL, supported by code and models that will be publicly available.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999331831932068,
                    "sentence": "2. An in-depth error analysis indicating where the models work well and where they still struggle, including discussion of structural consistency and long-distance dependencies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999916672706604,
                    "sentence": "3. Experiments that point toward directions for future improvements, including a detailed discussion of how and when syntactic parsers could be used to improve these results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999527335166931,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999310374259949,
                    "sentence": "1. The model achieves a 10% relative error reduction over the previous state of the art on the CoNLL 2005 and CoNLL 2012 datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999622106552124,
                    "sentence": "2. The authors provide a detailed error analysis that sheds light on the strengths and limitations of the model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999266862869263,
                    "sentence": "3. The model is able to capture long-range dependencies and syntactic constituency structure without explicitly modeling syntax.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999457001686096,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998279809951782,
                    "sentence": "1. The model still makes errors in labeling and attachment, particularly with prepositional phrases.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99995356798172,
                    "sentence": "2. The model's performance deteriorates on out-of-domain data, suggesting that it may not generalize well to new genres or datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999638795852661,
                    "sentence": "3. The authors do not provide a detailed comparison with other state-of-the-art models, making it difficult to evaluate the model's performance in relation to other approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996268153190613,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999788999557495,
                    "sentence": "1. How do the authors plan to address the issue of the model's performance deteriorating on out-of-domain data?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999862313270569,
                    "sentence": "2. Can the authors provide more details on how the model's performance compares to other state-of-the-art models?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999869465827942,
                    "sentence": "3. How do the authors plan to incorporate syntactic parsers into the model to further improve its performance?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary of the Paper\nThe paper introduces a new deep learning model for semantic role labeling (SRL) that achieves state-of-the-art results on the CoNLL 2005 and CoNLL 2012 datasets. The model uses a deep highway BiLSTM architecture with constrained decoding and incorporates recent advances in training deep recurrent neural networks. The authors also provide an in-depth error analysis to understand the strengths and limitations of the model.\nMain Contributions\n1. A new state-of-the-art deep network for end-to-end SRL, supported by code and models that will be publicly available.\n2. An in-depth error analysis indicating where the models work well and where they still struggle, including discussion of structural consistency and long-distance dependencies.\n3. Experiments that point toward directions for future improvements, including a detailed discussion of how and when syntactic parsers could be used to improve these results.\nStrengths\n1. The model achieves a 10% relative error reduction over the previous state of the art on the CoNLL 2005 and CoNLL 2012 datasets.\n2. The authors provide a detailed error analysis that sheds light on the strengths and limitations of the model.\n3. The model is able to capture long-range dependencies and syntactic constituency structure without explicitly modeling syntax.\nWeaknesses\n1. The model still makes errors in labeling and attachment, particularly with prepositional phrases.\n2. The model's performance deteriorates on out-of-domain data, suggesting that it may not generalize well to new genres or datasets.\n3. The authors do not provide a detailed comparison with other state-of-the-art models, making it difficult to evaluate the model's performance in relation to other approaches.\nQuestions to Authors\n1. How do the authors plan to address the issue of the model's performance deteriorating on out-of-domain data?\n2. Can the authors provide more details on how the model's performance compares to other state-of-the-art models?\n3. How do the authors plan to incorporate syntactic parsers into the model to further improve its performance?"
        }
    ]
}