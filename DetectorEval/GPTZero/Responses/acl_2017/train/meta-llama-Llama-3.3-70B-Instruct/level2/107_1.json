{
    "version": "2025-01-09-base",
    "scanId": "1aa01a0f-d056-4c95-aec2-2beec1c53156",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9988337755203247,
                    "sentence": "Summary of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9965447187423706,
                    "sentence": "The paper presents two approaches for weakly supervised cross-lingual named entity recognition (NER) with no human annotation in the target language.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985799193382263,
                    "sentence": "The first approach is based on annotation projection, where a heuristic data selection scheme is developed to select good-quality projection-labeled NER data from noisy comparable corpora.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986917972564697,
                    "sentence": "The second approach is based on representation projection, where word embeddings are projected from a target language to a source language, allowing a single NER system to be applied to multiple languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991498589515686,
                    "sentence": "Two co-decoding schemes are also proposed to combine the outputs of the two projection-based approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.998780369758606,
                    "sentence": "Main Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9977813363075256,
                    "sentence": "1. Annotation Projection Approach: A heuristic data selection scheme is developed to select good-quality projection-labeled NER data from noisy comparable corpora, improving the accuracy of the target-language NER system.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9980193376541138,
                    "sentence": "2. Representation Projection Approach: A new approach for direct NER model transfer based on representation projection is proposed, allowing a single NER system to be applied to multiple languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99896639585495,
                    "sentence": "3. Co-Decoding Schemes: Two co-decoding schemes are proposed to combine the outputs of the two projection-based approaches, achieving higher accuracy than both individual systems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9981479644775391,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999784231185913,
                    "sentence": "1. Effective Use of Comparable Corpora: The paper demonstrates the effectiveness of using comparable corpora for cross-lingual NER, which is a valuable resource for low-resource languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999831914901733,
                    "sentence": "2. Improved Accuracy: The proposed approaches achieve higher accuracy than state-of-the-art cross-lingual NER approaches, especially for languages with limited resources.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999615550041199,
                    "sentence": "3. Flexibility: The representation projection approach allows for easy addition of new languages without requiring separate embeddings for each language pair.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999571442604065,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999110698699951,
                    "sentence": "1. Dependence on Alignment Accuracy: The annotation projection approach relies on the accuracy of the alignment system, which can be a limitation for languages with poor alignment quality.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998524188995361,
                    "sentence": "2. Limited Evaluation: The paper only evaluates the proposed approaches on a limited number of languages and datasets, which may not be representative of all languages and scenarios.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998707175254822,
                    "sentence": "3. Complexity: The co-decoding schemes may add complexity to the overall system, which can be a challenge for practical deployment.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9969414472579956,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9976524710655212,
                    "sentence": "1. How do the proposed approaches perform on languages with very different scripts or grammatical structures?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.998132050037384,
                    "sentence": "2. Can the representation projection approach be extended to other NLP tasks beyond NER?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974489212036133,
                    "sentence": "3. How do the co-decoding schemes handle conflicts between the two projection-based approaches, and what are the implications for overall system performance?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9984984300152882,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984984300152882,
                "mixed": 0.0015015699847118259
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984984300152882,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984984300152882,
                    "human": 0,
                    "mixed": 0.0015015699847118259
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary of the Paper\nThe paper presents two approaches for weakly supervised cross-lingual named entity recognition (NER) with no human annotation in the target language. The first approach is based on annotation projection, where a heuristic data selection scheme is developed to select good-quality projection-labeled NER data from noisy comparable corpora. The second approach is based on representation projection, where word embeddings are projected from a target language to a source language, allowing a single NER system to be applied to multiple languages. Two co-decoding schemes are also proposed to combine the outputs of the two projection-based approaches.\nMain Contributions\n1. Annotation Projection Approach: A heuristic data selection scheme is developed to select good-quality projection-labeled NER data from noisy comparable corpora, improving the accuracy of the target-language NER system.\n2. Representation Projection Approach: A new approach for direct NER model transfer based on representation projection is proposed, allowing a single NER system to be applied to multiple languages.\n3. Co-Decoding Schemes: Two co-decoding schemes are proposed to combine the outputs of the two projection-based approaches, achieving higher accuracy than both individual systems.\nStrengths\n1. Effective Use of Comparable Corpora: The paper demonstrates the effectiveness of using comparable corpora for cross-lingual NER, which is a valuable resource for low-resource languages.\n2. Improved Accuracy: The proposed approaches achieve higher accuracy than state-of-the-art cross-lingual NER approaches, especially for languages with limited resources.\n3. Flexibility: The representation projection approach allows for easy addition of new languages without requiring separate embeddings for each language pair.\nWeaknesses\n1. Dependence on Alignment Accuracy: The annotation projection approach relies on the accuracy of the alignment system, which can be a limitation for languages with poor alignment quality.\n2. Limited Evaluation: The paper only evaluates the proposed approaches on a limited number of languages and datasets, which may not be representative of all languages and scenarios.\n3. Complexity: The co-decoding schemes may add complexity to the overall system, which can be a challenge for practical deployment.\nQuestions to Authors\n1. How do the proposed approaches perform on languages with very different scripts or grammatical structures?\n2. Can the representation projection approach be extended to other NLP tasks beyond NER?\n3. How do the co-decoding schemes handle conflicts between the two projection-based approaches, and what are the implications for overall system performance?"
        }
    ]
}