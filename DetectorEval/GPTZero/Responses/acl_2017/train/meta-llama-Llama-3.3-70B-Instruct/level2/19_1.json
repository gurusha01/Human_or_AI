{
    "version": "2025-01-09-base",
    "scanId": "739e3a72-3645-4e3f-bd83-29d6f9496c03",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999793767929077,
                    "sentence": "Summary of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999911189079285,
                    "sentence": "This paper proposes a novel approach to zero pronoun resolution by automatically generating large-scale pseudo training data and utilizing an attention-based neural network model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999675154685974,
                    "sentence": "The authors address the issue of limited annotated data for zero pronoun resolution by generating pseudo training data using a cloze-style reading comprehension approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999901652336121,
                    "sentence": "They also propose a two-step training method, which combines the benefits of large-scale pseudo training data and task-specific data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999798536300659,
                    "sentence": "Main Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999918937683105,
                    "sentence": "1. Automatic generation of pseudo training data: The authors propose a simple and effective method to generate large-scale pseudo training data for zero pronoun resolution, which can alleviate the issue of limited annotated data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999914169311523,
                    "sentence": "2. Attention-based neural network model: The authors utilize an attention-based neural network model to resolve zero pronouns, which can effectively capture the context information and improve the performance of zero pronoun resolution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999812841415405,
                    "sentence": "3. Two-step training approach: The authors propose a two-step training approach, which combines the benefits of large-scale pseudo training data and task-specific data, and can be easily adapted to other tasks as well.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999565482139587,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999877214431763,
                    "sentence": "1. Effective use of pseudo training data: The authors demonstrate the effectiveness of using pseudo training data to improve the performance of zero pronoun resolution, which can alleviate the issue of limited annotated data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999544620513916,
                    "sentence": "2. State-of-the-art results: The authors achieve state-of-the-art results on the OntoNotes 5.0 corpus, which demonstrates the effectiveness of their proposed approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999626874923706,
                    "sentence": "3. Simple and efficient method: The authors propose a simple and efficient method to generate pseudo training data, which can be easily adapted to other tasks as well.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999613761901855,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999752640724182,
                    "sentence": "1. Limited analysis of errors: The authors only provide a limited analysis of errors, which may not be sufficient to understand the limitations of their proposed approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999749660491943,
                    "sentence": "2. Lack of comparison with other methods: The authors do not provide a comprehensive comparison with other methods, which may make it difficult to understand the strengths and weaknesses of their proposed approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999804496765137,
                    "sentence": "3. Dependence on task-specific data: The authors' proposed approach relies on task-specific data, which may limit its applicability to other tasks or domains.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996256828308105,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999616146087646,
                    "sentence": "1. Can you provide more details on the analysis of errors and the limitations of your proposed approach?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999029040336609,
                    "sentence": "2. How does your proposed approach compare with other methods, such as supervised or unsupervised approaches?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999604821205139,
                    "sentence": "3. Can you provide more details on the applicability of your proposed approach to other tasks or domains?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary of the Paper\nThis paper proposes a novel approach to zero pronoun resolution by automatically generating large-scale pseudo training data and utilizing an attention-based neural network model. The authors address the issue of limited annotated data for zero pronoun resolution by generating pseudo training data using a cloze-style reading comprehension approach. They also propose a two-step training method, which combines the benefits of large-scale pseudo training data and task-specific data.\nMain Contributions\n1. Automatic generation of pseudo training data: The authors propose a simple and effective method to generate large-scale pseudo training data for zero pronoun resolution, which can alleviate the issue of limited annotated data.\n2. Attention-based neural network model: The authors utilize an attention-based neural network model to resolve zero pronouns, which can effectively capture the context information and improve the performance of zero pronoun resolution.\n3. Two-step training approach: The authors propose a two-step training approach, which combines the benefits of large-scale pseudo training data and task-specific data, and can be easily adapted to other tasks as well.\nStrengths\n1. Effective use of pseudo training data: The authors demonstrate the effectiveness of using pseudo training data to improve the performance of zero pronoun resolution, which can alleviate the issue of limited annotated data.\n2. State-of-the-art results: The authors achieve state-of-the-art results on the OntoNotes 5.0 corpus, which demonstrates the effectiveness of their proposed approach.\n3. Simple and efficient method: The authors propose a simple and efficient method to generate pseudo training data, which can be easily adapted to other tasks as well.\nWeaknesses\n1. Limited analysis of errors: The authors only provide a limited analysis of errors, which may not be sufficient to understand the limitations of their proposed approach.\n2. Lack of comparison with other methods: The authors do not provide a comprehensive comparison with other methods, which may make it difficult to understand the strengths and weaknesses of their proposed approach.\n3. Dependence on task-specific data: The authors' proposed approach relies on task-specific data, which may limit its applicability to other tasks or domains.\nQuestions to Authors\n1. Can you provide more details on the analysis of errors and the limitations of your proposed approach?\n2. How does your proposed approach compare with other methods, such as supervised or unsupervised approaches?\n3. Can you provide more details on the applicability of your proposed approach to other tasks or domains?"
        }
    ]
}