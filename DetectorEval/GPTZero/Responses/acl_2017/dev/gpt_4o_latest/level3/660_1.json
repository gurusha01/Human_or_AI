{
    "version": "2025-01-09-base",
    "scanId": "3b6acaed-52a7-4656-b126-b59c6bbfc66a",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999884963035583,
                    "sentence": "Review",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "Summary and Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998152256012,
                    "sentence": "This paper introduces two novel methodologies for English poetry generation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999945163726807,
                    "sentence": "The first approach employs a neural phonetic encoder with a Hidden Markov Model (HMM) decoder to implicitly learn both form and content.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973177909851,
                    "sentence": "The second approach combines a character-level language model with a Weighted Finite State Transducer (WFST) to enforce rhythm constraints, treating poetry generation as a constraint satisfaction problem.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999954104423523,
                    "sentence": "The latter approach also incorporates heuristic methods to constrain poems by theme (e.g., love) and poetic devices (e.g., alliteration).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999954700469971,
                    "sentence": "The evaluation includes intrinsic rhythm comparisons with a gold standard and extrinsic human assessments for readability, form, and evocation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999817609786987,
                    "sentence": "Results demonstrate that the second model outperforms the first, with human evaluators often unable to distinguish between machine-generated and human-written poems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999839663505554,
                    "sentence": "The primary contributions of this work are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999976396560669,
                    "sentence": "1. A robust methodology for poetry generation that combines neural language models with WFSTs to enforce rhythmic constraints, which allows for greater control over poetic form and thematic content.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999733567237854,
                    "sentence": "2. A heuristic approach for incorporating themes and poetic devices into generated poetry, enabling flexibility and creative diversity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999650716781616,
                    "sentence": "3. A comprehensive evaluation framework, including human assessments, demonstrating the indistinguishability of machine-generated poetry from human poetry.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961853027344,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999768137931824,
                    "sentence": "1. Novelty and Technical Rigor: The integration of neural language models with WFSTs for rhythm enforcement is a significant advancement, offering a flexible and interpretable mechanism for generating poetry with strict formal constraints.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999825954437256,
                    "sentence": "The heuristic methods for themes and poetic devices further enhance the creative potential of the system.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999783039093018,
                    "sentence": "2. Evaluation Quality: The use of both intrinsic and extrinsic evaluations, particularly the human indistinguishability test, provides strong evidence of the system's effectiveness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999874830245972,
                    "sentence": "The finding that human evaluators often misclassify machine-generated poetry as human-written is compelling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999909400939941,
                    "sentence": "3. Clarity and Reproducibility: The paper is well-written and provides sufficient detail about the models, training procedures, and evaluation protocols, making the work accessible and reproducible for future research.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999903440475464,
                    "sentence": "4. Impact on the Field: This work bridges the gap between statistical and rule-based approaches to poetry generation, demonstrating the potential of combining neural models with symbolic constraints.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999996542930603,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994695186615,
                    "sentence": "1. Evaluation Protocol Details: The paper lacks sufficient detail about the human evaluators, such as their level of expertise in poetry and the number of judgments per poem.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999912977218628,
                    "sentence": "Additionally, the fluency of non-native English evaluators and its impact on results is not addressed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997329115867615,
                    "sentence": "2. First Model's Relevance: The phonetic-level model, while interesting, is less effective and generalizable compared to the second model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989985227584839,
                    "sentence": "The paper could reduce its focus on this model and allocate more space to evaluating the second model, particularly the impact of heuristics on themes and poetic devices.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995518922805786,
                    "sentence": "3. Non-Word Generation: The paper does not discuss whether the second model has mechanisms to avoid generating non-words or how frequently such errors occur.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994924664497375,
                    "sentence": "This is an important consideration for practical usability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996927976608276,
                    "sentence": "4. Limited Exploration of Combined Constraints: While the paper explores themes and poetic devices independently, it does not investigate the joint application of these constraints, which could provide deeper insights into the model's creative capabilities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9973391890525818,
                    "sentence": "5. Related Work: The paper could better situate its contributions within prior research, particularly the work on combining neural models with WFSTs, such as Goyal et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9400363564491272,
                    "sentence": "(COLING 2016).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8652361631393433,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9690248370170593,
                    "sentence": "1. Does the second model include a mechanism to avoid generating non-words?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9275500774383545,
                    "sentence": "If not, how frequent are non-words in the output, and how are they handled during evaluation?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9411807060241699,
                    "sentence": "2. Could you provide more details about the human evaluators, such as their poetry expertise and the number of judgments per poem?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.906047523021698,
                    "sentence": "How might non-native English speakers have influenced the results?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9057670831680298,
                    "sentence": "3. Have you considered exploring the joint application of constraints for themes and poetic devices?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9129604697227478,
                    "sentence": "If so, what challenges or opportunities do you foresee?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8930908441543579,
                    "sentence": "Recommendation",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7682771682739258,
                    "sentence": "This paper presents a significant contribution to the field of computational creativity and poetry generation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8222271800041199,
                    "sentence": "While there are some areas for improvement, particularly in evaluation protocols and the exploration of combined constraints, the strengths of the work outweigh its weaknesses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6744384765625,
                    "sentence": "I recommend acceptance with minor revisions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.07332528267997859
                }
            ],
            "completely_generated_prob": 0.8753704990852369,
            "class_probabilities": {
                "human": 0.11057250597192597,
                "ai": 0.8753704990852369,
                "mixed": 0.014056994942837287
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8753704990852369,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8753704990852369,
                    "human": 0.11057250597192597,
                    "mixed": 0.014056994942837287
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Review\nSummary and Contributions\nThis paper introduces two novel methodologies for English poetry generation. The first approach employs a neural phonetic encoder with a Hidden Markov Model (HMM) decoder to implicitly learn both form and content. The second approach combines a character-level language model with a Weighted Finite State Transducer (WFST) to enforce rhythm constraints, treating poetry generation as a constraint satisfaction problem. The latter approach also incorporates heuristic methods to constrain poems by theme (e.g., love) and poetic devices (e.g., alliteration). The evaluation includes intrinsic rhythm comparisons with a gold standard and extrinsic human assessments for readability, form, and evocation. Results demonstrate that the second model outperforms the first, with human evaluators often unable to distinguish between machine-generated and human-written poems. \nThe primary contributions of this work are:\n1. A robust methodology for poetry generation that combines neural language models with WFSTs to enforce rhythmic constraints, which allows for greater control over poetic form and thematic content.\n2. A heuristic approach for incorporating themes and poetic devices into generated poetry, enabling flexibility and creative diversity.\n3. A comprehensive evaluation framework, including human assessments, demonstrating the indistinguishability of machine-generated poetry from human poetry.\nStrengths\n1. Novelty and Technical Rigor: The integration of neural language models with WFSTs for rhythm enforcement is a significant advancement, offering a flexible and interpretable mechanism for generating poetry with strict formal constraints. The heuristic methods for themes and poetic devices further enhance the creative potential of the system.\n2. Evaluation Quality: The use of both intrinsic and extrinsic evaluations, particularly the human indistinguishability test, provides strong evidence of the system's effectiveness. The finding that human evaluators often misclassify machine-generated poetry as human-written is compelling.\n3. Clarity and Reproducibility: The paper is well-written and provides sufficient detail about the models, training procedures, and evaluation protocols, making the work accessible and reproducible for future research.\n4. Impact on the Field: This work bridges the gap between statistical and rule-based approaches to poetry generation, demonstrating the potential of combining neural models with symbolic constraints.\nWeaknesses\n1. Evaluation Protocol Details: The paper lacks sufficient detail about the human evaluators, such as their level of expertise in poetry and the number of judgments per poem. Additionally, the fluency of non-native English evaluators and its impact on results is not addressed.\n2. First Model's Relevance: The phonetic-level model, while interesting, is less effective and generalizable compared to the second model. The paper could reduce its focus on this model and allocate more space to evaluating the second model, particularly the impact of heuristics on themes and poetic devices.\n3. Non-Word Generation: The paper does not discuss whether the second model has mechanisms to avoid generating non-words or how frequently such errors occur. This is an important consideration for practical usability.\n4. Limited Exploration of Combined Constraints: While the paper explores themes and poetic devices independently, it does not investigate the joint application of these constraints, which could provide deeper insights into the model's creative capabilities.\n5. Related Work: The paper could better situate its contributions within prior research, particularly the work on combining neural models with WFSTs, such as Goyal et al. (COLING 2016).\nQuestions to Authors\n1. Does the second model include a mechanism to avoid generating non-words? If not, how frequent are non-words in the output, and how are they handled during evaluation?\n2. Could you provide more details about the human evaluators, such as their poetry expertise and the number of judgments per poem? How might non-native English speakers have influenced the results?\n3. Have you considered exploring the joint application of constraints for themes and poetic devices? If so, what challenges or opportunities do you foresee?\nRecommendation\nThis paper presents a significant contribution to the field of computational creativity and poetry generation. While there are some areas for improvement, particularly in evaluation protocols and the exploration of combined constraints, the strengths of the work outweigh its weaknesses. I recommend acceptance with minor revisions."
        }
    ]
}