{
    "version": "2025-01-09-base",
    "scanId": "20bfd0ea-4f2f-414a-a461-dc82e8b726d9",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9851134419441223,
                    "sentence": "- Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9926446080207825,
                    "sentence": "The paper introduces several innovative contributions to (transition-based) dependency parsing by generalizing the concepts of non-monotonic transition systems and dynamic oracles to unrestricted non-projective dependency parsing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9845888018608093,
                    "sentence": "The theoretical and algorithmic insights are presented with clarity and depth, and the overall exposition of the paper is commendably lucid.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9911160469055176,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9910567998886108,
                    "sentence": "Although the primary motivation for employing Covington's algorithm lies in its ability to handle non-projective arcs, the paper would have been further strengthened by an empirical error analysis specifically targeting non-projective structures.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9814614057540894,
                    "sentence": "Additionally, while the paper's main contributions are theoretical, it would have been beneficial to include a comparison against the state of the art on the CoNLL datasets, rather than limiting the evaluation to the monotonic baseline version of the same parser.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9952772855758667,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9911539554595947,
                    "sentence": "This work extends the transition-based framework of Covington's dependency parsing algorithm (designed for unrestricted non-projective structures) by introducing non-monotonicity, allowing later transitions to revise structures created by earlier ones.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9936206936836243,
                    "sentence": "The paper also demonstrates how approximate dynamic oracles can be developed for this new system.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.971906304359436,
                    "sentence": "Experimental results show that these oracles provide a close approximation and that the non-monotonic system achieves higher parsing accuracy than its monotonic counterpart for most of the languages evaluated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.954981803894043,
                    "sentence": "The theoretical contributions are, in my opinion, substantial enough to warrant publication.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8758247494697571,
                    "sentence": "However, the empirical evaluation could be enhanced.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9562896490097046,
                    "sentence": "Specifically, an error analysis focusing on whether the non-monotonic system improves accuracy on non-projective structures would be highly relevant.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9635977149009705,
                    "sentence": "This is particularly important because: (i) the ability to recover non-projective structures is the primary motivation for using Covington's algorithm; and (ii) non-projective structures often involve long-distance dependencies, which are challenging for greedy transition-based parsers, making it plausible that the proposed system would offer improvements in this area.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9976600408554077,
                    "sentence": "Another aspect worth exploring is the relationship between the empirical results and the state of the art, especially given recent advancements in word embeddings and neural network-based techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9966471791267395,
                    "sentence": "For instance, the paper argues that non-monotonicity reduces the error propagation typically seen in classical greedy transition-based parsers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9815344214439392,
                    "sentence": "However, another approach to addressing this issue is the use of recurrent neural networks as preprocessors, which capture more global sentence context in word representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9625715017318726,
                    "sentence": "Are these two approaches competitive or complementary?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.989348828792572,
                    "sentence": "While a comprehensive investigation of this question is beyond the scope of the paper, a brief discussion would add valuable context.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8616129159927368,
                    "sentence": "- Specific Questions:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6666503548622131,
                    "sentence": "1. Why were only 9 out of the 13 datasets from the CoNLL-X shared task included in the experiments?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8873629570007324,
                    "sentence": "Explicitly stating the reason would help preempt any concerns or doubts from readers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7113617658615112,
                    "sentence": "2. Do you have any hypotheses regarding the observed decrease in accuracy for Basque with the non-monotonic system?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.49261587858200073,
                    "sentence": "Similar, albeit weaker, trends are also noticeable for Turkish, Catalan, Hungarian, and possibly German.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6811521053314209,
                    "sentence": "3. How do your results compare to the state of the art on these datasets?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.38170552253723145,
                    "sentence": "Providing this comparison would help contextualize your findings and allow readers to better assess the significance of your improvements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7033932209014893,
                    "sentence": "- Author Response:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.3814740478992462,
                    "sentence": "I am satisfied with the author's response and find no reason to revise my initial review.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.3063829682933457
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.9841954571483108,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9841954571483108,
                "mixed": 0.015804542851689255
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9841954571483108,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9841954571483108,
                    "human": 0,
                    "mixed": 0.015804542851689255
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "- Strengths: \nThe paper introduces several innovative contributions to (transition-based) dependency parsing by generalizing the concepts of non-monotonic transition systems and dynamic oracles to unrestricted non-projective dependency parsing. The theoretical and algorithmic insights are presented with clarity and depth, and the overall exposition of the paper is commendably lucid.\n- Weaknesses: \nAlthough the primary motivation for employing Covington's algorithm lies in its ability to handle non-projective arcs, the paper would have been further strengthened by an empirical error analysis specifically targeting non-projective structures. Additionally, while the paper's main contributions are theoretical, it would have been beneficial to include a comparison against the state of the art on the CoNLL datasets, rather than limiting the evaluation to the monotonic baseline version of the same parser.\n- General Discussion: \nThis work extends the transition-based framework of Covington's dependency parsing algorithm (designed for unrestricted non-projective structures) by introducing non-monotonicity, allowing later transitions to revise structures created by earlier ones. The paper also demonstrates how approximate dynamic oracles can be developed for this new system. Experimental results show that these oracles provide a close approximation and that the non-monotonic system achieves higher parsing accuracy than its monotonic counterpart for most of the languages evaluated.\nThe theoretical contributions are, in my opinion, substantial enough to warrant publication. However, the empirical evaluation could be enhanced. Specifically, an error analysis focusing on whether the non-monotonic system improves accuracy on non-projective structures would be highly relevant. This is particularly important because: (i) the ability to recover non-projective structures is the primary motivation for using Covington's algorithm; and (ii) non-projective structures often involve long-distance dependencies, which are challenging for greedy transition-based parsers, making it plausible that the proposed system would offer improvements in this area.\nAnother aspect worth exploring is the relationship between the empirical results and the state of the art, especially given recent advancements in word embeddings and neural network-based techniques. For instance, the paper argues that non-monotonicity reduces the error propagation typically seen in classical greedy transition-based parsers. However, another approach to addressing this issue is the use of recurrent neural networks as preprocessors, which capture more global sentence context in word representations. Are these two approaches competitive or complementary? While a comprehensive investigation of this question is beyond the scope of the paper, a brief discussion would add valuable context.\n- Specific Questions: \n1. Why were only 9 out of the 13 datasets from the CoNLL-X shared task included in the experiments? Explicitly stating the reason would help preempt any concerns or doubts from readers. \n2. Do you have any hypotheses regarding the observed decrease in accuracy for Basque with the non-monotonic system? Similar, albeit weaker, trends are also noticeable for Turkish, Catalan, Hungarian, and possibly German. \n3. How do your results compare to the state of the art on these datasets? Providing this comparison would help contextualize your findings and allow readers to better assess the significance of your improvements.\n- Author Response: \nI am satisfied with the author's response and find no reason to revise my initial review."
        }
    ]
}