{
    "version": "2025-01-09-base",
    "scanId": "bc15ba28-1380-4743-af93-9aaac6b9d83a",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0660865306854248,
                    "sentence": "This paper proposed a new phrasal RNN architecture for sequence to sequence",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07025489211082458,
                    "sentence": "generation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0546969510614872,
                    "sentence": "They have evaluated their architecture based on (i) the language",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1207016333937645,
                    "sentence": "modelling test evaluated on PTB and FBIS and (ii) Chinese-English machine",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16066163778305054,
                    "sentence": "translation task on NIST MT02-08 evaluation sets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05688847601413727,
                    "sentence": "The phrasal RNN (pRNN)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0673740953207016,
                    "sentence": "architecture is achieved by generating subnetworks of phrases.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04024647921323776,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01092697586864233,
                    "sentence": "====",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11259458214044571,
                    "sentence": "A new phrasal architecture.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.058426376432180405,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010378758423030376,
                    "sentence": "====",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13461549580097198,
                    "sentence": "Technical:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05579262971878052,
                    "sentence": "It's unclear whether there is a limit set on the phrase length of the pRNN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03793070837855339,
                    "sentence": "Maybe I've missed this in the paper, if there is, please be more explicit about",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06999435275793076,
                    "sentence": "it because it affects the model quite drastically if for every sentence the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03662862256169319,
                    "sentence": "largest phrase length is the sentence length.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04507250338792801,
                    "sentence": "- It's because if the largest phrase length is the sentence length, then model",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08246374875307083,
                    "sentence": "can be simplified into a some sort of convolution RNN where the each state of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06508903950452805,
                    "sentence": "the RNN goes through some convolution layer before a final softmax and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08856064081192017,
                    "sentence": "attention.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05011127516627312,
                    "sentence": "- If there is a limit set on the phrase length of pRNN, then it makes the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10435160249471664,
                    "sentence": "system more tractable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04693369194865227,
                    "sentence": "But that would also mean that the phrases are determined",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03857182711362839,
                    "sentence": "by token ngrams which produces a sliding window of the \"pyramid encoders\" for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06461016833782196,
                    "sentence": "each sentence where there are instance where the parameter for these phrases",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07984479516744614,
                    "sentence": "will be set close to zero to disable the phrases and these phrases would be a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07812443375587463,
                    "sentence": "good intrinsic evaluation of the pRNN in addition to evaluating it purely on",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12275461852550507,
                    "sentence": "perplexity and BLEU extrinsically.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05646286904811859,
                    "sentence": "The usage of attention mechanism without some sort of pruning might be",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.039010439068078995,
                    "sentence": "problematic at the phrasal level.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04367145150899887,
                    "sentence": "The author have opted for some sort of greedy",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.044815145432949066,
                    "sentence": "pruning as described in the caption of figure 4.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.024793589487671852,
                    "sentence": "But I support given a fixed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03431102633476257,
                    "sentence": "set of phrase pairs at train time, the attention mechanism at the phrasal level",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.056638844311237335,
                    "sentence": "can be pre-computed but at inference (apply the attention on new data at test",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06990910321474075,
                    "sentence": "time), this might be kind of problematic when the architecture is scaled to a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18661081790924072,
                    "sentence": "larger dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0758790597319603,
                    "sentence": "Empirical:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09064050763845444,
                    "sentence": "One issue with the language modelling experiment is the choice of evaluation",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06425230205059052,
                    "sentence": "and train set.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0787859559059143,
                    "sentence": "Possibly a dataset like common crawl or enwiki8 would be more",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10170172899961472,
                    "sentence": "appropriate for language modelling experiments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09921368211507797,
                    "sentence": "The main issue of the paper is in the experiments and results reporting, it",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1530340015888214,
                    "sentence": "needs quite a bit of reworking.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07806893438100815,
                    "sentence": "- The evaluation on PTB (table 2) isn't a fair one since the model was trained",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.024578813463449478,
                    "sentence": "on a larger corpus (FBIS) and then tested on PTB.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027624525129795074,
                    "sentence": "The fact that the previous",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.029150288552045822,
                    "sentence": "study reported a 126 perplexity baseline using LSTM and the LSTM's perplexity",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04232010245323181,
                    "sentence": "of 106.9 provided by the author showed that the FBIS gives an advantage to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04327955096960068,
                    "sentence": "computing the language model's perplexity when tested on PTB.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025389406830072403,
                    "sentence": "- Also, regarding section 3.3, please cite appropriate publications the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019987808540463448,
                    "sentence": "\"previous work\" presented in the tables.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02699948102235794,
                    "sentence": "And are the previous work using the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04337897151708603,
                    "sentence": "same training set?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.049272142350673676,
                    "sentence": "- Additionally, why isn't the the GRU version of pRNNv reported in the FBIS",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05321493372321129,
                    "sentence": "evaluation in Table 3?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0462818518280983,
                    "sentence": "The result section cannot be simply presenting a table without explanation:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.037878163158893585,
                    "sentence": "- Still on the result sections, although it's clear that BLEU and perplexity",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03241293132305145,
                    "sentence": "are objective automatic measure to evaluate the new architecture.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026594627648591995,
                    "sentence": "It's not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04205750674009323,
                    "sentence": "really okay to put up the tables and show the perplexity and BLEU scores",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03146140277385712,
                    "sentence": "without some explanation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022162359207868576,
                    "sentence": "E.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.020693931728601456,
                    "sentence": "in Table 2, it's necessary to explain why the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.028529562056064606,
                    "sentence": "LSTM's perplexity from previous work is higher than the author's",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026795629411935806,
                    "sentence": "implementation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.020171023905277252,
                    "sentence": "Same in Table 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018900327384471893,
                    "sentence": "The result presented in Table 4 don't match the description in Section 4.3:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03075919672846794,
                    "sentence": "- It's not true that the pRNN outperforms both PBSMT and Enc-Dec model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04577033221721649,
                    "sentence": "The",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04059506952762604,
                    "sentence": "authors should make it clear that on different evaluation sets, the scores",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.044816985726356506,
                    "sentence": "differs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.031080301851034164,
                    "sentence": "And it's the averaged test scores that pRNN performs better",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03279277682304382,
                    "sentence": "- Please also make it clear whether the \"Test Avg.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026696251705288887,
                    "sentence": "is a micro-average (all",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05475610867142677,
                    "sentence": "testsets are concatenated and evaluated as one set) or macro-average (average",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07905382663011551,
                    "sentence": "taken across the scores of individual test sets) score.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05702923610806465,
                    "sentence": "For table 4, please also include the significance of the BLEU improvement made",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07379288971424103,
                    "sentence": "by the pRNN with respect to the the baseline, see",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04655775427818298,
                    "sentence": "https://github.com/jhclark/multeval",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04115791246294975,
                    "sentence": "General Discussion",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017418913543224335,
                    "sentence": "====",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05022637918591499,
                    "sentence": "As the main contribution of this work is on the phrasal effect of the new RNN",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.039208706468343735,
                    "sentence": "architecture, it's rather important to show that the phrases are more coherent",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05191250145435333,
                    "sentence": "than the vanilla LSTM / RNN model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0592411532998085,
                    "sentence": "Thus the BLEU evaluation is insufficient.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10177244246006012,
                    "sentence": "A",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0668400451540947,
                    "sentence": "closer look at evaluating the phrases in a subset of the evaluation set would",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07571562379598618,
                    "sentence": "be necessary to support the claims.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.045347072184085846,
                    "sentence": "Does the baseline system (groundhog) contains the attention mechanism?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.040776707231998444,
                    "sentence": "- If so, please be more specific in describing it in section 4.2 and Table 4.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23871979117393494,
                    "sentence": "- If not, please remove the attention layer after the encoder in figure 5.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3408585786819458,
                    "sentence": "Also, the lack of attention mechanism provides a disadvantage to the baseline",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.35818421840667725,
                    "sentence": "enc-dec system and it's unclear whether the pRNN can outperform or be an",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5315228700637817,
                    "sentence": "additive feature to the enc-dec system with an attention mechanism.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.24159996211528778,
                    "sentence": "The unfair",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6005350351333618,
                    "sentence": "disadvantage is even more prevalent when the pRNN uses multiple phrasal",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5832790732383728,
                    "sentence": "attention layers within a single sentence while a simple enc-dec system without",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6802502870559692,
                    "sentence": "attention is used as a benchmark =(",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1933315098285675,
                    "sentence": "Question: Wouldn't a simpler way to get phrasal RNN is to put the \"pyramid\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19262902438640594,
                    "sentence": "RNNs of a phrase into some soft of a average pooling layer?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.31701913475990295,
                    "sentence": "Minor Issues",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09318101406097412,
                    "sentence": "====",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14502491056919098,
                    "sentence": "Figure 2 is a little redundant, I think figure 1 is enough to compare it",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13826186954975128,
                    "sentence": "against the pRNN (figure3 and 4).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13807204365730286,
                    "sentence": "Also, possibly figure 3 can be combined into the pyramid part of figure 4.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.100726418197155,
                    "sentence": "And",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10668089985847473,
                    "sentence": "more space can be freed up to further explain the results section.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04771404340863228,
                    "sentence": "Please don't abuse figure/table captions, whenever possible, please try to keep",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07101012766361237,
                    "sentence": "the description of the tables and figures in-text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07616809755563736,
                    "sentence": "Please put the verbose caption description in the main text for Figure 3, 4,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1225244551897049,
                    "sentence": "5 and Table 4",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07351122051477432,
                    "sentence": "Spacing in between some of the equations can also be reduced (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18601684272289276,
                    "sentence": "in latex use",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2224487066268921,
                    "sentence": "\\vspace{-5mm} )",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 59,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 65,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 66,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 68,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 69,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 71,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 72,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 74,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 76,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 77,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 78,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 79,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 80,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 81,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 82,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 83,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 84,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 85,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 88,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 89,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 90,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 91,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 92,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 93,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 94,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 95,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 97,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 98,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 99,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 100,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 101,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 102,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 103,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 104,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 105,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 106,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 108,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 109,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 110,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 111,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 112,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 113,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 115,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.05922069315259543,
            "class_probabilities": {
                "human": 0.9400469575553512,
                "ai": 0.05922069315259543,
                "mixed": 0.0007323492920532675
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9400469575553512,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.05922069315259543,
                    "human": 0.9400469575553512,
                    "mixed": 0.0007323492920532675
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposed a new phrasal RNN architecture for sequence to sequence\ngeneration. They have evaluated their architecture based on (i) the language\nmodelling test evaluated on PTB and FBIS and (ii) Chinese-English machine\ntranslation task on NIST MT02-08 evaluation sets. The phrasal RNN (pRNN)\narchitecture is achieved by generating subnetworks of phrases. \nStrengths\n====\nA new phrasal architecture. \nWeaknesses\n====\nTechnical: \nIt's unclear whether there is a limit set on the phrase length of the pRNN.\nMaybe I've missed this in the paper, if there is, please be more explicit about\nit because it affects the model quite drastically if for every sentence the\nlargest phrase length is the sentence length. \n - It's because if the largest phrase length is the sentence length, then model\ncan be simplified into a some sort of convolution RNN where the each state of\nthe RNN goes through some convolution layer before a final softmax and\nattention. \n - If there is a limit set on the phrase length of pRNN, then it makes the\nsystem more tractable. But that would also mean that the phrases are determined\nby token ngrams which produces a sliding window of the \"pyramid encoders\" for\neach sentence where there are instance where the parameter for these phrases\nwill be set close to zero to disable the phrases and these phrases would be a\ngood intrinsic evaluation of the pRNN in addition to evaluating it purely on\nperplexity and BLEU extrinsically. \nThe usage of attention mechanism without some sort of pruning might be\nproblematic at the phrasal level. The author have opted for some sort of greedy\npruning as described in the caption of figure 4. But I support given a fixed\nset of phrase pairs at train time, the attention mechanism at the phrasal level\ncan be pre-computed but at inference (apply the attention on new data at test\ntime), this might be kind of problematic when the architecture is scaled to a\nlarger dataset. \nEmpirical: \nOne issue with the language modelling experiment is the choice of evaluation\nand train set. Possibly a dataset like common crawl or enwiki8 would be more\nappropriate for language modelling experiments. \nThe main issue of the paper is in the experiments and results reporting, it\nneeds quite a bit of reworking. \n - The evaluation on PTB (table 2) isn't a fair one since the model was trained\non a larger corpus (FBIS) and then tested on PTB. The fact that the previous\nstudy reported a 126 perplexity baseline using LSTM and the LSTM's perplexity\nof 106.9 provided by the author showed that the FBIS gives an advantage to\ncomputing the language model's perplexity when tested on PTB.\n - Also, regarding section 3.3, please cite appropriate publications the\n\"previous work\" presented in the tables. And are the previous work using the\nsame training set? \n- Additionally, why isn't the the GRU version of pRNNv reported in the FBIS\nevaluation in Table 3?\nThe result section cannot be simply presenting a table without explanation:\n - Still on the result sections, although it's clear that BLEU and perplexity\nare objective automatic measure to evaluate the new architecture. It's not\nreally okay to put up the tables and show the perplexity and BLEU scores\nwithout some explanation. E.g. in Table 2, it's necessary to explain why the\nLSTM's perplexity from previous work is higher than the author's\nimplementation. Same in Table 3. \nThe result presented in Table 4 don't match the description in Section 4.3:\n - It's not true that the pRNN outperforms both PBSMT and Enc-Dec model. The\nauthors should make it clear that on different evaluation sets, the scores\ndiffers. And it's the averaged test scores that pRNN performs better\n- Please also make it clear whether the \"Test Avg.\" is a micro-average (all\ntestsets are concatenated and evaluated as one set) or macro-average (average\ntaken across the scores of individual test sets) score. \nFor table 4, please also include the significance of the BLEU improvement made\nby the pRNN with respect to the the baseline, see\nhttps://github.com/jhclark/multeval\nGeneral Discussion\n====\nAs the main contribution of this work is on the phrasal effect of the new RNN\narchitecture, it's rather important to show that the phrases are more coherent\nthan the vanilla LSTM / RNN model. Thus the BLEU evaluation is insufficient. A\ncloser look at evaluating the phrases in a subset of the evaluation set would\nbe necessary to support the claims. \nDoes the baseline system (groundhog) contains the attention mechanism? \n - If so, please be more specific in describing it in section 4.2 and Table 4. \n - If not, please remove the attention layer after the encoder in figure 5.\nAlso, the lack of attention mechanism provides a disadvantage to the baseline\nenc-dec system and it's unclear whether the pRNN can outperform or be an\nadditive feature to the enc-dec system with an attention mechanism. The unfair\ndisadvantage is even more prevalent when the pRNN uses multiple phrasal\nattention layers within a single sentence while a simple enc-dec system without\nattention is used as a benchmark =(\nQuestion: Wouldn't a simpler way to get phrasal RNN is to put the \"pyramid\"\nRNNs of a phrase into some soft of a average pooling layer?\nMinor Issues \n====\nFigure 2 is a little redundant, I think figure 1 is enough to compare it\nagainst the pRNN (figure3 and 4).\nAlso, possibly figure 3 can be combined into the pyramid part of figure 4. And\nmore space can be freed up to further explain the results section. \nPlease don't abuse figure/table captions, whenever possible, please try to keep\nthe description of the tables and figures in-text. \nPlease put the verbose caption description in the main text for Figure 3, 4,\n5 and Table 4\nSpacing in between some of the equations can also be reduced (e.g. in latex use\n\\vspace{-5mm} )"
        }
    ]
}