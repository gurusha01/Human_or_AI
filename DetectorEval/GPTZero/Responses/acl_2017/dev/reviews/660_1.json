{
    "version": "2025-01-09-base",
    "scanId": "249aa2f9-2f1c-4331-b69b-9277b557c6be",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.006093410775065422,
                    "sentence": "The paper presents two approaches for generating English poetry.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013924011029303074,
                    "sentence": "The first",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0042573329992592335,
                    "sentence": "approach combine a neural phonetic encoder predicting the next phoneme with a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003921431489288807,
                    "sentence": "phonetic-orthographic HMM decoder computing the most likely word corresponding",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004617681261152029,
                    "sentence": "to a sequence of phonemes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0038810705300420523,
                    "sentence": "The second approach combines a character language",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005605540703982115,
                    "sentence": "model with a weigthed FST to impose rythm constraints on the output of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02070542424917221,
                    "sentence": "language model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004319856874644756,
                    "sentence": "For the second approach, the authors also present a heuristic",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004658580292016268,
                    "sentence": "approach which permit constraining the generated poem according to theme (e.g;,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005897587165236473,
                    "sentence": "love) or poetic devices (e.g., alliteration).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011567516252398491,
                    "sentence": "The generated poems are evaluated",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008990882895886898,
                    "sentence": "both instrinsically by comparing the rythm of the generated lines with a gold",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004198303446173668,
                    "sentence": "standard and extrinsically by asking 70 human evaluators to (i) determine",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00571645051240921,
                    "sentence": "whether the poem was written by a human or a machine and (ii) rate poems wrt to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007367509882897139,
                    "sentence": "readability, form and evocation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012579160742461681,
                    "sentence": "The results indicate that the second model",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004647539462894201,
                    "sentence": "performs best and that human evaluators find it difficult to distinguish",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006657714489847422,
                    "sentence": "between human written and machine generated poems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00149416399654001,
                    "sentence": "This is an interesting, clearly written article with novel ideas (two different",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004405883140861988,
                    "sentence": "models for poetry generation, one based on a phonetic language model the other",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004660674370825291,
                    "sentence": "on a character LM) and convincing results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002078971127048135,
                    "sentence": "For the evaluation, more precision about the evaluators and the protocol would",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0031310617923736572,
                    "sentence": "be good.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0028301484417170286,
                    "sentence": "Did all evaluators evaluate all poems and if not how many judgments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0019262558780610561,
                    "sentence": "were collected for each poem for each task?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027063434943556786,
                    "sentence": "You mention 9 non English native",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018887652084231377,
                    "sentence": "speakers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019722960889339447,
                    "sentence": "Poems are notoriously hard to read.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025105256587266922,
                    "sentence": "How fluent were these?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014273603446781635,
                    "sentence": "In the second model (character based), perhaps I missed it, but do you have a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026026373729109764,
                    "sentence": "mechanism to avoid generating non words?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017206281423568726,
                    "sentence": "If not, how frequent are non words in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017596792429685593,
                    "sentence": "the generated poems?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019259817898273468,
                    "sentence": "In the first model, why use an HMM to transliterate from phonetic to an",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.016106460243463516,
                    "sentence": "orhographic representation rather than a CRF?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022808684036135674,
                    "sentence": "Since overall, you rule out the first model as a good generic model for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025876635685563087,
                    "sentence": "generating poetry, it might have been more interesting to spend less space on",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0216281246393919,
                    "sentence": "that model and more on the evaluation of the second model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01362164132297039,
                    "sentence": "In particular, I",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025270001962780952,
                    "sentence": "would have been interested in a more detailed discussion of the impact of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018798217177391052,
                    "sentence": "heuristic you use to constrain theme or poetic devices.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014730043709278107,
                    "sentence": "How do these impact",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023647258058190346,
                    "sentence": "evaluation results?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.020047293975949287,
                    "sentence": "Could they be combined to jointly constrain theme and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008117356337606907,
                    "sentence": "poetic devices?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01691252365708351,
                    "sentence": "The combination of a neural mode with a WFST is reminiscent of the following",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021122409030795097,
                    "sentence": "paper which combine character based neural model to generate from dialog acts",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01916121318936348,
                    "sentence": "with an WFST to avoid generating non words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023713380098342896,
                    "sentence": "YOu should relate your work to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017432373017072678,
                    "sentence": "theirs and cite them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03869350999593735,
                    "sentence": "Natural Language Generation through Character-Based RNNs with Finite-State",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05314759537577629,
                    "sentence": "Prior Knowledge",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021869251504540443,
                    "sentence": "Goyal, Raghav and Dymetman, Marc and Gaussier, Eric and LIG, Uni",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05591089278459549,
                    "sentence": "COLING 2016",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.025047363853838715,
            "class_probabilities": {
                "human": 0.9749114577339202,
                "ai": 0.025047363853838715,
                "mixed": 4.1178412241002176e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9749114577339202,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.025047363853838715,
                    "human": 0.9749114577339202,
                    "mixed": 4.1178412241002176e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper presents two approaches for generating English poetry. The first\napproach combine a neural phonetic encoder predicting the next phoneme with a\nphonetic-orthographic HMM decoder computing the most likely word corresponding\nto a sequence of phonemes. The second approach combines a character language\nmodel with a weigthed FST to impose rythm constraints on the output of the\nlanguage model. For the second approach, the authors also present a heuristic\napproach which permit constraining the generated poem according to theme (e.g;,\nlove) or poetic devices (e.g., alliteration). The generated poems are evaluated\nboth instrinsically by comparing the rythm of the generated lines with a gold\nstandard and extrinsically by asking 70 human evaluators to (i) determine\nwhether the poem was written by a human or a machine and (ii) rate poems wrt to\nreadability, form and evocation. The results indicate that the second model\nperforms best and that human evaluators find it difficult to distinguish\nbetween human written and machine generated poems.\nThis is an interesting, clearly written article with novel ideas (two different\nmodels for poetry generation, one based on a phonetic language model the other\non a character LM) and convincing results.\n For the evaluation, more precision about the evaluators and the protocol would\nbe good. Did all evaluators evaluate all poems and if not how many judgments\nwere collected for each poem for each task ? You mention 9 non English native\nspeakers. Poems are notoriously hard to read. How fluent were these ? \nIn the second model (character based), perhaps I missed it, but do you have a\nmechanism to avoid generating non words ? If not, how frequent are non words in\nthe generated poems ?\nIn the first model, why use an HMM to transliterate from phonetic to an\norhographic representation rather than a CRF? \nSince overall, you rule out the first model as a good generic model for\ngenerating poetry, it might have been more interesting to spend less space on\nthat model and more on the evaluation of the second model. In particular, I\nwould have been interested in a more detailed discussion of the impact of the\nheuristic you use to constrain theme or poetic devices. How do these impact\nevaluation results ? Could they be combined to jointly constrain theme and\npoetic devices ? \nThe combination of a neural mode with a WFST is reminiscent of the following\npaper which combine character based neural model to generate from dialog acts\nwith an WFST to avoid generating non words. YOu should relate your work to\ntheirs and cite them. \nNatural Language Generation through Character-Based RNNs with Finite-State\nPrior Knowledge\nGoyal, Raghav and Dymetman, Marc and Gaussier, Eric and LIG, Uni\nCOLING 2016"
        }
    ]
}