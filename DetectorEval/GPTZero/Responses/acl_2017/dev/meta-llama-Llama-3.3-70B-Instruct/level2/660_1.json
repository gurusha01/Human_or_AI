{
    "version": "2025-01-09-base",
    "scanId": "245766e0-b2db-44dc-bb89-275baab0f58d",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.981309175491333,
                    "sentence": "Summary of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8618361353874207,
                    "sentence": "The paper proposes two novel methodologies for the automatic generation of rhythmic poetry in various forms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9465347528457642,
                    "sentence": "The first approach uses a neural language model trained on a phonetic encoding to learn an implicit representation of both the form and content of English poetry.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9478451609611511,
                    "sentence": "The second approach considers poetry generation as a constraint satisfaction problem, where a generative neural language model is tasked with learning a representation of content, and a discriminative weighted finite state machine constrains it on the basis of form.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9865678548812866,
                    "sentence": "Main Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9907703995704651,
                    "sentence": "1. Phonetic-level Model: The paper proposes a neural language model trained on a phonetic encoding of poetry to learn an implicit representation of both form and content.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9913414120674133,
                    "sentence": "2. Constrained Character-level Model: The paper proposes a pipeline containing a generative language model representing content, and a discriminative model representing form, allowing for the generation of poetry with arbitrary forms and themes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9913684725761414,
                    "sentence": "3. Evaluation: The paper conducts an intrinsic evaluation of the models and an extrinsic evaluation using human annotators, showing that the generated poetry is indistinguishable from human-written poetry.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9742448925971985,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9871573448181152,
                    "sentence": "1. Novel Approach: The paper proposes a novel approach to poetry generation, using phonetic encoding and constraint satisfaction to generate rhythmic poetry.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999747276306152,
                    "sentence": "2. Effective Evaluation: The paper conducts a thorough evaluation of the models, including both intrinsic and extrinsic evaluations, to demonstrate the effectiveness of the approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999788403511047,
                    "sentence": "3. High-Quality Output: The paper shows that the generated poetry is of high quality, with participants unable to distinguish it from human-written poetry.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999822378158569,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999977707862854,
                    "sentence": "1. Limited Generalizability: The phonetic-level model is limited in its ability to generalize to novel forms of verse.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999784231185913,
                    "sentence": "2. Dependence on Training Data: The models rely heavily on the quality and diversity of the training data, which may limit their ability to generate poetry in different styles or forms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999586343765259,
                    "sentence": "3. Lack of Interpretability: The paper could benefit from a more detailed analysis of the generated poetry, to understand the strengths and weaknesses of the models and identify areas for improvement.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996386766433716,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999341368675232,
                    "sentence": "1. How do the authors plan to address the limited generalizability of the phonetic-level model, and what potential solutions do they propose?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999228715896606,
                    "sentence": "2. Can the authors provide more details on the training data used for the models, and how they plan to expand the dataset to improve the diversity and quality of the generated poetry?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999273419380188,
                    "sentence": "3. How do the authors plan to improve the interpretability of the models, and what methods do they propose to analyze and understand the generated poetry?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.8119739381064363,
            "class_probabilities": {
                "human": 0.18679001347792185,
                "ai": 0.8119739381064363,
                "mixed": 0.0012360484156418805
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8119739381064363,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8119739381064363,
                    "human": 0.18679001347792185,
                    "mixed": 0.0012360484156418805
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary of the Paper\nThe paper proposes two novel methodologies for the automatic generation of rhythmic poetry in various forms. The first approach uses a neural language model trained on a phonetic encoding to learn an implicit representation of both the form and content of English poetry. The second approach considers poetry generation as a constraint satisfaction problem, where a generative neural language model is tasked with learning a representation of content, and a discriminative weighted finite state machine constrains it on the basis of form.\nMain Contributions\n1. Phonetic-level Model: The paper proposes a neural language model trained on a phonetic encoding of poetry to learn an implicit representation of both form and content.\n2. Constrained Character-level Model: The paper proposes a pipeline containing a generative language model representing content, and a discriminative model representing form, allowing for the generation of poetry with arbitrary forms and themes.\n3. Evaluation: The paper conducts an intrinsic evaluation of the models and an extrinsic evaluation using human annotators, showing that the generated poetry is indistinguishable from human-written poetry.\nStrengths\n1. Novel Approach: The paper proposes a novel approach to poetry generation, using phonetic encoding and constraint satisfaction to generate rhythmic poetry.\n2. Effective Evaluation: The paper conducts a thorough evaluation of the models, including both intrinsic and extrinsic evaluations, to demonstrate the effectiveness of the approach.\n3. High-Quality Output: The paper shows that the generated poetry is of high quality, with participants unable to distinguish it from human-written poetry.\nWeaknesses\n1. Limited Generalizability: The phonetic-level model is limited in its ability to generalize to novel forms of verse.\n2. Dependence on Training Data: The models rely heavily on the quality and diversity of the training data, which may limit their ability to generate poetry in different styles or forms.\n3. Lack of Interpretability: The paper could benefit from a more detailed analysis of the generated poetry, to understand the strengths and weaknesses of the models and identify areas for improvement.\nQuestions to Authors\n1. How do the authors plan to address the limited generalizability of the phonetic-level model, and what potential solutions do they propose?\n2. Can the authors provide more details on the training data used for the models, and how they plan to expand the dataset to improve the diversity and quality of the generated poetry?\n3. How do the authors plan to improve the interpretability of the models, and what methods do they propose to analyze and understand the generated poetry?"
        }
    ]
}