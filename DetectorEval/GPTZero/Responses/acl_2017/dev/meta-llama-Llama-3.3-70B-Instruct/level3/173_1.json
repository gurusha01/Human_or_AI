{
    "version": "2025-01-09-base",
    "scanId": "6e38c887-244b-4475-89e5-385b128d1710",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999986886978149,
                    "sentence": "This paper presents a comprehensive study on models of referential word meaning, exploring different approaches to combine visual and distributional information for object naming tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "The authors investigate three models: Direct Cross-Modal Mapping (TRANSFER), Lexical Mapping Through Individual Word Classifiers (WAC), and Word Prediction via Cross-Modal Similarity Mapping (SIM-WAP).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998927116394,
                    "sentence": "The main contributions of this work are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998152256012,
                    "sentence": "1. The authors propose a novel approach, SIM-WAP, which combines the strengths of cross-modal mapping and individual word classifiers by training predictors for each word in the vocabulary and exploiting lexical similarity relations encoded in a distributional space.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979138374329,
                    "sentence": "2. The paper provides a thorough evaluation of the three models in both standard and zero-shot object naming tasks, demonstrating that the SIM-WAP model outperforms the other two models in the zero-shot setup.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999974966049194,
                    "sentence": "3. The authors show that combining the predictions of different models can lead to improved performance, suggesting that the models capture complementary aspects of referential word meaning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963641166687,
                    "sentence": "The strengths of this paper include:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999971389770508,
                    "sentence": "1. The authors provide a clear and detailed explanation of the models and their motivations, making it easy to follow and understand the contributions of the work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999971985816956,
                    "sentence": "2. The paper presents a comprehensive evaluation of the models, including both standard and zero-shot object naming tasks, and provides insights into the strengths and weaknesses of each approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990196228027344,
                    "sentence": "3. The authors discuss the implications of their findings for referring expression generation (REG) systems and highlight potential avenues for future research.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989792704582214,
                    "sentence": "However, there are some weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.997582733631134,
                    "sentence": "1. The paper contains many grammar errors, particularly in the abstract, which can make it difficult to understand the main contributions and findings of the work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.997368335723877,
                    "sentence": "2. The authors could provide more context and background information on the related work, making it easier for readers to understand the significance and novelty of the proposed approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9975551962852478,
                    "sentence": "3. Some of the tables and figures could be improved for better readability and clarity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989008903503418,
                    "sentence": "Overall, this paper presents a significant contribution to the field of natural language processing and computer vision, and the authors' findings have important implications for the development of REG systems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5353791117668152,
                    "sentence": "Questions to authors:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7076566219329834,
                    "sentence": "1. Can you provide more details on how the SIM-WAP model is trained and how it exploits lexical similarity relations encoded in a distributional space?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7251520752906799,
                    "sentence": "2. How do you plan to scale up the findings of this work to larger test sets and more complex object naming tasks?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7609227299690247,
                    "sentence": "3. Can you discuss the potential applications of the proposed models in real-world REG systems and how they can be integrated with other components, such as attribute selection and contextual information?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.9841954571483108,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9841954571483108,
                "mixed": 0.015804542851689255
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9841954571483108,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9841954571483108,
                    "human": 0,
                    "mixed": 0.015804542851689255
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a comprehensive study on models of referential word meaning, exploring different approaches to combine visual and distributional information for object naming tasks. The authors investigate three models: Direct Cross-Modal Mapping (TRANSFER), Lexical Mapping Through Individual Word Classifiers (WAC), and Word Prediction via Cross-Modal Similarity Mapping (SIM-WAP). \nThe main contributions of this work are: \n1. The authors propose a novel approach, SIM-WAP, which combines the strengths of cross-modal mapping and individual word classifiers by training predictors for each word in the vocabulary and exploiting lexical similarity relations encoded in a distributional space.\n2. The paper provides a thorough evaluation of the three models in both standard and zero-shot object naming tasks, demonstrating that the SIM-WAP model outperforms the other two models in the zero-shot setup.\n3. The authors show that combining the predictions of different models can lead to improved performance, suggesting that the models capture complementary aspects of referential word meaning.\nThe strengths of this paper include:\n1. The authors provide a clear and detailed explanation of the models and their motivations, making it easy to follow and understand the contributions of the work.\n2. The paper presents a comprehensive evaluation of the models, including both standard and zero-shot object naming tasks, and provides insights into the strengths and weaknesses of each approach.\n3. The authors discuss the implications of their findings for referring expression generation (REG) systems and highlight potential avenues for future research.\nHowever, there are some weaknesses:\n1. The paper contains many grammar errors, particularly in the abstract, which can make it difficult to understand the main contributions and findings of the work.\n2. The authors could provide more context and background information on the related work, making it easier for readers to understand the significance and novelty of the proposed approaches.\n3. Some of the tables and figures could be improved for better readability and clarity.\nOverall, this paper presents a significant contribution to the field of natural language processing and computer vision, and the authors' findings have important implications for the development of REG systems. \nQuestions to authors:\n1. Can you provide more details on how the SIM-WAP model is trained and how it exploits lexical similarity relations encoded in a distributional space?\n2. How do you plan to scale up the findings of this work to larger test sets and more complex object naming tasks?\n3. Can you discuss the potential applications of the proposed models in real-world REG systems and how they can be integrated with other components, such as attribute selection and contextual information?"
        }
    ]
}