{
    "version": "2025-01-09-base",
    "scanId": "986faab7-b801-4768-8590-056c955e14ea",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999901652336121,
                    "sentence": "Review",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986290931702,
                    "sentence": "Summary and Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963641166687,
                    "sentence": "This paper proposes a novel neural architecture for text coherence modeling, leveraging convolutional neural networks (CNNs) applied to the entity grid representation of text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999949932098389,
                    "sentence": "The authors address key limitations of traditional entity grid models, such as their reliance on discrete representations and task-agnostic feature extraction, by introducing distributed representations and end-to-end training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999993085861206,
                    "sentence": "The model captures long-range entity transitions and incorporates entity-specific features, achieving state-of-the-art results on three coherence assessment tasks: discrimination, insertion, and summary coherence rating.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999993622303009,
                    "sentence": "The authors also release their code, enhancing reproducibility.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999839663505554,
                    "sentence": "The main contributions of the paper are as follows:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999812841415405,
                    "sentence": "1. Neuralization of Entity Grid Models: The paper introduces a CNN-based architecture that operates on distributed representations of entity grids, enabling the modeling of longer entity transitions and improving generalization.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999836087226868,
                    "sentence": "2. Task-Specific Feature Learning: The proposed end-to-end training framework allows the model to learn task-specific high-level features automatically, addressing a key limitation of traditional grid models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999912977218628,
                    "sentence": "3. Empirical Validation: The model demonstrates significant performance improvements over existing methods on three coherence evaluation tasks, including a 4% gain in discrimination accuracy and a 2.5% gain in insertion accuracy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999939799308777,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999885559082031,
                    "sentence": "1. Novelty and Technical Contribution: The paper successfully adapts CNNs to the entity grid framework, a well-established approach in text coherence modeling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999977707862854,
                    "sentence": "This innovation addresses the dimensionality and feature extraction challenges of traditional models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999861121177673,
                    "sentence": "2. Empirical Rigor: The authors evaluate their model on three distinct tasks using widely accepted datasets, demonstrating consistent improvements over baseline and state-of-the-art methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999876618385315,
                    "sentence": "The use of pretraining and fine-tuning for the summary coherence task is particularly noteworthy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999896883964539,
                    "sentence": "3. Reproducibility: The release of code and detailed descriptions of the model architecture and hyperparameter tuning enhance the paper's reproducibility and potential impact on the field.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999935626983643,
                    "sentence": "4. Scalability: The model's ability to handle longer entity transitions without overfitting is a significant improvement over traditional grid models, which are constrained to short transitions (k â ¤ 3).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999892711639404,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999945759773254,
                    "sentence": "1. Limited Scope of Entity-Specific Features: While the model incorporates entity-specific features, it uses only three simple features (e.g., named entity type, salience).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999896883964539,
                    "sentence": "Incorporating richer features, such as rhetorical relations or semantic roles, could further enhance performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.04721755161881447,
                    "sentence": "2. Task-Specific Training: The model is trained on the discrimination task and evaluated on insertion without task-specific fine-tuning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.05117505416274071,
                    "sentence": "This may limit its effectiveness on the insertion task, as evidenced by the smaller performance gains in this setting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.09743200987577438,
                    "sentence": "3. Dataset Dependence: The model's strong performance is demonstrated primarily on the WSJ dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.06372402608394623,
                    "sentence": "While this dataset is larger and more diverse than others, additional experiments on varied domains (e.g., conversational or narrative texts) would strengthen the generalizability claims.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.08989634364843369,
                    "sentence": "4. Comparison with Recent Neural Models: The paper excludes results from Li and Hovy (2014) due to poor performance on the WSJ dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.2205793857574463,
                    "sentence": "However, a deeper analysis of why this method underperformed would provide valuable insights and contextualize the contributions of the proposed model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9715730547904968,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.997725248336792,
                    "sentence": "1. Have you considered incorporating richer entity-specific features, such as semantic roles or rhetorical relations, into the model?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995583295822144,
                    "sentence": "If so, what challenges did you encounter?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991031885147095,
                    "sentence": "2. How does the model perform on datasets beyond WSJ, such as conversational or narrative texts?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995179176330566,
                    "sentence": "Would the convolutional approach generalize to these domains?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995415806770325,
                    "sentence": "3. Could the model be trained directly on the insertion task?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989781379699707,
                    "sentence": "If so, how would this affect performance compared to training on discrimination?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9983117580413818,
                    "sentence": "Conclusion",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999700665473938,
                    "sentence": "This paper presents a significant advancement in text coherence modeling by introducing a CNN-based approach to the entity grid framework.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995917081832886,
                    "sentence": "Despite some limitations in feature richness and task-specific training, the model's strong empirical performance and innovative design make it a valuable contribution to the field.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9966440796852112,
                    "sentence": "I recommend acceptance, with minor revisions to address the noted weaknesses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 0.958904109589041,
            "class_probabilities": {
                "human": 0,
                "ai": 0.958904109589041,
                "mixed": 0.041095890410958895
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.958904109589041,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.958904109589041,
                    "human": 0,
                    "mixed": 0.041095890410958895
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Review\nSummary and Contributions\nThis paper proposes a novel neural architecture for text coherence modeling, leveraging convolutional neural networks (CNNs) applied to the entity grid representation of text. The authors address key limitations of traditional entity grid models, such as their reliance on discrete representations and task-agnostic feature extraction, by introducing distributed representations and end-to-end training. The model captures long-range entity transitions and incorporates entity-specific features, achieving state-of-the-art results on three coherence assessment tasks: discrimination, insertion, and summary coherence rating. The authors also release their code, enhancing reproducibility.\nThe main contributions of the paper are as follows:\n1. Neuralization of Entity Grid Models: The paper introduces a CNN-based architecture that operates on distributed representations of entity grids, enabling the modeling of longer entity transitions and improving generalization.\n2. Task-Specific Feature Learning: The proposed end-to-end training framework allows the model to learn task-specific high-level features automatically, addressing a key limitation of traditional grid models.\n3. Empirical Validation: The model demonstrates significant performance improvements over existing methods on three coherence evaluation tasks, including a 4% gain in discrimination accuracy and a 2.5% gain in insertion accuracy.\nStrengths\n1. Novelty and Technical Contribution: The paper successfully adapts CNNs to the entity grid framework, a well-established approach in text coherence modeling. This innovation addresses the dimensionality and feature extraction challenges of traditional models.\n2. Empirical Rigor: The authors evaluate their model on three distinct tasks using widely accepted datasets, demonstrating consistent improvements over baseline and state-of-the-art methods. The use of pretraining and fine-tuning for the summary coherence task is particularly noteworthy.\n3. Reproducibility: The release of code and detailed descriptions of the model architecture and hyperparameter tuning enhance the paper's reproducibility and potential impact on the field.\n4. Scalability: The model's ability to handle longer entity transitions without overfitting is a significant improvement over traditional grid models, which are constrained to short transitions (k â ¤ 3).\nWeaknesses\n1. Limited Scope of Entity-Specific Features: While the model incorporates entity-specific features, it uses only three simple features (e.g., named entity type, salience). Incorporating richer features, such as rhetorical relations or semantic roles, could further enhance performance.\n2. Task-Specific Training: The model is trained on the discrimination task and evaluated on insertion without task-specific fine-tuning. This may limit its effectiveness on the insertion task, as evidenced by the smaller performance gains in this setting.\n3. Dataset Dependence: The model's strong performance is demonstrated primarily on the WSJ dataset. While this dataset is larger and more diverse than others, additional experiments on varied domains (e.g., conversational or narrative texts) would strengthen the generalizability claims.\n4. Comparison with Recent Neural Models: The paper excludes results from Li and Hovy (2014) due to poor performance on the WSJ dataset. However, a deeper analysis of why this method underperformed would provide valuable insights and contextualize the contributions of the proposed model.\nQuestions to Authors\n1. Have you considered incorporating richer entity-specific features, such as semantic roles or rhetorical relations, into the model? If so, what challenges did you encounter?\n2. How does the model perform on datasets beyond WSJ, such as conversational or narrative texts? Would the convolutional approach generalize to these domains?\n3. Could the model be trained directly on the insertion task? If so, how would this affect performance compared to training on discrimination?\nConclusion\nThis paper presents a significant advancement in text coherence modeling by introducing a CNN-based approach to the entity grid framework. Despite some limitations in feature richness and task-specific training, the model's strong empirical performance and innovative design make it a valuable contribution to the field. I recommend acceptance, with minor revisions to address the noted weaknesses."
        }
    ]
}