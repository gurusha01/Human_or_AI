{
    "version": "2025-01-09-base",
    "scanId": "53814cb5-b1a6-4f4b-b0e1-91ea4c224ca4",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.7194104790687561,
                    "sentence": "- Strengths: A well written paper, examining the use of context in lexical",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6455029249191284,
                    "sentence": "entailment task is a great idea, a well defined approach and experimental",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6365208029747009,
                    "sentence": "set-up and good analysis of the results",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7455770969390869,
                    "sentence": "- Weaknesses: Some information is missing or insufficient, e.g., the table",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6411565542221069,
                    "sentence": "captions should be more descriptive, a clear description for each of the word",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5281069874763489,
                    "sentence": "type features should be given.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7102558612823486,
                    "sentence": "General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7700020670890808,
                    "sentence": "The paper presents a proposal of consideration of context",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7127105593681335,
                    "sentence": "in lexical entailment task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6827576160430908,
                    "sentence": "The results from the experiments demonstrate that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7796390056610107,
                    "sentence": "context-informed models do better than context-agnostic models on the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7192556858062744,
                    "sentence": "entailment task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17286834120750427,
                    "sentence": "I liked the idea of creating negative examples to get negative annotations",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3013935983181,
                    "sentence": "automatically in the two ways described in the paper based on WordNet positive",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.26757338643074036,
                    "sentence": "examples.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.22526618838310242,
                    "sentence": "(new dataset; an interesting method to develop dataset)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16787074506282806,
                    "sentence": "I also liked the idea of transforming already-used context-agnostic",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15981170535087585,
                    "sentence": "representations into contextualized representations, experimenting with",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06845590472221375,
                    "sentence": "different ways to get contextualized representations (i.e., mask vs",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13776589930057526,
                    "sentence": "contetx2vec), and testing the model on 3 different datasets (generalizability",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08652979135513306,
                    "sentence": "not just across different datasets but also cross-linguistically).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09823030233383179,
                    "sentence": "Motivations for various decisions in the experimental design were good to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05591574311256409,
                    "sentence": "see, e.g., why authors used the split they used for CONTEXT-PPDB (it showed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07120363414287567,
                    "sentence": "that they thought out clearly what exactly they were doing and why).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11156073957681656,
                    "sentence": "Lines 431-434: authors might want to state briefly how the class weights were",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12463048100471497,
                    "sentence": "determined and added to account for the unbalanced data in the CONTEXT-WN",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0680389404296875,
                    "sentence": "experiments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09083670377731323,
                    "sentence": "Would it affect direct comparisons with previous work, in what",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17598266899585724,
                    "sentence": "ways?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14982685446739197,
                    "sentence": "Change in Line 589: directionality 4 --> directionality, as in Table 4",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11842081695795059,
                    "sentence": "Suggested change in Line 696-697: is-a hierarchy of WordNet --> \"is-a\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10834790766239166,
                    "sentence": "hierarchy of WordNet",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1433015912771225,
                    "sentence": "For the sake of completeness, represent \"mask\" also in Figure 1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21868498623371124,
                    "sentence": "I have read the author response.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.39158061953931694,
            "class_probabilities": {
                "human": 0.5988880063542494,
                "ai": 0.39158061953931694,
                "mixed": 0.009531374106433677
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.5988880063542494,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.39158061953931694,
                    "human": 0.5988880063542494,
                    "mixed": 0.009531374106433677
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "- Strengths: A well written paper, examining the use of context in lexical\nentailment task is a great idea, a well defined approach and experimental\nset-up and good analysis of the results \n- Weaknesses: Some information is missing or insufficient, e.g., the table\ncaptions should be more descriptive, a clear description for each of the word\ntype features should be given.\nGeneral Discussion: \nThe paper presents a proposal of consideration of context\nin lexical entailment task. The results from the experiments demonstrate that\ncontext-informed models do better than context-agnostic models on the\nentailment task. \nI liked the idea of creating negative examples to get negative annotations\nautomatically in the two ways described in the paper based on WordNet positive\nexamples. (new dataset; an interesting method to develop dataset)\nI also liked the idea of transforming already-used context-agnostic\nrepresentations into contextualized representations, experimenting with\ndifferent ways to get contextualized representations (i.e., mask vs\ncontetx2vec), and testing the model on 3 different datasets (generalizability\nnot just across different datasets but also cross-linguistically).\nMotivations for various decisions in the experimental design were good to\nsee, e.g., why authors used the split they used for CONTEXT-PPDB (it showed\nthat they thought out clearly what exactly they were doing and why).\nLines 431-434: authors might want to state briefly how the class weights were\ndetermined and added to account for the unbalanced data in the CONTEXT-WN\nexperiments. Would it affect direct comparisons with previous work, in what\nways? \nChange in Line 589: directionality 4 --> directionality, as in Table 4\nSuggested change in Line 696-697: is-a hierarchy of WordNet --> \"is-a\"\nhierarchy of WordNet \nFor the sake of completeness, represent \"mask\" also in Figure 1.\nI have read the author response."
        }
    ]
}