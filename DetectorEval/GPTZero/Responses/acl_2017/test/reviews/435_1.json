{
    "version": "2025-01-09-base",
    "scanId": "bf65cbde-a259-4fae-9ab3-d7e3ff427d8c",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.797908365726471,
                    "sentence": "This paper develops an LSTM-based model for classifying connective uses for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.698828935623169,
                    "sentence": "whether they indicate that a causal relation was intended.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5049328207969666,
                    "sentence": "The guiding idea is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.40635961294174194,
                    "sentence": "that the expression of causal relations is extremely diverse and thus not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.355518639087677,
                    "sentence": "amenable to syntactic treatment, and that the more abstract representations",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.46963801980018616,
                    "sentence": "delivered by neural models are therefore more suitable as the basis for making",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2403523474931717,
                    "sentence": "these decisions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5547996759414673,
                    "sentence": "The experiments are on the AltLex corpus developed by Hidley and McKeown.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9496256113052368,
                    "sentence": "The",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6587259769439697,
                    "sentence": "results offer modest but consistent support for the general idea, and they",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6951307654380798,
                    "sentence": "provide some initial insights into how best to translate this idea into a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8211302161216736,
                    "sentence": "model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7380341291427612,
                    "sentence": "The paper distribution includes the TensorFlow-based models used for the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.608396053314209,
                    "sentence": "experiments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.758929967880249,
                    "sentence": "Some critical comments and questions:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.513994038105011,
                    "sentence": "* The introduction is unusual in that it is more like a literature review than",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6888642907142639,
                    "sentence": "a full overview of what the paper contains.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5114477276802063,
                    "sentence": "This leads to some redundancy with",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5914064049720764,
                    "sentence": "the related work section that follows it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6279650926589966,
                    "sentence": "I guess I am open to a non-standard",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5806424617767334,
                    "sentence": "sort of intro, but this one really doesn't work: despite reviewing a lot of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6113950610160828,
                    "sentence": "ideas, it doesn't take a stand on what causation is or how it is expressed, but",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6706740260124207,
                    "sentence": "rather only makes a negative point (it's not reducible to syntax).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4507759213447571,
                    "sentence": "We aren't",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7612149715423584,
                    "sentence": "really told what the positive contribution will be except for the very general",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7141266465187073,
                    "sentence": "final paragraph of the section.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7343263626098633,
                    "sentence": "* Extending the above, I found it disappointing that the paper isn't really",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.898196280002594,
                    "sentence": "clear about the theory of causation being assumed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8273332118988037,
                    "sentence": "The authors seem to default",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7997784614562988,
                    "sentence": "to a counterfactual view that is broadly like that of David Lewis, where",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8791565299034119,
                    "sentence": "causation is a modal sufficiency claim with some other counterfactual",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8894437551498413,
                    "sentence": "conditions added to it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8561223745346069,
                    "sentence": "See line 238 and following; that arrow needs to be a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8461458086967468,
                    "sentence": "very special kind of implication for this to work at all, and there are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8832693099975586,
                    "sentence": "well-known problems with Lewis's theory (see",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00459709670394659,
                    "sentence": "http://bcopley.com/wp-content/uploads/CopleyWolff2014.pdf).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004918716847896576,
                    "sentence": "There are comments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008438298478722572,
                    "sentence": "elsewhere in the paper that the authors don't endorse the counterfactual view,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004754872526973486,
                    "sentence": "but then what is the theory being assumed?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005541401449590921,
                    "sentence": "It can't just be the temporal",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018820542842149734,
                    "sentence": "constraint mentioned on page 3!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01045098528265953,
                    "sentence": "* I don't understand the comments regarding the example on line 256.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003513013245537877,
                    "sentence": "The",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022623619064688683,
                    "sentence": "authors seem to be saying that they regard the sentence as false.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007905474863946438,
                    "sentence": "If it's true,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.024152671918272972,
                    "sentence": "then there should be some causal link between the argument and the breakage.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02525223419070244,
                    "sentence": "There are remaining issues about how to divide events into sub-events, and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03021221049129963,
                    "sentence": "these impact causal theories, but those are not being discussed here, leaving",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008684715256094933,
                    "sentence": "me confused.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019954653456807137,
                    "sentence": "* The caption for Figure 1 is misleading, since the diagram is supposed to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0344373993575573,
                    "sentence": "depict only the \"Pair_LSTM\" variant of the model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.024559877812862396,
                    "sentence": "My bigger complaint is that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05437145009636879,
                    "sentence": "this diagram is needlessly imprecise.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.029440609738230705,
                    "sentence": "I suppose it's okay to leave parts of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022541185840964317,
                    "sentence": "standard model definition out of the prose, but then these diagrams should have",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0338444858789444,
                    "sentence": "a clear and consistent semantics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03279346227645874,
                    "sentence": "What are all the empty circles between input",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026283573359251022,
                    "sentence": "and the \"LSTM\" boxes?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018618373200297356,
                    "sentence": "The prose seems to say that the model has a look-up",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026660868898034096,
                    "sentence": "layer, a Glove layer, and then... what?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01212017610669136,
                    "sentence": "How many layers of representation are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05459482595324516,
                    "sentence": "there?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03377499803900719,
                    "sentence": "The diagram is precise about the pooling tanh layers pre-softmax, but",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.015838630497455597,
                    "sentence": "not about this.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02362317591905594,
                    "sentence": "I'm also not clear on what the \"LSTM\" boxes represent.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01574834994971752,
                    "sentence": "It seems",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02203785814344883,
                    "sentence": "like it's just the leftmost/final representation that is directly connected to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02391824498772621,
                    "sentence": "the layers above.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02151317335665226,
                    "sentence": "I suggest depicting that connection clearly.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027917975559830666,
                    "sentence": "* I don't understand the sentence beginning on line 480.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03397399187088013,
                    "sentence": "The models under",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03557305037975311,
                    "sentence": "discussion do not intrinsically require any padding.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010275380685925484,
                    "sentence": "I'm guessing this is a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03370977193117142,
                    "sentence": "requirement of TensorFlow and/or efficient training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03519698977470398,
                    "sentence": "That's fine.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027673130854964256,
                    "sentence": "If that's",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9133080840110779,
                    "sentence": "correct, please say that.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9614412784576416,
                    "sentence": "I don't understand the final clause, though.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9224157333374023,
                    "sentence": "How is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9181194305419922,
                    "sentence": "this issue even related to the question of what is \"the most convenient way to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.961729109287262,
                    "sentence": "encode the causal meaning\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9417626857757568,
                    "sentence": "I don't see how convenience is an issue or how this",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9152891039848328,
                    "sentence": "relates directly to causal meaning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9356405138969421,
                    "sentence": "* The authors find that having two independent LSTMs (\"Stated_LSTM\") is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9524329900741577,
                    "sentence": "somewhat better than one where the first feeds into the second.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9512176513671875,
                    "sentence": "This issue is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9740538597106934,
                    "sentence": "reminiscent of discussions in the literature on natural language entailment,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9573873281478882,
                    "sentence": "where the question is whether to represent premise and hypothesis independently",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9743914604187012,
                    "sentence": "or have the first feed into the second.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8681297898292542,
                    "sentence": "I regard this as an open question for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9396787881851196,
                    "sentence": "entailment, and I bet it needs further investigation for causal relations too.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8565504550933838,
                    "sentence": "So I can't really endorse the sentence beginning on line 587: \"This behaviour",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9660205841064453,
                    "sentence": "means that our assumption about the relation between the meanings of the two",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9599336981773376,
                    "sentence": "input events does not hold, so it is better to encode each argument",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9319403171539307,
                    "sentence": "independently and then to measure the relation between the arguments by using",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.978114128112793,
                    "sentence": "dense layers.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9498641490936279,
                    "sentence": "This is very surprising since we are talking about subparts of a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9697918891906738,
                    "sentence": "sentence that might share a lot of information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9615234732627869,
                    "sentence": "* It's hard to make sense of the hyperparameters that led to the best",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.971975564956665,
                    "sentence": "performance across tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.902350902557373,
                    "sentence": "Compare line 578 with line 636, for example.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7572309970855713,
                    "sentence": "Should",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8919527530670166,
                    "sentence": "we interpret this or just attribute it to the unpredictability of how these",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9695676565170288,
                    "sentence": "models interact with data?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9261746406555176,
                    "sentence": "* Section 4.3 concludes by saying, of the connective 'which then', that the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8220971822738647,
                    "sentence": "system can \"correctly disambiguate its causal meaning\", whereas that of Hidey",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9177799820899963,
                    "sentence": "and McKeown does not.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8489697575569153,
                    "sentence": "That might be correct, but one example doesn't suffice to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.948403000831604,
                    "sentence": "show it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9345287680625916,
                    "sentence": "To substantiate this point, I suggest making up a wide range of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9387716054916382,
                    "sentence": "examples that manifest the ambiguity and seeing how often the system delivers",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9072479605674744,
                    "sentence": "the right verdict.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8759260177612305,
                    "sentence": "This will help address the question of whether it got lucky",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6962214112281799,
                    "sentence": "with the example from table 8.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.3063829682933457
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.3063829682933457
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 59,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 63,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 66,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 67,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 69,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 71,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 73,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 76,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 79,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 80,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 82,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 83,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 84,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 86,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 87,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 88,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 90,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 91,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 92,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 93,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 94,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 95,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 97,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 98,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 99,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.45887534985363754
                },
                {
                    "start_sentence_index": 102,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 103,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 104,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 105,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 106,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 108,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 110,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 111,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 113,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.30862404391972925,
            "class_probabilities": {
                "human": 0.6912808420031116,
                "ai": 0.30862404391972925,
                "mixed": 9.511407715911251e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.6912808420031116,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.30862404391972925,
                    "human": 0.6912808420031116,
                    "mixed": 9.511407715911251e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper develops an LSTM-based model for classifying connective uses for\nwhether they indicate that a causal relation was intended. The guiding idea is\nthat the expression of causal relations is extremely diverse and thus not\namenable to syntactic treatment, and that the more abstract representations\ndelivered by neural models are therefore more suitable as the basis for making\nthese decisions.\nThe experiments are on the AltLex corpus developed by Hidley and McKeown. The\nresults offer modest but consistent support for the general idea, and they\nprovide some initial insights into how best to translate this idea into a\nmodel. The paper distribution includes the TensorFlow-based models used for the\nexperiments.\nSome critical comments and questions:\n* The introduction is unusual in that it is more like a literature review than\na full overview of what the paper contains. This leads to some redundancy with\nthe related work section that follows it. I guess I am open to a non-standard\nsort of intro, but this one really doesn't work: despite reviewing a lot of\nideas, it doesn't take a stand on what causation is or how it is expressed, but\nrather only makes a negative point (it's not reducible to syntax). We aren't\nreally told what the positive contribution will be except for the very general\nfinal paragraph of the section.\n* Extending the above, I found it disappointing that the paper isn't really\nclear about the theory of causation being assumed. The authors seem to default\nto a counterfactual view that is broadly like that of David Lewis, where\ncausation is a modal sufficiency claim with some other counterfactual\nconditions added to it. See line 238 and following; that arrow needs to be a\nvery special kind of implication for this to work at all, and there are\nwell-known problems with Lewis's theory (see\nhttp://bcopley.com/wp-content/uploads/CopleyWolff2014.pdf). There are comments\nelsewhere in the paper that the authors don't endorse the counterfactual view,\nbut then what is the theory being assumed? It can't just be the temporal\nconstraint mentioned on page 3!\n* I don't understand the comments regarding the example on line 256. The\nauthors seem to be saying that they regard the sentence as false. If it's true,\nthen there should be some causal link between the argument and the breakage.\nThere are remaining issues about how to divide events into sub-events, and\nthese impact causal theories, but those are not being discussed here, leaving\nme confused.\n* The caption for Figure 1 is misleading, since the diagram is supposed to\ndepict only the \"Pair_LSTM\" variant of the model. My bigger complaint is that\nthis diagram is needlessly imprecise. I suppose it's okay to leave parts of the\nstandard model definition out of the prose, but then these diagrams should have\na clear and consistent semantics. What are all the empty circles between input\nand the \"LSTM\" boxes? The prose seems to say that the model has a look-up\nlayer, a Glove layer, and then ... what? How many layers of representation are\nthere? The diagram is precise about the pooling tanh layers pre-softmax, but\nnot about this. I'm also not clear on what the \"LSTM\" boxes represent. It seems\nlike it's just the leftmost/final representation that is directly connected to\nthe layers above. I suggest depicting that connection clearly.\n* I don't understand the sentence beginning on line 480. The models under\ndiscussion do not intrinsically require any padding. I'm guessing this is a\nrequirement of TensorFlow and/or efficient training. That's fine. If that's\ncorrect, please say that. I don't understand the final clause, though. How is\nthis issue even related to the question of what is \"the most convenient way to\nencode the causal meaning\"? I don't see how convenience is an issue or how this\nrelates directly to causal meaning.\n* The authors find that having two independent LSTMs (\"Stated_LSTM\") is\nsomewhat better than one where the first feeds into the second. This issue is\nreminiscent of discussions in the literature on natural language entailment,\nwhere the question is whether to represent premise and hypothesis independently\nor have the first feed into the second. I regard this as an open question for\nentailment, and I bet it needs further investigation for causal relations too.\nSo I can't really endorse the sentence beginning on line 587: \"This behaviour\nmeans that our assumption about the relation between the meanings of the two\ninput events does not hold, so it is better to encode each argument\nindependently and then to measure the relation between the arguments by using\ndense layers.\" This is very surprising since we are talking about subparts of a\nsentence that might share a lot of information.\n* It's hard to make sense of the hyperparameters that led to the best\nperformance across tasks. Compare line 578 with line 636, for example. Should\nwe interpret this or just attribute it to the unpredictability of how these\nmodels interact with data?\n* Section 4.3 concludes by saying, of the connective 'which then', that the\nsystem can \"correctly disambiguate its causal meaning\", whereas that of Hidey\nand McKeown does not. That might be correct, but one example doesn't suffice to\nshow it. To substantiate this point, I suggest making up a wide range of\nexamples that manifest the ambiguity and seeing how often the system delivers\nthe right verdict. This will help address the question of whether it got lucky\nwith the example from table 8."
        }
    ]
}