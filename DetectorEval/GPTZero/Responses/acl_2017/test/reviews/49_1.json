{
    "version": "2025-01-09-base",
    "scanId": "82b1c950-6d9a-44ad-ae2f-2e130dc05126",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.014796855859458447,
                    "sentence": "- Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02812606282532215,
                    "sentence": "The paper presents an interesting extension to attention-based neural MT",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018022170290350914,
                    "sentence": "approaches, which leverages source-sentence chunking as additional piece of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014351225458085537,
                    "sentence": "information from the source sentence.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01288106944411993,
                    "sentence": "The model is modified such that this",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02670123428106308,
                    "sentence": "chunking information is used differently by two recurrent layers: while one",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04714076966047287,
                    "sentence": "focuses in generating a chunk at a time, the other focuses on generating the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04174892604351044,
                    "sentence": "words within the chunk.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027689343318343163,
                    "sentence": "This is interesting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01868024840950966,
                    "sentence": "I believe readers will enjoy",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03777460753917694,
                    "sentence": "getting to know this approach and how it performs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.042651042342185974,
                    "sentence": "The paper is very clearly written, and alternative approaches are clearly",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.040743637830019,
                    "sentence": "contrasted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03804998844861984,
                    "sentence": "The evaluation is well conducted, has a direct contrast with other",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.020655449479818344,
                    "sentence": "papers (and evaluation tables), and even though it could be strengthened (see",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014690853655338287,
                    "sentence": "my comments below), it is convincing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04374917224049568,
                    "sentence": "- Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009808776900172234,
                    "sentence": "As always, more could be done in the experiments section to strengthen the case",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02896507829427719,
                    "sentence": "for chunk-based models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012088742107152939,
                    "sentence": "For example, Table 3 indicates good results for Model 2",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014810455963015556,
                    "sentence": "and Model 3 compared to previous papers, but a careful reader will wonder",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012632103636860847,
                    "sentence": "whether these improvements come from switching from LSTMs to GRUs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006336540915071964,
                    "sentence": "In other",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014945490285754204,
                    "sentence": "words, it would be good to see the GRU tree-to-sequence result to verify that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027544258162379265,
                    "sentence": "the chunk-based approach is still best.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011106859892606735,
                    "sentence": "Another important aspect is the lack of ensembling results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02545410394668579,
                    "sentence": "The authors put a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02483256533741951,
                    "sentence": "lot of emphasis is claiming that this is the best single NMT model ever",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.221815288066864,
                    "sentence": "published.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03265863656997681,
                    "sentence": "While this is probably true, in the end the best WAT system for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.038019340485334396,
                    "sentence": "Eng-Jap is at 38.20 (if I'm reading the table correctly) - it's an ensemble of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021875791251659393,
                    "sentence": "3. If the authors were able to report that their 3-way chunk-based ensemble",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017210692167282104,
                    "sentence": "comes top of the table, then this paper could have a much stronger impact.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014971970580518246,
                    "sentence": "Finally, Table 3 would be more interesting if it included decoding times.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.031894344836473465,
                    "sentence": "The",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008144144900143147,
                    "sentence": "authors mention briefly that the character-based model is less time-consuming",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009991686791181564,
                    "sentence": "(presumably based on Eriguchi et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010390159673988819,
                    "sentence": "'16), but no cite is provided, and no",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011808897368609905,
                    "sentence": "numbers from chunk-based decoding are reported either.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007948613725602627,
                    "sentence": "Is the chunk-based model",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007656278554350138,
                    "sentence": "faster or slower than word-based?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010370712727308273,
                    "sentence": "Similar?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.019701126962900162,
                    "sentence": "Who know...",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004768822342157364,
                    "sentence": "Adding a column to Table",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009672951884567738,
                    "sentence": "3 with decoding times would give more value to the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023307230323553085,
                    "sentence": "- General Discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006285978015512228,
                    "sentence": "Overall I think the paper is interesting and worth publishing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008406776003539562,
                    "sentence": "I have minor",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010195014998316765,
                    "sentence": "comments and suggestions to the authors about how to improve their presentation",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009128594771027565,
                    "sentence": "(in my opinion, of course).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02804437465965748,
                    "sentence": "* I think they should clearly state early on that the chunks are supplied",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07384376227855682,
                    "sentence": "externally - in other words, that the model does not learn how to chunk.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.058538880199193954,
                    "sentence": "This",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10894525051116943,
                    "sentence": "only became apparent to me when reading about CaboCha on page 6 - I don't think",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06440731883049011,
                    "sentence": "it's mentioned earlier, and it is important.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06843248754739761,
                    "sentence": "* I don't see why the authors contrast against the char-based baseline so often",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09525882452726364,
                    "sentence": "in the text (at least a couple of times they boast a +4.68 BLEU gain).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.039986323565244675,
                    "sentence": "I don't",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11161032319068909,
                    "sentence": "think readers are bothered...",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08590424060821533,
                    "sentence": "Readers are interested in gains over the best",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08097324520349503,
                    "sentence": "baseline.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1163083016872406,
                    "sentence": "* It would be good to add a bit more detail about the way UNKs are being",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17316676676273346,
                    "sentence": "handled by the neural decoder, or at least add a citation to the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15331722795963287,
                    "sentence": "dictionary-based replacement strategy being used here.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12512922286987305,
                    "sentence": "* The sentence in line 212 (\"We train a GRU that encodes a source sentence into",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0745551586151123,
                    "sentence": "a single vector\") is not strictly correct.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0938752293586731,
                    "sentence": "The correct way would be to say that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10188313573598862,
                    "sentence": "you do a bidirectional encoder that encodes the source sentence into a set of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08909520506858826,
                    "sentence": "vectors... at least, that's what I see in Figure 2.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.066046342253685,
                    "sentence": "* The motivating example of lines 69-87 is a bit weird.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.050204940140247345,
                    "sentence": "Does \"you\" depend on",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07354182749986649,
                    "sentence": "\"bite\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08322754502296448,
                    "sentence": "Or does it depend on the source side?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06819744408130646,
                    "sentence": "Because if it doesn't depend on",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1043144017457962,
                    "sentence": "\"bite\", then the argument that this is a long-dependency problem doesn't really",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14780078828334808,
                    "sentence": "apply.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 63,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 64,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 65,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 67,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 68,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 69,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 71,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 74,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 75,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.06040878407802044,
            "class_probabilities": {
                "human": 0.9393019591459637,
                "ai": 0.06040878407802044,
                "mixed": 0.0002892567760158828
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9393019591459637,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.06040878407802044,
                    "human": 0.9393019591459637,
                    "mixed": 0.0002892567760158828
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "- Strengths:\nThe paper presents an interesting extension to attention-based neural MT\napproaches, which leverages source-sentence chunking as additional piece of\ninformation from the source sentence. The model is modified such that this\nchunking information is used differently by two recurrent layers: while one\nfocuses in generating a chunk at a time, the other focuses on generating the\nwords within the chunk. This is interesting. I believe readers will enjoy\ngetting to know this approach and how it performs.\nThe paper is very clearly written, and alternative approaches are clearly\ncontrasted. The evaluation is well conducted, has a direct contrast with other\npapers (and evaluation tables), and even though it could be strengthened (see\nmy comments below), it is convincing.\n- Weaknesses:\nAs always, more could be done in the experiments section to strengthen the case\nfor chunk-based models. For example, Table 3 indicates good results for Model 2\nand Model 3 compared to previous papers, but a careful reader will wonder\nwhether these improvements come from switching from LSTMs to GRUs. In other\nwords, it would be good to see the GRU tree-to-sequence result to verify that\nthe chunk-based approach is still best.\nAnother important aspect is the lack of ensembling results. The authors put a\nlot of emphasis is claiming that this is the best single NMT model ever\npublished. While this is probably true, in the end the best WAT system for\nEng-Jap is at 38.20 (if I'm reading the table correctly) - it's an ensemble of\n3. If the authors were able to report that their 3-way chunk-based ensemble\ncomes top of the table, then this paper could have a much stronger impact.\nFinally, Table 3 would be more interesting if it included decoding times. The\nauthors mention briefly that the character-based model is less time-consuming\n(presumably based on Eriguchi et al.'16), but no cite is provided, and no\nnumbers from chunk-based decoding are reported either. Is the chunk-based model\nfaster or slower than word-based? Similar? Who know... Adding a column to Table\n3 with decoding times would give more value to the paper.\n- General Discussion:\nOverall I think the paper is interesting and worth publishing. I have minor\ncomments and suggestions to the authors about how to improve their presentation\n(in my opinion, of course). \n* I think they should clearly state early on that the chunks are supplied\nexternally - in other words, that the model does not learn how to chunk. This\nonly became apparent to me when reading about CaboCha on page 6 - I don't think\nit's mentioned earlier, and it is important.\n* I don't see why the authors contrast against the char-based baseline so often\nin the text (at least a couple of times they boast a +4.68 BLEU gain). I don't\nthink readers are bothered... Readers are interested in gains over the best\nbaseline.\n* It would be good to add a bit more detail about the way UNKs are being\nhandled by the neural decoder, or at least add a citation to the\ndictionary-based replacement strategy being used here.\n* The sentence in line 212 (\"We train a GRU that encodes a source sentence into\na single vector\") is not strictly correct. The correct way would be to say that\nyou do a bidirectional encoder that encodes the source sentence into a set of\nvectors... at least, that's what I see in Figure 2.\n* The motivating example of lines 69-87 is a bit weird. Does \"you\" depend on\n\"bite\"? Or does it depend on the source side? Because if it doesn't depend on\n\"bite\", then the argument that this is a long-dependency problem doesn't really\napply."
        }
    ]
}