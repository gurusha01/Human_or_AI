{
    "version": "2025-01-09-base",
    "scanId": "8cf3181b-3028-473d-8c5a-77b4ce122e2a",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.02588612399995327,
                    "sentence": "- Strengths: The authors have nice coverage of a different range of language",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03384740650653839,
                    "sentence": "settings to isolate the way that relatedness and amount of morphology interact",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.047550592571496964,
                    "sentence": "(i.e., translating between closely related morphologically rich languages vs",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05128972977399826,
                    "sentence": "distant ones) in affecting what the system learns about morphology.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0228215754032135,
                    "sentence": "They",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04413598030805588,
                    "sentence": "include an illuminating analysis of what parts of the architecture end up being",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03370624780654907,
                    "sentence": "responsible for learning morphology, particularly in examining how the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05824176222085953,
                    "sentence": "attention mechanism leads to more impoverished target side representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0803234800696373,
                    "sentence": "Their findings are of high interest and practical usefulness for other users of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06860386580228806,
                    "sentence": "NMT.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08943891525268555,
                    "sentence": "- Weaknesses: They gloss over the details of their character-based encoder.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04562806338071823,
                    "sentence": "There are many different ways to learn character-based representations, and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06835105270147324,
                    "sentence": "omitting a discussion of how they do this leaves open questions about the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07362693548202515,
                    "sentence": "generality of their findings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10524990409612656,
                    "sentence": "Also, their analysis could've been made more",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.050862640142440796,
                    "sentence": "interesting had they chosen languages with richer and more challenging",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05510822311043739,
                    "sentence": "morphology such as Turkish or Finnish, accompanied by finer-grained morphology",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12952418625354767,
                    "sentence": "prediction and analysis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10716646909713745,
                    "sentence": "- General Discussion: This paper brings insight into what NMT models learn",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08642881363630295,
                    "sentence": "about morphology by training NMT systems and using the encoder or decoder",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10749496519565582,
                    "sentence": "representations, respectively, as input feature representations to a POS- or",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.108160100877285,
                    "sentence": "morphology-tagging classification task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1717906892299652,
                    "sentence": "This paper is a straightforward",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08258368074893951,
                    "sentence": "extension of \"Does String-Based Neural MT Learn Source Syntax?,\" using the same",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05926467478275299,
                    "sentence": "methodology but this time applied to morphology.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09702924638986588,
                    "sentence": "Their findings offer useful",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10422264784574509,
                    "sentence": "insights into what NMT systems learn.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.039839419682113825,
            "class_probabilities": {
                "human": 0.9601605803178862,
                "ai": 0.039839419682113825,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9601605803178862,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.039839419682113825,
                    "human": 0.9601605803178862,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "- Strengths: The authors have nice coverage of a different range of language\nsettings to isolate the way that relatedness and amount of morphology interact\n(i.e., translating between closely related morphologically rich languages vs\ndistant ones) in affecting what the system learns about morphology. They\ninclude an illuminating analysis of what parts of the architecture end up being\nresponsible for learning morphology, particularly in examining how the\nattention mechanism leads to more impoverished target side representations.\nTheir findings are of high interest and practical usefulness for other users of\nNMT. \n- Weaknesses: They gloss over the details of their character-based encoder.\nThere are many different ways to learn character-based representations, and\nomitting a discussion of how they do this leaves open questions about the\ngenerality of their findings. Also, their analysis could've been made more\ninteresting had they chosen languages with richer and more challenging\nmorphology such as Turkish or Finnish, accompanied by finer-grained morphology\nprediction and analysis.\n- General Discussion: This paper brings insight into what NMT models learn\nabout morphology by training NMT systems and using the encoder or decoder\nrepresentations, respectively, as input feature representations to a POS- or\nmorphology-tagging classification task. This paper is a straightforward\nextension of \"Does String-Based Neural MT Learn Source Syntax?,\" using the same\nmethodology but this time applied to morphology. Their findings offer useful\ninsights into what NMT systems learn."
        }
    ]
}