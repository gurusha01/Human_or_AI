{
    "version": "2025-01-09-base",
    "scanId": "f3258627-f9ff-45d6-83e8-059c78d87368",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.033616434782743454,
                    "sentence": "This paper proposes a supervised metric learning approach built on top of the recent \"word-movers distance\" [19] (a transport distance applied to word2vec word embeddings).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03016565553843975,
                    "sentence": "The proposed approach can be applied to any transport distance based on squared Euclidian distances after linear projection.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03140896186232567,
                    "sentence": "On top of learning the linear projection to maximise performance, the proposed approach also learns a weighting of words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.024733461439609528,
                    "sentence": "The latter is specific to the document application, it consists in re-weighting the frequency of each word by a learned weight, and re-normalising the word frequencies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027600537985563278,
                    "sentence": "The paper presents an efficient optimisation method to learn the proposed parameterised metric.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03915105015039444,
                    "sentence": "A thorough experimental evaluation shows the effectiveness of the proposed approach by comparing it to a large number of reasonable baselines on a number of document classification datasets using a kNN classifier based on the proposed learned metric.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03251121938228607,
                    "sentence": "+ This work extends the recent word-movers distance, which is an interesting technically and useful extension (shown to be effective on a number of kNN text classification tasks).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.035341378301382065,
                    "sentence": "- The potential impact is perhaps limited by the fact that earth-movers distance with a metric learning via a \"word centroid distance\" initialisation performs similar to the full learning of the proposed distance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.037570539861917496,
                    "sentence": "See the difference of the last two rows in Table 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7508844137191772,
                    "sentence": "In other words, the main technical contributions of this paper do not seem to contribute very much over this initialisation method based on existing techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8173081278800964,
                    "sentence": "- One thing that I missed in table 3 is an evaluation of the \"word centroid embedding\" (weighted mean of word embeddings for the document) with all tested existing metric learning approaches (ITML, LMNN, NCA).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7357946634292603,
                    "sentence": "- Another point missing in the evaluation is an assessment of the relative importance of the word-specific weights, and the projection matrix A.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7534457445144653,
                    "sentence": "It would be useful to see performance with each one of these components being active in isolation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6694983839988708,
                    "sentence": "o The originality is mostly related to the way to optimise the metric (Line 156\"\"175), the idea of a linear metric learning within the earth-movers distance is very interesting but a limited contribution in itself.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5877702832221985,
                    "sentence": "+ The paper is very well written and a pleasure to read.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4914526343345642,
                    "sentence": "There are a few minor issues that could be clarified: - Line 152: \"The authors\": of which paper?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.49696415662765503,
                    "sentence": "[1,7,8]?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.35365456342697144,
                    "sentence": "- Equation 11: shouldn't alpha and beta carry stars here?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3941773772239685,
                    "sentence": "- It would be useful to explicitly recall around line 170 that this is the Sinkhorn scaling that is referred to in the introduction in line 56.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 19,
                    "completely_generated_prob": 2.465568918597086e-15
                }
            ],
            "completely_generated_prob": 0.4467518749339812,
            "class_probabilities": {
                "human": 0.5531213689658815,
                "ai": 0.4467518749339812,
                "mixed": 0.0001267561001373191
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.5531213689658815,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.4467518749339812,
                    "human": 0.5531213689658815,
                    "mixed": 0.0001267561001373191
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes a supervised metric learning approach built on top of the recent \"word-movers distance\" [19] (a transport distance applied to word2vec word embeddings). The proposed approach can be applied to any transport distance based on squared Euclidian distances after linear projection. On top of learning the linear projection to maximise performance, the proposed approach also learns a weighting of words. The latter is specific to the document application, it consists in re-weighting the frequency of each word by a learned weight, and re-normalising the word frequencies. The paper presents an efficient optimisation method to learn the proposed parameterised metric. A thorough experimental evaluation shows the effectiveness of the proposed approach by comparing it to a large number of reasonable baselines on a number of document classification datasets using a kNN classifier based on the proposed learned metric. + This work extends the recent word-movers distance, which is an interesting technically and useful extension (shown to be effective on a number of kNN text classification tasks). - The potential impact is perhaps limited by the fact that earth-movers distance with a metric learning via a \"word centroid distance\" initialisation performs similar to the full learning of the proposed distance. See the difference of the last two rows in Table 3. In other words, the main technical contributions of this paper do not seem to contribute very much over this initialisation method based on existing techniques. - One thing that I missed in table 3 is an evaluation of the \"word centroid embedding\" (weighted mean of word embeddings for the document) with all tested existing metric learning approaches (ITML, LMNN, NCA). - Another point missing in the evaluation is an assessment of the relative importance of the word-specific weights, and the projection matrix A. It would be useful to see performance with each one of these components being active in isolation. o The originality is mostly related to the way to optimise the metric (Line 156\"\"175), the idea of a linear metric learning within the earth-movers distance is very interesting but a limited contribution in itself. + The paper is very well written and a pleasure to read. There are a few minor issues that could be clarified: - Line 152: \"The authors\": of which paper? [1,7,8] ? - Equation 11: shouldn't alpha and beta carry stars here ? - It would be useful to explicitly recall around line 170 that this is the Sinkhorn scaling that is referred to in the introduction in line 56."
        }
    ]
}