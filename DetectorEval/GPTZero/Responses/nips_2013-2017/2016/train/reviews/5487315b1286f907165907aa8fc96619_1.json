{
    "version": "2025-01-09-base",
    "scanId": "8299599b-8300-4f24-9270-424c5272d8fc",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.8099815249443054,
                    "sentence": "In this work the authors derive a convex approximation to a bi-level training objective for two-layer networks where the hidden middle layer has structure -- i.e., it must satisfy certain complex constraints.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8033559918403625,
                    "sentence": "They show their derivation, discuss how it applies in two specific structured settings, and perform experiments on transliteration and image inpainting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7282828688621521,
                    "sentence": "My main concern with this paper is that it makes many assumptions, adjustments, and approximations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8691544532775879,
                    "sentence": "As a result, it is difficult to be confident about what the resulting algorithm is actually doing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8045060634613037,
                    "sentence": "For instance, the obvious likelihood objective is replaced with a \"bi-level\" objective that does not seem to have any natural interpretation in an optimization context.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8442320227622986,
                    "sentence": "Here, it is chosen simply because it makes the optimization simpler, which, while not inherently bad, deserves some discussion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8893759846687317,
                    "sentence": "Does this change the types of models learned?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8186255693435669,
                    "sentence": "How?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7863849401473999,
                    "sentence": "Similarly, an SDP relaxation is made but not characterized -- how should we value the convexity it affords versus the degraded fidelity?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.810815155506134,
                    "sentence": "There are also some technical/clarity issues.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7300398349761963,
                    "sentence": "For instance, the claim that optimizing over S is equivalent to optimizing over Y in line 132 is false, unless Y is constrained in some way -- for example, to be a subset of {0,1}^d.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7825721502304077,
                    "sentence": "But as far as I can tell such a constraint is never stated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7529293894767761,
                    "sentence": "There are also a number of typos and grammar mistakes that make the paper more difficult to read.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3877570927143097,
                    "sentence": "The experiments are interesting and show some positive results with respect to CRF-AE, but given that the goal of the paper is essentially to \"convexify\" CRF-AE, it would be nice to see the specifics of this, rather than just final performance numbers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3904324471950531,
                    "sentence": "For instance, does CVX achieve higher likelihood than CRF-AE?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.40751969814300537,
                    "sentence": "(It might, since it is convex and therefore find the global optimum.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4370644688606262,
                    "sentence": "Or it might not, since it makes changes to the objective and relaxes the optimization to make it convex.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4833793342113495,
                    "sentence": "If it doesn't achieve higher likelihood, then how can we explain the positive results?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4335758686065674,
                    "sentence": "Does it run faster?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5374221801757812,
                    "sentence": "Also, it would be nice to see how these results compare to non-structured methods as well, to see how important structure is for these problems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6592733860015869,
                    "sentence": "Overall, I am left with a lot of questions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6618527770042419,
                    "sentence": "I think the method might be useful, but in my opinion it needs a more careful presentation and analysis to be convincing, as well as more detailed experiments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.831824779510498,
                    "sentence": "--- Post-feedback edit: The authors rightly noted in their feedback that my claim about line 132 is wrong, i.e., the claim in the paper is correct.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8250046968460083,
                    "sentence": "My apologies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7371870875358582,
                    "sentence": "I've raised my technical quality score to a 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 25,
                    "completely_generated_prob": 2.0831838560023363e-08
                }
            ],
            "completely_generated_prob": 0.49776035834266513,
            "class_probabilities": {
                "human": 0.5022396416573348,
                "ai": 0.49776035834266513,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.5022396416573348,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.49776035834266513,
                    "human": 0.5022396416573348,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "In this work the authors derive a convex approximation to a bi-level training objective for two-layer networks where the hidden middle layer has structure -- i.e., it must satisfy certain complex constraints. They show their derivation, discuss how it applies in two specific structured settings, and perform experiments on transliteration and image inpainting. My main concern with this paper is that it makes many assumptions, adjustments, and approximations. As a result, it is difficult to be confident about what the resulting algorithm is actually doing. For instance, the obvious likelihood objective is replaced with a \"bi-level\" objective that does not seem to have any natural interpretation in an optimization context. Here, it is chosen simply because it makes the optimization simpler, which, while not inherently bad, deserves some discussion. Does this change the types of models learned? How? Similarly, an SDP relaxation is made but not characterized -- how should we value the convexity it affords versus the degraded fidelity? There are also some technical/clarity issues. For instance, the claim that optimizing over S is equivalent to optimizing over Y in line 132 is false, unless Y is constrained in some way -- for example, to be a subset of {0,1}^d. But as far as I can tell such a constraint is never stated. There are also a number of typos and grammar mistakes that make the paper more difficult to read. The experiments are interesting and show some positive results with respect to CRF-AE, but given that the goal of the paper is essentially to \"convexify\" CRF-AE, it would be nice to see the specifics of this, rather than just final performance numbers. For instance, does CVX achieve higher likelihood than CRF-AE? (It might, since it is convex and therefore find the global optimum. Or it might not, since it makes changes to the objective and relaxes the optimization to make it convex.) If it doesn't achieve higher likelihood, then how can we explain the positive results? Does it run faster? Also, it would be nice to see how these results compare to non-structured methods as well, to see how important structure is for these problems. Overall, I am left with a lot of questions. I think the method might be useful, but in my opinion it needs a more careful presentation and analysis to be convincing, as well as more detailed experiments. --- Post-feedback edit: The authors rightly noted in their feedback that my claim about line 132 is wrong, i.e., the claim in the paper is correct. My apologies. I've raised my technical quality score to a 3."
        }
    ]
}