{
    "version": "2025-01-09-base",
    "scanId": "ae55ee54-cbf9-46d4-bf50-4ca7be6011d3",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.004087706096470356,
                    "sentence": "This paper considers saddle-point problems with a convex-concave property.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004819308407604694,
                    "sentence": "The authors show how this problem can be addressed using existing stochastic variance reduced techniques (such as SVRG and SAGA) coupled with a proximal operator.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004001941531896591,
                    "sentence": "They study these algorithms in the monotone operator setting showing linear convergence.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004219707101583481,
                    "sentence": "They also propose an accelerated variant as well as analyze a non-uniform sampling scheme.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004599952604621649,
                    "sentence": "Novelty/originality: The contributions of this paper are significant.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009680873714387417,
                    "sentence": "The theoretical analysis is thorough and reveals some new insights for saddle-point problems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0072160083800554276,
                    "sentence": "The authors propose many extensions in this paper, the most significant one being that their method applies to non-separable functions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006052250973880291,
                    "sentence": "Technical quality: Although I really like the theoretical contributions of this paper, I was nevertheless quite disappointed in the way it is presented.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006572799291461706,
                    "sentence": "I think the authors could have made the paper more accessible by making the connection to monotone operators more clear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004062049090862274,
                    "sentence": "This appears as an extension in Section 6 but the analysis provided by the authors is based on monotone operators.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005642033647745848,
                    "sentence": "On the experimental side, I would have liked to see experimental results on more than two datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6879191398620605,
                    "sentence": "In the case of separable functions, the authors should also have compared to accelerated methods such as this stochastic variant of Chambolle-Pock algorithm: http://www.jmlr.org/proceedings/papers/v37/zhanga15.pdf Please add this reference to your submission.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8035319447517395,
                    "sentence": "There are a few points that I would like the authors should clarify: 1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8286514282226562,
                    "sentence": "How strong are the assumptions A-C, particularly assumption (A).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7882354855537415,
                    "sentence": "For example, I wonder whether their assumptions hold for solving the saddle-point problem induced by SVM.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7501887083053589,
                    "sentence": "2. I can not fully understand the differences between stochastic primal-dual method and their suggested method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7864106893539429,
                    "sentence": "Can the authors elaborate on this point?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8152117133140564,
                    "sentence": "3. In theorem 2, I am not sure about constant \\mu.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8138371109962463,
                    "sentence": "Is it the monotonicity constant mentioned in appendix?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7282392978668213,
                    "sentence": "How can we compare this result with the result of theorem 1?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8707433938980103,
                    "sentence": "4. The transition from assumption (A)-(C) to strong monotonicity (in appendix) is confusing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.944942057132721,
                    "sentence": "Do assumptions (A)-(C) imply monotonicity?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8490130305290222,
                    "sentence": "Minor issues: Some mix-up with the constant L used as the condition number and the Lipschitz constant: \"The quantity L represents the condition number of the problem\" and \"we need the Lipschitz constant L\" Forward-Backward algorithm: please add a reference",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 23,
                    "completely_generated_prob": 2.0942835340987155e-10
                }
            ],
            "completely_generated_prob": 0.21917721611329694,
            "class_probabilities": {
                "human": 0.7782549278033645,
                "ai": 0.21917721611329694,
                "mixed": 0.0025678560833386015
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.7782549278033645,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.21917721611329694,
                    "human": 0.7782549278033645,
                    "mixed": 0.0025678560833386015
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper considers saddle-point problems with a convex-concave property. The authors show how this problem can be addressed using existing stochastic variance reduced techniques (such as SVRG and SAGA) coupled with a proximal operator. They study these algorithms in the monotone operator setting showing linear convergence. They also propose an accelerated variant as well as analyze a non-uniform sampling scheme. Novelty/originality: The contributions of this paper are significant. The theoretical analysis is thorough and reveals some new insights for saddle-point problems. The authors propose many extensions in this paper, the most significant one being that their method applies to non-separable functions. Technical quality: Although I really like the theoretical contributions of this paper, I was nevertheless quite disappointed in the way it is presented. I think the authors could have made the paper more accessible by making the connection to monotone operators more clear. This appears as an extension in Section 6 but the analysis provided by the authors is based on monotone operators. On the experimental side, I would have liked to see experimental results on more than two datasets. In the case of separable functions, the authors should also have compared to accelerated methods such as this stochastic variant of Chambolle-Pock algorithm: http://www.jmlr.org/proceedings/papers/v37/zhanga15.pdf Please add this reference to your submission. There are a few points that I would like the authors should clarify: 1. How strong are the assumptions A-C, particularly assumption (A). For example, I wonder whether their assumptions hold for solving the saddle-point problem induced by SVM. 2. I can not fully understand the differences between stochastic primal-dual method and their suggested method. Can the authors elaborate on this point? 3. In theorem 2, I am not sure about constant \\mu. Is it the monotonicity constant mentioned in appendix? How can we compare this result with the result of theorem 1? 4. The transition from assumption (A)-(C) to strong monotonicity (in appendix) is confusing. Do assumptions (A)-(C) imply monotonicity? Minor issues: Some mix-up with the constant L used as the condition number and the Lipschitz constant: \"The quantity L represents the condition number of the problem\" and \"we need the Lipschitz constant L\" Forward-Backward algorithm: please add a reference"
        }
    ]
}