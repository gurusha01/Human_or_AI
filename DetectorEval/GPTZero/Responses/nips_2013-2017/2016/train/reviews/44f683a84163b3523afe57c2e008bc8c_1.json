{
    "version": "2025-01-09-base",
    "scanId": "c02f144b-44d8-48e3-9963-faf8ae1dd231",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.01625395379960537,
                    "sentence": "The paper applies both generative adversarial networks (GAN) and variational auto encoders (VAE) to volumetric data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008813930675387383,
                    "sentence": "This enables modeling and sampling the distribution of 3d volumetric shapes, yields a 3d shape descriptor, and * yields a mapping from (2d) photos to the 3d shape descriptor and thus a 3d shape reconstruction without supervision (only training data are voxel grids).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011000746861100197,
                    "sentence": "The paper evaluates 3d object classification on ModelNet and single image 3d reconstruction on the IKEA dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008325422182679176,
                    "sentence": "It shows qualitative results for samples from the 3d shape distribution, effect of different dimensions of the 3d shape descriptor, 3d shape interpolation, 3d shape arithmetic, and discriminative features learned by the network.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007091014180332422,
                    "sentence": "The novelty is somewhat limited: The combination of VAE and GAN to enable the presented tasks has been used in this constellation in Larsen et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007638359442353249,
                    "sentence": "2016. New is the extension to volumetric data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008466839790344238,
                    "sentence": "This is achieved with architectures similar to the ones used in Radford et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009588461369276047,
                    "sentence": "2016, Sharma et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006199353374540806,
                    "sentence": "2016. The extensions appears relatively straight forward, ie.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007956823334097862,
                    "sentence": "volumetric convolutions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007777531165629625,
                    "sentence": "Quantitative results are convincing and show significant improvements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03533194959163666,
                    "sentence": "For 3d shape classification the presented method is competitive to fully supervised related work (ignoring the methods that are pretrained on imagenet) even though in this work the representation learning is unsupervised.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.035985253751277924,
                    "sentence": "Compared to other unsupervised methods, this method is stronger by quite a gap, halving the number of mistakes on ModelNet10.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06106634810566902,
                    "sentence": "For single image 3d reconstruction this method also shows a significant improvement from 38% to 53% accuracy on the IKEA benchmark.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.052441082894802094,
                    "sentence": "The paper is well written, presented clearly, and contains a decent amount of technical details (as in details of how to train the model).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.040591415017843246,
                    "sentence": "References are adequate.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04974377900362015,
                    "sentence": "(There are no proofs or theoretic analyses.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05402849614620209,
                    "sentence": "There are several qualitative results, giving some analysis of the model and it's quality.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04709101840853691,
                    "sentence": "Sometimes it is a bit unclear what the insight is.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08327712118625641,
                    "sentence": "Overall, although the novelty is limited, the paper demonstrates (1) how well the representation learnt by GANs and VAEs performs and (2) significantly advances the state of the art for unsupervised representations in 3d volumetric shape classification and single image 3d reconstruction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09618984162807465,
                    "sentence": "These insights will be interesting to the community.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 21,
                    "completely_generated_prob": 1.369041255298935e-18
                }
            ],
            "completely_generated_prob": 0.039837804045504216,
            "class_probabilities": {
                "human": 0.9601216422360306,
                "ai": 0.039837804045504216,
                "mixed": 4.055371846526579e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9601216422360306,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.039837804045504216,
                    "human": 0.9601216422360306,
                    "mixed": 4.055371846526579e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper applies both generative adversarial networks (GAN) and variational auto encoders (VAE) to volumetric data. This enables modeling and sampling the distribution of 3d volumetric shapes, yields a 3d shape descriptor, and * yields a mapping from (2d) photos to the 3d shape descriptor and thus a 3d shape reconstruction without supervision (only training data are voxel grids). The paper evaluates 3d object classification on ModelNet and single image 3d reconstruction on the IKEA dataset. It shows qualitative results for samples from the 3d shape distribution, effect of different dimensions of the 3d shape descriptor, 3d shape interpolation, 3d shape arithmetic, and discriminative features learned by the network. The novelty is somewhat limited: The combination of VAE and GAN to enable the presented tasks has been used in this constellation in Larsen et al. 2016. New is the extension to volumetric data. This is achieved with architectures similar to the ones used in Radford et al. 2016, Sharma et al. 2016. The extensions appears relatively straight forward, ie. volumetric convolutions. Quantitative results are convincing and show significant improvements. For 3d shape classification the presented method is competitive to fully supervised related work (ignoring the methods that are pretrained on imagenet) even though in this work the representation learning is unsupervised. Compared to other unsupervised methods, this method is stronger by quite a gap, halving the number of mistakes on ModelNet10. For single image 3d reconstruction this method also shows a significant improvement from 38% to 53% accuracy on the IKEA benchmark. The paper is well written, presented clearly, and contains a decent amount of technical details (as in details of how to train the model). References are adequate. (There are no proofs or theoretic analyses.) There are several qualitative results, giving some analysis of the model and it's quality. Sometimes it is a bit unclear what the insight is. Overall, although the novelty is limited, the paper demonstrates (1) how well the representation learnt by GANs and VAEs performs and (2) significantly advances the state of the art for unsupervised representations in 3d volumetric shape classification and single image 3d reconstruction. These insights will be interesting to the community."
        }
    ]
}