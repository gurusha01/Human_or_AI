{
    "version": "2025-01-09-base",
    "scanId": "589ea3b6-6797-44be-bf05-b7c95b3d7b9e",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9998716115951538,
                    "sentence": "This paper investigates saddle-point problems characterized by convex-concave properties.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998922944068909,
                    "sentence": "The authors demonstrate how such problems can be tackled using existing stochastic variance-reduced techniques (e.g., SVRG and SAGA) combined with a proximal operator.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999114274978638,
                    "sentence": "They analyze these algorithms within the framework of monotone operators, establishing linear convergence rates.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999061822891235,
                    "sentence": "Additionally, they propose an accelerated variant and explore a non-uniform sampling strategy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996680021286011,
                    "sentence": "Novelty/Originality:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993518590927124,
                    "sentence": "The contributions of this work are substantial.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996569156646729,
                    "sentence": "The theoretical analysis is rigorous and provides new insights into saddle-point problems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996819496154785,
                    "sentence": "The authors present several extensions, the most notable being the applicability of their method to non-separable functions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992172122001648,
                    "sentence": "Technical Quality:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990203976631165,
                    "sentence": "While I appreciate the theoretical advancements presented in this paper, I found the exposition lacking in clarity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988971948623657,
                    "sentence": "Specifically, the connection to monotone operators could have been made more explicit.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992510676383972,
                    "sentence": "Although this connection is discussed as an extension in Section 6, the analysis throughout the paper fundamentally relies on monotone operators.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.998740017414093,
                    "sentence": "On the experimental side, the evaluation is somewhat limited, as results are provided for only two datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8644325137138367,
                    "sentence": "For separable functions, the authors should have included comparisons to accelerated methods, such as the stochastic variant of the Chambolle-Pock algorithm (see: http://www.jmlr.org/proceedings/papers/v37/zhanga15.pdf).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9716839790344238,
                    "sentence": "I recommend adding this reference to the submission.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986403584480286,
                    "sentence": "Points for Clarification:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993597865104675,
                    "sentence": "1. How restrictive are assumptions A-C, particularly assumption (A)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996771812438965,
                    "sentence": "For instance, do these assumptions hold for the saddle-point problem arising in SVMs?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998783469200134,
                    "sentence": "2. The distinction between the stochastic primal-dual method and the proposed approach is unclear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998025894165039,
                    "sentence": "Could the authors elaborate on this difference?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996180534362793,
                    "sentence": "3. In Theorem 2, the constant \\(\\mu\\) is ambiguous.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995971322059631,
                    "sentence": "Is it the monotonicity constant mentioned in the appendix?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990058541297913,
                    "sentence": "How does this result compare to Theorem 1?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987870454788208,
                    "sentence": "4. The transition from assumptions (A)-(C) to strong monotonicity in the appendix is confusing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991334080696106,
                    "sentence": "Do assumptions (A)-(C) necessarily imply monotonicity?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9946222901344299,
                    "sentence": "Minor Issues:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9746425747871399,
                    "sentence": "- There is some inconsistency in the use of the constant \\(L\\), which is referred to both as the condition number and the Lipschitz constant: \"The quantity \\(L\\) represents the condition number of the problem\" and \"we need the Lipschitz constant \\(L\\).\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997150301933289,
                    "sentence": "- Please include a reference for the Forward-Backward algorithm.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9926183471516448,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9926183471516448,
                "mixed": 0.007381652848355174
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9926183471516448,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9926183471516448,
                    "human": 0,
                    "mixed": 0.007381652848355174
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper investigates saddle-point problems characterized by convex-concave properties. The authors demonstrate how such problems can be tackled using existing stochastic variance-reduced techniques (e.g., SVRG and SAGA) combined with a proximal operator. They analyze these algorithms within the framework of monotone operators, establishing linear convergence rates. Additionally, they propose an accelerated variant and explore a non-uniform sampling strategy. \nNovelty/Originality: \nThe contributions of this work are substantial. The theoretical analysis is rigorous and provides new insights into saddle-point problems. The authors present several extensions, the most notable being the applicability of their method to non-separable functions. \nTechnical Quality: \nWhile I appreciate the theoretical advancements presented in this paper, I found the exposition lacking in clarity. Specifically, the connection to monotone operators could have been made more explicit. Although this connection is discussed as an extension in Section 6, the analysis throughout the paper fundamentally relies on monotone operators. \nOn the experimental side, the evaluation is somewhat limited, as results are provided for only two datasets. For separable functions, the authors should have included comparisons to accelerated methods, such as the stochastic variant of the Chambolle-Pock algorithm (see: http://www.jmlr.org/proceedings/papers/v37/zhanga15.pdf). I recommend adding this reference to the submission. \nPoints for Clarification: \n1. How restrictive are assumptions A-C, particularly assumption (A)? For instance, do these assumptions hold for the saddle-point problem arising in SVMs? \n2. The distinction between the stochastic primal-dual method and the proposed approach is unclear. Could the authors elaborate on this difference? \n3. In Theorem 2, the constant \\(\\mu\\) is ambiguous. Is it the monotonicity constant mentioned in the appendix? How does this result compare to Theorem 1? \n4. The transition from assumptions (A)-(C) to strong monotonicity in the appendix is confusing. Do assumptions (A)-(C) necessarily imply monotonicity? \nMinor Issues: \n- There is some inconsistency in the use of the constant \\(L\\), which is referred to both as the condition number and the Lipschitz constant: \"The quantity \\(L\\) represents the condition number of the problem\" and \"we need the Lipschitz constant \\(L\\).\" \n- Please include a reference for the Forward-Backward algorithm."
        }
    ]
}