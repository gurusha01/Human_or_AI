{
    "version": "2025-01-09-base",
    "scanId": "e53ab499-9d16-4559-a2e3-95346fbddd68",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.990047812461853,
                    "sentence": "This paper introduces a supervised metric learning framework built upon the recent \"word-movers distance\" [19], which is a transport distance applied to word2vec word embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9920729994773865,
                    "sentence": "The proposed method is generalizable to any transport distance that relies on squared Euclidean distances after applying a linear projection.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9867545962333679,
                    "sentence": "In addition to learning the linear projection to optimize performance, the approach incorporates a mechanism for learning word-specific weights.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9835876226425171,
                    "sentence": "These weights are tailored to the document application, achieved by re-weighting the frequency of each word with a learned parameter and subsequently re-normalizing the word frequencies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9864683151245117,
                    "sentence": "The paper also describes an efficient optimization procedure to train the parameterized metric.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9864223599433899,
                    "sentence": "Comprehensive experimental results demonstrate the effectiveness of the proposed method by benchmarking it against numerous strong baselines across multiple document classification datasets using a kNN classifier with the learned metric.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9180663228034973,
                    "sentence": "+ This work builds upon the recent word-movers distance, providing a technically interesting and practically useful extension, as evidenced by its strong performance on various kNN text classification tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9191413521766663,
                    "sentence": "- However, the potential impact of the work may be somewhat constrained, as the earth-movers distance combined with metric learning via a \"word centroid distance\" initialization achieves comparable performance to the fully learned proposed distance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9101253151893616,
                    "sentence": "This can be observed in the last two rows of Table 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9037876129150391,
                    "sentence": "In essence, the primary technical contributions of the paper appear to offer only marginal improvements over this initialization method, which is based on existing techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9967808127403259,
                    "sentence": "- One notable omission in Table 3 is the evaluation of the \"word centroid embedding\" (computed as the weighted mean of word embeddings for the document) when used with all the existing metric learning approaches tested (e.g., ITML, LMNN, NCA).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9969664216041565,
                    "sentence": "- Another missing aspect in the evaluation is an analysis of the relative contributions of the word-specific weights and the projection matrix \\(A\\).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9956236481666565,
                    "sentence": "It would be valuable to assess the performance when each of these components is activated in isolation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994109869003296,
                    "sentence": "o The originality of the work primarily lies in the optimization of the metric (Lines 156\"\"175).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991485476493835,
                    "sentence": "While the concept of linear metric learning within the earth-movers distance framework is intriguing, it represents a relatively modest contribution on its own.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992693066596985,
                    "sentence": "+ The paper is exceptionally well written and enjoyable to read.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986029863357544,
                    "sentence": "There are a few minor points that could benefit from clarification:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991205930709839,
                    "sentence": "- Line 152: To which paper do \"The authors\" refer?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999408483505249,
                    "sentence": "[1,7,8]?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985975027084351,
                    "sentence": "- Equation 11: Shouldn't \\(\\alpha\\) and \\(\\beta\\) include stars here?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987750053405762,
                    "sentence": "- Around Line 170, it would be helpful to explicitly remind readers that this refers to the Sinkhorn scaling mentioned in the introduction (Line 56).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9984930238596827,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984930238596827,
                "mixed": 0.001506976140317253
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984930238596827,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984930238596827,
                    "human": 0,
                    "mixed": 0.001506976140317253
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper introduces a supervised metric learning framework built upon the recent \"word-movers distance\" [19], which is a transport distance applied to word2vec word embeddings. The proposed method is generalizable to any transport distance that relies on squared Euclidean distances after applying a linear projection. In addition to learning the linear projection to optimize performance, the approach incorporates a mechanism for learning word-specific weights. These weights are tailored to the document application, achieved by re-weighting the frequency of each word with a learned parameter and subsequently re-normalizing the word frequencies. The paper also describes an efficient optimization procedure to train the parameterized metric. Comprehensive experimental results demonstrate the effectiveness of the proposed method by benchmarking it against numerous strong baselines across multiple document classification datasets using a kNN classifier with the learned metric. \n+ This work builds upon the recent word-movers distance, providing a technically interesting and practically useful extension, as evidenced by its strong performance on various kNN text classification tasks. \n- However, the potential impact of the work may be somewhat constrained, as the earth-movers distance combined with metric learning via a \"word centroid distance\" initialization achieves comparable performance to the fully learned proposed distance. This can be observed in the last two rows of Table 3. In essence, the primary technical contributions of the paper appear to offer only marginal improvements over this initialization method, which is based on existing techniques. \n- One notable omission in Table 3 is the evaluation of the \"word centroid embedding\" (computed as the weighted mean of word embeddings for the document) when used with all the existing metric learning approaches tested (e.g., ITML, LMNN, NCA). \n- Another missing aspect in the evaluation is an analysis of the relative contributions of the word-specific weights and the projection matrix \\(A\\). It would be valuable to assess the performance when each of these components is activated in isolation. \no The originality of the work primarily lies in the optimization of the metric (Lines 156\"\"175). While the concept of linear metric learning within the earth-movers distance framework is intriguing, it represents a relatively modest contribution on its own. \n+ The paper is exceptionally well written and enjoyable to read. \nThere are a few minor points that could benefit from clarification: \n- Line 152: To which paper do \"The authors\" refer? [1,7,8]? \n- Equation 11: Shouldn't \\(\\alpha\\) and \\(\\beta\\) include stars here? \n- Around Line 170, it would be helpful to explicitly remind readers that this refers to the Sinkhorn scaling mentioned in the introduction (Line 56)."
        }
    ]
}