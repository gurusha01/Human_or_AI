{
    "version": "2025-01-09-base",
    "scanId": "01ed7d1e-d4b5-493b-85ec-7416ff30d471",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9993644952774048,
                    "sentence": "In this paper, the authors propose a convex approximation to a bi-level training objective for two-layer networks, where the hidden middle layer is subject to specific structural constraints.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992657899856567,
                    "sentence": "They present their derivation, demonstrate its application in two structured scenarios, and conduct experiments on transliteration and image inpainting tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996306300163269,
                    "sentence": "My primary concern with this work is the reliance on numerous assumptions, adjustments, and approximations, which make it challenging to fully understand the behavior of the resulting algorithm.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996028542518616,
                    "sentence": "For example, the standard likelihood objective is substituted with a \"bi-level\" objective that lacks a clear interpretation in the context of optimization.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994229674339294,
                    "sentence": "While this choice simplifies the optimization process, it warrants further discussion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988441467285156,
                    "sentence": "Does this substitution influence the types of models learned?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9981814026832581,
                    "sentence": "If so, in what way?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991545081138611,
                    "sentence": "Similarly, the paper employs an SDP relaxation but does not provide a detailed characterization of it\"\"how should we weigh the benefits of convexity against the potential loss of fidelity?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9976479411125183,
                    "sentence": "There are also some technical and clarity-related issues.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984444379806519,
                    "sentence": "For instance, the assertion in line 132 that optimizing over S is equivalent to optimizing over Y is incorrect unless Y is constrained in some way, such as being a subset of {0,1}^d.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994404315948486,
                    "sentence": "However, no such constraint appears to be explicitly stated in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990217685699463,
                    "sentence": "Additionally, the manuscript contains several typos and grammatical errors that detract from its readability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9798152446746826,
                    "sentence": "While the experiments yield interesting and positive results compared to CRF-AE, the paper's primary goal is to \"convexify\" CRF-AE.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9462912678718567,
                    "sentence": "It would therefore be valuable to see more detailed analyses beyond final performance metrics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9599743485450745,
                    "sentence": "For instance, does the proposed CVX approach achieve higher likelihood than CRF-AE?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9723125696182251,
                    "sentence": "This could be expected, given its convexity and ability to find the global optimum, but it might not, due to changes in the objective and the relaxation used to achieve convexity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.943356454372406,
                    "sentence": "If it does not achieve higher likelihood, how can the positive experimental results be explained?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9689003229141235,
                    "sentence": "Does the proposed method offer faster runtime?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9398322701454163,
                    "sentence": "Furthermore, a comparison with non-structured methods would be helpful to assess the importance of structure in these tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9382106065750122,
                    "sentence": "Overall, while the method has potential, I am left with numerous unanswered questions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9543502926826477,
                    "sentence": "In my view, the paper requires a more thorough presentation and analysis to be convincing, as well as more detailed experimental evaluations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9794086813926697,
                    "sentence": "--- Post-feedback edit: The authors correctly pointed out in their response that my earlier claim regarding line 132 was incorrect, and the claim in the paper is indeed valid.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9919373393058777,
                    "sentence": "I apologize for this oversight and have adjusted my technical quality score to a 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 8,
                    "completely_generated_prob": 0.9187750751329665
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 11,
                    "completely_generated_prob": 0.9367359127724141
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9984984300152882,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984984300152882,
                "mixed": 0.0015015699847118259
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984984300152882,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984984300152882,
                    "human": 0,
                    "mixed": 0.0015015699847118259
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "In this paper, the authors propose a convex approximation to a bi-level training objective for two-layer networks, where the hidden middle layer is subject to specific structural constraints. They present their derivation, demonstrate its application in two structured scenarios, and conduct experiments on transliteration and image inpainting tasks. My primary concern with this work is the reliance on numerous assumptions, adjustments, and approximations, which make it challenging to fully understand the behavior of the resulting algorithm. For example, the standard likelihood objective is substituted with a \"bi-level\" objective that lacks a clear interpretation in the context of optimization. While this choice simplifies the optimization process, it warrants further discussion. Does this substitution influence the types of models learned? If so, in what way? Similarly, the paper employs an SDP relaxation but does not provide a detailed characterization of it\"\"how should we weigh the benefits of convexity against the potential loss of fidelity?\nThere are also some technical and clarity-related issues. For instance, the assertion in line 132 that optimizing over S is equivalent to optimizing over Y is incorrect unless Y is constrained in some way, such as being a subset of {0,1}^d. However, no such constraint appears to be explicitly stated in the paper. Additionally, the manuscript contains several typos and grammatical errors that detract from its readability. While the experiments yield interesting and positive results compared to CRF-AE, the paper's primary goal is to \"convexify\" CRF-AE. It would therefore be valuable to see more detailed analyses beyond final performance metrics. For instance, does the proposed CVX approach achieve higher likelihood than CRF-AE? This could be expected, given its convexity and ability to find the global optimum, but it might not, due to changes in the objective and the relaxation used to achieve convexity. If it does not achieve higher likelihood, how can the positive experimental results be explained? Does the proposed method offer faster runtime? Furthermore, a comparison with non-structured methods would be helpful to assess the importance of structure in these tasks.\nOverall, while the method has potential, I am left with numerous unanswered questions. In my view, the paper requires a more thorough presentation and analysis to be convincing, as well as more detailed experimental evaluations. \n--- Post-feedback edit: The authors correctly pointed out in their response that my earlier claim regarding line 132 was incorrect, and the claim in the paper is indeed valid. I apologize for this oversight and have adjusted my technical quality score to a 3."
        }
    ]
}