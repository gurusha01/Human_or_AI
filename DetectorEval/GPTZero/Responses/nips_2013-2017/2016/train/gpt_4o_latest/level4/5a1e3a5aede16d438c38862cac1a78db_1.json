{
    "version": "2025-01-09-base",
    "scanId": "9f3444eb-563e-4158-aec1-71f2ad426437",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9991281032562256,
                    "sentence": "This paper investigates solutions to the optimization problem min.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9975851774215698,
                    "sentence": "\"\"x\"\"_1 subject to \"\"\\Phi x - y\"\" â ¤ Ï, where the second norm is either the L1 or L-infinity norm.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990159273147583,
                    "sentence": "The authors present a dual characterization of the solution sets, demonstrating that recovering the structure of the optimal x is sometimes achievable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9964478611946106,
                    "sentence": "Given the highly saturated field this paper contributes to\"\"with hundreds or even thousands of prior works on sparse recovery in linear systems\"\"it is crucial to clearly position the paper and justify its relevance within the context of NIPS.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9967992901802063,
                    "sentence": "Unfortunately, I feel this paper falls short in that regard.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9935024380683899,
                    "sentence": "While the authors claim novelty in their proof techniques, these primarily involve constructing a dual vector that optimizes the problem under certain noise conditions on w (where y = \\Phi x + w) and arguing that sign or structure recovery is feasible.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9888052344322205,
                    "sentence": "However, the dual witness approach has a well-established history in the analysis of convex relaxations of sparsity problems, dating back to foundational work by Donoho, Candes, Tao, and Wainwright.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9870306253433228,
                    "sentence": "As such, it is unclear whether the contributions here are genuinely novel.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9881531000137329,
                    "sentence": "The experimental evaluation also leaves much to be desired.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9944968223571777,
                    "sentence": "It is not entirely clear what specific experiment is being conducted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9952479004859924,
                    "sentence": "Is there noise in the observation of y?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9881947636604309,
                    "sentence": "What is the noise distribution assumed for w?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9929492473602295,
                    "sentence": "My understanding is that the justification for this paper hinges on the idea that varying the noise distribution for w would slightly alter the analysis, which is reasonable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9952001571655273,
                    "sentence": "However, the experiments do not appear to explore this aspect.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9954566955566406,
                    "sentence": "Furthermore, Figure 2 seems to indicate that classical L2 loss techniques outperform the proposed approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9919445514678955,
                    "sentence": "Is this outcome a result of the noise distribution used in the experiments?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9940131902694702,
                    "sentence": "Or does it suggest that employing L1 or L-infinity norms is inherently suboptimal?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9906516075134277,
                    "sentence": "The experiments fail to provide clear explanatory insights, leaving the takeaways ambiguous.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 8,
                    "completely_generated_prob": 0.9187750751329665
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 10,
                    "completely_generated_prob": 0.9316904254198173
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper investigates solutions to the optimization problem min. \"\"x\"\"_1 subject to \"\"\\Phi x - y\"\" â ¤ Ï , where the second norm is either the L1 or L-infinity norm. The authors present a dual characterization of the solution sets, demonstrating that recovering the structure of the optimal x is sometimes achievable. Given the highly saturated field this paper contributes to\"\"with hundreds or even thousands of prior works on sparse recovery in linear systems\"\"it is crucial to clearly position the paper and justify its relevance within the context of NIPS. Unfortunately, I feel this paper falls short in that regard. While the authors claim novelty in their proof techniques, these primarily involve constructing a dual vector that optimizes the problem under certain noise conditions on w (where y = \\Phi x + w) and arguing that sign or structure recovery is feasible. However, the dual witness approach has a well-established history in the analysis of convex relaxations of sparsity problems, dating back to foundational work by Donoho, Candes, Tao, and Wainwright. As such, it is unclear whether the contributions here are genuinely novel. \nThe experimental evaluation also leaves much to be desired. It is not entirely clear what specific experiment is being conducted. Is there noise in the observation of y? What is the noise distribution assumed for w? My understanding is that the justification for this paper hinges on the idea that varying the noise distribution for w would slightly alter the analysis, which is reasonable. However, the experiments do not appear to explore this aspect. Furthermore, Figure 2 seems to indicate that classical L2 loss techniques outperform the proposed approaches. Is this outcome a result of the noise distribution used in the experiments? Or does it suggest that employing L1 or L-infinity norms is inherently suboptimal? The experiments fail to provide clear explanatory insights, leaving the takeaways ambiguous."
        }
    ]
}