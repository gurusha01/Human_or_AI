{
    "version": "2025-01-09-base",
    "scanId": "752235a0-d45f-43b8-b6a7-6f6457622fba",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999489188194275,
                    "sentence": "The paper investigates the support recovery guarantees of underdetermined sparse regression using the `1-norm regularizer with non-smooth loss functions (`1 and ` norms), extending existing theory from the smooth `2 case.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999604821205139,
                    "sentence": "The authors derive conditions under which the support of the recovered vector remains stable under small additive noise, and introduce the concept of \"extended support\" to explain instability scenarios.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999179840087891,
                    "sentence": "The theoretical findings are validated through numerical experiments in compressed sensing, highlighting the differences in support stability across `1, `2, and ` losses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998379349708557,
                    "sentence": "This work builds on prior studies of sparse recovery (e.g., Fuchs [6], Zhao and Yu [19]) but uniquely addresses non-smooth loss functions, which are critical for handling impulse or uniform noise.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999351501464844,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999455213546753,
                    "sentence": "1. Novelty: The paper addresses a significant gap in the literature by extending support recovery theory to non-smooth loss functions (`1 and ` ).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999571442604065,
                    "sentence": "This is a meaningful contribution, as these loss functions are widely used in practice but lack rigorous theoretical guarantees.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999560713768005,
                    "sentence": "2. Theoretical Rigor: The authors provide a sharp characterization of support stability and instability, leveraging dual certificates and restricted injectivity conditions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999597072601318,
                    "sentence": "The proofs are detailed and carefully structured, addressing the challenges posed by non-smoothness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999483823776245,
                    "sentence": "3. Practical Relevance: The work has clear implications for compressed sensing and other high-dimensional inverse problems, particularly in scenarios involving non-Gaussian noise.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998975396156311,
                    "sentence": "4. Numerical Validation: The experiments are well-designed and illustrate the theoretical findings effectively.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999515414237976,
                    "sentence": "The comparison of support stability across different loss functions (`1, `2, ` ) is particularly insightful.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999419450759888,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999281167984009,
                    "sentence": "1. Clarity: While the paper is mathematically rigorous, it is dense and could benefit from clearer explanations for a broader audience.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9972509145736694,
                    "sentence": "For example, the intuition behind the extended support and its practical implications could be elaborated further.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9971382021903992,
                    "sentence": "2. Scope Limitations: The analysis is restricted to small noise regimes and does not address larger noise scenarios, which are common in real-world applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9947716593742371,
                    "sentence": "While the authors acknowledge this limitation, it reduces the practical applicability of the results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9943147897720337,
                    "sentence": "3. Generalization: The results are primarily focused on `1, `2, and ` losses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9905574917793274,
                    "sentence": "Although the authors claim that their framework can be extended to other non-smooth losses, this generalization is not demonstrated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9967332482337952,
                    "sentence": "4. Empirical Validation: The numerical experiments are limited to synthetic data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9970769882202148,
                    "sentence": "Validation on real-world datasets would strengthen the paper's claims and demonstrate its practical utility.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974488019943237,
                    "sentence": "Arguments for Acceptance",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988201260566711,
                    "sentence": "- The paper addresses an important and underexplored problem, providing novel theoretical insights.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990264773368835,
                    "sentence": "- The results are rigorous and well-supported by numerical experiments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993566274642944,
                    "sentence": "- The work is likely to inspire further research on non-smooth loss functions in sparse recovery.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9976587295532227,
                    "sentence": "Arguments Against Acceptance",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984884858131409,
                    "sentence": "- The paper's clarity and accessibility could be improved, particularly for non-expert readers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992830157279968,
                    "sentence": "- The scope is limited to small noise regimes, reducing its practical impact.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999077320098877,
                    "sentence": "- Lack of real-world validation leaves questions about the applicability of the results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9970433115959167,
                    "sentence": "Recommendation",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9953981637954712,
                    "sentence": "Overall, this paper makes a strong theoretical contribution to the field of sparse recovery and is well-suited for NIPS.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9943013787269592,
                    "sentence": "While there are some limitations in scope and clarity, the novelty and rigor of the work outweigh these concerns.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9877927899360657,
                    "sentence": "I recommend acceptance, with suggestions to improve clarity and include real-world validations in future work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 0.9841954571483108,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9841954571483108,
                "mixed": 0.015804542851689255
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9841954571483108,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9841954571483108,
                    "human": 0,
                    "mixed": 0.015804542851689255
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper investigates the support recovery guarantees of underdetermined sparse regression using the `1-norm regularizer with non-smooth loss functions (`1 and ` norms), extending existing theory from the smooth `2 case. The authors derive conditions under which the support of the recovered vector remains stable under small additive noise, and introduce the concept of \"extended support\" to explain instability scenarios. The theoretical findings are validated through numerical experiments in compressed sensing, highlighting the differences in support stability across `1, `2, and ` losses. This work builds on prior studies of sparse recovery (e.g., Fuchs [6], Zhao and Yu [19]) but uniquely addresses non-smooth loss functions, which are critical for handling impulse or uniform noise.\nStrengths\n1. Novelty: The paper addresses a significant gap in the literature by extending support recovery theory to non-smooth loss functions (`1 and ` ). This is a meaningful contribution, as these loss functions are widely used in practice but lack rigorous theoretical guarantees.\n2. Theoretical Rigor: The authors provide a sharp characterization of support stability and instability, leveraging dual certificates and restricted injectivity conditions. The proofs are detailed and carefully structured, addressing the challenges posed by non-smoothness.\n3. Practical Relevance: The work has clear implications for compressed sensing and other high-dimensional inverse problems, particularly in scenarios involving non-Gaussian noise.\n4. Numerical Validation: The experiments are well-designed and illustrate the theoretical findings effectively. The comparison of support stability across different loss functions (`1, `2, ` ) is particularly insightful.\nWeaknesses\n1. Clarity: While the paper is mathematically rigorous, it is dense and could benefit from clearer explanations for a broader audience. For example, the intuition behind the extended support and its practical implications could be elaborated further.\n2. Scope Limitations: The analysis is restricted to small noise regimes and does not address larger noise scenarios, which are common in real-world applications. While the authors acknowledge this limitation, it reduces the practical applicability of the results.\n3. Generalization: The results are primarily focused on `1, `2, and ` losses. Although the authors claim that their framework can be extended to other non-smooth losses, this generalization is not demonstrated.\n4. Empirical Validation: The numerical experiments are limited to synthetic data. Validation on real-world datasets would strengthen the paper's claims and demonstrate its practical utility.\nArguments for Acceptance\n- The paper addresses an important and underexplored problem, providing novel theoretical insights.\n- The results are rigorous and well-supported by numerical experiments.\n- The work is likely to inspire further research on non-smooth loss functions in sparse recovery.\nArguments Against Acceptance\n- The paper's clarity and accessibility could be improved, particularly for non-expert readers.\n- The scope is limited to small noise regimes, reducing its practical impact.\n- Lack of real-world validation leaves questions about the applicability of the results.\nRecommendation\nOverall, this paper makes a strong theoretical contribution to the field of sparse recovery and is well-suited for NIPS. While there are some limitations in scope and clarity, the novelty and rigor of the work outweigh these concerns. I recommend acceptance, with suggestions to improve clarity and include real-world validations in future work."
        }
    ]
}