{
    "version": "2025-01-09-base",
    "scanId": "bd614afc-bf85-4c23-b9f2-4c4dc1d0feac",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9985772967338562,
                    "sentence": "This manuscript presents a novel supervised metric learning framework, leveraging the \"word-movers distance\" [19], a transport distance applied to word2vec word embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9980639815330505,
                    "sentence": "The proposed approach is versatile and can be applied to any transport distance based on squared Euclidean distances after linear projection.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9983975291252136,
                    "sentence": "In addition to learning the linear projection to optimize performance, the approach also learns a word-specific weighting scheme.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985954165458679,
                    "sentence": "This weighting scheme, tailored to document applications, involves re-weighting the frequency of each word by a learned weight and re-normalizing the word frequencies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993464946746826,
                    "sentence": "The authors introduce an efficient optimization method to learn the parameters of the proposed metric.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984508752822876,
                    "sentence": "A comprehensive experimental evaluation demonstrates the effectiveness of the proposed approach by comparing it to numerous baselines on several document classification datasets using a kNN classifier based on the learned metric.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9908408522605896,
                    "sentence": "The work offers an interesting and useful extension of the recent word-movers distance, showcasing its effectiveness in various kNN text classification tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.11908090859651566,
                    "sentence": "However, the potential impact may be limited, as an earth-movers distance with metric learning via a \"word centroid distance\" initialization achieves similar performance to the fully learned proposed distance, as observed in the last two rows of Table 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985347390174866,
                    "sentence": "This suggests that the primary technical contributions may not significantly enhance the performance beyond the initialization method based on existing techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974165558815002,
                    "sentence": "Notably, the evaluation in Table 3 lacks a comparison of the \"word centroid embedding\" (weighted mean of word embeddings for the document) with existing metric learning approaches (ITML, LMNN, NCA).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9977627992630005,
                    "sentence": "Furthermore, an assessment of the relative importance of word-specific weights and the projection matrix A is missing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9941420555114746,
                    "sentence": "It would be beneficial to evaluate the performance with each of these components active in isolation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9535819292068481,
                    "sentence": "The originality of the paper primarily stems from the optimization of the metric (Lines 156-175), where the concept of linear metric learning within the earth-movers distance is intriguing but constitutes a limited contribution in itself.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9348376393318176,
                    "sentence": "The manuscript is well-written and enjoyable to read, with a few minor issues that require clarification:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.944291353225708,
                    "sentence": "- Line 152 refers to \"The authors\" without specifying the paper ([1,7,8]?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8201891183853149,
                    "sentence": ");",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9075333476066589,
                    "sentence": "- Equation 11 may require alpha and beta to be starred;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8895964622497559,
                    "sentence": "- It would be helpful to explicitly mention around Line 170 that the optimization method refers to the Sinkhorn scaling introduced in Line 56.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.45887534985363754
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9658502932045533,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9658502932045533,
                "mixed": 0.034149706795446697
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9658502932045533,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9658502932045533,
                    "human": 0,
                    "mixed": 0.034149706795446697
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This manuscript presents a novel supervised metric learning framework, leveraging the \"word-movers distance\" [19], a transport distance applied to word2vec word embeddings. The proposed approach is versatile and can be applied to any transport distance based on squared Euclidean distances after linear projection. In addition to learning the linear projection to optimize performance, the approach also learns a word-specific weighting scheme. This weighting scheme, tailored to document applications, involves re-weighting the frequency of each word by a learned weight and re-normalizing the word frequencies. The authors introduce an efficient optimization method to learn the parameters of the proposed metric. A comprehensive experimental evaluation demonstrates the effectiveness of the proposed approach by comparing it to numerous baselines on several document classification datasets using a kNN classifier based on the learned metric.\nThe work offers an interesting and useful extension of the recent word-movers distance, showcasing its effectiveness in various kNN text classification tasks. However, the potential impact may be limited, as an earth-movers distance with metric learning via a \"word centroid distance\" initialization achieves similar performance to the fully learned proposed distance, as observed in the last two rows of Table 3. This suggests that the primary technical contributions may not significantly enhance the performance beyond the initialization method based on existing techniques.\nNotably, the evaluation in Table 3 lacks a comparison of the \"word centroid embedding\" (weighted mean of word embeddings for the document) with existing metric learning approaches (ITML, LMNN, NCA). Furthermore, an assessment of the relative importance of word-specific weights and the projection matrix A is missing. It would be beneficial to evaluate the performance with each of these components active in isolation.\nThe originality of the paper primarily stems from the optimization of the metric (Lines 156-175), where the concept of linear metric learning within the earth-movers distance is intriguing but constitutes a limited contribution in itself. The manuscript is well-written and enjoyable to read, with a few minor issues that require clarification: \n- Line 152 refers to \"The authors\" without specifying the paper ([1,7,8]?);\n- Equation 11 may require alpha and beta to be starred;\n- It would be helpful to explicitly mention around Line 170 that the optimization method refers to the Sinkhorn scaling introduced in Line 56."
        }
    ]
}