{
    "version": "2025-01-09-base",
    "scanId": "858386d1-07ca-42f0-9e1f-0cf0c76c8b95",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999095797538757,
                    "sentence": "This paper presents a theoretical analysis of the support recovery guarantees for underdetermined sparse regression using the `1-norm as a regularizer and non-smooth loss functions, specifically `1 and `â^ž losses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997932314872742,
                    "sentence": "The authors provide a sharp condition that ensures the stability of the support of the vector to recover, even in the presence of small additive noise.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997439980506897,
                    "sentence": "The paper's main contribution is Theorem 1, which characterizes the stability of the support in terms of a minimal norm certificate and the restricted injectivity condition.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999271631240845,
                    "sentence": "The paper is well-structured and clearly written, with a thorough introduction to the problem and a detailed presentation of the theoretical results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991452097892761,
                    "sentence": "The authors also provide numerical experiments to illustrate the support stability in a compressed sensing setting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9983081817626953,
                    "sentence": "The results show that the `2 data fidelity constraint provides the highest support stability, while the `1 loss function has a small advantage over the `â^ž loss.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.995978057384491,
                    "sentence": "However, the paper's novelty is questionable due to the crowded space of sparse recovery in linear systems, with similar techniques and concepts already established in previous works.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9942554235458374,
                    "sentence": "The proof techniques used in the paper, although claimed to be novel, resemble the dual witness technique with a long history in analysis of convex relaxations of sparsity problems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9981734752655029,
                    "sentence": "The experimental evaluation is lacking, with unclear details on the experiment setup, noise distribution, and observation of y, making it difficult to interpret the results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984143376350403,
                    "sentence": "The experiments seem to suggest that classical L2 loss techniques are the best, but it is unclear whether this is due to the noise distribution used or the ineffectiveness of L1 or L-infinity norms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974789023399353,
                    "sentence": "In terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996368288993835,
                    "sentence": "However, the paper could benefit from more detailed experimental evaluations and a clearer discussion of the novelty and significance of the results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9657436609268188,
                    "sentence": "Arguments pro acceptance:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.924182653427124,
                    "sentence": "* The paper provides a thorough theoretical analysis of the support recovery guarantees for underdetermined sparse regression.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.968900203704834,
                    "sentence": "* The results are well-presented, and the paper is easy to follow.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9654290676116943,
                    "sentence": "* The numerical experiments provide some insights into the support stability in a compressed sensing setting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9332630038261414,
                    "sentence": "Arguments con acceptance:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.960364043712616,
                    "sentence": "* The paper's novelty is questionable due to the crowded space of sparse recovery in linear systems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9414854645729065,
                    "sentence": "* The proof techniques used in the paper are not significantly new.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9707544445991516,
                    "sentence": "* The experimental evaluation is lacking, and the results are difficult to interpret.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9145598411560059,
                    "sentence": "* The paper could benefit from more detailed discussions of the significance and impact of the results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9926183471516448,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9926183471516448,
                "mixed": 0.007381652848355174
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9926183471516448,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9926183471516448,
                    "human": 0,
                    "mixed": 0.007381652848355174
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a theoretical analysis of the support recovery guarantees for underdetermined sparse regression using the `1-norm as a regularizer and non-smooth loss functions, specifically `1 and `âˆž losses. The authors provide a sharp condition that ensures the stability of the support of the vector to recover, even in the presence of small additive noise. The paper's main contribution is Theorem 1, which characterizes the stability of the support in terms of a minimal norm certificate and the restricted injectivity condition.\nThe paper is well-structured and clearly written, with a thorough introduction to the problem and a detailed presentation of the theoretical results. The authors also provide numerical experiments to illustrate the support stability in a compressed sensing setting. The results show that the `2 data fidelity constraint provides the highest support stability, while the `1 loss function has a small advantage over the `âˆž loss.\nHowever, the paper's novelty is questionable due to the crowded space of sparse recovery in linear systems, with similar techniques and concepts already established in previous works. The proof techniques used in the paper, although claimed to be novel, resemble the dual witness technique with a long history in analysis of convex relaxations of sparsity problems.\nThe experimental evaluation is lacking, with unclear details on the experiment setup, noise distribution, and observation of y, making it difficult to interpret the results. The experiments seem to suggest that classical L2 loss techniques are the best, but it is unclear whether this is due to the noise distribution used or the ineffectiveness of L1 or L-infinity norms.\nIn terms of quality, the paper is technically sound, and the claims are well-supported by theoretical analysis. However, the paper could benefit from more detailed experimental evaluations and a clearer discussion of the novelty and significance of the results.\nArguments pro acceptance:\n* The paper provides a thorough theoretical analysis of the support recovery guarantees for underdetermined sparse regression.\n* The results are well-presented, and the paper is easy to follow.\n* The numerical experiments provide some insights into the support stability in a compressed sensing setting.\nArguments con acceptance:\n* The paper's novelty is questionable due to the crowded space of sparse recovery in linear systems.\n* The proof techniques used in the paper are not significantly new.\n* The experimental evaluation is lacking, and the results are difficult to interpret.\n* The paper could benefit from more detailed discussions of the significance and impact of the results."
        }
    ]
}