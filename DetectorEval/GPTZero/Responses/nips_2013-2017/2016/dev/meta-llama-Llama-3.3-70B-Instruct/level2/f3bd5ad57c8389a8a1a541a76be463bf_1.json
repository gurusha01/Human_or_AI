{
    "version": "2025-01-09-base",
    "scanId": "e1e18718-0385-4f64-86b1-177564ecb6f1",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999969601631165,
                    "sentence": "This paper proposes a novel approach to monocular depth estimation by training a neural network to predict probability distributions over local coefficients of the scene depth map in an overcomplete representation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999951124191284,
                    "sentence": "The network outputs distributions for various spatial derivatives at each location, allowing it to express confidence and ambiguity about different aspects of the scene geometry.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999952912330627,
                    "sentence": "The authors then employ a globalization procedure to combine these local predictions and estimate the scene depth map.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999927282333374,
                    "sentence": "The main claims of the paper are that this approach can effectively summarize the depth cues present in a single image and produce accurate depth estimates.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999944567680359,
                    "sentence": "The authors support these claims through experiments on the NYU v2 depth benchmark, where their method achieves state-of-the-art performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963641166687,
                    "sentence": "The paper is well-written, and the authors provide a clear and detailed explanation of their approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973773956299,
                    "sentence": "The use of an overcomplete representation and probability distributions to model local coefficients is a novel and interesting idea.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999969601631165,
                    "sentence": "The globalization procedure is also well-motivated and effectively combines the local predictions to produce a coherent depth estimate.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973177909851,
                    "sentence": "The experimental results are impressive, and the authors provide a thorough evaluation of their method, including an ablation study to analyze the contribution of different components of their representation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999975562095642,
                    "sentence": "The comparison to other state-of-the-art approaches is also comprehensive, and the results demonstrate the effectiveness of the proposed method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999934434890747,
                    "sentence": "However, there are some limitations to the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99989253282547,
                    "sentence": "The authors could provide more analysis of the failure cases, such as the example in column 6 of Figure 4, where the method mis-estimates the depth of a large planar region.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998216032981873,
                    "sentence": "Additionally, the computational cost of the method is relatively high, taking 24 seconds per image on an NVIDIA Titan X GPU.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999339580535889,
                    "sentence": "Overall, the paper is well-organized, and the authors provide a clear and detailed explanation of their approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999223351478577,
                    "sentence": "The experimental results are impressive, and the method achieves state-of-the-art performance on the NYU v2 depth benchmark.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999662041664124,
                    "sentence": "The paper has the potential to make a significant contribution to the field of computer vision, and the authors' ideas and approach are likely to be of interest to researchers and practitioners in the field.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999112486839294,
                    "sentence": "Arguments pro acceptance:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999977707862854,
                    "sentence": "* The paper proposes a novel and interesting approach to monocular depth estimation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999745488166809,
                    "sentence": "* The authors provide a clear and detailed explanation of their method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999600648880005,
                    "sentence": "* The experimental results are impressive, and the method achieves state-of-the-art performance on the NYU v2 depth benchmark.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999572038650513,
                    "sentence": "* The paper has the potential to make a significant contribution to the field of computer vision.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998409748077393,
                    "sentence": "Arguments con acceptance:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999574422836304,
                    "sentence": "* The computational cost of the method is relatively high.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999212622642517,
                    "sentence": "* The authors could provide more analysis of the failure cases.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999239444732666,
                    "sentence": "* The paper could benefit from more discussion of the limitations and potential extensions of the method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9984984300152882,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984984300152882,
                "mixed": 0.0015015699847118259
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984984300152882,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984984300152882,
                    "human": 0,
                    "mixed": 0.0015015699847118259
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes a novel approach to monocular depth estimation by training a neural network to predict probability distributions over local coefficients of the scene depth map in an overcomplete representation. The network outputs distributions for various spatial derivatives at each location, allowing it to express confidence and ambiguity about different aspects of the scene geometry. The authors then employ a globalization procedure to combine these local predictions and estimate the scene depth map.\nThe main claims of the paper are that this approach can effectively summarize the depth cues present in a single image and produce accurate depth estimates. The authors support these claims through experiments on the NYU v2 depth benchmark, where their method achieves state-of-the-art performance.\nThe paper is well-written, and the authors provide a clear and detailed explanation of their approach. The use of an overcomplete representation and probability distributions to model local coefficients is a novel and interesting idea. The globalization procedure is also well-motivated and effectively combines the local predictions to produce a coherent depth estimate.\nThe experimental results are impressive, and the authors provide a thorough evaluation of their method, including an ablation study to analyze the contribution of different components of their representation. The comparison to other state-of-the-art approaches is also comprehensive, and the results demonstrate the effectiveness of the proposed method.\nHowever, there are some limitations to the paper. The authors could provide more analysis of the failure cases, such as the example in column 6 of Figure 4, where the method mis-estimates the depth of a large planar region. Additionally, the computational cost of the method is relatively high, taking 24 seconds per image on an NVIDIA Titan X GPU.\nOverall, the paper is well-organized, and the authors provide a clear and detailed explanation of their approach. The experimental results are impressive, and the method achieves state-of-the-art performance on the NYU v2 depth benchmark. The paper has the potential to make a significant contribution to the field of computer vision, and the authors' ideas and approach are likely to be of interest to researchers and practitioners in the field.\nArguments pro acceptance:\n* The paper proposes a novel and interesting approach to monocular depth estimation.\n* The authors provide a clear and detailed explanation of their method.\n* The experimental results are impressive, and the method achieves state-of-the-art performance on the NYU v2 depth benchmark.\n* The paper has the potential to make a significant contribution to the field of computer vision.\nArguments con acceptance:\n* The computational cost of the method is relatively high.\n* The authors could provide more analysis of the failure cases.\n* The paper could benefit from more discussion of the limitations and potential extensions of the method."
        }
    ]
}