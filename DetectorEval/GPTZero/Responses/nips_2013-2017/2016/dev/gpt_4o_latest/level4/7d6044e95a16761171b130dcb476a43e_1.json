{
    "version": "2025-01-09-base",
    "scanId": "29fdbf77-ad2a-43e9-be94-14c0981240d6",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9995874762535095,
                    "sentence": "The authors propose a family of probabilistic models that integrate structured prior distributions, represented as graphical models, with highly nonlinear observation models implemented via neural networks, arguing that these two paradigms have complementary strengths.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991613030433655,
                    "sentence": "The aim is to leverage the interpretability and efficient inference mechanisms of graphical models alongside the representation learning capabilities of neural networks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9976483583450317,
                    "sentence": "The primary contribution of the paper is an efficient stochastic variational inference algorithm for training such hybrid models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9983371496200562,
                    "sentence": "This algorithm employs a recognition model, implemented as a neural network, to address the non-conjugate observation model, enabling efficient mean-field updates for inferring the local latent variables.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9964815974235535,
                    "sentence": "The experimental section is limited, presenting qualitative results on a synthetic dataset and a small dataset of low-resolution video.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.990996778011322,
                    "sentence": "The use of a neural recognition model to approximate conjugacy in a surrogate objective for inferring local latent variables is a compelling and significant idea.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9941281080245972,
                    "sentence": "However, this approach is less direct compared to the variational autoencoder (VAE) framework, where the recognition model directly parameterizes the variational posterior.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9939995408058167,
                    "sentence": "A comparison between these two approaches, along with a discussion of their respective advantages and disadvantages, would have been valuable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.997221827507019,
                    "sentence": "Overall, the paper is well-written, though certain sections are dense and lack sufficient detail.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9958601593971252,
                    "sentence": "The supplementary material was crucial for clarifying aspects that were unclear in the main text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.986321210861206,
                    "sentence": "While the experimental section is sparse and lacks quantitative results, I do not view this as a major drawback for a paper with such a strong conceptual contribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9859225749969482,
                    "sentence": "However, the related work section overlooks several recent papers on sequence modeling within the VAE framework, as well as the notable work of Titsias and Lazaro-Gredilla [1].",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9814780354499817,
                    "sentence": "References",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9923676252365112,
                    "sentence": "[1] M. K. Titsias and M. Lazaro-Gredilla.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9958651065826416,
                    "sentence": "Doubly Stochastic Variational Bayes for Non-Conjugate Inference, ICML, 2014.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9961636828644501,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9961636828644501,
                "mixed": 0.003836317135549872
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9961636828644501,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9961636828644501,
                    "human": 0,
                    "mixed": 0.003836317135549872
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The authors propose a family of probabilistic models that integrate structured prior distributions, represented as graphical models, with highly nonlinear observation models implemented via neural networks, arguing that these two paradigms have complementary strengths. The aim is to leverage the interpretability and efficient inference mechanisms of graphical models alongside the representation learning capabilities of neural networks. The primary contribution of the paper is an efficient stochastic variational inference algorithm for training such hybrid models. This algorithm employs a recognition model, implemented as a neural network, to address the non-conjugate observation model, enabling efficient mean-field updates for inferring the local latent variables. \nThe experimental section is limited, presenting qualitative results on a synthetic dataset and a small dataset of low-resolution video. The use of a neural recognition model to approximate conjugacy in a surrogate objective for inferring local latent variables is a compelling and significant idea. However, this approach is less direct compared to the variational autoencoder (VAE) framework, where the recognition model directly parameterizes the variational posterior. A comparison between these two approaches, along with a discussion of their respective advantages and disadvantages, would have been valuable. \nOverall, the paper is well-written, though certain sections are dense and lack sufficient detail. The supplementary material was crucial for clarifying aspects that were unclear in the main text. While the experimental section is sparse and lacks quantitative results, I do not view this as a major drawback for a paper with such a strong conceptual contribution. However, the related work section overlooks several recent papers on sequence modeling within the VAE framework, as well as the notable work of Titsias and Lazaro-Gredilla [1]. \nReferences \n[1] M. K. Titsias and M. Lazaro-Gredilla. Doubly Stochastic Variational Bayes for Non-Conjugate Inference, ICML, 2014."
        }
    ]
}