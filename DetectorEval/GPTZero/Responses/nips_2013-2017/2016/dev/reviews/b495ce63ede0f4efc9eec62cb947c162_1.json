{
    "version": "2025-01-09-base",
    "scanId": "bd0fbc84-2765-4407-a945-5aecae21555c",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.7123905420303345,
                    "sentence": "This paper presents a deep learning approach to learn correspondences between pairs of images.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7025235891342163,
                    "sentence": "They use a FCN with a novel correspondence contrastive loss and active hard-negative mining.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6248497366905212,
                    "sentence": "They demonstrate the performance of this approach on a number of public datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11549238115549088,
                    "sentence": "A well written description of the methods with convincing results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08684105426073074,
                    "sentence": "More details about the \"semantic \" aspect of this approach would be helpful.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.00010005932717626924
                }
            ],
            "completely_generated_prob": 0.42460510328068046,
            "class_probabilities": {
                "human": 0.5710206561360874,
                "ai": 0.42460510328068046,
                "mixed": 0.004374240583232077
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.5710206561360874,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.42460510328068046,
                    "human": 0.5710206561360874,
                    "mixed": 0.004374240583232077
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a deep learning approach to learn correspondences between pairs of images. They use a FCN with a novel correspondence contrastive loss and active hard-negative mining. They demonstrate the performance of this approach on a number of public datasets. A well written description of the methods with convincing results. More details about the \"semantic \" aspect of this approach would be helpful."
        }
    ]
}