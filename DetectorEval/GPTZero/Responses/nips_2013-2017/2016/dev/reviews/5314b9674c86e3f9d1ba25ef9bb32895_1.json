{
    "version": "2025-01-09-base",
    "scanId": "62ba9e70-a56d-4968-ba1e-93e9da2498c0",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.22609417140483856,
                    "sentence": "The paper proposes the use of the matrix product states decomposition (MPS) of a tensor network for a general multiclass supervised classification problem.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2342936247587204,
                    "sentence": "The paper is well written, however assumes the reader has some familiarity with the concepts of MPS and tensor networks which are commonly used techniques in the field of quantum physics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18081900477409363,
                    "sentence": "The proposed methodology builds on prior work (citations [3] and [4]) and the contribution of the paper is incremental and somehow similar in nature to the aforementioned work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.29210272431373596,
                    "sentence": "The main contributions of the paper can be summarized into two main parts: a) It defines a tensor inspired encoding (kernel) that can be applied to any classification problem where the data is represented in fixed length vector form.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.38246867060661316,
                    "sentence": "b) It optimizes the MPS representation for the classification task at hand by using gradient descent as opposed to [4] where the MPS representation is chosen first in an unsupervised manner and then used it afterwards in a disjoint fashion for the classification task by applying a classification algorithm to the resulting transformed data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3598279654979706,
                    "sentence": "1) The paper assumes some familiarity with tensor networks and MPS.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.35122150182724,
                    "sentence": "This may be common in the quantum physics area but not so on the NIPS community (In my opinion).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.27835309505462646,
                    "sentence": "Hence the paper could be greatly improved by better introduction the reader to the concepts and build from the bottom up.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0018263153033331037,
                    "sentence": "This is not an easy task due to the amount of space available in a NIPS paper but nonetheless its necessary to improve readability of the paper 2) Please add dimensions to the vector and matrices.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0023618657141923904,
                    "sentence": "This would help improve readability as well.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0020271390676498413,
                    "sentence": "3) In line 153 it is mentioned that a zig-zag ordering is used but Figure 8 does not seems to illustrate a zig-zag pattern.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001868056715466082,
                    "sentence": "Is this a typo?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003216069657355547,
                    "sentence": "Did you use the wrong Figure?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0013184044510126114,
                    "sentence": "Please clarify.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0022261515259742737,
                    "sentence": "4) Please elaborate regarding the differences between the work presented here and [3] and [4] early on the paper, for a reader with few or no experience with tensor networks this information can be useful to follow the paper and understand the contributions of the work presented here.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002653468167409301,
                    "sentence": "5) Also for this audience the connection to Neural networks is very informative, however is briefly mentioned at the end of the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0022114510647952557,
                    "sentence": "Please elaborate on this topic.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0032340551260858774,
                    "sentence": "6) Can you explain how initialization is done?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005549376830458641,
                    "sentence": "How sensitive the problem is to local minima?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002190224127843976,
                    "sentence": "How did you deal with this problem?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004149127285927534,
                    "sentence": "7) It would be helpful to mention what tools where used to calculate SVD.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 21,
                    "completely_generated_prob": 1.369041255298935e-18
                }
            ],
            "completely_generated_prob": 0.07288466908684726,
            "class_probabilities": {
                "human": 0.9271153309131527,
                "ai": 0.07288466908684726,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9271153309131527,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.07288466908684726,
                    "human": 0.9271153309131527,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper proposes the use of the matrix product states decomposition (MPS) of a tensor network for a general multiclass supervised classification problem. The paper is well written, however assumes the reader has some familiarity with the concepts of MPS and tensor networks which are commonly used techniques in the field of quantum physics. The proposed methodology builds on prior work (citations [3] and [4]) and the contribution of the paper is incremental and somehow similar in nature to the aforementioned work. The main contributions of the paper can be summarized into two main parts: a) It defines a tensor inspired encoding (kernel) that can be applied to any classification problem where the data is represented in fixed length vector form. b) It optimizes the MPS representation for the classification task at hand by using gradient descent as opposed to [4] where the MPS representation is chosen first in an unsupervised manner and then used it afterwards in a disjoint fashion for the classification task by applying a classification algorithm to the resulting transformed data. 1) The paper assumes some familiarity with tensor networks and MPS. This may be common in the quantum physics area but not so on the NIPS community (In my opinion). Hence the paper could be greatly improved by better introduction the reader to the concepts and build from the bottom up. This is not an easy task due to the amount of space available in a NIPS paper but nonetheless its necessary to improve readability of the paper 2) Please add dimensions to the vector and matrices. This would help improve readability as well. 3) In line 153 it is mentioned that a zig-zag ordering is used but Figure 8 does not seems to illustrate a zig-zag pattern. Is this a typo? Did you use the wrong Figure? Please clarify. 4) Please elaborate regarding the differences between the work presented here and [3] and [4] early on the paper, for a reader with few or no experience with tensor networks this information can be useful to follow the paper and understand the contributions of the work presented here. 5) Also for this audience the connection to Neural networks is very informative, however is briefly mentioned at the end of the paper. Please elaborate on this topic. 6) Can you explain how initialization is done? How sensitive the problem is to local minima? How did you deal with this problem? 7) It would be helpful to mention what tools where used to calculate SVD."
        }
    ]
}