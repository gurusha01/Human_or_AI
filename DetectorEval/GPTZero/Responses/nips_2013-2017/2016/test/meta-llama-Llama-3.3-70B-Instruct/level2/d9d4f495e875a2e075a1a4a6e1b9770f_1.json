{
    "version": "2025-01-09-base",
    "scanId": "d688d939-e4a4-4a31-979d-88be4b64610b",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999994039535522,
                    "sentence": "This paper presents a novel approach to video prediction, specifically designed for interactive agents such as robots.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999999463558197,
                    "sentence": "The authors propose an action-conditioned video prediction model that explicitly models pixel motion, allowing it to generalize to previously unseen objects.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999992847442627,
                    "sentence": "The model is trained on a large dataset of robot interactions, consisting of 59,000 sequences with 1.5 million video frames.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999989867210388,
                    "sentence": "The experiments demonstrate that the proposed method outperforms prior video prediction methods, both quantitatively and qualitatively, on multiple metrics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "The main claims of the paper are: (1) the proposed model can predict future video frames more accurately than prior methods, and (2) the model can generalize to previously unseen objects.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999990463256836,
                    "sentence": "The authors support these claims with extensive experiments on two datasets: a robotic pushing dataset and a human motion dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999989867210388,
                    "sentence": "The results show that the proposed model achieves state-of-the-art performance on both datasets, and that it can predict plausible video sequences more than 10 time steps into the future.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "The paper is well-written, and the authors provide a clear and concise explanation of the proposed method and the experiments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "The related work section is thorough, and the authors provide a good overview of the current state of video prediction research.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986290931702,
                    "sentence": "The paper also includes a detailed description of the dataset collection process and the experimental setup, which is helpful for reproducibility.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9567173719406128,
                    "sentence": "The strengths of the paper are: (1) the proposed model is novel and well-motivated, (2) the experiments are extensive and well-designed, and (3) the results are impressive and demonstrate the effectiveness of the proposed method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.900304913520813,
                    "sentence": "The weaknesses of the paper are: (1) the model is complex and may be difficult to implement, and (2) the paper could benefit from more analysis of the limitations of the proposed method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8260583877563477,
                    "sentence": "Overall, I believe that this paper is a strong contribution to the field of video prediction and interactive agents.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.926268458366394,
                    "sentence": "The proposed method is novel and well-motivated, and the experiments demonstrate its effectiveness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8280558586120605,
                    "sentence": "I would recommend accepting this paper for publication.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6483646631240845,
                    "sentence": "Arguments pro acceptance:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9494181275367737,
                    "sentence": "* The proposed method is novel and well-motivated",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9143617153167725,
                    "sentence": "* The experiments are extensive and well-designed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8813466429710388,
                    "sentence": "* The results are impressive and demonstrate the effectiveness of the proposed method",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8465093970298767,
                    "sentence": "* The paper is well-written and provides a clear and concise explanation of the proposed method and the experiments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8002899885177612,
                    "sentence": "Arguments con acceptance:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9249527454376221,
                    "sentence": "* The model is complex and may be difficult to implement",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8754844069480896,
                    "sentence": "* The paper could benefit from more analysis of the limitations of the proposed method",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.888989269733429,
                    "sentence": "* The paper may not provide enough comparison to other state-of-the-art methods",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8395870327949524,
                    "sentence": "Rating: 9/10",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7636507153511047,
                    "sentence": "Recommendation: Accept with minor revisions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7125717401504517,
                    "sentence": "The authors should consider adding more analysis of the limitations of the proposed method and providing more comparison to other state-of-the-art methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9967818260192871,
                    "sentence": "Additionally, the authors should consider simplifying the model and providing more implementation details to make it easier to reproduce the results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.07332528267997859
                }
            ],
            "completely_generated_prob": 0.7995711047355243,
            "class_probabilities": {
                "human": 0.19427518060025914,
                "ai": 0.7995711047355243,
                "mixed": 0.006153714664216576
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.7995711047355243,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.7995711047355243,
                    "human": 0.19427518060025914,
                    "mixed": 0.006153714664216576
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a novel approach to video prediction, specifically designed for interactive agents such as robots. The authors propose an action-conditioned video prediction model that explicitly models pixel motion, allowing it to generalize to previously unseen objects. The model is trained on a large dataset of robot interactions, consisting of 59,000 sequences with 1.5 million video frames. The experiments demonstrate that the proposed method outperforms prior video prediction methods, both quantitatively and qualitatively, on multiple metrics.\nThe main claims of the paper are: (1) the proposed model can predict future video frames more accurately than prior methods, and (2) the model can generalize to previously unseen objects. The authors support these claims with extensive experiments on two datasets: a robotic pushing dataset and a human motion dataset. The results show that the proposed model achieves state-of-the-art performance on both datasets, and that it can predict plausible video sequences more than 10 time steps into the future.\nThe paper is well-written, and the authors provide a clear and concise explanation of the proposed method and the experiments. The related work section is thorough, and the authors provide a good overview of the current state of video prediction research. The paper also includes a detailed description of the dataset collection process and the experimental setup, which is helpful for reproducibility.\nThe strengths of the paper are: (1) the proposed model is novel and well-motivated, (2) the experiments are extensive and well-designed, and (3) the results are impressive and demonstrate the effectiveness of the proposed method. The weaknesses of the paper are: (1) the model is complex and may be difficult to implement, and (2) the paper could benefit from more analysis of the limitations of the proposed method.\nOverall, I believe that this paper is a strong contribution to the field of video prediction and interactive agents. The proposed method is novel and well-motivated, and the experiments demonstrate its effectiveness. I would recommend accepting this paper for publication.\nArguments pro acceptance:\n* The proposed method is novel and well-motivated\n* The experiments are extensive and well-designed\n* The results are impressive and demonstrate the effectiveness of the proposed method\n* The paper is well-written and provides a clear and concise explanation of the proposed method and the experiments\nArguments con acceptance:\n* The model is complex and may be difficult to implement\n* The paper could benefit from more analysis of the limitations of the proposed method\n* The paper may not provide enough comparison to other state-of-the-art methods\nRating: 9/10\nRecommendation: Accept with minor revisions. The authors should consider adding more analysis of the limitations of the proposed method and providing more comparison to other state-of-the-art methods. Additionally, the authors should consider simplifying the model and providing more implementation details to make it easier to reproduce the results."
        }
    ]
}