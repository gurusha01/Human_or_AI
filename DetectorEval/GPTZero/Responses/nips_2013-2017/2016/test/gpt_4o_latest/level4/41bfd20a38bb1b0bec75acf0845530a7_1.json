{
    "version": "2025-01-09-base",
    "scanId": "3f42b706-93ff-4799-bdc2-715fcd214419",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.007208392024040222,
                    "sentence": "This paper investigates the use of structured sparsity (group lasso) to reduce the size of convolutional neural networks in a manner that is more structured and thus better suited for vectorized computation on GPUs compared to the recently explored l1 regularization by Han et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011123512871563435,
                    "sentence": "I consider this to be a significant contribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01250526774674654,
                    "sentence": "The experimental results are promising, and I find the approach to depth regularization particularly intriguing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006427167449146509,
                    "sentence": "Overall, this is a well-executed paper with a solid set of experimental findings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9956868290901184,
                    "sentence": "Enhancing the efficiency of DNNs is a fundamental challenge in deep learning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985156059265137,
                    "sentence": "Moreover, sparsification offers additional benefits, such as improved regularization and enhanced interpretability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996774196624756,
                    "sentence": "However, the level of novelty is somewhat limited, as structured sparsity is already a well-established concept.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 7,
                    "completely_generated_prob": 0.01437310773797646
                }
            ],
            "completely_generated_prob": 0.425683952633728,
            "class_probabilities": {
                "human": 0,
                "ai": 0.1486320947325439,
                "mixed": 0.851367905267456
            },
            "average_generated_prob": 0.42857142857142855,
            "predicted_class": "mixed",
            "confidence_score": 0.851367905267456,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.1486320947325439,
                    "human": 0,
                    "mixed": 0.851367905267456
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text may include parts written by AI.",
            "document_classification": "MIXED",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper investigates the use of structured sparsity (group lasso) to reduce the size of convolutional neural networks in a manner that is more structured and thus better suited for vectorized computation on GPUs compared to the recently explored l1 regularization by Han et al. I consider this to be a significant contribution. The experimental results are promising, and I find the approach to depth regularization particularly intriguing. Overall, this is a well-executed paper with a solid set of experimental findings. Enhancing the efficiency of DNNs is a fundamental challenge in deep learning. Moreover, sparsification offers additional benefits, such as improved regularization and enhanced interpretability. However, the level of novelty is somewhat limited, as structured sparsity is already a well-established concept."
        }
    ]
}