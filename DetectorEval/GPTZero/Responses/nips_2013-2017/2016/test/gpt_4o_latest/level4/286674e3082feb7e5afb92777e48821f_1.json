{
    "version": "2025-01-09-base",
    "scanId": "a4700c7c-9046-4134-b96c-f1ec9b7a482c",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9874433875083923,
                    "sentence": "The authors present novel theoretical contributions to graph clustering that do not rely on assumptions about the graph's generative process (e.g., the observed graph is not assumed to follow a specific generative model like the stochastic block model).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9869700074195862,
                    "sentence": "The central idea of the paper is that if a graph clustering method identifies a clustering that reasonably fits the graph (under a specific definition), then any other clustering that fits the graph equally well must be close to the first one.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.995294451713562,
                    "sentence": "This work is highly interesting and tackles a significant problem by offering distribution-free results for graph clustering.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9976291060447693,
                    "sentence": "Although some material has been relegated to the supplementary section due to the conference's page limit, the paper remains clear and comprehensible without requiring frequent reference to this additional content.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9979008436203003,
                    "sentence": "I am, however, skeptical about the use of \"hats\" to denote observed quantities (e.g., \\(\\hat{L}\\) for the observed Laplacian), as this notation choice may not be ideal.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987718462944031,
                    "sentence": "That said, the paper is generally well-written and reasonably clear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990431070327759,
                    "sentence": "The results themselves are compelling, well-discussed, and supported by illustrative examples.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995676875114441,
                    "sentence": "Nevertheless, they are not without limitations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.062325067818164825,
                    "sentence": "As demonstrated in the experimental section, certain real-world graphs require smoothing to reveal structure that aligns with the theoretical framework proposed by the authors, whereas many classical algorithms can recover the ground truth structure without such preprocessing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.22920924425125122,
                    "sentence": "Moreover, two key limitations stand out: 1) The main result for PFM employs a non-standard distance measure between clusterings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.360981285572052,
                    "sentence": "While the authors argue that this measure may be more natural than the classical one, this claim is debatable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6907620429992676,
                    "sentence": "2) The results rely on a form of \"proxy\" model, where a model (e.g., a PFM) is reconstructed from a clustering and then compared to the original graph, rather than directly comparing the clustering to the graph or its generative process.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9545610547065735,
                    "sentence": "While this approach is natural within the authors' chosen framework, it imposes strong constraints on what constitutes a \"good\" clustering for a given graph.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9646865725517273,
                    "sentence": "Specifically, it requires that the graph be well-approximated in the normalized Laplacian sense.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9729350805282593,
                    "sentence": "While such constraints are necessary to derive rigorous results, it raises questions about the broader implications of these restrictions, particularly in light of the framework's limitations on certain real-world datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.6535213355143276
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.06788505859236459
                }
            ],
            "completely_generated_prob": 0.8596764774936939,
            "class_probabilities": {
                "human": 0.1099278184806362,
                "ai": 0.8596764774936939,
                "mixed": 0.030395704025669885
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8596764774936939,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8596764774936939,
                    "human": 0.1099278184806362,
                    "mixed": 0.030395704025669885
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The authors present novel theoretical contributions to graph clustering that do not rely on assumptions about the graph's generative process (e.g., the observed graph is not assumed to follow a specific generative model like the stochastic block model). The central idea of the paper is that if a graph clustering method identifies a clustering that reasonably fits the graph (under a specific definition), then any other clustering that fits the graph equally well must be close to the first one. This work is highly interesting and tackles a significant problem by offering distribution-free results for graph clustering. Although some material has been relegated to the supplementary section due to the conference's page limit, the paper remains clear and comprehensible without requiring frequent reference to this additional content. \nI am, however, skeptical about the use of \"hats\" to denote observed quantities (e.g., \\(\\hat{L}\\) for the observed Laplacian), as this notation choice may not be ideal. That said, the paper is generally well-written and reasonably clear. The results themselves are compelling, well-discussed, and supported by illustrative examples. Nevertheless, they are not without limitations. As demonstrated in the experimental section, certain real-world graphs require smoothing to reveal structure that aligns with the theoretical framework proposed by the authors, whereas many classical algorithms can recover the ground truth structure without such preprocessing. \nMoreover, two key limitations stand out: 1) The main result for PFM employs a non-standard distance measure between clusterings. While the authors argue that this measure may be more natural than the classical one, this claim is debatable. 2) The results rely on a form of \"proxy\" model, where a model (e.g., a PFM) is reconstructed from a clustering and then compared to the original graph, rather than directly comparing the clustering to the graph or its generative process. While this approach is natural within the authors' chosen framework, it imposes strong constraints on what constitutes a \"good\" clustering for a given graph. Specifically, it requires that the graph be well-approximated in the normalized Laplacian sense. While such constraints are necessary to derive rigorous results, it raises questions about the broader implications of these restrictions, particularly in light of the framework's limitations on certain real-world datasets."
        }
    ]
}