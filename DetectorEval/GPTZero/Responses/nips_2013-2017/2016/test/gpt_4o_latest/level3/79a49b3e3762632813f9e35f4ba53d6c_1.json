{
    "version": "2025-01-09-base",
    "scanId": "090caaac-a74d-463f-adc8-b421a52eb87c",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999967813491821,
                    "sentence": "This paper addresses the problem of estimating class priors from positive-unlabeled (PU) data, extending prior work by incorporating noisy positive samples.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999957084655762,
                    "sentence": "The authors propose two practical classification algorithms that explicitly model noise in positive labels and utilize univariate transforms to handle high-dimensional data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999995231628418,
                    "sentence": "The theoretical foundation is built on the AlphaMax framework, and the authors prove that their univariate transforms preserve the class prior, enabling effective estimation without relying on kernel density estimation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999949336051941,
                    "sentence": "While the paper builds on prior work (e.g., Jain et al., 2016), it aims to address practical challenges in real-world, noisy, high-dimensional datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960660934448,
                    "sentence": "Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999951720237732,
                    "sentence": "The paper provides a solid theoretical analysis of identifiability issues, which is a critical aspect of learning from noisy PU data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999914765357971,
                    "sentence": "The proposed algorithms are practical and demonstrate competitive performance compared to existing methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999927878379822,
                    "sentence": "By avoiding kernel density estimation, the authors address a significant bottleneck in high-dimensional settings, making their approach more scalable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999987781047821,
                    "sentence": "The theoretical contributions, particularly the proof of class prior preservation under univariate transforms, are well-motivated and relevant to the field.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999895095825195,
                    "sentence": "The experimental results are promising, showcasing the method's robustness to noise and its applicability to real-world data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999856352806091,
                    "sentence": "Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999809861183167,
                    "sentence": "The paper's novelty is a concern, as it closely follows prior work and extends it in a relatively natural way to handle noisy positives.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.24893294274806976,
                    "sentence": "While the theoretical contributions are sound, the main result of relating observed \\( P(y\"x) \\) to the true one is not particularly surprising, given prior work (e.g., Scott et al., 2013).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.3403034508228302,
                    "sentence": "Additionally, the paper lacks sufficient discussion on its distinction from general asymmetric label noise settings and does not compare against several relevant methods (e.g., Sanderson & Scott, Liu & Tao, Ramaswamy et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.28580203652381897,
                    "sentence": "), which weakens its positioning within the broader literature.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8329806327819824,
                    "sentence": "Clarity issues are also present, particularly in the probabilistic model in Figure 1 and the missing results in Section 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8398395776748657,
                    "sentence": "The description of the algorithm in Section 4 could be more explicit, especially regarding its connection to classifier outputs on positive and unlabeled samples.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9275827407836914,
                    "sentence": "Minor writing issues, such as notation inconsistencies and a typo in \"Theorem 1 (identifiablity),\" detract from the overall readability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9558499455451965,
                    "sentence": "Pro and Con Arguments for Acceptance:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9659163951873779,
                    "sentence": "Pro: The paper addresses a practical and important problem, provides a sound theoretical foundation, and proposes scalable algorithms with promising results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.962656557559967,
                    "sentence": "Con: The novelty is limited, clarity issues remain, and the paper lacks sufficient comparison with related work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9416742324829102,
                    "sentence": "Recommendation: While the paper makes a meaningful contribution to the field, addressing clarity issues and providing a more thorough comparison with related work would significantly strengthen it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9345305562019348,
                    "sentence": "I recommend acceptance only if these concerns are adequately addressed in a revision.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 7,
                    "completely_generated_prob": 0.11601769141592862
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.8753704990852369,
            "class_probabilities": {
                "human": 0.11057250597192597,
                "ai": 0.8753704990852369,
                "mixed": 0.014056994942837287
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8753704990852369,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8753704990852369,
                    "human": 0.11057250597192597,
                    "mixed": 0.014056994942837287
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper addresses the problem of estimating class priors from positive-unlabeled (PU) data, extending prior work by incorporating noisy positive samples. The authors propose two practical classification algorithms that explicitly model noise in positive labels and utilize univariate transforms to handle high-dimensional data. The theoretical foundation is built on the AlphaMax framework, and the authors prove that their univariate transforms preserve the class prior, enabling effective estimation without relying on kernel density estimation. While the paper builds on prior work (e.g., Jain et al., 2016), it aims to address practical challenges in real-world, noisy, high-dimensional datasets.\nStrengths: \nThe paper provides a solid theoretical analysis of identifiability issues, which is a critical aspect of learning from noisy PU data. The proposed algorithms are practical and demonstrate competitive performance compared to existing methods. By avoiding kernel density estimation, the authors address a significant bottleneck in high-dimensional settings, making their approach more scalable. The theoretical contributions, particularly the proof of class prior preservation under univariate transforms, are well-motivated and relevant to the field. The experimental results are promising, showcasing the method's robustness to noise and its applicability to real-world data.\nWeaknesses: \nThe paper's novelty is a concern, as it closely follows prior work and extends it in a relatively natural way to handle noisy positives. While the theoretical contributions are sound, the main result of relating observed \\( P(y\"x) \\) to the true one is not particularly surprising, given prior work (e.g., Scott et al., 2013). Additionally, the paper lacks sufficient discussion on its distinction from general asymmetric label noise settings and does not compare against several relevant methods (e.g., Sanderson & Scott, Liu & Tao, Ramaswamy et al.), which weakens its positioning within the broader literature. Clarity issues are also present, particularly in the probabilistic model in Figure 1 and the missing results in Section 3. The description of the algorithm in Section 4 could be more explicit, especially regarding its connection to classifier outputs on positive and unlabeled samples. Minor writing issues, such as notation inconsistencies and a typo in \"Theorem 1 (identifiablity),\" detract from the overall readability.\nPro and Con Arguments for Acceptance: \nPro: The paper addresses a practical and important problem, provides a sound theoretical foundation, and proposes scalable algorithms with promising results. \nCon: The novelty is limited, clarity issues remain, and the paper lacks sufficient comparison with related work.\nRecommendation: While the paper makes a meaningful contribution to the field, addressing clarity issues and providing a more thorough comparison with related work would significantly strengthen it. I recommend acceptance only if these concerns are adequately addressed in a revision."
        }
    ]
}