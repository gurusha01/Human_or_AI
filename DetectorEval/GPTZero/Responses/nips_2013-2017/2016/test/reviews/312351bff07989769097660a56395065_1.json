{
    "version": "2025-01-09-base",
    "scanId": "a4864312-5481-4a60-9bb2-15b071eced9d",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.6964846849441528,
                    "sentence": "The paper proposes a \"neural transducer\" model for sequence-to-sequence tasks that operates in a left-to-right and on-line fashion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6439042091369629,
                    "sentence": "In other words, the model produces output as the input is received instead of waiting until the full input is received like most sequence-to-sequence models do.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4697864055633545,
                    "sentence": "Key ideas used to make the model work include a recurrent attention mechanism, the use of an end-of-block symbol in the output alphabet to indicate when the transducer should move to the next input block, and approximate algorithms based on dynamic programming and beam search for training and inference with the transducer model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3664567172527313,
                    "sentence": "Experiments on the TIMIT speech task show that the model works well and explore some of the design parameters of the model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2666730284690857,
                    "sentence": "This is a well-done paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1882183998823166,
                    "sentence": "It attacks a problem that is worthwhile: how to construct and train a sequence-to-sequence model that can operate on-line instead of waiting for an entire input to be received.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16955961287021637,
                    "sentence": "It clearly describes an architecture for solving the problem, and walks the reader through the issues in the design of each component in the architecture: next-step prediction, the attention mechanism, and modeling the ends of blocks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.262527734041214,
                    "sentence": "It clearly explains the challenges that need to be overcome train the model and perform inference with it, and proposes reasonable approximate algorithms for training and inference.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13449949026107788,
                    "sentence": "The speech recognition experiments used to demonstrate the utility of the transducer model and to explore design issues such as maintenance of recurrent state across block boundaries, block size, design of the attention mechanism, and depth of the model are reasonable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2735762298107147,
                    "sentence": "There are a few issues that should be addressed to improve the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.126184344291687,
                    "sentence": "Page 3, line 93: \"We first compute the probability of l compute the probability of seeing output sequence\" -- editing problem.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09241758286952972,
                    "sentence": "Section 3.4: I was disappointed that there was no discussion of how well or poorly the three different approaches to end-of-block modeling worked.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15574277937412262,
                    "sentence": "I assume that the use of the < e > symbol was best, but how much worse were the other two methods?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21825379133224487,
                    "sentence": "Section 3.5: Computing alignments less frequently than model updates is also quite reminiscent of the use of lattices in sequence-discriminative training of acoustic models in speech recognition, as in D. Povey and P. C. Woodland, \"Large scale discriminative training for speech recognition,\" in Proc.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7549222111701965,
                    "sentence": "ASR Workshop, 2000, http://www.danielpovey.com/files/asr00.pdf, and B. Kingsbury, \"Lattice-based optimization of sequence classification criteria for neural-network acoustic modeling,\" in Proc.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.759400486946106,
                    "sentence": "ICASSP, 2009, https://www.semanticscholar.org/paper/Lattice-based-optimization-of-sequence-Kingsbury/2443dc59cf3d6cc1deba6d3220d61664b1a7eada/pdf In future work on the transducer model, it might be of interest to consider using lattices to represent alignment information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.35539889335632324,
                    "sentence": "Methods developed for rescoring lattices using RNN language models might be useful for dealing with the fact that the neural transducer is conditioned on all of the input up to the present moment and all of the output labels generated up to the present moment.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3023257255554199,
                    "sentence": "See, for example, X. Liu, Y. Wang, X. Chen, M. J. F. Gales, and P. C. Woodland, \"Efficient lattice rescoring using recurrent neural network language models,\" in Proc.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.26266106963157654,
                    "sentence": "ICASSP, 2014, http://mi.eng.cam.ac.uk/projects/cued-rnnlm/papers/RNNLMlatrescore.pdf Page 7, lines 202-203: \"Log Mel filterbanks\" -> \"Log Mel spectra\" Section 4.2: It appears that the TIMIT experiments are not entirely standard.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.42754435539245605,
                    "sentence": "It is typical to collapse the TIMIT phones more than was done in this paper, and to specifically exclude certain data from the training set and to report results only on the core test set.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.33738577365875244,
                    "sentence": "See, for example T. N. Sainath, B. Ramabhadran, M. Picheny, D. Nahamoo, and D. Kanevsky, \"Exemplar-Based Sparse Representation Features: From TIMIT to LVCSR,\" IEEE Transactions on Speech and Audio Processing, 19(8):2598--2613, Nov. 2011, https://36e9b848-a-62cb3a1a-s-sites.googlegroups.com/site/tsainath/tsainathtsap2010submission2column_final.pdf or K. F. Lee and H. W. Hon, \"Speaker-independent Phone Recognition Using Hidden Markov Models,\" IEEE Transacations on Acoustics, Speech and Signal Processing, 37:1641\"\"1648, 1989, http://repository.cmu.edu/cgi/viewcontent.cgi?article=2768&context=compsci The TIMIT experiments would be more easily compared to others if the standard framework were followed and this was clearly stated in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1221809834241867,
                    "sentence": "Section 4.2: You should have tried initializing the transducer by training on the HMM-GMM alignments, and then continuing training with aligments inferred using the transducer.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16096016764640808,
                    "sentence": "This might have led to even better TIMIT performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 23,
                    "completely_generated_prob": 2.3367398512545458e-20
                }
            ],
            "completely_generated_prob": 0.19570930781951335,
            "class_probabilities": {
                "human": 0.8016456582633052,
                "ai": 0.19570930781951335,
                "mixed": 0.00264503391718133
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.8016456582633052,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.19570930781951335,
                    "human": 0.8016456582633052,
                    "mixed": 0.00264503391718133
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper proposes a \"neural transducer\" model for sequence-to-sequence tasks that operates in a left-to-right and on-line fashion. In other words, the model produces output as the input is received instead of waiting until the full input is received like most sequence-to-sequence models do. Key ideas used to make the model work include a recurrent attention mechanism, the use of an end-of-block symbol in the output alphabet to indicate when the transducer should move to the next input block, and approximate algorithms based on dynamic programming and beam search for training and inference with the transducer model. Experiments on the TIMIT speech task show that the model works well and explore some of the design parameters of the model. This is a well-done paper. It attacks a problem that is worthwhile: how to construct and train a sequence-to-sequence model that can operate on-line instead of waiting for an entire input to be received. It clearly describes an architecture for solving the problem, and walks the reader through the issues in the design of each component in the architecture: next-step prediction, the attention mechanism, and modeling the ends of blocks. It clearly explains the challenges that need to be overcome train the model and perform inference with it, and proposes reasonable approximate algorithms for training and inference. The speech recognition experiments used to demonstrate the utility of the transducer model and to explore design issues such as maintenance of recurrent state across block boundaries, block size, design of the attention mechanism, and depth of the model are reasonable. There are a few issues that should be addressed to improve the paper. Page 3, line 93: \"We first compute the probability of l compute the probability of seeing output sequence\" -- editing problem. Section 3.4: I was disappointed that there was no discussion of how well or poorly the three different approaches to end-of-block modeling worked. I assume that the use of the < e > symbol was best, but how much worse were the other two methods? Section 3.5: Computing alignments less frequently than model updates is also quite reminiscent of the use of lattices in sequence-discriminative training of acoustic models in speech recognition, as in D. Povey and P. C. Woodland, \"Large scale discriminative training for speech recognition,\" in Proc. ASR Workshop, 2000, http://www.danielpovey.com/files/asr00.pdf, and B. Kingsbury, \"Lattice-based optimization of sequence classification criteria for neural-network acoustic modeling,\" in Proc. ICASSP, 2009, https://www.semanticscholar.org/paper/Lattice-based-optimization-of-sequence-Kingsbury/2443dc59cf3d6cc1deba6d3220d61664b1a7eada/pdf In future work on the transducer model, it might be of interest to consider using lattices to represent alignment information. Methods developed for rescoring lattices using RNN language models might be useful for dealing with the fact that the neural transducer is conditioned on all of the input up to the present moment and all of the output labels generated up to the present moment. See, for example, X. Liu, Y. Wang, X. Chen, M. J. F. Gales, and P. C. Woodland, \"Efficient lattice rescoring using recurrent neural network language models,\" in Proc. ICASSP, 2014, http://mi.eng.cam.ac.uk/projects/cued-rnnlm/papers/RNNLMlatrescore.pdf Page 7, lines 202-203: \"Log Mel filterbanks\" -> \"Log Mel spectra\" Section 4.2: It appears that the TIMIT experiments are not entirely standard. It is typical to collapse the TIMIT phones more than was done in this paper, and to specifically exclude certain data from the training set and to report results only on the core test set. See, for example T. N. Sainath, B. Ramabhadran, M. Picheny, D. Nahamoo, and D. Kanevsky, \"Exemplar-Based Sparse Representation Features: From TIMIT to LVCSR,\" IEEE Transactions on Speech and Audio Processing, 19(8):2598--2613, Nov. 2011, https://36e9b848-a-62cb3a1a-s-sites.googlegroups.com/site/tsainath/tsainathtsap2010submission2column_final.pdf or K. F. Lee and H. W. Hon, \"Speaker-independent Phone Recognition Using Hidden Markov Models,\" IEEE Transacations on Acoustics, Speech and Signal Processing, 37:1641\"\"1648, 1989, http://repository.cmu.edu/cgi/viewcontent.cgi?article=2768&context=compsci The TIMIT experiments would be more easily compared to others if the standard framework were followed and this was clearly stated in the paper. Section 4.2: You should have tried initializing the transducer by training on the HMM-GMM alignments, and then continuing training with aligments inferred using the transducer. This might have led to even better TIMIT performance."
        }
    ]
}