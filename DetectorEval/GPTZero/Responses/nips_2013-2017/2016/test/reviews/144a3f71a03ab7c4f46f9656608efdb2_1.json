{
    "version": "2025-01-09-base",
    "scanId": "c7f46574-f0d1-4dda-bf06-a9b1f0616724",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.033568497747182846,
                    "sentence": "This paper concerns the constrained optimisation problem of learning Bayesian networks from local scores with ancestral constraints.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03164881840348244,
                    "sentence": "The search is branch-and-bound where the nodes in the search tree are CPDAGs and we 'move down' from CPDAG1 to CPDAG2 by (roughly) choosing a parent set for a BN variable which is not a node in CPDAG1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06348676234483719,
                    "sentence": "Sensible symmetry breaking is effected.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06643307209014893,
                    "sentence": "The search is A where the URLearning system is used to provide a heuristic.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09130599349737167,
                    "sentence": "(Details of how this happens are not given here but are available in an earlier paper).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05010347440838814,
                    "sentence": "Given ancestral constraints, some pruning of the search tree is possible.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10346353054046631,
                    "sentence": "Lemma 3 (supplementary material) is the key result here.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0746675580739975,
                    "sentence": "I believe it to be true, but I don't understand the proof.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03243187069892883,
                    "sentence": "The phrase \"By the EC tree edge generation rules, Gk also contains edge Z - > W\" needs more explanation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.038152653723955154,
                    "sentence": "In addition there are implied constraints ( \"implied constraints\" is the standard terminology, here they are called \"projected constraints\").",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04049075394868851,
                    "sentence": "A bunch of ancestral constraints will imply constraints on edges which can be used for pruning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03494757413864136,
                    "sentence": "Constraints on permissible topological orderings are also inferred (\"ordering constraints\").",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05727457255125046,
                    "sentence": "The approach to doing this is not properly explained.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.033202312886714935,
                    "sentence": "We have the statement that we \"can infer Y < Z from Z not an ancestor of Y\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021373288705945015,
                    "sentence": "The issue is the word \"can\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05094227194786072,
                    "sentence": "Clearly there are DAGs with Z is not an ancestor of Y but Y < Z is a consistent order: the graph with vertices Z and Y and no edges, for example.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025116143748164177,
                    "sentence": "The authors, of course, know this!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0323653444647789,
                    "sentence": "What they mean to say is that if \"Z not an ancestor of Y\" then we can choose to add the constraint Y < Z.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.057669248431921005,
                    "sentence": "So the idea is to 'infer' as many consistent ordering constraints as possible (not just those which are entailed).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08298033475875854,
                    "sentence": "The authors are careful not to 'infer' too many and use a MAXSAT approach to do the inference.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06390047818422318,
                    "sentence": "Experiments are conducted where the number of variables, datapoints and ancestral constraints are varied.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16676664352416992,
                    "sentence": "There is a comparison with the GOBNILP system where the current system is shown to be far faster than GOBNILP.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08352921903133392,
                    "sentence": "As the authors note, without ancestral constraints, GOBNILP performs worse than A approaches when there is no limit on parent set cardinality.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6307947635650635,
                    "sentence": "In the current experiments there is no such limit, so it is difficult to tell whether GOBNILP's poor performance here is due to its 'normal' failure to deal with many parent sets or is more specifically down to dealing with ancestral constraints poorly.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5398998856544495,
                    "sentence": "Also the encoding of ancestral constraints ( given in the supplementary material) is based on a MAXSAT encoding from [Cussens, 2008] rather than, say, the ILP encoding found in Section 3.1.1 of [Cussens, 2010].",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6237393617630005,
                    "sentence": "And this MAXSAT encoding is a poor formulation for an ILP system.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19035476446151733,
                    "sentence": "Why not just have the A(X,Y) binary variables in addition to the I(Z,U) variables and omit the (cubic number of!)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16378197073936462,
                    "sentence": "E(X,Y,Z) variables?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18696346879005432,
                    "sentence": "I think all that is then needed is the transitivity constraints on the A(X,Y) variables and the following constraints linking A and I variables: A(X,Y) \\geq \\sum{U:X \\in U} I(Y,U) In other words if X is a parent of Y then X is an ancestor of Y.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.25789445638656616,
                    "sentence": "This formulation provides a far tighter linear relaxation and should provide much better performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13200326263904572,
                    "sentence": "This is the approach of Section 3.1.1 of [Cussens, 2010] for a total ordering on variables but with a constraint dropped since ancestor is a partial, not total oder.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18536868691444397,
                    "sentence": "I am confident that even with a sensible ILP formulation of ancestral constraints the current system will outperform GOBNILP, but the paper is weakened by comparing to a poor formulation rather than a sensible one.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10154388844966888,
                    "sentence": "It would be interesting to compare the current method to that of van Beek and Hoffmann, particularly since it often outperforms GOBNILP.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1641770601272583,
                    "sentence": "I don't think it would be too hard to adapt that method to allow ancestral constraints to be posted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1525055319070816,
                    "sentence": "The paper by van Beek and Hoffmann is not mentioned by the current authors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17977836728096008,
                    "sentence": "[Cussens, 2010] James Cussens.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2525772750377655,
                    "sentence": "Maximum likelihood pedigree reconstruction using integer programming\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16797387599945068,
                    "sentence": "WCB'10.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21774891018867493,
                    "sentence": "Peter van Beek and Hella-Franziska Hoffmann.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3189481198787689,
                    "sentence": "Machine learning of Bayesian networks using constraint programming.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2927972376346588,
                    "sentence": "Proceedings of CP 2015, Cork, Ireland, August, 2015.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 41,
                    "completely_generated_prob": 2.274134500326115e-36
                }
            ],
            "completely_generated_prob": 0.14708607016012423,
            "class_probabilities": {
                "human": 0.8525399650639967,
                "ai": 0.14708607016012423,
                "mixed": 0.00037396477587904874
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.8525399650639967,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.14708607016012423,
                    "human": 0.8525399650639967,
                    "mixed": 0.00037396477587904874
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper concerns the constrained optimisation problem of learning Bayesian networks from local scores with ancestral constraints. The search is branch-and-bound where the nodes in the search tree are CPDAGs and we 'move down' from CPDAG1 to CPDAG2 by (roughly) choosing a parent set for a BN variable which is not a node in CPDAG1. Sensible symmetry breaking is effected. The search is A where the URLearning system is used to provide a heuristic. (Details of how this happens are not given here but are available in an earlier paper). Given ancestral constraints, some pruning of the search tree is possible. Lemma 3 (supplementary material) is the key result here. I believe it to be true, but I don't understand the proof. The phrase \"By the EC tree edge generation rules, Gk also contains edge Z - > W\" needs more explanation. In addition there are implied constraints ( \"implied constraints\" is the standard terminology, here they are called \"projected constraints\"). A bunch of ancestral constraints will imply constraints on edges which can be used for pruning. Constraints on permissible topological orderings are also inferred (\"ordering constraints\"). The approach to doing this is not properly explained. We have the statement that we \"can infer Y < Z from Z not an ancestor of Y\". The issue is the word \"can\". Clearly there are DAGs with Z is not an ancestor of Y but Y < Z is a consistent order: the graph with vertices Z and Y and no edges, for example. The authors, of course, know this! What they mean to say is that if \"Z not an ancestor of Y\" then we can choose to add the constraint Y < Z. So the idea is to 'infer' as many consistent ordering constraints as possible (not just those which are entailed). The authors are careful not to 'infer' too many and use a MAXSAT approach to do the inference. Experiments are conducted where the number of variables, datapoints and ancestral constraints are varied. There is a comparison with the GOBNILP system where the current system is shown to be far faster than GOBNILP. As the authors note, without ancestral constraints, GOBNILP performs worse than A approaches when there is no limit on parent set cardinality. In the current experiments there is no such limit, so it is difficult to tell whether GOBNILP's poor performance here is due to its 'normal' failure to deal with many parent sets or is more specifically down to dealing with ancestral constraints poorly. Also the encoding of ancestral constraints ( given in the supplementary material) is based on a MAXSAT encoding from [Cussens, 2008] rather than, say, the ILP encoding found in Section 3.1.1 of [Cussens, 2010]. And this MAXSAT encoding is a poor formulation for an ILP system. Why not just have the A(X,Y) binary variables in addition to the I(Z,U) variables and omit the (cubic number of!) E(X,Y,Z) variables? I think all that is then needed is the transitivity constraints on the A(X,Y) variables and the following constraints linking A and I variables: A(X,Y) \\geq \\sum{U:X \\in U} I(Y,U) In other words if X is a parent of Y then X is an ancestor of Y. This formulation provides a far tighter linear relaxation and should provide much better performance. This is the approach of Section 3.1.1 of [Cussens, 2010] for a total ordering on variables but with a constraint dropped since ancestor is a partial, not total oder. I am confident that even with a sensible ILP formulation of ancestral constraints the current system will outperform GOBNILP, but the paper is weakened by comparing to a poor formulation rather than a sensible one. It would be interesting to compare the current method to that of van Beek and Hoffmann, particularly since it often outperforms GOBNILP. I don't think it would be too hard to adapt that method to allow ancestral constraints to be posted. The paper by van Beek and Hoffmann is not mentioned by the current authors. [Cussens, 2010] James Cussens. Maximum likelihood pedigree reconstruction using integer programming\". WCB'10. Peter van Beek and Hella-Franziska Hoffmann. Machine learning of Bayesian networks using constraint programming. Proceedings of CP 2015, Cork, Ireland, August, 2015."
        }
    ]
}