{
    "version": "2025-01-09-base",
    "scanId": "ddf3f9e1-2326-405e-ae0c-fcd31fdb4df9",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9998347759246826,
                    "sentence": "Paraphrased Review: Variational Laws of Visual Attention for Dynamic Scenes",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991372227668762,
                    "sentence": "The authors explore the regions in static and dynamic images that humans are most likely to attend to.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986497759819031,
                    "sentence": "They propose a model by defining three foundational principles of visual attention, conceptualized as an energy function minimized by eye movements: (1) Eye movements are restricted by a harmonic oscillator at the image boundaries within a retina of limited size.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9977458119392395,
                    "sentence": "(2) A \"curiosity-driven principle\" emphasizes areas with significant brightness variations in both fine and blurred versions of the image.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994684457778931,
                    "sentence": "(3) Brightness invariance, which increases in response to brightness changes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984368681907654,
                    "sentence": "Using a cost function derived from these principles, the authors formulate differential equations to predict eye movements across static and dynamic images, based on initial eye position and velocity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9935899376869202,
                    "sentence": "The proposed method is quantitatively evaluated on datasets of human eye movements for both static and dynamic scenes, demonstrating performance comparable to state-of-the-art techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974980354309082,
                    "sentence": "The formalization of saliency and the modeling of eye movements are pivotal challenges in computational vision and cognitive science.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984445571899414,
                    "sentence": "Psychologists have long grappled with ambiguous definitions of saliency, and the authors present a novel and innovative model (to the best of my knowledge) that could advance our understanding of what makes certain regions salient and provide a formal framework for modeling eye movements within the bottom-up paradigm.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9957110285758972,
                    "sentence": "While the method may not outperform state-of-the-art approaches on every metric or dataset, it delivers strong results and offers a refreshing perspective on the problem.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.15342195332050323,
                    "sentence": "However, some of the above assessment is speculative, as the paper is poorly written and difficult to follow.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.11196917295455933,
                    "sentence": "I strongly recommend that the authors have the manuscript proofread by others and expand on the abbreviations used (both in the equations and in Section 3).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.1863209456205368,
                    "sentence": "Additionally, I suggest moving the two-page Appendix to the supplementary material and using the freed-up space to clearly define each variable and function used in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.097844198346138,
                    "sentence": "Even if these are standard conventions in the authors' field, the NIPS audience spans multiple disciplines, and some readers may struggle to follow the mathematical details without clearer explanations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.20096604526042938,
                    "sentence": "As a psychologist, I would have appreciated a stronger connection between the proposed work and the psychological literature on eye movements as optimal strategies for information gathering.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.21314722299575806,
                    "sentence": "For example, the authors could reference Najemnik, J., & Geisler, W. S. (2008).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.19097945094108582,
                    "sentence": "Eye movement statistics in humans are consistent with an optimal search strategy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.16264644265174866,
                    "sentence": "Journal of Vision, 8(3), 1-14.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.13042356073856354,
                    "sentence": "There are additional relevant studies, particularly from Geisler's lab, that the authors could explore.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.715919554233551,
                    "sentence": "I would be interested in a discussion of how their approach aligns with or diverges from these findings\"\"for instance, whether their model restates similar principles or offers independent insights that could be integrated into a more comprehensive framework.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 6,
                    "completely_generated_prob": 1.474742012248794e-05
                }
            ],
            "completely_generated_prob": 0.7936028431808086,
            "class_probabilities": {
                "human": 0.1936532144943455,
                "ai": 0.7936028431808086,
                "mixed": 0.012743942324846002
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.7936028431808086,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.7936028431808086,
                    "human": 0.1936532144943455,
                    "mixed": 0.012743942324846002
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Paraphrased Review: Variational Laws of Visual Attention for Dynamic Scenes\nThe authors explore the regions in static and dynamic images that humans are most likely to attend to. They propose a model by defining three foundational principles of visual attention, conceptualized as an energy function minimized by eye movements: (1) Eye movements are restricted by a harmonic oscillator at the image boundaries within a retina of limited size. (2) A \"curiosity-driven principle\" emphasizes areas with significant brightness variations in both fine and blurred versions of the image. (3) Brightness invariance, which increases in response to brightness changes. Using a cost function derived from these principles, the authors formulate differential equations to predict eye movements across static and dynamic images, based on initial eye position and velocity. The proposed method is quantitatively evaluated on datasets of human eye movements for both static and dynamic scenes, demonstrating performance comparable to state-of-the-art techniques.\nThe formalization of saliency and the modeling of eye movements are pivotal challenges in computational vision and cognitive science. Psychologists have long grappled with ambiguous definitions of saliency, and the authors present a novel and innovative model (to the best of my knowledge) that could advance our understanding of what makes certain regions salient and provide a formal framework for modeling eye movements within the bottom-up paradigm. While the method may not outperform state-of-the-art approaches on every metric or dataset, it delivers strong results and offers a refreshing perspective on the problem.\nHowever, some of the above assessment is speculative, as the paper is poorly written and difficult to follow. I strongly recommend that the authors have the manuscript proofread by others and expand on the abbreviations used (both in the equations and in Section 3). Additionally, I suggest moving the two-page Appendix to the supplementary material and using the freed-up space to clearly define each variable and function used in the paper. Even if these are standard conventions in the authors' field, the NIPS audience spans multiple disciplines, and some readers may struggle to follow the mathematical details without clearer explanations.\nAs a psychologist, I would have appreciated a stronger connection between the proposed work and the psychological literature on eye movements as optimal strategies for information gathering. For example, the authors could reference Najemnik, J., & Geisler, W. S. (2008). Eye movement statistics in humans are consistent with an optimal search strategy. Journal of Vision, 8(3), 1-14. There are additional relevant studies, particularly from Geisler's lab, that the authors could explore. I would be interested in a discussion of how their approach aligns with or diverges from these findings\"\"for instance, whether their model restates similar principles or offers independent insights that could be integrated into a more comprehensive framework."
        }
    ]
}