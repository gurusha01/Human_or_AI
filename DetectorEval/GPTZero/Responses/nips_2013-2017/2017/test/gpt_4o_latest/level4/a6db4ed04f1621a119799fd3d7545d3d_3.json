{
    "version": "2025-01-09-base",
    "scanId": "9b9056b5-c647-4c50-8ef1-b3273eae0951",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9981216788291931,
                    "sentence": "This paper presents novel contributions in two key areas: introducing a new dataset for nowcasting (though the reviewer could not find an explicit claim in the paper regarding its public availability) and leveraging the concept of the 'Spatial Transformer Network' within a convRNN framework to predict future frames based on recent input sequences.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9982519149780273,
                    "sentence": "The introduction is well-written, and the problem is effectively motivated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985070824623108,
                    "sentence": "The remainder of the paper is clearly organized, but the following two aspects are less satisfactory:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9980418086051941,
                    "sentence": "1. The use of \\mathcal{U}t, \\mathcal{V}t, and their associated \\gamma function warrants a more detailed explanation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991351366043091,
                    "sentence": "Based on the rest of the paper, this appears to be the sole technical distinction from the Spatial Transformer Network, which instead learns a 2Ãᅳ3 affine transformation matrix.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993381500244141,
                    "sentence": "It is unclear why this approach was replaced with continuous optical flow, and further justification is needed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989914894104004,
                    "sentence": "2. While the experiments are moderately convincing, the observed differences are often not statistically significant (this is inferred by the reviewer, as no confidence intervals are provided).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9980073571205139,
                    "sentence": "Furthermore, the reviewer finds it unusual that Conv3D baselines frequently underperform Conv2D baselines, given the nature of the problem, and this discrepancy should be clarified.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9960504174232483,
                    "sentence": "The reviewer encourages the authors to address these concerns in their revisions to strengthen the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9952976703643799,
                    "sentence": "Additional Note: The author feedback satisfactorily resolves the reviewer's questions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents novel contributions in two key areas: introducing a new dataset for nowcasting (though the reviewer could not find an explicit claim in the paper regarding its public availability) and leveraging the concept of the 'Spatial Transformer Network' within a convRNN framework to predict future frames based on recent input sequences.\nThe introduction is well-written, and the problem is effectively motivated. The remainder of the paper is clearly organized, but the following two aspects are less satisfactory: \n1. The use of \\mathcal{U}t, \\mathcal{V}t, and their associated \\gamma function warrants a more detailed explanation. Based on the rest of the paper, this appears to be the sole technical distinction from the Spatial Transformer Network, which instead learns a 2Ã—3 affine transformation matrix. It is unclear why this approach was replaced with continuous optical flow, and further justification is needed. \n2. While the experiments are moderately convincing, the observed differences are often not statistically significant (this is inferred by the reviewer, as no confidence intervals are provided). Furthermore, the reviewer finds it unusual that Conv3D baselines frequently underperform Conv2D baselines, given the nature of the problem, and this discrepancy should be clarified.\nThe reviewer encourages the authors to address these concerns in their revisions to strengthen the paper.\nAdditional Note: The author feedback satisfactorily resolves the reviewer's questions."
        }
    ]
}