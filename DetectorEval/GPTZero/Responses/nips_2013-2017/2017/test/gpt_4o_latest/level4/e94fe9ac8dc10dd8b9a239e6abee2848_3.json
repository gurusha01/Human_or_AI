{
    "version": "2025-01-09-base",
    "scanId": "e4757147-be37-4ecc-aa2b-a446d796ad84",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9995077252388,
                    "sentence": "This paper addresses the challenge of approximating matrices in the absence of a clear metric on the data, utilizing the lâ Є norm (defined as the count of non-zero elements in the difference between the original data and its approximation).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992321729660034,
                    "sentence": "The authors propose a low-rank solution to this problem.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988833069801331,
                    "sentence": "However, the paper does not provide a concrete practical scenario where this approach would be particularly useful.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9963476061820984,
                    "sentence": "Notably, the concept of \"low rank\" inherently suggests some degree of linearity, which in turn implies the existence of a metric.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9961701035499573,
                    "sentence": "This raises questions about the applicability of the method when the data cannot be meaningfully interpreted with a metric in the first place.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9946812391281128,
                    "sentence": "For instance, in the case of k=1, it is trivial to make the first row and one element in each subsequent row of A-A' equal to zero (resulting in 2n-1 zero elements).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9944455027580261,
                    "sentence": "However, predicting the remaining elements linearly in this context appears arbitrary.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9959642291069031,
                    "sentence": "Furthermore, if the elements of A are continuous variables sampled from a distribution lacking linear properties, the probability that any low-rank approximation A' will result in more than the minimal number of elements in A-A' being exactly zero (as required by the lâ Є norm) is effectively zero.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9822575449943542,
                    "sentence": "In this sense, when the data is randomly drawn from a continuous distribution, it is highly likely that OPT^(k) will approximate (n-k)(m-k).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6703891754150391,
                    "sentence": "For small values of k, theorems such as Theorem 2, which discuss multiples of OPT^(k), become somewhat trivial (e.g., O(kÂ²)OPT^(k) > 2OPT^(k) > mn) in the case of \"random\" data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9877071380615234,
                    "sentence": "This suggests that the problem may instead lie in identifying cases where external factors cause the data to already be close to low rank.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9843451380729675,
                    "sentence": "In such situations, many elements would naturally conform to the linear low-rank relationship with other elements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9824409484863281,
                    "sentence": "The authors themselves acknowledge this point, as noted in line 272, where they state that the work is most relevant when A is already approximately low rank.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986265897750854,
                    "sentence": "From a theoretical perspective, the mathematical development and randomized algorithms presented in the paper are quite compelling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991723895072937,
                    "sentence": "However, moving some of the technical details to the supplementary material and crafting a more cohesive narrative that connects the algorithms to well-defined learning problems could significantly enhance the paper's impact and clarity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9906297326087952,
                    "sentence": "Specific comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9903579354286194,
                    "sentence": "- Line 48: \"supplementary\" should be revised to \"supplementary material.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.986316442489624,
                    "sentence": "- Line 244: The repeated use of \"w.h.p.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9921718239784241,
                    "sentence": "in the same statement is unnecessary, though it may serve as a concise way to present the result.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.3063829682933457
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9961636828644501,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9961636828644501,
                "mixed": 0.003836317135549872
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9961636828644501,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9961636828644501,
                    "human": 0,
                    "mixed": 0.003836317135549872
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper addresses the challenge of approximating matrices in the absence of a clear metric on the data, utilizing the lâ € norm (defined as the count of non-zero elements in the difference between the original data and its approximation). The authors propose a low-rank solution to this problem.\nHowever, the paper does not provide a concrete practical scenario where this approach would be particularly useful. Notably, the concept of \"low rank\" inherently suggests some degree of linearity, which in turn implies the existence of a metric. This raises questions about the applicability of the method when the data cannot be meaningfully interpreted with a metric in the first place. For instance, in the case of k=1, it is trivial to make the first row and one element in each subsequent row of A-A' equal to zero (resulting in 2n-1 zero elements). However, predicting the remaining elements linearly in this context appears arbitrary. Furthermore, if the elements of A are continuous variables sampled from a distribution lacking linear properties, the probability that any low-rank approximation A' will result in more than the minimal number of elements in A-A' being exactly zero (as required by the lâ € norm) is effectively zero.\nIn this sense, when the data is randomly drawn from a continuous distribution, it is highly likely that OPT^(k) will approximate (n-k)(m-k). For small values of k, theorems such as Theorem 2, which discuss multiples of OPT^(k), become somewhat trivial (e.g., O(kÂ²)OPT^(k) > 2OPT^(k) > mn) in the case of \"random\" data.\nThis suggests that the problem may instead lie in identifying cases where external factors cause the data to already be close to low rank. In such situations, many elements would naturally conform to the linear low-rank relationship with other elements. The authors themselves acknowledge this point, as noted in line 272, where they state that the work is most relevant when A is already approximately low rank.\nFrom a theoretical perspective, the mathematical development and randomized algorithms presented in the paper are quite compelling. However, moving some of the technical details to the supplementary material and crafting a more cohesive narrative that connects the algorithms to well-defined learning problems could significantly enhance the paper's impact and clarity.\nSpecific comments:\n- Line 48: \"supplementary\" should be revised to \"supplementary material.\"\n- Line 244: The repeated use of \"w.h.p.\" in the same statement is unnecessary, though it may serve as a concise way to present the result."
        }
    ]
}