{
    "version": "2025-01-09-base",
    "scanId": "d793116c-6584-4122-a698-479ebbae27c1",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999814629554749,
                    "sentence": "This paper explores an extension of the continuous cache models recently introduced by Grave et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.999981701374054,
                    "sentence": "The authors propose an unbounded continuous cache model capable of accounting for events from an indefinite past.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999781847000122,
                    "sentence": "While the idea is intriguing, the paper lacks strong experimental evidence to substantiate its claims.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999753832817078,
                    "sentence": "The primary assertion is that this model outperforms Grave et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999751448631287,
                    "sentence": "'s approach, yet no direct comparison is provided.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999745488166809,
                    "sentence": "Instead, the paper appears to compare its model with older cache models, such as those by Kuhn et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.99996018409729,
                    "sentence": "from the 1990s.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999750256538391,
                    "sentence": "However, this comparison is unclear, as the authors dedicate only one line (line 206) to describing the models they benchmark against.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999673366546631,
                    "sentence": "The phrase \"the static model interpolated with the unigram probability distribution observed up to time t\" seems to align with Kuhn et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999640583992004,
                    "sentence": "'s work and does not correspond to Grave et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999650716781616,
                    "sentence": "'s model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999694228172302,
                    "sentence": "The authors also emphasize the significance of large vocabularies but fail to disclose the vocabulary sizes used in their experiments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999649524688721,
                    "sentence": "Additionally, it is unclear why all datasets were lowercased if the focus is on large vocabularies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9999525547027588,
                    "sentence": "These omissions, combined with the lack of clarity in the experimental section, detract from the paper's potential.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9652286171913147,
                    "sentence": "This is unfortunate, as the initial sections (1-3) were highly promising.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9703399538993835,
                    "sentence": "We recommend that the authors refine the experimental section to enhance the paper's publishability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3832668662071228,
                    "sentence": "Minor comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3654659390449524,
                    "sentence": "* line 5: stores -> store",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2723473310470581,
                    "sentence": "* line 13: twice \"be\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12051169574260712,
                    "sentence": "* line 30: speach -> speech",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1352006196975708,
                    "sentence": "* line 31: \"THE model\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11156332492828369,
                    "sentence": "* line 59: \"assumptions ABOUT\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09095706790685654,
                    "sentence": "* line 72: no comma after \"and\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06950490921735764,
                    "sentence": "* line 79: algorithm -> algorithmS",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07216645032167435,
                    "sentence": "* line 79: approach -> approachES",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10081207752227783,
                    "sentence": "* line 97: non-parameteric -> non-parametric",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03851718455553055,
                    "sentence": "* line 99: \"THE nineties\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03487261012196541,
                    "sentence": "* line 110: \"aN update rule\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04065985977649689,
                    "sentence": "* line 127: Khun -> Kuhn",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017885342240333557,
                    "sentence": "* line 197: motivationS",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014611609280109406,
                    "sentence": "* line 197: \"adapt to A changing distribution\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017562447115778923,
                    "sentence": "* line 211: \"time steps\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.016144121065735817,
                    "sentence": "* line 211: adaptative -> adaptive",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.037850186228752136,
                    "sentence": "* table 2: the caption mentions that the model is trained on news 2007, but in fact this varies throughout the table?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.016006873920559883,
                    "sentence": "* line 216: interest -> interested",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023817045614123344,
                    "sentence": "* line 235: millions -> million",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0227850079536438,
                    "sentence": "* line 267: experimentS",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.016726862639188766,
                    "sentence": "* line 269: where do these percentages come from?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012463274411857128,
                    "sentence": "they seem wrong...",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025082264095544815,
                    "sentence": "* line 281: \"THE static model\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.020898010581731796,
                    "sentence": "* line 283: Set",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 11,
                    "completely_generated_prob": 0.9367359127724141
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.4855911726804124,
            "class_probabilities": {
                "human": 0.5040431701030927,
                "ai": 0.4855911726804124,
                "mixed": 0.010365657216494847
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.5040431701030927,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.4855911726804124,
                    "human": 0.5040431701030927,
                    "mixed": 0.010365657216494847
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper explores an extension of the continuous cache models recently introduced by Grave et al. The authors propose an unbounded continuous cache model capable of accounting for events from an indefinite past. While the idea is intriguing, the paper lacks strong experimental evidence to substantiate its claims. The primary assertion is that this model outperforms Grave et al.'s approach, yet no direct comparison is provided. Instead, the paper appears to compare its model with older cache models, such as those by Kuhn et al. from the 1990s. However, this comparison is unclear, as the authors dedicate only one line (line 206) to describing the models they benchmark against. The phrase \"the static model interpolated with the unigram probability distribution observed up to time t\" seems to align with Kuhn et al.'s work and does not correspond to Grave et al.'s model.\nThe authors also emphasize the significance of large vocabularies but fail to disclose the vocabulary sizes used in their experiments. Additionally, it is unclear why all datasets were lowercased if the focus is on large vocabularies. These omissions, combined with the lack of clarity in the experimental section, detract from the paper's potential. This is unfortunate, as the initial sections (1-3) were highly promising. We recommend that the authors refine the experimental section to enhance the paper's publishability.\nMinor comments: \n* line 5: stores -> store \n* line 13: twice \"be\" \n* line 30: speach -> speech \n* line 31: \"THE model\" \n* line 59: \"assumptions ABOUT\" \n* line 72: no comma after \"and\" \n* line 79: algorithm -> algorithmS \n* line 79: approach -> approachES \n* line 97: non-parameteric -> non-parametric \n* line 99: \"THE nineties\" \n* line 110: \"aN update rule\" \n* line 127: Khun -> Kuhn \n* line 197: motivationS \n* line 197: \"adapt to A changing distribution\" \n* line 211: \"time steps\" \n* line 211: adaptative -> adaptive \n* table 2: the caption mentions that the model is trained on news 2007, but in fact this varies throughout the table? \n* line 216: interest -> interested \n* line 235: millions -> million \n* line 267: experimentS \n* line 269: where do these percentages come from? they seem wrong... \n* line 281: \"THE static model\" \n* line 283: Set"
        }
    ]
}