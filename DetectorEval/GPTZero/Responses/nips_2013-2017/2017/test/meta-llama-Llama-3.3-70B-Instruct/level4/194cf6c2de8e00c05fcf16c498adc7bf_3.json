{
    "version": "2025-01-09-base",
    "scanId": "8b0c618c-5e54-4721-9025-1ea54d66d949",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9978058934211731,
                    "sentence": "This paper presents a novel framework for investigating eye movements, accurately capturing the current state of research in this field, as far as I can discern, albeit with the caveat that my expertise lies outside the domains of perception and eye movements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9979665875434875,
                    "sentence": "Existing approaches typically rely on a saliency map defined over an image, with fixation points selected through an optimization or maximization process.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987649321556091,
                    "sentence": "In contrast, the proposed model, EYMOL, operates under a distinct premise, applying the \"Least Action Principle\" directly to gaze trajectories.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992509484291077,
                    "sentence": "While certain mathematical aspects, particularly those in the extensive appendix, exceeded my grasp due to my limited physics background, I was still able to comprehend the fundamental principles of this approach and its differentiation from preceding models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9968959093093872,
                    "sentence": "The application of the model to a real dataset of eye movements and its comparison to alternative models are noteworthy, with the results generally supporting the validity of the new approach, even if it does not outperform others on every metric.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.997985303401947,
                    "sentence": "The paper may hold significant interest for certain segments of the vision science community, such as attendees of the Vision Sciences Society (VSS).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9971640706062317,
                    "sentence": "However, its suitability for NIPS is less clear to me, and I believe this should be assessed in conjunction with the opinions of more specialized reviewers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974343776702881,
                    "sentence": "The paper likely contributes a new and intriguing theory that could stimulate further empirical research, thereby possessing both novelty and merit within the perception sciences.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a novel framework for investigating eye movements, accurately capturing the current state of research in this field, as far as I can discern, albeit with the caveat that my expertise lies outside the domains of perception and eye movements. Existing approaches typically rely on a saliency map defined over an image, with fixation points selected through an optimization or maximization process. In contrast, the proposed model, EYMOL, operates under a distinct premise, applying the \"Least Action Principle\" directly to gaze trajectories. While certain mathematical aspects, particularly those in the extensive appendix, exceeded my grasp due to my limited physics background, I was still able to comprehend the fundamental principles of this approach and its differentiation from preceding models. The application of the model to a real dataset of eye movements and its comparison to alternative models are noteworthy, with the results generally supporting the validity of the new approach, even if it does not outperform others on every metric.\nThe paper may hold significant interest for certain segments of the vision science community, such as attendees of the Vision Sciences Society (VSS). However, its suitability for NIPS is less clear to me, and I believe this should be assessed in conjunction with the opinions of more specialized reviewers. The paper likely contributes a new and intriguing theory that could stimulate further empirical research, thereby possessing both novelty and merit within the perception sciences."
        }
    ]
}