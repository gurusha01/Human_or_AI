{
    "version": "2025-01-09-base",
    "scanId": "d62ff098-a6c8-49cf-8665-23ca1d2b9d58",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999885559082031,
                    "sentence": "This paper investigates the challenge of training a sequence classifier in the absence of labeled data, leveraging sequential output statistics instead.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999889135360718,
                    "sentence": "The motivation behind this approach stems from scenarios where obtaining labels is prohibitively expensive, whereas sequential output statistics can be readily acquired.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999805688858032,
                    "sentence": "A quintessential example of this is Optical Character Recognition (OCR), where the output statistics are embodied by language models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999749660491943,
                    "sentence": "The authors propose an unsupervised learning cost function that is inherently intuitive, conceptualizing the transformation from the input sequence to the output sequence as a mapping that converts the input distribution into a distribution within the output domain.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999788403511047,
                    "sentence": "The cost is then measured as the cross-entropy between the output statistics and the transformed distribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999727606773376,
                    "sentence": "The authors delve into several desirable properties of the proposed cost function, noting that although it is non-convex, it exhibits a superior coverage-seeking property compared to existing methodologies, which enhances its optimizability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999961793422699,
                    "sentence": "Furthermore, they transform the cost into its primal-dual form and introduce a stochastic gradient method for optimization.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999561905860901,
                    "sentence": "Empirical evaluations conducted on two real-world applications demonstrate the efficacy of this approach, yielding results that closely approximate those achieved through supervised learning, while alternative methods perform poorly.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999379515647888,
                    "sentence": "The presentation of the paper is commendable for its clarity, and it provides thorough comparisons with related works, although a comprehensive assessment of the literature coverage would require more in-depth familiarity with this specific research direction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999281167984009,
                    "sentence": "In summary, the proposed approach is intuitively appealing, and the paper offers detailed discussions highlighting its advantages over existing methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999853253364563,
                    "sentence": "The experimental results provide substantial evidence supporting the effectiveness of the proposed method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998753666877747,
                    "sentence": "Minor suggestions:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998834729194641,
                    "sentence": "- Line 283: The phrase \"rate rate\" appears to be a typographical error and should be corrected to simply \"rate\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper investigates the challenge of training a sequence classifier in the absence of labeled data, leveraging sequential output statistics instead. The motivation behind this approach stems from scenarios where obtaining labels is prohibitively expensive, whereas sequential output statistics can be readily acquired. A quintessential example of this is Optical Character Recognition (OCR), where the output statistics are embodied by language models. The authors propose an unsupervised learning cost function that is inherently intuitive, conceptualizing the transformation from the input sequence to the output sequence as a mapping that converts the input distribution into a distribution within the output domain. The cost is then measured as the cross-entropy between the output statistics and the transformed distribution.\nThe authors delve into several desirable properties of the proposed cost function, noting that although it is non-convex, it exhibits a superior coverage-seeking property compared to existing methodologies, which enhances its optimizability. Furthermore, they transform the cost into its primal-dual form and introduce a stochastic gradient method for optimization. Empirical evaluations conducted on two real-world applications demonstrate the efficacy of this approach, yielding results that closely approximate those achieved through supervised learning, while alternative methods perform poorly.\nThe presentation of the paper is commendable for its clarity, and it provides thorough comparisons with related works, although a comprehensive assessment of the literature coverage would require more in-depth familiarity with this specific research direction.\nIn summary, the proposed approach is intuitively appealing, and the paper offers detailed discussions highlighting its advantages over existing methods. The experimental results provide substantial evidence supporting the effectiveness of the proposed method.\nMinor suggestions:\n- Line 283: The phrase \"rate rate\" appears to be a typographical error and should be corrected to simply \"rate\"."
        }
    ]
}