{
    "version": "2025-01-09-base",
    "scanId": "bee9b745-4462-43ad-956d-fa4b50c9278b",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0004321924352552742,
                    "sentence": "Summary.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00047128365258686244,
                    "sentence": "The paper is about contextual bandits with N arms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007960398797877133,
                    "sentence": "In each round the learner observes a context x_{ti} for each arm, chooses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001162504660896957,
                    "sentence": "an arm to pull and receives reward r_{ti}.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00035797173040919006,
                    "sentence": "The question is what structure to impose on the rewards.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.000550497614312917,
                    "sentence": "The authors note that",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0011511712800711393,
                    "sentence": "E[r{ti}] = < x{ti}, theta > is a common choice, as is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0016912127612158656,
                    "sentence": "E[r{ti}] = < x{ti}, theta_i >",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008356734178960323,
                    "sentence": "The former allows for faster learning, but has less capacity while the latter has more capacity and slower learning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006884858012199402,
                    "sentence": "The natural question",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005867331055924296,
                    "sentence": "addressed in this paper concerns the middle ground, which is simultaneously generalized by kernelization.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008468948653899133,
                    "sentence": "The main idea is to augment the context space so the learner observes (z{ti}, x{ti}) where z_{ti} lies in some other space Z.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004828358651138842,
                    "sentence": "Then a kernel can be defined on this augmented space that measures similarity between contexts and determines the degree of sharing",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007340465672314167,
                    "sentence": "between the arms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007691294886171818,
                    "sentence": "Contribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005249904352240264,
                    "sentence": "The main contribution as far as I can tell is the idea to augment the context space in this way.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005759032210335135,
                    "sentence": "The regret analysis",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004984543193131685,
                    "sentence": "employs the usual techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001443848479539156,
                    "sentence": "Novelty.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005248412489891052,
                    "sentence": "There is something new here, but not much.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010301772272214293,
                    "sentence": "Unless I am somehow mistaken the analysis of Valko et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009035180555656552,
                    "sentence": "should apply directly to the augmented",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0004584902198985219,
                    "sentence": "contexts with more-or-less the same guarantees.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008566364995203912,
                    "sentence": "So the new idea is really the augmentation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010030356934294105,
                    "sentence": "Impact.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009683203534223139,
                    "sentence": "It's hard to tell what will be the impact of this paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010111838346347213,
                    "sentence": "From a theoretical perspective there is not much new.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007652782369405031,
                    "sentence": "The practical experiments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008388936403207481,
                    "sentence": "are definitely appreciated, but not overwhelming.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0014222372556105256,
                    "sentence": "Eg., what about linear Thompson sampling?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02055680938065052,
                    "sentence": "Correctness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.015391766093671322,
                    "sentence": "I only skimmed the proofs in the supplementary material, but the bound passes plausibility tests.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025942794978618622,
                    "sentence": "Overall.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013377209194004536,
                    "sentence": "This seems like a borderline paper to me.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018914781510829926,
                    "sentence": "I would increase my score if the authors can argue convincingly that the theoretical results are really doing",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03370526805520058,
                    "sentence": "more than the analysis in the cited paper of Valko et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04677340015769005,
                    "sentence": "Other comments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07297161221504211,
                    "sentence": "- On L186 you remark that under \"further assumption that after time t, n_{a,t} = t/N\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09774774312973022,
                    "sentence": "But this assumption is completely unjustified, so how meaningful",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07509514689445496,
                    "sentence": "are conclusions drawn from it?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0966423749923706,
                    "sentence": "- It's a pity that the analysis was not possible for Algorithm 1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12303323298692703,
                    "sentence": "I presume the sup-\"blah blah\" algorithms don't really work?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07265547662973404,
                    "sentence": "It could be useful to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1263718456029892,
                    "sentence": "show their regret relative to Algorithm 1 in one of the figures.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17131124436855316,
                    "sentence": "Someone needs to address these issues at some point (but I know this is a tricky problem).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14834780991077423,
                    "sentence": "Minors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10680735111236572,
                    "sentence": "- I would capitalize A_t and other random variables.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10381744056940079,
                    "sentence": "- L49: \"one estimate\" -> \"one estimates\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07013949006795883,
                    "sentence": "- L98: \"za\" -> \"za \\in \\mathcal Z\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2028818428516388,
                    "sentence": "- L110: The notation t_a as a set that depends on t and a is just odd.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23965445160865784,
                    "sentence": "- L114: Why all the primes?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.225694939494133,
                    "sentence": "- There must be some noise assumption on the rewards (or bounded, or whatever).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1482592225074768,
                    "sentence": "Did I miss it?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21923761069774628,
                    "sentence": "- L135: augmented context here is also (a, x_a).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.0375246461941804,
            "class_probabilities": {
                "human": 0.9624347023880775,
                "ai": 0.0375246461941804,
                "mixed": 4.065141774218333e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9624347023880775,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.0375246461941804,
                    "human": 0.9624347023880775,
                    "mixed": 4.065141774218333e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary.\nThe paper is about contextual bandits with N arms. In each round the learner observes a context x_{ti} for each arm, chooses\nan arm to pull and receives reward r_{ti}.\nThe question is what structure to impose on the rewards. The authors note that\nE[r{ti}] = < x{ti}, theta > is a common choice, as is \nE[r{ti}] = < x{ti}, theta_i >\nThe former allows for faster learning, but has less capacity while the latter has more capacity and slower learning. The natural question\naddressed in this paper concerns the middle ground, which is simultaneously generalized by kernelization.\nThe main idea is to augment the context space so the learner observes (z{ti}, x{ti}) where z_{ti} lies in some other space Z.\nThen a kernel can be defined on this augmented space that measures similarity between contexts and determines the degree of sharing\nbetween the arms.\nContribution.\nThe main contribution as far as I can tell is the idea to augment the context space in this way. The regret analysis\nemploys the usual techniques.\nNovelty. \nThere is something new here, but not much. Unless I am somehow mistaken the analysis of Valko et al. should apply directly to the augmented\ncontexts with more-or-less the same guarantees. So the new idea is really the augmentation. \nImpact.\nIt's hard to tell what will be the impact of this paper. From a theoretical perspective there is not much new. The practical experiments\nare definitely appreciated, but not overwhelming. Eg., what about linear Thompson sampling? \nCorrectness. \nI only skimmed the proofs in the supplementary material, but the bound passes plausibility tests.\nOverall.\nThis seems like a borderline paper to me. I would increase my score if the authors can argue convincingly that the theoretical results are really doing\nmore than the analysis in the cited paper of Valko et al.\nOther comments.\n- On L186 you remark that under \"further assumption that after time t, n_{a,t} = t/N\". But this assumption is completely unjustified, so how meaningful\n are conclusions drawn from it?\n- It's a pity that the analysis was not possible for Algorithm 1. I presume the sup-\"blah blah\" algorithms don't really work? It could be useful to \n show their regret relative to Algorithm 1 in one of the figures. Someone needs to address these issues at some point (but I know this is a tricky problem).\nMinors.\n- I would capitalize A_t and other random variables.\n- L49: \"one estimate\" -> \"one estimates\".\n- L98: \"za\" -> \"za \\in \\mathcal Z\".\n- L110: The notation t_a as a set that depends on t and a is just odd.\n- L114: Why all the primes?\n- There must be some noise assumption on the rewards (or bounded, or whatever). Did I miss it?\n- L135: augmented context here is also (a, x_a)."
        }
    ]
}