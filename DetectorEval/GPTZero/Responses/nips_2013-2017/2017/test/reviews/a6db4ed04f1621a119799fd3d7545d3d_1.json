{
    "version": "2025-01-09-base",
    "scanId": "fb63db08-21b2-4751-8b47-748f2886f1a7",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.7199440002441406,
                    "sentence": "This paper introduces TrajGRU, an extension of the convolutional LSTM/GRU.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7725376486778259,
                    "sentence": "Contrary to convLSTM/GRU, TrajGRU aims at learning location dependant filter support for each hidden state location.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7167680263519287,
                    "sentence": "TrajGRU generates a flow field from the current input and previous hidden state and then warp the previous hidden states through bilinear sampling following this flow field.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7383292317390442,
                    "sentence": "Author evaluate their proposal on a video generation on two datasets, MovingMNIST having 3 digits at the same time and HKO-7 nowcasting dataset, where TrajRU outperforms their convolutional counterpart.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7283379435539246,
                    "sentence": "Few specific question/remarks:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7443426251411438,
                    "sentence": "Did you compare TrajGRU with ConvGRU having a larger support than just a 5x5 kernels?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7505518198013306,
                    "sentence": "Does the TrajGRU requires more computation than a convGRU due to its warping operation?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6657364368438721,
                    "sentence": "It would be informative to provide the overall parameter, number of operation and running time for the models evaluated in the experiment section.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7214998602867126,
                    "sentence": "Why did you trained the model for a fix number of epoch rather than doing early stopping, could the performances of some model be improved by stopping the training earlier?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5343549251556396,
                    "sentence": "- Quality",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6765680313110352,
                    "sentence": "The paper seems technically sound.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.66276615858078,
                    "sentence": "- Clarity",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7098924517631531,
                    "sentence": "The paper is clear overall.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7432810068130493,
                    "sentence": "It would be nice to specify the warp method to have more complete view of the TrajGRU.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7304632663726807,
                    "sentence": "Also it is not clear what are the number of examples and training/validation/test splits for the HKO-7 datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.642797589302063,
                    "sentence": "-Originality",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6078424453735352,
                    "sentence": "Few other works have explored the use of warping for video model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.619269847869873,
                    "sentence": "See \"Spatio-temporal video autoencoder with differentiable memory\" for instance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6373949646949768,
                    "sentence": "It would to compare/contrast TrajGRU to this approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5437422394752502,
                    "sentence": "-Significance/Conclusion",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6243346929550171,
                    "sentence": "Designing model that learn good video representation is still an ongoing research problem.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5607667565345764,
                    "sentence": "This paper propose a novel model that propose to learn the filter support in addition to filter weight which is an interesting step toward better video model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.44851842522621155,
                    "sentence": "However, the approach is only tested so far on one synthetic dataset (MovingMnist) and one specialized nowcasting dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7062549591064453,
                    "sentence": "It would be good to see if this model lead to better video representation for more traditional video task such as human action classification with generic videos.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                }
            ],
            "completely_generated_prob": 0.23146322332043734,
            "class_probabilities": {
                "human": 0.7684609244807739,
                "ai": 0.23146322332043734,
                "mixed": 7.58521987887963e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.7684609244807739,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.23146322332043734,
                    "human": 0.7684609244807739,
                    "mixed": 7.58521987887963e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper introduces TrajGRU, an extension of the convolutional LSTM/GRU. Contrary to convLSTM/GRU, TrajGRU aims at learning location dependant filter support for each hidden state location. TrajGRU generates a flow field from the current input and previous hidden state and then warp the previous hidden states through bilinear sampling following this flow field.\nAuthor evaluate their proposal on a video generation on two datasets, MovingMNIST having 3 digits at the same time and HKO-7 nowcasting dataset, where TrajRU outperforms their convolutional counterpart.\nFew specific question/remarks:\nDid you compare TrajGRU with ConvGRU having a larger support than just a 5x5 kernels? \nDoes the TrajGRU requires more computation than a convGRU due to its warping operation? It would be informative to provide the overall parameter, number of operation and running time for the models evaluated in the experiment section. \nWhy did you trained the model for a fix number of epoch rather than doing early stopping, could the performances of some model be improved by stopping the training earlier?\n- Quality\nThe paper seems technically sound.\n- Clarity\nThe paper is clear overall. It would be nice to specify the warp method to have more complete view of the TrajGRU. Also it is not clear what are the number of examples and training/validation/test splits for the HKO-7 datasets.\n-Originality\nFew other works have explored the use of warping for video model. See \"Spatio-temporal video autoencoder with differentiable memory\" for instance. It would to compare/contrast TrajGRU to this approach. \n-Significance/Conclusion\nDesigning model that learn good video representation is still an ongoing research problem.\nThis paper propose a novel model that propose to learn the filter support in addition to filter weight which is an interesting step toward better video model. \nHowever, the approach is only tested so far on one synthetic dataset (MovingMnist) and one specialized nowcasting dataset. It would be good to see if this model lead to better video representation for more traditional video task such as human action classification with generic videos."
        }
    ]
}