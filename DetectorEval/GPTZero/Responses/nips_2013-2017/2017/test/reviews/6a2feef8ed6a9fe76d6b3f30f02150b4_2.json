{
    "version": "2025-01-09-base",
    "scanId": "cc817db6-94ef-43b0-9442-abba0d622332",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.6901968121528625,
                    "sentence": "The paper pulls together a few important recent ideas on optimizing deep neural networks (as an alternative to popular SGD variants).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7617454528808594,
                    "sentence": "The derivation of the Tikhonov regularized problem in Eq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5479227304458618,
                    "sentence": "(4) and (5) from the recursive objective in Eq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6435877084732056,
                    "sentence": "(2) through relaxing the ReLU outputs as a convex projection is very clean and convincing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5705857872962952,
                    "sentence": "The decomposition into an inverse problem (activations), a least-squares problem (weights) and a final classification problem (soft-max weights) is illuminating.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.3006254732608795,
                    "sentence": "This formulation provides a novel perspectives on deep learning and offers many interesting avenues, e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5155988931655884,
                    "sentence": "generalization of ReLUs, more general connectivity patterns through shortcuts (as suggested in the used architecture), sparsity in network connectivity, etc.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.35083314776420593,
                    "sentence": "When it comes to optimization, the paper points out that it is difficult to guarantee convergence of a naive alternating optimization scheme (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.41688451170921326,
                    "sentence": "ADMM) and thus resort to an easier to analyze block-coordinate descent algorithm, presented in Algorithm 1 and analyzed in Section 4.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5381181240081787,
                    "sentence": "On the plus side: the authors are able to derive a convergent algorithm.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.3779474198818207,
                    "sentence": "On the minus side: it seems that there is a lot more to explore here and that the paper is merely a first (somewhat preliminary) step towards exploiting the derived problem formulation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.38717448711395264,
                    "sentence": "A proof of concept on MNIST data is given in Section 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.4463907480239868,
                    "sentence": "One has to say, that the experimental section is relatively weak: one data set, matlab vs. phython code, very limited analysis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.4039001166820526,
                    "sentence": "This requires a more extensive quantitative (run-time, solution quality) and qualitativ investigation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5201202034950256,
                    "sentence": "Figure 4 - a percentage pie chart is really confusing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.4848913848400116,
                    "sentence": "For the final version, a more extensive evaluation would greatly improve the quality of the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 7,
                    "completely_generated_prob": 2.1228438805416278e-06
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.00010005932717626924
                }
            ],
            "completely_generated_prob": 0.7019888226294921,
            "class_probabilities": {
                "human": 0.298011177370508,
                "ai": 0.7019888226294921,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.7019888226294921,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.7019888226294921,
                    "human": 0.298011177370508,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9964626556597271,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.0035373443402728546,
                        "ai_paraphrased": 0.9964626556597271
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.0035373442402728546,
                            "ai_paraphrased": 0.9964626556597271
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper pulls together a few important recent ideas on optimizing deep neural networks (as an alternative to popular SGD variants). The derivation of the Tikhonov regularized problem in Eq. (4) and (5) from the recursive objective in Eq. (2) through relaxing the ReLU outputs as a convex projection is very clean and convincing. The decomposition into an inverse problem (activations), a least-squares problem (weights) and a final classification problem (soft-max weights) is illuminating. This formulation provides a novel perspectives on deep learning and offers many interesting avenues, e.g. generalization of ReLUs, more general connectivity patterns through shortcuts (as suggested in the used architecture), sparsity in network connectivity, etc.\nWhen it comes to optimization, the paper points out that it is difficult to guarantee convergence of a naive alternating optimization scheme (e.g. ADMM) and thus resort to an easier to analyze block-coordinate descent algorithm, presented in Algorithm 1 and analyzed in Section 4. On the plus side: the authors are able to derive a convergent algorithm. On the minus side: it seems that there is a lot more to explore here and that the paper is merely a first (somewhat preliminary) step towards exploiting the derived problem formulation. \nA proof of concept on MNIST data is given in Section 3. One has to say, that the experimental section is relatively weak: one data set, matlab vs. phython code, very limited analysis. This requires a more extensive quantitative (run-time, solution quality) and qualitativ investigation. Figure 4 - a percentage pie chart is really confusing. For the final version, a more extensive evaluation would greatly improve the quality of the paper."
        }
    ]
}