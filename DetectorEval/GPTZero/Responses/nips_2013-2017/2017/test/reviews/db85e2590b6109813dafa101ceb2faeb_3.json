{
    "version": "2025-01-09-base",
    "scanId": "48deb914-28d1-4528-ac59-f8519491fbc1",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.007516378071159124,
                    "sentence": "The paper is interesting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00815149862319231,
                    "sentence": "The propose training neural networks with a cost that explicitly favors networks that are easier to compress by truncated SVD.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005071323364973068,
                    "sentence": "They formulate this regularization as a cost on the nuclear norm of the weight matrices, which they enforce with the soft threshold of the singular values as the proximal operator after every epoch.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006109882611781359,
                    "sentence": "I found the idea interesting, and the experimental sections I thought gave a nice breakdown of the results of their own experiments and the behavior of their proposed method, but I would have liked to see some more comparative results, i.e.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0071930778212845325,
                    "sentence": "the performance of their own network versus other compression techniques targeting the same number of parameters on the datasets, for instance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009103599935770035,
                    "sentence": "Overall good paper, interesting idea, good execution, but experiments somewhat lacking.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 6,
                    "completely_generated_prob": 1.474742012248794e-05
                }
            ],
            "completely_generated_prob": 0.020796750353547094,
            "class_probabilities": {
                "human": 0.9792032496464529,
                "ai": 0.020796750353547094,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9792032496464529,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.020796750353547094,
                    "human": 0.9792032496464529,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper is interesting. The propose training neural networks with a cost that explicitly favors networks that are easier to compress by truncated SVD. They formulate this regularization as a cost on the nuclear norm of the weight matrices, which they enforce with the soft threshold of the singular values as the proximal operator after every epoch. I found the idea interesting, and the experimental sections I thought gave a nice breakdown of the results of their own experiments and the behavior of their proposed method, but I would have liked to see some more comparative results, i.e. the performance of their own network versus other compression techniques targeting the same number of parameters on the datasets, for instance. Overall good paper, interesting idea, good execution, but experiments somewhat lacking."
        }
    ]
}