{
    "version": "2025-01-09-base",
    "scanId": "ba72114b-2f7c-4eea-b260-bfbe24e7372c",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0019673898350447416,
                    "sentence": "The paper proposes a new approach to the study of eye movements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008404180407524109,
                    "sentence": "The authors correctly summarize the current state of the art (as far as I understand it, but I admit from the outset I am not an expert in perception or eye movements).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010013447608798742,
                    "sentence": "Basically these approaches are based on a saliency map that is defined over an image and fixations points are selected in a optimization/maximization approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008190142689272761,
                    "sentence": "This model (EYMOL) works according to a different assumption and instead is defined directly on trajectories of gaze according to a \"Least Action Principle.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007055044989101589,
                    "sentence": "The details of some of the math were beyond my ability to evaluate because I don't have the necessary physics background (particularly the extensive appendix).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007748333737254143,
                    "sentence": "However, even still I was able to understand the key elements of the approach and how it differs from past models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0013003407511860132,
                    "sentence": "The model is helpfully applied to real data set of eye-movements and is compared against a variety of alternative models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008760120836086571,
                    "sentence": "While it doesn't dominate on every measure, the results are favorable for the new approach and demonstrate that it has some validity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009200613712891936,
                    "sentence": "I think the paper might be of interest to some people in the vision science community (e.g., attendees of VSS).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010950511787086725,
                    "sentence": "I'm not quite as convinced this makes a great contribution to NIPS, however I think that should be evaluated against other reviewer's opinions who are more expert.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0017174221575260162,
                    "sentence": "I think it likely advances a new and interesting theory that could inspire further empirical research, and so has both novelty and merit for perception sciences.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 8,
                    "completely_generated_prob": 3.002405151306975e-07
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                }
            ],
            "completely_generated_prob": 0.01728879156693996,
            "class_probabilities": {
                "human": 0.98271120843306,
                "ai": 0.01728879156693996,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.98271120843306,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.01728879156693996,
                    "human": 0.98271120843306,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper proposes a new approach to the study of eye movements. The authors correctly summarize the current state of the art (as far as I understand it, but I admit from the outset I am not an expert in perception or eye movements). Basically these approaches are based on a saliency map that is defined over an image and fixations points are selected in a optimization/maximization approach. This model (EYMOL) works according to a different assumption and instead is defined directly on trajectories of gaze according to a \"Least Action Principle.\" The details of some of the math were beyond my ability to evaluate because I don't have the necessary physics background (particularly the extensive appendix). However, even still I was able to understand the key elements of the approach and how it differs from past models. The model is helpfully applied to real data set of eye-movements and is compared against a variety of alternative models. While it doesn't dominate on every measure, the results are favorable for the new approach and demonstrate that it has some validity.\nI think the paper might be of interest to some people in the vision science community (e.g., attendees of VSS). I'm not quite as convinced this makes a great contribution to NIPS, however I think that should be evaluated against other reviewer's opinions who are more expert. I think it likely advances a new and interesting theory that could inspire further empirical research, and so has both novelty and merit for perception sciences."
        }
    ]
}