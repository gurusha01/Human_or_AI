{
    "version": "2025-01-09-base",
    "scanId": "49fb3315-294b-42a5-a623-06e042047491",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9057010412216187,
                    "sentence": "The paper introduces two algorithms aimed at addressing errors in the shape of segments in electron microscopy images for neural circuit reconstruction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8732160925865173,
                    "sentence": "One algorithm identifies errors, while the other corrects them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.819261908531189,
                    "sentence": "These algorithms are combined heuristically to iteratively refine an initial segmentation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9498707056045532,
                    "sentence": "* Contribution",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8545706868171692,
                    "sentence": "The first deep network (referred to as the detector) determines whether the segment overlapping the central pixel of a given ROI requires correction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.806007981300354,
                    "sentence": "The second deep network (referred to as the corrector) predicts the correct shape of the segment overlapping the central pixel.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8743153214454651,
                    "sentence": "From my understanding, using only the output of the corrector at each pixel and a segmentation metric like VI, one could frame a consensus problem for the entire volume.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8665156364440918,
                    "sentence": "However, this potential problem is neither explored nor acknowledged in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8040000796318054,
                    "sentence": "Instead, the authors employ a greedy algorithm (informally described in Section 5) that incrementally updates the segmentation, apparently relying on a superpixel segmentation (also briefly mentioned in Section 5).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6090179085731506,
                    "sentence": "While the empirical results may hold value for the connectomics community (a judgment I am not in a position to make), I am skeptical about the broader applicability of this greedy algorithm beyond connectomics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.49016985297203064,
                    "sentence": "In conclusion, I believe this paper lacks sufficient relevance for the broader NIPS audience.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7514134049415588,
                    "sentence": "* Presentation",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5149939060211182,
                    "sentence": "The paper is generally well-structured and clearly written.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5925250053405762,
                    "sentence": "However, the technical sections (3, 4, and especially 5) are overly informal, making it difficult to fully grasp the precise workings of the proposed algorithms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.761716365814209,
                    "sentence": "The introduction and related work sections should downplay the comparison between a problem that is hard to solve and one whose solution is easy to verify.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8502180576324463,
                    "sentence": "This concept is already well-known to computer scientists through the definition of the complexity class NP.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9341446757316589,
                    "sentence": "Specifically, I disagree with the claim that \"the error detection task is better posed than the supervoxel agglomeration task.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8848579525947571,
                    "sentence": "* Related work",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9368511438369751,
                    "sentence": "The suggested connections between the proposed method and GANs [8,9] as well as visual attention [10] are tenuous, speculative, and lack technical substantiation within this work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9546244740486145,
                    "sentence": "If the authors wish to allude to such connections, they should do so briefly in an outlook section at the end of the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.45887534985363754
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.8119739381064363,
            "class_probabilities": {
                "human": 0.18679001347792185,
                "ai": 0.8119739381064363,
                "mixed": 0.0012360484156418805
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8119739381064363,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8119739381064363,
                    "human": 0.18679001347792185,
                    "mixed": 0.0012360484156418805
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper introduces two algorithms aimed at addressing errors in the shape of segments in electron microscopy images for neural circuit reconstruction. One algorithm identifies errors, while the other corrects them. These algorithms are combined heuristically to iteratively refine an initial segmentation.\n* Contribution\nThe first deep network (referred to as the detector) determines whether the segment overlapping the central pixel of a given ROI requires correction. The second deep network (referred to as the corrector) predicts the correct shape of the segment overlapping the central pixel.\nFrom my understanding, using only the output of the corrector at each pixel and a segmentation metric like VI, one could frame a consensus problem for the entire volume. However, this potential problem is neither explored nor acknowledged in the paper. Instead, the authors employ a greedy algorithm (informally described in Section 5) that incrementally updates the segmentation, apparently relying on a superpixel segmentation (also briefly mentioned in Section 5).\nWhile the empirical results may hold value for the connectomics community (a judgment I am not in a position to make), I am skeptical about the broader applicability of this greedy algorithm beyond connectomics.\nIn conclusion, I believe this paper lacks sufficient relevance for the broader NIPS audience.\n* Presentation\nThe paper is generally well-structured and clearly written. However, the technical sections (3, 4, and especially 5) are overly informal, making it difficult to fully grasp the precise workings of the proposed algorithms.\nThe introduction and related work sections should downplay the comparison between a problem that is hard to solve and one whose solution is easy to verify. This concept is already well-known to computer scientists through the definition of the complexity class NP. Specifically, I disagree with the claim that \"the error detection task is better posed than the supervoxel agglomeration task.\"\n* Related work\nThe suggested connections between the proposed method and GANs [8,9] as well as visual attention [10] are tenuous, speculative, and lack technical substantiation within this work. If the authors wish to allude to such connections, they should do so briefly in an outlook section at the end of the paper."
        }
    ]
}