{
    "version": "2025-01-09-base",
    "scanId": "7c1af77f-6e67-48de-819d-6ba6ebd21568",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9967503547668457,
                    "sentence": "The paper primarily focuses on convolutional kernel networks (CKNs) [13, 14].",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.995225191116333,
                    "sentence": "In this work, the authors investigate the stability of the representations produced by CKNs with respect to \\(C^1\\) diffeomorphisms (e.g., translations), as defined in Eq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9976143836975098,
                    "sentence": "(4).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9930635690689087,
                    "sentence": "They demonstrate that stability is preserved for norm-preserving and non-expansive kernels [(A1-A2), line 193], provided that the patch sizes are chosen appropriately [(A3)].",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.986131489276886,
                    "sentence": "Additionally, the extension from \\((\\mathbb{R}^d, +)\\) to locally compact groups is outlined in Section 4.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9919251203536987,
                    "sentence": "The manuscript is well-structured, clearly articulated, and technically robust, blending concepts from two impactful fields\"\"deep networks and kernel methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9924803376197815,
                    "sentence": "The stability results presented are likely to be of interest to the machine learning community.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9938474893569946,
                    "sentence": "- The paper would benefit from a more detailed discussion on the motivation for the stability analysis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.996207058429718,
                    "sentence": "Currently, the only motivation provided is a brief statement (line 56-57: \"Finally, we note that the Lipschitz stability of deep predictive models was found to be important to get robustness to adversarial examples [7].",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9941579103469849,
                    "sentence": "\"), which does not sufficiently emphasize the significance of the paper's main contribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.992107093334198,
                    "sentence": "- The overloading of the \\(\\kappa\\) notation in (A3) [line 193] may cause confusion, as it is also used to denote the function defining the kernel \\(K\\) in Eq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9947668313980103,
                    "sentence": "(10).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9903009533882141,
                    "sentence": "- In the displayed equation between lines 384 and 385, the second part (\"and \\(\\forall v...\\)\") is redundant due to the symmetry of the kernel \\(k\\), as it is equivalent to the first constraint (\"\\(\\forall u...\\)\").",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9870921969413757,
                    "sentence": "- Line 416: The definition of \\(\\phi\\) is missing and should be introduced in Eq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9835716485977173,
                    "sentence": "(10) as \\(\\langle \\phi(z), \\phi(z') \\rangle_{H(K)}\\).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9880126714706421,
                    "sentence": "- Lines 427-428: The inequality under \"=\" appears to also hold with equality.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.993213415145874,
                    "sentence": "The term \\(\" \"\"z\"\" - \"\"z\"\" \"^2\\) should instead be \\(\" \"\"z\"\" - \"\"z'\"\" \"^2\\).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9899958968162537,
                    "sentence": "References:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9980650544166565,
                    "sentence": "- [3, 6, 8, 13, 14, 18, 25-27, 30, 31]: Missing page numbers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9961246848106384,
                    "sentence": "- [9]: Correct citation -> Amit Daniely, Roy Frostig, Yoram Singer.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.31157445907592773,
                    "sentence": "\"Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.4871913492679596,
                    "sentence": "Advances in Neural Information Processing Systems (NIPS), pages 2253-2261, 2016.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.2605155110359192,
                    "sentence": "- [17]: Correct citation -> Krikamol Muandet, Kenji Fukumizu, Bharath Sriperumbudur, Bernhard SchÃ¶lkopf.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.37488216161727905,
                    "sentence": "\"Kernel Mean Embedding of Distributions: A Review and Beyond.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.41154834628105164,
                    "sentence": "Foundations and Trends in Machine Learning, 10(1-2): 1-141.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.365898072719574,
                    "sentence": "- [19]: Correct citation -> Anant Raj, Abhishek Kumar, Youssef Mroueh, Tom Fletcher, Bernhard SchÃ¶lkopf.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.4194892644882202,
                    "sentence": "\"International Conference on Artificial Intelligence and Statistics (AISTATS),\" PMLR 54:1225-1235, 2017.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.31403061747550964,
                    "sentence": "- [32]: Accepted (https://2017.icml.cc/Conferences/2017/Schedule?type=Poster) -> Yuchen Zhang, Percy Liang, Martin Wainwright.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.42100101709365845,
                    "sentence": "\"Convexified Convolutional Neural Networks.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.4419141113758087,
                    "sentence": "International Conference on Machine Learning (ICML), 2017, accepted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.07332528267997859
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                }
            ],
            "completely_generated_prob": 0.6910625819072902,
            "class_probabilities": {
                "human": 0.30361881425749376,
                "ai": 0.6910625819072902,
                "mixed": 0.005318603835216009
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.6910625819072902,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.6910625819072902,
                    "human": 0.30361881425749376,
                    "mixed": 0.005318603835216009
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper primarily focuses on convolutional kernel networks (CKNs) [13, 14]. In this work, the authors investigate the stability of the representations produced by CKNs with respect to \\(C^1\\) diffeomorphisms (e.g., translations), as defined in Eq. (4). They demonstrate that stability is preserved for norm-preserving and non-expansive kernels [(A1-A2), line 193], provided that the patch sizes are chosen appropriately [(A3)]. Additionally, the extension from \\((\\mathbb{R}^d, +)\\) to locally compact groups is outlined in Section 4.\nThe manuscript is well-structured, clearly articulated, and technically robust, blending concepts from two impactful fields\"\"deep networks and kernel methods. The stability results presented are likely to be of interest to the machine learning community.\n- The paper would benefit from a more detailed discussion on the motivation for the stability analysis. Currently, the only motivation provided is a brief statement (line 56-57: \"Finally, we note that the Lipschitz stability of deep predictive models was found to be important to get robustness to adversarial examples [7].\"), which does not sufficiently emphasize the significance of the paper's main contribution.\n- The overloading of the \\(\\kappa\\) notation in (A3) [line 193] may cause confusion, as it is also used to denote the function defining the kernel \\(K\\) in Eq. (10).\n- In the displayed equation between lines 384 and 385, the second part (\"and \\(\\forall v...\\)\") is redundant due to the symmetry of the kernel \\(k\\), as it is equivalent to the first constraint (\"\\(\\forall u...\\)\").\n- Line 416: The definition of \\(\\phi\\) is missing and should be introduced in Eq. (10) as \\(\\langle \\phi(z), \\phi(z') \\rangle_{H(K)}\\).\n- Lines 427-428: The inequality under \"=\" appears to also hold with equality. The term \\(\" \"\"z\"\" - \"\"z\"\" \"^2\\) should instead be \\(\" \"\"z\"\" - \"\"z'\"\" \"^2\\).\nReferences:\n- [3, 6, 8, 13, 14, 18, 25-27, 30, 31]: Missing page numbers.\n- [9]: Correct citation -> Amit Daniely, Roy Frostig, Yoram Singer. \"Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity.\" Advances in Neural Information Processing Systems (NIPS), pages 2253-2261, 2016.\n- [17]: Correct citation -> Krikamol Muandet, Kenji Fukumizu, Bharath Sriperumbudur, Bernhard SchÃ¶lkopf. \"Kernel Mean Embedding of Distributions: A Review and Beyond.\" Foundations and Trends in Machine Learning, 10(1-2): 1-141.\n- [19]: Correct citation -> Anant Raj, Abhishek Kumar, Youssef Mroueh, Tom Fletcher, Bernhard SchÃ¶lkopf. \"International Conference on Artificial Intelligence and Statistics (AISTATS),\" PMLR 54:1225-1235, 2017.\n- [32]: Accepted (https://2017.icml.cc/Conferences/2017/Schedule?type=Poster) -> Yuchen Zhang, Percy Liang, Martin Wainwright. \"Convexified Convolutional Neural Networks.\" International Conference on Machine Learning (ICML), 2017, accepted."
        }
    ]
}