{
    "version": "2025-01-09-base",
    "scanId": "8503747d-550a-461c-81c7-800ee3ff19c6",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.011519505642354488,
                    "sentence": "The paper proposes a new conditional independence test.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011457589454948902,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013795589096844196,
                    "sentence": "1) The paper identifies that in ordered for a test to work an assumption on the smoothness of conditional density should be made.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009878458455204964,
                    "sentence": "Authors propose such an assumption and bound distance in total variation between density under the null hypothesis and density obtained from bootstrap under this assumption.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012980046682059765,
                    "sentence": "This is novel.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011255880817770958,
                    "sentence": "2) Paper uses this assumption to bound error of the optimal classifier on the training set (1.1 (iii))",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010815020650625229,
                    "sentence": "3) Theorem 1, which combines the assumption on smoothness, the assumption that hat R can be achieved with error eta and the assumption on difference in errors between optimal and trained classifier, is novel, insightful and non-trivial.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013176420703530312,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01095618586987257,
                    "sentence": "Paper is hard to read and does not give much interpretation of the results, to an extent that I am not sure if I understand them correctly.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018945597112178802,
                    "sentence": "E.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0188899002969265,
                    "sentence": "consider inequality in the section 1.1 iii) assume the alternative hypothesis holds and r0=0.1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017931196838617325,
                    "sentence": "Suppose G is a small class, say linear functions, and suppose they are not expressive enough to distinguish between f and f^CI at all.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01605292782187462,
                    "sentence": "Can you explain, intuitively, how the small probability of the error can be achieved ( hat R < 0.1 + o1 < 0.2 for large n)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.00010005932717626924
                }
            ],
            "completely_generated_prob": 0.039837804045504216,
            "class_probabilities": {
                "human": 0.9601216422360306,
                "ai": 0.039837804045504216,
                "mixed": 4.055371846526579e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9601216422360306,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.039837804045504216,
                    "human": 0.9601216422360306,
                    "mixed": 4.055371846526579e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper proposes a new conditional independence test.\nStrengths\n1) The paper identifies that in ordered for a test to work an assumption on the smoothness of conditional density should be made. Authors propose such an assumption and bound distance in total variation between density under the null hypothesis and density obtained from bootstrap under this assumption. This is novel.\n2) Paper uses this assumption to bound error of the optimal classifier on the training set (1.1 (iii))\n3) Theorem 1, which combines the assumption on smoothness, the assumption that hat R can be achieved with error eta and the assumption on difference in errors between optimal and trained classifier, is novel, insightful and non-trivial. \nWeaknesses\nPaper is hard to read and does not give much interpretation of the results, to an extent that I am not sure if I understand them correctly. E.g. consider inequality in the section 1.1 iii) assume the alternative hypothesis holds and r0=0.1. Suppose G is a small class, say linear functions, and suppose they are not expressive enough to distinguish between f and f^CI at all. Can you explain, intuitively, how the small probability of the error can be achieved ( hat R < 0.1 + o1 < 0.2 for large n)?"
        }
    ]
}