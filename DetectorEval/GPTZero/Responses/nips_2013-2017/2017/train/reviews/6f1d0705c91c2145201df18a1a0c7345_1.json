{
    "version": "2025-01-09-base",
    "scanId": "51745ff9-8049-453a-8369-3bf87a11700d",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.7592152953147888,
                    "sentence": "The paper presents an implicit variational inference method for likelihood-free inference.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6595563292503357,
                    "sentence": "This approach builds on previous work and particularly on Hierarchical Variational Inference and Implicit Variational Bayes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6879421472549438,
                    "sentence": "The key trick used in the paper is the subtraction of the log empirical distribution log q(xn) and the transformation of the ELBO in the form given by eq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7579580545425415,
                    "sentence": "4, which suggests the use of log density ratio estimation as a tool for likelihood-free variational inference.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7613210082054138,
                    "sentence": "The rest methodological details of the papers are based on standard tools, such as log density",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7509991526603699,
                    "sentence": "ratio estimation, reparametrization and hierarchical variational distributions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6655716300010681,
                    "sentence": "While I found the trick to deal with likelihood intractability very interesting, it requires log density ratio estimation in high-dimensional spaces (in the joint space of data xn and latent variable zn).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6891176700592041,
                    "sentence": "This is very challenging since log density ratio estimation in high dimensions is an extremely difficult problem and there is no clear evidence that the authors provide a stable algorithm to deal that.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7657784223556519,
                    "sentence": "For instance, the fact that the authors have not applied their method to a standard GAN (for generating high dimensional data such as images) but instead they have constructed this rather weird Bayesian GAN for classification (see page 7) indicates that the current algorithm is very unstable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7025899291038513,
                    "sentence": "In fact it is hard to see how to stabilize the proposed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.710324764251709,
                    "sentence": "algorithm since initially the \"variational joint\" will be very different from the \"real joint\" and it is precisely this situation that makes log density ratio estimation completely unreliable, leading to very biased gradients in the early crucial iterations of the optimization.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.7012240715000121,
            "class_probabilities": {
                "human": 0.2976865220809293,
                "ai": 0.7012240715000121,
                "mixed": 0.0010894064190585953
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.7012240715000121,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.7012240715000121,
                    "human": 0.2976865220809293,
                    "mixed": 0.0010894064190585953
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper presents an implicit variational inference method for likelihood-free inference. This approach builds on previous work and particularly on Hierarchical Variational Inference and Implicit Variational Bayes. \nThe key trick used in the paper is the subtraction of the log empirical distribution log q(xn) and the transformation of the ELBO in the form given by eq. 4, which suggests the use of log density ratio estimation as a tool for likelihood-free variational inference. The rest methodological details of the papers are based on standard tools, such as log density \nratio estimation, reparametrization and hierarchical variational distributions. \nWhile I found the trick to deal with likelihood intractability very interesting, it requires log density ratio estimation in high-dimensional spaces (in the joint space of data xn and latent variable zn). This is very challenging since log density ratio estimation in high dimensions is an extremely difficult problem and there is no clear evidence that the authors provide a stable algorithm to deal that. For instance, the fact that the authors have not applied their method to a standard GAN (for generating high dimensional data such as images) but instead they have constructed this rather weird Bayesian GAN for classification (see page 7) indicates that the current algorithm is very unstable. In fact it is hard to see how to stabilize the proposed \nalgorithm since initially the \"variational joint\" will be very different from the \"real joint\" and it is precisely this situation that makes log density ratio estimation completely unreliable, leading to very biased gradients in the early crucial iterations of the optimization."
        }
    ]
}