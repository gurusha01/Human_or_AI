{
    "version": "2025-01-09-base",
    "scanId": "2d3e1762-e496-4406-9e9d-c14f9f714561",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.8839224576950073,
                    "sentence": "The main contribution of the paper is a new framework for parallel machine learning algorithms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9406586289405823,
                    "sentence": "The idea is to combine base learners more effectively than simply averaging.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9337249398231506,
                    "sentence": "Specifically, subsets of hypotheses are replaced by their radon point.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9213586449623108,
                    "sentence": "They prove complexity bounds for their method and also empirically compare their results with parallel algorithms in Spark and using base linear models in Weka.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9269761443138123,
                    "sentence": "The paper is quite interesting since it proposes essentially a black-box method to combine weak learners together.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9365251064300537,
                    "sentence": "The approach seems to be an alternative to bagging weak learners together.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.87795090675354,
                    "sentence": "The theoretical contribution is the analysis of the complexity of the radon machine, where, since the original samples can be broken down into multiple parts, the resulting parallel machine is much more efficient as compared to the base learner that operates on all the original samples.They also show a PAC bound on the radon machine.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8793039917945862,
                    "sentence": "The theoretical contributions seems to be pretty good in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9269158840179443,
                    "sentence": "One major concern was the practical aspect, particularly for high-dimensional data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8858998417854309,
                    "sentence": "It is not clear how well the proposed approach performs here.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8913330435752869,
                    "sentence": "the experiments seem to be for very low dimensional datasets (18 features?)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9121553897857666,
                    "sentence": "which is perhaps not realistic for modern machine learning problems in most domains.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9561692476272583,
                    "sentence": "If the authors could emphasize on how high-dimensional could be handled by their method, the paper would be much stronger.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 9,
                    "completely_generated_prob": 0.9257822263275673
                }
            ],
            "completely_generated_prob": 0.706120647383059,
            "class_probabilities": {
                "human": 0.29372542799595996,
                "ai": 0.706120647383059,
                "mixed": 0.0001539246209811207
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.706120647383059,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.706120647383059,
                    "human": 0.29372542799595996,
                    "mixed": 0.0001539246209811207
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The main contribution of the paper is a new framework for parallel machine learning algorithms. The idea is to combine base learners more effectively than simply averaging. Specifically, subsets of hypotheses are replaced by their radon point. They prove complexity bounds for their method and also empirically compare their results with parallel algorithms in Spark and using base linear models in Weka.\nThe paper is quite interesting since it proposes essentially a black-box method to combine weak learners together. The approach seems to be an alternative to bagging weak learners together. The theoretical contribution is the analysis of the complexity of the radon machine, where, since the original samples can be broken down into multiple parts, the resulting parallel machine is much more efficient as compared to the base learner that operates on all the original samples.They also show a PAC bound on the radon machine. The theoretical contributions seems to be pretty good in the paper. One major concern was the practical aspect, particularly for high-dimensional data. It is not clear how well the proposed approach performs here. the experiments seem to be for very low dimensional datasets (18 features?) which is perhaps not realistic for modern machine learning problems in most domains. If the authors could emphasize on how high-dimensional could be handled by their method, the paper would be much stronger."
        }
    ]
}