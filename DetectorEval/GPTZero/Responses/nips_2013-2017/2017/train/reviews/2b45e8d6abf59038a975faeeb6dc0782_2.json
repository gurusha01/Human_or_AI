{
    "version": "2025-01-09-base",
    "scanId": "889938d6-d08b-41e3-8162-f68df7a64c39",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0042451778426766396,
                    "sentence": "This paper presents the population matching discrepancy (PMD) as a better alternative to MMD for distribution matching applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004029278643429279,
                    "sentence": "It is shown that PMD is a sampled version of Wasserstein metric or earth mover's distance, and it has a few advantages over MMD, most notably stronger gradients and the applicability of smaller mini-batch sizes, and fewer hyperparameters.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003361594397574663,
                    "sentence": "For training generative models at least, the MMD metric does suffer from weak gradients and the requirement of large mini-batches, the proposals in this paper therefore provides a nice solution to both of these problems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0041342549957334995,
                    "sentence": "The small mini-batch claim is verified quite nicely in the empirical results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0038432045839726925,
                    "sentence": "The verification of the stronger gradients claim is less satisfactory, since the MMD metric depends on the scale parameter sigma, it is essential to consider either the best sigma or a range of sigmas when making such a claim.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0026582591235637665,
                    "sentence": "In terms of having fewer hyper-parameters, I feel this claim is less well-supported, because PMD depends on a distance metric, and this distance metric might contain extra hyperparameters as well as in the MMD case.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0029255803674459457,
                    "sentence": "Moreover, it is hard to get a reliable distance metric in a high dimensional space, therefore PMD may suffer from the same issue of relying on a distance metric as MMD.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006116610020399094,
                    "sentence": "On the other hand, there are some standard heuristics for MMDs about how to choose the bandwidth parameter, it would be good to compare against such heuristics and treat MMD as a hyperparameter-free metric as well.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009917449206113815,
                    "sentence": "Overall I think the proposed method has the nice property of permitting small minibatch sizes therefore fast training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009988944977521896,
                    "sentence": "It seems like a valid improvement over large batch MMD methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009087971411645412,
                    "sentence": "But the it still has the problem of relying on a distance metric, which may limit its success on modeling higher dimensional data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                }
            ],
            "completely_generated_prob": 0.024462635563563526,
            "class_probabilities": {
                "human": 0.9755373644364365,
                "ai": 0.024462635563563526,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9755373644364365,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.024462635563563526,
                    "human": 0.9755373644364365,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents the population matching discrepancy (PMD) as a better alternative to MMD for distribution matching applications. It is shown that PMD is a sampled version of Wasserstein metric or earth mover's distance, and it has a few advantages over MMD, most notably stronger gradients and the applicability of smaller mini-batch sizes, and fewer hyperparameters.\nFor training generative models at least, the MMD metric does suffer from weak gradients and the requirement of large mini-batches, the proposals in this paper therefore provides a nice solution to both of these problems. The small mini-batch claim is verified quite nicely in the empirical results. The verification of the stronger gradients claim is less satisfactory, since the MMD metric depends on the scale parameter sigma, it is essential to consider either the best sigma or a range of sigmas when making such a claim.\nIn terms of having fewer hyper-parameters, I feel this claim is less well-supported, because PMD depends on a distance metric, and this distance metric might contain extra hyperparameters as well as in the MMD case. Moreover, it is hard to get a reliable distance metric in a high dimensional space, therefore PMD may suffer from the same issue of relying on a distance metric as MMD. On the other hand, there are some standard heuristics for MMDs about how to choose the bandwidth parameter, it would be good to compare against such heuristics and treat MMD as a hyperparameter-free metric as well.\nOverall I think the proposed method has the nice property of permitting small minibatch sizes therefore fast training. It seems like a valid improvement over large batch MMD methods. But the it still has the problem of relying on a distance metric, which may limit its success on modeling higher dimensional data."
        }
    ]
}