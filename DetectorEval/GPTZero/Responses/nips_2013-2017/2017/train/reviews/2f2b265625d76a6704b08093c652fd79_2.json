{
    "version": "2025-01-09-base",
    "scanId": "5d1d60fe-1c6c-4c1a-9049-89284c3c3973",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0011124196462333202,
                    "sentence": "Thank you for an interesting read.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0025278180837631226,
                    "sentence": "This paper proposed an information geometric (IG) view of the f-GAN algorithm.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0035205180756747723,
                    "sentence": "It first showed that f-GAN converges in parameter space using the 1-1 mapping of f-divergence and chi-divergence and a Bregman divergence result.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0023050636518746614,
                    "sentence": "Then it also discussed a proper way to implement f-GAN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0029296313878148794,
                    "sentence": "Finally in the main text it provided a factorisation result of the deep neural network representation and discussed the choice of activation functions which has 1-1 mapping to the chi (or f) function.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002712290035560727,
                    "sentence": "I didn't check every detail in the appendix but it seems to me that the proofs (except for Thm.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001925419783219695,
                    "sentence": "8 which I don't have time to read before due) are correct.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0019453491549938917,
                    "sentence": "I think this paper is very dense and contains many new results that could be of interest for machine learning and information theory.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002355303382501006,
                    "sentence": "Especially I'm impressed to see the exposition of Thm 4 which tells the IG part of the story for f-GAN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001572217559441924,
                    "sentence": "So I think this paper is a clear accept.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002894934732466936,
                    "sentence": "However, I do think this paper could be very difficult to understand for those who don't know too much about the connections between IT and IG (at least the simplest one that KL for an exponential family can be mapped to Bregman divergence, and the Fenchel duality stuff).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002709080930799246,
                    "sentence": "Many deep learning engineers could be this kind of person and also they're the main audience for a GAN paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0015415996313095093,
                    "sentence": "So the following are my suggestions that could potentially make the paper clearer:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002021822612732649,
                    "sentence": "1. I like Fig 1 in the appendix which states the connections between IT and IG in f-GAN context.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0016652669291943312,
                    "sentence": "Might consider moving it to the main text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0017965605948120356,
                    "sentence": "2. Might be helpful to make a clear statement why considering the IG view could be helpful at the beginning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0021709855645895004,
                    "sentence": "My understanding is that you can use the geometry in the parameter space to discuss the behaviour of optimisation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0017940581310540438,
                    "sentence": "You mentioned that briefly in page 7 which I found is a bit too late.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0017554124351590872,
                    "sentence": "3. I'm not sure if I understand how section 5 connects to f-GAN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0025885431095957756,
                    "sentence": "It seems to me that you just used the deformed exponential family to explain the distribution a deep neural net can represent, thus not a consequence of f-GAN optimisation results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0015404396690428257,
                    "sentence": "Yes I buy the point that v, f, and chi have 1-1 correspondence, but then you didn't say anything about how this result could help design the f-GAN game, e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.400456041097641,
                    "sentence": "which f divergence we should pick, or given an activation function, which f-GAN objective works the best in terms of say convergence.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.28662288188934326,
                    "sentence": "4. Why for Thm 6 the phi_l can be viewed as \"deep sufficient statistics\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.41245031356811523,
                    "sentence": "I don't think eq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.49770793318748474,
                    "sentence": "(13) is of the form of a deformed exponential family?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.41426751017570496,
                    "sentence": "5. As said, might be helpful to consider moving line 257-269 to other places.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.32916462421417236,
                    "sentence": "Also it seems to me that the utility theory part is not directly related to the IG view, so might be good to delete that paragraph (you can keep it in the appendix) and free some spaces to explain your main results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3789369761943817,
                    "sentence": "6. I feel the experiments are not directly related to the main points claimed in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.24516108632087708,
                    "sentence": "For example, you can discuss (A) by only having the results from section 5, i.e.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.41410964727401733,
                    "sentence": "I don't really need to know the IG view of f-GAN to apply these new activation functions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4105376601219177,
                    "sentence": "Also for (B) I only need to understand section 4, which is not that closely related to the IG view of f-GAN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.587899386882782,
                    "sentence": "Especially your results of WGAN could be distractive and confusing, since this paper is mainly about f-GANs, and I actually spent some time to find the sentence (line 227-228) about WGAN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8225786685943604,
                    "sentence": "In summary, while this paper provides many useful results and dense derivations, I have a feeling that the material is not organised in a crystal clear way.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7924959063529968,
                    "sentence": "Instead, it looks like squeezing results from multiple papers to an 8-page NIPS submission.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6766313314437866,
                    "sentence": "So while I am supportive for acceptance, I do think this paper needs editing to make the claims clearer and more coherent.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 6,
                    "completely_generated_prob": 1.474742012248794e-05
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.00010005932717626924
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.07332528267997859
                }
            ],
            "completely_generated_prob": 0.12598562404704858,
            "class_probabilities": {
                "human": 0.8714005663254193,
                "ai": 0.12598562404704858,
                "mixed": 0.0026138096275321277
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.8714005663254193,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.12598562404704858,
                    "human": 0.8714005663254193,
                    "mixed": 0.0026138096275321277
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Thank you for an interesting read.\nThis paper proposed an information geometric (IG) view of the f-GAN algorithm. It first showed that f-GAN converges in parameter space using the 1-1 mapping of f-divergence and chi-divergence and a Bregman divergence result. Then it also discussed a proper way to implement f-GAN. Finally in the main text it provided a factorisation result of the deep neural network representation and discussed the choice of activation functions which has 1-1 mapping to the chi (or f) function. I didn't check every detail in the appendix but it seems to me that the proofs (except for Thm. 8 which I don't have time to read before due) are correct.\nI think this paper is very dense and contains many new results that could be of interest for machine learning and information theory. Especially I'm impressed to see the exposition of Thm 4 which tells the IG part of the story for f-GAN. So I think this paper is a clear accept. \nHowever, I do think this paper could be very difficult to understand for those who don't know too much about the connections between IT and IG (at least the simplest one that KL for an exponential family can be mapped to Bregman divergence, and the Fenchel duality stuff). Many deep learning engineers could be this kind of person and also they're the main audience for a GAN paper. So the following are my suggestions that could potentially make the paper clearer:\n1. I like Fig 1 in the appendix which states the connections between IT and IG in f-GAN context. Might consider moving it to the main text.\n2. Might be helpful to make a clear statement why considering the IG view could be helpful at the beginning. My understanding is that you can use the geometry in the parameter space to discuss the behaviour of optimisation. You mentioned that briefly in page 7 which I found is a bit too late. \n3. I'm not sure if I understand how section 5 connects to f-GAN. It seems to me that you just used the deformed exponential family to explain the distribution a deep neural net can represent, thus not a consequence of f-GAN optimisation results. Yes I buy the point that v, f, and chi have 1-1 correspondence, but then you didn't say anything about how this result could help design the f-GAN game, e.g. which f divergence we should pick, or given an activation function, which f-GAN objective works the best in terms of say convergence.\n4. Why for Thm 6 the phi_l can be viewed as \"deep sufficient statistics\"? I don't think eq. (13) is of the form of a deformed exponential family?\n5. As said, might be helpful to consider moving line 257-269 to other places. Also it seems to me that the utility theory part is not directly related to the IG view, so might be good to delete that paragraph (you can keep it in the appendix) and free some spaces to explain your main results.\n6. I feel the experiments are not directly related to the main points claimed in the paper. For example, you can discuss (A) by only having the results from section 5, i.e. I don't really need to know the IG view of f-GAN to apply these new activation functions. Also for (B) I only need to understand section 4, which is not that closely related to the IG view of f-GAN. Especially your results of WGAN could be distractive and confusing, since this paper is mainly about f-GANs, and I actually spent some time to find the sentence (line 227-228) about WGAN.\nIn summary, while this paper provides many useful results and dense derivations, I have a feeling that the material is not organised in a crystal clear way. Instead, it looks like squeezing results from multiple papers to an 8-page NIPS submission. So while I am supportive for acceptance, I do think this paper needs editing to make the claims clearer and more coherent."
        }
    ]
}