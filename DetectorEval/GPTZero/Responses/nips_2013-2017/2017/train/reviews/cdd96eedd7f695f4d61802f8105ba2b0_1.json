{
    "version": "2025-01-09-base",
    "scanId": "9db50c8d-aed3-4ac2-b433-80f79a6f6f5a",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0005267079686746001,
                    "sentence": "This paper proposes an unsupervised network embedding learning framework.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005783067317679524,
                    "sentence": "The contributions include: a) designing an objective function based on matrix tri-factorization which can preserve the proximity and the global node ranking of the graph simultaneously; b) providing sufficient theoretical derivations to the objective function they designed; c) testing the performance of node embeddings, which are learned by optimizing the objective function through a neural network, on three real world datasets and several data mining tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007008824031800032,
                    "sentence": "Pros:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005517122335731983,
                    "sentence": "+: This paper has good theoretical foundations, and the loss function can be well explained from the proximity preserving and global ranking preserving view.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005470782052725554,
                    "sentence": "+: The results are fairly strong on all the tasks and datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001416955841705203,
                    "sentence": "Cons:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0005850725574418902,
                    "sentence": "-: The paper puts too much space on theoretical derivations but little on experiments, and some lemmas are trivial thus should be omitted or concisely written, e.g., Lemma 3.5 and Lemma 3.6.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007055113674141467,
                    "sentence": "-: Part in Line 169 ~ Line 184 is not directly related to the final objective function.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008914842619560659,
                    "sentence": "Maximizing the modularity is the special case of (6) when alpha = 1, and they don't use this function as a part of the final loss function, thus I think this part is relatively irrelevant to the main framework.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008954933728091419,
                    "sentence": "-: Also it seems quite straightforward to incorporate node ranking information in their frameworks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009100165916606784,
                    "sentence": "The simplest way is to add a second objective, like the way the authors did in this paper, although the experiment results show that adding this part boosts the performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008519060211256146,
                    "sentence": "-: Some writing details should be improved.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001010448788292706,
                    "sentence": "In the experiment part, results under different evaluation metrics should be listed separately.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0012702579842880368,
                    "sentence": "And I suggest to add one more baseline, i.e., GCN (Kipf and Welling (ICLR 2017)), which is a strong node embedding learning method based on graph convolution network.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                }
            ],
            "completely_generated_prob": 0.008764888981516596,
            "class_probabilities": {
                "human": 0.9912351110184834,
                "ai": 0.008764888981516596,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9912351110184834,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.008764888981516596,
                    "human": 0.9912351110184834,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes an unsupervised network embedding learning framework. The contributions include: a) designing an objective function based on matrix tri-factorization which can preserve the proximity and the global node ranking of the graph simultaneously; b) providing sufficient theoretical derivations to the objective function they designed; c) testing the performance of node embeddings, which are learned by optimizing the objective function through a neural network, on three real world datasets and several data mining tasks.\nPros:\n+: This paper has good theoretical foundations, and the loss function can be well explained from the proximity preserving and global ranking preserving view.\n+: The results are fairly strong on all the tasks and datasets.\nCons:\n-: The paper puts too much space on theoretical derivations but little on experiments, and some lemmas are trivial thus should be omitted or concisely written, e.g., Lemma 3.5 and Lemma 3.6.\n-: Part in Line 169 ~ Line 184 is not directly related to the final objective function. Maximizing the modularity is the special case of (6) when alpha = 1, and they don't use this function as a part of the final loss function, thus I think this part is relatively irrelevant to the main framework.\n-: Also it seems quite straightforward to incorporate node ranking information in their frameworks. The simplest way is to add a second objective, like the way the authors did in this paper, although the experiment results show that adding this part boosts the performance.\n-: Some writing details should be improved. In the experiment part, results under different evaluation metrics should be listed separately. And I suggest to add one more baseline, i.e., GCN (Kipf and Welling (ICLR 2017)), which is a strong node embedding learning method based on graph convolution network."
        }
    ]
}