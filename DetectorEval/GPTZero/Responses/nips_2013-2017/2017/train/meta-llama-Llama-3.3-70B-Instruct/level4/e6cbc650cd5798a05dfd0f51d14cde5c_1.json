{
    "version": "2025-01-09-base",
    "scanId": "2dc860be-4be9-4f6e-bded-7576c90cfa38",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999472498893738,
                    "sentence": "This manuscript presents a novel recurrent network approach to sparse estimation, drawing inspiration from sparse Bayesian learning (SBL) principles.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999741911888123,
                    "sentence": "The authors demonstrate that a recurrent architecture can effectively implement a variant of SBL, with simulation results revealing distinct time dynamics for various quantities, thereby justifying the incorporation of recurrent network design concepts to adapt the architecture.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99997478723526,
                    "sentence": "This ultimately yields a recurrent network that appears to surpass optimization-based methods in both simulations and real-world applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999743103981018,
                    "sentence": "The primary strengths of this work lie in its potential for significant impact, as the concept of leveraging a recurrent network for sparse estimation is highly promising.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999719262123108,
                    "sentence": "The manuscript is exceptionally well-written, with the authors providing meticulous motivation for their design choices and presenting comprehensive numerical experiments that underscore the technique's efficacy in tackling complex sparse decomposition problems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999350905418396,
                    "sentence": "One notable weakness of the manuscript is that numerous implementation details and experimental specifics are relegated to the supplementary material, resulting in a somewhat vague main paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999140501022339,
                    "sentence": "However, this is a reasonable concession given the constraints on paper length.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This manuscript presents a novel recurrent network approach to sparse estimation, drawing inspiration from sparse Bayesian learning (SBL) principles. The authors demonstrate that a recurrent architecture can effectively implement a variant of SBL, with simulation results revealing distinct time dynamics for various quantities, thereby justifying the incorporation of recurrent network design concepts to adapt the architecture. This ultimately yields a recurrent network that appears to surpass optimization-based methods in both simulations and real-world applications.\nThe primary strengths of this work lie in its potential for significant impact, as the concept of leveraging a recurrent network for sparse estimation is highly promising. The manuscript is exceptionally well-written, with the authors providing meticulous motivation for their design choices and presenting comprehensive numerical experiments that underscore the technique's efficacy in tackling complex sparse decomposition problems.\nOne notable weakness of the manuscript is that numerous implementation details and experimental specifics are relegated to the supplementary material, resulting in a somewhat vague main paper. However, this is a reasonable concession given the constraints on paper length."
        }
    ]
}