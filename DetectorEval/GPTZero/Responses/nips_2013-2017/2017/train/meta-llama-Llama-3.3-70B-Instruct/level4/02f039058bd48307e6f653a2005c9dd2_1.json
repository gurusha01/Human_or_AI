{
    "version": "2025-01-09-base",
    "scanId": "4cedb031-861a-4561-b6e1-806fdf0b68e2",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9984757304191589,
                    "sentence": "This paper presents a model-powered approach for conducting conditional independence tests on iid data, leveraging nearest neighbor bootstrap to generate samples that closely follow the conditional independence distribution, denoted as $f^{CI}$.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987684488296509,
                    "sentence": "A classifier is then trained and tested to determine if it can distinguish between the observation distribution and the bootstrapped distribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9978156685829163,
                    "sentence": "If the classifier's performance is comparable to a random guess, the null hypothesis that the data follows conditional independence is not rejected; otherwise, it is accepted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989162683486938,
                    "sentence": "The authors establish bounds on the closeness of the nearest neighbor bootstrapped distribution to $f^{CI}$ in terms of total variation distance and bounds on empirical risks under ideal classification settings and for near-independent samples.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9980469346046448,
                    "sentence": "The paper tackles an important problem and is presented clearly.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990447759628296,
                    "sentence": "Detailed comments are as follows:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985343813896179,
                    "sentence": "Major:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9981755018234253,
                    "sentence": "1. The methodology appears to be separable into two primary components: generating samples that mimic $f_{CI}$ and using a classifier for determination.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988458156585693,
                    "sentence": "It is worth exploring whether either step can be substituted with existing solutions from the literature.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9981308579444885,
                    "sentence": "For instance, combining the permutation-based method from [7] with the classification-based approach, or using nearest neighbor bootstrap with the kernel two-sample test, could yield interesting performance comparisons.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9978978633880615,
                    "sentence": "2. In the finite sample size setting, the nearest neighbor bootstrap distribution approximates $f_{CI}$.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9960620403289795,
                    "sentence": "If the ground truth indicates that $x$ and $y$ are weakly dependent given $z$, it is unclear how the proposed method would differentiate this scenario.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9975368976593018,
                    "sentence": "3. The method's symmetry with respect to $x$ and $y$ is questionable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9972663521766663,
                    "sentence": "From a causal perspective, $x$ and $y$ can be dependent given $z$ due to different causal models (e.g., $x$ causes $y$ or $y$ causes $x$).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9979941248893738,
                    "sentence": "In such cases, determining which variable to sample becomes crucial, a consideration not addressed by the authors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9975440502166748,
                    "sentence": "4. The selection of the parameter $\\tau$ in Algorithms 2 and 3 raises significant concerns.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988992810249329,
                    "sentence": "Minor:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989822506904602,
                    "sentence": "In Algorithms 2 and 3, the empirical risk should be normalized by dividing it by the sample size to ensure accurate calculations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9984984300152882,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984984300152882,
                "mixed": 0.0015015699847118259
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984984300152882,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984984300152882,
                    "human": 0,
                    "mixed": 0.0015015699847118259
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a model-powered approach for conducting conditional independence tests on iid data, leveraging nearest neighbor bootstrap to generate samples that closely follow the conditional independence distribution, denoted as $f^{CI}$. A classifier is then trained and tested to determine if it can distinguish between the observation distribution and the bootstrapped distribution. If the classifier's performance is comparable to a random guess, the null hypothesis that the data follows conditional independence is not rejected; otherwise, it is accepted.\nThe authors establish bounds on the closeness of the nearest neighbor bootstrapped distribution to $f^{CI}$ in terms of total variation distance and bounds on empirical risks under ideal classification settings and for near-independent samples. The paper tackles an important problem and is presented clearly.\nDetailed comments are as follows:\nMajor:\n1. The methodology appears to be separable into two primary components: generating samples that mimic $f_{CI}$ and using a classifier for determination. It is worth exploring whether either step can be substituted with existing solutions from the literature. For instance, combining the permutation-based method from [7] with the classification-based approach, or using nearest neighbor bootstrap with the kernel two-sample test, could yield interesting performance comparisons.\n2. In the finite sample size setting, the nearest neighbor bootstrap distribution approximates $f_{CI}$. If the ground truth indicates that $x$ and $y$ are weakly dependent given $z$, it is unclear how the proposed method would differentiate this scenario.\n3. The method's symmetry with respect to $x$ and $y$ is questionable. From a causal perspective, $x$ and $y$ can be dependent given $z$ due to different causal models (e.g., $x$ causes $y$ or $y$ causes $x$). In such cases, determining which variable to sample becomes crucial, a consideration not addressed by the authors.\n4. The selection of the parameter $\\tau$ in Algorithms 2 and 3 raises significant concerns.\nMinor:\nIn Algorithms 2 and 3, the empirical risk should be normalized by dividing it by the sample size to ensure accurate calculations."
        }
    ]
}