{
    "version": "2025-01-09-base",
    "scanId": "579c4713-47e5-403c-917d-087b76b2b046",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9992204308509827,
                    "sentence": "Overall, I consider the paper to be well-structured and the concept to be both intuitive and well-founded.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989144802093506,
                    "sentence": "Nevertheless, I have several technical concerns and questions regarding the methodology employed in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987230896949768,
                    "sentence": "* The architecture of the encoder (Fig.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990920424461365,
                    "sentence": "4) raises a question about the necessity of explicitly generating K posterior mean/variances before combining them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990156292915344,
                    "sentence": "Would it not be more efficient to have the encoder network directly generate the posterior mean/variances, and what benefits does the current approach provide in comparison?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992997646331787,
                    "sentence": "* Given that the ultimate goal is conditional caption generation, which does not inherently require posterior inference, I wonder if the use of VAE is overly complex.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988527894020081,
                    "sentence": "An alternative approach could involve directly learning the decoder through maximum likelihood, where z can still be sampled from p(z\"c) and marginalized to approximate the maximization of p(x\"c) = â^'[p(zi\"c)p(x\"zi, c)].",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996073842048645,
                    "sentence": "This could potentially yield a stronger LSTM baseline while still incorporating z.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985026121139526,
                    "sentence": "* The computation of KL-divergence in GMM-CVAE is not clearly explained and warrants further clarification.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9975404739379883,
                    "sentence": "* The standard deviations Ïƒk in the prior play a crucial role in balancing KL-divergence and reconstruction error during training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.992417573928833,
                    "sentence": "I am interested in knowing whether the authors explored different values for Ïƒk during training, as they did during testing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9928781390190125,
                    "sentence": "It seems reasonable to maintain consistency in Ïƒ_k values between training and testing phases.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9863129258155823,
                    "sentence": "Additionally, a minor typo was noticed: on line 36, \"maximize (an upper bound on) the likelihood\" should likely be \"minimize (a lower bound on) the likelihood\" or simply \"lower bound\" for accuracy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997847017652333,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997847017652333,
                "mixed": 0.00021529823476680056
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997847017652333,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997847017652333,
                    "human": 0,
                    "mixed": 0.00021529823476680056
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Overall, I consider the paper to be well-structured and the concept to be both intuitive and well-founded. Nevertheless, I have several technical concerns and questions regarding the methodology employed in the paper.\n* The architecture of the encoder (Fig. 4) raises a question about the necessity of explicitly generating K posterior mean/variances before combining them. Would it not be more efficient to have the encoder network directly generate the posterior mean/variances, and what benefits does the current approach provide in comparison?\n* Given that the ultimate goal is conditional caption generation, which does not inherently require posterior inference, I wonder if the use of VAE is overly complex. An alternative approach could involve directly learning the decoder through maximum likelihood, where z can still be sampled from p(z\"c) and marginalized to approximate the maximization of p(x\"c) = âˆ'[p(zi\"c)p(x\"zi, c)]. This could potentially yield a stronger LSTM baseline while still incorporating z.\n* The computation of KL-divergence in GMM-CVAE is not clearly explained and warrants further clarification.\n* The standard deviations Ïƒk in the prior play a crucial role in balancing KL-divergence and reconstruction error during training. I am interested in knowing whether the authors explored different values for Ïƒk during training, as they did during testing. It seems reasonable to maintain consistency in Ïƒ_k values between training and testing phases.\nAdditionally, a minor typo was noticed: on line 36, \"maximize (an upper bound on) the likelihood\" should likely be \"minimize (a lower bound on) the likelihood\" or simply \"lower bound\" for accuracy."
        }
    ]
}