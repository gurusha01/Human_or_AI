{
    "version": "2025-01-09-base",
    "scanId": "be30fa0d-b499-45b6-aa5a-cfdd90d4d1fc",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.8257610201835632,
                    "sentence": "This manuscript presents an unsupervised framework for learning network embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.854970395565033,
                    "sentence": "The key contributions of this work are: a) the development of an objective function grounded in matrix tri-factorization, which effectively preserves both proximity and global node ranking within the graph; b) the provision of comprehensive theoretical underpinnings for the designed objective function; and c) the evaluation of node embeddings, learned through neural network optimization of the objective function, across three real-world datasets and multiple data mining tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9097128510475159,
                    "sentence": "Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8729678392410278,
                    "sentence": "* The manuscript boasts robust theoretical underpinnings, with the loss function being well-explained from the perspectives of preserving proximity and global ranking.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9274054169654846,
                    "sentence": "* The experimental results demonstrate strong performance across all tasks and datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8930705189704895,
                    "sentence": "Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9030866026878357,
                    "sentence": "* The manuscript allocates an disproportionate amount of space to theoretical derivations at the expense of experimental discussions, with some lemmas (e.g., Lemma 3.5 and Lemma 3.6) being trivial and thus deserving of omission or concise presentation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9693129062652588,
                    "sentence": "* The section spanning Lines 169 to 184 appears tangential to the final objective function, as maximizing modularity represents a special case of equation (6) when alpha equals 1, and is not integrated into the final loss function, rendering it somewhat irrelevant to the core framework.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9638256430625916,
                    "sentence": "* Incorporating node ranking information into the framework seems relatively straightforward, achievable through the addition of a secondary objective, akin to the approach adopted by the authors, despite the experimental results indicating a performance boost from this addition.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9566070437431335,
                    "sentence": "* Certain writing aspects require refinement, including the separate listing of results under different evaluation metrics in the experimental section, and the consideration of adding an additional baseline, specifically GCN (Kipf and Welling, ICLR 2017), a potent node embedding learning method leveraging graph convolutional networks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.8129788192879676,
            "class_probabilities": {
                "human": 0.18702118071203244,
                "ai": 0.8129788192879676,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8129788192879676,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8129788192879676,
                    "human": 0.18702118071203244,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This manuscript presents an unsupervised framework for learning network embeddings. The key contributions of this work are: a) the development of an objective function grounded in matrix tri-factorization, which effectively preserves both proximity and global node ranking within the graph; b) the provision of comprehensive theoretical underpinnings for the designed objective function; and c) the evaluation of node embeddings, learned through neural network optimization of the objective function, across three real-world datasets and multiple data mining tasks.\nStrengths:\n* The manuscript boasts robust theoretical underpinnings, with the loss function being well-explained from the perspectives of preserving proximity and global ranking.\n* The experimental results demonstrate strong performance across all tasks and datasets.\nWeaknesses:\n* The manuscript allocates an disproportionate amount of space to theoretical derivations at the expense of experimental discussions, with some lemmas (e.g., Lemma 3.5 and Lemma 3.6) being trivial and thus deserving of omission or concise presentation.\n* The section spanning Lines 169 to 184 appears tangential to the final objective function, as maximizing modularity represents a special case of equation (6) when alpha equals 1, and is not integrated into the final loss function, rendering it somewhat irrelevant to the core framework.\n* Incorporating node ranking information into the framework seems relatively straightforward, achievable through the addition of a secondary objective, akin to the approach adopted by the authors, despite the experimental results indicating a performance boost from this addition.\n* Certain writing aspects require refinement, including the separate listing of results under different evaluation metrics in the experimental section, and the consideration of adding an additional baseline, specifically GCN (Kipf and Welling, ICLR 2017), a potent node embedding learning method leveraging graph convolutional networks."
        }
    ]
}