{
    "version": "2025-01-09-base",
    "scanId": "8b8b8f5d-57a9-4c1b-85cb-dd05cfcd22da",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9997186660766602,
                    "sentence": "The paper addresses the problem of active hypothesis testing under constraints of limited information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999416172504425,
                    "sentence": "Specifically, it considers the probability of 'correct indication,' denoted as q(j,w), where j represents the true hypothesis and w the chosen action.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992792010307312,
                    "sentence": "The authors assume that q(j,w) is bounded below by \\alpha(w) for all j, with \\alpha(w) being known to the controller.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991623163223267,
                    "sentence": "They begin by analyzing the incomplete-Bayesian (IB) update rule, where all q's are substituted with \\alpha's, resulting in an approximation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9964249134063721,
                    "sentence": "They demonstrate that under this IB update rule, achieving a posterior error probability of (1-\\delta) requires at least O(log(1/\\delta)) samples.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.996510922908783,
                    "sentence": "Subsequently, they establish that their gradient-based policy achieves an order-wise optimal sample complexity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9376208186149597,
                    "sentence": "I have several technical questions:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8837196826934814,
                    "sentence": "On the upper bound: The authors assert that the upper bound is derived by considering the worst-case scenario where q(w,j) = \\alpha(w) for all w when j is the true hypothesis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.868061900138855,
                    "sentence": "If this is the case, how does the analysis in this paper differ from that of the Bayesian update case?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6695560812950134,
                    "sentence": "(If my interpretation is correct, q(w,j) = \\alpha(w) would imply that the IB update rule is equivalent to the Bayesian update rule.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7580230236053467,
                    "sentence": "Additionally, in practical scenarios, it is possible for q(w,j) to approach 1 while \\alpha(w) approaches 1/2.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7187755107879639,
                    "sentence": "Under such conditions, does the upper bound still provide any meaningful guarantees?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8604623079299927,
                    "sentence": "On the lower bound: Does the derived lower bound recover the existing lower bounds for the case of complete information?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8450565934181213,
                    "sentence": "On simulation results: It would be beneficial if the authors could include the lower and upper bounds on E[T] and compare these theoretical results with their simulation outcomes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.03396563365573288
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9954476479514417,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9954476479514417,
                "mixed": 0.004552352048558421
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9954476479514417,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9954476479514417,
                    "human": 0,
                    "mixed": 0.004552352048558421
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper addresses the problem of active hypothesis testing under constraints of limited information. Specifically, it considers the probability of 'correct indication,' denoted as q(j,w), where j represents the true hypothesis and w the chosen action. The authors assume that q(j,w) is bounded below by \\alpha(w) for all j, with \\alpha(w) being known to the controller. They begin by analyzing the incomplete-Bayesian (IB) update rule, where all q's are substituted with \\alpha's, resulting in an approximation. They demonstrate that under this IB update rule, achieving a posterior error probability of (1-\\delta) requires at least O(log(1/\\delta)) samples. Subsequently, they establish that their gradient-based policy achieves an order-wise optimal sample complexity.\nI have several technical questions:\nOn the upper bound: The authors assert that the upper bound is derived by considering the worst-case scenario where q(w,j) = \\alpha(w) for all w when j is the true hypothesis. If this is the case, how does the analysis in this paper differ from that of the Bayesian update case? (If my interpretation is correct, q(w,j) = \\alpha(w) would imply that the IB update rule is equivalent to the Bayesian update rule.) Additionally, in practical scenarios, it is possible for q(w,j) to approach 1 while \\alpha(w) approaches 1/2. Under such conditions, does the upper bound still provide any meaningful guarantees?\nOn the lower bound: Does the derived lower bound recover the existing lower bounds for the case of complete information?\nOn simulation results: It would be beneficial if the authors could include the lower and upper bounds on E[T] and compare these theoretical results with their simulation outcomes."
        }
    ]
}