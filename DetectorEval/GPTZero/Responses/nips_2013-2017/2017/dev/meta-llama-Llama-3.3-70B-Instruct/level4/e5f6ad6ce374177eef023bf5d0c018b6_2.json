{
    "version": "2025-01-09-base",
    "scanId": "0f783953-d2cc-4048-af97-355bc7389464",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999895095825195,
                    "sentence": "This manuscript explores predictive learning, primarily focusing on video prediction, utilizing a Recurrent Neural Network (RNN) architecture.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999868273735046,
                    "sentence": "It introduces a novel variation of the Long Short-Term Memory (LSTM) network, termed ST-LSTM, which incorporates recurrent connections that are not limited to the forward time direction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999749660491943,
                    "sentence": "The predictive network is constructed from ST-LSTM blocks, each resembling a convolutional LSTM unit but with modifications to accommodate an additional input.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999992311000824,
                    "sentence": "This supplementary input originates from the last layer of the preceding time step and enters the first layer of the current time step, subsequently propagating through the layers of the current time step.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999911785125732,
                    "sentence": "The resulting ST-LSTM structure bears resemblance to the combination of two independent LSTM units that interact through the concatenation of their memories, as illustrated in figure 2(left).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999992311000824,
                    "sentence": "However, the formulation of the loss function is not explicitly stated in the manuscript, with the closest reference being equation 1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999912977218628,
                    "sentence": "It is assumed to be a Mean Squared Error (MSE) loss, but confirmation is necessary as other forms of loss functions could be applicable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999982476234436,
                    "sentence": "The authors present results on the Moving MNIST (synthetic) and KTH (natural) datasets, demonstrating both Peak Signal-to-Noise Ratio (PSNR)/Structural Similarity Index Measure (SSIM) and generated samples.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999898672103882,
                    "sentence": "They compare their PredRNN model with other baseline models, achieving the best results on these datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998420476913452,
                    "sentence": "Notably, on the Moving MNIST dataset, a comparison of different LSTM schemes shows that ST-LSTM yields the best results, which is a significant finding.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9982007145881653,
                    "sentence": "Nevertheless, the experimental section could be enhanced by including more diverse datasets, as the two presented datasets have relatively predictable futures.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99808269739151,
                    "sentence": "It would be intriguing to observe the model's performance on less constrained datasets, such as Sports1m, UCF101, or the Google \"Push\" dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9435568451881409,
                    "sentence": "Although the paper presents a complex and seemingly effective predictor structure, the loss function is rarely mentioned.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9227480292320251,
                    "sentence": "As highlighted in references [17] and [19], a simple loss function like MSE may not perform well when the future distribution is multimodal.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8816518187522888,
                    "sentence": "The manuscript would benefit from comparisons with other non-LSTM-based methods, such as those discussed in section 1.2, including Video Prediction Networks (VPNs) and Generative Adversarial Networks (GANs), which appear to be strong competitors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6696943640708923,
                    "sentence": "Additional notes include:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.4117317497730255,
                    "sentence": "- Figure 1: While the figure is clear, the meaning of the orange arrows (in comparison to the black arrows) is not entirely understood.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.20888873934745789,
                    "sentence": "- Figure 2(right): As interpreted, each W box should also have an Xt input, not just W1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.9841954571483108,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9841954571483108,
                "mixed": 0.015804542851689255
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9841954571483108,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9841954571483108,
                    "human": 0,
                    "mixed": 0.015804542851689255
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This manuscript explores predictive learning, primarily focusing on video prediction, utilizing a Recurrent Neural Network (RNN) architecture. It introduces a novel variation of the Long Short-Term Memory (LSTM) network, termed ST-LSTM, which incorporates recurrent connections that are not limited to the forward time direction.\nThe predictive network is constructed from ST-LSTM blocks, each resembling a convolutional LSTM unit but with modifications to accommodate an additional input. This supplementary input originates from the last layer of the preceding time step and enters the first layer of the current time step, subsequently propagating through the layers of the current time step.\nThe resulting ST-LSTM structure bears resemblance to the combination of two independent LSTM units that interact through the concatenation of their memories, as illustrated in figure 2(left).\nHowever, the formulation of the loss function is not explicitly stated in the manuscript, with the closest reference being equation 1. It is assumed to be a Mean Squared Error (MSE) loss, but confirmation is necessary as other forms of loss functions could be applicable.\nThe authors present results on the Moving MNIST (synthetic) and KTH (natural) datasets, demonstrating both Peak Signal-to-Noise Ratio (PSNR)/Structural Similarity Index Measure (SSIM) and generated samples. They compare their PredRNN model with other baseline models, achieving the best results on these datasets. Notably, on the Moving MNIST dataset, a comparison of different LSTM schemes shows that ST-LSTM yields the best results, which is a significant finding.\nNevertheless, the experimental section could be enhanced by including more diverse datasets, as the two presented datasets have relatively predictable futures. It would be intriguing to observe the model's performance on less constrained datasets, such as Sports1m, UCF101, or the Google \"Push\" dataset. Although the paper presents a complex and seemingly effective predictor structure, the loss function is rarely mentioned. As highlighted in references [17] and [19], a simple loss function like MSE may not perform well when the future distribution is multimodal. The manuscript would benefit from comparisons with other non-LSTM-based methods, such as those discussed in section 1.2, including Video Prediction Networks (VPNs) and Generative Adversarial Networks (GANs), which appear to be strong competitors.\nAdditional notes include:\n- Figure 1: While the figure is clear, the meaning of the orange arrows (in comparison to the black arrows) is not entirely understood.\n- Figure 2(right): As interpreted, each W box should also have an Xt input, not just W1."
        }
    ]
}