{
    "version": "2025-01-09-base",
    "scanId": "7375c8eb-29b9-4d14-998d-b0daa065a9fa",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.999731719493866,
                    "sentence": "This manuscript proposes an attention-based approach for recognizing actions and human object interactions, which can operate with or without additional supervision.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996321201324463,
                    "sentence": "The model yields improved accuracy without substantially increasing the network size or computational complexity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985427260398865,
                    "sentence": "The authors conduct a thorough empirical and analytical examination of the attention module and derive bottom-up and top-down attention as low-rank approximations of bilinear pooling methods, typically used for fine-grained classification.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995225667953491,
                    "sentence": "The efficacy of the proposed method is validated through experiments on three benchmark datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9954317212104797,
                    "sentence": "A notable benefit of this work is the ability to learn attention maps in an unsupervised manner, providing insights into the regions of focus for the network in terms of both bottom-up saliency and top-down attention.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9938870668411255,
                    "sentence": "This capability eliminates the need for detecting bounding boxes, which is often required in hard attention mechanisms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9961440563201904,
                    "sentence": "The work presented is intriguing, and the underlying idea appears well-motivated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9966433048248291,
                    "sentence": "The manuscript is also well-written.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9927905797958374,
                    "sentence": "However, a major concern arises regarding the approximation of the fully-connected weight matrix in second-order pooling using the product of two rank-1 vectors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.994160532951355,
                    "sentence": "It is essential to investigate the potential information loss compared to the original matrix and assess whether such loss impacts the attention map.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9920876026153564,
                    "sentence": "Further theoretical analysis and discussion on this aspect are necessary.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9947940707206726,
                    "sentence": "Additionally, several minor issues were identified:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9871582388877869,
                    "sentence": "On page 3, the phrase \"network architecture that incorporate(s) this attention module and explore(s) a pose...\" contains a subject-verb agreement error.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9780239462852478,
                    "sentence": "Page 5 states \"It consist(s) of a stack of modules,\" which also requires correction for subject-verb agreement.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.989851176738739,
                    "sentence": "Lastly, on page 8, the sentence \"... image resized to 450px at(as) input time did\" contains an unclear phrase that needs revision for better understanding.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9984984300152882,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984984300152882,
                "mixed": 0.0015015699847118259
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984984300152882,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984984300152882,
                    "human": 0,
                    "mixed": 0.0015015699847118259
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This manuscript proposes an attention-based approach for recognizing actions and human object interactions, which can operate with or without additional supervision. The model yields improved accuracy without substantially increasing the network size or computational complexity. The authors conduct a thorough empirical and analytical examination of the attention module and derive bottom-up and top-down attention as low-rank approximations of bilinear pooling methods, typically used for fine-grained classification. The efficacy of the proposed method is validated through experiments on three benchmark datasets.\nA notable benefit of this work is the ability to learn attention maps in an unsupervised manner, providing insights into the regions of focus for the network in terms of both bottom-up saliency and top-down attention. This capability eliminates the need for detecting bounding boxes, which is often required in hard attention mechanisms.\nThe work presented is intriguing, and the underlying idea appears well-motivated. The manuscript is also well-written. However, a major concern arises regarding the approximation of the fully-connected weight matrix in second-order pooling using the product of two rank-1 vectors. It is essential to investigate the potential information loss compared to the original matrix and assess whether such loss impacts the attention map. Further theoretical analysis and discussion on this aspect are necessary.\nAdditionally, several minor issues were identified: \nOn page 3, the phrase \"network architecture that incorporate(s) this attention module and explore(s) a pose ...\" contains a subject-verb agreement error.\nPage 5 states \"It consist(s) of a stack of modules,\" which also requires correction for subject-verb agreement.\nLastly, on page 8, the sentence \"... image resized to 450px at(as) input time did\" contains an unclear phrase that needs revision for better understanding."
        }
    ]
}