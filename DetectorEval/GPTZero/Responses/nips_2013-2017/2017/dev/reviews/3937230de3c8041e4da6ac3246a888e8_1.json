{
    "version": "2025-01-09-base",
    "scanId": "b481cc73-1be6-4bcc-bb5b-7b1639abd3e8",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.002128911903128028,
                    "sentence": "The authors propose variational memory addressing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0015578048769384623,
                    "sentence": "It augments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00182815152220428,
                    "sentence": "generative models with external memory and hard attention, and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002221175003796816,
                    "sentence": "interestingly, derives read and write mechanisms that mimick more",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0013439350295811892,
                    "sentence": "classical probabilistic graphical models than the more sophisticated",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0023802760988473892,
                    "sentence": "mechanisms as in, e.g., neural Turing machines.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0013680849224328995,
                    "sentence": "In their formulation, external memory acts much like a global variable",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001805424108169973,
                    "sentence": "in topic models and mixture models, whether they sample a \"membership\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0016493953298777342,
                    "sentence": "given by the hard attention and proceed to generate the local variable",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0020189736969769,
                    "sentence": "z and data x conditional on memory indexed by this membership.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0020998744294047356,
                    "sentence": "I found",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0015379323158413172,
                    "sentence": "this a particularly useful way of understanding memory in the context",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001534949871711433,
                    "sentence": "of latent variable models, where writing corresponds to inference.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002749587409198284,
                    "sentence": "As the authors note in, e.g., L175-186, it seems the algorithm does",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0021805642172694206,
                    "sentence": "not scale well with respect to the external memory size.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.000820863526314497,
                    "sentence": "This can be",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0021143322810530663,
                    "sentence": "justified mathematically as the the variance of the black box",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0031448721420019865,
                    "sentence": "gradients with respect q(a) parameters increases with the size of a.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0024367670994251966,
                    "sentence": "It is unlikely that VIMCO can help much in this regard.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0033823340199887753,
                    "sentence": "That said, I'm",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003475656732916832,
                    "sentence": "impressed that the authors were able to get interesting results with",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004715749528259039,
                    "sentence": "\"M\" up to 1024.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.01281881855424871,
            "class_probabilities": {
                "human": 0.9871811814457513,
                "ai": 0.01281881855424871,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9871811814457513,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.01281881855424871,
                    "human": 0.9871811814457513,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The authors propose variational memory addressing. It augments\ngenerative models with external memory and hard attention, and\ninterestingly, derives read and write mechanisms that mimick more\nclassical probabilistic graphical models than the more sophisticated\nmechanisms as in, e.g., neural Turing machines.\nIn their formulation, external memory acts much like a global variable\nin topic models and mixture models, whether they sample a \"membership\"\ngiven by the hard attention and proceed to generate the local variable\nz and data x conditional on memory indexed by this membership. I found\nthis a particularly useful way of understanding memory in the context\nof latent variable models, where writing corresponds to inference.\nAs the authors note in, e.g., L175-186, it seems the algorithm does\nnot scale well with respect to the external memory size. This can be\njustified mathematically as the the variance of the black box\ngradients with respect q(a) parameters increases with the size of a.\nIt is unlikely that VIMCO can help much in this regard. That said, I'm\nimpressed that the authors were able to get interesting results with\n\"M\" up to 1024."
        }
    ]
}