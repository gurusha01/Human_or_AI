{
    "version": "2025-01-09-base",
    "scanId": "1f6c9968-dd3f-4ef5-b16b-af9d3c5fbe88",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.028145108371973038,
                    "sentence": "The paper studies the problem of active hypothesis testing with limited information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.054147131741046906,
                    "sentence": "More specifically, denoting the probability of 'correct indication' by q(j,w) if the true hypothesis is j and the chosen action is w, they assume that q(j,w) is bounded below by \\alpha(w) for all j, and this quantity is available to the controller.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13045836985111237,
                    "sentence": "They first study the incomplete-bayesian update rule, where all q's are replaced with alpha's, hence approximate, and show that with this IB update rule, one needs at least O(log(1/\\delta)) to achieve (1-\\delta) posterior error probability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12342549115419388,
                    "sentence": "Then, they show that their gradient-based policy achieves the order-wise optimal sample complexity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02719377726316452,
                    "sentence": "I have a few technical questions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05325853079557419,
                    "sentence": "On the upper bound: The authors claim that the upper bound is obtained by considering the worst case scenario where q(w,j) = \\alpha(w) for every w if j is the true hypothesis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07394294440746307,
                    "sentence": "If that's the case, how is different the analysis given in this paper from that for Bayesian update case?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.047497622668743134,
                    "sentence": "(If my understanding is correct, q(w,j) = \\alpha(w) implies IB update rule = Bayesian update rule.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04383900761604309,
                    "sentence": "Further, what can happen in reality is that q(w,j) is arbitrarily close to 1, and alpha(w) is arbitrarily close to 1/2.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.033060427755117416,
                    "sentence": "In this case, can the upper bound provide any guarantee?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0407751202583313,
                    "sentence": "On the lower bound: Can this bound recover the existing lower bounds for the case of complete information?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.032224781811237335,
                    "sentence": "On simulation results: It will be great if the authors can present the lower & upper bounds on E[T] and compare them with the simulation results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.00010005932717626924
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.0375246461941804,
            "class_probabilities": {
                "human": 0.9624347023880775,
                "ai": 0.0375246461941804,
                "mixed": 4.065141774218333e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9624347023880775,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.0375246461941804,
                    "human": 0.9624347023880775,
                    "mixed": 4.065141774218333e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper studies the problem of active hypothesis testing with limited information. More specifically, denoting the probability of 'correct indication' by q(j,w) if the true hypothesis is j and the chosen action is w, they assume that q(j,w) is bounded below by \\alpha(w) for all j, and this quantity is available to the controller. They first study the incomplete-bayesian update rule, where all q's are replaced with alpha's, hence approximate, and show that with this IB update rule, one needs at least O(log(1/\\delta)) to achieve (1-\\delta) posterior error probability. Then, they show that their gradient-based policy achieves the order-wise optimal sample complexity. \nI have a few technical questions. \nOn the upper bound: The authors claim that the upper bound is obtained by considering the worst case scenario where q(w,j) = \\alpha(w) for every w if j is the true hypothesis. If that's the case, how is different the analysis given in this paper from that for Bayesian update case? (If my understanding is correct, q(w,j) = \\alpha(w) implies IB update rule = Bayesian update rule.) Further, what can happen in reality is that q(w,j) is arbitrarily close to 1, and alpha(w) is arbitrarily close to 1/2. In this case, can the upper bound provide any guarantee? \nOn the lower bound: Can this bound recover the existing lower bounds for the case of complete information? \nOn simulation results: It will be great if the authors can present the lower & upper bounds on E[T] and compare them with the simulation results."
        }
    ]
}