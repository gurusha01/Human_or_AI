{
    "version": "2025-01-09-base",
    "scanId": "2f4a27d2-a4a2-44a4-aa63-9ced2a43ef52",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.012358808889985085,
                    "sentence": "This paper deals with predictive learning (mainly video prediction), using a RNN type of structure.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012608122080564499,
                    "sentence": "A new (to my knowledge) variation of LSTM is introduced, called ST-LSTM, with recurrent connections not only in the forward time direction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01365803275257349,
                    "sentence": "The predictive network is composed of ST-LSTM blocks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007673301734030247,
                    "sentence": "Each of these block resemble a convolutional LSTM unit, with some differences to include an additional input.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00884545873850584,
                    "sentence": "This extra input comes from the last layer of the previous time step, and enters at the first layer of the current time step, it is then propagated through the layers at the current time step.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008059022016823292,
                    "sentence": "The resulting ST-LSTM is similar to the combination of two independent LSTM units, interacting through concatenation of the memories (figure 2(left)).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00884761568158865,
                    "sentence": "I couldn't find an explicit formulation of the loss (the closest I could find is equation 1).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008906791917979717,
                    "sentence": "I am assuming that it is a MSE loss, but this should be confirmed, since other forms are possible.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009214621037244797,
                    "sentence": "Results are presented on the Moving MNIST (synthetic) and KTH (natural) datasets, showing both PSNR/SSIM and generations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012709921225905418,
                    "sentence": "The authors compare their PredRNN with other baselines, and show the best results on these datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9981911182403564,
                    "sentence": "On Moving MNIST, there is a comparison of different LSTM schemes, and ST-LSTM show the best results, which is a good result.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.997734010219574,
                    "sentence": "However, the experimental section could be stronger by having more datasets (the two datasets presented have little ambiguity in their future, it could be interesting to see how the model preforms in less contained dataset, such as Sports1m, UCF101 or the Google \"Push\" dataset, for instance).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9972700476646423,
                    "sentence": "Although this paper present a complex (and, as it seems, good) structure for the predictor, the loss function is almost never mentioned.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.998527467250824,
                    "sentence": "As (among others) [17] and [19] mention, a simple loss such as the MSE cannot work well when the future distribution is multimodal.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9983596801757812,
                    "sentence": "The paper would also be stronger if compared with other methods (non LSTM-based), such as the ones presented in section 1.2.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9990049004554749,
                    "sentence": "In particular, VPNs and GANs seem like strong competitors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9989805221557617,
                    "sentence": "Notes:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9979209303855896,
                    "sentence": "- Figure 1: Although the figure is clear, I do not quite understand what the orange arrows mean (compared to the black arrows).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9985816478729248,
                    "sentence": "- Figure 2(right): As I understand it, each W box should also have an Xt input (not just W1)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.07332528267997859
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.39821528165086445,
            "class_probabilities": {
                "human": 0.6017847183491355,
                "ai": 0.39821528165086445,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.6017847183491355,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.39821528165086445,
                    "human": 0.6017847183491355,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper deals with predictive learning (mainly video prediction), using a RNN type of structure. A new (to my knowledge) variation of LSTM is introduced, called ST-LSTM, with recurrent connections not only in the forward time direction.\nThe predictive network is composed of ST-LSTM blocks. Each of these block resemble a convolutional LSTM unit, with some differences to include an additional input. This extra input comes from the last layer of the previous time step, and enters at the first layer of the current time step, it is then propagated through the layers at the current time step.\nThe resulting ST-LSTM is similar to the combination of two independent LSTM units, interacting through concatenation of the memories (figure 2(left)).\nI couldn't find an explicit formulation of the loss (the closest I could find is equation 1). I am assuming that it is a MSE loss, but this should be confirmed, since other forms are possible.\nResults are presented on the Moving MNIST (synthetic) and KTH (natural) datasets, showing both PSNR/SSIM and generations. The authors compare their PredRNN with other baselines, and show the best results on these datasets. On Moving MNIST, there is a comparison of different LSTM schemes, and ST-LSTM show the best results, which is a good result.\nHowever, the experimental section could be stronger by having more datasets (the two datasets presented have little ambiguity in their future, it could be interesting to see how the model preforms in less contained dataset, such as Sports1m, UCF101 or the Google \"Push\" dataset, for instance). Although this paper present a complex (and, as it seems, good) structure for the predictor, the loss function is almost never mentioned. As (among others) [17] and [19] mention, a simple loss such as the MSE cannot work well when the future distribution is multimodal. The paper would also be stronger if compared with other methods (non LSTM-based), such as the ones presented in section 1.2. In particular, VPNs and GANs seem like strong competitors.\nNotes:\n- Figure 1: Although the figure is clear, I do not quite understand what the orange arrows mean (compared to the black arrows).\n- Figure 2(right): As I understand it, each W box should also have an Xt input (not just W1)"
        }
    ]
}