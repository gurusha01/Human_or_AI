{
    "version": "2025-01-09-base",
    "scanId": "27b4da8f-2fb6-419f-8016-ea97cfa92d6b",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.6716468334197998,
                    "sentence": "%%% UPDATE: Thank you for your response, which has been read %%%",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8708100318908691,
                    "sentence": "This paper addresses an interesting topic - how to encode symmetries or invariances into kernels.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8450713753700256,
                    "sentence": "The principal application area is in Bayesian nonparametric regression, where constraints may be presented as prior information but the form of the regression function is not fully specified.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.792340099811554,
                    "sentence": "An important example of such a constraint is when the field being modelled is known to be of the divergence kind, so that a certain physical quantity is conserved.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8900792002677917,
                    "sentence": "Related work in this area has included both ANOVA kernels and Stein's method-based kernel, which are each constrained to have vanishing integrals.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8848605751991272,
                    "sentence": "The present work differs, in that it attempts to consider more general forms of constraint.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9091968536376953,
                    "sentence": "This effort is commendable, as generic kernels continue to be widely used in machine learning applications without strong physical justification.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8521217107772827,
                    "sentence": "I think the proposed method is not general and there is no theory to suggest that it will work in anything other than some special cases, but nevertheless it is interesting and could reasonably be in the proceedings for NIPS.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.842400312423706,
                    "sentence": "- The authors ought to discuss their work in relation to \"Learning with Algebraic Invariances, and the Invariant Kernel Trick\" by Franz J. KirÃ¡ly, Andreas Ziehe, Klaus-Robert MÃ¼ller.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009409270714968443,
                    "sentence": "- On page 4 it is incorrectly claimed that the prior for f will \"inherit\" the properties of the prior for g. This is of course not true - if g has a prior GP(0,k) where k generates a Sobolev space of order b and if \\mathcal{F} is a differential operator of order c, then the prior on g will be something like a Sobolev space of order b - c. So the smoothness properties of f and g differ.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010740774450823665,
                    "sentence": "- On page 5, it reads as though the equation \"fi = \\Phii \\xi f\" is without loss of generality, but it is of course an ansatz.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0011836467310786247,
                    "sentence": "This could be better emphasised by clearly labelling this (and the equation \"g = \\Gamma \\xi^g\") as an ansatz.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001181483268737793,
                    "sentence": "- The limited generality of the method could be better acknowledged.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0012687509879469872,
                    "sentence": "Perhaps an example where the method fails could be included.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.7145451996534505
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                }
            ],
            "completely_generated_prob": 0.3086534012031467,
            "class_probabilities": {
                "human": 0.6913465987968532,
                "ai": 0.3086534012031467,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.6913465987968532,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.3086534012031467,
                    "human": 0.6913465987968532,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "%%% UPDATE: Thank you for your response, which has been read %%%\nThis paper addresses an interesting topic - how to encode symmetries or invariances into kernels. The principal application area is in Bayesian nonparametric regression, where constraints may be presented as prior information but the form of the regression function is not fully specified. An important example of such a constraint is when the field being modelled is known to be of the divergence kind, so that a certain physical quantity is conserved. Related work in this area has included both ANOVA kernels and Stein's method-based kernel, which are each constrained to have vanishing integrals. The present work differs, in that it attempts to consider more general forms of constraint. This effort is commendable, as generic kernels continue to be widely used in machine learning applications without strong physical justification.\nI think the proposed method is not general and there is no theory to suggest that it will work in anything other than some special cases, but nevertheless it is interesting and could reasonably be in the proceedings for NIPS.\n- The authors ought to discuss their work in relation to \"Learning with Algebraic Invariances, and the Invariant Kernel Trick\" by Franz J. KirÃ¡ly, Andreas Ziehe, Klaus-Robert MÃ¼ller.\n- On page 4 it is incorrectly claimed that the prior for f will \"inherit\" the properties of the prior for g. This is of course not true - if g has a prior GP(0,k) where k generates a Sobolev space of order b and if \\mathcal{F} is a differential operator of order c, then the prior on g will be something like a Sobolev space of order b - c. So the smoothness properties of f and g differ.\n- On page 5, it reads as though the equation \"fi = \\Phii \\xi f\" is without loss of generality, but it is of course an ansatz. This could be better emphasised by clearly labelling this (and the equation \"g = \\Gamma \\xi^g\") as an ansatz.\n- The limited generality of the method could be better acknowledged. Perhaps an example where the method fails could be included."
        }
    ]
}