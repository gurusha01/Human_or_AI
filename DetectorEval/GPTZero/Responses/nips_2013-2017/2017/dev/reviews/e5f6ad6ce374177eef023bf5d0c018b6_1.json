{
    "version": "2025-01-09-base",
    "scanId": "08d69bf1-0921-4a99-bfb2-1a3593bed471",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.005976105108857155,
                    "sentence": "The work introduces a new architecture for conditional video generation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00864899531006813,
                    "sentence": "It is is based heavily on convolutional LSTMs, with the insight that the prior architecture where each layer of hierarchy represents increasingly abstract properties of the scene may be suboptimal for video generation (unlike classification, a generative model needs, even at the output layer, to retain information about the precise position of objects in the scene).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007946256548166275,
                    "sentence": "The model introduced here, PredRNN extends convolutional LSTMs to contain two memory cells, one which flows through time at the same layer (like the original ConvLSTM), and one which flows up through the layers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010720831342041492,
                    "sentence": "The authors test the model on two datasets: moving MNIST digits and KTH action recognition dataset and demonstrate superior MSE in video prediction to prior work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008997554890811443,
                    "sentence": "The paper is fairly well-written and cites prior work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013351242989301682,
                    "sentence": "The architecture is novel and interesting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010550995357334614,
                    "sentence": "I think the comparison with prior work could be strengthened which would make it easier to understand the empirical strength of these results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01967356540262699,
                    "sentence": "For example, the Kalchbrenner, 2016 claims to reach near the lower-bound the MNIST digit task, but is not included as a baseline.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027769660577178,
                    "sentence": "Prior work on MNIST (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.26396939158439636,
                    "sentence": "(Kalchbrenner, 2016) and the original introduction of the dataset, (Srivastava, 2016) report the cross-entropy loss.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15162502229213715,
                    "sentence": "Here, the authors focus on the maximum likelihood output, but it would be helpful for comparison with prior work to also report the likelihood.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14601562917232513,
                    "sentence": "Additionally, the computational complexity is mentioned as an advantage of this model, but no detailed analysis or comparison is performed so its hard to know how this compares computational complexity with prior work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2933363616466522,
                    "sentence": "Minor notational suggestion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15634685754776,
                    "sentence": "It might be easier for the reader to follow if you use M instead of C for the cell state in equation 3 so that the connection with equation 4 is clearer.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0746086910367012,
                    "sentence": "[I've read the author's response.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05127529799938202,
                    "sentence": "I think this paper is stronger for comparison with prior work (which I assume they'll include in the final version) so I have raised my evaluation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08362945914268494,
                    "sentence": "I'm still unclear if they are training with MSE and other approaches are using different losses, doesn't that provide an advantage to this model when evaluating using MSE?]",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.00010005932717626924
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 6,
                    "completely_generated_prob": 1.474742012248794e-05
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                }
            ],
            "completely_generated_prob": 0.07586545004865985,
            "class_probabilities": {
                "human": 0.9231467185704982,
                "ai": 0.07586545004865985,
                "mixed": 0.0009878313808419248
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9231467185704982,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.07586545004865985,
                    "human": 0.9231467185704982,
                    "mixed": 0.0009878313808419248
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The work introduces a new architecture for conditional video generation. It is is based heavily on convolutional LSTMs, with the insight that the prior architecture where each layer of hierarchy represents increasingly abstract properties of the scene may be suboptimal for video generation (unlike classification, a generative model needs, even at the output layer, to retain information about the precise position of objects in the scene). The model introduced here, PredRNN extends convolutional LSTMs to contain two memory cells, one which flows through time at the same layer (like the original ConvLSTM), and one which flows up through the layers. The authors test the model on two datasets: moving MNIST digits and KTH action recognition dataset and demonstrate superior MSE in video prediction to prior work. The paper is fairly well-written and cites prior work.\nThe architecture is novel and interesting. I think the comparison with prior work could be strengthened which would make it easier to understand the empirical strength of these results. For example, the Kalchbrenner, 2016 claims to reach near the lower-bound the MNIST digit task, but is not included as a baseline. Prior work on MNIST (e.g. (Kalchbrenner, 2016) and the original introduction of the dataset, (Srivastava, 2016) report the cross-entropy loss. Here, the authors focus on the maximum likelihood output, but it would be helpful for comparison with prior work to also report the likelihood.\nAdditionally, the computational complexity is mentioned as an advantage of this model, but no detailed analysis or comparison is performed so its hard to know how this compares computational complexity with prior work.\nMinor notational suggestion:\nIt might be easier for the reader to follow if you use M instead of C for the cell state in equation 3 so that the connection with equation 4 is clearer.\n[I've read the author's response. I think this paper is stronger for comparison with prior work (which I assume they'll include in the final version) so I have raised my evaluation. I'm still unclear if they are training with MSE and other approaches are using different losses, doesn't that provide an advantage to this model when evaluating using MSE?]"
        }
    ]
}