{
    "version": "2025-01-09-base",
    "scanId": "56a2d53d-8336-44d7-a8a7-e41112d0754d",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.8871122598648071,
                    "sentence": "The authors present a novel method for inference in Gaussian processes subject to linear equality constraints.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7823492288589478,
                    "sentence": "In contrast to previous approaches, which used techniques such as data augmentation with artificial observations, the proposed method incorporates the linear constraints directly into the GP kernel such that all draws from the GP satisfy the constraints.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6059666275978088,
                    "sentence": "This is an elegant solution for linearly constrained GP regression problems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3295096755027771,
                    "sentence": "The principal drawback of this approach appears to be the non-trivial task of finding an operator Gx that spans the nullspace of Fx.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.22964289784431458,
                    "sentence": "Algorithm 1 suggests an iterative approach to constructing such an operator, but little guidance is given for the crucial step of selecting a set of scalar operators (\\xig).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11454114317893982,
                    "sentence": "For the running example, the differential operators are natural guesses given the form of Fx, but how might this be done more generally?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10622351616621017,
                    "sentence": "Moreover, is it guaranteed that such an operator exists?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06965278089046478,
                    "sentence": "Minor comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10669972002506256,
                    "sentence": "- Section 3.1 seems out of place.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07333241403102875,
                    "sentence": "It would naturally fall under \"Related Work,\" but that is currently deferred to the end.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04822813346982002,
                    "sentence": "Personally, I think Related Work should come before Section 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2690858244895935,
                    "sentence": "- The discussion of \"interpreting Fx and Gx as matrices\" and \"thinking of F_x[f] as matrix-vector multiplications\" is a bit informal and could be made more rigorous.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06075936555862427,
                    "sentence": "As written, the reader is left wondering if/when this is warranted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.07332528267997859
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                }
            ],
            "completely_generated_prob": 0.42460510328068046,
            "class_probabilities": {
                "human": 0.5710206561360874,
                "ai": 0.42460510328068046,
                "mixed": 0.004374240583232077
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.5710206561360874,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.42460510328068046,
                    "human": 0.5710206561360874,
                    "mixed": 0.004374240583232077
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The authors present a novel method for inference in Gaussian processes subject to linear equality constraints. In contrast to previous approaches, which used techniques such as data augmentation with artificial observations, the proposed method incorporates the linear constraints directly into the GP kernel such that all draws from the GP satisfy the constraints. This is an elegant solution for linearly constrained GP regression problems. \nThe principal drawback of this approach appears to be the non-trivial task of finding an operator Gx that spans the nullspace of Fx. Algorithm 1 suggests an iterative approach to constructing such an operator, but little guidance is given for the crucial step of selecting a set of scalar operators (\\xig). For the running example, the differential operators are natural guesses given the form of Fx, but how might this be done more generally? Moreover, is it guaranteed that such an operator exists? \nMinor comments:\n- Section 3.1 seems out of place. It would naturally fall under \"Related Work,\" but that is currently deferred to the end. Personally, I think Related Work should come before Section 3.\n- The discussion of \"interpreting Fx and Gx as matrices\" and \"thinking of F_x[f] as matrix-vector multiplications\" is a bit informal and could be made more rigorous. As written, the reader is left wondering if/when this is warranted."
        }
    ]
}