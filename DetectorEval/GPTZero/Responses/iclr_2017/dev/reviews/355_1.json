{
    "version": "2025-01-09-base",
    "scanId": "59146ab3-8567-4e8e-8632-121974077bf3",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.7331335544586182,
                    "sentence": "The paper describes approaches taken to train learning agents for the 3D game Doom.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7245166301727295,
                    "sentence": "The authors propose a number of performance enhancements (curriculum learning, attention (zoomed-in centered) frames, reward shaping, game variables, post-training rules) inspired by domain knowledge.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7567520141601562,
                    "sentence": "The enhancements together lead to a clear win as demonstrated by the competition results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6758054494857788,
                    "sentence": "From Fig 4, the curriculum learning clearly helps with learning over increasingly difficult settings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6479536890983582,
                    "sentence": "A nice result is that there is no overfitting to the harder classes once they have learned (probably because the curriculum is health and speed).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.4175319969654083,
                    "sentence": "The authors conclude from Fig 5 that the adaptive curriculum is better and more stable that pure A3C; however, this is a bit of a stretch given that graph.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5496986508369446,
                    "sentence": "They go on to say that Pure A3C doesn't learn at all in the harder map but then show no result/graph to back this claim.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5915630459785461,
                    "sentence": "Tbl 5 shows a clear benefit of the post-training rules.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5720206499099731,
                    "sentence": "If the goal is to solve problems like these (3D shooters), then this paper makes a significant contribution in that it shows which techniques are practical for solving the problem and ultimately improving performance in these kinds of tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6317002773284912,
                    "sentence": "Still, I am just not excited about this paper, mainly because it relies so heavily of many sources of domain knowledge, it is quite far from the pure reinforcement learning problem.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.509765088558197,
                    "sentence": "The results are relatively unsurprising.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6239162087440491,
                    "sentence": "Maybe they are novel for this problem, though.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6981627941131592,
                    "sentence": "I'm not sure we can realistically draw any conclusions about Figure 6 in the paper's current form.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.679597795009613,
                    "sentence": "I recommend the authors increase the resolution or run some actual metrics to determine the fuzziness/clarity of each row/image: something more concrete than an arrow of already low-resolution images.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6674278974533081,
                    "sentence": "--- Added after rebuttal:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8228891491889954,
                    "sentence": "I still do not see any high-res images for Figure 6 or any link to them, but I trust that the authors will add them if accepted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 6,
                    "completely_generated_prob": 1.474742012248794e-05
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.701879209777099,
            "class_probabilities": {
                "human": 0.29796464407233625,
                "ai": 0.701879209777099,
                "mixed": 0.00015614615056494093
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.701879209777099,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.701879209777099,
                    "human": 0.29796464407233625,
                    "mixed": 0.00015614615056494093
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper describes approaches taken to train learning agents for the 3D game Doom. The authors propose a number of performance enhancements (curriculum learning, attention (zoomed-in centered) frames, reward shaping, game variables, post-training rules) inspired by domain knowledge.\nThe enhancements together lead to a clear win as demonstrated by the competition results. From Fig 4, the curriculum learning clearly helps with learning over increasingly difficult settings. A nice result is that there is no overfitting to the harder classes once they have learned (probably because the curriculum is health and speed). The authors conclude from Fig 5 that the adaptive curriculum is better and more stable that pure A3C; however, this is a bit of a stretch given that graph. They go on to say that Pure A3C doesn't learn at all in the harder map but then show no result/graph to back this claim. Tbl 5 shows a clear benefit of the post-training rules.\nIf the goal is to solve problems like these (3D shooters), then this paper makes a significant contribution in that it shows which techniques are practical for solving the problem and ultimately improving performance in these kinds of tasks. Still, I am just not excited about this paper, mainly because it relies so heavily of many sources of domain knowledge, it is quite far from the pure reinforcement learning problem. The results are relatively unsurprising. Maybe they are novel for this problem, though.\nI'm not sure we can realistically draw any conclusions about Figure 6 in the paper's current form. I recommend the authors increase the resolution or run some actual metrics to determine the fuzziness/clarity of each row/image: something more concrete than an arrow of already low-resolution images.\n--- Added after rebuttal:\nI still do not see any high-res images for Figure 6 or any link to them, but I trust that the authors will add them if accepted."
        }
    ]
}