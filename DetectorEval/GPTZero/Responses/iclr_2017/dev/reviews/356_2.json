{
    "version": "2025-01-09-base",
    "scanId": "8b06a783-1e44-4707-9737-04d77ff3802e",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.27587077021598816,
                    "sentence": "This paper sets out to tackle the program synthesis problem: given a set of input/output pairs discover the program that generated them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.26871544122695923,
                    "sentence": "The authors propose a bipartite model, with one component that is a generative model of tree-structured programs and the other component an input/output pair encoder for conditioning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15362116694450378,
                    "sentence": "They consider applying many variants of this basic model to a FlashFill DSL.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14933855831623077,
                    "sentence": "The experiments explore a practical dataset and achieve fine numbers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17382346093654633,
                    "sentence": "The range of models considered, carefulness of the exposition, and basic experimental setup make this a valuable paper for an important area of research.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1469649374485016,
                    "sentence": "I have a few questions, which I think would strengthen the paper, but think it's worth accepting as is.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.176518514752388,
                    "sentence": "Questions/Comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19510696828365326,
                    "sentence": "- The dataset is a good choice, because it is simple and easy to understand.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14587047696113586,
                    "sentence": "What is the effect of the \"rule based strategy\" for computing well formed input strings?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13666479289531708,
                    "sentence": "- Clarify what \"backtracking search\" is?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18908174335956573,
                    "sentence": "I assume it is the same as trying to generate the latent function?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.297489732503891,
                    "sentence": "- In general describing the accuracy as you increase the sample size could be summarize simply by reporting the log-probability of the latent function.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.20751848816871643,
                    "sentence": "Perhaps it's worth reporting that?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2008616328239441,
                    "sentence": "Not sure if I missed something.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 6,
                    "completely_generated_prob": 1.474742012248794e-05
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                }
            ],
            "completely_generated_prob": 0.1276676162807097,
            "class_probabilities": {
                "human": 0.8722807660846754,
                "ai": 0.1276676162807097,
                "mixed": 5.161763461484218e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.8722807660846754,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.1276676162807097,
                    "human": 0.8722807660846754,
                    "mixed": 5.161763461484218e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper sets out to tackle the program synthesis problem: given a set of input/output pairs discover the program that generated them. The authors propose a bipartite model, with one component that is a generative model of tree-structured programs and the other component an input/output pair encoder for conditioning. They consider applying many variants of this basic model to a FlashFill DSL. The experiments explore a practical dataset and achieve fine numbers. The range of models considered, carefulness of the exposition, and basic experimental setup make this a valuable paper for an important area of research. I have a few questions, which I think would strengthen the paper, but think it's worth accepting as is.\nQuestions/Comments:\n- The dataset is a good choice, because it is simple and easy to understand. What is the effect of the \"rule based strategy\" for computing well formed input strings?\n- Clarify what \"backtracking search\" is? I assume it is the same as trying to generate the latent function? \n- In general describing the accuracy as you increase the sample size could be summarize simply by reporting the log-probability of the latent function. Perhaps it's worth reporting that? Not sure if I missed something."
        }
    ]
}