{
    "version": "2025-01-09-base",
    "scanId": "51f26ecb-ae61-427b-b8d7-bcb49f686c97",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.4271623194217682,
                    "sentence": "\" There have been numerous works \" on learning from raw waveforms and training letter-based CTC networks for speech recognition, however, there are very few works on combining both of them with purely ConvNet as it is done in this paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5261109471321106,
                    "sentence": "It is interesting to see results on a large scale corpus such as Librispeech that is used in this paper, though some baseline results from hybrid NN/HMM systems should be provided.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5773276686668396,
                    "sentence": "To readers, it is unclear how this system is close to state-of-the-art only from Table 2.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4945143163204193,
                    "sentence": "The key contribution of this paper may be the end-to-end sequence training criterion for their CTC variant (where the blank symbol is dropped), which may be viewed as sequence training of CTC as H. Sak, et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4946327209472656,
                    "sentence": "\"Learning acoustic frame labeling for speech recognition with recurrent neural networks\", 2015.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4955472946166992,
                    "sentence": "However, instead of generating the denominator lattices using a frame-level trained CTC model first, this paper directly compute the sequence-level loss by considering all the competing hypothesis in the normalizer.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3874082565307617,
                    "sentence": "Therefore, the model is trained end-to-end.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3891673982143402,
                    "sentence": "From this perspective, it is closely related to D. Povey's LF-MMI for sequence-training of HMMs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.41201210021972656,
                    "sentence": "As another reviewer has pointed out, references and discussions on that should be provided.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3330874443054199,
                    "sentence": "This approach should be more expensive than frame-level training of CTCs, however, from Table 1, the authors' implementation is much faster.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.35007423162460327,
                    "sentence": "Did the systems there use the same sampling rate?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.30256912112236023,
                    "sentence": "You said at the end of 2.2 that the step size for your model is 20ms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.35701918601989746,
                    "sentence": "Is it also the same for Baidu's CTC system.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3114856779575348,
                    "sentence": "Also, have you tried increasing the step size, e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.37671273946762085,
                    "sentence": "to 30ms or 40ms, as people have found that it may work (equally) better, while significantly cut down the computational cost.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 6,
                    "completely_generated_prob": 1.474742012248794e-05
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 6,
                    "completely_generated_prob": 1.474742012248794e-05
                }
            ],
            "completely_generated_prob": 0.1276676162807097,
            "class_probabilities": {
                "human": 0.8722807660846754,
                "ai": 0.1276676162807097,
                "mixed": 5.161763461484218e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.8722807660846754,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.1276676162807097,
                    "human": 0.8722807660846754,
                    "mixed": 5.161763461484218e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "\" There have been numerous works \" on learning from raw waveforms and training letter-based CTC networks for speech recognition, however, there are very few works on combining both of them with purely ConvNet as it is done in this paper. It is interesting to see results on a large scale corpus such as Librispeech that is used in this paper, though some baseline results from hybrid NN/HMM systems should be provided. To readers, it is unclear how this system is close to state-of-the-art only from Table 2.\nThe key contribution of this paper may be the end-to-end sequence training criterion for their CTC variant (where the blank symbol is dropped), which may be viewed as sequence training of CTC as H. Sak, et al. \"Learning acoustic frame labeling for speech recognition with recurrent neural networks\", 2015. However, instead of generating the denominator lattices using a frame-level trained CTC model first, this paper directly compute the sequence-level loss by considering all the competing hypothesis in the normalizer. Therefore, the model is trained end-to-end. From this perspective, it is closely related to D. Povey's LF-MMI for sequence-training of HMMs. As another reviewer has pointed out, references and discussions on that should be provided. \nThis approach should be more expensive than frame-level training of CTCs, however, from Table 1, the authors' implementation is much faster. Did the systems there use the same sampling rate? You said at the end of 2.2 that the step size for your model is 20ms. Is it also the same for Baidu's CTC system. Also, have you tried increasing the step size, e.g. to 30ms or 40ms, as people have found that it may work (equally) better, while significantly cut down the computational cost."
        }
    ]
}