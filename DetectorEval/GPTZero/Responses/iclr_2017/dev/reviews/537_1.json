{
    "version": "2025-01-09-base",
    "scanId": "eef7d7a8-4b0f-4240-a399-098dc4b9aa44",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0019825524650514126,
                    "sentence": "This paper addresses the problem of decoding barcode-like markers depicted in an image.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0014384289970621467,
                    "sentence": "The main insight is to train a CNN from generated data produced from a GAN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0014477132353931665,
                    "sentence": "The GAN is trained using unlabeled images, and leverages a \"3D model\" that undergoes learnt image transformations (e.g., blur, lighting, background).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0019358252175152302,
                    "sentence": "The parameters for the image transformations are trained such that it confuses a GAN discriminator.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0020961551927030087,
                    "sentence": "A CNN is trained using images generated from the GAN and compared with hand-crafted features and from training with real images.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0018081681337207556,
                    "sentence": "The proposed method out-performs both baselines on decoding the barcode markers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0026582195423543453,
                    "sentence": "The proposed GAN architecture could potentially be interesting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002209792612120509,
                    "sentence": "However, I won't champion the paper as the evaluation could be improved.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0025272415950894356,
                    "sentence": "A critical missing baseline is a comparison against a generic GAN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0014435105258598924,
                    "sentence": "Without this it's hard to judge the benefit of the more structured GAN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0029703567270189524,
                    "sentence": "Also, it would be worth seeing the result when one combines generated and real images for the final task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004507375881075859,
                    "sentence": "A couple of references that are relevant to this work (for object detection using rendered views of 3D shapes):",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1423129439353943,
                    "sentence": "[A] Xingchao Peng, Baochen Sun, Karim Ali, Kate Saenko, Learning Deep Object Detectors from 3D Models; ICCV, 2015.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19852788746356964,
                    "sentence": "[B] Deep Exemplar 2D-3D Detection by Adapting from Real to Rendered Views.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18869571387767792,
                    "sentence": "Francisco Massa, Bryan C. Russell, Mathieu Aubry.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18504244089126587,
                    "sentence": "CVPR 2016.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1486537903547287,
                    "sentence": "The problem domain (decoding barcode markers on bees) is limited.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1215057373046875,
                    "sentence": "It would be great to see this applied to another problem domain, e.g., object detection from 3D models as shown in paper reference [A], where direct comparison against prior work could be performed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13498392701148987,
                    "sentence": "I found the writing to be somewhat vague throughout.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13276436924934387,
                    "sentence": "For instance, on first reading of the introduction it is not clear what exactly is the contribution of the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.27114784717559814,
                    "sentence": "Minor comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11810436099767685,
                    "sentence": "Fig 3 - Are these really renders from a 3D model?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18715570867061615,
                    "sentence": "The images look like 2D images, perhaps spatially warped via a homography.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16066884994506836,
                    "sentence": "Page 3: \"chapter\" => \"section\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2080920785665512,
                    "sentence": "In Table 2, what is the loss used for the DCNN?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2131473422050476,
                    "sentence": "Fig 9 (a) - The last four images look like they have strange artifacts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1408454030752182,
                    "sentence": "Can you explain these?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 6,
                    "completely_generated_prob": 1.474742012248794e-05
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                }
            ],
            "completely_generated_prob": 0.05924693143200553,
            "class_probabilities": {
                "human": 0.9404634541111649,
                "ai": 0.05924693143200553,
                "mixed": 0.0002896144568295141
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9404634541111649,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.05924693143200553,
                    "human": 0.9404634541111649,
                    "mixed": 0.0002896144568295141
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper addresses the problem of decoding barcode-like markers depicted in an image. The main insight is to train a CNN from generated data produced from a GAN. The GAN is trained using unlabeled images, and leverages a \"3D model\" that undergoes learnt image transformations (e.g., blur, lighting, background). The parameters for the image transformations are trained such that it confuses a GAN discriminator. A CNN is trained using images generated from the GAN and compared with hand-crafted features and from training with real images. The proposed method out-performs both baselines on decoding the barcode markers.\nThe proposed GAN architecture could potentially be interesting. However, I won't champion the paper as the evaluation could be improved.\nA critical missing baseline is a comparison against a generic GAN. Without this it's hard to judge the benefit of the more structured GAN. Also, it would be worth seeing the result when one combines generated and real images for the final task. \nA couple of references that are relevant to this work (for object detection using rendered views of 3D shapes):\n[A] Xingchao Peng, Baochen Sun, Karim Ali, Kate Saenko, Learning Deep Object Detectors from 3D Models; ICCV, 2015.\n[B] Deep Exemplar 2D-3D Detection by Adapting from Real to Rendered Views. Francisco Massa, Bryan C. Russell, Mathieu Aubry. CVPR 2016.\nThe problem domain (decoding barcode markers on bees) is limited. It would be great to see this applied to another problem domain, e.g., object detection from 3D models as shown in paper reference [A], where direct comparison against prior work could be performed. \nI found the writing to be somewhat vague throughout. For instance, on first reading of the introduction it is not clear what exactly is the contribution of the paper. \nMinor comments:\nFig 3 - Are these really renders from a 3D model? The images look like 2D images, perhaps spatially warped via a homography. \nPage 3: \"chapter\" => \"section\".\nIn Table 2, what is the loss used for the DCNN?\nFig 9 (a) - The last four images look like they have strange artifacts. Can you explain these?"
        }
    ]
}