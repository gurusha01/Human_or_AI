{
    "version": "2025-01-09-base",
    "scanId": "4c9193e5-837f-490c-8e21-8474c72dbd3f",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0045355516485869884,
                    "sentence": "Update: After reading the rebuttal comments and the revised paper, I'm leaving the rating as it was before.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005049337167292833,
                    "sentence": "This paper proposes an unsupervised algorithm for transferring samples from one domain to another (related) domain under the constraint that some predefined f returns same result for the input and the result.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006203401833772659,
                    "sentence": "Pros:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003958206158131361,
                    "sentence": "1. The paper presents an interesting idea of comparing samples from different domains using a fixed perceptual function f.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004887444898486137,
                    "sentence": "2. The proposed method produces visually appealing results on several datasets",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00379169057123363,
                    "sentence": "3. The authors demonstrate how their approach can be used for domain adaptation and obtain improved results on the SVHN->MNIST task",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00419453764334321,
                    "sentence": "4. The paper is well-written and easy to read",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012580844573676586,
                    "sentence": "Cons:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002790977479889989,
                    "sentence": "1. The novelty of the method is relatively minor (I consider f-constancy term as the main contribution)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003203322645276785,
                    "sentence": "2. It feels like the proposed approach would break for more dissimilar domains.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002917835721746087,
                    "sentence": "The method relies on a fixed f which is trained on the source domain.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004641643725335598,
                    "sentence": "This f can potentially drop information important for obtaining 1) better reconstructions in the target domain 2) more tightly related x and g(f(x)).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004628829658031464,
                    "sentence": "I think the authors should consider either training all the modules in the model end-to-end or incorporating target samples into the training of f.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004799877293407917,
                    "sentence": "3. A single domain adaptation experiment is definitely not enough to consider the proposed method as a universal alternative to the existing DA approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005219241138547659,
                    "sentence": "I would also like to point out that using super-resolved outputs as opposed to the actual model's outputs can produce a false impression of the visual quality of the transferred samples.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008339042775332928,
                    "sentence": "I'd suggest moving original outputs from the appendix into the main part.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                }
            ],
            "completely_generated_prob": 0.024462635563563526,
            "class_probabilities": {
                "human": 0.9755373644364365,
                "ai": 0.024462635563563526,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9755373644364365,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.024462635563563526,
                    "human": 0.9755373644364365,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Update: After reading the rebuttal comments and the revised paper, I'm leaving the rating as it was before.\nThis paper proposes an unsupervised algorithm for transferring samples from one domain to another (related) domain under the constraint that some predefined f returns same result for the input and the result.\nPros:\n1. The paper presents an interesting idea of comparing samples from different domains using a fixed perceptual function f.\n2. The proposed method produces visually appealing results on several datasets\n3. The authors demonstrate how their approach can be used for domain adaptation and obtain improved results on the SVHN->MNIST task\n4. The paper is well-written and easy to read\nCons:\n1. The novelty of the method is relatively minor (I consider f-constancy term as the main contribution)\n2. It feels like the proposed approach would break for more dissimilar domains. The method relies on a fixed f which is trained on the source domain. This f can potentially drop information important for obtaining 1) better reconstructions in the target domain 2) more tightly related x and g(f(x)). I think the authors should consider either training all the modules in the model end-to-end or incorporating target samples into the training of f.\n3. A single domain adaptation experiment is definitely not enough to consider the proposed method as a universal alternative to the existing DA approaches.\nI would also like to point out that using super-resolved outputs as opposed to the actual model's outputs can produce a false impression of the visual quality of the transferred samples. I'd suggest moving original outputs from the appendix into the main part."
        }
    ]
}