{
    "version": "2025-01-09-base",
    "scanId": "df3632e5-a854-4ccf-92bb-6f0f98cdc437",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.3132645785808563,
                    "sentence": "Altogether a very good paper, a nice read, and interesting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5698239207267761,
                    "sentence": "The work advances the state of the art on differentially-private deep learning, is quite well-written, and relatively thorough.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3816550374031067,
                    "sentence": "One caveat is that although the approach is intended to be general, no theoretical guarantees are provided about the learning performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5384806394577026,
                    "sentence": "Privacy-preserving machine learning papers often analyze both the privacy (in the worst case, DP setting) and the learning performance (often under different assumptions).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5292511582374573,
                    "sentence": "Since the learning performance might depend on the choice of architecture; future experimentation is encouraged, even using the same data sets, with different architectures.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.545423150062561,
                    "sentence": "If this will not be added, then please justify the choice of architecture used, and/or clarify what can be generalized about the observed learning performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.44840627908706665,
                    "sentence": "Another caveat is that the reported epsilons are not those that can be privately released; the authors note that their technique for doing so would change the resulting epsilon.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2986034154891968,
                    "sentence": "However this would need to be resolved in order to have a meaningful comparison to the epsilon-delta values reported in related work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.42133453488349915,
                    "sentence": "Finally, as has been acknowledged in the paper, the present approach may not work on other natural data types.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2260552942752838,
                    "sentence": "Experiments on other data sets is strongly encouraged.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.37799376249313354,
                    "sentence": "Also, please cite the data sets used.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.34086281061172485,
                    "sentence": "Other comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.35737723112106323,
                    "sentence": "Discussion of certain parts of the related work are thorough.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.43258193135261536,
                    "sentence": "However, please add some survey/discussion of the related work on differentially-private semi-supervised learning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5365327596664429,
                    "sentence": "For example, in the context of random forests, the following paper also proposed differentially-private semi-supervised learning via a teacher-learner approach (although not denoted as \"teacher-learner\").",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6866616010665894,
                    "sentence": "The only time the private labeled data is used is when learning the \"primary ensemble.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9924757480621338,
                    "sentence": "A \"secondary ensemble\" is then learned only from the unlabeled (non-private) data, with pseudo-labels generated by the primary ensemble.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9845728278160095,
                    "sentence": "G. Jagannathan, C. Monteleoni, and K. Pillaipakkamnatt: A Semi-Supervised Learning Approach to Differential Privacy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9390993118286133,
                    "sentence": "Proc.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.989503800868988,
                    "sentence": "2013 IEEE International Conference on Data Mining Workshops, IEEE Workshop on Privacy Aspects of Data Mining (PADM), 2013.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.984082818031311,
                    "sentence": "Section C. does a nice comparison of approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9893364906311035,
                    "sentence": "Please make sure the quantitative results here constitute an apples-to-apples comparison with the GAN results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9805713891983032,
                    "sentence": "The paper is extremely well-written, for the most part.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9687409400939941,
                    "sentence": "Some places needing clarification include:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9612051248550415,
                    "sentence": "- Last paragraph of 3.1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9836595058441162,
                    "sentence": "\"all teachers\"¦.get the same training data\"¦.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9802854657173157,
                    "sentence": "This should be rephrased to make it clear that it is not the same w.r.t.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9792616367340088,
                    "sentence": "all the teachers, but w.r.t.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9676941633224487,
                    "sentence": "the same teacher on the neighboring database.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9741421937942505,
                    "sentence": "- 4.1: The authors state: \"The number n of teachers is limited by a trade-off between the classification task's complexity and the available data.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9796186089515686,
                    "sentence": "However, since this tradeoff is not formalized, the statement is imprecise.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9842059016227722,
                    "sentence": "In particular, if the analysis is done in the i.i.d.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9742978811264038,
                    "sentence": "setting, the tradeoff would also likely depend on the relation of the target hypothesis to the data distribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9806651473045349,
                    "sentence": "- Discussion of figure 3 was rather unclear in the text and caption and should be revised for clarity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9941797256469727,
                    "sentence": "In the text section, at first the explanation seems to imply that a larger gap is better (as is also indicated in the caption).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9969657063484192,
                    "sentence": "However later it is stated that the gap stays under 20%.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9970871210098267,
                    "sentence": "These sentences seem contradictory, which is likely not what was intended.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.0022792978668507114
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                }
            ],
            "completely_generated_prob": 0.49770307481643766,
            "class_probabilities": {
                "human": 0.5021818426438073,
                "ai": 0.49770307481643766,
                "mixed": 0.00011508253975490195
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.5021818426438073,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.49770307481643766,
                    "human": 0.5021818426438073,
                    "mixed": 0.00011508253975490195
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Altogether a very good paper, a nice read, and interesting. The work advances the state of the art on differentially-private deep learning, is quite well-written, and relatively thorough.\nOne caveat is that although the approach is intended to be general, no theoretical guarantees are provided about the learning performance. Privacy-preserving machine learning papers often analyze both the privacy (in the worst case, DP setting) and the learning performance (often under different assumptions). Since the learning performance might depend on the choice of architecture; future experimentation is encouraged, even using the same data sets, with different architectures. If this will not be added, then please justify the choice of architecture used, and/or clarify what can be generalized about the observed learning performance.\nAnother caveat is that the reported epsilons are not those that can be privately released; the authors note that their technique for doing so would change the resulting epsilon. However this would need to be resolved in order to have a meaningful comparison to the epsilon-delta values reported in related work.\nFinally, as has been acknowledged in the paper, the present approach may not work on other natural data types. Experiments on other data sets is strongly encouraged. Also, please cite the data sets used.\nOther comments:\nDiscussion of certain parts of the related work are thorough. However, please add some survey/discussion of the related work on differentially-private semi-supervised learning. For example, in the context of random forests, the following paper also proposed differentially-private semi-supervised learning via a teacher-learner approach (although not denoted as \"teacher-learner\"). The only time the private labeled data is used is when learning the \"primary ensemble.\" A \"secondary ensemble\" is then learned only from the unlabeled (non-private) data, with pseudo-labels generated by the primary ensemble.\nG. Jagannathan, C. Monteleoni, and K. Pillaipakkamnatt: A Semi-Supervised Learning Approach to Differential Privacy. Proc. 2013 IEEE International Conference on Data Mining Workshops, IEEE Workshop on Privacy Aspects of Data Mining (PADM), 2013.\nSection C. does a nice comparison of approaches. Please make sure the quantitative results here constitute an apples-to-apples comparison with the GAN results. \nThe paper is extremely well-written, for the most part. Some places needing clarification include:\n- Last paragraph of 3.1. \"all teachers\"¦.get the same training data\"¦.\" This should be rephrased to make it clear that it is not the same w.r.t. all the teachers, but w.r.t. the same teacher on the neighboring database.\n- 4.1: The authors state: \"The number n of teachers is limited by a trade-off between the classification task's complexity and the available data.\" However, since this tradeoff is not formalized, the statement is imprecise. In particular, if the analysis is done in the i.i.d. setting, the tradeoff would also likely depend on the relation of the target hypothesis to the data distribution.\n- Discussion of figure 3 was rather unclear in the text and caption and should be revised for clarity. In the text section, at first the explanation seems to imply that a larger gap is better (as is also indicated in the caption). However later it is stated that the gap stays under 20%. These sentences seem contradictory, which is likely not what was intended."
        }
    ]
}