{
    "version": "2025-01-09-base",
    "scanId": "8a06ee53-e252-410c-83ba-a65e10d90d74",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.2932291030883789,
                    "sentence": "Update: thank you for running more experiments, and add more explanations in the manuscript.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.29625561833381653,
                    "sentence": "They addressed most of my concerns, so I updated the score accordingly.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3202485144138336,
                    "sentence": "The work aims at learning a generative function G that can maps input from source domain to the target domain, such that a given representation function f remain unchanged accepting inputs from either domain.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3944532573223114,
                    "sentence": "The criteria is termed f-constancy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.30710551142692566,
                    "sentence": "The proposed method is evaluated on two visual domain adaptation tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.37227681279182434,
                    "sentence": "The paper is relatively easy to follow, and the authors provided quite extensive experimental results on the two datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.40340444445610046,
                    "sentence": "f-constancy is the main novelty of the work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.28758877515792847,
                    "sentence": "It seems counter-intuitive to force the function G to be of g o f, i.e., starting from a restricted function f which might have already lost information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.34714171290397644,
                    "sentence": "As in the face dataset, f is learned to optimize the performance of certain task on some external dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2855421006679535,
                    "sentence": "It is not clear if an input from the source or target domain can be recovered from applying G as in equation (5) and (6).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3135223388671875,
                    "sentence": "Also, the f function is learned with a particular task in mind.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3013690710067749,
                    "sentence": "As in the two experiments, the representation function f is learned to identify the digits in the source SVHN dataset or the identity of some face dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2648823857307434,
                    "sentence": "As a result, the procedure has to be repeated if we were to perform domain adaptation for the same domains but for different tasks, such as recognizing expressions instead of identity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21528229117393494,
                    "sentence": "Do the authors have insight on why the baseline method proposed in equation (1) and (2) perform so poorly?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.328097939491272,
                    "sentence": "Figure 5 shows some visual comparison between style transfer and the proposed method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2505348324775696,
                    "sentence": "It is not clear though which method is better.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2881886661052704,
                    "sentence": "Will it be possible to apply style transfer to generate emojis from photos and repeat the experiments shown in table 4?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 6,
                    "completely_generated_prob": 1.474742012248794e-05
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                }
            ],
            "completely_generated_prob": 0.1519714707116977,
            "class_probabilities": {
                "human": 0.847975265147624,
                "ai": 0.1519714707116977,
                "mixed": 5.326414067820469e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.847975265147624,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.1519714707116977,
                    "human": 0.847975265147624,
                    "mixed": 5.326414067820469e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Update: thank you for running more experiments, and add more explanations in the manuscript. They addressed most of my concerns, so I updated the score accordingly. \nThe work aims at learning a generative function G that can maps input from source domain to the target domain, such that a given representation function f remain unchanged accepting inputs from either domain. The criteria is termed f-constancy. The proposed method is evaluated on two visual domain adaptation tasks. \nThe paper is relatively easy to follow, and the authors provided quite extensive experimental results on the two datasets. f-constancy is the main novelty of the work. \nIt seems counter-intuitive to force the function G to be of g o f, i.e., starting from a restricted function f which might have already lost information. As in the face dataset, f is learned to optimize the performance of certain task on some external dataset. It is not clear if an input from the source or target domain can be recovered from applying G as in equation (5) and (6). Also, the f function is learned with a particular task in mind. As in the two experiments, the representation function f is learned to identify the digits in the source SVHN dataset or the identity of some face dataset. As a result, the procedure has to be repeated if we were to perform domain adaptation for the same domains but for different tasks, such as recognizing expressions instead of identity. \nDo the authors have insight on why the baseline method proposed in equation (1) and (2) perform so poorly?\nFigure 5 shows some visual comparison between style transfer and the proposed method. It is not clear though which method is better. Will it be possible to apply style transfer to generate emojis from photos and repeat the experiments shown in table 4?"
        }
    ]
}