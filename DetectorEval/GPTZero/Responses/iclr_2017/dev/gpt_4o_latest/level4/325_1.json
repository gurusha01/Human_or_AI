{
    "version": "2025-01-09-base",
    "scanId": "ad8b89ce-5957-46f4-86c1-4160cff32b4d",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9834039807319641,
                    "sentence": "This paper presents a generative model that converts noise into model samples through a progressive denoising process.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9809651970863342,
                    "sentence": "The approach shares similarities with diffusion-based generative models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9867508411407471,
                    "sentence": "However, in contrast to the diffusion framework:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9849270582199097,
                    "sentence": "- It employs only a limited number of denoising steps, making it significantly more computationally efficient.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9835342764854431,
                    "sentence": "- Instead of following a reverse trajectory, the conditional chain for the approximate posterior directly transitions to q(z(0) \" x) and then proceeds in the same direction as the generative model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9891036152839661,
                    "sentence": "This design enables the inference chain to act as a perturbation around the generative model, guiding it toward the data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9867628216743469,
                    "sentence": "(This aspect also appears to have some conceptual overlap with ladder networks.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9883559942245483,
                    "sentence": "- There is no tractable variational bound on the log likelihood.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9746898412704468,
                    "sentence": "I found the core idea intriguing and was impressed by the visual sample quality achieved with a short chain.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9816040992736816,
                    "sentence": "The inpainting results stood out, as one-shot inpainting is generally not feasible in most generative modeling frameworks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9631387591362,
                    "sentence": "However, the work would be more compelling with a log likelihood comparison that does not rely on Parzen likelihoods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.985806941986084,
                    "sentence": "Detailed comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9634343385696411,
                    "sentence": "Sec.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9642702341079712,
                    "sentence": "2:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9651527404785156,
                    "sentence": "- \"theta(0) the\" \"theta(0) be the\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9439316987991333,
                    "sentence": "- \"theta(t) the\" \"theta(t) be the\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9494280815124512,
                    "sentence": "- \"what we will be using\" \"which we will be doing\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9632413387298584,
                    "sentence": "I appreciate the approach of inferring q(z^0\"x) and running inference in the same direction as the generative chain.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9653262495994568,
                    "sentence": "This aspect reminds me somewhat of ladder networks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8751509785652161,
                    "sentence": "- \"q.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7568112015724182,
                    "sentence": "Having learned\" \"q.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8069470524787903,
                    "sentence": "[paragraph break] Having learned\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8611941933631897,
                    "sentence": "Sec.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9440679550170898,
                    "sentence": "3.3:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8564954400062561,
                    "sentence": "- \"learn to inverse\" \"learn to reverse\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.919491708278656,
                    "sentence": "Sec.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9765439033508301,
                    "sentence": "4:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.894198477268219,
                    "sentence": "- \"For each experiments\" \"For each experiment\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9757043719291687,
                    "sentence": "How sensitive are the results to the infusion rate?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9071372747421265,
                    "sentence": "Sec.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9617516398429871,
                    "sentence": "5:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9633756279945374,
                    "sentence": "- \"appears to provide more accurate models\" ᅳ I don't believe this was demonstrated, as there is no direct comparison to the Sohl-Dickstein paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9452695846557617,
                    "sentence": "Fig.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9866600632667542,
                    "sentence": "4:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9816814661026001,
                    "sentence": "- Neat!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.45887534985363754
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.8923758534658037,
            "class_probabilities": {
                "human": 0.10626570421472266,
                "ai": 0.8923758534658037,
                "mixed": 0.00135844231947367
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8923758534658037,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8923758534658037,
                    "human": 0.10626570421472266,
                    "mixed": 0.00135844231947367
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a generative model that converts noise into model samples through a progressive denoising process. The approach shares similarities with diffusion-based generative models. However, in contrast to the diffusion framework:\n- It employs only a limited number of denoising steps, making it significantly more computationally efficient.\n- Instead of following a reverse trajectory, the conditional chain for the approximate posterior directly transitions to q(z(0) \" x) and then proceeds in the same direction as the generative model. This design enables the inference chain to act as a perturbation around the generative model, guiding it toward the data. (This aspect also appears to have some conceptual overlap with ladder networks.)\n- There is no tractable variational bound on the log likelihood.\nI found the core idea intriguing and was impressed by the visual sample quality achieved with a short chain. The inpainting results stood out, as one-shot inpainting is generally not feasible in most generative modeling frameworks. However, the work would be more compelling with a log likelihood comparison that does not rely on Parzen likelihoods.\nDetailed comments:\nSec. 2: \n- \"theta(0) the\" \"theta(0) be the\" \n- \"theta(t) the\" \"theta(t) be the\" \n- \"what we will be using\" \"which we will be doing\" \nI appreciate the approach of inferring q(z^0\"x) and running inference in the same direction as the generative chain. This aspect reminds me somewhat of ladder networks. \n- \"q. Having learned\" \"q. [paragraph break] Having learned\" \nSec. 3.3: \n- \"learn to inverse\" \"learn to reverse\" \nSec. 4: \n- \"For each experiments\" \"For each experiment\" \nHow sensitive are the results to the infusion rate? \nSec. 5: \n- \"appears to provide more accurate models\" — I don't believe this was demonstrated, as there is no direct comparison to the Sohl-Dickstein paper. \nFig. 4: \n- Neat!"
        }
    ]
}