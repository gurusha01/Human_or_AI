{
    "version": "2025-01-09-base",
    "scanId": "eaef6b0c-d0ab-4720-9b22-634fb244ab65",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9986297488212585,
                    "sentence": "This study reinterprets paragraph vectors from a generative perspective, which serves to justify the existing method for inferring paragraph vectors and the application of an L2 regularizer on paragraph embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.998849093914032,
                    "sentence": "Additionally, the work advocates for the joint training of a classifier on paragraph vectors to facilitate text classification.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987497329711914,
                    "sentence": "The paper contains several citation inconsistencies, both in in-text references and in the bibliography formatting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990373253822327,
                    "sentence": "For instance, some entries include first names while others do not.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9980509877204895,
                    "sentence": "It is recommended that the authors use a tool such as BibTeX to ensure a more uniform and professional bibliography.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9911496639251709,
                    "sentence": "Furthermore, the work appears to lack significant novelty.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9058361053466797,
                    "sentence": "The authors assert that no method exists for inferring paragraph vectors for unseen documents.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9400084614753723,
                    "sentence": "However, this claim is incorrect.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6736940741539001,
                    "sentence": "The original paragraph vector paper explicitly describes a process where, to infer a new vector, the model parameters are held constant while gradient descent is applied to the new paragraph vector.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.826230525970459,
                    "sentence": "This approach does not require the original dataset for inference.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7758910059928894,
                    "sentence": "The method proposed in this paper essentially mirrors this process by finding the MAP estimate for a new vector.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.856054961681366,
                    "sentence": "Consequently, the primary contribution of the generative framing appears to be the introduction of regularization on the embedding matrix.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.643186628818512,
                    "sentence": "The supervised generative paragraph vector approach involves jointly training a linear classifier on the paragraph vectors, while the inference process for paragraph vectors remains unchanged.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.42493876814842224,
                    "sentence": "Additionally, for the n-gram-based method, the authors should reference Li et al., 2015.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.42078861594200134,
                    "sentence": "In the experimental section, tables 1 and 2 are poorly formatted, with decimal points (e.g.,.0) being truncated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.39813119173049927,
                    "sentence": "The authors also fail to specify the size of the paragraph vectors used.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.384380042552948,
                    "sentence": "Moreover, the results for SGPV are inferior to those reported in the original paragraph vector paper, where SST-1 achieved 48.7 and SST-2 achieved 86.3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.3034868836402893,
                    "sentence": "Reference:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.21000851690769196,
                    "sentence": "Bofang Li, Tao Liu, Xiaoyong Du, Deyuan Zhang, Zhe Zhao, Learning Document Embeddings by Predicting N-grams for Sentiment Classification of Long Movie Reviews, 2015.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.3436238582234724
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.6616541353383459,
            "class_probabilities": {
                "human": 0,
                "ai": 0.6616541353383459,
                "mixed": 0.3383458646616541
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.6616541353383459,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.6616541353383459,
                    "human": 0,
                    "mixed": 0.3383458646616541
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This study reinterprets paragraph vectors from a generative perspective, which serves to justify the existing method for inferring paragraph vectors and the application of an L2 regularizer on paragraph embeddings. Additionally, the work advocates for the joint training of a classifier on paragraph vectors to facilitate text classification.\nThe paper contains several citation inconsistencies, both in in-text references and in the bibliography formatting. For instance, some entries include first names while others do not. It is recommended that the authors use a tool such as BibTeX to ensure a more uniform and professional bibliography. Furthermore, the work appears to lack significant novelty.\nThe authors assert that no method exists for inferring paragraph vectors for unseen documents. However, this claim is incorrect. The original paragraph vector paper explicitly describes a process where, to infer a new vector, the model parameters are held constant while gradient descent is applied to the new paragraph vector. This approach does not require the original dataset for inference. The method proposed in this paper essentially mirrors this process by finding the MAP estimate for a new vector. Consequently, the primary contribution of the generative framing appears to be the introduction of regularization on the embedding matrix.\nThe supervised generative paragraph vector approach involves jointly training a linear classifier on the paragraph vectors, while the inference process for paragraph vectors remains unchanged. Additionally, for the n-gram-based method, the authors should reference Li et al., 2015.\nIn the experimental section, tables 1 and 2 are poorly formatted, with decimal points (e.g., .0) being truncated. The authors also fail to specify the size of the paragraph vectors used. Moreover, the results for SGPV are inferior to those reported in the original paragraph vector paper, where SST-1 achieved 48.7 and SST-2 achieved 86.3.\nReference: \nBofang Li, Tao Liu, Xiaoyong Du, Deyuan Zhang, Zhe Zhao, Learning Document Embeddings by Predicting N-grams for Sentiment Classification of Long Movie Reviews, 2015."
        }
    ]
}