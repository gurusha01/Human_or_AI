{
    "version": "2025-01-09-base",
    "scanId": "da55fa7c-92de-4214-b9f3-f0e92ec2d3af",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9996707439422607,
                    "sentence": "This paper tackles the challenge of decoding barcode-like markers from images.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994797706604004,
                    "sentence": "The core idea is to train a CNN using synthetic data generated by a GAN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991936087608337,
                    "sentence": "The GAN itself is trained on unlabeled images and incorporates a \"3D model\" that undergoes learned image transformations (e.g., blur, lighting, background changes).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987874031066895,
                    "sentence": "The transformation parameters are optimized to confuse the GAN discriminator.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988958835601807,
                    "sentence": "A CNN is then trained on the GAN-generated images and compared against two baselines: one using hand-crafted features and another trained on real images.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999238908290863,
                    "sentence": "The proposed approach achieves better performance than both baselines in decoding barcode markers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989832639694214,
                    "sentence": "The proposed GAN architecture has potential merit.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984230399131775,
                    "sentence": "However, I am hesitant to strongly endorse the paper due to limitations in the evaluation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992544651031494,
                    "sentence": "A key missing baseline is a comparison against a standard GAN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999027669429779,
                    "sentence": "Without this, it is difficult to assess the advantages of the more structured GAN proposed in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9982426762580872,
                    "sentence": "Additionally, it would be valuable to evaluate the performance when combining generated and real images for the final task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999514639377594,
                    "sentence": "Two references relevant to this work, particularly for object detection using rendered views of 3D shapes, are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998288154602051,
                    "sentence": "[A] Xingchao Peng, Baochen Sun, Karim Ali, Kate Saenko, Learning Deep Object Detectors from 3D Models; ICCV, 2015.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998084902763367,
                    "sentence": "[B] Deep Exemplar 2D-3D Detection by Adapting from Real to Rendered Views.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996966123580933,
                    "sentence": "Francisco Massa, Bryan C. Russell, Mathieu Aubry.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9983674883842468,
                    "sentence": "CVPR 2016.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995852112770081,
                    "sentence": "The problem domain (decoding barcode markers on bees) is quite narrow.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993483424186707,
                    "sentence": "It would be interesting to see the method applied to a broader domain, such as object detection from 3D models as explored in reference [A], where direct comparisons to prior work could be made.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992238283157349,
                    "sentence": "The writing is somewhat unclear in places.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988629817962646,
                    "sentence": "For example, the introduction does not clearly articulate the paper's main contributions on an initial read.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.997359573841095,
                    "sentence": "Minor comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995218515396118,
                    "sentence": "- Fig 3: Are these truly renders from a 3D model?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992467761039734,
                    "sentence": "The images appear to be 2D images spatially warped via a homography.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994838237762451,
                    "sentence": "- Page 3: Replace \"chapter\" with \"section.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990806579589844,
                    "sentence": "- Table 2: What loss function is used for the DCNN?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995208978652954,
                    "sentence": "- Fig 9 (a): The last four images exhibit unusual artifacts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9980189204216003,
                    "sentence": "Could you clarify the cause of these?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper tackles the challenge of decoding barcode-like markers from images. The core idea is to train a CNN using synthetic data generated by a GAN. The GAN itself is trained on unlabeled images and incorporates a \"3D model\" that undergoes learned image transformations (e.g., blur, lighting, background changes). The transformation parameters are optimized to confuse the GAN discriminator. A CNN is then trained on the GAN-generated images and compared against two baselines: one using hand-crafted features and another trained on real images. The proposed approach achieves better performance than both baselines in decoding barcode markers.\nThe proposed GAN architecture has potential merit. However, I am hesitant to strongly endorse the paper due to limitations in the evaluation.\nA key missing baseline is a comparison against a standard GAN. Without this, it is difficult to assess the advantages of the more structured GAN proposed in the paper. Additionally, it would be valuable to evaluate the performance when combining generated and real images for the final task.\nTwo references relevant to this work, particularly for object detection using rendered views of 3D shapes, are:\n[A] Xingchao Peng, Baochen Sun, Karim Ali, Kate Saenko, Learning Deep Object Detectors from 3D Models; ICCV, 2015.\n[B] Deep Exemplar 2D-3D Detection by Adapting from Real to Rendered Views. Francisco Massa, Bryan C. Russell, Mathieu Aubry. CVPR 2016.\nThe problem domain (decoding barcode markers on bees) is quite narrow. It would be interesting to see the method applied to a broader domain, such as object detection from 3D models as explored in reference [A], where direct comparisons to prior work could be made.\nThe writing is somewhat unclear in places. For example, the introduction does not clearly articulate the paper's main contributions on an initial read.\nMinor comments:\n- Fig 3: Are these truly renders from a 3D model? The images appear to be 2D images spatially warped via a homography.\n- Page 3: Replace \"chapter\" with \"section.\"\n- Table 2: What loss function is used for the DCNN?\n- Fig 9 (a): The last four images exhibit unusual artifacts. Could you clarify the cause of these?"
        }
    ]
}