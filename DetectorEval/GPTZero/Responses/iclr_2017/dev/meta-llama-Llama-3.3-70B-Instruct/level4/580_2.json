{
    "version": "2025-01-09-base",
    "scanId": "098e5fc1-14ed-4f0b-a6d0-0f0905699fa6",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.25933369994163513,
                    "sentence": "Summary: The authors introduce an input-switched affine network for character-level language modeling, a type of RNN that eschews pointwise nonlinearity in favor of switching the transition matrix and bias based on the input character, thereby facilitating intelligibility through the decomposition of output contributions into kappa_s^t terms and enabling the use of basic linear algebra to probe the network.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15424412488937378,
                    "sentence": "As a reviewer, I have a solid understanding of the paper's main ideas and arguments, although I am not an expert in RNN language models or machine learning intelligibility and interpretability, and my familiarity with related work is limited to deconvnet for vision-CNNs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11079932749271393,
                    "sentence": "The strengths of this paper include its originality and novelty, as well as its high quality, clarity, and evident thoroughness, with section 4.5 being particularly noteworthy for its discussion of projecting into readout subspace versus \"computational\" subspace.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08459124714136124,
                    "sentence": "However, I have some reservations regarding the results, which I find not entirely convincing in two key aspects:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11949780583381653,
                    "sentence": "(1) the ISAN model's performance is only demonstrated on a small task (text8), leaving its potential as a strong character-level language model on larger-scale tasks uncertain,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08523592352867126,
                    "sentence": "(2) the analysis sections, while replete with intriguing plots and ideas, yield limited concrete insights into the learned network, with some analyses, such as those in sections 4.2-4.3, relying on quantities like kappas^t that seem to have questionable meaningfulness, as exemplified by Figure 2, where the influence of the '' character on the logit of 'e' appears obscure.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1471732258796692,
                    "sentence": "Additionally, the ISAN architecture, as proposed, appears suited only for small-vocabulary language modeling, and it is unclear which analysis findings are specific to ISAN and which might generalize to nonlinear RNNs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13521432876586914,
                    "sentence": "Despite these concerns, which outnumber the strengths, I recommend accepting this paper, largely due to its originality, which inherently makes it more susceptible to critiques, as well as its strong motivation, execution, and potential to inspire further investigations in this area.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.11111719830715079,
            "class_probabilities": {
                "human": 0.8879545042967993,
                "ai": 0.11111719830715079,
                "mixed": 0.000928297396049714
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.8879545042967993,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.11111719830715079,
                    "human": 0.8879545042967993,
                    "mixed": 0.000928297396049714
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary: The authors introduce an input-switched affine network for character-level language modeling, a type of RNN that eschews pointwise nonlinearity in favor of switching the transition matrix and bias based on the input character, thereby facilitating intelligibility through the decomposition of output contributions into kappa_s^t terms and enabling the use of basic linear algebra to probe the network.\nAs a reviewer, I have a solid understanding of the paper's main ideas and arguments, although I am not an expert in RNN language models or machine learning intelligibility and interpretability, and my familiarity with related work is limited to deconvnet for vision-CNNs.\nThe strengths of this paper include its originality and novelty, as well as its high quality, clarity, and evident thoroughness, with section 4.5 being particularly noteworthy for its discussion of projecting into readout subspace versus \"computational\" subspace.\nHowever, I have some reservations regarding the results, which I find not entirely convincing in two key aspects: \n(1) the ISAN model's performance is only demonstrated on a small task (text8), leaving its potential as a strong character-level language model on larger-scale tasks uncertain, \n(2) the analysis sections, while replete with intriguing plots and ideas, yield limited concrete insights into the learned network, with some analyses, such as those in sections 4.2-4.3, relying on quantities like kappas^t that seem to have questionable meaningfulness, as exemplified by Figure 2, where the influence of the '' character on the logit of 'e' appears obscure.\nAdditionally, the ISAN architecture, as proposed, appears suited only for small-vocabulary language modeling, and it is unclear which analysis findings are specific to ISAN and which might generalize to nonlinear RNNs.\nDespite these concerns, which outnumber the strengths, I recommend accepting this paper, largely due to its originality, which inherently makes it more susceptible to critiques, as well as its strong motivation, execution, and potential to inspire further investigations in this area."
        }
    ]
}