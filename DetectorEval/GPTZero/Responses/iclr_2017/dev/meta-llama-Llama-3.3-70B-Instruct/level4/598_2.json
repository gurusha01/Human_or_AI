{
    "version": "2025-01-09-base",
    "scanId": "9a975a5a-73cf-4801-9873-48034c065de1",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999512434005737,
                    "sentence": "This paper explores a unique approach by integrating learning from raw waveforms and training letter-based CTC networks using a purely ConvNet architecture, a combination that has been rarely investigated in previous studies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999181628227234,
                    "sentence": "The utilization of a large-scale corpus like Librispeech yields interesting results, although the inclusion of baseline results from hybrid NN/HMM systems would provide a more comprehensive comparison.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999301433563232,
                    "sentence": "The proximity of this system to state-of-the-art performance is not immediately clear from Table 2, leaving readers seeking additional context.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995710253715515,
                    "sentence": "A significant contribution of this work lies in its end-to-end sequence training criterion for the CTC variant, which eliminates the blank symbol.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992976784706116,
                    "sentence": "This approach can be seen as an extension of sequence training for CTC, similar to the work by H. Sak et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985364675521851,
                    "sentence": "in 2015, \"Learning acoustic frame labeling for speech recognition with recurrent neural networks.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988456964492798,
                    "sentence": "However, unlike the aforementioned study, which generates denominator lattices using a frame-level trained CTC model, this paper computes the sequence-level loss directly by considering all competing hypotheses in the normalizer, thereby facilitating end-to-end training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987859725952148,
                    "sentence": "This methodology bears a close resemblance to D. Povey's LF-MMI for sequence-training of HMMs, and as noted by another reviewer, a more detailed discussion and reference to this relationship would be beneficial.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988500475883484,
                    "sentence": "The proposed approach is expected to be more computationally expensive than frame-level CTC training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992901086807251,
                    "sentence": "Nonetheless, the authors' implementation, as shown in Table 1, demonstrates a significant speed advantage.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990633726119995,
                    "sentence": "It is essential to clarify whether the systems compared in Table 1 operated at the same sampling rate.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989665746688843,
                    "sentence": "Furthermore, the step size of 20ms mentioned at the end of Section 2.2 for the authors' model raises questions about its consistency with Baidu's CTC system.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999639630317688,
                    "sentence": "Additionally, exploring the impact of increasing the step size (e.g., to 30ms or 40ms) on performance and computational cost would be worthwhile, as previous studies have indicated potential benefits in this regard.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                }
            ],
            "completely_generated_prob": 0.9984984300152882,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984984300152882,
                "mixed": 0.0015015699847118259
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984984300152882,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984984300152882,
                    "human": 0,
                    "mixed": 0.0015015699847118259
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper explores a unique approach by integrating learning from raw waveforms and training letter-based CTC networks using a purely ConvNet architecture, a combination that has been rarely investigated in previous studies. The utilization of a large-scale corpus like Librispeech yields interesting results, although the inclusion of baseline results from hybrid NN/HMM systems would provide a more comprehensive comparison. The proximity of this system to state-of-the-art performance is not immediately clear from Table 2, leaving readers seeking additional context.\nA significant contribution of this work lies in its end-to-end sequence training criterion for the CTC variant, which eliminates the blank symbol. This approach can be seen as an extension of sequence training for CTC, similar to the work by H. Sak et al. in 2015, \"Learning acoustic frame labeling for speech recognition with recurrent neural networks.\" However, unlike the aforementioned study, which generates denominator lattices using a frame-level trained CTC model, this paper computes the sequence-level loss directly by considering all competing hypotheses in the normalizer, thereby facilitating end-to-end training. This methodology bears a close resemblance to D. Povey's LF-MMI for sequence-training of HMMs, and as noted by another reviewer, a more detailed discussion and reference to this relationship would be beneficial.\nThe proposed approach is expected to be more computationally expensive than frame-level CTC training. Nonetheless, the authors' implementation, as shown in Table 1, demonstrates a significant speed advantage. It is essential to clarify whether the systems compared in Table 1 operated at the same sampling rate. Furthermore, the step size of 20ms mentioned at the end of Section 2.2 for the authors' model raises questions about its consistency with Baidu's CTC system. Additionally, exploring the impact of increasing the step size (e.g., to 30ms or 40ms) on performance and computational cost would be worthwhile, as previous studies have indicated potential benefits in this regard."
        }
    ]
}