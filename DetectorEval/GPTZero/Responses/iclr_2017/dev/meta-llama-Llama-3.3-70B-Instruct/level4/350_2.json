{
    "version": "2025-01-09-base",
    "scanId": "8ec38ef6-677d-4e5a-a923-5621a0dfb6ee",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.99921053647995,
                    "sentence": "This paper explores a thriving area in computer vision and machine learning, where the physical structure and semantics of the world are learned from video without supervision.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999403715133667,
                    "sentence": "The authors examine how predicting future image frames, an inherently unsupervised task, can be leveraged to infer object structure and properties, such as single object pose, category, and steering angle, following a supervised linear readout step.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991781115531921,
                    "sentence": "The paper is engaging, well-written, and presents an innovative network architecture, PredNet, designed for video frame prediction, which yields promising results on both synthetic and real-world images.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992253184318542,
                    "sentence": "The comprehensive experimental evaluation and analysis provided by the authors establish a robust foundation for comparison with future studies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998575448989868,
                    "sentence": "However, there are some limitations to be addressed:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996652007102966,
                    "sentence": "- The connection to predictive coding, used as a motivation for the PredNet model, requires more thorough explanation within the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998599290847778,
                    "sentence": "- The notion that the proposed method learns an implicit model of the objects comprising the scene, although intriguing, remains vague and somewhat speculative.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999895453453064,
                    "sentence": "A minor suggestion is to include, alongside the number of labeled training examples (Fig.5), the amount of unsupervised training data utilized to develop the representations, providing additional insight into the training process.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper explores a thriving area in computer vision and machine learning, where the physical structure and semantics of the world are learned from video without supervision. The authors examine how predicting future image frames, an inherently unsupervised task, can be leveraged to infer object structure and properties, such as single object pose, category, and steering angle, following a supervised linear readout step.\nThe paper is engaging, well-written, and presents an innovative network architecture, PredNet, designed for video frame prediction, which yields promising results on both synthetic and real-world images. The comprehensive experimental evaluation and analysis provided by the authors establish a robust foundation for comparison with future studies.\nHowever, there are some limitations to be addressed:\n- The connection to predictive coding, used as a motivation for the PredNet model, requires more thorough explanation within the paper.\n- The notion that the proposed method learns an implicit model of the objects comprising the scene, although intriguing, remains vague and somewhat speculative.\nA minor suggestion is to include, alongside the number of labeled training examples (Fig.5), the amount of unsupervised training data utilized to develop the representations, providing additional insight into the training process."
        }
    ]
}