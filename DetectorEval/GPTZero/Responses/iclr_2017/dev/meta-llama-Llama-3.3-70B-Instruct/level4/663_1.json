{
    "version": "2025-01-09-base",
    "scanId": "c75f507f-84a4-45da-af09-8d7894130de0",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9715709090232849,
                    "sentence": "This manuscript presents a multi-model product classification system on a large scale, comprising three primary components: an Image CNN utilizing the VGG 16 architecture, a text CNN based on Kim 2014, and decision-level fusion policies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.935906171798706,
                    "sentence": "The authors explore various fusion strategies, including policies that combine inputs from text and image CNN probabilities, select either CNN, average predictions, or employ end-to-end training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8231094479560852,
                    "sentence": "The experimental findings indicate that the text CNN outperforms the image CNN, and multi-model fusion yields a slight improvement in accuracy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9118861556053162,
                    "sentence": "Notably, end-to-end feature-level fusion performs worse than the text CNN alone, which is somewhat unexpected.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8189934492111206,
                    "sentence": "The manuscript is well-written, offering valuable practical insights into training large-scale models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.726241409778595,
                    "sentence": "However, I am inclined to recommend rejection due to the following concerns:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7477686405181885,
                    "sentence": "1. The study lacks reporting on additional datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8193645477294922,
                    "sentence": "Since the authors do not plan to release the Walmart dataset, reproducing the results will be highly challenging without access to this dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7206907272338867,
                    "sentence": "2. The technical contributions of the paper are limited, as all the decision-level fusion policies investigated have been previously explored in other studies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6750286221504211,
                    "sentence": "3. The performance gains achieved are also modest, which further supports the consideration of rejection.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.7145451996534505
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.3063829682933457
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.998496231132286,
            "class_probabilities": {
                "human": 0,
                "ai": 0.998496231132286,
                "mixed": 0.0015037688677139365
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.998496231132286,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.998496231132286,
                    "human": 0,
                    "mixed": 0.0015037688677139365
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This manuscript presents a multi-model product classification system on a large scale, comprising three primary components: an Image CNN utilizing the VGG 16 architecture, a text CNN based on Kim 2014, and decision-level fusion policies. The authors explore various fusion strategies, including policies that combine inputs from text and image CNN probabilities, select either CNN, average predictions, or employ end-to-end training. The experimental findings indicate that the text CNN outperforms the image CNN, and multi-model fusion yields a slight improvement in accuracy. Notably, end-to-end feature-level fusion performs worse than the text CNN alone, which is somewhat unexpected. The manuscript is well-written, offering valuable practical insights into training large-scale models. However, I am inclined to recommend rejection due to the following concerns:\n1. The study lacks reporting on additional datasets. Since the authors do not plan to release the Walmart dataset, reproducing the results will be highly challenging without access to this dataset.\n2. The technical contributions of the paper are limited, as all the decision-level fusion policies investigated have been previously explored in other studies.\n3. The performance gains achieved are also modest, which further supports the consideration of rejection."
        }
    ]
}