{
    "version": "2025-01-09-base",
    "scanId": "a89fff16-686c-4f26-a2f5-7e035699c1a9",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.998486340045929,
                    "sentence": "This paper presents a compelling VAE framework for topic models, primarily focusing on the development of a recognition model to facilitate efficient inference.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990230202674866,
                    "sentence": "By leveraging \"amortized inference,\" this approach significantly accelerates the inference process compared to traditional methods, which require iterative inference for each document.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9841816425323486,
                    "sentence": "Several aspects of the paper warrant discussion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9196307063102722,
                    "sentence": "Equation 5 employs the notation p(theta(h)\"alpha), which could be more intuitively represented as P(h\"alpha).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9758028388023376,
                    "sentence": "The proposed generative model appears to be document-length agnostic, as it solely generates probabilities over the word space using latent variables.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9695836901664734,
                    "sentence": "In contrast, the recognition model exhibits sensitivity to document length, as alterations in document length substantially impact the probabilities q(z\"x) due to changes in the input to q.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9340865612030029,
                    "sentence": "This discrepancy seems undesirable and could potentially be mitigated by normalizing the input to the recognition network.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9585322141647339,
                    "sentence": "Furthermore, it is plausible that the ProdLDA model bears equivalence to a variant of exponential family PCA, warranting further exploration of this potential connection.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9961636828644501,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9961636828644501,
                "mixed": 0.003836317135549872
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9961636828644501,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9961636828644501,
                    "human": 0,
                    "mixed": 0.003836317135549872
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a compelling VAE framework for topic models, primarily focusing on the development of a recognition model to facilitate efficient inference. By leveraging \"amortized inference,\" this approach significantly accelerates the inference process compared to traditional methods, which require iterative inference for each document. Several aspects of the paper warrant discussion:\nEquation 5 employs the notation p(theta(h)\"alpha), which could be more intuitively represented as P(h\"alpha).\nThe proposed generative model appears to be document-length agnostic, as it solely generates probabilities over the word space using latent variables. In contrast, the recognition model exhibits sensitivity to document length, as alterations in document length substantially impact the probabilities q(z\"x) due to changes in the input to q. This discrepancy seems undesirable and could potentially be mitigated by normalizing the input to the recognition network.\nFurthermore, it is plausible that the ProdLDA model bears equivalence to a variant of exponential family PCA, warranting further exploration of this potential connection."
        }
    ]
}