{
    "version": "2025-01-09-base",
    "scanId": "ff19503c-6eb7-47bf-8f47-53d68cc6fd43",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9872276186943054,
                    "sentence": "This paper proposes a novel technique called Neuro-Symbolic Program Synthesis (NSPS) that learns to generate a program incrementally without the need for an explicit search.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9623907804489136,
                    "sentence": "The approach is based on two novel neural modules: the cross correlation I/O network and the Recursive-Reverse-Recursive Neural Network (R3NN).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9095583558082581,
                    "sentence": "The R3NN model encodes partial trees in a Domain-Specific Language (DSL) and assigns probabilities to different non-terminals in a partial derivation and corresponding expansions to guide the search for complete derivations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.889387845993042,
                    "sentence": "The paper tackles the specific question of program induction, which is a fundamental problem in Machine Learning and Artificial Intelligence.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8956540822982788,
                    "sentence": "The approach is well-motivated, as it addresses the limitations of existing neural architectures for program induction, such as being computationally expensive and hard to train, and not being able to learn interpretable programs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8199548721313477,
                    "sentence": "However, I decide to reject this paper due to two key reasons.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7911059260368347,
                    "sentence": "Firstly, the experimental results are unconvincing due to the lack of comparison with other state-of-the-art methods, such as FLANN, and the lack of speed comparison.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7950779795646667,
                    "sentence": "Secondly, the paper's motivation to eliminate heuristics used to prune memories is undermined by the authors' own use of heuristics in Section 3.1, which feels like a workaround rather than a solution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8293206691741943,
                    "sentence": "To improve the paper, I suggest that the authors provide more convincing experimental results, including comparisons with other state-of-the-art methods and speed comparisons.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8714691996574402,
                    "sentence": "Additionally, the authors should address the issue of using heuristics in their approach and provide a more rigorous solution to eliminate the need for heuristics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9809340834617615,
                    "sentence": "I would like to ask the authors to clarify the following points: (1) How does the R3NN model handle the case where the input-output examples are inconsistent or noisy?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9756269454956055,
                    "sentence": "(2) Can the authors provide more details on the training process, including the hyperparameter settings and the optimization algorithm used?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9839220643043518,
                    "sentence": "(3) How does the NSPS approach compare to other program synthesis techniques, such as those based on symbolic constraint solving or stochastic search?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.07332528267997859
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 0.49770307481643766,
            "class_probabilities": {
                "human": 0.5021818426438073,
                "ai": 0.49770307481643766,
                "mixed": 0.00011508253975490195
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.5021818426438073,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.49770307481643766,
                    "human": 0.5021818426438073,
                    "mixed": 0.00011508253975490195
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes a novel technique called Neuro-Symbolic Program Synthesis (NSPS) that learns to generate a program incrementally without the need for an explicit search. The approach is based on two novel neural modules: the cross correlation I/O network and the Recursive-Reverse-Recursive Neural Network (R3NN). The R3NN model encodes partial trees in a Domain-Specific Language (DSL) and assigns probabilities to different non-terminals in a partial derivation and corresponding expansions to guide the search for complete derivations.\nThe paper tackles the specific question of program induction, which is a fundamental problem in Machine Learning and Artificial Intelligence. The approach is well-motivated, as it addresses the limitations of existing neural architectures for program induction, such as being computationally expensive and hard to train, and not being able to learn interpretable programs.\nHowever, I decide to reject this paper due to two key reasons. Firstly, the experimental results are unconvincing due to the lack of comparison with other state-of-the-art methods, such as FLANN, and the lack of speed comparison. Secondly, the paper's motivation to eliminate heuristics used to prune memories is undermined by the authors' own use of heuristics in Section 3.1, which feels like a workaround rather than a solution.\nTo improve the paper, I suggest that the authors provide more convincing experimental results, including comparisons with other state-of-the-art methods and speed comparisons. Additionally, the authors should address the issue of using heuristics in their approach and provide a more rigorous solution to eliminate the need for heuristics.\nI would like to ask the authors to clarify the following points: (1) How does the R3NN model handle the case where the input-output examples are inconsistent or noisy? (2) Can the authors provide more details on the training process, including the hyperparameter settings and the optimization algorithm used? (3) How does the NSPS approach compare to other program synthesis techniques, such as those based on symbolic constraint solving or stochastic search?"
        }
    ]
}