{
    "version": "2025-01-09-base",
    "scanId": "78dfcb18-5ee4-4b6d-a18f-7dc8a5412e11",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9998716711997986,
                    "sentence": "Summary",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999747276306152,
                    "sentence": "This paper presents a novel end-to-end speech recognition system that combines a convolutional neural network (CNN) with a graph decoding approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998499751091003,
                    "sentence": "The system is trained to output letters directly from the speech signal, without the need for phonetic transcription or force alignment.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999857485294342,
                    "sentence": "The authors introduce an automatic segmentation criterion, called AutoSegCriterion (ASG), which is simpler and faster than the popular Connectionist Temporal Classification (CTC) criterion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999921977519989,
                    "sentence": "The system achieves competitive results on the LibriSpeech corpus, with a word error rate (WER) of 7.2% using Mel-Frequency Cepstral Coefficients (MFCC) features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9983304142951965,
                    "sentence": "Decision",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989808201789856,
                    "sentence": "I decide to Accept this paper, with two key reasons: (1) the paper proposes a novel and simple end-to-end speech recognition system that achieves competitive results on a benchmark dataset, and (2) the authors introduce a new automatic segmentation criterion that is faster and as accurate as the popular CTC criterion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988466501235962,
                    "sentence": "Supporting Arguments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.998964250087738,
                    "sentence": "The paper is well-motivated, and the authors provide a clear overview of the existing speech recognition systems and their limitations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984967112541199,
                    "sentence": "The proposed system is simple and efficient, with a CNN-based acoustic model and a graph decoding approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998580813407898,
                    "sentence": "The ASG criterion is a significant contribution, as it simplifies the decoding process and reduces the computational complexity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995022416114807,
                    "sentence": "The experimental results demonstrate the effectiveness of the proposed system, with competitive WERs on the LibriSpeech corpus.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9906099438667297,
                    "sentence": "Additional Feedback",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990629553794861,
                    "sentence": "To further improve the paper, I suggest that the authors provide more details on the implementation of the ASG criterion and the beam-search decoder.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9958552122116089,
                    "sentence": "Additionally, it would be interesting to see more experiments on the robustness of the system to different types of noise and acoustic conditions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9816601872444153,
                    "sentence": "The authors may also consider comparing their system with other state-of-the-art speech recognition systems, such as those using recurrent neural networks (RNNs) or attention-based models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.4586130380630493,
                    "sentence": "Questions for the Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.4979057013988495,
                    "sentence": "I would like to ask the authors to clarify the following points: (1) How does the ASG criterion handle out-of-vocabulary words or unseen letters in the training data?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5132764577865601,
                    "sentence": "(2) Can the authors provide more details on the computational complexity of the ASG criterion compared to the CTC criterion?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6056562662124634,
                    "sentence": "(3) How does the system perform on other benchmark datasets, such as TIMIT or WSJ?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                }
            ],
            "completely_generated_prob": 0.9984800378301695,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984800378301695,
                "mixed": 0.0015199621698304396
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984800378301695,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984800378301695,
                    "human": 0,
                    "mixed": 0.0015199621698304396
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary\nThis paper presents a novel end-to-end speech recognition system that combines a convolutional neural network (CNN) with a graph decoding approach. The system is trained to output letters directly from the speech signal, without the need for phonetic transcription or force alignment. The authors introduce an automatic segmentation criterion, called AutoSegCriterion (ASG), which is simpler and faster than the popular Connectionist Temporal Classification (CTC) criterion. The system achieves competitive results on the LibriSpeech corpus, with a word error rate (WER) of 7.2% using Mel-Frequency Cepstral Coefficients (MFCC) features.\nDecision\nI decide to Accept this paper, with two key reasons: (1) the paper proposes a novel and simple end-to-end speech recognition system that achieves competitive results on a benchmark dataset, and (2) the authors introduce a new automatic segmentation criterion that is faster and as accurate as the popular CTC criterion.\nSupporting Arguments\nThe paper is well-motivated, and the authors provide a clear overview of the existing speech recognition systems and their limitations. The proposed system is simple and efficient, with a CNN-based acoustic model and a graph decoding approach. The ASG criterion is a significant contribution, as it simplifies the decoding process and reduces the computational complexity. The experimental results demonstrate the effectiveness of the proposed system, with competitive WERs on the LibriSpeech corpus.\nAdditional Feedback\nTo further improve the paper, I suggest that the authors provide more details on the implementation of the ASG criterion and the beam-search decoder. Additionally, it would be interesting to see more experiments on the robustness of the system to different types of noise and acoustic conditions. The authors may also consider comparing their system with other state-of-the-art speech recognition systems, such as those using recurrent neural networks (RNNs) or attention-based models.\nQuestions for the Authors\nI would like to ask the authors to clarify the following points: (1) How does the ASG criterion handle out-of-vocabulary words or unseen letters in the training data? (2) Can the authors provide more details on the computational complexity of the ASG criterion compared to the CTC criterion? (3) How does the system perform on other benchmark datasets, such as TIMIT or WSJ?"
        }
    ]
}