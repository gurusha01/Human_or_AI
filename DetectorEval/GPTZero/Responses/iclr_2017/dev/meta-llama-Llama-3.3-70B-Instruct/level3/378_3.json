{
    "version": "2025-01-09-base",
    "scanId": "0b7c51f3-3ae5-4ec7-8ca3-d5155392ce4b",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999819993972778,
                    "sentence": "Summary",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999886155128479,
                    "sentence": "The paper proposes a novel end-to-end speech recognition system that combines a convolutional neural network (CNN) with a graph decoding approach, trained using a new sequence criterion called AutoSegCriterion (ASG).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999751448631287,
                    "sentence": "The system is designed to output letters directly from the speech signal, without the need for phonetic transcription or force alignment.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999992311000824,
                    "sentence": "The authors demonstrate competitive results on the LibriSpeech corpus, with word error rates (WERs) of 7.2% for MFCC features, 9.4% for power spectrum features, and 10.1% for raw speech.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999545216560364,
                    "sentence": "Decision",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999080896377563,
                    "sentence": "I decide to Accept this paper, with two key reasons: (1) the proposed ASG criterion shows promising results, with faster computation times and comparable accuracy to the popular Connectionist Temporal Classification (CTC) criterion, and (2) the system's end-to-end architecture and simplicity make it an attractive alternative to traditional speech recognition pipelines.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999674379825592,
                    "sentence": "Supporting Arguments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998852014541626,
                    "sentence": "The paper provides a clear and well-motivated introduction to the problem of speech recognition, highlighting the limitations of traditional approaches and the potential benefits of end-to-end systems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999388456344604,
                    "sentence": "The authors also provide a thorough explanation of the ASG criterion and its advantages over CTC.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999961256980896,
                    "sentence": "The experimental results demonstrate the effectiveness of the proposed system, with competitive WERs on the LibriSpeech corpus.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999895691871643,
                    "sentence": "Additionally, the authors provide a detailed analysis of the impact of training size and data augmentation on the system's performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998777508735657,
                    "sentence": "Additional Feedback",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999956488609314,
                    "sentence": "To further improve the paper, I suggest that the authors consider evaluating their system on other standard speech recognition benchmarks, such as TIMIT or WSJ, to demonstrate its generalizability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999896764755249,
                    "sentence": "Additionally, the authors could provide more details on the computational resources required to train and deploy their system, as well as its potential applications in real-world scenarios.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9918595552444458,
                    "sentence": "Questions for the Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9892781972885132,
                    "sentence": "To clarify my understanding of the paper, I would like to ask the authors the following questions:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9768074154853821,
                    "sentence": "1. How do the authors plan to address the issue of out-of-vocabulary words, which may not be well-represented in the training data?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9766908884048462,
                    "sentence": "2. Can the authors provide more details on the language model used in the decoder, and how it is integrated with the ASG criterion?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9765509366989136,
                    "sentence": "3. How do the authors envision their system being used in practice, and what potential applications do they see for their technology?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997847017652333,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997847017652333,
                "mixed": 0.00021529823476680056
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997847017652333,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997847017652333,
                    "human": 0,
                    "mixed": 0.00021529823476680056
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary\nThe paper proposes a novel end-to-end speech recognition system that combines a convolutional neural network (CNN) with a graph decoding approach, trained using a new sequence criterion called AutoSegCriterion (ASG). The system is designed to output letters directly from the speech signal, without the need for phonetic transcription or force alignment. The authors demonstrate competitive results on the LibriSpeech corpus, with word error rates (WERs) of 7.2% for MFCC features, 9.4% for power spectrum features, and 10.1% for raw speech.\nDecision\nI decide to Accept this paper, with two key reasons: (1) the proposed ASG criterion shows promising results, with faster computation times and comparable accuracy to the popular Connectionist Temporal Classification (CTC) criterion, and (2) the system's end-to-end architecture and simplicity make it an attractive alternative to traditional speech recognition pipelines.\nSupporting Arguments\nThe paper provides a clear and well-motivated introduction to the problem of speech recognition, highlighting the limitations of traditional approaches and the potential benefits of end-to-end systems. The authors also provide a thorough explanation of the ASG criterion and its advantages over CTC. The experimental results demonstrate the effectiveness of the proposed system, with competitive WERs on the LibriSpeech corpus. Additionally, the authors provide a detailed analysis of the impact of training size and data augmentation on the system's performance.\nAdditional Feedback\nTo further improve the paper, I suggest that the authors consider evaluating their system on other standard speech recognition benchmarks, such as TIMIT or WSJ, to demonstrate its generalizability. Additionally, the authors could provide more details on the computational resources required to train and deploy their system, as well as its potential applications in real-world scenarios.\nQuestions for the Authors\nTo clarify my understanding of the paper, I would like to ask the authors the following questions:\n1. How do the authors plan to address the issue of out-of-vocabulary words, which may not be well-represented in the training data?\n2. Can the authors provide more details on the language model used in the decoder, and how it is integrated with the ASG criterion?\n3. How do the authors envision their system being used in practice, and what potential applications do they see for their technology?"
        }
    ]
}