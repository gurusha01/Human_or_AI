{
    "version": "2025-01-09-base",
    "scanId": "ef1d746b-a628-48ce-8148-1e778b22706e",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9998137950897217,
                    "sentence": "Summary",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997676014900208,
                    "sentence": "The paper presents a novel end-to-end automatic speech recognition system that combines a convolutional neural network (CNN) with a sequence criterion, called AutoSegCriterion, and a simple beam-search decoder.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997084736824036,
                    "sentence": "The system is trained to output letters directly from the speech signal, without the need for phonetic transcription or force alignment.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999585747718811,
                    "sentence": "The authors claim that their approach is simpler, faster, and more accurate than traditional methods, including Connectionist Temporal Classification (CTC).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987832903862,
                    "sentence": "Decision",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998840093612671,
                    "sentence": "I decide to accept this paper, with the main reason being that it presents a well-motivated and innovative approach to speech recognition, with promising results on the LibriSpeech corpus.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999176859855652,
                    "sentence": "The authors provide a clear and detailed explanation of their method, and the experimental results demonstrate the effectiveness of their approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995750784873962,
                    "sentence": "Supporting Arguments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999000430107117,
                    "sentence": "The paper is well-structured and easy to follow, with a clear introduction to the problem and the proposed solution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998763799667358,
                    "sentence": "The authors provide a thorough review of the related work and motivate their approach by highlighting the limitations of traditional methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998731017112732,
                    "sentence": "The experimental results are convincing, with the proposed method achieving competitive results on the LibriSpeech corpus.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99994957447052,
                    "sentence": "The authors also provide a detailed analysis of the results and discuss the advantages and limitations of their approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999878466129303,
                    "sentence": "Additional Feedback",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999256134033203,
                    "sentence": "To further improve the paper, I would like to see more comparisons with other state-of-the-art methods, including RNN-based approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999446272850037,
                    "sentence": "Additionally, it would be interesting to see the results of the proposed method on other speech recognition datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999227523803711,
                    "sentence": "The authors could also provide more details on the implementation of the AutoSegCriterion and the beam-search decoder, as well as the hyperparameter tuning process.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9958295226097107,
                    "sentence": "Questions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998526573181152,
                    "sentence": "I would like the authors to clarify the following points:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999427795410156,
                    "sentence": "* How does the proposed method handle out-of-vocabulary words or rare words?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999624490737915,
                    "sentence": "* Can the authors provide more details on the computational resources required to train and test their system?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999698400497437,
                    "sentence": "* How does the proposed method compare to other end-to-end speech recognition systems, such as those using attention-based models?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999976634979248,
                    "sentence": "* Can the authors provide more insights into the advantages and limitations of using a CNN-based approach for speech recognition, compared to RNN-based approaches?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997862822885396,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997862822885396,
                "mixed": 0.00021371771146045916
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997862822885396,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997862822885396,
                    "human": 0,
                    "mixed": 0.00021371771146045916
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary\nThe paper presents a novel end-to-end automatic speech recognition system that combines a convolutional neural network (CNN) with a sequence criterion, called AutoSegCriterion, and a simple beam-search decoder. The system is trained to output letters directly from the speech signal, without the need for phonetic transcription or force alignment. The authors claim that their approach is simpler, faster, and more accurate than traditional methods, including Connectionist Temporal Classification (CTC).\nDecision\nI decide to accept this paper, with the main reason being that it presents a well-motivated and innovative approach to speech recognition, with promising results on the LibriSpeech corpus. The authors provide a clear and detailed explanation of their method, and the experimental results demonstrate the effectiveness of their approach.\nSupporting Arguments\nThe paper is well-structured and easy to follow, with a clear introduction to the problem and the proposed solution. The authors provide a thorough review of the related work and motivate their approach by highlighting the limitations of traditional methods. The experimental results are convincing, with the proposed method achieving competitive results on the LibriSpeech corpus. The authors also provide a detailed analysis of the results and discuss the advantages and limitations of their approach.\nAdditional Feedback\nTo further improve the paper, I would like to see more comparisons with other state-of-the-art methods, including RNN-based approaches. Additionally, it would be interesting to see the results of the proposed method on other speech recognition datasets. The authors could also provide more details on the implementation of the AutoSegCriterion and the beam-search decoder, as well as the hyperparameter tuning process.\nQuestions\nI would like the authors to clarify the following points:\n* How does the proposed method handle out-of-vocabulary words or rare words?\n* Can the authors provide more details on the computational resources required to train and test their system?\n* How does the proposed method compare to other end-to-end speech recognition systems, such as those using attention-based models?\n* Can the authors provide more insights into the advantages and limitations of using a CNN-based approach for speech recognition, compared to RNN-based approaches?"
        }
    ]
}