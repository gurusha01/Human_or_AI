{
    "version": "2025-01-09-base",
    "scanId": "b5a44cd5-3f21-4b41-9ef8-99283bef60ca",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9997298121452332,
                    "sentence": "Summary",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998233318328857,
                    "sentence": "The paper proposes a novel technique called Neuro-Symbolic Program Synthesis (NSPS) that learns to generate programs incrementally based on given input-output examples.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996426701545715,
                    "sentence": "The approach uses a Recursive-Reverse-Recursive Neural Network (R3NN) to encode and expand partial program trees into full program trees.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992581009864807,
                    "sentence": "The paper demonstrates the effectiveness of NSPS in the domain of regular expression-based string transformations, showing that it can construct programs for both known and unseen tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.980363130569458,
                    "sentence": "Decision",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9975966215133667,
                    "sentence": "I decide to Accept this paper, with the main reason being that the approach is well-motivated and supported by experimental results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9956715703010559,
                    "sentence": "The paper tackles a specific problem in program induction, namely the limitations of existing neural architectures, and proposes a novel solution that addresses these limitations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.982495129108429,
                    "sentence": "Supporting Arguments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9957073926925659,
                    "sentence": "The paper provides a clear and well-structured presentation of the problem, the proposed approach, and the experimental results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974416494369507,
                    "sentence": "The authors motivate the need for a neuro-symbolic approach to program synthesis, highlighting the limitations of existing neural architectures.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9970561861991882,
                    "sentence": "The R3NN model is well-described, and the experimental results demonstrate its effectiveness in constructing programs for both known and unseen tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9969792366027832,
                    "sentence": "The paper also provides a thorough comparison with existing approaches, including a simple recurrent model (io2seq), and shows that the R3NN model outperforms it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.994587779045105,
                    "sentence": "Additional Feedback",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9958352446556091,
                    "sentence": "To further improve the paper, I suggest that the authors provide more details on the training process, including the hyperparameter settings and the computational resources used.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9950222969055176,
                    "sentence": "Additionally, it would be interesting to see more examples of the constructed programs, including those that are not perfect but still achieve good results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9946784973144531,
                    "sentence": "The authors may also want to consider providing more analysis on the limitations of the approach and potential avenues for future research.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9930307865142822,
                    "sentence": "Questions for the Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9966644048690796,
                    "sentence": "1. Can you provide more details on the training process, including the hyperparameter settings and the computational resources used?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9934371113777161,
                    "sentence": "2. How do you plan to address the scalability issues in training with programs of larger size?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.997581422328949,
                    "sentence": "3. Can you provide more examples of the constructed programs, including those that are not perfect but still achieve good results?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9975062012672424,
                    "sentence": "4. How do you think the approach can be extended to other domains, such as numerical computations or data structures?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997847017652333,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997847017652333,
                "mixed": 0.00021529823476680056
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997847017652333,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997847017652333,
                    "human": 0,
                    "mixed": 0.00021529823476680056
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary\nThe paper proposes a novel technique called Neuro-Symbolic Program Synthesis (NSPS) that learns to generate programs incrementally based on given input-output examples. The approach uses a Recursive-Reverse-Recursive Neural Network (R3NN) to encode and expand partial program trees into full program trees. The paper demonstrates the effectiveness of NSPS in the domain of regular expression-based string transformations, showing that it can construct programs for both known and unseen tasks.\nDecision\nI decide to Accept this paper, with the main reason being that the approach is well-motivated and supported by experimental results. The paper tackles a specific problem in program induction, namely the limitations of existing neural architectures, and proposes a novel solution that addresses these limitations.\nSupporting Arguments\nThe paper provides a clear and well-structured presentation of the problem, the proposed approach, and the experimental results. The authors motivate the need for a neuro-symbolic approach to program synthesis, highlighting the limitations of existing neural architectures. The R3NN model is well-described, and the experimental results demonstrate its effectiveness in constructing programs for both known and unseen tasks. The paper also provides a thorough comparison with existing approaches, including a simple recurrent model (io2seq), and shows that the R3NN model outperforms it.\nAdditional Feedback\nTo further improve the paper, I suggest that the authors provide more details on the training process, including the hyperparameter settings and the computational resources used. Additionally, it would be interesting to see more examples of the constructed programs, including those that are not perfect but still achieve good results. The authors may also want to consider providing more analysis on the limitations of the approach and potential avenues for future research.\nQuestions for the Authors\n1. Can you provide more details on the training process, including the hyperparameter settings and the computational resources used?\n2. How do you plan to address the scalability issues in training with programs of larger size?\n3. Can you provide more examples of the constructed programs, including those that are not perfect but still achieve good results?\n4. How do you think the approach can be extended to other domains, such as numerical computations or data structures?"
        }
    ]
}