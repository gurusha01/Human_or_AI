{
    "version": "2025-01-09-base",
    "scanId": "7b2f553c-e54a-4c14-a364-bf03a47199a9",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.002116739982739091,
                    "sentence": "The paper presents a theoretically well motivated for visualizing what parts of the input feature map are responsible for the output decision.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002691057277843356,
                    "sentence": "The key insight is that features that maximally change the output and are simultaneously more unpredictable from other features are the most important ones.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002857160521671176,
                    "sentence": "Most previous work has focused on finding features that maximally change the output without accounting for their predictability from other features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0025715441443026066,
                    "sentence": "Authors build upon ideas presented in the work of Robnik-Å ikonja & Kononenko (2008).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002174266381189227,
                    "sentence": "The results indicate that the proposed visualization mechanism based on modeling conditional distribution identifies more salient regions as compared to a mechanism based on modeling marginal distribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002057938603684306,
                    "sentence": "I like that authors have presented visualization results for a single image across multiple networks and multiple classes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0017782620852813125,
                    "sentence": "There results show that the proposed method indeed picks up on class-discriminative features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001418758649379015,
                    "sentence": "Authors have provided a link to visualizations for a random sample of images in a comment \"\" I encourage the authors to include this in the appendix of the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009473175159655511,
                    "sentence": "My one concern with the paper is \"\" Zeiler et al., proposed a visualization method by greying small square regions in the image.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006547082448378205,
                    "sentence": "This is similar to computing the visualization using the marginal distribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006542873452417552,
                    "sentence": "Authors compute the marginal visualization using 10 samples, however in the limit of infinite samples the image region would be gray.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006303113186731935,
                    "sentence": "The conditional distribution is computed using a normal distribution that provides some regularization and therefore estimating the conditional and marginal distributions using 10 samples each is not justified.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0012117372825741768,
                    "sentence": "I would like to see the comparison when grey image patches (akin to Zeiler et al.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00255531445145607,
                    "sentence": "are used for visualization against the approach based on the conditional distribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                }
            ],
            "completely_generated_prob": 0.020660391318316405,
            "class_probabilities": {
                "human": 0.9793396086816837,
                "ai": 0.020660391318316405,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9793396086816837,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.020660391318316405,
                    "human": 0.9793396086816837,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper presents a theoretically well motivated for visualizing what parts of the input feature map are responsible for the output decision. The key insight is that features that maximally change the output and are simultaneously more unpredictable from other features are the most important ones. Most previous work has focused on finding features that maximally change the output without accounting for their predictability from other features. Authors build upon ideas presented in the work of Robnik-Å ikonja & Kononenko (2008).\nThe results indicate that the proposed visualization mechanism based on modeling conditional distribution identifies more salient regions as compared to a mechanism based on modeling marginal distribution. I like that authors have presented visualization results for a single image across multiple networks and multiple classes. There results show that the proposed method indeed picks up on class-discriminative features. Authors have provided a link to visualizations for a random sample of images in a comment \"\" I encourage the authors to include this in the appendix of the paper. \nMy one concern with the paper is \"\" Zeiler et al., proposed a visualization method by greying small square regions in the image. This is similar to computing the visualization using the marginal distribution. Authors compute the marginal visualization using 10 samples, however in the limit of infinite samples the image region would be gray. The conditional distribution is computed using a normal distribution that provides some regularization and therefore estimating the conditional and marginal distributions using 10 samples each is not justified. \nI would like to see the comparison when grey image patches (akin to Zeiler et al.) are used for visualization against the approach based on the conditional distribution."
        }
    ]
}