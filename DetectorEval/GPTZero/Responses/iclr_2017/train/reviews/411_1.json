{
    "version": "2025-01-09-base",
    "scanId": "d07c8c3e-90da-4a49-bf25-4679c1d73067",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.01592988520860672,
                    "sentence": "This work builds on top of STOKE (Schkufza et al., 2013), which is a superoptimization engine for program binaries.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010331806726753712,
                    "sentence": "It works by starting with an existing program, and proposing modifications to it according to a proposal distribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005865925457328558,
                    "sentence": "Proposals are accepted according to the Metropolis-Hastings criteria.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008086792193353176,
                    "sentence": "The acceptance criteria takes into account the correctness of the program, and performance of the new program.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00684537785127759,
                    "sentence": "Thus, the MCMC process is likely to converge to correct programs with high performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005199086386710405,
                    "sentence": "Typically, the proposal distribution is fixed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003434378420934081,
                    "sentence": "The contribution of this work is to learn the proposal distribution as a function of the features of the program (bag of words of all the opcodes in the program).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0035517802461981773,
                    "sentence": "The experiments compare with the baselines of uniform proposal distribution, and a baseline where one just learns the weights of the proposal distribution but without conditioning on the features of the program.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0064950790256261826,
                    "sentence": "The evaluation shows that the proposed method has slightly better performance than the compared baselines.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0029573366045951843,
                    "sentence": "The significance of this work at ICLR seems to be quite low., both because this is not a progress in learning representations, but a straightforward application of neural networks and REINFORCE to yet another task which has non-differentiable components.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004957048688083887,
                    "sentence": "The task itself (superoptimization) is not of significant interest to ICLR readers/attendees.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0026459998916834593,
                    "sentence": "A conference like AAAI/UAI seem a better fit for this work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0056790802627801895,
                    "sentence": "The proposed method is seemingly novel.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0056317467242479324,
                    "sentence": "Typical MCMC-based synthesis methods are lacking due to their being no learning components in them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0036368435248732567,
                    "sentence": "However, to make this work compelling, the authors should consider demonstrating the proposed method in other synthesis tasks, or even more generally, other tasks where MH-MCMC is used, and a learnt proposal distribution can be beneficial.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0038168118335306644,
                    "sentence": "Superoptimization alone (esp with small improvements over baselines) is not compelling enough.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0028175802435725927,
                    "sentence": "It is also not clear if there is any significant representation learning is going on.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003490953240543604,
                    "sentence": "Since a BoW feature is used to represent the programs, the neural network cannot possibly learn anything more than just correlations between presence of opcodes and good moves.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002017524093389511,
                    "sentence": "Such a model cannot possibly understand the program semantics in any way.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0029033778700977564,
                    "sentence": "It would have been a more interesting contribution if the authors had used a model (such as Tree-LSTM) which attempts to learn the semantics the program.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0037385665345937014,
                    "sentence": "The quite naive method of learning makes this paper not a favorable candidate for acceptance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004423508886247873,
                    "sentence": "Answers to the questions posted by reviewers would help for a more high-quality review.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0049115074798464775,
                    "sentence": "Thanks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 9,
                    "completely_generated_prob": 4.1887248735431006e-08
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.00010005932717626924
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                }
            ],
            "completely_generated_prob": 0.024462635563563526,
            "class_probabilities": {
                "human": 0.9755373644364365,
                "ai": 0.024462635563563526,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9755373644364365,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.024462635563563526,
                    "human": 0.9755373644364365,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This work builds on top of STOKE (Schkufza et al., 2013), which is a superoptimization engine for program binaries. It works by starting with an existing program, and proposing modifications to it according to a proposal distribution. Proposals are accepted according to the Metropolis-Hastings criteria. The acceptance criteria takes into account the correctness of the program, and performance of the new program. Thus, the MCMC process is likely to converge to correct programs with high performance. Typically, the proposal distribution is fixed. The contribution of this work is to learn the proposal distribution as a function of the features of the program (bag of words of all the opcodes in the program). The experiments compare with the baselines of uniform proposal distribution, and a baseline where one just learns the weights of the proposal distribution but without conditioning on the features of the program. The evaluation shows that the proposed method has slightly better performance than the compared baselines.\nThe significance of this work at ICLR seems to be quite low., both because this is not a progress in learning representations, but a straightforward application of neural networks and REINFORCE to yet another task which has non-differentiable components. The task itself (superoptimization) is not of significant interest to ICLR readers/attendees. A conference like AAAI/UAI seem a better fit for this work.\nThe proposed method is seemingly novel. Typical MCMC-based synthesis methods are lacking due to their being no learning components in them. However, to make this work compelling, the authors should consider demonstrating the proposed method in other synthesis tasks, or even more generally, other tasks where MH-MCMC is used, and a learnt proposal distribution can be beneficial. Superoptimization alone (esp with small improvements over baselines) is not compelling enough.\nIt is also not clear if there is any significant representation learning is going on. Since a BoW feature is used to represent the programs, the neural network cannot possibly learn anything more than just correlations between presence of opcodes and good moves. Such a model cannot possibly understand the program semantics in any way. It would have been a more interesting contribution if the authors had used a model (such as Tree-LSTM) which attempts to learn the semantics the program. The quite naive method of learning makes this paper not a favorable candidate for acceptance.\nAnswers to the questions posted by reviewers would help for a more high-quality review. Thanks."
        }
    ]
}