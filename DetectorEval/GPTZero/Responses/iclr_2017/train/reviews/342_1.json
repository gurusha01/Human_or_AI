{
    "version": "2025-01-09-base",
    "scanId": "b22f0305-1fdf-498b-b053-cff4f22ec7d7",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.3282916843891144,
                    "sentence": "The work combines variational recurrent neural networks, and adversarial neural networks to handle domain adaptation for time series data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.265193909406662,
                    "sentence": "The proposed method, along with several competing algorithms are compared on two healthcare datasets constructed from MIMIC-III in domain adaptation settings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13588979840278625,
                    "sentence": "The new contribution of the work is relatively small.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23761124908924103,
                    "sentence": "It extends VRNN with adversarial training for learning domain agnostic representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.27198633551597595,
                    "sentence": "From the experimental results, the proposed method clearly out-performs competing algorithms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23146328330039978,
                    "sentence": "However, it is not clear where the advantage is coming from.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15287598967552185,
                    "sentence": "The only difference between the proposed method and R-DANN is using variational RNN vs RNN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07609061896800995,
                    "sentence": "Little insights were provided on how this could bring such a big difference in terms of performance and the drastic difference in the temporal dependencies captured by these two methods in Figure 4.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19191336631774902,
                    "sentence": "Detailed comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03961852192878723,
                    "sentence": "1. Please provide more details on what is plotted in Figure 1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06721595674753189,
                    "sentence": "Is 1 (b) is the t-sne projection of representations learned by DANN or R-DANN?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05146957188844681,
                    "sentence": "The text in section 4.4 suggests it's the later case.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04677287116646767,
                    "sentence": "It is surprising to see such a regular plot for VRADA.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05111616104841232,
                    "sentence": "What do you think are the two dominant latent factors encoded in figure 1 (c)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06631119549274445,
                    "sentence": "2. In Table 2, the two baselines have quite significant difference in performance testing on the entire target (including validation set) vs on the test set only.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1265849769115448,
                    "sentence": "VRADA, on the other hand, performs almost identical in these two settings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09188111126422882,
                    "sentence": "Could you please offer some explanation on this?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10209106653928757,
                    "sentence": "3. Please explain figure 3 and 4 in more details.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07406900823116302,
                    "sentence": "how to interpret the x-axis of figure 3, and the x and y axes of figure 4.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07811934500932693,
                    "sentence": "Again the right two plots in figure 4 are extremely regular comparing to the ones on the left.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 6,
                    "completely_generated_prob": 1.474742012248794e-05
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.00010005932717626924
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                }
            ],
            "completely_generated_prob": 0.2611247946660578,
            "class_probabilities": {
                "human": 0.7353460735506663,
                "ai": 0.2611247946660578,
                "mixed": 0.0035291317832757073
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.7353460735506663,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.2611247946660578,
                    "human": 0.7353460735506663,
                    "mixed": 0.0035291317832757073
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The work combines variational recurrent neural networks, and adversarial neural networks to handle domain adaptation for time series data. The proposed method, along with several competing algorithms are compared on two healthcare datasets constructed from MIMIC-III in domain adaptation settings.\nThe new contribution of the work is relatively small. It extends VRNN with adversarial training for learning domain agnostic representations. From the experimental results, the proposed method clearly out-performs competing algorithms. However, it is not clear where the advantage is coming from. The only difference between the proposed method and R-DANN is using variational RNN vs RNN. Little insights were provided on how this could bring such a big difference in terms of performance and the drastic difference in the temporal dependencies captured by these two methods in Figure 4. \nDetailed comments:\n1. Please provide more details on what is plotted in Figure 1. Is 1 (b) is the t-sne projection of representations learned by DANN or R-DANN? The text in section 4.4 suggests it's the later case. It is surprising to see such a regular plot for VRADA. What do you think are the two dominant latent factors encoded in figure 1 (c)? \n2. In Table 2, the two baselines have quite significant difference in performance testing on the entire target (including validation set) vs on the test set only. VRADA, on the other hand, performs almost identical in these two settings. Could you please offer some explanation on this?\n3. Please explain figure 3 and 4 in more details. how to interpret the x-axis of figure 3, and the x and y axes of figure 4. Again the right two plots in figure 4 are extremely regular comparing to the ones on the left."
        }
    ]
}