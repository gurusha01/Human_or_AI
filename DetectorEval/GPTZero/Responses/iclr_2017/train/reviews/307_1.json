{
    "version": "2025-01-09-base",
    "scanId": "96eb8939-659d-4dd0-afd1-f079653c752d",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.5917977690696716,
                    "sentence": "This paper was submitted to arXiv last week:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5399995446205139,
                    "sentence": "This paper presents a new, public dataset and tasks for goal-oriented dialogue applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5552814602851868,
                    "sentence": "The dataset and tasks are constructed artificially using rule-based programs, in such a way that different aspects of dialogue system performance can be evaluated ranging from issuing API calls to displaying options, as well as full-fledged dialogue.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5164097547531128,
                    "sentence": "This is a welcome contribution to the dialogue literature, which will help facilitate future research into developing and understanding dialogue systems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.35524019598960876,
                    "sentence": "Still, there are pitfalls in taking this approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4217816889286041,
                    "sentence": "First, it is not clear how suitable Deep Learning models are for these tasks compared to traditional methods (rule-based systems or shallow models), since Deep Learning models are known to require many training examples and therefore performance difference between different neural networks may simply boil down to regularization techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3226984441280365,
                    "sentence": "The tasks 1-5 are also completely deterministic, which means evaluating performance on these tasks won't measure the ability of the models to handle noisy and ambiguous interactions (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.48146411776542664,
                    "sentence": "inferring a distribution over user goals, or executing dialogue repair strategies), which is a very important aspect in dialogue applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2955985367298126,
                    "sentence": "Overall, I still believe this is an interesting direction to explore.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4462892413139343,
                    "sentence": "As discussed in the comments below, the paper does not have any baseline model with word order information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.34486207365989685,
                    "sentence": "I think this is a strong weakness of the paper, because it makes the neural networks appear unreasonably strong, yet simpler baselines could very likely be be competitive (or better) than the proposed neural networks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008669315837323666,
                    "sentence": "To maintain a fair evaluation and correctly assess the power of representation learning for this task, I think it's important that the authors experiment with one additional non-neural network benchmark model which takes into account word order information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0074827889911830425,
                    "sentence": "This would more convincly demonstrate the utility of Deep Learning models for this task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007575382478535175,
                    "sentence": "For example, the one could experiment with a logistic regression model which takes as input 1) word embeddings (similar to the Supervised Embeddings model), 2) bi-gram features, and 3) match-type features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006406974978744984,
                    "sentence": "If such a baseline is included, I will increase my rating to 8.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007522575557231903,
                    "sentence": "Final minor comment: in the conclusion, the paper states \"the existing work has no well defined measures of performances\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008520277217030525,
                    "sentence": "This is not really true.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005077415611594915,
                    "sentence": "End-to-end trainable models for task-oriented dialogue have well-defined performance measures.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00462482962757349,
                    "sentence": "See, for example \"A Network-based End-to-End Trainable Task-oriented Dialogue System\" by Wen et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005602233577519655,
                    "sentence": "On the other hand, non-goal-oriented dialogue are generally harder to evaluate, but given human subjects these can also be evaluated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006164683494716883,
                    "sentence": "In fact, this is what Liu et al (2016) do for Twitter.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008120656944811344,
                    "sentence": "See also, \"Strategy and Policy Learning for Non-Task-Oriented Conversational Systems\" by Yu et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007343686884269118,
                    "sentence": "----",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007184183690696955,
                    "sentence": "I've updated my score following the new results added in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 6,
                    "completely_generated_prob": 1.474742012248794e-05
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 6,
                    "completely_generated_prob": 1.474742012248794e-05
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 7,
                    "completely_generated_prob": 2.1228438805416278e-06
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.13711016669196363,
            "class_probabilities": {
                "human": 0.8628387744078284,
                "ai": 0.13711016669196363,
                "mixed": 5.105890020803014e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.8628387744078284,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.13711016669196363,
                    "human": 0.8628387744078284,
                    "mixed": 5.105890020803014e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper was submitted to arXiv last week:\nThis paper presents a new, public dataset and tasks for goal-oriented dialogue applications. The dataset and tasks are constructed artificially using rule-based programs, in such a way that different aspects of dialogue system performance can be evaluated ranging from issuing API calls to displaying options, as well as full-fledged dialogue.\nThis is a welcome contribution to the dialogue literature, which will help facilitate future research into developing and understanding dialogue systems. Still, there are pitfalls in taking this approach. First, it is not clear how suitable Deep Learning models are for these tasks compared to traditional methods (rule-based systems or shallow models), since Deep Learning models are known to require many training examples and therefore performance difference between different neural networks may simply boil down to regularization techniques. The tasks 1-5 are also completely deterministic, which means evaluating performance on these tasks won't measure the ability of the models to handle noisy and ambiguous interactions (e.g. inferring a distribution over user goals, or executing dialogue repair strategies), which is a very important aspect in dialogue applications. Overall, I still believe this is an interesting direction to explore.\nAs discussed in the comments below, the paper does not have any baseline model with word order information. I think this is a strong weakness of the paper, because it makes the neural networks appear unreasonably strong, yet simpler baselines could very likely be be competitive (or better) than the proposed neural networks. To maintain a fair evaluation and correctly assess the power of representation learning for this task, I think it's important that the authors experiment with one additional non-neural network benchmark model which takes into account word order information. This would more convincly demonstrate the utility of Deep Learning models for this task. For example, the one could experiment with a logistic regression model which takes as input 1) word embeddings (similar to the Supervised Embeddings model), 2) bi-gram features, and 3) match-type features. If such a baseline is included, I will increase my rating to 8.\nFinal minor comment: in the conclusion, the paper states \"the existing work has no well defined measures of performances\". This is not really true. End-to-end trainable models for task-oriented dialogue have well-defined performance measures. See, for example \"A Network-based End-to-End Trainable Task-oriented Dialogue System\" by Wen et al. On the other hand, non-goal-oriented dialogue are generally harder to evaluate, but given human subjects these can also be evaluated. In fact, this is what Liu et al (2016) do for Twitter. See also, \"Strategy and Policy Learning for Non-Task-Oriented Conversational Systems\" by Yu et al.\n----\nI've updated my score following the new results added in the paper."
        }
    ]
}