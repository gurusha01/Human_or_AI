{
    "version": "2025-01-09-base",
    "scanId": "50cae660-80db-49ad-875e-57faceeb9476",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9894474744796753,
                    "sentence": "This paper proposes an approach for future frame prediction in videos by separately encoding motion and content, complemented by the use of multi-scale residual connections.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9885097146034241,
                    "sentence": "The authors provide both qualitative and quantitative results on the KTH, Weizmann, and UCF-101 datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9908843040466309,
                    "sentence": "The concept of decoupling motion and content is intriguing and appears effective for the given task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9891617894172668,
                    "sentence": "However, the contribution feels relatively incremental in light of prior work on multi-stream networks, and it remains unclear whether this specific decoupling strategy is broadly applicable or impactful beyond the scope of future frame prediction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.988149106502533,
                    "sentence": "While the results on the KTH and Weizmann datasets are compelling and show significant improvements over baselines, the performance on the less constrained UCF-101 dataset is less impressive.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9872547388076782,
                    "sentence": "Furthermore, the qualitative examples for UCF-101 are unconvincing, as noted in the pre-review question.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9941187500953674,
                    "sentence": "In summary, this is a well-executed study with an interesting, albeit not highly novel, idea.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9927268624305725,
                    "sentence": "To enhance the paper's contribution, it would be beneficial to demonstrate the broader applicability of the proposed decoupling approach, such as its utility for other video-related tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.8129788192879676,
            "class_probabilities": {
                "human": 0.18702118071203244,
                "ai": 0.8129788192879676,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8129788192879676,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8129788192879676,
                    "human": 0.18702118071203244,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes an approach for future frame prediction in videos by separately encoding motion and content, complemented by the use of multi-scale residual connections. The authors provide both qualitative and quantitative results on the KTH, Weizmann, and UCF-101 datasets.\nThe concept of decoupling motion and content is intriguing and appears effective for the given task. However, the contribution feels relatively incremental in light of prior work on multi-stream networks, and it remains unclear whether this specific decoupling strategy is broadly applicable or impactful beyond the scope of future frame prediction.\nWhile the results on the KTH and Weizmann datasets are compelling and show significant improvements over baselines, the performance on the less constrained UCF-101 dataset is less impressive. Furthermore, the qualitative examples for UCF-101 are unconvincing, as noted in the pre-review question.\nIn summary, this is a well-executed study with an interesting, albeit not highly novel, idea. To enhance the paper's contribution, it would be beneficial to demonstrate the broader applicability of the proposed decoupling approach, such as its utility for other video-related tasks."
        }
    ]
}