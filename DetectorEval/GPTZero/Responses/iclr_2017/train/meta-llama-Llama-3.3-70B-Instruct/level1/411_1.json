{
    "version": "2025-01-09-base",
    "scanId": "dd932617-5e27-4491-9d2b-b992e907bb98",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999086260795593,
                    "sentence": "Summary",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999538660049438,
                    "sentence": "The paper proposes a novel learning-based approach for code super-optimization, which involves transforming a given program into a more efficient version while preserving its input-output behavior.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998615980148315,
                    "sentence": "The authors introduce a reinforcement learning framework to estimate the proposal distribution for optimizing the source code under consideration.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999229311943054,
                    "sentence": "The approach is evaluated on two datasets, including the \"Hacker's Delight\" corpus and a set of automatically generated programs, and is shown to outperform state-of-the-art approaches for code super-optimization.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984069466590881,
                    "sentence": "Decision",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997941255569458,
                    "sentence": "I decide to Accept this paper, with two key reasons for this choice: (1) the paper tackles a specific and important problem in code optimization, and (2) the approach is well-motivated and supported by experimental results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995424151420593,
                    "sentence": "Supporting Arguments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998643398284912,
                    "sentence": "The paper clearly defines the problem of code super-optimization and motivates the need for a learning-based approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997905492782593,
                    "sentence": "The authors provide a thorough review of related work and demonstrate a good understanding of the literature.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997869729995728,
                    "sentence": "The proposed approach is well-explained, and the experimental results are convincing, showing significant improvements over state-of-the-art methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995959997177124,
                    "sentence": "Additional Feedback",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998127222061157,
                    "sentence": "To further improve the paper, I suggest that the authors provide more details on the implementation of the reinforcement learning framework, including the choice of hyperparameters and the optimization algorithm used.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998272657394409,
                    "sentence": "Additionally, it would be helpful to include more examples of optimized programs to illustrate the effectiveness of the approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998964071273804,
                    "sentence": "Furthermore, the authors may want to consider discussing potential limitations and future directions for their work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998338222503662,
                    "sentence": "Questions for the Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998202919960022,
                    "sentence": "To clarify my understanding of the paper, I would like the authors to answer the following questions:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999729573726654,
                    "sentence": "1. Can you provide more details on the choice of the reward function used in the reinforcement learning framework?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998666644096375,
                    "sentence": "2. How do you handle the case where the optimized program is not significantly better than the original program?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998313784599304,
                    "sentence": "3. Have you considered applying your approach to other domains, such as compiler optimization or program synthesis?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary\nThe paper proposes a novel learning-based approach for code super-optimization, which involves transforming a given program into a more efficient version while preserving its input-output behavior. The authors introduce a reinforcement learning framework to estimate the proposal distribution for optimizing the source code under consideration. The approach is evaluated on two datasets, including the \"Hacker's Delight\" corpus and a set of automatically generated programs, and is shown to outperform state-of-the-art approaches for code super-optimization.\nDecision\nI decide to Accept this paper, with two key reasons for this choice: (1) the paper tackles a specific and important problem in code optimization, and (2) the approach is well-motivated and supported by experimental results.\nSupporting Arguments\nThe paper clearly defines the problem of code super-optimization and motivates the need for a learning-based approach. The authors provide a thorough review of related work and demonstrate a good understanding of the literature. The proposed approach is well-explained, and the experimental results are convincing, showing significant improvements over state-of-the-art methods.\nAdditional Feedback\nTo further improve the paper, I suggest that the authors provide more details on the implementation of the reinforcement learning framework, including the choice of hyperparameters and the optimization algorithm used. Additionally, it would be helpful to include more examples of optimized programs to illustrate the effectiveness of the approach. Furthermore, the authors may want to consider discussing potential limitations and future directions for their work.\nQuestions for the Authors\nTo clarify my understanding of the paper, I would like the authors to answer the following questions:\n1. Can you provide more details on the choice of the reward function used in the reinforcement learning framework?\n2. How do you handle the case where the optimized program is not significantly better than the original program?\n3. Have you considered applying your approach to other domains, such as compiler optimization or program synthesis?"
        }
    ]
}