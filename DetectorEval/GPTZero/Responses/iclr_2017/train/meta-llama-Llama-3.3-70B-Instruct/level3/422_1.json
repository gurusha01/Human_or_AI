{
    "version": "2025-01-09-base",
    "scanId": "c380f7d9-0f7d-410f-8f80-83e31c778b4d",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999743103981018,
                    "sentence": "This paper proposes Deep Variational Bayes Filters (DVBF), a novel approach to learning state-space models from raw, non-Markovian sequence data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999473690986633,
                    "sentence": "The authors leverage Stochastic Gradient Variational Bayes (SGVB) to enable efficient inference and learning of latent dynamics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999091029167175,
                    "sentence": "The key contribution of this work is the introduction of a reparametrization trick that allows the transition model to be learned in a way that enforces state-space model assumptions, enabling reliable system identification and long-term prediction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997856020927429,
                    "sentence": "I decide to accept this paper, with two key reasons for this choice: (1) the paper tackles a specific and important problem in the field of state-space models, and (2) the approach is well-motivated and supported by experimental results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998016357421875,
                    "sentence": "The paper provides a clear and detailed explanation of the proposed method, including the reparametrization trick and the lower bound objective function.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997422099113464,
                    "sentence": "The experiments demonstrate the effectiveness of DVBF in recovering latent states that identify underlying physical quantities, and the generative model shows stable long-term predictions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998278617858887,
                    "sentence": "However, I have some concerns regarding the notation and terminology used in the paper, which could be clarified to avoid confusion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998072981834412,
                    "sentence": "Additionally, the paper could benefit from a more compact and clear presentation of the ideas, with a quicker dive into the specifics of the proposed approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999790370464325,
                    "sentence": "To improve the paper, I suggest that the authors provide more details on the implementation of the DVBF algorithm, including the choice of hyperparameters and the optimization procedure.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999751091003418,
                    "sentence": "Furthermore, it would be helpful to include more experimental results, such as comparisons with other state-of-the-art methods, to further demonstrate the effectiveness of DVBF.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998003840446472,
                    "sentence": "I would like the authors to answer the following questions to clarify my understanding of the paper: (1) Can you provide more details on the choice of the recognition model and the transition network?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997639060020447,
                    "sentence": "(2) How do you handle the case where the true posterior distribution is intractable?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998127818107605,
                    "sentence": "(3) Can you provide more experimental results on the performance of DVBF in comparison to other state-of-the-art methods?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes Deep Variational Bayes Filters (DVBF), a novel approach to learning state-space models from raw, non-Markovian sequence data. The authors leverage Stochastic Gradient Variational Bayes (SGVB) to enable efficient inference and learning of latent dynamics. The key contribution of this work is the introduction of a reparametrization trick that allows the transition model to be learned in a way that enforces state-space model assumptions, enabling reliable system identification and long-term prediction.\nI decide to accept this paper, with two key reasons for this choice: (1) the paper tackles a specific and important problem in the field of state-space models, and (2) the approach is well-motivated and supported by experimental results.\nThe paper provides a clear and detailed explanation of the proposed method, including the reparametrization trick and the lower bound objective function. The experiments demonstrate the effectiveness of DVBF in recovering latent states that identify underlying physical quantities, and the generative model shows stable long-term predictions.\nHowever, I have some concerns regarding the notation and terminology used in the paper, which could be clarified to avoid confusion. Additionally, the paper could benefit from a more compact and clear presentation of the ideas, with a quicker dive into the specifics of the proposed approach.\nTo improve the paper, I suggest that the authors provide more details on the implementation of the DVBF algorithm, including the choice of hyperparameters and the optimization procedure. Furthermore, it would be helpful to include more experimental results, such as comparisons with other state-of-the-art methods, to further demonstrate the effectiveness of DVBF.\nI would like the authors to answer the following questions to clarify my understanding of the paper: (1) Can you provide more details on the choice of the recognition model and the transition network? (2) How do you handle the case where the true posterior distribution is intractable? (3) Can you provide more experimental results on the performance of DVBF in comparison to other state-of-the-art methods?"
        }
    ]
}