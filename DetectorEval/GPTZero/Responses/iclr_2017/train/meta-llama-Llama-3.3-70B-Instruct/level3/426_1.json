{
    "version": "2025-01-09-base",
    "scanId": "fea258bd-cadb-4bb3-a793-76603f7483e0",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9986827373504639,
                    "sentence": "This paper addresses the interesting problem of aligning word vectors across languages, with a notable contribution being the introduction of the \"inverted Softmax\" idea.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985198974609375,
                    "sentence": "The authors provide a theoretical foundation for their approach, proving that the linear transformation between word vector spaces should be orthogonal, and demonstrate its effectiveness in improving translation precision.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991188049316406,
                    "sentence": "However, I decide to reject this paper for two key reasons.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984828233718872,
                    "sentence": "Firstly, the evaluation of the approach is not strong, and the downstream task of translating sentences is not sufficiently challenging.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987882971763611,
                    "sentence": "The authors rely heavily on a specific test set and do not demonstrate the robustness of their approach to more diverse language pairs or tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9979956150054932,
                    "sentence": "Secondly, the paper fails to adequately discuss and cite key prior work, such as Haghighi et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992693662643433,
                    "sentence": "(2008) and Hermann & Blunsom (2013), which is essential for placing their contribution in the context of existing research.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985970854759216,
                    "sentence": "To support my decision, I note that the experiments are limited to European/Romance languages, and it is unclear how the approach would perform on more divergent language pairs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9982120990753174,
                    "sentence": "Additionally, the concept of orthogonality requirements could be related to using a Mahalanobis distance/covar matrix to learn mappings, which is worth discussing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9592685103416443,
                    "sentence": "The term \"translation\" may also be misleading when discussing word alignment across languages, and an alternative term should be considered.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9674376845359802,
                    "sentence": "To improve the paper, I suggest that the authors perform experiments with more divergent language pairs, discuss and cite key prior work, and consider alternative terms for \"translation\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9779115915298462,
                    "sentence": "I would also like the authors to answer the following questions: How do the results change when using different word vector representations or dimensionality reduction techniques?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9847131371498108,
                    "sentence": "Can the approach be extended to handle out-of-vocabulary words or domain adaptation?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9899731278419495,
                    "sentence": "How does the \"inverted Softmax\" compare to other methods for mitigating the hubness problem?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9872758984565735,
                    "sentence": "In terms of the conference guidelines, I have considered the following questions:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9963922500610352,
                    "sentence": "1. The specific question/problem tackled by the paper is the alignment of word vectors across languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9926183819770813,
                    "sentence": "2. The approach is well-motivated, but lacks a thorough discussion of prior work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9958460927009583,
                    "sentence": "3. The paper does not fully support its claims, as the evaluation is limited and the approach is not demonstrated to be robust to diverse language pairs or tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9950016140937805,
                    "sentence": "Overall, while the paper has some notable contributions, it requires significant improvements in terms of evaluation, prior work discussion, and robustness to diverse language pairs and tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9984984300152882,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984984300152882,
                "mixed": 0.0015015699847118259
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984984300152882,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984984300152882,
                    "human": 0,
                    "mixed": 0.0015015699847118259
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper addresses the interesting problem of aligning word vectors across languages, with a notable contribution being the introduction of the \"inverted Softmax\" idea. The authors provide a theoretical foundation for their approach, proving that the linear transformation between word vector spaces should be orthogonal, and demonstrate its effectiveness in improving translation precision.\nHowever, I decide to reject this paper for two key reasons. Firstly, the evaluation of the approach is not strong, and the downstream task of translating sentences is not sufficiently challenging. The authors rely heavily on a specific test set and do not demonstrate the robustness of their approach to more diverse language pairs or tasks. Secondly, the paper fails to adequately discuss and cite key prior work, such as Haghighi et al. (2008) and Hermann & Blunsom (2013), which is essential for placing their contribution in the context of existing research.\nTo support my decision, I note that the experiments are limited to European/Romance languages, and it is unclear how the approach would perform on more divergent language pairs. Additionally, the concept of orthogonality requirements could be related to using a Mahalanobis distance/covar matrix to learn mappings, which is worth discussing. The term \"translation\" may also be misleading when discussing word alignment across languages, and an alternative term should be considered.\nTo improve the paper, I suggest that the authors perform experiments with more divergent language pairs, discuss and cite key prior work, and consider alternative terms for \"translation\". I would also like the authors to answer the following questions: How do the results change when using different word vector representations or dimensionality reduction techniques? Can the approach be extended to handle out-of-vocabulary words or domain adaptation? How does the \"inverted Softmax\" compare to other methods for mitigating the hubness problem? \nIn terms of the conference guidelines, I have considered the following questions: \n1. The specific question/problem tackled by the paper is the alignment of word vectors across languages.\n2. The approach is well-motivated, but lacks a thorough discussion of prior work.\n3. The paper does not fully support its claims, as the evaluation is limited and the approach is not demonstrated to be robust to diverse language pairs or tasks. \nOverall, while the paper has some notable contributions, it requires significant improvements in terms of evaluation, prior work discussion, and robustness to diverse language pairs and tasks."
        }
    ]
}