{
    "version": "2025-01-09-base",
    "scanId": "d400ccc9-e8fb-4d23-ad2c-de960a7b090a",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999518990516663,
                    "sentence": "This paper proposes a novel approach to learn decomposition of sequences for speech recognition, which has potential applications in other areas like machine translation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998281598091125,
                    "sentence": "The authors formulate learning of a binary autoencoder as a biconvex optimization problem, which learns from the pairwise correlations between encoded and decoded bits.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998922348022461,
                    "sentence": "The approach is well-motivated, and the authors provide a clear explanation of the problem setup and the proposed solution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999060034751892,
                    "sentence": "The paper tackles the specific question of learning a binary autoencoder with worst-case optimal loss, and the approach is well-placed in the literature.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999051094055176,
                    "sentence": "The authors provide a clear comparison with existing methods, such as byte pair encoding (BPE), and demonstrate the effectiveness of their approach through experiments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995196461677551,
                    "sentence": "The paper supports its claims with theoretical results and empirical evaluations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999823808670044,
                    "sentence": "The authors provide a detailed analysis of the proposed approach and demonstrate its effectiveness in learning binary autoencoders with worst-case optimal loss.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997018575668335,
                    "sentence": "The experimental results show that the proposed approach is competitive with existing methods, such as BPE, and can achieve better performance in some cases.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993409514427185,
                    "sentence": "However, there are some limitations to the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996992349624634,
                    "sentence": "The authors assume that the data is i.i.d., which may not always be the case in practice.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997864961624146,
                    "sentence": "Additionally, the approach may not be directly applicable to other domains, such as machine translation, without significant modifications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9927715063095093,
                    "sentence": "To improve the paper, the authors could provide more detailed analysis of the proposed approach and its limitations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9917250275611877,
                    "sentence": "They could also explore the application of the approach to other domains, such as machine translation, and demonstrate its effectiveness in these areas.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9665163159370422,
                    "sentence": "In terms of the conference guidelines, I would accept this paper with minor revisions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990448951721191,
                    "sentence": "The paper is well-written, and the authors provide a clear explanation of the proposed approach and its effectiveness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9982380270957947,
                    "sentence": "However, the authors could provide more detailed analysis of the approach and its limitations, and explore its application to other domains.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974058866500854,
                    "sentence": "Some questions I would like the authors to answer are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987683892250061,
                    "sentence": "* How does the proposed approach handle non-i.i.d.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974599480628967,
                    "sentence": "data?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992397427558899,
                    "sentence": "* Can the approach be directly applied to other domains, such as machine translation, or would significant modifications be required?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995895624160767,
                    "sentence": "* How does the approach compare to other methods, such as BPE, in terms of computational complexity and scalability?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993364214897156,
                    "sentence": "* Can the authors provide more detailed analysis of the proposed approach and its limitations, and explore its application to other domains?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999341607093811,
                    "sentence": "Overall, the paper is well-written, and the authors provide a clear explanation of the proposed approach and its effectiveness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989673495292664,
                    "sentence": "With some minor revisions, the paper could be even stronger and more effective in demonstrating the potential of the proposed approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9997862822885396,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997862822885396,
                "mixed": 0.00021371771146045916
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997862822885396,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997862822885396,
                    "human": 0,
                    "mixed": 0.00021371771146045916
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes a novel approach to learn decomposition of sequences for speech recognition, which has potential applications in other areas like machine translation. The authors formulate learning of a binary autoencoder as a biconvex optimization problem, which learns from the pairwise correlations between encoded and decoded bits. The approach is well-motivated, and the authors provide a clear explanation of the problem setup and the proposed solution.\nThe paper tackles the specific question of learning a binary autoencoder with worst-case optimal loss, and the approach is well-placed in the literature. The authors provide a clear comparison with existing methods, such as byte pair encoding (BPE), and demonstrate the effectiveness of their approach through experiments.\nThe paper supports its claims with theoretical results and empirical evaluations. The authors provide a detailed analysis of the proposed approach and demonstrate its effectiveness in learning binary autoencoders with worst-case optimal loss. The experimental results show that the proposed approach is competitive with existing methods, such as BPE, and can achieve better performance in some cases.\nHowever, there are some limitations to the paper. The authors assume that the data is i.i.d., which may not always be the case in practice. Additionally, the approach may not be directly applicable to other domains, such as machine translation, without significant modifications.\nTo improve the paper, the authors could provide more detailed analysis of the proposed approach and its limitations. They could also explore the application of the approach to other domains, such as machine translation, and demonstrate its effectiveness in these areas.\nIn terms of the conference guidelines, I would accept this paper with minor revisions. The paper is well-written, and the authors provide a clear explanation of the proposed approach and its effectiveness. However, the authors could provide more detailed analysis of the approach and its limitations, and explore its application to other domains.\nSome questions I would like the authors to answer are:\n* How does the proposed approach handle non-i.i.d. data?\n* Can the approach be directly applied to other domains, such as machine translation, or would significant modifications be required?\n* How does the approach compare to other methods, such as BPE, in terms of computational complexity and scalability?\n* Can the authors provide more detailed analysis of the proposed approach and its limitations, and explore its application to other domains? \nOverall, the paper is well-written, and the authors provide a clear explanation of the proposed approach and its effectiveness. With some minor revisions, the paper could be even stronger and more effective in demonstrating the potential of the proposed approach."
        }
    ]
}