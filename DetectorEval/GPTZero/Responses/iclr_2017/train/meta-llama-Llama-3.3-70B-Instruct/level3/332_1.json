{
    "version": "2025-01-09-base",
    "scanId": "3457cd0f-d011-45e4-b56e-c395b4a45a2e",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9941855669021606,
                    "sentence": "Summary",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9963823556900024,
                    "sentence": "The paper proposes a model, Object Persistence Net (OPnet), that learns to associate different views of 3D objects using a triplet loss to encourage two views of the same object to be closer than an image of a different object.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9903773665428162,
                    "sentence": "The approach is evaluated on object instance and category retrieval, and compared against baseline CNNs, with an additional comparison against human perception on the \"Tenenbaum objects\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9907056093215942,
                    "sentence": "The paper demonstrates that the OPnet outperforms the baseline models in similarity judgment tasks, especially in recognizing novel objects and objects from unseen categories.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9945328831672668,
                    "sentence": "Decision",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9973791837692261,
                    "sentence": "I decide to reject the paper, with two key reasons for this choice.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9954454302787781,
                    "sentence": "Firstly, the paper lacks relevant references to related work, such as the \"image purification\" paper, which learns to map CNN features to light field descriptors for view-invariant object retrieval.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.996397078037262,
                    "sentence": "Secondly, the paper is missing a direct comparison against existing approaches, such as the cross-view retrieval experiment in the \"image purification\" paper, which has available code and data online.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.989602267742157,
                    "sentence": "Supporting Arguments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9958821535110474,
                    "sentence": "The paper's approach is well-motivated, and the use of triplet loss is a good idea.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9966063499450684,
                    "sentence": "However, the lack of references to related work and the missing comparison against existing approaches make it difficult to evaluate the novelty and effectiveness of the proposed approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999257922172546,
                    "sentence": "Additionally, the paper's evaluation is limited to a specific dataset and task, and it is unclear how well the approach would generalize to other datasets and tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993945956230164,
                    "sentence": "Additional Feedback",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999681830406189,
                    "sentence": "To improve the paper, I suggest that the authors provide a more comprehensive review of related work, including the \"image purification\" paper and other relevant approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994209408760071,
                    "sentence": "Additionally, the authors should compare their approach against existing approaches, such as the cross-view retrieval experiment in the \"image purification\" paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997292160987854,
                    "sentence": "The authors should also consider evaluating their approach on a wider range of datasets and tasks to demonstrate its generalizability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9921882152557373,
                    "sentence": "Questions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989555478096008,
                    "sentence": "I would like the authors to answer the following questions to clarify my understanding of the paper and provide additional evidence to support their claims:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985800385475159,
                    "sentence": "1. How does the OPnet approach differ from the \"image purification\" paper, and what are the advantages and disadvantages of each approach?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988026022911072,
                    "sentence": "2. Can the authors provide a more detailed comparison against existing approaches, including the cross-view retrieval experiment in the \"image purification\" paper?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992249608039856,
                    "sentence": "3. How does the OPnet approach generalize to other datasets and tasks, and what are the limitations of the approach?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9984930238596827,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984930238596827,
                "mixed": 0.001506976140317253
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984930238596827,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984930238596827,
                    "human": 0,
                    "mixed": 0.001506976140317253
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary\nThe paper proposes a model, Object Persistence Net (OPnet), that learns to associate different views of 3D objects using a triplet loss to encourage two views of the same object to be closer than an image of a different object. The approach is evaluated on object instance and category retrieval, and compared against baseline CNNs, with an additional comparison against human perception on the \"Tenenbaum objects\". The paper demonstrates that the OPnet outperforms the baseline models in similarity judgment tasks, especially in recognizing novel objects and objects from unseen categories.\nDecision\nI decide to reject the paper, with two key reasons for this choice. Firstly, the paper lacks relevant references to related work, such as the \"image purification\" paper, which learns to map CNN features to light field descriptors for view-invariant object retrieval. Secondly, the paper is missing a direct comparison against existing approaches, such as the cross-view retrieval experiment in the \"image purification\" paper, which has available code and data online.\nSupporting Arguments\nThe paper's approach is well-motivated, and the use of triplet loss is a good idea. However, the lack of references to related work and the missing comparison against existing approaches make it difficult to evaluate the novelty and effectiveness of the proposed approach. Additionally, the paper's evaluation is limited to a specific dataset and task, and it is unclear how well the approach would generalize to other datasets and tasks.\nAdditional Feedback\nTo improve the paper, I suggest that the authors provide a more comprehensive review of related work, including the \"image purification\" paper and other relevant approaches. Additionally, the authors should compare their approach against existing approaches, such as the cross-view retrieval experiment in the \"image purification\" paper. The authors should also consider evaluating their approach on a wider range of datasets and tasks to demonstrate its generalizability.\nQuestions\nI would like the authors to answer the following questions to clarify my understanding of the paper and provide additional evidence to support their claims:\n1. How does the OPnet approach differ from the \"image purification\" paper, and what are the advantages and disadvantages of each approach?\n2. Can the authors provide a more detailed comparison against existing approaches, including the cross-view retrieval experiment in the \"image purification\" paper?\n3. How does the OPnet approach generalize to other datasets and tasks, and what are the limitations of the approach?"
        }
    ]
}