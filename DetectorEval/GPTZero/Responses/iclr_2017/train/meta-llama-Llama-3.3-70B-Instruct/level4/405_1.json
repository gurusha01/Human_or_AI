{
    "version": "2025-01-09-base",
    "scanId": "35a96cae-75f5-4bf0-a2a9-9ed4cd99f25e",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9997011423110962,
                    "sentence": "[UPDATE]",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999222993850708,
                    "sentence": "Upon reviewing the author's response and revised manuscript, I have increased my review score for two key reasons.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.998904287815094,
                    "sentence": "1. I appreciate the authors' efforts to further examine the distinction between their work and existing research (Scheduled sampling, Unsupervised learning using LSTM), providing valuable insights into these comparisons.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9980424642562866,
                    "sentence": "The empirical evidence presented in this paper demonstrates the superiority of the 100%-Pred scheme for high-dimensional video and long-term predictions, a finding that would benefit from brief discussion in the final revision, potentially in the appendix or main text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988596439361572,
                    "sentence": "2. The revised manuscript offers more comprehensive results than its predecessor, which will prove highly beneficial to the research community given the computationally expensive nature of large-scale experiments in high-dimensional video prediction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985449910163879,
                    "sentence": "The results and discussions presented in this paper will contribute significantly to the field.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999218583106995,
                    "sentence": "- Summary",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9975636601448059,
                    "sentence": "This manuscript introduces a novel RNN architecture for action-conditional future prediction, where actions are integrated into the recurrent connection of the LSTM core, outperforming the previous state-of-the-art architecture [Oh et al.].",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987199306488037,
                    "sentence": "The paper also explores various architectures, including frame-dependent/independent modes and observation/prediction-dependent architectures.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987711310386658,
                    "sentence": "Experimental results show that the proposed architecture, combined with a fully prediction-dependent training scheme, achieves state-of-the-art performance in several complex visual domains.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5637949705123901,
                    "sentence": "Furthermore, the prediction architecture is shown to enhance exploration in a 3D environment.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.872593879699707,
                    "sentence": "- Novelty",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5187063813209534,
                    "sentence": "While the proposed architecture does not exhibit strong novelty, its distinction from [Oh et al.]",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5753505825996399,
                    "sentence": "lies in the integration of actions into the LSTM, whereas [Oh et al.]",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6773660778999329,
                    "sentence": "combines actions after the LSTM.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7032227516174316,
                    "sentence": "Notably, jumpy prediction was previously introduced by [Srivastava et al.]",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8166868090629578,
                    "sentence": "in the deep learning domain.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9238314032554626,
                    "sentence": "- Experiment",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7762419581413269,
                    "sentence": "The experimental design is thorough and well-executed, evaluating different training schemes and comparing architectures across several rich domains (Atari, 3D worlds).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7352759838104248,
                    "sentence": "The proposed method achieves state-of-the-art results in many domains and demonstrates an application in model-based exploration.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8218420147895813,
                    "sentence": "- Clarity",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6150026917457581,
                    "sentence": "The manuscript is well-written and easy to follow, facilitating a clear understanding of the presented concepts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7219156622886658,
                    "sentence": "- Overall",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5373585820198059,
                    "sentence": "Although the novelty of the proposed architecture is limited, it yields promising results in Atari games and 3D environments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7543856501579285,
                    "sentence": "The systematic evaluation of different architectures presented in the paper will be a valuable resource for the community.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9372566938400269,
                    "sentence": "[Reference]",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8655683994293213,
                    "sentence": "Nitish Srivastava, Elman Mansimov, Ruslan Salakhutdinov.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9130513668060303,
                    "sentence": "Unsupervised Learning with LSTMs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9301427602767944,
                    "sentence": "ICML 2016.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.5710657228372709
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.0022792978668507114
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 0.7936028431808086,
            "class_probabilities": {
                "human": 0.1936532144943455,
                "ai": 0.7936028431808086,
                "mixed": 0.012743942324846002
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.7936028431808086,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.7936028431808086,
                    "human": 0.1936532144943455,
                    "mixed": 0.012743942324846002
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "[UPDATE]\nUpon reviewing the author's response and revised manuscript, I have increased my review score for two key reasons.\n1. I appreciate the authors' efforts to further examine the distinction between their work and existing research (Scheduled sampling, Unsupervised learning using LSTM), providing valuable insights into these comparisons.\nThe empirical evidence presented in this paper demonstrates the superiority of the 100%-Pred scheme for high-dimensional video and long-term predictions, a finding that would benefit from brief discussion in the final revision, potentially in the appendix or main text.\n2. The revised manuscript offers more comprehensive results than its predecessor, which will prove highly beneficial to the research community given the computationally expensive nature of large-scale experiments in high-dimensional video prediction.\nThe results and discussions presented in this paper will contribute significantly to the field.\n- Summary\nThis manuscript introduces a novel RNN architecture for action-conditional future prediction, where actions are integrated into the recurrent connection of the LSTM core, outperforming the previous state-of-the-art architecture [Oh et al.]. The paper also explores various architectures, including frame-dependent/independent modes and observation/prediction-dependent architectures. Experimental results show that the proposed architecture, combined with a fully prediction-dependent training scheme, achieves state-of-the-art performance in several complex visual domains. Furthermore, the prediction architecture is shown to enhance exploration in a 3D environment.\n- Novelty\nWhile the proposed architecture does not exhibit strong novelty, its distinction from [Oh et al.] lies in the integration of actions into the LSTM, whereas [Oh et al.] combines actions after the LSTM. Notably, jumpy prediction was previously introduced by [Srivastava et al.] in the deep learning domain.\n- Experiment\nThe experimental design is thorough and well-executed, evaluating different training schemes and comparing architectures across several rich domains (Atari, 3D worlds). The proposed method achieves state-of-the-art results in many domains and demonstrates an application in model-based exploration.\n- Clarity\nThe manuscript is well-written and easy to follow, facilitating a clear understanding of the presented concepts.\n- Overall\nAlthough the novelty of the proposed architecture is limited, it yields promising results in Atari games and 3D environments. The systematic evaluation of different architectures presented in the paper will be a valuable resource for the community.\n[Reference]\nNitish Srivastava, Elman Mansimov, Ruslan Salakhutdinov. Unsupervised Learning with LSTMs. ICML 2016."
        }
    ]
}