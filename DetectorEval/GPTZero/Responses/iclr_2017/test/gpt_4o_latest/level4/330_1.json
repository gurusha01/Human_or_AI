{
    "version": "2025-01-09-base",
    "scanId": "655f96b0-a3c5-418a-a739-aa8cdb9c9079",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.5038527846336365,
                    "sentence": "This paper presents a method for generating vector representations of documents using a skip-gram style learning approach, augmented with a regularizer in the form of a global context vector and various dropout mechanisms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.25111135840415955,
                    "sentence": "While the individual components introduced in this work are not novel, I believe their combination in this particular manner is innovative.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.32326582074165344,
                    "sentence": "Additionally, I found the detailed analysis of the model's behavior in Section 3 to be insightful and well-executed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23769579827785492,
                    "sentence": "The primary limitation of this submission lies in its relatively weak empirical evaluation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1728401929140091,
                    "sentence": "There are arguably more compelling tasks than sentiment analysis and k-way classification to demonstrate the method's utility.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2230767011642456,
                    "sentence": "Similarly, dedicating 2/3 of a page to t-SNE projections feels like a missed opportunity to provide deeper analysis or evaluation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16940614581108093,
                    "sentence": "Despite my reservations about the limited evaluation and my agreement with other reviewers regarding the use of soft baselines, I believe this paper warrants acceptance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2685219645500183,
                    "sentence": "The proposed algorithm is both interesting and efficient, and it is reasonable to expect that other researchers may find value in the ideas presented here.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                }
            ],
            "completely_generated_prob": 0.09736134165188028,
            "class_probabilities": {
                "human": 0.9026386583481196,
                "ai": 0.09736134165188028,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9026386583481196,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.09736134165188028,
                    "human": 0.9026386583481196,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a method for generating vector representations of documents using a skip-gram style learning approach, augmented with a regularizer in the form of a global context vector and various dropout mechanisms. While the individual components introduced in this work are not novel, I believe their combination in this particular manner is innovative. Additionally, I found the detailed analysis of the model's behavior in Section 3 to be insightful and well-executed.\nThe primary limitation of this submission lies in its relatively weak empirical evaluation. There are arguably more compelling tasks than sentiment analysis and k-way classification to demonstrate the method's utility. Similarly, dedicating 2/3 of a page to t-SNE projections feels like a missed opportunity to provide deeper analysis or evaluation.\nDespite my reservations about the limited evaluation and my agreement with other reviewers regarding the use of soft baselines, I believe this paper warrants acceptance. The proposed algorithm is both interesting and efficient, and it is reasonable to expect that other researchers may find value in the ideas presented here."
        }
    ]
}