{
    "version": "2025-01-09-base",
    "scanId": "023ebd13-7289-4e85-808b-27d1e541264a",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9668813347816467,
                    "sentence": "This paper introduces an amortized variant of the Stein variational gradient descent (SVGD) method, where \"a neural network is trained to mimic the SVGD dynamics.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.952214241027832,
                    "sentence": "The proposed approach is applied to generative adversarial training, resulting in a training procedure that interprets the discriminator as an energy-based probabilistic model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9626876711845398,
                    "sentence": "One concern I have with the presentation is that considerable effort is devoted to framing the method as broadly applicable, yet the empirical evaluation is limited to a single specific scenario.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9601787328720093,
                    "sentence": "In my opinion, this creates a disconnect: either the paper does not adequately demonstrate the claimed wide applicability of the proposed method, or it spends too much time laying the groundwork for SteinGAN without providing sufficient empirical validation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9020808339118958,
                    "sentence": "As a result, the empirical results presented in the paper fall short of convincingly supporting the proposed approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6433417797088623,
                    "sentence": "Furthermore, as another reviewer noted, DCGAN is becoming an outdated benchmark for comparison.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5485288500785828,
                    "sentence": "From a qualitative perspective, SteinGAN samples do not appear significantly better than DCGAN samples, except for the CelebA dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.25763413310050964,
                    "sentence": "However, in that case, the DCGAN samples do not seem to match those presented in the original DCGAN paper\"\"where exactly do these samples come from?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.3205496072769165,
                    "sentence": "Quantitatively, DCGAN slightly outperforms SteinGAN on the ImageNet Inception Score, while SteinGAN marginally surpasses DCGAN on the CIFAR10 Inception Score.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.27128735184669495,
                    "sentence": "Additionally, I find the \"testing accuracy\" score to be an unconvincing evaluation metric.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.25699037313461304,
                    "sentence": "While it does measure the amount of information captured in the simulated image sets, it is limited to information relevant to the discrimination task and does not account for more general modeling capabilities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.24802985787391663,
                    "sentence": "For example, this metric is likely insensitive to information contained in the background of the images.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.2905106842517853,
                    "sentence": "For the reasons outlined above, I do not believe this paper is ready for publication at ICLR.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.3063829682933457
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.4937288086193664,
            "class_probabilities": {
                "human": 0.31246660384140834,
                "ai": 0.4937288086193664,
                "mixed": 0.1938045875392253
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.4937288086193664,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.4937288086193664,
                    "human": 0.31246660384140834,
                    "mixed": 0.1938045875392253
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper introduces an amortized variant of the Stein variational gradient descent (SVGD) method, where \"a neural network is trained to mimic the SVGD dynamics.\" The proposed approach is applied to generative adversarial training, resulting in a training procedure that interprets the discriminator as an energy-based probabilistic model.\nOne concern I have with the presentation is that considerable effort is devoted to framing the method as broadly applicable, yet the empirical evaluation is limited to a single specific scenario. In my opinion, this creates a disconnect: either the paper does not adequately demonstrate the claimed wide applicability of the proposed method, or it spends too much time laying the groundwork for SteinGAN without providing sufficient empirical validation.\nAs a result, the empirical results presented in the paper fall short of convincingly supporting the proposed approach. Furthermore, as another reviewer noted, DCGAN is becoming an outdated benchmark for comparison.\nFrom a qualitative perspective, SteinGAN samples do not appear significantly better than DCGAN samples, except for the CelebA dataset. However, in that case, the DCGAN samples do not seem to match those presented in the original DCGAN paper\"\"where exactly do these samples come from?\nQuantitatively, DCGAN slightly outperforms SteinGAN on the ImageNet Inception Score, while SteinGAN marginally surpasses DCGAN on the CIFAR10 Inception Score. Additionally, I find the \"testing accuracy\" score to be an unconvincing evaluation metric. While it does measure the amount of information captured in the simulated image sets, it is limited to information relevant to the discrimination task and does not account for more general modeling capabilities. For example, this metric is likely insensitive to information contained in the background of the images.\nFor the reasons outlined above, I do not believe this paper is ready for publication at ICLR."
        }
    ]
}