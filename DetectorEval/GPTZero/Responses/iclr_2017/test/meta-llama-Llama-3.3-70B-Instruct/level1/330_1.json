{
    "version": "2025-01-09-base",
    "scanId": "befc368d-7720-4ca9-883a-5284224c2e61",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999950528144836,
                    "sentence": "The paper \"Document Vector through Corruption (Doc2VecC)\" presents a novel approach to document representation learning, which efficiently captures the semantic meanings of documents.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999900460243225,
                    "sentence": "The authors propose a simple yet effective model architecture that represents each document as a simple average of word embeddings, while introducing a corruption model that favors informative or rare words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999903440475464,
                    "sentence": "This approach outperforms several state-of-the-art document representation learning algorithms in terms of testing efficiency and expressiveness of the generated representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999766945838928,
                    "sentence": "I decide to accept this paper, with two key reasons for this choice: (1) the approach is well-motivated and grounded in the literature, and (2) the paper provides convincing empirical evidence to support its claims.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999911785125732,
                    "sentence": "The authors demonstrate the effectiveness of their approach on several tasks, including sentiment analysis, document classification, and semantic relatedness, and show that it outperforms other methods in terms of accuracy and efficiency.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999901056289673,
                    "sentence": "The paper provides a clear and well-structured presentation of the approach, including a detailed description of the model architecture and the corruption mechanism.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999886751174927,
                    "sentence": "The authors also provide a thorough analysis of the results, including a discussion of the strengths and limitations of their approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999902248382568,
                    "sentence": "The empirical evaluation is comprehensive and well-designed, with a clear description of the experimental setup and the results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999901056289673,
                    "sentence": "To further improve the paper, I would suggest that the authors provide more insight into the corruption mechanism and its effect on the word embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999875426292419,
                    "sentence": "For example, they could provide more detailed analysis of the words that are most affected by the corruption, and how this affects the overall performance of the model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999987781047821,
                    "sentence": "Additionally, the authors could consider providing more comparison with other methods, such as those using recurrent neural networks or convolutional neural networks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999891519546509,
                    "sentence": "Some questions I would like the authors to answer to clarify my understanding of the paper include: (1) How does the corruption rate affect the performance of the model, and what is the optimal corruption rate for different tasks?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999784231185913,
                    "sentence": "(2) Can the authors provide more insight into the data-dependent regularization introduced by the corruption mechanism, and how it affects the word embeddings?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999834895133972,
                    "sentence": "(3) How does the approach handle out-of-vocabulary words, and what are the implications for tasks with limited training data?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper \"Document Vector through Corruption (Doc2VecC)\" presents a novel approach to document representation learning, which efficiently captures the semantic meanings of documents. The authors propose a simple yet effective model architecture that represents each document as a simple average of word embeddings, while introducing a corruption model that favors informative or rare words. This approach outperforms several state-of-the-art document representation learning algorithms in terms of testing efficiency and expressiveness of the generated representations.\nI decide to accept this paper, with two key reasons for this choice: (1) the approach is well-motivated and grounded in the literature, and (2) the paper provides convincing empirical evidence to support its claims. The authors demonstrate the effectiveness of their approach on several tasks, including sentiment analysis, document classification, and semantic relatedness, and show that it outperforms other methods in terms of accuracy and efficiency.\nThe paper provides a clear and well-structured presentation of the approach, including a detailed description of the model architecture and the corruption mechanism. The authors also provide a thorough analysis of the results, including a discussion of the strengths and limitations of their approach. The empirical evaluation is comprehensive and well-designed, with a clear description of the experimental setup and the results.\nTo further improve the paper, I would suggest that the authors provide more insight into the corruption mechanism and its effect on the word embeddings. For example, they could provide more detailed analysis of the words that are most affected by the corruption, and how this affects the overall performance of the model. Additionally, the authors could consider providing more comparison with other methods, such as those using recurrent neural networks or convolutional neural networks.\nSome questions I would like the authors to answer to clarify my understanding of the paper include: (1) How does the corruption rate affect the performance of the model, and what is the optimal corruption rate for different tasks? (2) Can the authors provide more insight into the data-dependent regularization introduced by the corruption mechanism, and how it affects the word embeddings? (3) How does the approach handle out-of-vocabulary words, and what are the implications for tasks with limited training data?"
        }
    ]
}