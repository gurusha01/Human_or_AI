{
    "version": "2025-01-09-base",
    "scanId": "8a1973de-505a-4b58-8d77-9bf0b3d64028",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9995487332344055,
                    "sentence": "In consideration of the authors' detailed responses and the revised manuscript, I am upgrading my evaluation to a score of 8 and reiterating my endorsement for this paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994462132453918,
                    "sentence": "I believe it has the potential to be one of the most outstanding non-traditional applied deep learning contributions at ICLR, garnering significant interest and attention from attendees.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997427463531494,
                    "sentence": "This manuscript presents a contemporary deep learning approach to predicting medications taken by patients over a period, based solely on the sequence of ICD-9 codes assigned during that time.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995368719100952,
                    "sentence": "The problem is formulated as a multilabel sequence classification task, distinct from language modeling which is typically a multiclass classification problem.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995200037956238,
                    "sentence": "The authors propose utilizing standard LSTM and GRU architectures, incorporating embedding layers to manage sparse categorical inputs, a method akin to that described in related research by Choi et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989901185035706,
                    "sentence": "Through experiments conducted on a cohort of approximately 610,000 patient records, they demonstrate that RNN models outperform robust baselines, including an MLP, a random forest, and a common sense baseline.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.998914897441864,
                    "sentence": "The performance differences between recurrent models and the MLP appear substantial enough to be significant, considering the size of the test set.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991921186447144,
                    "sentence": "The paper's strengths include:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987583756446838,
                    "sentence": "- The problem's importance, as highlighted by the authors, who note that Electronic Health Records (EHRs), widely adopted due to legislation and federal incentives, have failed to deliver on their promises of more accurate records and fewer medication errors, presenting a significant opportunity for data mining and machine learning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990565776824951,
                    "sentence": "- The manuscript is well-written, featuring a clear introduction, thorough discussion of related work, concise description of experiments and metrics, and intriguing qualitative analysis of results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991179704666138,
                    "sentence": "- The empirical results are robust, with RNNs achieving a significant win over convincing baselines, contrasting with some recent related papers where the gap between RNN and MLP performance was minimal.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999271035194397,
                    "sentence": "- The discussion is comprehensive and thoughtful, with the authors correctly interpreting the kidney code embedding results as particularly promising.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986711740493774,
                    "sentence": "However, there are weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989089965820312,
                    "sentence": "- The authors make several unconventional decisions regarding data preprocessing and experimental design, notably choosing to use truncated patient sequences ending at random time points rather than full sequences.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9980582594871521,
                    "sentence": "While this does not invalidate the results, it is somewhat counterintuitive and the explanation is challenging to follow, potentially reducing the paper's impact and the RNN's advantage.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9978412389755249,
                    "sentence": "- The chosen metrics are appropriate but may be difficult for non-experts to interpret in terms of absolute and relative performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999257504940033,
                    "sentence": "The authors should consider explaining the level of performance necessary for each metric to be clinically useful and whether the gaps between models are significant.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993405938148499,
                    "sentence": "- The paper does not propose novel methods, a significant weakness for a methods-focused conference like ICLR.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990764260292053,
                    "sentence": "Despite this, the empirical strength and application interest may warrant acceptance, but exploring additional aspects, such as the hypothesis that higher capacity models are more prone to overfitting noisy targets, could enhance competitiveness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989031553268433,
                    "sentence": "A final consideration is the paper's weakness as a clinical study: the absence of ground truth labels for missing medications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991576671600342,
                    "sentence": "Models are trained and tested on data with noisy labels, which, while not a significant issue for training if the noise is random, could skew test metrics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986479878425598,
                    "sentence": "The assumption of non-systemic label noise seems unlikely given the data's source from human clinicians.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989914894104004,
                    "sentence": "Clinical reviewers may view the paper skeptically due to this limitation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990878701210022,
                    "sentence": "The authors will need to address evaluation creatively or invest in labeling data to prove the method's efficacy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984725713729858,
                    "sentence": "Overall, I support the acceptance of this paper, believing it will be of great interest to the ICLR community.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9978179335594177,
                    "sentence": "However, addressing the reviewers' critiques, particularly the issue of overfitting to imperfect labels, could strengthen the paper and potentially lead to a higher score and stronger advocacy for its acceptance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "In consideration of the authors' detailed responses and the revised manuscript, I am upgrading my evaluation to a score of 8 and reiterating my endorsement for this paper. I believe it has the potential to be one of the most outstanding non-traditional applied deep learning contributions at ICLR, garnering significant interest and attention from attendees.\nThis manuscript presents a contemporary deep learning approach to predicting medications taken by patients over a period, based solely on the sequence of ICD-9 codes assigned during that time. The problem is formulated as a multilabel sequence classification task, distinct from language modeling which is typically a multiclass classification problem. The authors propose utilizing standard LSTM and GRU architectures, incorporating embedding layers to manage sparse categorical inputs, a method akin to that described in related research by Choi et al. Through experiments conducted on a cohort of approximately 610,000 patient records, they demonstrate that RNN models outperform robust baselines, including an MLP, a random forest, and a common sense baseline. The performance differences between recurrent models and the MLP appear substantial enough to be significant, considering the size of the test set.\nThe paper's strengths include:\n- The problem's importance, as highlighted by the authors, who note that Electronic Health Records (EHRs), widely adopted due to legislation and federal incentives, have failed to deliver on their promises of more accurate records and fewer medication errors, presenting a significant opportunity for data mining and machine learning.\n- The manuscript is well-written, featuring a clear introduction, thorough discussion of related work, concise description of experiments and metrics, and intriguing qualitative analysis of results.\n- The empirical results are robust, with RNNs achieving a significant win over convincing baselines, contrasting with some recent related papers where the gap between RNN and MLP performance was minimal.\n- The discussion is comprehensive and thoughtful, with the authors correctly interpreting the kidney code embedding results as particularly promising.\nHowever, there are weaknesses:\n- The authors make several unconventional decisions regarding data preprocessing and experimental design, notably choosing to use truncated patient sequences ending at random time points rather than full sequences. While this does not invalidate the results, it is somewhat counterintuitive and the explanation is challenging to follow, potentially reducing the paper's impact and the RNN's advantage.\n- The chosen metrics are appropriate but may be difficult for non-experts to interpret in terms of absolute and relative performance. The authors should consider explaining the level of performance necessary for each metric to be clinically useful and whether the gaps between models are significant.\n- The paper does not propose novel methods, a significant weakness for a methods-focused conference like ICLR. Despite this, the empirical strength and application interest may warrant acceptance, but exploring additional aspects, such as the hypothesis that higher capacity models are more prone to overfitting noisy targets, could enhance competitiveness.\nA final consideration is the paper's weakness as a clinical study: the absence of ground truth labels for missing medications. Models are trained and tested on data with noisy labels, which, while not a significant issue for training if the noise is random, could skew test metrics. The assumption of non-systemic label noise seems unlikely given the data's source from human clinicians. Clinical reviewers may view the paper skeptically due to this limitation. The authors will need to address evaluation creatively or invest in labeling data to prove the method's efficacy.\nOverall, I support the acceptance of this paper, believing it will be of great interest to the ICLR community. However, addressing the reviewers' critiques, particularly the issue of overfitting to imperfect labels, could strengthen the paper and potentially lead to a higher score and stronger advocacy for its acceptance."
        }
    ]
}