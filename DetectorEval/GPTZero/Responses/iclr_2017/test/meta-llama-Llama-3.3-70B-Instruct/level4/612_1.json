{
    "version": "2025-01-09-base",
    "scanId": "aeba16cf-f979-4e67-a5f3-de78981adc93",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9981893301010132,
                    "sentence": "This paper presents a framework for predicting future frames by transforming the previous frame, rather than directly predicting pixels.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9969882369041443,
                    "sentence": "However, similar approaches have been explored in prior research.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9979395270347595,
                    "sentence": "The authors claim that existing methods are deterministic, but their proposed model also fails to address multimodality.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9985285997390747,
                    "sentence": "In my previous feedback, I suggested evaluating their method using two RGB frames as input to predict the transformation as output, which would allow for a quantitative assessment of the benefits of utilizing transformations as both input and output.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991511702537537,
                    "sentence": "This is particularly relevant, as this work is the first to use transformations as input.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989469647407532,
                    "sentence": "Unfortunately, the authors misinterpreted this suggestion, responding that using RGB frames as input to predict future frames would result in blurry outputs, which was not the intended point of the proposal.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993573427200317,
                    "sentence": "As a result, the novelty of this contribution, relative to existing works, remains unclear and unvalidated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a framework for predicting future frames by transforming the previous frame, rather than directly predicting pixels. However, similar approaches have been explored in prior research. The authors claim that existing methods are deterministic, but their proposed model also fails to address multimodality. \nIn my previous feedback, I suggested evaluating their method using two RGB frames as input to predict the transformation as output, which would allow for a quantitative assessment of the benefits of utilizing transformations as both input and output. This is particularly relevant, as this work is the first to use transformations as input. Unfortunately, the authors misinterpreted this suggestion, responding that using RGB frames as input to predict future frames would result in blurry outputs, which was not the intended point of the proposal. As a result, the novelty of this contribution, relative to existing works, remains unclear and unvalidated."
        }
    ]
}