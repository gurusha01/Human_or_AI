{
    "version": "2025-01-09-base",
    "scanId": "6af02302-c1c2-462c-81df-52bf622d1b28",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.17639414966106415,
                    "sentence": "This paper is about learning unsupervised state representations using multi-task reinforcement learning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19988709688186646,
                    "sentence": "The authors propose a novel approach combining gated neural networks with multitask learning with robotics priors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.20245666801929474,
                    "sentence": "They evaluated their approach on two simulated datasets and showed promising results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17530420422554016,
                    "sentence": "The paper is clearly written and is theoretically sound.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.24231292307376862,
                    "sentence": "Positives:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.22804147005081177,
                    "sentence": "+ Gating to enable learning a joint representation",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1519167125225067,
                    "sentence": "+ Multi-task learning extended from a single task in prior work",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12545634806156158,
                    "sentence": "+ Combining multiple types of losses to learn a strong representation (Coherence, Proportionality, Causality, Repeatability, Consistency and Separation)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12020339071750641,
                    "sentence": "Negatives:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18981394171714783,
                    "sentence": "- Parameters choice is arbitrary (w parameters)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17802920937538147,
                    "sentence": "- Limiting the multi-task learning to be different to individual tasks rather than sharing and transferring knowledge between tasks",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19540056586265564,
                    "sentence": "- The experiments could have been conducted using a standardized simulation tool such as OpenAI Gym to make it easy to compare.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2234594076871872,
                    "sentence": "I would recommend that the authors consider a more standardized way of picking the model parameters and evaluate on a more standard and high-dimensional datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.04094257758090865,
            "class_probabilities": {
                "human": 0.9587663676756332,
                "ai": 0.04094257758090865,
                "mixed": 0.0002910547434582826
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9587663676756332,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.04094257758090865,
                    "human": 0.9587663676756332,
                    "mixed": 0.0002910547434582826
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper is about learning unsupervised state representations using multi-task reinforcement learning. The authors propose a novel approach combining gated neural networks with multitask learning with robotics priors. They evaluated their approach on two simulated datasets and showed promising results. The paper is clearly written and is theoretically sound.\nPositives:\n+ Gating to enable learning a joint representation\n+ Multi-task learning extended from a single task in prior work\n+ Combining multiple types of losses to learn a strong representation (Coherence, Proportionality, Causality, Repeatability, Consistency and Separation)\nNegatives:\n- Parameters choice is arbitrary (w parameters)\n- Limiting the multi-task learning to be different to individual tasks rather than sharing and transferring knowledge between tasks\n- The experiments could have been conducted using a standardized simulation tool such as OpenAI Gym to make it easy to compare.\nI would recommend that the authors consider a more standardized way of picking the model parameters and evaluate on a more standard and high-dimensional datasets."
        }
    ]
}