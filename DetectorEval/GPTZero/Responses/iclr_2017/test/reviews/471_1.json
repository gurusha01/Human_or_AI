{
    "version": "2025-01-09-base",
    "scanId": "de9b5ad6-81b1-415c-a0b9-0c560c9b84db",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.13255728781223297,
                    "sentence": "This paper extends neural conversational models into the batch reinforcement learning setting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09172837436199188,
                    "sentence": "The idea is that you can collect human scoring data for some responses from a dialogue model, however such scores are expensive.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12149106711149216,
                    "sentence": "Thus, it is natural to use off-policy learning \"\" training a base policy on unsupervised data, deploying that policy to collect human scores, and then learning off-line from those scores.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11243102699518204,
                    "sentence": "While the overall contribution is modest (extending off-policy actor-critic to the application of dialogue generation), the approach is well-motivated, and the paper is written clearly and is easy to understand.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12993557751178741,
                    "sentence": "My main concern is that the primary dataset used (restaurant recommendations) is very small (6000 conversations).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07406233996152878,
                    "sentence": "In fact, it is several orders of magnitude smaller than other datasets used in the literature (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18048465251922607,
                    "sentence": "Twitter, the Ubuntu Dialogue Corpus) for dialogue generation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1183256208896637,
                    "sentence": "It is a bit surprising to me that RNN chatbots (with no additional structure) are able to generate reasonable utterances on such a small dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2412317991256714,
                    "sentence": "Wen et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08228146284818649,
                    "sentence": "(2016) are able to do this on a similarly small restaurant dataset, but this is mostly because they map directly from dialogue states to surface form, rather than some embedding representation of the context.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1886412650346756,
                    "sentence": "Thus, it remains to be seen if the approaches in this paper also result in improvements when much more unsupervised data is available.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.32968416810035706,
                    "sentence": "References:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4191041886806488,
                    "sentence": "Wen, Tsung-Hsien, Milica Gasic, Nikola Mrksic, Lina M. Rojas-Barahona, Pei-Hao Su, Stefan Ultes, David Vandyke, and Steve Young.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5703877806663513,
                    "sentence": "\"A Network-based End-to-End Trainable Task-oriented Dialogue System.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6626534461975098,
                    "sentence": "arXiv preprint arXiv:1604.04562 (2016).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 7,
                    "completely_generated_prob": 2.1228438805416278e-06
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                }
            ],
            "completely_generated_prob": 0.24256741654484168,
            "class_probabilities": {
                "human": 0.7573578272058379,
                "ai": 0.24256741654484168,
                "mixed": 7.475624932039773e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.7573578272058379,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.24256741654484168,
                    "human": 0.7573578272058379,
                    "mixed": 7.475624932039773e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper extends neural conversational models into the batch reinforcement learning setting. The idea is that you can collect human scoring data for some responses from a dialogue model, however such scores are expensive. Thus, it is natural to use off-policy learning \"\" training a base policy on unsupervised data, deploying that policy to collect human scores, and then learning off-line from those scores.\nWhile the overall contribution is modest (extending off-policy actor-critic to the application of dialogue generation), the approach is well-motivated, and the paper is written clearly and is easy to understand. \nMy main concern is that the primary dataset used (restaurant recommendations) is very small (6000 conversations). In fact, it is several orders of magnitude smaller than other datasets used in the literature (e.g. Twitter, the Ubuntu Dialogue Corpus) for dialogue generation. It is a bit surprising to me that RNN chatbots (with no additional structure) are able to generate reasonable utterances on such a small dataset. Wen et al. (2016) are able to do this on a similarly small restaurant dataset, but this is mostly because they map directly from dialogue states to surface form, rather than some embedding representation of the context. Thus, it remains to be seen if the approaches in this paper also result in improvements when much more unsupervised data is available.\nReferences:\nWen, Tsung-Hsien, Milica Gasic, Nikola Mrksic, Lina M. Rojas-Barahona, Pei-Hao Su, Stefan Ultes, David Vandyke, and Steve Young. \"A Network-based End-to-End Trainable Task-oriented Dialogue System.\" arXiv preprint arXiv:1604.04562 (2016)."
        }
    ]
}