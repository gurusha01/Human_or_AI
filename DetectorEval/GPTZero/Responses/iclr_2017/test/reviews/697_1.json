{
    "version": "2025-01-09-base",
    "scanId": "00bee371-123a-4949-a819-53abd8a8f007",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.028313223272562027,
                    "sentence": "The paper considers Grassmannian SGD to optimize the skip gram negative sampling (SGNS) objective for learning better word embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017308395355939865,
                    "sentence": "It is not clear why the proposed optimization approach has any advantage over the existing vanilla SGD-based approach - neither approach comes with theoretical guarantees - the empirical comparisons show marginal improvements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.041393280029296875,
                    "sentence": "Furthermore, the key idea here - that of projector splitting algorithm - has been applied on numerous occasions to machine learning problems - see references by Vandereycken on matrix completion and by Sepulchre on matrix factorization.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.022141605615615845,
                    "sentence": "The computational cost of the two approaches is not carefully discussed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.028944801539182663,
                    "sentence": "For instance, how expensive is the SVD in (7)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.047228168696165085,
                    "sentence": "One can always perform an efficient low-rank update to the SVD - therefore, a rank one update requires O(nd) operations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03783256188035011,
                    "sentence": "What is the computational cost of each iteration of the proposed approach?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                }
            ],
            "completely_generated_prob": 0.058471088130131146,
            "class_probabilities": {
                "human": 0.9415289118698688,
                "ai": 0.058471088130131146,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9415289118698688,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.058471088130131146,
                    "human": 0.9415289118698688,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper considers Grassmannian SGD to optimize the skip gram negative sampling (SGNS) objective for learning better word embeddings. It is not clear why the proposed optimization approach has any advantage over the existing vanilla SGD-based approach - neither approach comes with theoretical guarantees - the empirical comparisons show marginal improvements. Furthermore, the key idea here - that of projector splitting algorithm - has been applied on numerous occasions to machine learning problems - see references by Vandereycken on matrix completion and by Sepulchre on matrix factorization. \nThe computational cost of the two approaches is not carefully discussed. For instance, how expensive is the SVD in (7)? One can always perform an efficient low-rank update to the SVD - therefore, a rank one update requires O(nd) operations. What is the computational cost of each iteration of the proposed approach?"
        }
    ]
}