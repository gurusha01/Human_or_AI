{
    "version": "2025-01-09-base",
    "scanId": "ea8f2a3e-bf41-45fa-9007-341e3071ef58",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0016304681776091456,
                    "sentence": "This paper proposes the graph convolutional networks, motivated from approximating graph convolutions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0021253926679491997,
                    "sentence": "In one propagation step, what the model does can be simplified as, first linearly transform the node representations for each node, and then multiply the transformed node representations with the normalized affinity matrix (with self-connections added), and then pass through nonlinearity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002017046557739377,
                    "sentence": "This model is used for semi-supervised learning on graphs, and in the experiments it demonstrated quite impressive results compared to other baselines, outperforming them by a significant margin.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002517581218853593,
                    "sentence": "The evaluation of propagation model is also interesting, where different variants of the model and design decisions are evaluated and compared.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001844875980168581,
                    "sentence": "It is surprising that such a simple model works so much better than all the baselines.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001838139956817031,
                    "sentence": "Considering that the model used is just a two-layer model in most experiments, this is really surprising as a two-layer model is very local, and the output of a node can only be affected by nodes in a 2-hop neighborhood, and no longer range interactions can play any roles in this.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0018004330340772867,
                    "sentence": "Since computation is quite efficient (sec.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0018137667793780565,
                    "sentence": "6.3), I wonder if adding more layers helped anything or not.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001304086996242404,
                    "sentence": "Even though motivated from graph convolutions, when simplified as the paper suggests, the operations the model does are quite simple.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0017573358491063118,
                    "sentence": "Compared to Duvenaud et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002312645548954606,
                    "sentence": "2015 and Li et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009561675833538175,
                    "sentence": "2016, the proposed method is simpler and does almost strictly less things.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0018051498336717486,
                    "sentence": "So how would the proposed GCN compare against these methods?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001880541443824768,
                    "sentence": "Overall I think this model is simple, but the connection to graph convolutions is interesting, and the experiment results are quite good.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002342271851375699,
                    "sentence": "There are a few questions that still remain, but I feel this paper can be accepted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.00010005932717626924
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                }
            ],
            "completely_generated_prob": 0.009998674697021016,
            "class_probabilities": {
                "human": 0.990001325302979,
                "ai": 0.009998674697021016,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.990001325302979,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.009998674697021016,
                    "human": 0.990001325302979,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes the graph convolutional networks, motivated from approximating graph convolutions. In one propagation step, what the model does can be simplified as, first linearly transform the node representations for each node, and then multiply the transformed node representations with the normalized affinity matrix (with self-connections added), and then pass through nonlinearity.\nThis model is used for semi-supervised learning on graphs, and in the experiments it demonstrated quite impressive results compared to other baselines, outperforming them by a significant margin. The evaluation of propagation model is also interesting, where different variants of the model and design decisions are evaluated and compared.\nIt is surprising that such a simple model works so much better than all the baselines. Considering that the model used is just a two-layer model in most experiments, this is really surprising as a two-layer model is very local, and the output of a node can only be affected by nodes in a 2-hop neighborhood, and no longer range interactions can play any roles in this. Since computation is quite efficient (sec. 6.3), I wonder if adding more layers helped anything or not.\nEven though motivated from graph convolutions, when simplified as the paper suggests, the operations the model does are quite simple. Compared to Duvenaud et al. 2015 and Li et al. 2016, the proposed method is simpler and does almost strictly less things. So how would the proposed GCN compare against these methods?\nOverall I think this model is simple, but the connection to graph convolutions is interesting, and the experiment results are quite good. There are a few questions that still remain, but I feel this paper can be accepted."
        }
    ]
}