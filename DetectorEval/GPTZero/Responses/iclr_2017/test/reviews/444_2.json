{
    "version": "2025-01-09-base",
    "scanId": "aa812f03-9fae-46c8-ab95-5686baff0c71",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0527518093585968,
                    "sentence": "This work proposes a pattern extraction method to both understand what a trained LSTM has learnt and to allow implementation of a hand-coded algorithm that performs similarly to the LSTM.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03823864459991455,
                    "sentence": "Good results are shown on one dataset for one model architecture so it is unclear how well this approach will generalize, however, it seems it will be a useful way to understand and debug models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.029770921915769577,
                    "sentence": "The questions in WikiMovies seem to be generated from templates and so this pattern matching approach will likely work well.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03650680556893349,
                    "sentence": "However, from the experiments it's not clear if this will extend to other types of Q&A tasks where the answer may be free form text and not be a substring in the document.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03781300410628319,
                    "sentence": "Is the model required to produce a continuous span over the original document?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.046915698796510696,
                    "sentence": "The approach also seems to have some deficiencies in how it handles word types such as numbers or entity names.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.021294105798006058,
                    "sentence": "This can be encoded in the embedding for the word but from the description of the algorithm, it seems that the approach requires an entity detector.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02674390748143196,
                    "sentence": "Does this mean that the approach is unable to determine when it has reached an entity from the decomposition of the output of the LSTM?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03421755135059357,
                    "sentence": "The results where 'manual pattern matching' where explicit year annotations are used, seem to show that the automatic method is unable to deal with word types.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02582472749054432,
                    "sentence": "It would also be good to see an attention model as a baseline in addition to the gradient-based baseline.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.057018958032131195,
                    "sentence": "Minor comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03525838255882263,
                    "sentence": "- P and Q seem to be undefined.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03077618032693863,
                    "sentence": "- Some references seem to be bad, e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02796974591910839,
                    "sentence": "in section 5.1: 'in 1' instead of 'in table 1'.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02147149294614792,
                    "sentence": "Similarly above section 7: 'as shown in 3' and in section 7.1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01128141675144434,
                    "sentence": "- In the paragraph above section 6.3: 'adam' -> 'Adam'.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.06633669730667867,
            "class_probabilities": {
                "human": 0.9336633026933213,
                "ai": 0.06633669730667867,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9336633026933213,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.06633669730667867,
                    "human": 0.9336633026933213,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This work proposes a pattern extraction method to both understand what a trained LSTM has learnt and to allow implementation of a hand-coded algorithm that performs similarly to the LSTM. Good results are shown on one dataset for one model architecture so it is unclear how well this approach will generalize, however, it seems it will be a useful way to understand and debug models.\nThe questions in WikiMovies seem to be generated from templates and so this pattern matching approach will likely work well. However, from the experiments it's not clear if this will extend to other types of Q&A tasks where the answer may be free form text and not be a substring in the document. Is the model required to produce a continuous span over the original document?\nThe approach also seems to have some deficiencies in how it handles word types such as numbers or entity names. This can be encoded in the embedding for the word but from the description of the algorithm, it seems that the approach requires an entity detector. Does this mean that the approach is unable to determine when it has reached an entity from the decomposition of the output of the LSTM? The results where 'manual pattern matching' where explicit year annotations are used, seem to show that the automatic method is unable to deal with word types.\nIt would also be good to see an attention model as a baseline in addition to the gradient-based baseline.\nMinor comments:\n- P and Q seem to be undefined.\n- Some references seem to be bad, e.g. in section 5.1: 'in 1' instead of 'in table 1'. Similarly above section 7: 'as shown in 3' and in section 7.1.\n- In the paragraph above section 6.3: 'adam' -> 'Adam'."
        }
    ]
}