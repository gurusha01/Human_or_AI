{
    "version": "2025-01-09-base",
    "scanId": "8b561a38-8814-433d-8bc3-773465684550",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.03248792886734009,
                    "sentence": "Sorry for the late review -- I've been having technical problems with OpenReview which prevented me from posting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13414190709590912,
                    "sentence": "This paper presents a method for learning to predict things from sets of data points.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06268074363470078,
                    "sentence": "The method is a hierarchical version of the VAE, where the top layer consists of an abstract context unit that summarizes a dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0880511924624443,
                    "sentence": "Experiments show that the method is able to \"learn to learn\" by acquiring the ability to learn distributions from small numbers of examples.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.061741773039102554,
                    "sentence": "Overall, this paper is a nice addition to the literature on one- or few-shot learning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1420690417289734,
                    "sentence": "The method is conceptually simple and elegant, and seems to perform well.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1513226181268692,
                    "sentence": "Compared to other recent papers on one-shot learning, the proposed method is simpler, and is based on unsupervised representation learning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0986117497086525,
                    "sentence": "The paper is clearly written and a pleasure to read.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16228888928890228,
                    "sentence": "The name of the paper is overly grandiose relative to what was done; the proposed method doesn't seem to have much in common with a statistician, unless one means by that \"someone who thinks up statistics\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.299028605222702,
                    "sentence": "The experiments are well chosen, and the few-shot learning results seem pretty solid given the simplicity of the method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16833674907684326,
                    "sentence": "The spatial MNIST dataset is interesting and might make a good toy benchmark.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3420328199863434,
                    "sentence": "The inputs in Figure 4 seem pretty dense, though; shouldn't the method be able to recognize the distribution with fewer samples?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3962910771369934,
                    "sentence": "(Nitpick: the red points in Figure 4 don't seem to correspond to meaningful points as was claimed in the text.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6287018060684204,
                    "sentence": "Will the authors release the code?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.06633669730667867,
            "class_probabilities": {
                "human": 0.9336633026933213,
                "ai": 0.06633669730667867,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9336633026933213,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.06633669730667867,
                    "human": 0.9336633026933213,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Sorry for the late review -- I've been having technical problems with OpenReview which prevented me from posting.\nThis paper presents a method for learning to predict things from sets of data points. The method is a hierarchical version of the VAE, where the top layer consists of an abstract context unit that summarizes a dataset. Experiments show that the method is able to \"learn to learn\" by acquiring the ability to learn distributions from small numbers of examples.\nOverall, this paper is a nice addition to the literature on one- or few-shot learning. The method is conceptually simple and elegant, and seems to perform well. Compared to other recent papers on one-shot learning, the proposed method is simpler, and is based on unsupervised representation learning. The paper is clearly written and a pleasure to read.\nThe name of the paper is overly grandiose relative to what was done; the proposed method doesn't seem to have much in common with a statistician, unless one means by that \"someone who thinks up statistics\". \nThe experiments are well chosen, and the few-shot learning results seem pretty solid given the simplicity of the method.\nThe spatial MNIST dataset is interesting and might make a good toy benchmark. The inputs in Figure 4 seem pretty dense, though; shouldn't the method be able to recognize the distribution with fewer samples? (Nitpick: the red points in Figure 4 don't seem to correspond to meaningful points as was claimed in the text.) \nWill the authors release the code?"
        }
    ]
}