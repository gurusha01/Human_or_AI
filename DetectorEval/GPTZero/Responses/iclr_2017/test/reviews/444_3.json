{
    "version": "2025-01-09-base",
    "scanId": "44d69acd-c793-4d55-b771-9520204922a7",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9770737290382385,
                    "sentence": "This paper proposes a novel method for extracting rule-based classifiers from trained LSTM models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9521809220314026,
                    "sentence": "The proposed method is applied to a factoid question-answering task, where it is demonstrated that the extracted rules perform comparatively to the original LSTM.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9042450785636902,
                    "sentence": "The analysis of the extracted rules illustrate the features the LSTM model picks up on.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8570582866668701,
                    "sentence": "Analyzing and visualizing the computations carried out by RNNs in order to understand the functions they compute is an important direction of research.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8539004921913147,
                    "sentence": "This sort of analysis will help us understand the pitfalls of RNNs, and how we can improve them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8825523257255554,
                    "sentence": "Although the approach taken is relatively inflexible - each rule is defined as an ordered sequence of words - the authors experiment with three different scores for picking salient words (state-difference, cell-difference and gradient) and their approach yields comparable performance, which suggests that the extracted rules mimic the RNN closely.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9100919961929321,
                    "sentence": "The results are also somewhat surprising, since most of the rules consist only of two or three words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.94029301404953,
                    "sentence": "It would have been interesting to try extend the approach on other natural language processing tasks, such as machine translation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8942240476608276,
                    "sentence": "Presumably the rules learned here will be quite different.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9246410727500916,
                    "sentence": "Other comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9851658940315247,
                    "sentence": "- Eq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.962358832359314,
                    "sentence": "(12) is over-parametrized with two vectors $P$ and $Q$.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9309498071670532,
                    "sentence": "The same function can be computed with a single vector.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9685851335525513,
                    "sentence": "This becomes clear when you divide both the numerator and denominator by $e^{P h_t}$.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9546157717704773,
                    "sentence": "- Section 4.1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9448567628860474,
                    "sentence": "Is it correct that this section is focused on the forward LSTM?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9140591621398926,
                    "sentence": "If so, please clarify it in the text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.969903826713562,
                    "sentence": "- In Eq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9746216535568237,
                    "sentence": "(13), define $c_0 = 0$.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.971424400806427,
                    "sentence": "- Eq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9528011083602905,
                    "sentence": "(13) is exactly the same as Eq.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9592019319534302,
                    "sentence": "(15).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9377576112747192,
                    "sentence": "Is there a mistake?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9583691954612732,
                    "sentence": "- In Table 1, third column should have word \"film\" highlighted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9735736846923828,
                    "sentence": "- \"are shown in 2\" -> \"are shown in Table 2\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9674915075302124,
                    "sentence": "- Since there are some problems representing numbers, it may help to replace each digit with the hashtag symbol.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.8119739381064363,
            "class_probabilities": {
                "human": 0.18679001347792185,
                "ai": 0.8119739381064363,
                "mixed": 0.0012360484156418805
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8119739381064363,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8119739381064363,
                    "human": 0.18679001347792185,
                    "mixed": 0.0012360484156418805
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes a novel method for extracting rule-based classifiers from trained LSTM models. The proposed method is applied to a factoid question-answering task, where it is demonstrated that the extracted rules perform comparatively to the original LSTM. The analysis of the extracted rules illustrate the features the LSTM model picks up on.\nAnalyzing and visualizing the computations carried out by RNNs in order to understand the functions they compute is an important direction of research. This sort of analysis will help us understand the pitfalls of RNNs, and how we can improve them. Although the approach taken is relatively inflexible - each rule is defined as an ordered sequence of words - the authors experiment with three different scores for picking salient words (state-difference, cell-difference and gradient) and their approach yields comparable performance, which suggests that the extracted rules mimic the RNN closely. The results are also somewhat surprising, since most of the rules consist only of two or three words.\nIt would have been interesting to try extend the approach on other natural language processing tasks, such as machine translation. Presumably the rules learned here will be quite different.\nOther comments:\n- Eq. (12) is over-parametrized with two vectors $P$ and $Q$. The same function can be computed with a single vector. This becomes clear when you divide both the numerator and denominator by $e^{P h_t}$.\n- Section 4.1. Is it correct that this section is focused on the forward LSTM? If so, please clarify it in the text.\n- In Eq. (13), define $c_0 = 0$.\n- Eq. (13) is exactly the same as Eq. (15). Is there a mistake?\n- In Table 1, third column should have word \"film\" highlighted.\n- \"are shown in 2\" -> \"are shown in Table 2\".\n- Since there are some problems representing numbers, it may help to replace each digit with the hashtag symbol ."
        }
    ]
}