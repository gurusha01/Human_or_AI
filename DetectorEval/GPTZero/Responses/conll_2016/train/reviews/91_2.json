{
    "version": "2025-01-09-base",
    "scanId": "a5537e3a-6a85-48d7-9739-27389b6a6981",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.005244302563369274,
                    "sentence": "This paper applies the idea of translation model pruning to neural MT.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012531789019703865,
                    "sentence": "The",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004311099648475647,
                    "sentence": "authors explore three simple threshold and histogram pruning schemes, two of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00581749202683568,
                    "sentence": "which are applied separately to each weight class, while the third is applied",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004143014084547758,
                    "sentence": "to the entire model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004854596219956875,
                    "sentence": "The authors also show that retraining the models produces",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004576725885272026,
                    "sentence": "performance equal to the full model, even when 90% of the weights are pruned.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00320307700894773,
                    "sentence": "An extensive analysis explains the superiority of the class-blind pruning",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0033988775685429573,
                    "sentence": "scheme, as well as the performance boost through retraining.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003000842873007059,
                    "sentence": "While the main idea of the paper is simple, it seems quite useful for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004958122503012419,
                    "sentence": "memory-restricted applications of NMT.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0037789619527757168,
                    "sentence": "I particularly liked the analysis",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003585255704820156,
                    "sentence": "section which gives further insight into the model components that are usually",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00415078504011035,
                    "sentence": "treated like black boxes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0024017547257244587,
                    "sentence": "While these insights are interesting by themselves,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004195360466837883,
                    "sentence": "the paper's main motivation is model compression.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001982836751267314,
                    "sentence": "This argument would be",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0033418156672269106,
                    "sentence": "stronger if the paper included some numbers on actual memory consumption of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0030378601513803005,
                    "sentence": "compressed model in comparison to the uncompressed model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0028447166550904512,
                    "sentence": "Some minor remarks:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0023404289968311787,
                    "sentence": "- There is a substantial amount of work on pruning translation models in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0032867491245269775,
                    "sentence": "phrase-based SMT, which could be referenced in related work, e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0036214443389326334,
                    "sentence": "Johnson, J., Martin, J., Foster, G. and Kuhn, R.: Improving Translation Quality",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003739908803254366,
                    "sentence": "by Discarding Most of the Phrasetable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006591155659407377,
                    "sentence": "EMNLP 07 or",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0037798581179231405,
                    "sentence": "Zens, R., Stanton, D. and Peng X.: A Systematic Comparison of Phrase Table",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002866921480745077,
                    "sentence": "Pruning Techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006951855029910803,
                    "sentence": "EMNLP 12",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0029541258700191975,
                    "sentence": "- It took me a while to understand Figure 5.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0028101319912821054,
                    "sentence": "I would find it more informative",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009176734834909439,
                    "sentence": "to add an additional barplot under figure 4 showing highest discarded weight",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010616070590913296,
                    "sentence": "magnitude by class.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00729293143376708,
                    "sentence": "This would also allow a comparison across all pruning",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010304226540029049,
                    "sentence": "methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.024462635563563526,
            "class_probabilities": {
                "human": 0.9755373644364365,
                "ai": 0.024462635563563526,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9755373644364365,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.024462635563563526,
                    "human": 0.9755373644364365,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper applies the idea of translation model pruning to neural MT. The\nauthors explore three simple threshold and histogram pruning schemes, two of\nwhich are applied separately to each weight class, while the third is applied\nto the entire model. The authors also show that retraining the models produces\nperformance equal to the full model, even when 90% of the weights are pruned.\nAn extensive analysis explains the superiority of the class-blind pruning\nscheme, as well as the performance boost through retraining. \nWhile the main idea of the paper is simple, it seems quite useful for\nmemory-restricted applications of NMT. I particularly liked the analysis\nsection which gives further insight into the model components that are usually\ntreated like black boxes. While these insights are interesting by themselves,\nthe paper's main motivation is model compression. This argument would be\nstronger if the paper included some numbers on actual memory consumption of the\ncompressed model in comparison to the uncompressed model. \nSome minor remarks:\n- There is a substantial amount of work on pruning translation models in\nphrase-based SMT, which could be referenced in related work, e.g. \nJohnson, J., Martin, J., Foster, G. and Kuhn, R.: Improving Translation Quality\nby Discarding Most of the Phrasetable. EMNLP 07 or\nZens, R., Stanton, D. and Peng X.: A Systematic Comparison of Phrase Table\nPruning Techniques. EMNLP 12\n- It took me a while to understand Figure 5. I would find it more informative\nto add an additional barplot under figure 4 showing highest discarded weight\nmagnitude by class. This would also allow a comparison across all pruning\nmethods."
        }
    ]
}