{
    "version": "2025-01-09-base",
    "scanId": "8342f5d0-b2c0-4f2a-a3a8-70c38d2742a9",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.005349184852093458,
                    "sentence": "The authors present a new version of the coreference task tailored to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006580875720828772,
                    "sentence": "Wikipedia.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004839078523218632,
                    "sentence": "The task is to identify the coreference chain specifically",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0027204689104110003,
                    "sentence": "corresponding to the entity that the Wikipedia article is about.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004174634348601103,
                    "sentence": "The authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0049699293449521065,
                    "sentence": "annotate 30 documents with all coreference chains, of which roughly 25% of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007119908928871155,
                    "sentence": "mentions refer to the \"main concept\" of the article.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0044286916963756084,
                    "sentence": "They then describe some",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002746429294347763,
                    "sentence": "simple baselines and a basic classifier which outperforms these.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0040029967203736305,
                    "sentence": "Moreover, they",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004410451278090477,
                    "sentence": "integrate their classifier into the Stanford (rule-based) coreference system",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0072951046749949455,
                    "sentence": "and see substantial benefit over all state-of-the-art systems on Wikipedia.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004417591728270054,
                    "sentence": "I think this paper proposes an interesting twist on coreference that makes good",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004778779111802578,
                    "sentence": "sense from an information extraction perspective, has the potential to somewhat",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0030620540492236614,
                    "sentence": "revitalize and shake up coreference research, and might bridge the gap in an",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006558891385793686,
                    "sentence": "interesting way between coreference literature and entity linking literature.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0027468272019177675,
                    "sentence": "I am sometimes unimpressed by papers that dredge up a new task that standard",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0019361709710210562,
                    "sentence": "systems perform poorly on and then propose a tweak so that their system does",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009881547885015607,
                    "sentence": "better.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0023537632077932358,
                    "sentence": "However, in this case, the actual task itself is quite motivating to me",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.002014875877648592,
                    "sentence": "and rather than the authors fishing for a new domain to run things in, it",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0041770231910049915,
                    "sentence": "really does feel like \"hey, wait, these standard systems perform poorly in a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006377988029271364,
                    "sentence": "setting that's actually pretty important.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0073963189497590065,
                    "sentence": "THE TASK: Main concept resolution is an intriguing task from an IE perspective.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00506607536226511,
                    "sentence": "I can imagine many times where documents revolve primarily around a particular",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008315385319292545,
                    "sentence": "entity (biographical documents, dossiers or briefings about a person or event,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006375549361109734,
                    "sentence": "clinical records, etc.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003907037898898125,
                    "sentence": "and where the information we care about extracting is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008439156226813793,
                    "sentence": "specific to that entity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009053962305188179,
                    "sentence": "The standard coreference task has always had the issue",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005093781743198633,
                    "sentence": "of large numbers of mentions that would seemingly be pretty irrelevant for most",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004121988080441952,
                    "sentence": "IE problems (like generic mentions), and this task is unquestionably composed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004043944180011749,
                    "sentence": "of mentions that actually do matter.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003970544785261154,
                    "sentence": "From a methodology standpoint, the notion of a \"main concept\" provides a bit of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0039443098939955235,
                    "sentence": "a discourse anchor that is useful for coreference, but there appears to still",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004112159367650747,
                    "sentence": "be substantial overhead to improve beyond the baselines, particularly on",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007650416344404221,
                    "sentence": "non-pronominal mentions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0042760418727993965,
                    "sentence": "Doing coreference directly on Wikipedia also opens the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00442247511819005,
                    "sentence": "doors for more interesting use of knowledge, which the authors illustrate here.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003326520323753357,
                    "sentence": "So I think this domain is likely to be an interesting testbed for ideas which",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0031824724283069372,
                    "sentence": "would improve coreference overall, but which in the general setting would be",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006791302002966404,
                    "sentence": "more difficult to get robust improvements with and which would be dwarfed by",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010749511420726776,
                    "sentence": "the amount of work dealing with other aspects of the problem.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005394495092332363,
                    "sentence": "Moreover, unlike past work which has carved off a slice of coreference (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005341945681720972,
                    "sentence": "the Winograd schema work), this paper makes a big impact on the metrics of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007129761390388012,
                    "sentence": "overall coreference problem on a domain (Wikipedia) that many in the ACL",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008313764818012714,
                    "sentence": "community are pretty interested in.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008305685594677925,
                    "sentence": "THE TECHNIQUES: Overall, the techniques are not the strong point of this paper,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007995924912393093,
                    "sentence": "though they do seem to be effective.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009757629595696926,
                    "sentence": "The features seem pretty sensible, but it",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007498794700950384,
                    "sentence": "seems like additional conjunctions of these may help (and it's unclear whether",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005317786242812872,
                    "sentence": "the authors did any experimentation in this vein).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006914416793733835,
                    "sentence": "The authors should also",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010736748576164246,
                    "sentence": "state earlier in the work that their primary MC resolution system is a binary",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010730229318141937,
                    "sentence": "classifier; this is not explicitly stated early enough and the model is left",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006648221053183079,
                    "sentence": "undefined throughout the description of featurization.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02153542824089527,
                    "sentence": "MINOR DETAILS:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008026925846934319,
                    "sentence": "Organization: I would perhaps introduce the dataset immediately after \"Related",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005849855486303568,
                    "sentence": "Works\" (i.e.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009864188730716705,
                    "sentence": "have it be the new Section 3) so that concrete results can be",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013621794991195202,
                    "sentence": "given in \"Baselines\", further motivating \"Approach\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014427397400140762,
                    "sentence": "When Section 4 refers to Dcoref and Scoref, you should cite the Stanford papers",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011165698990225792,
                    "sentence": "or make it clear that it's the Stanford coreference system (many will be",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013265589252114296,
                    "sentence": "unfamiliar with the Dcoref/Scoref names).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.014664579182863235,
                    "sentence": "The use of the term \"candidate list\" was unclear, especially in the following:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.016544394195079803,
                    "sentence": "\"We leverage the hyperlink structure of the article in order to enrich the list",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025540823116898537,
                    "sentence": "of mentions with shallow semantic attributes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013642772100865841,
                    "sentence": "For each link found within the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018787074834108353,
                    "sentence": "article under consideration, we look through the candidate list for all",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013434747233986855,
                    "sentence": "mentions that match the surface string of the link.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.011108255945146084,
                    "sentence": "Please make it clear that the \"candidate list\" is the set of mentions in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009624624624848366,
                    "sentence": "article that are possible candidates for being coreferent with the MC.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013013397343456745,
                    "sentence": "I think",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008420441299676895,
                    "sentence": "most readers will understand that this module is supposed to import semantic",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006886473391205072,
                    "sentence": "information from the link structure of Wikipedia (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010460283607244492,
                    "sentence": "if a mention is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009168772958219051,
                    "sentence": "hyperlinked to an article that is female in Freebase, that mention is female),",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01170189119875431,
                    "sentence": "so try to keep the terminology clear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03399261459708214,
                    "sentence": "Section 6.1 says \"we consider the union of WCR mentions and all mentions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03788014128804207,
                    "sentence": "predicted by the method described in (Raghunathan et al., 2010).\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09438977390527725,
                    "sentence": "However,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02771918661892414,
                    "sentence": "Section 4.1 implies that these are the same?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09151636064052582,
                    "sentence": "I'm missing where additional WCR",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0701063722372055,
                    "sentence": "mentions would be extracted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 63,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 64,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 65,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 66,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 68,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 69,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 70,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 71,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 73,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 74,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 76,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 77,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 78,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 79,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 81,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 83,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.0261024689270432,
            "class_probabilities": {
                "human": 0.9731394009119056,
                "ai": 0.0261024689270432,
                "mixed": 0.0007581301610510362
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9731394009119056,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.0261024689270432,
                    "human": 0.9731394009119056,
                    "mixed": 0.0007581301610510362
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The authors present a new version of the coreference task tailored to\nWikipedia. The task is to identify the coreference chain specifically\ncorresponding to the entity that the Wikipedia article is about. The authors\nannotate 30 documents with all coreference chains, of which roughly 25% of the\nmentions refer to the \"main concept\" of the article. They then describe some\nsimple baselines and a basic classifier which outperforms these. Moreover, they\nintegrate their classifier into the Stanford (rule-based) coreference system\nand see substantial benefit over all state-of-the-art systems on Wikipedia.\nI think this paper proposes an interesting twist on coreference that makes good\nsense from an information extraction perspective, has the potential to somewhat\nrevitalize and shake up coreference research, and might bridge the gap in an\ninteresting way between coreference literature and entity linking literature. \nI am sometimes unimpressed by papers that dredge up a new task that standard\nsystems perform poorly on and then propose a tweak so that their system does\nbetter. However, in this case, the actual task itself is quite motivating to me\nand rather than the authors fishing for a new domain to run things in, it\nreally does feel like \"hey, wait, these standard systems perform poorly in a\nsetting that's actually pretty important.\"\nTHE TASK: Main concept resolution is an intriguing task from an IE perspective.\n I can imagine many times where documents revolve primarily around a particular\nentity (biographical documents, dossiers or briefings about a person or event,\nclinical records, etc.) and where the information we care about extracting is\nspecific to that entity. The standard coreference task has always had the issue\nof large numbers of mentions that would seemingly be pretty irrelevant for most\nIE problems (like generic mentions), and this task is unquestionably composed\nof mentions that actually do matter.\nFrom a methodology standpoint, the notion of a \"main concept\" provides a bit of\na discourse anchor that is useful for coreference, but there appears to still\nbe substantial overhead to improve beyond the baselines, particularly on\nnon-pronominal mentions. Doing coreference directly on Wikipedia also opens the\ndoors for more interesting use of knowledge, which the authors illustrate here.\nSo I think this domain is likely to be an interesting testbed for ideas which\nwould improve coreference overall, but which in the general setting would be\nmore difficult to get robust improvements with and which would be dwarfed by\nthe amount of work dealing with other aspects of the problem.\nMoreover, unlike past work which has carved off a slice of coreference (e.g.\nthe Winograd schema work), this paper makes a big impact on the metrics of the\noverall coreference problem on a domain (Wikipedia) that many in the ACL\ncommunity are pretty interested in.\nTHE TECHNIQUES: Overall, the techniques are not the strong point of this paper,\nthough they do seem to be effective. The features seem pretty sensible, but it\nseems like additional conjunctions of these may help (and it's unclear whether\nthe authors did any experimentation in this vein). The authors should also\nstate earlier in the work that their primary MC resolution system is a binary\nclassifier; this is not explicitly stated early enough and the model is left\nundefined throughout the description of featurization.\nMINOR DETAILS:\nOrganization: I would perhaps introduce the dataset immediately after \"Related\nWorks\" (i.e. have it be the new Section 3) so that concrete results can be\ngiven in \"Baselines\", further motivating \"Approach\".\nWhen Section 4 refers to Dcoref and Scoref, you should cite the Stanford papers\nor make it clear that it's the Stanford coreference system (many will be\nunfamiliar with the Dcoref/Scoref names).\nThe use of the term \"candidate list\" was unclear, especially in the following:\n\"We leverage the hyperlink structure of the article in order to enrich the list\nof mentions with shallow semantic attributes. For each link found within the\narticle under consideration, we look through the candidate list for all\nmentions that match the surface string of the link.\"\nPlease make it clear that the \"candidate list\" is the set of mentions in the\narticle that are possible candidates for being coreferent with the MC. I think\nmost readers will understand that this module is supposed to import semantic\ninformation from the link structure of Wikipedia (e.g. if a mention is\nhyperlinked to an article that is female in Freebase, that mention is female),\nso try to keep the terminology clear.\nSection 6.1 says \"we consider the union of WCR mentions and all mentions\npredicted by the method described in (Raghunathan et al., 2010).\" However,\nSection 4.1 implies that these are the same? I'm missing where additional WCR\nmentions would be extracted."
        }
    ]
}