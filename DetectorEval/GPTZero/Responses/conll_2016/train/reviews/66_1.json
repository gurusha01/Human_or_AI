{
    "version": "2025-01-09-base",
    "scanId": "1fb9b659-a324-4fd7-8f41-657af68e6396",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.11225318908691406,
                    "sentence": "This paper presents a Stack LSTM parser based on the work of Henderson et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09678154438734055,
                    "sentence": "(2008, 2013) on joint syntactic/semantic transition-based parsing and Dyer et",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1255098581314087,
                    "sentence": "al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08937304466962814,
                    "sentence": "(2015) on stack LSTM syntactic parsing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11802459508180618,
                    "sentence": "The use of the transition system",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09853105247020721,
                    "sentence": "from the former and the stack LSTM from the latter shows interesting results",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11771371960639954,
                    "sentence": "compared to the joint systems on the CoNLL 2008 and 2009 shared tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03661153465509415,
                    "sentence": "I like this paper a lot because it is well-written, well-explained, the related",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.061347249895334244,
                    "sentence": "work is good and the results are very interesting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0745738074183464,
                    "sentence": "The methodology is sound",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0385909229516983,
                    "sentence": "(with a minor concern regarding the Chinese embeddings, leading me to believe",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04497889429330826,
                    "sentence": "than very good embeddings can be more informative than a very clever model...).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09605194628238678,
                    "sentence": "Moreover, the description of the system is clear, the hyperparameters are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08113962411880493,
                    "sentence": "justified and the discussion is interesting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.034859754145145416,
                    "sentence": "The only thing I would say is that the proposed system lacks originality in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06950804591178894,
                    "sentence": "sense that the work of Henderson et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.058616962283849716,
                    "sentence": "puts the basis of semi-synchronised",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06028546765446663,
                    "sentence": "joint syntax-semantic transition-based parsing several years ago and Dyer et",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.056356675922870636,
                    "sentence": "al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.061127737164497375,
                    "sentence": "came up with the stack LSTM last year, so it is not a new method, per say.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05755934864282608,
                    "sentence": "But in my opinion, we were waiting for such a parser to be designed and so I'm",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12624746561050415,
                    "sentence": "glad it was done here.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.07523667934849379,
            "class_probabilities": {
                "human": 0.9247182013490944,
                "ai": 0.07523667934849379,
                "mixed": 4.511930241175358e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9247182013490944,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.07523667934849379,
                    "human": 0.9247182013490944,
                    "mixed": 4.511930241175358e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper presents a Stack LSTM parser based on the work of Henderson et al.\n(2008, 2013) on joint syntactic/semantic transition-based parsing and Dyer et\nal. (2015) on stack LSTM syntactic parsing. The use of the transition system\nfrom the former and the stack LSTM from the latter shows interesting results\ncompared to the joint systems on the CoNLL 2008 and 2009 shared tasks.\nI like this paper a lot because it is well-written, well-explained, the related\nwork is good and the results are very interesting. The methodology is sound\n(with a minor concern regarding the Chinese embeddings, leading me to believe\nthan very good embeddings can be more informative than a very clever model...).\nMoreover, the description of the system is clear, the hyperparameters are\njustified and the discussion is interesting.\nThe only thing I would say is that the proposed system lacks originality in the\nsense that the work of Henderson et al. puts the basis of semi-synchronised\njoint syntax-semantic transition-based parsing several years ago and Dyer et\nal. came up with the stack LSTM last year, so it is not a new method, per say.\nBut in my opinion, we were waiting for such a parser to be designed and so I'm\nglad it was done here."
        }
    ]
}