{
    "version": "2025-01-09-base",
    "scanId": "b0827d95-8a28-4fc3-a8de-b71bcb33817d",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.009618561714887619,
                    "sentence": "A combination of word2vec and LDA could be potentially interesting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012556911446154118,
                    "sentence": "The main",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006193085573613644,
                    "sentence": "problem with the current paper is that the technical details are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008065830916166306,
                    "sentence": "incomprehensible.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0076293619349598885,
                    "sentence": "Section 2 needs a complete rewrite so that a reader familiar",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008265065960586071,
                    "sentence": "with word2vec and LDA could relatively easily get a high-level picture of how",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009698143228888512,
                    "sentence": "the models are being combined.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0076372697949409485,
                    "sentence": "The current presentation doesn't achieve that.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02249602973461151,
                    "sentence": "More detailed comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008368507958948612,
                    "sentence": "The third paragraph of the introduction makes no sense to me.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0027153671253472567,
                    "sentence": "\"requires",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0035604790318757296,
                    "sentence": "deriving a new approximation\" - approximation of what?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003932190127670765,
                    "sentence": "why is it time consuming",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0035667677875608206,
                    "sentence": "to develop prototypes?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004546608310192823,
                    "sentence": "Why is it easier to evaluate features?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006873199716210365,
                    "sentence": "Why use the same word vectors for pivot and target (unlike in word2vec)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.007868688553571701,
                    "sentence": "What's",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003797772340476513,
                    "sentence": "the motivation for that decision?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003467300906777382,
                    "sentence": "what does it mean to separate words from a marginal distribution?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004976939409971237,
                    "sentence": "what's co-adaptation?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004358930513262749,
                    "sentence": "\"If we only included structure up to this point\" - what kind of structure?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009150974452495575,
                    "sentence": "\"it's similarity\" -> its",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00763050839304924,
                    "sentence": "Footnote 1 breaks anonymity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0027246996760368347,
                    "sentence": "There doesn't appear to be any evaluation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005422545596957207,
                    "sentence": "The days when it was ok to just give",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006776376627385616,
                    "sentence": "some example clusters are long gone in NLP.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003856166498735547,
                    "sentence": "Figure 2 looks like it might be a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.003834346542134881,
                    "sentence": "quantitative evaluation, but it's only described in the overly long caption.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0034744867589324713,
                    "sentence": "The statement in the conclusion that the model solves word analogies is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0037619671784341335,
                    "sentence": "overstating what was shown, which was just a few cherry-picked examples of king",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.00566876819357276,
                    "sentence": "+ queen etc.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005887418054044247,
                    "sentence": "sort.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005884976591914892,
                    "sentence": "The Chang ref has the conference/journal name as \"Advances in...\" You'd like",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009787231683731079,
                    "sentence": "me to guess the venue?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.03483077260757958,
            "class_probabilities": {
                "human": 0.9651284621953693,
                "ai": 0.03483077260757958,
                "mixed": 4.07651970510046e-05
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9651284621953693,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.03483077260757958,
                    "human": 0.9651284621953693,
                    "mixed": 4.07651970510046e-05
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "A combination of word2vec and LDA could be potentially interesting. The main\nproblem with the current paper is that the technical details are\nincomprehensible. Section 2 needs a complete rewrite so that a reader familiar\nwith word2vec and LDA could relatively easily get a high-level picture of how\nthe models are being combined. The current presentation doesn't achieve that.\nMore detailed comments:\nThe third paragraph of the introduction makes no sense to me. \"requires\nderiving a new approximation\" - approximation of what? why is it time consuming\nto develop prototypes? Why is it easier to evaluate features?\nWhy use the same word vectors for pivot and target (unlike in word2vec)? What's\nthe motivation for that decision?\nwhat does it mean to separate words from a marginal distribution?\nwhat's co-adaptation?\n\"If we only included structure up to this point\" - what kind of structure?\n\"it's similarity\" -> its\nFootnote 1 breaks anonymity.\nThere doesn't appear to be any evaluation. The days when it was ok to just give\nsome example clusters are long gone in NLP. Figure 2 looks like it might be a\nquantitative evaluation, but it's only described in the overly long caption.\nThe statement in the conclusion that the model solves word analogies is\noverstating what was shown, which was just a few cherry-picked examples of king\n+ queen etc. sort.\nThe Chang ref has the conference/journal name as \"Advances in ...\" You'd like\nme to guess the venue?"
        }
    ]
}