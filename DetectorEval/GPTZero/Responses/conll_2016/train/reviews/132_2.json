{
    "version": "2025-01-09-base",
    "scanId": "3b223a54-4d07-4c88-b87f-4257c6a7ee9e",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.24557331204414368,
                    "sentence": "This paper proposes a neural-styled topic model, extending the objective of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2558548152446747,
                    "sentence": "word2vec to also learn document embeddings, which it then constrains through",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19508397579193115,
                    "sentence": "sparsification, hence mimicking the output of a topic model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1601867973804474,
                    "sentence": "I really liked the model that the authors proposed, and found the examples",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23527809977531433,
                    "sentence": "presented by the authors to be highly promising.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13618209958076477,
                    "sentence": "What was really missing from",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10122215002775192,
                    "sentence": "the paper, however, was any empirical evaluation of the model -- evaluation",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11802594363689423,
                    "sentence": "entirely falls back on tables of examples, without any indication of how",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1394219696521759,
                    "sentence": "representative the examples are, or any attempt to directly compare with",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18573366105556488,
                    "sentence": "standard or neural topic models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08369071781635284,
                    "sentence": "Without empirical evaluation, it is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1717401146888733,
                    "sentence": "impossible to get a sense of the true worth of the model, making it very hard",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11495082080364227,
                    "sentence": "to accept the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17123478651046753,
                    "sentence": "Some ideas of how the authors could have achieved this:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10732755810022354,
                    "sentence": "(1) use the topic representation of each document in a supervised document",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2505071461200714,
                    "sentence": "categorisation setup to compare against a topic model with the same topic",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.059951119124889374,
                    "sentence": "cardinality (i.e.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1313069760799408,
                    "sentence": "as an indirect evaluation of the quality of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15673905611038208,
                    "sentence": "representation); or (2) through direct evaluation over a dataset with document",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2526100277900696,
                    "sentence": "similarity annotations (based on pairwise comparison over topic vectors).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1648847609758377,
                    "sentence": "It's fantastic that you are releasing code, but you have compromised anonymity",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3033590316772461,
                    "sentence": "in publishing the github link in the submitted version of the paper (strictly",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2524700462818146,
                    "sentence": "speaking, this is sufficient for the paper to be rejected outright, but I",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.27179938554763794,
                    "sentence": "leave that up to the PCs)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.37259814143180847,
                    "sentence": "Other issues:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3797515332698822,
                    "sentence": "- how did you select the examples in Figures 3-6?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4515952467918396,
                    "sentence": "presenting a subset of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3675796687602997,
                    "sentence": "actual topics etc.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.26891887187957764,
                    "sentence": "potentially reeks of cherry picking.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21703380346298218,
                    "sentence": "- in Section 2.2.1 you discuss the possibility of calculating word",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3455899953842163,
                    "sentence": "representations for topics based on pairwise comparison with each word in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4281775951385498,
                    "sentence": "the vocabulary, but this is going to be an extremely expensive process for a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.36543703079223633,
                    "sentence": "reasonable vocab size and number of topics; is this really feasible?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.30350562930107117,
                    "sentence": "- you say that you identify \"tokens\" using SpaCy in Section 3.1 -- how?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.37677907943725586,
                    "sentence": "You",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.39549267292022705,
                    "sentence": "extract noun chunks (but not any other chunk type), similarly to the Section",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.44061776995658875,
                    "sentence": "3.2, or something else?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5068471431732178,
                    "sentence": "Given that you go on to say that you use word2vec",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5634220838546753,
                    "sentence": "pre-trained embeddings (which include only small numbers of multiword",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5861712098121643,
                    "sentence": "terms), it wasn't clear what you were doing here.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6262528896331787,
                    "sentence": "- how does your model deal with OOV terms?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5826703310012817,
                    "sentence": "Yes, in the experiments you report",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5748116374015808,
                    "sentence": "in the paper you appear to train the model over the entire document",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5949389338493347,
                    "sentence": "collection so it perhaps isn't an immediate problem, but there will be",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5989915132522583,
                    "sentence": "contexts where you want to apply the trained model to novel documents, in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.025425897911190987,
                    "sentence": "which case the updating of the word2vec token embeddings is going to mean",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017973119392991066,
                    "sentence": "that any non-updated (OOV, relative to the training collection) word2vec",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.017894618213176727,
                    "sentence": "embeddings are not going to be directly comparable to the tuned embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01296550314873457,
                    "sentence": "- the finding that 20 topics worked best over the 20 Newsgroups corpus wasn't",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.018946748226881027,
                    "sentence": "surprising given its composition.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.009137328714132309,
                    "sentence": "Possibly another (very simple) form of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01214180514216423,
                    "sentence": "evaluation here could have been based on some information-theoretic",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.015303883701562881,
                    "sentence": "comparison relative to the true document labels, where again you would have",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0155372004956007,
                    "sentence": "been able to perform a direct comparison with LDA etc.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.023924415931105614,
                    "sentence": "- a couple of other neural topic models that you meed to compare yourself with",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010509532876312733,
                    "sentence": "are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0244428813457489,
                    "sentence": "Cao, Ziqiang, Sujian Li, Yang Liu, Wenjie Li, and Heng Ji.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08516586571931839,
                    "sentence": "\"A Novel Neural",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.050203803926706314,
                    "sentence": "Topic Model and Its Supervised Extension.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05229562893509865,
                    "sentence": "In AAAI, pp.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07573291659355164,
                    "sentence": "2210-2216.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.026970522478222847,
                    "sentence": "2015.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07505406439304352,
                    "sentence": "Nguyen, Dat Quoc, Richard Billingsley, Lan Du, and Mark Johnson.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0635426864027977,
                    "sentence": "\"Improving",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07344016432762146,
                    "sentence": "Topic Models with Latent Feature Word Representations.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03704294562339783,
                    "sentence": "Transactions of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12231070548295975,
                    "sentence": "Association for Computational Linguistics 3 (2015): 299-313.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11074189096689224,
                    "sentence": "Shamanta, Debakar, Sheikh Motahar Naim, Parang Saraf, Naren Ramakrishnan, and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09636177122592926,
                    "sentence": "M. Shahriar Hossain.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11963048577308655,
                    "sentence": "\"Concurrent Inference of Topic Models and Distributed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03699834272265434,
                    "sentence": "Vector Representations.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11734875291585922,
                    "sentence": "In Machine Learning and Knowledge Discovery in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10437814146280289,
                    "sentence": "Databases, pp.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10898446291685104,
                    "sentence": "441-457.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06346847862005234,
                    "sentence": "Springer International Publishing, 2015.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07741553336381912,
                    "sentence": "Low-level things:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06319548934698105,
                    "sentence": "line 315: \"it's similarity\" -> \"its similarity\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04638800770044327,
                    "sentence": "line 361: what does it mean for the \"topic basis\" to be affected (and the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0715818926692009,
                    "sentence": "\"are\" is awkward here)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06786754727363586,
                    "sentence": "- in the caption of Figure 5, the examples should perhaps be \"terms\" rather",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.048712342977523804,
                    "sentence": "than \"words\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.043838877230882645,
                    "sentence": "- the reference formatting is all over the place, e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08417893201112747,
                    "sentence": "\"Advances in...\",",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11073943227529526,
                    "sentence": "\"Advances in Neural...\", Roder et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08817567676305771,
                    "sentence": "is missing the conference name, etc.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 49,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 53,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 64,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 66,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 67,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 68,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 70,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 72,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 75,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 76,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 77,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 78,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 79,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 80,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 81,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 83,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                }
            ],
            "completely_generated_prob": 0.08688750385093799,
            "class_probabilities": {
                "human": 0.9113098508409513,
                "ai": 0.08688750385093799,
                "mixed": 0.0018026453081107464
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9113098508409513,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.08688750385093799,
                    "human": 0.9113098508409513,
                    "mixed": 0.0018026453081107464
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes a neural-styled topic model, extending the objective of\nword2vec to also learn document embeddings, which it then constrains through\nsparsification, hence mimicking the output of a topic model.\nI really liked the model that the authors proposed, and found the examples\npresented by the authors to be highly promising. What was really missing from\nthe paper, however, was any empirical evaluation of the model -- evaluation\nentirely falls back on tables of examples, without any indication of how\nrepresentative the examples are, or any attempt to directly compare with\nstandard or neural topic models. Without empirical evaluation, it is\nimpossible to get a sense of the true worth of the model, making it very hard\nto accept the paper. Some ideas of how the authors could have achieved this:\n(1) use the topic representation of each document in a supervised document\ncategorisation setup to compare against a topic model with the same topic\ncardinality (i.e. as an indirect evaluation of the quality of the\nrepresentation); or (2) through direct evaluation over a dataset with document\nsimilarity annotations (based on pairwise comparison over topic vectors).\nIt's fantastic that you are releasing code, but you have compromised anonymity\nin publishing the github link in the submitted version of the paper (strictly\nspeaking, this is sufficient for the paper to be rejected outright, but I\nleave that up to the PCs)\nOther issues:\n- how did you select the examples in Figures 3-6? presenting a subset of the\n actual topics etc. potentially reeks of cherry picking.\n- in Section 2.2.1 you discuss the possibility of calculating word\n representations for topics based on pairwise comparison with each word in\n the vocabulary, but this is going to be an extremely expensive process for a\n reasonable vocab size and number of topics; is this really feasible?\n- you say that you identify \"tokens\" using SpaCy in Section 3.1 -- how? You\n extract noun chunks (but not any other chunk type), similarly to the Section\n 3.2, or something else? Given that you go on to say that you use word2vec\n pre-trained embeddings (which include only small numbers of multiword\n terms), it wasn't clear what you were doing here.\n- how does your model deal with OOV terms? Yes, in the experiments you report\n in the paper you appear to train the model over the entire document\n collection so it perhaps isn't an immediate problem, but there will be\n contexts where you want to apply the trained model to novel documents, in\n which case the updating of the word2vec token embeddings is going to mean\n that any non-updated (OOV, relative to the training collection) word2vec\n embeddings are not going to be directly comparable to the tuned embeddings.\n- the finding that 20 topics worked best over the 20 Newsgroups corpus wasn't\n surprising given its composition. Possibly another (very simple) form of\n evaluation here could have been based on some information-theoretic\n comparison relative to the true document labels, where again you would have\n been able to perform a direct comparison with LDA etc.\n- a couple of other neural topic models that you meed to compare yourself with\n are:\nCao, Ziqiang, Sujian Li, Yang Liu, Wenjie Li, and Heng Ji. \"A Novel Neural\nTopic Model and Its Supervised Extension.\" In AAAI, pp. 2210-2216. 2015.\nNguyen, Dat Quoc, Richard Billingsley, Lan Du, and Mark Johnson. \"Improving\nTopic Models with Latent Feature Word Representations.\" Transactions of the\nAssociation for Computational Linguistics 3 (2015): 299-313.\nShamanta, Debakar, Sheikh Motahar Naim, Parang Saraf, Naren Ramakrishnan, and\nM. Shahriar Hossain. \"Concurrent Inference of Topic Models and Distributed\nVector Representations.\" In Machine Learning and Knowledge Discovery in\nDatabases, pp. 441-457. Springer International Publishing, 2015.\nLow-level things:\nline 315: \"it's similarity\" -> \"its similarity\"\nline 361: what does it mean for the \"topic basis\" to be affected (and the\n\"are\" is awkward here)\n- in the caption of Figure 5, the examples should perhaps be \"terms\" rather\n than \"words\"\n- the reference formatting is all over the place, e.g. \"Advances in ...\",\n \"Advances in Neural ...\", Roder et al. is missing the conference name, etc."
        }
    ]
}