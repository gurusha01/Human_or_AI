{
    "version": "2025-01-09-base",
    "scanId": "8582b830-139b-47bc-9bf5-288540c1dc71",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.0016048067482188344,
                    "sentence": "This paper describes four methods of obtaining multilingual word embeddings and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001093051745556295,
                    "sentence": "a modified QVEC metric for evaluating the efficacy of these embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0012595138978213072,
                    "sentence": "The",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0018036976689472795,
                    "sentence": "embedding methods are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008817922207526863,
                    "sentence": "(1) multiCluster: Uses a dictionary to map words to multilingual clusters.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0011009485460817814,
                    "sentence": "Cluster embeddings are then obtained which serve as embeddings for the words",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0013941751094534993,
                    "sentence": "that reside in each cluster.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001055113971233368,
                    "sentence": "(2) multiCCA: Extends the approach presented by Faruqui and Dyer (2014) for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009337022784166038,
                    "sentence": "embedding bilingual words, to multilingual words by using English embeddings as",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0012731950264424086,
                    "sentence": "the anchor space.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0008348224801011384,
                    "sentence": "Bilingual dictionaries (other_language -> English) are then",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0011729823891073465,
                    "sentence": "used to obtain projections from other monolingual embeddings for words in other",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0012925342889502645,
                    "sentence": "languages to the anchor space.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0012135718716308475,
                    "sentence": "(3) multiSkip: Extends the approach presented by Luong et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0007725076866336167,
                    "sentence": "(2015b) for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0013782980386167765,
                    "sentence": "embedding using source and target context (via alignment), to the multilingual",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0012915711849927902,
                    "sentence": "case by extending the objective function to include components for all",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001419611624442041,
                    "sentence": "available parallel corpora.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0011660456657409668,
                    "sentence": "(4) Translation invariance: Uses a low rank decomposition of the word PMI",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0016951531870290637,
                    "sentence": "matrix with an objective with includes bilingual alignment frequency",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0013775414554402232,
                    "sentence": "components.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.001037019887007773,
                    "sentence": "May only work for bilingual embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0015850607305765152,
                    "sentence": "The evaluation method uses CCA to maximize the correlation between the word",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0017163153970614076,
                    "sentence": "embeddings and possibly hand crafted linguistic data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0009584090439602733,
                    "sentence": "Basis vectors are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0013469633413478732,
                    "sentence": "obtained for the aligned dimensions which produce a score which is invariant to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010811929823830724,
                    "sentence": "rotation and linear transformations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0010642915731295943,
                    "sentence": "The proposed method also extends this to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0006351635092869401,
                    "sentence": "multilingual evaluations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0017333399737253785,
                    "sentence": "In general, the paper is well written and describes the work clearly.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0016564406687393785,
                    "sentence": "A few",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004227304365485907,
                    "sentence": "major issues:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0015946273924782872,
                    "sentence": "(1) What is the new contribution with respect to the translation invariance",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0029438454657793045,
                    "sentence": "embedding approach of Gardner et al.?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0015844928566366434,
                    "sentence": "If it is the extension to multilingual",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0018873662920668721,
                    "sentence": "embeddings, a few lines explaining the novelty would help.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18930953741073608,
                    "sentence": "(2) The use of super-sense annotations across multiple languages is a problem.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23947709798812866,
                    "sentence": "The number of features in the intersection of multiple languages may become",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19059185683727264,
                    "sentence": "really small.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2132209688425064,
                    "sentence": "How do the authors propose to address this problem (beyond",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.21390272676944733,
                    "sentence": "footnote 9)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2764938771724701,
                    "sentence": "(3) How much does coverage affect the score in table 2?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.22214533388614655,
                    "sentence": "For example, for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.35139793157577515,
                    "sentence": "dependency parsing, multi cluster and multiCCA have significantly different",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.36164337396621704,
                    "sentence": "coverage numbers with scores that are close.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3138442933559418,
                    "sentence": "(4) In general, the results in table 3 do not tell a consistent story.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.27818968892097473,
                    "sentence": "Mainly,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1874595582485199,
                    "sentence": "for most of the intrinsic metrics, the multilingual embedding techniques do not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.29265791177749634,
                    "sentence": "seem to perform the best.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.17165595293045044,
                    "sentence": "Given that one of the primary goals of this paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.273199200630188,
                    "sentence": "was to create embeddings that perform well under the word translation metric",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19796882569789886,
                    "sentence": "(intra-language), it is disappointing that the method that performs best (by",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2401084452867508,
                    "sentence": "far) is the invariance approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.29558834433555603,
                    "sentence": "It is also strange that the multi-cluster",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.32027435302734375,
                    "sentence": "approach, which discards inter-cluster (word and language) semantic information",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19024644792079926,
                    "sentence": "performs the best with respect to the extrinsic metrics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.254464328289032,
                    "sentence": "Other questions for the authors:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2967943251132965,
                    "sentence": "(1) What is the loss in performance by fixing the word embeddings in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5634140968322754,
                    "sentence": "dependency parsing task?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4078019857406616,
                    "sentence": "What was the gain by simply using these embeddings as",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3685895502567291,
                    "sentence": "alternatives to the random embeddings in the LSTM stack parser?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3677327334880829,
                    "sentence": "(2) Is table 1 an average over the 17 embeddings described in section 5.1?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.3931950628757477,
                    "sentence": "(3) Are there any advantages of using the multi-Skip approach instead of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7057693600654602,
                    "sentence": "learning bilingual embeddings and performing multi-CCA to learning projections",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.416538804769516,
                    "sentence": "across the distinct spaces?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4652286469936371,
                    "sentence": "(4) The dictionary extraction approach (from parallel corpora via alignments or",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.341104120016098,
                    "sentence": "from google translate) may not reflect the challenges of using real lexicons.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6011714935302734,
                    "sentence": "Did you explore the use of any real multi-lingual dictionaries?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 44,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 48,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 50,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 51,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 52,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 54,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 55,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 56,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 57,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 58,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 60,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 61,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 62,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 63,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 64,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 65,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 66,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 67,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.07286165202115429,
            "class_probabilities": {
                "human": 0.9268225467824988,
                "ai": 0.07286165202115429,
                "mixed": 0.0003158011963468892
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9268225467824988,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.07286165202115429,
                    "human": 0.9268225467824988,
                    "mixed": 0.0003158011963468892
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper describes four methods of obtaining multilingual word embeddings and\na modified QVEC metric for evaluating the efficacy of these embeddings. The\nembedding methods are: \n(1) multiCluster : Uses a dictionary to map words to multilingual clusters.\nCluster embeddings are then obtained which serve as embeddings for the words\nthat reside in each cluster. \n(2) multiCCA : Extends the approach presented by Faruqui and Dyer (2014) for\nembedding bilingual words, to multilingual words by using English embeddings as\nthe anchor space. Bilingual dictionaries (other_language -> English) are then\nused to obtain projections from other monolingual embeddings for words in other\nlanguages to the anchor space. \n(3) multiSkip : Extends the approach presented by Luong et al. (2015b) for\nembedding using source and target context (via alignment), to the multilingual\ncase by extending the objective function to include components for all\navailable parallel corpora. \n(4) Translation invariance : Uses a low rank decomposition of the word PMI\nmatrix with an objective with includes bilingual alignment frequency\ncomponents. May only work for bilingual embeddings. \nThe evaluation method uses CCA to maximize the correlation between the word\nembeddings and possibly hand crafted linguistic data. Basis vectors are\nobtained for the aligned dimensions which produce a score which is invariant to\nrotation and linear transformations. The proposed method also extends this to\nmultilingual evaluations. \nIn general, the paper is well written and describes the work clearly. A few\nmajor issues:\n(1) What is the new contribution with respect to the translation invariance\nembedding approach of Gardner et al.? If it is the extension to multilingual\nembeddings, a few lines explaining the novelty would help. \n(2) The use of super-sense annotations across multiple languages is a problem.\nThe number of features in the intersection of multiple languages may become\nreally small. How do the authors propose to address this problem (beyond\nfootnote 9)?\n(3) How much does coverage affect the score in table 2? For example, for\ndependency parsing, multi cluster and multiCCA have significantly different\ncoverage numbers with scores that are close. \n(4) In general, the results in table 3 do not tell a consistent story. Mainly,\nfor most of the intrinsic metrics, the multilingual embedding techniques do not\nseem to perform the best. Given that one of the primary goals of this paper\nwas to create embeddings that perform well under the word translation metric\n(intra-language), it is disappointing that the method that performs best (by\nfar) is the invariance approach. It is also strange that the multi-cluster\napproach, which discards inter-cluster (word and language) semantic information\nperforms the best with respect to the extrinsic metrics.\nOther questions for the authors:\n(1) What is the loss in performance by fixing the word embeddings in the\ndependency parsing task? What was the gain by simply using these embeddings as\nalternatives to the random embeddings in the LSTM stack parser? \n(2) Is table 1 an average over the 17 embeddings described in section 5.1? \n(3) Are there any advantages of using the multi-Skip approach instead of\nlearning bilingual embeddings and performing multi-CCA to learning projections\nacross the distinct spaces?\n(4) The dictionary extraction approach (from parallel corpora via alignments or\nfrom google translate) may not reflect the challenges of using real lexicons.\nDid you explore the use of any real multi-lingual dictionaries?"
        }
    ]
}