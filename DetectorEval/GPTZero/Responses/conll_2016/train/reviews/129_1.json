{
    "version": "2025-01-09-base",
    "scanId": "4e04ba70-e3b2-4c18-a21d-644917c73efc",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.017644688487052917,
                    "sentence": "The paper describes an MT training data selection approach that scores and",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01949959248304367,
                    "sentence": "ranks general-domain sentences using a CNN classifier.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004970627836883068,
                    "sentence": "Comparison to prior work",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013322890736162663,
                    "sentence": "using continuous or n-gram based language models is well done, even though it",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01080993190407753,
                    "sentence": "is not clear of the paper also compared against bilingual data selection (e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.028262324631214142,
                    "sentence": "sum of difference of cross-entropies).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008100872859358788,
                    "sentence": "The motivation to use a CNN instead of an RNN/LSTM was first unclear to me, but",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005684162490069866,
                    "sentence": "it is a strength of the paper to argue that certain sections of a text/sentence",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004833501763641834,
                    "sentence": "are more important than others and this is achieved by a CNN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.004443726502358913,
                    "sentence": "However, the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013950629159808159,
                    "sentence": "paper does not experimentally show whether a BOW or SEQ (or the combination of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0058735995553433895,
                    "sentence": "both( representation is more important and why.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.012124053202569485,
                    "sentence": "The textual description of the CNN (one-hot or semi-supervised using",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01607605814933777,
                    "sentence": "pre-trained embeddings)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008070763200521469,
                    "sentence": "is clear, detailed, and points out the important aspects.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.006754980888217688,
                    "sentence": "However, a picture of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.010236778296530247,
                    "sentence": "the layers showing how inputs are combined would be worth a thousand words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005170546006411314,
                    "sentence": "The paper is overall well written, but some parentheses for citations are not",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.005630444269627333,
                    "sentence": "necessary (\\citet vs. \\citep) (e.g line 385).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008310225792229176,
                    "sentence": "Experiments and evaluation support the claims of the paper, but I am a little",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.01058235950767994,
                    "sentence": "bit concerned about the method of determining the number of selected in-domain",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.008487734943628311,
                    "sentence": "sentences (line 443) based on a separate validation set:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.013188238255679607,
                    "sentence": "- What validation data is used here?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7553994059562683,
                    "sentence": "It is also not clear on what data",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8250784277915955,
                    "sentence": "hyperparameters of the CNN models are chosen.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7500172853469849,
                    "sentence": "How sensitive are the models to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5550983548164368,
                    "sentence": "this?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8051597476005554,
                    "sentence": "- Table 2 should really compare scores of different approaches with the same",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8980252742767334,
                    "sentence": "number of sentences selected.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8234829902648926,
                    "sentence": "As Figure 1 shows, the approach of the paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7526994943618774,
                    "sentence": "still seems to outperform the baselines in this case.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7935113906860352,
                    "sentence": "Other comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6362245678901672,
                    "sentence": "- I would be interested in an experiment that compares the technique of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7357677221298218,
                    "sentence": "paper against baselines when more in-domain data is available, not just the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7470767498016357,
                    "sentence": "development set.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6300233006477356,
                    "sentence": "- The results or discussion section could feature some example sentences",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6546549201011658,
                    "sentence": "selected by the different methods to support the claims made in section 5.4.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4870462417602539,
                    "sentence": "- In regards to the argument of abstracting away from surface forms in 5.4:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7209571599960327,
                    "sentence": "Another baseline to compare against could have been the work of Axelrod, 2015,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7416605949401855,
                    "sentence": "who replace some words with POS tags to reduce LM data sparsity to see whether",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8157631754875183,
                    "sentence": "the word2vec embeddings provide an additional advantage over this.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6141886711120605,
                    "sentence": "- Using the sum of source and target classification scores is very similar to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7215327024459839,
                    "sentence": "source & target Lewis-Moore LM data selection: sum of difference of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7184358239173889,
                    "sentence": "cross-entropies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.49406951665878296,
                    "sentence": "A reference to this work around line 435 would be reasonable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.41012492775917053,
                    "sentence": "Finally, I wonder if you could learn weights for the sum of both source &",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4318758547306061,
                    "sentence": "target classification scores by extending the CNN model to the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.40392792224884033,
                    "sentence": "bilingual/parallel setting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.3063829682933457
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 39,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 46,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 47,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.14427574476600216,
            "class_probabilities": {
                "human": 0.8553490582555842,
                "ai": 0.14427574476600216,
                "mixed": 0.0003751969784136672
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.8553490582555842,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.14427574476600216,
                    "human": 0.8553490582555842,
                    "mixed": 0.0003751969784136672
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper describes an MT training data selection approach that scores and\nranks general-domain sentences using a CNN classifier. Comparison to prior work\nusing continuous or n-gram based language models is well done, even though it\nis not clear of the paper also compared against bilingual data selection (e.g.\nsum of difference of cross-entropies).\nThe motivation to use a CNN instead of an RNN/LSTM was first unclear to me, but\nit is a strength of the paper to argue that certain sections of a text/sentence\nare more important than others and this is achieved by a CNN. However, the\npaper does not experimentally show whether a BOW or SEQ (or the combination of\nboth( representation is more important and why.\nThe textual description of the CNN (one-hot or semi-supervised using\npre-trained embeddings) \nis clear, detailed, and points out the important aspects. However, a picture of\nthe layers showing how inputs are combined would be worth a thousand words.\nThe paper is overall well written, but some parentheses for citations are not\nnecessary (\\citet vs. \\citep) (e.g line 385).\nExperiments and evaluation support the claims of the paper, but I am a little\nbit concerned about the method of determining the number of selected in-domain\nsentences (line 443) based on a separate validation set:\n- What validation data is used here? It is also not clear on what data\nhyperparameters of the CNN models are chosen. How sensitive are the models to\nthis?\n- Table 2 should really compare scores of different approaches with the same\nnumber of sentences selected. As Figure 1 shows, the approach of the paper\nstill seems to outperform the baselines in this case. \nOther comments:\n- I would be interested in an experiment that compares the technique of the\npaper against baselines when more in-domain data is available, not just the\ndevelopment set.\n- The results or discussion section could feature some example sentences\nselected by the different methods to support the claims made in section 5.4.\n- In regards to the argument of abstracting away from surface forms in 5.4:\nAnother baseline to compare against could have been the work of Axelrod, 2015,\nwho replace some words with POS tags to reduce LM data sparsity to see whether\nthe word2vec embeddings provide an additional advantage over this.\n- Using the sum of source and target classification scores is very similar to\nsource & target Lewis-Moore LM data selection: sum of difference of\ncross-entropies. A reference to this work around line 435 would be reasonable.\nFinally, I wonder if you could learn weights for the sum of both source &\ntarget classification scores by extending the CNN model to the\nbilingual/parallel setting."
        }
    ]
}