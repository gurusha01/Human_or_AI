{
    "version": "2025-01-09-base",
    "scanId": "fb86a98c-e703-4497-8623-52d67a7ab52d",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.5003156661987305,
                    "sentence": "The aim of this paper is to show that distributional information stored in word",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5987198948860168,
                    "sentence": "vector models contain information about POS labels.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19583415985107422,
                    "sentence": "They use a version of the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.403742253780365,
                    "sentence": "BNC annotated with UD POS and in which words have been replaced by lemmas.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.31844913959503174,
                    "sentence": "They",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.37656369805336,
                    "sentence": "train word embeddings on this corpus, then use the resulting vectors to train a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2987169027328491,
                    "sentence": "logistic classifier to predict the word POS.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.28313833475112915,
                    "sentence": "Evaluations are performed on the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2276192158460617,
                    "sentence": "same corpus (using cross-validation) as well as on other corpora.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2662813067436218,
                    "sentence": "Results are",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.20809558033943176,
                    "sentence": "clearly presented and discussed and analyzed at length.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.29270651936531067,
                    "sentence": "The paper is clear and well-written.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.23584787547588348,
                    "sentence": "The main issue with this paper is that it",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.30263838171958923,
                    "sentence": "does not contain anything new in terms of NLP or ML.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.36933472752571106,
                    "sentence": "It describe a set of",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.39149656891822815,
                    "sentence": "straightforward experiments without any new NLP or ML ideas or methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.43378788232803345,
                    "sentence": "Results",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12170644104480743,
                    "sentence": "are interesting indeed, in so far that they provide an empirical grounding to",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16791345179080963,
                    "sentence": "the notion of POS.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2655261754989624,
                    "sentence": "In that regard, it is certainly worth being published in a",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4843754768371582,
                    "sentence": "(quantitative/emprirical) linguistic venue.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4907073378562927,
                    "sentence": "On another note, the literature on POS tagging and POS induction using word",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5594453811645508,
                    "sentence": "embeddings should be cited more extensively (cf.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5814197659492493,
                    "sentence": "for instance Lin, Ammar, Duer",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5390979051589966,
                    "sentence": "and Levin 2015; Ling et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5621916651725769,
                    "sentence": "2015 [EMNLP]; Plank, SÃƒ,gaard and Goldberg",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2865909934043884,
                    "sentence": "2016...).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.49776035834266513,
            "class_probabilities": {
                "human": 0.5022396416573348,
                "ai": 0.49776035834266513,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.5022396416573348,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.49776035834266513,
                    "human": 0.5022396416573348,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The aim of this paper is to show that distributional information stored in word\nvector models contain information about POS labels. They use a version of the\nBNC annotated with UD POS and in which words have been replaced by lemmas. They\ntrain word embeddings on this corpus, then use the resulting vectors to train a\nlogistic classifier to predict the word POS. Evaluations are performed on the\nsame corpus (using cross-validation) as well as on other corpora. Results are\nclearly presented and discussed and analyzed at length.\nThe paper is clear and well-written. The main issue with this paper is that it\ndoes not contain anything new in terms of NLP or ML. It describe a set of\nstraightforward experiments without any new NLP or ML ideas or methods. Results\nare interesting indeed, in so far that they provide an empirical grounding to\nthe notion of POS. In that regard, it is certainly worth being published in a\n(quantitative/emprirical) linguistic venue.\nOn another note, the literature on POS tagging and POS induction using word\nembeddings should be cited more extensively (cf. for instance Lin, Ammar, Duer\nand Levin 2015; Ling et al. 2015 [EMNLP]; Plank, SÃƒÂ¸gaard and Goldberg\n2016...)."
        }
    ]
}