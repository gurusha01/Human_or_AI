{
    "version": "2025-01-09-base",
    "scanId": "c3deb8ed-5b5f-4094-a40e-4454968fb924",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.06601528078317642,
                    "sentence": "This paper proposes a method for evaluating topic quality based on using word",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07795270532369614,
                    "sentence": "embeddings to calculate similarity (either directly or indirectly via matrix",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0684637650847435,
                    "sentence": "factorisation), achieving impressive results over standard datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07210319489240646,
                    "sentence": "The proposed method represents a natural but important next step in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11935596168041229,
                    "sentence": "evolutionary path of research on topic evaluation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.027980033308267593,
                    "sentence": "The thing that troubled me",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.051729850471019745,
                    "sentence": "most with the results was that, while you achieve state-of-the-art results for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07769589126110077,
                    "sentence": "all three datasets, there are large inconsistencies in which methods perform",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.0644068717956543,
                    "sentence": "and which methods perform less well (below the state of the art).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06163637340068817,
                    "sentence": "In practice,",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07391459494829178,
                    "sentence": "none of the proposed methods consistently beats the state of the art, and the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.164772629737854,
                    "sentence": "SVD-based methods perform notably badly over the genomics dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08384772390127182,
                    "sentence": "For someone",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13139638304710388,
                    "sentence": "who wants to take your method off the shelf and use it over any arbitrary",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10595101863145828,
                    "sentence": "dataset, this is a considerable worry.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.07071585953235626,
                    "sentence": "I suspect that the lower results for",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.14243176579475403,
                    "sentence": "SVD over genomics relate to the proportion of OOV terms (see comment below),",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09678827226161957,
                    "sentence": "and that it may be possible to automatically predict which method will perform",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12409217655658722,
                    "sentence": "best based on vocab match with GloVe etc., but there is no such discussion in",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08076833933591843,
                    "sentence": "the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.18880897760391235,
                    "sentence": "Other issues:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12661977112293243,
                    "sentence": "- the proposed method has strong similarities with methods proposed in the",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1864316165447235,
                    "sentence": "lexical chaining literature, which I would encourage the authors to read up",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.28354981541633606,
                    "sentence": "on and include in any future version of the paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1138070747256279,
                    "sentence": "- you emphasis that your method has no parameters, but the word embedding",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13198649883270264,
                    "sentence": "methods have a large number of parameters, which are implicit in your",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05340522527694702,
                    "sentence": "method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08213799446821213,
                    "sentence": "Not a huge deal, but worth acknowledging",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1692797988653183,
                    "sentence": "- how does your method deal with OOV terms, e.g.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16986072063446045,
                    "sentence": "in the genomics dataset",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05595745891332626,
                    "sentence": "(i.e.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1814321130514145,
                    "sentence": "terms not present in the pretrained GloVe embeddings)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10328566282987595,
                    "sentence": "Are they simply",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1436537653207779,
                    "sentence": "ignored?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13678134977817535,
                    "sentence": "What impact does this have on the method?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.04377157986164093,
                    "sentence": "Low-level issues:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13966961205005646,
                    "sentence": "- in your description of word embeddings in Section 2.1, you implicitly assume",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1422724723815918,
                    "sentence": "that the length of the vector is unimportant (in saying that cosine",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1376115381717682,
                    "sentence": "similarity can be used to measure the similarity between two vectors).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12846872210502625,
                    "sentence": "If",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1687464416027069,
                    "sentence": "the vectors are unit length, this is unproblematic, but word2vec actually",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1601472645998001,
                    "sentence": "doesn't return unit-length vectors (the pre-trained vectors have been",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.2585165500640869,
                    "sentence": "normalised post hoc, and if you run word2vec yourself, the vector length is",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15668539702892303,
                    "sentence": "certainly not uniform).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.16799375414848328,
                    "sentence": "A small detail, but important.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.15732820332050323,
                    "sentence": "- the graphs in Figure 1 are too small to be readable",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 36,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 37,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 40,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 41,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 42,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 43,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 45,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.09353082711899116,
            "class_probabilities": {
                "human": 0.9064691728810088,
                "ai": 0.09353082711899116,
                "mixed": 0
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9064691728810088,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.09353082711899116,
                    "human": 0.9064691728810088,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper proposes a method for evaluating topic quality based on using word\nembeddings to calculate similarity (either directly or indirectly via matrix\nfactorisation), achieving impressive results over standard datasets.\nThe proposed method represents a natural but important next step in the\nevolutionary path of research on topic evaluation. The thing that troubled me\nmost with the results was that, while you achieve state-of-the-art results for\nall three datasets, there are large inconsistencies in which methods perform\nand which methods perform less well (below the state of the art). In practice,\nnone of the proposed methods consistently beats the state of the art, and the\nSVD-based methods perform notably badly over the genomics dataset. For someone\nwho wants to take your method off the shelf and use it over any arbitrary\ndataset, this is a considerable worry. I suspect that the lower results for\nSVD over genomics relate to the proportion of OOV terms (see comment below),\nand that it may be possible to automatically predict which method will perform\nbest based on vocab match with GloVe etc., but there is no such discussion in\nthe paper.\nOther issues:\n- the proposed method has strong similarities with methods proposed in the\n lexical chaining literature, which I would encourage the authors to read up\n on and include in any future version of the paper\n- you emphasis that your method has no parameters, but the word embedding\n methods have a large number of parameters, which are implicit in your\n method. Not a huge deal, but worth acknowledging\n- how does your method deal with OOV terms, e.g. in the genomics dataset\n (i.e. terms not present in the pretrained GloVe embeddings)? Are they simply\n ignored? What impact does this have on the method?\nLow-level issues:\n- in your description of word embeddings in Section 2.1, you implicitly assume\n that the length of the vector is unimportant (in saying that cosine\n similarity can be used to measure the similarity between two vectors). If\n the vectors are unit length, this is unproblematic, but word2vec actually\n doesn't return unit-length vectors (the pre-trained vectors have been\n normalised post hoc, and if you run word2vec yourself, the vector length is\n certainly not uniform). A small detail, but important.\n- the graphs in Figure 1 are too small to be readable"
        }
    ]
}