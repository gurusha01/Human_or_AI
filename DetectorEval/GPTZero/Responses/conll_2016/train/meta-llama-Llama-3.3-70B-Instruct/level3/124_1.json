{
    "version": "2025-01-09-base",
    "scanId": "d2ee3f50-3399-4031-ba15-4c24a3575344",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.984731912612915,
                    "sentence": "Summary of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9957405924797058,
                    "sentence": "The paper proposes a novel approach, TBuckets, to measure the quality of Latent Dirichlet Allocation (LDA) based topics by grouping topic words into thematic groups or buckets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9939464926719666,
                    "sentence": "The approach uses three techniques: TBuckets-Clustering, TBuckets-SVD, and TBuckets-SVD-Reorg, to create buckets of words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9976872205734253,
                    "sentence": "The coherence score of a topic is computed based on the properties of words in the largest bucket.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987427592277527,
                    "sentence": "The authors evaluate their techniques on three publicly available datasets and demonstrate better performance than the state-of-the-art results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8177760243415833,
                    "sentence": "Main Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5103151202201843,
                    "sentence": "1. Novel Approach: The paper proposes a novel approach, TBuckets, to measure topic quality, which is based on grouping topic words into thematic groups or buckets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.24132676422595978,
                    "sentence": "2. Three Techniques: The authors propose three techniques for creating buckets of words: TBuckets-Clustering, TBuckets-SVD, and TBuckets-SVD-Reorg.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5008931756019592,
                    "sentence": "3. Parameter-Free: The techniques TBuckets-SVD and TBuckets-SVD-Reorg require absolutely no parameter tuning, making them more efficient than the state-of-the-art technique.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.23092906177043915,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963641166687,
                    "sentence": "1. Well-Written and Easy to Follow: The paper is well-written and easy to follow, making it accessible to a wide range of readers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999950528144836,
                    "sentence": "2. Interesting Idea: The idea of using buckets to measure topic quality is interesting and may inspire research in other NLP tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999911189079285,
                    "sentence": "3. Better Performance: The authors demonstrate better performance than the state-of-the-art results on three publicly available datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999902844429016,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999919533729553,
                    "sentence": "1. Lack of Clear Justification: The paper lacks clear justification for using cognitive features, specifically eye-movement patterns, for sentiment analysis and sarcasm detection.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999852180480957,
                    "sentence": "2. Marginal Improvement: The inclusion of cognitive features only results in marginal improvement in performance, as seen in the comparison between Sn+Sr+Gz and Sn+Sr.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999806880950928,
                    "sentence": "3. Unconvincing Discussion: The paper's discussion on the feasibility of the approach is unconvincing, particularly in the example given in section 7.2, where the technique's usefulness is unclear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989235997200012,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998319149017334,
                    "sentence": "1. Can you provide more justification for using cognitive features, specifically eye-movement patterns, for sentiment analysis and sarcasm detection?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999899685382843,
                    "sentence": "2. How do you plan to address the marginal improvement in performance when using cognitive features?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998566508293152,
                    "sentence": "3. Can you provide more examples to demonstrate the usefulness of the TBuckets approach in other NLP tasks?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.8072947311766151,
            "class_probabilities": {
                "human": 0.18953237428868533,
                "ai": 0.8072947311766151,
                "mixed": 0.0031728945346996148
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8072947311766151,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8072947311766151,
                    "human": 0.18953237428868533,
                    "mixed": 0.0031728945346996148
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary of the Paper\nThe paper proposes a novel approach, TBuckets, to measure the quality of Latent Dirichlet Allocation (LDA) based topics by grouping topic words into thematic groups or buckets. The approach uses three techniques: TBuckets-Clustering, TBuckets-SVD, and TBuckets-SVD-Reorg, to create buckets of words. The coherence score of a topic is computed based on the properties of words in the largest bucket. The authors evaluate their techniques on three publicly available datasets and demonstrate better performance than the state-of-the-art results.\nMain Contributions\n1. Novel Approach: The paper proposes a novel approach, TBuckets, to measure topic quality, which is based on grouping topic words into thematic groups or buckets.\n2. Three Techniques: The authors propose three techniques for creating buckets of words: TBuckets-Clustering, TBuckets-SVD, and TBuckets-SVD-Reorg.\n3. Parameter-Free: The techniques TBuckets-SVD and TBuckets-SVD-Reorg require absolutely no parameter tuning, making them more efficient than the state-of-the-art technique.\nStrengths\n1. Well-Written and Easy to Follow: The paper is well-written and easy to follow, making it accessible to a wide range of readers.\n2. Interesting Idea: The idea of using buckets to measure topic quality is interesting and may inspire research in other NLP tasks.\n3. Better Performance: The authors demonstrate better performance than the state-of-the-art results on three publicly available datasets.\nWeaknesses\n1. Lack of Clear Justification: The paper lacks clear justification for using cognitive features, specifically eye-movement patterns, for sentiment analysis and sarcasm detection.\n2. Marginal Improvement: The inclusion of cognitive features only results in marginal improvement in performance, as seen in the comparison between Sn+Sr+Gz and Sn+Sr.\n3. Unconvincing Discussion: The paper's discussion on the feasibility of the approach is unconvincing, particularly in the example given in section 7.2, where the technique's usefulness is unclear.\nQuestions to Authors\n1. Can you provide more justification for using cognitive features, specifically eye-movement patterns, for sentiment analysis and sarcasm detection?\n2. How do you plan to address the marginal improvement in performance when using cognitive features?\n3. Can you provide more examples to demonstrate the usefulness of the TBuckets approach in other NLP tasks?"
        }
    ]
}