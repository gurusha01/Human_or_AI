{
    "version": "2025-01-09-base",
    "scanId": "84be799e-ebed-49a6-a6b1-978fd9433df4",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999908804893494,
                    "sentence": "Summary of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999731779098511,
                    "sentence": "The paper proposes a novel approach to sentiment analysis by augmenting traditional features with cognitive features derived from eye-movement patterns of readers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999620318412781,
                    "sentence": "The authors argue that sentiment analysis is a challenging task due to nuances at lexical, syntactic, semantic, and pragmatic levels.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999643564224243,
                    "sentence": "They introduce cognitive features extracted from eye-tracking data, which capture the reader's gaze behavior while annotating text with sentiment labels.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999794363975525,
                    "sentence": "The authors evaluate their approach on two datasets and demonstrate a significant improvement in sentiment polarity detection, especially for text with complex constructs like irony and sarcasm.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999927878379822,
                    "sentence": "Main Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999929070472717,
                    "sentence": "1. Introduction of cognitive features: The authors propose a new set of features derived from eye-movement patterns, which capture the reader's cognitive processes while reading sentiment-bearing text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999940991401672,
                    "sentence": "2. Improved sentiment analysis: The combined feature set of traditional and cognitive features achieves a significant improvement in sentiment polarity detection, with an increase of 3.7% and 9.3% in F-score on two datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999947547912598,
                    "sentence": "3. Effectiveness on complex text: The approach is particularly effective for text with complex constructs like irony and sarcasm, with a relative improvement of 6.1% on a held-out dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999943971633911,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999931454658508,
                    "sentence": "1. Novel approach: The paper introduces a new perspective on sentiment analysis by incorporating cognitive features derived from eye-movement patterns.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999921977519989,
                    "sentence": "2. Significant improvement: The approach achieves a significant improvement in sentiment polarity detection, especially for complex text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999442100524902,
                    "sentence": "3. Robust evaluation: The authors evaluate their approach on two datasets and perform a thorough analysis of the results, including statistical significance tests and feature significance analysis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999891519546509,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999863505363464,
                    "sentence": "1. Limited availability of eye-tracking data: The approach requires eye-tracking data, which may not be readily available for all applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999791979789734,
                    "sentence": "2. Complexity of gaze features: The extraction of cognitive features from eye-movement patterns may be complex and require significant computational resources.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999855756759644,
                    "sentence": "3. Limited generalizability: The approach may not generalize well to other languages or domains, and may require significant adaptation and fine-tuning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996296763420105,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999621510505676,
                    "sentence": "1. How do you plan to address the limited availability of eye-tracking data, and what strategies do you propose for collecting and annotating large-scale eye-tracking datasets?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999959409236908,
                    "sentence": "2. Can you provide more details on the computational resources required for extracting cognitive features from eye-movement patterns, and how you plan to optimize the feature extraction process?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999644160270691,
                    "sentence": "3. How do you plan to evaluate the generalizability of your approach to other languages and domains, and what adaptations or fine-tuning strategies do you propose for applying the approach to new datasets?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary of the Paper\nThe paper proposes a novel approach to sentiment analysis by augmenting traditional features with cognitive features derived from eye-movement patterns of readers. The authors argue that sentiment analysis is a challenging task due to nuances at lexical, syntactic, semantic, and pragmatic levels. They introduce cognitive features extracted from eye-tracking data, which capture the reader's gaze behavior while annotating text with sentiment labels. The authors evaluate their approach on two datasets and demonstrate a significant improvement in sentiment polarity detection, especially for text with complex constructs like irony and sarcasm.\nMain Contributions\n1. Introduction of cognitive features: The authors propose a new set of features derived from eye-movement patterns, which capture the reader's cognitive processes while reading sentiment-bearing text.\n2. Improved sentiment analysis: The combined feature set of traditional and cognitive features achieves a significant improvement in sentiment polarity detection, with an increase of 3.7% and 9.3% in F-score on two datasets.\n3. Effectiveness on complex text: The approach is particularly effective for text with complex constructs like irony and sarcasm, with a relative improvement of 6.1% on a held-out dataset.\nStrengths\n1. Novel approach: The paper introduces a new perspective on sentiment analysis by incorporating cognitive features derived from eye-movement patterns.\n2. Significant improvement: The approach achieves a significant improvement in sentiment polarity detection, especially for complex text.\n3. Robust evaluation: The authors evaluate their approach on two datasets and perform a thorough analysis of the results, including statistical significance tests and feature significance analysis.\nWeaknesses\n1. Limited availability of eye-tracking data: The approach requires eye-tracking data, which may not be readily available for all applications.\n2. Complexity of gaze features: The extraction of cognitive features from eye-movement patterns may be complex and require significant computational resources.\n3. Limited generalizability: The approach may not generalize well to other languages or domains, and may require significant adaptation and fine-tuning.\nQuestions to Authors\n1. How do you plan to address the limited availability of eye-tracking data, and what strategies do you propose for collecting and annotating large-scale eye-tracking datasets?\n2. Can you provide more details on the computational resources required for extracting cognitive features from eye-movement patterns, and how you plan to optimize the feature extraction process?\n3. How do you plan to evaluate the generalizability of your approach to other languages and domains, and what adaptations or fine-tuning strategies do you propose for applying the approach to new datasets?"
        }
    ]
}