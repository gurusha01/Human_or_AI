{
    "version": "2025-01-09-base",
    "scanId": "65fc8edf-dde9-4717-b978-e7a04611b8d7",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9975690841674805,
                    "sentence": "General comments:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9976542592048645,
                    "sentence": "This manuscript explores the relationship between part-of-speech tags and word embeddings, utilizing word embeddings to draw conclusions about the consistency of PoS tags and their connection to word vector representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9937999248504639,
                    "sentence": "A notable strength of the paper is its detailed error analysis, particularly in identifying outliers in classification.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.990023672580719,
                    "sentence": "However, a crucial aspect appears to be overlooked: the primary motivation behind the part-of-speech tagging of corpora like the BNC, which was to facilitate subsequent NLP tasks such as parsing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9824031591415405,
                    "sentence": "This perspective could reframe the discussion to focus on whether the distinctions made by distributional vectors offer more benefits to parsing compared to the original tags or Universal PoS tags.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9815266728401184,
                    "sentence": "Furthermore, the paper lacks a comprehensive review of related work in distributional PoS induction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9463251233100891,
                    "sentence": "It is recommended to start with Christodoulopoulos et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9667925238609314,
                    "sentence": "(2010) and include more recent non-DNN studies, such as Blunsom and Cohn (2011) and Yatbaz et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9685494899749756,
                    "sentence": "(2012).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9072092771530151,
                    "sentence": "In the context of this existing body of work, the results presented in section 5 are not particularly novel, as there are systems with more restricted external knowledge that achieve comparable results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7729688286781311,
                    "sentence": "Specific issues",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.21096660196781158,
                    "sentence": "The abstract states that distributional vectors contain information about PoS affiliation, a result that is not new, especially for English, as evidenced by the \"many-to-one\" or \"cluster purity\" numbers presented in distributionally-based PoS induction systems over the past 15 years.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9868089556694031,
                    "sentence": "The claim that relations between vectors are mostly semantic (lines 79-80) is inaccurate, as demonstrated by Mikolov or Colobert's work and subsequent studies, which show that these vectors also contain significant syntactic information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.983219563961029,
                    "sentence": "This contradicts the statement made at the beginning of section 2 (lines 107-108).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9871826767921448,
                    "sentence": "The decision to move to Universal PoS tags is questionable, as the fine-grained distinctions of the original tagset are more intriguing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9800012111663818,
                    "sentence": "Footnote 3 is unclear, as it is uncertain whether the failed attempts mentioned were conducted by the authors or other researchers, and what criteria were used to determine failure.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9780735373497009,
                    "sentence": "Additionally, the alignment of Brown cluster vectors with Universal PoS tags is noteworthy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9717825651168823,
                    "sentence": "The observation that proper nouns are not very similar to common nouns (lines 331-332) may not be particularly interesting, as the frequent occurrence of the function word \"the\" could largely explain this difference.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8739302754402161,
                    "sentence": "While analyzing the most frequent word/tag pairs is practically motivated, it would be insightful to examine the tail of the distribution, both in terms of vector representations and the types of errors made by the classifier.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8802300095558167,
                    "sentence": "This could lead to exploring alternative features beyond pure distributional and morphological ones, enabling better generalization of PoS tags to low-frequency words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8497745394706726,
                    "sentence": "Minor issues",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6002494692802429,
                    "sentence": "Sentential references should be changed to \\newcite{} format, such as \"Mikolov et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8227341175079346,
                    "sentence": "(2013b) showed\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.3063829682933457
                }
            ],
            "completely_generated_prob": 0.9923625107281651,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9923625107281651,
                "mixed": 0.007637489271834829
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9923625107281651,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9923625107281651,
                    "human": 0,
                    "mixed": 0.007637489271834829
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "General comments:\nThis manuscript explores the relationship between part-of-speech tags and word embeddings, utilizing word embeddings to draw conclusions about the consistency of PoS tags and their connection to word vector representations. A notable strength of the paper is its detailed error analysis, particularly in identifying outliers in classification. \nHowever, a crucial aspect appears to be overlooked: the primary motivation behind the part-of-speech tagging of corpora like the BNC, which was to facilitate subsequent NLP tasks such as parsing. This perspective could reframe the discussion to focus on whether the distinctions made by distributional vectors offer more benefits to parsing compared to the original tags or Universal PoS tags. \nFurthermore, the paper lacks a comprehensive review of related work in distributional PoS induction. It is recommended to start with Christodoulopoulos et al. (2010) and include more recent non-DNN studies, such as Blunsom and Cohn (2011) and Yatbaz et al. (2012). In the context of this existing body of work, the results presented in section 5 are not particularly novel, as there are systems with more restricted external knowledge that achieve comparable results.\nSpecific issues\nThe abstract states that distributional vectors contain information about PoS affiliation, a result that is not new, especially for English, as evidenced by the \"many-to-one\" or \"cluster purity\" numbers presented in distributionally-based PoS induction systems over the past 15 years.\nThe claim that relations between vectors are mostly semantic (lines 79-80) is inaccurate, as demonstrated by Mikolov or Colobert's work and subsequent studies, which show that these vectors also contain significant syntactic information. This contradicts the statement made at the beginning of section 2 (lines 107-108).\nThe decision to move to Universal PoS tags is questionable, as the fine-grained distinctions of the original tagset are more intriguing.\nFootnote 3 is unclear, as it is uncertain whether the failed attempts mentioned were conducted by the authors or other researchers, and what criteria were used to determine failure. Additionally, the alignment of Brown cluster vectors with Universal PoS tags is noteworthy.\nThe observation that proper nouns are not very similar to common nouns (lines 331-332) may not be particularly interesting, as the frequent occurrence of the function word \"the\" could largely explain this difference.\nWhile analyzing the most frequent word/tag pairs is practically motivated, it would be insightful to examine the tail of the distribution, both in terms of vector representations and the types of errors made by the classifier. This could lead to exploring alternative features beyond pure distributional and morphological ones, enabling better generalization of PoS tags to low-frequency words.\nMinor issues\nSentential references should be changed to \\newcite{} format, such as \"Mikolov et al. (2013b) showed\"."
        }
    ]
}