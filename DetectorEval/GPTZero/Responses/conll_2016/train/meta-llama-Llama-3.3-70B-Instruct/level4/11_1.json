{
    "version": "2025-01-09-base",
    "scanId": "a9393111-b06c-4f7e-bd57-cba7eaa7a39f",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.7290573716163635,
                    "sentence": "The authors introduce a novel variant of the coreference task, specifically designed for Wikipedia, which involves identifying the coreference chain that corresponds to the entity being described in the article.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.688986599445343,
                    "sentence": "They annotate 30 documents with all coreference chains and find that approximately 25% of the mentions refer to the \"main concept\" of the article.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5694425106048584,
                    "sentence": "The authors then present simple baselines and a basic classifier that outperforms them, and demonstrate that integrating their classifier into the Stanford coreference system yields substantial improvements over state-of-the-art systems on Wikipedia.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8173109292984009,
                    "sentence": "This paper proposes a fascinating twist on coreference that has significant potential to revitalize research in the field and bridge the gap between coreference and entity linking literature.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9871205687522888,
                    "sentence": "The task of main concept resolution is intriguing from an information extraction perspective, as it focuses on extracting information specific to a particular entity, which is often the central theme of a document.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9820986986160278,
                    "sentence": "The standard coreference task has limitations, such as including a large number of irrelevant mentions, which this task avoids.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.985576868057251,
                    "sentence": "From a methodological standpoint, the concept of a \"main concept\" provides a useful discourse anchor for coreference, but there is still significant room for improvement beyond the baselines, particularly for non-pronominal mentions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.0029055331833660603,
                    "sentence": "Conducting coreference on Wikipedia also opens up opportunities for leveraging knowledge in more interesting ways, as demonstrated by the authors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.00301422574557364,
                    "sentence": "This domain is likely to be an interesting testbed for ideas that can improve coreference overall, but may be challenging to evaluate in a general setting.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.44379734992980957,
                    "sentence": "Unlike previous work that has focused on specific aspects of coreference, this paper has a significant impact on the overall coreference problem on a domain of interest to the ACL community, namely Wikipedia.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9909247756004333,
                    "sentence": "The techniques presented are effective, although not particularly innovative, and the features used seem sensible.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987952709197998,
                    "sentence": "However, it is unclear whether the authors explored additional conjunctions of these features, which could potentially lead to further improvements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992554187774658,
                    "sentence": "Some minor suggestions for improvement include reorganizing the paper to introduce the dataset earlier, providing clearer citations for the Stanford coreference system, and clarifying the terminology used, such as the \"candidate list\" of mentions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992556571960449,
                    "sentence": "Additionally, there appears to be a discrepancy between Sections 4.1 and 6.1 regarding the extraction of WCR mentions, which should be addressed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999115467071533,
                    "sentence": "Overall, the paper presents a compelling new task and demonstrates significant improvements over state-of-the-art systems, making it a valuable contribution to the field.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.00408719312638748
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.07332528267997859
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.45887534985363754
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 0.5231714696687693,
            "class_probabilities": {
                "human": 0,
                "ai": 0.5231714696687693,
                "mixed": 0.47682853033123074
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.5231714696687693,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.5231714696687693,
                    "human": 0,
                    "mixed": 0.47682853033123074
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The authors introduce a novel variant of the coreference task, specifically designed for Wikipedia, which involves identifying the coreference chain that corresponds to the entity being described in the article. They annotate 30 documents with all coreference chains and find that approximately 25% of the mentions refer to the \"main concept\" of the article. The authors then present simple baselines and a basic classifier that outperforms them, and demonstrate that integrating their classifier into the Stanford coreference system yields substantial improvements over state-of-the-art systems on Wikipedia.\nThis paper proposes a fascinating twist on coreference that has significant potential to revitalize research in the field and bridge the gap between coreference and entity linking literature. The task of main concept resolution is intriguing from an information extraction perspective, as it focuses on extracting information specific to a particular entity, which is often the central theme of a document. The standard coreference task has limitations, such as including a large number of irrelevant mentions, which this task avoids.\nFrom a methodological standpoint, the concept of a \"main concept\" provides a useful discourse anchor for coreference, but there is still significant room for improvement beyond the baselines, particularly for non-pronominal mentions. Conducting coreference on Wikipedia also opens up opportunities for leveraging knowledge in more interesting ways, as demonstrated by the authors. This domain is likely to be an interesting testbed for ideas that can improve coreference overall, but may be challenging to evaluate in a general setting.\nUnlike previous work that has focused on specific aspects of coreference, this paper has a significant impact on the overall coreference problem on a domain of interest to the ACL community, namely Wikipedia. The techniques presented are effective, although not particularly innovative, and the features used seem sensible. However, it is unclear whether the authors explored additional conjunctions of these features, which could potentially lead to further improvements.\nSome minor suggestions for improvement include reorganizing the paper to introduce the dataset earlier, providing clearer citations for the Stanford coreference system, and clarifying the terminology used, such as the \"candidate list\" of mentions. Additionally, there appears to be a discrepancy between Sections 4.1 and 6.1 regarding the extraction of WCR mentions, which should be addressed. Overall, the paper presents a compelling new task and demonstrates significant improvements over state-of-the-art systems, making it a valuable contribution to the field."
        }
    ]
}