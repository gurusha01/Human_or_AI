{
    "version": "2025-01-09-base",
    "scanId": "e9257d50-9140-49f7-8e17-603388407c0e",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9874270558357239,
                    "sentence": "This paper investigates the presence of part-of-speech (POS) label information within the distributional data stored in word vector models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9764024615287781,
                    "sentence": "The authors utilize a modified version of the British National Corpus (BNC) annotated with Universal Dependencies (UD) POS tags, where words are replaced with their lemmas.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9830094575881958,
                    "sentence": "They then train word embeddings on this corpus and employ the resulting vectors to train a logistic classifier for predicting word POS.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9732112884521484,
                    "sentence": "The evaluations are conducted on the same corpus using cross-validation, as well as on additional corpora.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9558840990066528,
                    "sentence": "The results are presented in a clear and thorough manner, accompanied by extensive discussion and analysis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9515380263328552,
                    "sentence": "The paper is well-structured and clearly written.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9661681652069092,
                    "sentence": "However, a significant concern is that it lacks novelty in terms of natural language processing (NLP) or machine learning (ML) concepts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9943376183509827,
                    "sentence": "The experiments described are straightforward and do not introduce any new ideas or methods in NLP or ML.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9958584308624268,
                    "sentence": "Nevertheless, the results are interesting as they provide empirical evidence for the notion of POS, making it a worthwhile publication in a quantitative or empirical linguistics venue.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9957893490791321,
                    "sentence": "Furthermore, the paper would benefit from a more comprehensive citation of existing literature on POS tagging and induction using word embeddings, including notable works such as those by Lin, Ammar, Duer, and Levin (2015), Ling et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9970077276229858,
                    "sentence": "(2015), and Plank, SÃ,gaard, and Goldberg (2016).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.8944041024838034,
            "class_probabilities": {
                "human": 0.10559589751619658,
                "ai": 0.8944041024838034,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8944041024838034,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8944041024838034,
                    "human": 0.10559589751619658,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper investigates the presence of part-of-speech (POS) label information within the distributional data stored in word vector models. The authors utilize a modified version of the British National Corpus (BNC) annotated with Universal Dependencies (UD) POS tags, where words are replaced with their lemmas. They then train word embeddings on this corpus and employ the resulting vectors to train a logistic classifier for predicting word POS. The evaluations are conducted on the same corpus using cross-validation, as well as on additional corpora. The results are presented in a clear and thorough manner, accompanied by extensive discussion and analysis.\nThe paper is well-structured and clearly written. However, a significant concern is that it lacks novelty in terms of natural language processing (NLP) or machine learning (ML) concepts. The experiments described are straightforward and do not introduce any new ideas or methods in NLP or ML. Nevertheless, the results are interesting as they provide empirical evidence for the notion of POS, making it a worthwhile publication in a quantitative or empirical linguistics venue.\nFurthermore, the paper would benefit from a more comprehensive citation of existing literature on POS tagging and induction using word embeddings, including notable works such as those by Lin, Ammar, Duer, and Levin (2015), Ling et al. (2015), and Plank, SÃ¸gaard, and Goldberg (2016)."
        }
    ]
}