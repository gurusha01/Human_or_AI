{
    "version": "2025-01-09-base",
    "scanId": "da355e32-7e10-4762-9879-6f41b79548fd",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9987239241600037,
                    "sentence": "This paper introduces the first comprehensive semantic parsers for UCCA, a specific approach to graph-based semantic representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9966397285461426,
                    "sentence": "Notably, UCCA graphs can include \"nonterminal\" nodes that do not correspond to words in the input string, distinguishing them from CoNLL semantic dependency graphs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9939418435096741,
                    "sentence": "Additionally, UCCA graphs are \"grounded,\" meaning that the text tokens are represented as nodes in the semantic representation, unlike AMRs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9976866841316223,
                    "sentence": "The authors propose several parsing methods, including a transition-based parser that directly constructs UCCA parses, and evaluate their performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974158406257629,
                    "sentence": "Given the existence of UCCA and UCCA-annotated data, developing a semantic parser for UCCA seems justified.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9963827133178711,
                    "sentence": "However, the introduction and background section may be perceived as overly advocating for UCCA as the sole graph-based semantic representation formalism worth studying.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9962897896766663,
                    "sentence": "This stance may not be necessary, as a competent UCCA parser could be a valuable contribution in its own right.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9969712495803833,
                    "sentence": "The three criteria for semantic representation formalisms outlined in the introduction are not entirely convincing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9947714805603027,
                    "sentence": "For instance, the benefits of \"nonterminal nodes\" in terms of expressive capacity are unclear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9977724552154541,
                    "sentence": "While they may offer a solution to the issue of assigning a head to coordinated structures, it is uncertain what information can only be represented using nonterminal nodes and not, for example, through more informative edge labels.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9962530732154846,
                    "sentence": "Furthermore, the question of discontinuity is irrelevant in non-\"grounded\" semantic representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.991553783416748,
                    "sentence": "The advantages of \"grounded\" representations over AMR-style ones are also not apparent.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9983291029930115,
                    "sentence": "The term \"grounded\" has been used to describe various concepts in semantics over the past decade, and it may be beneficial for the authors to adopt a different term, such as \"anchored\" or \"lexicalized.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9959968328475952,
                    "sentence": "Therefore, the introductory section of the paper could be improved with more careful phrasing and argumentation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9979342222213745,
                    "sentence": "The parser itself appears to be satisfactory, although the details were not thoroughly examined.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9857107996940613,
                    "sentence": "Nevertheless, the evaluation results are not particularly impressive.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8291162252426147,
                    "sentence": "On \"primary\" edges, a basic MaltParser outperforms the BSP parser presented in this work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9049293398857117,
                    "sentence": "Moreover, the f-scores on \"remote\" edges, which a dependency-tree parser like Malt cannot compute directly, are not exceptionally high.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.13055385649204254,
                    "sentence": "The conversion of dependency graphs to dependency trees has been extensively studied under the name \"tree approximations\" in the context of the CoNLL 2014 and 2015 shared tasks on semantic dependency parsing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.08623763918876648,
                    "sentence": "Several authors have proposed methods for reconstructing the edges deleted during the graph-to-tree conversion, such as Agic et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.32067495584487915,
                    "sentence": "(2015).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.06472983956336975,
                    "sentence": "By incorporating these methods, it is likely that the f-score of the MaltParser (and the LSTM-based MaltParser) could be further improved, which would make the strength of the BSP parser even less clear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 7,
                    "completely_generated_prob": 0.9103421900070616
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 8,
                    "completely_generated_prob": 0.028370924005244397
                }
            ],
            "completely_generated_prob": 0.9658502932045533,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9658502932045533,
                "mixed": 0.034149706795446697
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9658502932045533,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9658502932045533,
                    "human": 0,
                    "mixed": 0.034149706795446697
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper introduces the first comprehensive semantic parsers for UCCA, a specific approach to graph-based semantic representations. Notably, UCCA graphs can include \"nonterminal\" nodes that do not correspond to words in the input string, distinguishing them from CoNLL semantic dependency graphs. Additionally, UCCA graphs are \"grounded,\" meaning that the text tokens are represented as nodes in the semantic representation, unlike AMRs. The authors propose several parsing methods, including a transition-based parser that directly constructs UCCA parses, and evaluate their performance.\nGiven the existence of UCCA and UCCA-annotated data, developing a semantic parser for UCCA seems justified. However, the introduction and background section may be perceived as overly advocating for UCCA as the sole graph-based semantic representation formalism worth studying. This stance may not be necessary, as a competent UCCA parser could be a valuable contribution in its own right.\nThe three criteria for semantic representation formalisms outlined in the introduction are not entirely convincing. For instance, the benefits of \"nonterminal nodes\" in terms of expressive capacity are unclear. While they may offer a solution to the issue of assigning a head to coordinated structures, it is uncertain what information can only be represented using nonterminal nodes and not, for example, through more informative edge labels. Furthermore, the question of discontinuity is irrelevant in non-\"grounded\" semantic representations. The advantages of \"grounded\" representations over AMR-style ones are also not apparent. The term \"grounded\" has been used to describe various concepts in semantics over the past decade, and it may be beneficial for the authors to adopt a different term, such as \"anchored\" or \"lexicalized.\" Therefore, the introductory section of the paper could be improved with more careful phrasing and argumentation.\nThe parser itself appears to be satisfactory, although the details were not thoroughly examined. Nevertheless, the evaluation results are not particularly impressive. On \"primary\" edges, a basic MaltParser outperforms the BSP parser presented in this work. Moreover, the f-scores on \"remote\" edges, which a dependency-tree parser like Malt cannot compute directly, are not exceptionally high. The conversion of dependency graphs to dependency trees has been extensively studied under the name \"tree approximations\" in the context of the CoNLL 2014 and 2015 shared tasks on semantic dependency parsing. Several authors have proposed methods for reconstructing the edges deleted during the graph-to-tree conversion, such as Agic et al. (2015). By incorporating these methods, it is likely that the f-score of the MaltParser (and the LSTM-based MaltParser) could be further improved, which would make the strength of the BSP parser even less clear."
        }
    ]
}