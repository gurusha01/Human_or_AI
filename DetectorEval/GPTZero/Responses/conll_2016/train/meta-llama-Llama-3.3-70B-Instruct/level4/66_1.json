{
    "version": "2025-01-09-base",
    "scanId": "9799d98a-f3b2-4b23-8b31-4c48f937dc62",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.621574342250824,
                    "sentence": "This manuscript proposes a Stack LSTM parser that builds upon the foundational work of Henderson et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6848950386047363,
                    "sentence": "(2008, 2013) on integrated syntactic and semantic transition-based parsing, as well as Dyer et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6821995973587036,
                    "sentence": "'s (2015) contributions to stack LSTM syntactic parsing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6904240250587463,
                    "sentence": "By combining the transition system from the former with the stack LSTM from the latter, the authors achieve notable results in comparison to joint systems on the CoNLL 2008 and 2009 shared tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9572141766548157,
                    "sentence": "I find this paper to be exceptionally well-crafted, with clear explanations, a thorough review of related work, and intriguing results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9483375549316406,
                    "sentence": "The methodology is robust, although I do have a minor reservation regarding the Chinese embeddings, which suggests to me that high-quality embeddings can be more insightful than even the most sophisticated models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9251830577850342,
                    "sentence": "The system description is concise, the hyperparameters are well-justified, and the discussion is engaging.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9726335406303406,
                    "sentence": "My sole criticism is that the proposed system may not introduce entirely new concepts, as Henderson et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9562297463417053,
                    "sentence": "laid the groundwork for semi-synchronized joint syntax-semantic transition-based parsing several years ago, and Dyer et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.955586850643158,
                    "sentence": "recently developed the stack LSTM.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9421259760856628,
                    "sentence": "However, in my view, the field has been awaiting a parser that integrates these concepts, and I am pleased to see it implemented effectively in this work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                }
            ],
            "completely_generated_prob": 0.7012240715000121,
            "class_probabilities": {
                "human": 0.2976865220809293,
                "ai": 0.7012240715000121,
                "mixed": 0.0010894064190585953
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.7012240715000121,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.7012240715000121,
                    "human": 0.2976865220809293,
                    "mixed": 0.0010894064190585953
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This manuscript proposes a Stack LSTM parser that builds upon the foundational work of Henderson et al. (2008, 2013) on integrated syntactic and semantic transition-based parsing, as well as Dyer et al.'s (2015) contributions to stack LSTM syntactic parsing. By combining the transition system from the former with the stack LSTM from the latter, the authors achieve notable results in comparison to joint systems on the CoNLL 2008 and 2009 shared tasks.\nI find this paper to be exceptionally well-crafted, with clear explanations, a thorough review of related work, and intriguing results. The methodology is robust, although I do have a minor reservation regarding the Chinese embeddings, which suggests to me that high-quality embeddings can be more insightful than even the most sophisticated models.\nThe system description is concise, the hyperparameters are well-justified, and the discussion is engaging. My sole criticism is that the proposed system may not introduce entirely new concepts, as Henderson et al. laid the groundwork for semi-synchronized joint syntax-semantic transition-based parsing several years ago, and Dyer et al. recently developed the stack LSTM. However, in my view, the field has been awaiting a parser that integrates these concepts, and I am pleased to see it implemented effectively in this work."
        }
    ]
}