{
    "version": "2025-01-09-base",
    "scanId": "d40aa2ab-7209-4daf-92b3-4165efbd8043",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999708533287048,
                    "sentence": "Summary of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999786615371704,
                    "sentence": "This paper presents a novel approach to coreference resolution in Wikipedia articles, focusing on identifying mentions of the main concept being described.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999771118164062,
                    "sentence": "The authors propose a binary classification problem, where a classifier decides whether a detected mention refers to the main concept.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999476075172424,
                    "sentence": "They exploit Wikipedia markup and characteristics, as well as links to external knowledge bases like Freebase, to acquire useful information on entities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999954342842102,
                    "sentence": "The approach outperforms state-of-the-art coreference resolution systems on a dedicated dataset, WCR, and improves the detection of coreference chains in Wikipedia articles when integrated into a rule-based coreference system.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999344348907471,
                    "sentence": "Main Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999412298202515,
                    "sentence": "1. Adapting coreference resolution to Wikipedia articles: The authors revisit a seldom-studied task and propose a testbed for evaluating systems designed for it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999268651008606,
                    "sentence": "2. Exploiting Wikipedia markup and external knowledge bases: The approach leverages Wikipedia's structured data and links to Freebase to improve coreference resolution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999397397041321,
                    "sentence": "3. Simple yet effective classification model: The authors propose a binary classification model that achieves high performance on the task.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999372363090515,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999264478683472,
                    "sentence": "1. Effective use of Wikipedia markup and external knowledge bases: The approach demonstrates the value of exploiting Wikipedia's structured data and links to Freebase for coreference resolution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999873042106628,
                    "sentence": "2. Simple yet effective classification model: The proposed model achieves high performance on the task, outperforming state-of-the-art systems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999675750732422,
                    "sentence": "3. Improvement of coreference resolution in Wikipedia articles: The approach improves the detection of coreference chains in Wikipedia articles when integrated into a rule-based coreference system.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999678134918213,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999372959136963,
                    "sentence": "1. Limited dataset size: The WCR dataset is relatively small compared to other coreference resolution datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998987913131714,
                    "sentence": "2. Dependence on Wikipedia markup and external knowledge bases: The approach relies heavily on the quality and availability of Wikipedia markup and links to Freebase.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999209642410278,
                    "sentence": "3. Limited evaluation of the approach: The authors only evaluate the approach on a single dataset and do not compare it to other state-of-the-art systems on other datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987528920173645,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998350739479065,
                    "sentence": "1. How do the authors plan to address the limited dataset size and potential biases in the WCR dataset?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996612668037415,
                    "sentence": "2. Can the approach be adapted to other domains or datasets, and if so, how?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997604489326477,
                    "sentence": "3. How do the authors plan to evaluate the approach on other datasets and compare it to other state-of-the-art systems?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997847017652333,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997847017652333,
                "mixed": 0.00021529823476680056
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997847017652333,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997847017652333,
                    "human": 0,
                    "mixed": 0.00021529823476680056
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary of the Paper\nThis paper presents a novel approach to coreference resolution in Wikipedia articles, focusing on identifying mentions of the main concept being described. The authors propose a binary classification problem, where a classifier decides whether a detected mention refers to the main concept. They exploit Wikipedia markup and characteristics, as well as links to external knowledge bases like Freebase, to acquire useful information on entities. The approach outperforms state-of-the-art coreference resolution systems on a dedicated dataset, WCR, and improves the detection of coreference chains in Wikipedia articles when integrated into a rule-based coreference system.\nMain Contributions\n1. Adapting coreference resolution to Wikipedia articles: The authors revisit a seldom-studied task and propose a testbed for evaluating systems designed for it.\n2. Exploiting Wikipedia markup and external knowledge bases: The approach leverages Wikipedia's structured data and links to Freebase to improve coreference resolution.\n3. Simple yet effective classification model: The authors propose a binary classification model that achieves high performance on the task.\nStrengths\n1. Effective use of Wikipedia markup and external knowledge bases: The approach demonstrates the value of exploiting Wikipedia's structured data and links to Freebase for coreference resolution.\n2. Simple yet effective classification model: The proposed model achieves high performance on the task, outperforming state-of-the-art systems.\n3. Improvement of coreference resolution in Wikipedia articles: The approach improves the detection of coreference chains in Wikipedia articles when integrated into a rule-based coreference system.\nWeaknesses\n1. Limited dataset size: The WCR dataset is relatively small compared to other coreference resolution datasets.\n2. Dependence on Wikipedia markup and external knowledge bases: The approach relies heavily on the quality and availability of Wikipedia markup and links to Freebase.\n3. Limited evaluation of the approach: The authors only evaluate the approach on a single dataset and do not compare it to other state-of-the-art systems on other datasets.\nQuestions to Authors\n1. How do the authors plan to address the limited dataset size and potential biases in the WCR dataset?\n2. Can the approach be adapted to other domains or datasets, and if so, how?\n3. How do the authors plan to evaluate the approach on other datasets and compare it to other state-of-the-art systems?"
        }
    ]
}