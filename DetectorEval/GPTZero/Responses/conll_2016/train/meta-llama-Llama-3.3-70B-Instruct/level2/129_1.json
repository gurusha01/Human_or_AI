{
    "version": "2025-01-09-base",
    "scanId": "693a3646-8f50-482d-ab95-6677ec54df3e",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999992251396179,
                    "sentence": "Summary of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999989867210388,
                    "sentence": "The paper proposes a method for domain adaptation in statistical machine translation (SMT) using semi-supervised convolutional neural networks (CNNs) to select in-domain training data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986886978149,
                    "sentence": "The approach is particularly effective when only a small amount of in-domain data is available.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980330467224,
                    "sentence": "The authors use a small amount of in-domain data as positive samples and randomly select negative samples from the general-domain training data to train a CNN classification model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999985694885254,
                    "sentence": "The learned model is then used to classify each sentence in the general-domain training data based on its domain relevance score, and the top-scoring sentences are selected to train the SMT system.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963641166687,
                    "sentence": "Main Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999990463256836,
                    "sentence": "1. The paper proposes a novel approach for domain adaptation in SMT using semi-supervised CNNs to select in-domain training data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986886978149,
                    "sentence": "2. The authors demonstrate the effectiveness of their approach on four different language directions with three test domains, achieving significant improvements over strong baseline systems trained with large amounts of data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979138374329,
                    "sentence": "3. The paper shows that the proposed approach can reduce the size of the in-domain sample to around 100 sentences and still obtain significant improvements in translation performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999964237213135,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982714653015,
                    "sentence": "1. The paper presents a well-motivated and clearly explained approach to domain adaptation in SMT.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999985098838806,
                    "sentence": "2. The authors provide a thorough evaluation of their approach on multiple language directions and test domains, demonstrating its effectiveness and robustness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999215006828308,
                    "sentence": "3. The paper highlights the potential of semi-supervised CNNs for selecting in-domain training data, which is a challenging problem in SMT.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999042749404907,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999005794525146,
                    "sentence": "1. The paper assumes that the in-domain data is available, even if only in small quantities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999294877052307,
                    "sentence": "In some cases, it may be difficult to obtain even a small amount of in-domain data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999290108680725,
                    "sentence": "2. The authors do not provide a detailed analysis of the computational resources required to train the CNN models, which could be a limitation for large-scale SMT systems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999606609344482,
                    "sentence": "3. The paper does not explore the potential of using other machine learning approaches, such as transfer learning or multi-task learning, for domain adaptation in SMT.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992557764053345,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998062252998352,
                    "sentence": "1. How do the authors plan to address the issue of obtaining in-domain data, especially in cases where it is scarce or difficult to collect?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998745918273926,
                    "sentence": "2. Can the authors provide more details on the computational resources required to train the CNN models, and how they can be optimized for large-scale SMT systems?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999239444732666,
                    "sentence": "3. Have the authors considered exploring other machine learning approaches, such as transfer learning or multi-task learning, for domain adaptation in SMT, and if so, what are the potential benefits and limitations of these approaches?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9984984300152882,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984984300152882,
                "mixed": 0.0015015699847118259
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984984300152882,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984984300152882,
                    "human": 0,
                    "mixed": 0.0015015699847118259
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Summary of the Paper\nThe paper proposes a method for domain adaptation in statistical machine translation (SMT) using semi-supervised convolutional neural networks (CNNs) to select in-domain training data. The approach is particularly effective when only a small amount of in-domain data is available. The authors use a small amount of in-domain data as positive samples and randomly select negative samples from the general-domain training data to train a CNN classification model. The learned model is then used to classify each sentence in the general-domain training data based on its domain relevance score, and the top-scoring sentences are selected to train the SMT system.\nMain Contributions\n1. The paper proposes a novel approach for domain adaptation in SMT using semi-supervised CNNs to select in-domain training data.\n2. The authors demonstrate the effectiveness of their approach on four different language directions with three test domains, achieving significant improvements over strong baseline systems trained with large amounts of data.\n3. The paper shows that the proposed approach can reduce the size of the in-domain sample to around 100 sentences and still obtain significant improvements in translation performance.\nStrengths\n1. The paper presents a well-motivated and clearly explained approach to domain adaptation in SMT.\n2. The authors provide a thorough evaluation of their approach on multiple language directions and test domains, demonstrating its effectiveness and robustness.\n3. The paper highlights the potential of semi-supervised CNNs for selecting in-domain training data, which is a challenging problem in SMT.\nWeaknesses\n1. The paper assumes that the in-domain data is available, even if only in small quantities. In some cases, it may be difficult to obtain even a small amount of in-domain data.\n2. The authors do not provide a detailed analysis of the computational resources required to train the CNN models, which could be a limitation for large-scale SMT systems.\n3. The paper does not explore the potential of using other machine learning approaches, such as transfer learning or multi-task learning, for domain adaptation in SMT.\nQuestions to Authors\n1. How do the authors plan to address the issue of obtaining in-domain data, especially in cases where it is scarce or difficult to collect?\n2. Can the authors provide more details on the computational resources required to train the CNN models, and how they can be optimized for large-scale SMT systems?\n3. Have the authors considered exploring other machine learning approaches, such as transfer learning or multi-task learning, for domain adaptation in SMT, and if so, what are the potential benefits and limitations of these approaches?"
        }
    ]
}