{
    "version": "2025-01-09-base",
    "scanId": "2c9aed3c-4038-44a7-81b5-b81860017254",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.999994695186615,
                    "sentence": "Review of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "Summary and Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979138374329,
                    "sentence": "This paper proposes a novel modification to the output layer of RNNs, specifically a BiLSTM, to improve sequence tagging in low-resource languages by learning from both gold-standard and projected annotations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999997615814209,
                    "sentence": "The core contribution is the introduction of a noise modeling layer that explicitly accounts for the discrepancies between clean and noisy labels, enabling the model to effectively utilize cross-lingual projected data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980330467224,
                    "sentence": "The authors demonstrate the effectiveness of their approach through experiments on eight simulated low-resource languages and two real-world low-resource languages, Malagasy and Kinyarwanda, achieving state-of-the-art results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999953508377075,
                    "sentence": "The primary contributions of this work are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999966621398926,
                    "sentence": "1. Noise Modeling Layer: The explicit modeling of noise in projected annotations is a key innovation, allowing the system to learn mappings between clean and noisy tags effectively.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "2. Joint Training Framework: The integration of gold-standard and projected data in a unified training objective is a significant methodological contribution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999976754188538,
                    "sentence": "3. Empirical Validation: The method achieves strong results across multiple languages, demonstrating its robustness and generalizability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967217445374,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986290931702,
                    "sentence": "1. Simplicity and Elegance: The proposed method is conceptually simple yet effective.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999970197677612,
                    "sentence": "The addition of a noise layer to the output of a BiLSTM is a minimal but impactful modification that addresses a critical issue in cross-lingual projection.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999971389770508,
                    "sentence": "2. State-of-the-Art Results: The model achieves superior performance on both simulated and real-world low-resource languages, outperforming prior methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999953508377075,
                    "sentence": "3. Modularity: The approach is modular and adaptable, making it potentially applicable to other NLP tasks and noisy label sources, such as crowdsourced annotations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999972581863403,
                    "sentence": "4. Practical Relevance: The use of a small gold-standard dataset (1,000 tokens) aligns with realistic constraints in low-resource language settings, making the approach practical and scalable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977946281433,
                    "sentence": "5. Insightful Noise Analysis: The visualization of the noise transformation matrix provides valuable insights into the nature of noise in projected annotations and the model's ability to handle it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999991655349731,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999974966049194,
                    "sentence": "1. Experimental Setup: The reliance on very small gold-standard datasets may not reflect typical real-world scenarios where slightly larger annotated corpora are often available.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999971985816956,
                    "sentence": "A broader range of dataset sizes could provide a more comprehensive evaluation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982714653015,
                    "sentence": "2. Lack of Sensitivity Analysis: The paper does not include a plot showing tagging accuracy as a function of gold annotation size, which would clarify the method's performance under varying conditions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9947323203086853,
                    "sentence": "3. Limited Evaluation: While the method is generalizable, the experiments are limited to cross-lingual projections.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9903332591056824,
                    "sentence": "Extending the evaluation to other noisy label sources (e.g., crowdsourcing) would strengthen the claims.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9809288382530212,
                    "sentence": "4. Projected Data Representation: The construction of vector representations for unaligned words in projected data is not clearly explained, raising questions about how these cases are handled.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9647687077522278,
                    "sentence": "5. Training Objective: The equal weighting of gold and noisy labels in the training objective is surprising.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9848459362983704,
                    "sentence": "Exploring and reporting the impact of different weightings could provide additional insights.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9942101836204529,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9957260489463806,
                    "sentence": "1. How does the model handle unaligned words in the projected data?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.996963620185852,
                    "sentence": "Could you clarify the construction of their vector representations?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9909305572509766,
                    "sentence": "2. Did you experiment with different weightings for gold and noisy labels in the training objective?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9860490560531616,
                    "sentence": "If so, what were the findings?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9946738481521606,
                    "sentence": "3. Could you provide a plot showing tagging accuracy as a function of the size of the gold-standard dataset?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9672562479972839,
                    "sentence": "Additional Comments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9899109601974487,
                    "sentence": "- There is a typographical error on line 267 (bracket mismatch) that needs correction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9908617734909058,
                    "sentence": "- The paper would benefit from a discussion on the computational efficiency of the proposed method compared to baseline approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9975024461746216,
                    "sentence": "In conclusion, this paper presents a significant contribution to low-resource NLP by addressing the challenges of noisy cross-lingual projections.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9978604316711426,
                    "sentence": "While there are areas for improvement, the strengths of the proposed method and its empirical results make it a strong candidate for acceptance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9984800378301695,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984800378301695,
                "mixed": 0.0015199621698304396
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984800378301695,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984800378301695,
                    "human": 0,
                    "mixed": 0.0015199621698304396
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Review of the Paper\nSummary and Contributions\nThis paper proposes a novel modification to the output layer of RNNs, specifically a BiLSTM, to improve sequence tagging in low-resource languages by learning from both gold-standard and projected annotations. The core contribution is the introduction of a noise modeling layer that explicitly accounts for the discrepancies between clean and noisy labels, enabling the model to effectively utilize cross-lingual projected data. The authors demonstrate the effectiveness of their approach through experiments on eight simulated low-resource languages and two real-world low-resource languages, Malagasy and Kinyarwanda, achieving state-of-the-art results.\nThe primary contributions of this work are:\n1. Noise Modeling Layer: The explicit modeling of noise in projected annotations is a key innovation, allowing the system to learn mappings between clean and noisy tags effectively.\n2. Joint Training Framework: The integration of gold-standard and projected data in a unified training objective is a significant methodological contribution.\n3. Empirical Validation: The method achieves strong results across multiple languages, demonstrating its robustness and generalizability.\nStrengths\n1. Simplicity and Elegance: The proposed method is conceptually simple yet effective. The addition of a noise layer to the output of a BiLSTM is a minimal but impactful modification that addresses a critical issue in cross-lingual projection.\n2. State-of-the-Art Results: The model achieves superior performance on both simulated and real-world low-resource languages, outperforming prior methods.\n3. Modularity: The approach is modular and adaptable, making it potentially applicable to other NLP tasks and noisy label sources, such as crowdsourced annotations.\n4. Practical Relevance: The use of a small gold-standard dataset (1,000 tokens) aligns with realistic constraints in low-resource language settings, making the approach practical and scalable.\n5. Insightful Noise Analysis: The visualization of the noise transformation matrix provides valuable insights into the nature of noise in projected annotations and the model's ability to handle it.\nWeaknesses\n1. Experimental Setup: The reliance on very small gold-standard datasets may not reflect typical real-world scenarios where slightly larger annotated corpora are often available. A broader range of dataset sizes could provide a more comprehensive evaluation.\n2. Lack of Sensitivity Analysis: The paper does not include a plot showing tagging accuracy as a function of gold annotation size, which would clarify the method's performance under varying conditions.\n3. Limited Evaluation: While the method is generalizable, the experiments are limited to cross-lingual projections. Extending the evaluation to other noisy label sources (e.g., crowdsourcing) would strengthen the claims.\n4. Projected Data Representation: The construction of vector representations for unaligned words in projected data is not clearly explained, raising questions about how these cases are handled.\n5. Training Objective: The equal weighting of gold and noisy labels in the training objective is surprising. Exploring and reporting the impact of different weightings could provide additional insights.\nQuestions to Authors\n1. How does the model handle unaligned words in the projected data? Could you clarify the construction of their vector representations?\n2. Did you experiment with different weightings for gold and noisy labels in the training objective? If so, what were the findings?\n3. Could you provide a plot showing tagging accuracy as a function of the size of the gold-standard dataset?\nAdditional Comments\n- There is a typographical error on line 267 (bracket mismatch) that needs correction.\n- The paper would benefit from a discussion on the computational efficiency of the proposed method compared to baseline approaches. \nIn conclusion, this paper presents a significant contribution to low-resource NLP by addressing the challenges of noisy cross-lingual projections. While there are areas for improvement, the strengths of the proposed method and its empirical results make it a strong candidate for acceptance."
        }
    ]
}