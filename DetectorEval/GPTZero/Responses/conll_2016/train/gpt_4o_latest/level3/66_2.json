{
    "version": "2025-01-09-base",
    "scanId": "f6f795f3-0c45-449e-a556-f4f3ea84fbd6",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999978542327881,
                    "sentence": "Review of the Submission",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980330467224,
                    "sentence": "Summary and Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999971985816956,
                    "sentence": "This paper introduces a joint syntactic and semantic transition-based dependency parser inspired by Henderson et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999945163726807,
                    "sentence": "(2008), with two key innovations: the use of vectorial state representations via stack LSTMs and a greedy search algorithm.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999927282333374,
                    "sentence": "The core idea is the use of stack LSTMs to capture large-scoped syntactic features, such as the path between predicates and role fillers, which are critical for semantic role labeling (SRL).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999865293502808,
                    "sentence": "The system is evaluated on the CoNLL 2008 (English) and CoNLL 2009 (multilingual) datasets, achieving competitive performance compared to older systems and demonstrating the feasibility of joint parsing without hand-crafted features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999717473983765,
                    "sentence": "The parser's simplicity and speed, enabled by its greedy algorithm, make it a practical choice for real-world applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999861717224121,
                    "sentence": "The authors also promise an open-source implementation, which could benefit the research community.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999820590019226,
                    "sentence": "The primary contributions of this work are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999902248382568,
                    "sentence": "1. A novel application of stack LSTMs to joint syntactic and semantic dependency parsing, obviating the need for hand-crafted features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999878406524658,
                    "sentence": "2. A fast, greedy parsing algorithm that achieves competitive results on benchmark datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999856948852539,
                    "sentence": "3. A demonstration of the potential for joint parsing models to approach the performance of pipeline systems while maintaining simplicity and efficiency.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933838844299,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999935626983643,
                    "sentence": "1. Innovative Use of Stack LSTMs: The paper effectively leverages stack LSTMs to represent the entire parser state, enabling the model to capture long-range syntactic and semantic dependencies without relying on expensive, hand-crafted features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999989926815033,
                    "sentence": "This is a significant step forward in representation learning for joint parsing tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999934434890747,
                    "sentence": "2. Practical Efficiency: The greedy algorithm ensures linear-time parsing, making the system highly efficient.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999946355819702,
                    "sentence": "The reported runtime (177.6 seconds for CoNLL 2009 English test data) is impressive and demonstrates the system's potential for real-world applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999929070472717,
                    "sentence": "3. Well-Written and Clear Presentation: The paper is well-structured and provides a clear explanation of the proposed approach, including detailed descriptions of the transitions, stack LSTMs, and experimental setup.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933242797852,
                    "sentence": "4. Open-Source Commitment: The promise of releasing an open-source implementation is commendable and will likely encourage further research and adoption of the proposed method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999845027923584,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999943375587463,
                    "sentence": "1. Greedy Algorithm Limitations: While the greedy algorithm ensures speed, it sacrifices accuracy compared to beam search or global optimization methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998951554298401,
                    "sentence": "This trade-off limits the system's comparability to state-of-the-art models and may hinder its adoption for tasks requiring higher accuracy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996951222419739,
                    "sentence": "2. Evaluation Gaps: The system lags behind recent state-of-the-art SRL systems that use global optimization or additional annotated datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997053146362305,
                    "sentence": "The authors acknowledge this but do not provide a clear roadmap for integrating such advances into their model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.998637318611145,
                    "sentence": "3. Clarity Issues in Section 2: The explanation of A1 and C-A1 links is unclear, and the differences between the proposed transitions and Henderson et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991674423217773,
                    "sentence": "'s work are not sufficiently summarized.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984698295593262,
                    "sentence": "This could confuse readers unfamiliar with the prior work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9981588125228882,
                    "sentence": "4. Redundancy in Section 3.3: The necessity of concatenating word predicates with their disambiguated senses is questionable, as it seems redundant and adds complexity without clear justification.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9959233999252319,
                    "sentence": "5. Confusing Organization in Section 4: The separation of multilingual results into Sections 4.1 and 4.2 is unclear, making it difficult to follow the discussion of CoNLL 2008 and 2009 datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9972917437553406,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997225403785706,
                    "sentence": "1. Could you clarify the specific advantages of using stack LSTMs over other neural architectures for joint parsing tasks?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998707175254822,
                    "sentence": "2. Why was a greedy algorithm chosen over beam search, and how do you plan to address its limitations in future work?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998721480369568,
                    "sentence": "3. Could you elaborate on the rationale for concatenating word predicates with their disambiguated senses in Section 3.3?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994020462036133,
                    "sentence": "4. How does the system handle cases where the oracle conversion of semantic parses into transitions fails (e.g., the 1.5% of sentences in CoNLL 2009)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996291995048523,
                    "sentence": "Recommendation",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996894598007202,
                    "sentence": "This paper presents a promising approach to joint syntactic and semantic dependency parsing, with notable contributions in efficiency and representation learning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997380971908569,
                    "sentence": "However, the reliance on a greedy algorithm and the lack of clarity in certain sections slightly weaken its impact.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994155168533325,
                    "sentence": "I recommend acceptance with minor revisions to address the clarity issues and provide additional justification for design choices.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 34,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 35,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 0.9926183471516448,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9926183471516448,
                "mixed": 0.007381652848355174
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9926183471516448,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9926183471516448,
                    "human": 0,
                    "mixed": 0.007381652848355174
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Review of the Submission\nSummary and Contributions \nThis paper introduces a joint syntactic and semantic transition-based dependency parser inspired by Henderson et al. (2008), with two key innovations: the use of vectorial state representations via stack LSTMs and a greedy search algorithm. The core idea is the use of stack LSTMs to capture large-scoped syntactic features, such as the path between predicates and role fillers, which are critical for semantic role labeling (SRL). The system is evaluated on the CoNLL 2008 (English) and CoNLL 2009 (multilingual) datasets, achieving competitive performance compared to older systems and demonstrating the feasibility of joint parsing without hand-crafted features. The parser's simplicity and speed, enabled by its greedy algorithm, make it a practical choice for real-world applications. The authors also promise an open-source implementation, which could benefit the research community.\nThe primary contributions of this work are: \n1. A novel application of stack LSTMs to joint syntactic and semantic dependency parsing, obviating the need for hand-crafted features. \n2. A fast, greedy parsing algorithm that achieves competitive results on benchmark datasets. \n3. A demonstration of the potential for joint parsing models to approach the performance of pipeline systems while maintaining simplicity and efficiency.\nStrengths \n1. Innovative Use of Stack LSTMs: The paper effectively leverages stack LSTMs to represent the entire parser state, enabling the model to capture long-range syntactic and semantic dependencies without relying on expensive, hand-crafted features. This is a significant step forward in representation learning for joint parsing tasks. \n2. Practical Efficiency: The greedy algorithm ensures linear-time parsing, making the system highly efficient. The reported runtime (177.6 seconds for CoNLL 2009 English test data) is impressive and demonstrates the system's potential for real-world applications. \n3. Well-Written and Clear Presentation: The paper is well-structured and provides a clear explanation of the proposed approach, including detailed descriptions of the transitions, stack LSTMs, and experimental setup. \n4. Open-Source Commitment: The promise of releasing an open-source implementation is commendable and will likely encourage further research and adoption of the proposed method.\nWeaknesses \n1. Greedy Algorithm Limitations: While the greedy algorithm ensures speed, it sacrifices accuracy compared to beam search or global optimization methods. This trade-off limits the system's comparability to state-of-the-art models and may hinder its adoption for tasks requiring higher accuracy. \n2. Evaluation Gaps: The system lags behind recent state-of-the-art SRL systems that use global optimization or additional annotated datasets. The authors acknowledge this but do not provide a clear roadmap for integrating such advances into their model. \n3. Clarity Issues in Section 2: The explanation of A1 and C-A1 links is unclear, and the differences between the proposed transitions and Henderson et al.'s work are not sufficiently summarized. This could confuse readers unfamiliar with the prior work. \n4. Redundancy in Section 3.3: The necessity of concatenating word predicates with their disambiguated senses is questionable, as it seems redundant and adds complexity without clear justification. \n5. Confusing Organization in Section 4: The separation of multilingual results into Sections 4.1 and 4.2 is unclear, making it difficult to follow the discussion of CoNLL 2008 and 2009 datasets.\nQuestions to Authors \n1. Could you clarify the specific advantages of using stack LSTMs over other neural architectures for joint parsing tasks? \n2. Why was a greedy algorithm chosen over beam search, and how do you plan to address its limitations in future work? \n3. Could you elaborate on the rationale for concatenating word predicates with their disambiguated senses in Section 3.3? \n4. How does the system handle cases where the oracle conversion of semantic parses into transitions fails (e.g., the 1.5% of sentences in CoNLL 2009)? \nRecommendation \nThis paper presents a promising approach to joint syntactic and semantic dependency parsing, with notable contributions in efficiency and representation learning. However, the reliance on a greedy algorithm and the lack of clarity in certain sections slightly weaken its impact. I recommend acceptance with minor revisions to address the clarity issues and provide additional justification for design choices."
        }
    ]
}