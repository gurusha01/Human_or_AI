{
    "version": "2025-01-09-base",
    "scanId": "05a2853d-4c3a-4ac9-84bb-766a800c2d9c",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999892711639404,
                    "sentence": "General Comments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999411702156067,
                    "sentence": "The paper introduces a joint syntactic and semantic transition-based dependency parser, drawing inspiration from the joint parser proposed by Henderson et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999924898147583,
                    "sentence": "(2008).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999440312385559,
                    "sentence": "The authors highlight two primary distinctions in their approach:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999151229858398,
                    "sentence": "- Instead of focusing on the top elements of the stack or the last parser configurations, vectorial representations are employed for the entire parser state.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999232292175293,
                    "sentence": "- The parsing algorithm relies on plain greedy search.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998005628585815,
                    "sentence": "The central innovation lies in leveraging stack LSTMs to construct a vector representation of the parser state that retains information about potentially wide-ranging syntactic features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999745786190033,
                    "sentence": "These features are particularly impactful for semantic role labeling, such as the path between a predicate and the head of a candidate role filler.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999811589717865,
                    "sentence": "The system is evaluated on the CoNLL 2008 dataset (English) and the multilingual CoNLL 2009 dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999163150787354,
                    "sentence": "Performance comparisons with prior systems reveal that the proposed approach performs competitively with 2008/2009 systems but falls short compared to more recent methods (see the bottom of Table 3).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998502731323242,
                    "sentence": "However, the authors emphasize that their system does not rely on hand-crafted features and achieves high efficiency due to its simple greedy algorithm.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999193549156189,
                    "sentence": "The paper is well-written and demonstrates a significant amount of work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998810887336731,
                    "sentence": "It builds on the increasingly popular stack LSTMs and applies them to the Henderson et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7698739767074585,
                    "sentence": "algorithm, which, in hindsight, appears to have been ahead of its time.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6385712027549744,
                    "sentence": "One concern I have is the reliance on the simple greedy algorithm, which limits the comparability of results with some of the cited works.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.543349027633667,
                    "sentence": "Including performance results with beam search would not have required substantial additional effort or space and would have provided a more comprehensive evaluation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9320734739303589,
                    "sentence": "---",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.756560206413269,
                    "sentence": "Detailed Comments and Questions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9150993824005127,
                    "sentence": "Section 2:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8645755052566528,
                    "sentence": "Adding a brief explanation of the presence of both A1 and C-A1 links would enhance the reader's understanding of the target task addressed in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8942192196846008,
                    "sentence": "A concise summary of the differences between the transition set used in this work and that of Henderson et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8884416818618774,
                    "sentence": "would be helpful.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8720402121543884,
                    "sentence": "Currently, it is unclear which elements are directly reused from Henderson et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8767337203025818,
                    "sentence": "and which are novel or modified.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9501408338546753,
                    "sentence": "Section 3.3:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9500685930252075,
                    "sentence": "Why is it necessary to concatenate the word predicate with its disambiguated sense in the representations?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9408262968063354,
                    "sentence": "This seems redundant, as the disambiguated sense is already specific to the predicate.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.970171332359314,
                    "sentence": "Section 4:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9312093257904053,
                    "sentence": "The organization of Sections 4.1 and 4.2 is somewhat unclear regarding multilinguality.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9607620239257812,
                    "sentence": "CoNLL 2008 focuses on English, while the CoNLL 2009 shared task extends to multiple languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9553356766700745,
                    "sentence": "Clarifying this distinction would improve the section's readability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.45887534985363754
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 0.8104414442106259,
            "class_probabilities": {
                "human": 0.18643747192206747,
                "ai": 0.8104414442106259,
                "mixed": 0.0031210838673066464
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8104414442106259,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8104414442106259,
                    "human": 0.18643747192206747,
                    "mixed": 0.0031210838673066464
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "General Comments\nThe paper introduces a joint syntactic and semantic transition-based dependency parser, drawing inspiration from the joint parser proposed by Henderson et al. (2008). The authors highlight two primary distinctions in their approach: \n- Instead of focusing on the top elements of the stack or the last parser configurations, vectorial representations are employed for the entire parser state. \n- The parsing algorithm relies on plain greedy search. \nThe central innovation lies in leveraging stack LSTMs to construct a vector representation of the parser state that retains information about potentially wide-ranging syntactic features. These features are particularly impactful for semantic role labeling, such as the path between a predicate and the head of a candidate role filler. \nThe system is evaluated on the CoNLL 2008 dataset (English) and the multilingual CoNLL 2009 dataset. Performance comparisons with prior systems reveal that the proposed approach performs competitively with 2008/2009 systems but falls short compared to more recent methods (see the bottom of Table 3). However, the authors emphasize that their system does not rely on hand-crafted features and achieves high efficiency due to its simple greedy algorithm. \nThe paper is well-written and demonstrates a significant amount of work. It builds on the increasingly popular stack LSTMs and applies them to the Henderson et al. algorithm, which, in hindsight, appears to have been ahead of its time. \nOne concern I have is the reliance on the simple greedy algorithm, which limits the comparability of results with some of the cited works. Including performance results with beam search would not have required substantial additional effort or space and would have provided a more comprehensive evaluation. \n---\nDetailed Comments and Questions \nSection 2: \nAdding a brief explanation of the presence of both A1 and C-A1 links would enhance the reader's understanding of the target task addressed in the paper. \nA concise summary of the differences between the transition set used in this work and that of Henderson et al. would be helpful. Currently, it is unclear which elements are directly reused from Henderson et al. and which are novel or modified. \nSection 3.3: \nWhy is it necessary to concatenate the word predicate with its disambiguated sense in the representations? This seems redundant, as the disambiguated sense is already specific to the predicate. \nSection 4: \nThe organization of Sections 4.1 and 4.2 is somewhat unclear regarding multilinguality. CoNLL 2008 focuses on English, while the CoNLL 2009 shared task extends to multiple languages. Clarifying this distinction would improve the section's readability."
        }
    ]
}