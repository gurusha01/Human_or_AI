{
    "version": "2025-01-09-base",
    "scanId": "7153d3dc-9fbe-4d9d-9af1-d2ed9101db7f",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.991507887840271,
                    "sentence": "This paper introduces an approach for multilingual named entity recognition by leveraging features derived from Wikipedia.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9928685426712036,
                    "sentence": "Utilizing a cross-lingual Wikifier, it maps phrases in a target language to corresponding English Wikipedia articles and extracts features from the associated entries.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9921168684959412,
                    "sentence": "The experiments demonstrate that this novel feature benefits not only monolingual scenarios but also the more challenging direct transfer setting, where an English-trained model is evaluated on a target language.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.994530975818634,
                    "sentence": "I found this paper to be well-executed and innovative.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9969504475593567,
                    "sentence": "It introduces a novel feature for named entity recognition and presents a comprehensive set of experiments to validate its effectiveness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9967437386512756,
                    "sentence": "The analysis of low-resource and non-Latin script languages is particularly compelling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9977837800979614,
                    "sentence": "However, what happens with named entities that are absent from Wikipedia?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9976203441619873,
                    "sentence": "Beyond the results presented, it would be valuable to examine how the proposed method impacts the recognition of such entities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9979230165481567,
                    "sentence": "The method's reliance on the cross-lingual Wikifier is another critical aspect.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9951909780502319,
                    "sentence": "With this additional step in the pipeline, how frequently do prediction errors arise due to inaccuracies in the Wikifier?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9953165054321289,
                    "sentence": "Lastly, considering the poor performance of direct transfer on Tamil and Bengali when lexical features are incorporated, I wonder if it might be feasible to regularize the different feature classes separately.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9969350099563599,
                    "sentence": "This could potentially prevent the model from becoming overly dependent on lexical features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9984984300152882,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984984300152882,
                "mixed": 0.0015015699847118259
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984984300152882,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984984300152882,
                    "human": 0,
                    "mixed": 0.0015015699847118259
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper introduces an approach for multilingual named entity recognition by leveraging features derived from Wikipedia. Utilizing a cross-lingual Wikifier, it maps phrases in a target language to corresponding English Wikipedia articles and extracts features from the associated entries. The experiments demonstrate that this novel feature benefits not only monolingual scenarios but also the more challenging direct transfer setting, where an English-trained model is evaluated on a target language.\nI found this paper to be well-executed and innovative. It introduces a novel feature for named entity recognition and presents a comprehensive set of experiments to validate its effectiveness. The analysis of low-resource and non-Latin script languages is particularly compelling.\nHowever, what happens with named entities that are absent from Wikipedia? Beyond the results presented, it would be valuable to examine how the proposed method impacts the recognition of such entities.\nThe method's reliance on the cross-lingual Wikifier is another critical aspect. With this additional step in the pipeline, how frequently do prediction errors arise due to inaccuracies in the Wikifier?\nLastly, considering the poor performance of direct transfer on Tamil and Bengali when lexical features are incorporated, I wonder if it might be feasible to regularize the different feature classes separately. This could potentially prevent the model from becoming overly dependent on lexical features."
        }
    ]
}