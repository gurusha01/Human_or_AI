{
    "version": "2025-01-09-base",
    "scanId": "9ca25ca3-718e-4876-aceb-d844640f6479",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9885650873184204,
                    "sentence": "The paper introduces the first broad-coverage semantic parsers for UCCA, a specific framework for graph-based semantic representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9796916246414185,
                    "sentence": "Unlike CoNLL semantic dependency graphs, UCCA graphs include \"nonterminal\" nodes that do not correspond to words in the text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9505246877670288,
                    "sentence": "In contrast to AMRs, UCCA graphs are \"grounded,\" meaning that text tokens are directly represented as nodes in the semantic graph.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9248067736625671,
                    "sentence": "The authors propose several parsing approaches, including a transition-based parser designed to construct UCCA parses, and they evaluate these methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8817949295043945,
                    "sentence": "Given the existence of UCCA and UCCA-annotated datasets, developing a semantic parser for UCCA seems like a reasonable endeavor.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9167519211769104,
                    "sentence": "However, the introduction and background sections strike a discordant note by appearing to claim that UCCA is the only graph-based semantic representation (SR) formalism worth studying.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9379959106445312,
                    "sentence": "This argument feels unconvincing and unnecessary\"\"creating a strong UCCA parser would already be a valuable contribution on its own.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9590721726417542,
                    "sentence": "I do not fully agree with the three criteria for semantic representation formalisms outlined in the introduction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9729065895080566,
                    "sentence": "For example, I am not convinced that \"nonterminal nodes\" add any significant expressive power.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9914497137069702,
                    "sentence": "While deciding on a head for a coordinated structure can be inconvenient, it is unclear what information could be captured with nonterminals that could not be represented through more informative edge labels.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9844000339508057,
                    "sentence": "Additionally, the issue of discontinuity does not arise in SRs that are not \"grounded.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9769368171691895,
                    "sentence": "The claimed advantages of \"grounded\" representations over AMR-style ones remain unclear to me.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992926716804504,
                    "sentence": "Furthermore, the term \"grounded\" has been used to describe various concepts in semantics over the past decade, and I suggest the authors consider alternative terminology, such as \"anchored\" or \"lexicalized.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999334454536438,
                    "sentence": "Overall, I believe the introductory section would benefit from more careful phrasing and argumentation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9926995635032654,
                    "sentence": "The parser itself appears adequate, though I did not verify the implementation details.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9842207431793213,
                    "sentence": "However, the evaluation results are not particularly compelling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9631019234657288,
                    "sentence": "For \"primary\" edges, the BSP parser underperforms compared to a straightforward MaltParser, and the f-scores for \"remote\" edges (which a dependency-tree parser like Malt cannot compute directly) are also relatively low.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8798748850822449,
                    "sentence": "Additionally, the problem of converting dependency graphs to dependency trees has been extensively studied under the term \"tree approximations,\" particularly in the CoNLL 2014 and 2015 shared tasks on semantic dependency parsing (albeit without \"nonterminal\" nodes).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9290570020675659,
                    "sentence": "Several researchers, such as Agi√Ñ et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.774430513381958,
                    "sentence": "(2015) in their work \"Semantic dependency graph parsing using tree approximations,\" have explored methods for reconstructing edges removed during graph-to-tree conversion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8307569026947021,
                    "sentence": "Incorporating such techniques could likely improve the f-scores of the MaltParser (and the LSTM-based MaltParser), which would further diminish the perceived advantage of the BSP parser.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 7,
                    "completely_generated_prob": 0.9103421900070616
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 7,
                    "completely_generated_prob": 0.7604022122935274
                }
            ],
            "completely_generated_prob": 0.9841954571483108,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9841954571483108,
                "mixed": 0.015804542851689255
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9841954571483108,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9841954571483108,
                    "human": 0,
                    "mixed": 0.015804542851689255
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "The paper introduces the first broad-coverage semantic parsers for UCCA, a specific framework for graph-based semantic representations. Unlike CoNLL semantic dependency graphs, UCCA graphs include \"nonterminal\" nodes that do not correspond to words in the text. In contrast to AMRs, UCCA graphs are \"grounded,\" meaning that text tokens are directly represented as nodes in the semantic graph. The authors propose several parsing approaches, including a transition-based parser designed to construct UCCA parses, and they evaluate these methods.\nGiven the existence of UCCA and UCCA-annotated datasets, developing a semantic parser for UCCA seems like a reasonable endeavor. However, the introduction and background sections strike a discordant note by appearing to claim that UCCA is the only graph-based semantic representation (SR) formalism worth studying. This argument feels unconvincing and unnecessary\"\"creating a strong UCCA parser would already be a valuable contribution on its own.\nI do not fully agree with the three criteria for semantic representation formalisms outlined in the introduction. For example, I am not convinced that \"nonterminal nodes\" add any significant expressive power. While deciding on a head for a coordinated structure can be inconvenient, it is unclear what information could be captured with nonterminals that could not be represented through more informative edge labels. Additionally, the issue of discontinuity does not arise in SRs that are not \"grounded.\" The claimed advantages of \"grounded\" representations over AMR-style ones remain unclear to me. Furthermore, the term \"grounded\" has been used to describe various concepts in semantics over the past decade, and I suggest the authors consider alternative terminology, such as \"anchored\" or \"lexicalized.\" Overall, I believe the introductory section would benefit from more careful phrasing and argumentation.\nThe parser itself appears adequate, though I did not verify the implementation details. However, the evaluation results are not particularly compelling. For \"primary\" edges, the BSP parser underperforms compared to a straightforward MaltParser, and the f-scores for \"remote\" edges (which a dependency-tree parser like Malt cannot compute directly) are also relatively low. Additionally, the problem of converting dependency graphs to dependency trees has been extensively studied under the term \"tree approximations,\" particularly in the CoNLL 2014 and 2015 shared tasks on semantic dependency parsing (albeit without \"nonterminal\" nodes). Several researchers, such as Agi√Ñ et al. (2015) in their work \"Semantic dependency graph parsing using tree approximations,\" have explored methods for reconstructing edges removed during graph-to-tree conversion. Incorporating such techniques could likely improve the f-scores of the MaltParser (and the LSTM-based MaltParser), which would further diminish the perceived advantage of the BSP parser."
        }
    ]
}