{
    "version": "2025-01-09-base",
    "scanId": "2a3a6da7-0cd8-48d7-8fe7-dae56a35d4d0",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.6673531532287598,
                    "sentence": "This paper introduces a Stack LSTM parser that builds upon the foundational work of Henderson et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6522496938705444,
                    "sentence": "(2008, 2013) on joint syntactic/semantic transition-based parsing and Dyer et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5992217063903809,
                    "sentence": "(2015) on stack LSTM syntactic parsing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5568143129348755,
                    "sentence": "By combining the transition system from the former with the stack LSTM from the latter, the paper demonstrates compelling results when compared to joint systems on the CoNLL 2008 and 2009 shared tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5700473785400391,
                    "sentence": "I found this paper to be highly commendable due to its clarity, thorough explanations, strong related work, and intriguing results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.3812183737754822,
                    "sentence": "The methodology is robust, though I have a minor concern regarding the Chinese embeddings, which suggests that high-quality embeddings might sometimes outweigh the benefits of an innovative model design.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.4019242227077484,
                    "sentence": "Additionally, the system's description is detailed, the choice of hyperparameters is well-justified, and the discussion is engaging and insightful.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6248484253883362,
                    "sentence": "The only critique I have is that the proposed system lacks novelty to some extent.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9068673253059387,
                    "sentence": "Henderson et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8219728469848633,
                    "sentence": "laid the groundwork for semi-synchronized joint syntax-semantic transition-based parsing several years ago, and Dyer et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8894442319869995,
                    "sentence": "introduced the stack LSTM approach last year.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.799328625202179,
                    "sentence": "Thus, the method itself is not entirely new.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8129646182060242,
                    "sentence": "However, I believe this parser was a natural and necessary progression, and I am pleased to see it developed in this work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.0006564766595293492
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.3436238582234724
                }
            ],
            "completely_generated_prob": 0.700057355423365,
            "class_probabilities": {
                "human": 0.29719122298149875,
                "ai": 0.700057355423365,
                "mixed": 0.00275142159513626
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.700057355423365,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.700057355423365,
                    "human": 0.29719122298149875,
                    "mixed": 0.00275142159513626
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper introduces a Stack LSTM parser that builds upon the foundational work of Henderson et al. (2008, 2013) on joint syntactic/semantic transition-based parsing and Dyer et al. (2015) on stack LSTM syntactic parsing. By combining the transition system from the former with the stack LSTM from the latter, the paper demonstrates compelling results when compared to joint systems on the CoNLL 2008 and 2009 shared tasks.\nI found this paper to be highly commendable due to its clarity, thorough explanations, strong related work, and intriguing results. The methodology is robust, though I have a minor concern regarding the Chinese embeddings, which suggests that high-quality embeddings might sometimes outweigh the benefits of an innovative model design.\nAdditionally, the system's description is detailed, the choice of hyperparameters is well-justified, and the discussion is engaging and insightful.\nThe only critique I have is that the proposed system lacks novelty to some extent. Henderson et al. laid the groundwork for semi-synchronized joint syntax-semantic transition-based parsing several years ago, and Dyer et al. introduced the stack LSTM approach last year. Thus, the method itself is not entirely new. However, I believe this parser was a natural and necessary progression, and I am pleased to see it developed in this work."
        }
    ]
}