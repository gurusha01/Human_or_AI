{
    "version": "2025-01-09-base",
    "scanId": "f1b80fa6-5aaa-4040-a1c1-d5dc18d2210a",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9982690215110779,
                    "sentence": "This paper introduces a method for identifying correspondences between languages using the Minimum Description Length (MDL) principle.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.997102677822113,
                    "sentence": "The author models correspondences between words with identical meanings across multiple Slavic languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.993934154510498,
                    "sentence": "They design codes for rules that align substrings in two or more languages and define an MDL objective that balances the complexity of the model with the data it explains.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9968022108078003,
                    "sentence": "The model is trained using the Expectation-Maximization (EM) algorithm and evaluated on a dataset of 13 Slavic languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9921324849128723,
                    "sentence": "The results are presented through various distance metrics, a phylogenetic tree, and examples of discovered correspondences.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9919798374176025,
                    "sentence": "The motivation and theoretical framework of the approach are sound.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9942654967308044,
                    "sentence": "MDL appears to be a suitable tool for addressing the problem, and the rationale for employing EM is well-articulated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9938889145851135,
                    "sentence": "However, some of the derivations were not entirely clear to me.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.996310830116272,
                    "sentence": "The authors highlight the similarity between the MDL objective and Bayesian inference, which brings to mind its application in (biological) phylogenetic inference, such as through the MrBayes tool.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.989208996295929,
                    "sentence": "An empirical comparison in this context could provide valuable insights.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9815196990966797,
                    "sentence": "Related Work",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9947424530982971,
                    "sentence": "- The paper lacks a comparison to existing methods for borrowing and cognate detection or other computational approaches in historical linguistics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9950375556945801,
                    "sentence": "For instance, studies by Alexandre Bouchard-CÃ'tÃ©, Tandy Warnow, Luay Nakhleh, and Andrew Kitchen are relevant.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9845783710479736,
                    "sentence": "While some tools may not be directly applicable to the given dataset, the authors could mention works like List and Moran (2013).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9871370792388916,
                    "sentence": "Additionally, tools from biological phylogenetics, such as PAUP* or MrBayes, could be considered.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.993026852607727,
                    "sentence": "Approach and Methodology",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9887406826019287,
                    "sentence": "- Alignment Procedure: The memory and runtime limitations seem to restrict the comparison to a maximum of five languages at a time.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9810267090797424,
                    "sentence": "Given the involvement of multiple languages and phylogenetic trees, it would be interesting to see how the authors plan to address this bottleneck.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9846019148826599,
                    "sentence": "- Phylogenetic Tree: The use of neighbor-joining for constructing phylogenetic trees has known drawbacks, such as the need for manual root specification.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9862000942230225,
                    "sentence": "Could more advanced methods be explored?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9958459734916687,
                    "sentence": "- EM Algorithm: Do the authors run the EM algorithm until convergence, or is there an alternative stopping criterion?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9960777163505554,
                    "sentence": "Data",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9960243701934814,
                    "sentence": "- The study combines two datasets: one of cognates and another that is not necessarily cognate-based (Swadesh lists).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9941545724868774,
                    "sentence": "Have the authors considered how this might affect the results?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9940182566642761,
                    "sentence": "- The data is presented in orthographic form, which could obscure many correspondences, particularly in languages with different scripts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.8615615367889404,
                    "sentence": "As a result, the learned rules might reflect script changes rather than genuine linguistic correspondences.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.7127348184585571,
                    "sentence": "This limitation could potentially be mitigated by working with phonetic transcriptions instead.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1283271610736847,
                    "sentence": "Unclear Points",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1057334765791893,
                    "sentence": "- What is meant by the \"optimal unigram for symbol usages in all rules\" (line 286)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1053151786327362,
                    "sentence": "- The merging process described in the maximization step was not entirely clear to me.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10638953745365143,
                    "sentence": "Minor Issue",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08484955877065659,
                    "sentence": "- Replace \"focus in on\" with \"focus on\" (line 440).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.19626827538013458,
                    "sentence": "References",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11494354903697968,
                    "sentence": "- Johann-Mattis List, Steven Moran.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.13061419129371643,
                    "sentence": "2013. An Open Source Toolkit for Quantitative Historical Linguistics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.028603442013263702,
                    "sentence": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 13\"\"18, Sofia, Bulgaria.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.030811099335551262,
                    "sentence": "Association for Computational Linguistics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02683766558766365,
                    "sentence": "[http://www.aclweb.org/anthology/P13-4003](http://www.aclweb.org/anthology/P13-4003).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.02582637593150139,
                    "sentence": "- Andrew Kitchen, Christopher Ehret, Shiferaw Assefa, and Connie J. Mulligan.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.03777160495519638,
                    "sentence": "2009. Bayesian phylogenetic analysis of Semitic languages identifies an Early Bronze Age origin of Semitic in the Near East.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.45887534985363754
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.00010005932717626924
                },
                {
                    "start_sentence_index": 38,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                }
            ],
            "completely_generated_prob": 0.49279214804212246,
            "class_probabilities": {
                "human": 0.5033519797858822,
                "ai": 0.49279214804212246,
                "mixed": 0.0038558721719952668
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.5033519797858822,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.49279214804212246,
                    "human": 0.5033519797858822,
                    "mixed": 0.0038558721719952668
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "This paper introduces a method for identifying correspondences between languages using the Minimum Description Length (MDL) principle. The author models correspondences between words with identical meanings across multiple Slavic languages. They design codes for rules that align substrings in two or more languages and define an MDL objective that balances the complexity of the model with the data it explains. The model is trained using the Expectation-Maximization (EM) algorithm and evaluated on a dataset of 13 Slavic languages. The results are presented through various distance metrics, a phylogenetic tree, and examples of discovered correspondences.\nThe motivation and theoretical framework of the approach are sound. MDL appears to be a suitable tool for addressing the problem, and the rationale for employing EM is well-articulated. However, some of the derivations were not entirely clear to me. The authors highlight the similarity between the MDL objective and Bayesian inference, which brings to mind its application in (biological) phylogenetic inference, such as through the MrBayes tool. An empirical comparison in this context could provide valuable insights.\nRelated Work\n- The paper lacks a comparison to existing methods for borrowing and cognate detection or other computational approaches in historical linguistics. For instance, studies by Alexandre Bouchard-CÃ´tÃ©, Tandy Warnow, Luay Nakhleh, and Andrew Kitchen are relevant. While some tools may not be directly applicable to the given dataset, the authors could mention works like List and Moran (2013). Additionally, tools from biological phylogenetics, such as PAUP* or MrBayes, could be considered.\nApproach and Methodology\n- Alignment Procedure: The memory and runtime limitations seem to restrict the comparison to a maximum of five languages at a time. Given the involvement of multiple languages and phylogenetic trees, it would be interesting to see how the authors plan to address this bottleneck.\n- Phylogenetic Tree: The use of neighbor-joining for constructing phylogenetic trees has known drawbacks, such as the need for manual root specification. Could more advanced methods be explored?\n- EM Algorithm: Do the authors run the EM algorithm until convergence, or is there an alternative stopping criterion?\nData\n- The study combines two datasets: one of cognates and another that is not necessarily cognate-based (Swadesh lists). Have the authors considered how this might affect the results?\n- The data is presented in orthographic form, which could obscure many correspondences, particularly in languages with different scripts. As a result, the learned rules might reflect script changes rather than genuine linguistic correspondences. This limitation could potentially be mitigated by working with phonetic transcriptions instead.\nUnclear Points\n- What is meant by the \"optimal unigram for symbol usages in all rules\" (line 286)?\n- The merging process described in the maximization step was not entirely clear to me.\nMinor Issue\n- Replace \"focus in on\" with \"focus on\" (line 440).\nReferences\n- Johann-Mattis List, Steven Moran. 2013. An Open Source Toolkit for Quantitative Historical Linguistics. Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 13\"\"18, Sofia, Bulgaria. Association for Computational Linguistics. [http://www.aclweb.org/anthology/P13-4003](http://www.aclweb.org/anthology/P13-4003).\n- Andrew Kitchen, Christopher Ehret, Shiferaw Assefa, and Connie J. Mulligan. 2009. Bayesian phylogenetic analysis of Semitic languages identifies an Early Bronze Age origin of Semitic in the Near East."
        }
    ]
}