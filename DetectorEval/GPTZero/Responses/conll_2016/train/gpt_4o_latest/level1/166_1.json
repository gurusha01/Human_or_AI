{
    "version": "2025-01-09-base",
    "scanId": "a0ca443a-be9d-464c-8835-1c037260cb4e",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999954700469971,
                    "sentence": "Review of the Submission",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999974966049194,
                    "sentence": "Summary and Contributions:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999954104423523,
                    "sentence": "This paper addresses the challenging task of Named Entity Recognition (NER) in low-resource and cross-lingual settings by leveraging cross-lingual wikification to generate language-independent features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999945163726807,
                    "sentence": "The authors propose a novel NER model that grounds words and phrases in non-English texts to English Wikipedia entries, utilizing FreeBase types and Wikipedia categories as features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960064888,
                    "sentence": "The model demonstrates strong performance in both monolingual and cross-lingual scenarios, outperforming state-of-the-art methods on CoNLL datasets (Spanish, German, Dutch) and five low-resource languages (Turkish, Tagalog, Yoruba, Bengali, Tamil).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999955296516418,
                    "sentence": "Additionally, the paper highlights the utility of training on multiple source languages and shows that the proposed features enhance monolingual NER systems as well.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999956488609314,
                    "sentence": "The main contributions of the paper are:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960064888,
                    "sentence": "1. Cross-lingual Wikification for NER: The introduction of a language-independent approach to NER using cross-lingual wikification, which provides robust features for both high-resource and low-resource languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999937415122986,
                    "sentence": "2. Performance on Low-Resource Languages: The model achieves competitive results on low-resource languages without requiring parallel corpora or native speaker interaction, demonstrating its practicality and scalability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994158744812,
                    "sentence": "3. Multi-Source Training: The paper shows that training on multiple source languages improves NER performance on target languages, illustrating the model's adaptability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999932050704956,
                    "sentence": "Strengths:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999992847442627,
                    "sentence": "1. Novelty and Practicality: The use of cross-lingual wikification as a core feature for NER is innovative and eliminates the need for language-specific annotated data, making the approach highly scalable across languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999938607215881,
                    "sentence": "2. Comprehensive Evaluation: The paper evaluates the model on a diverse set of languages, including low-resource languages with non-Latin scripts, and provides detailed analyses of feature contributions and the impact of Wikipedia size.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999953508377075,
                    "sentence": "3. Strong Results: The proposed model consistently outperforms baselines and state-of-the-art methods in both monolingual and cross-lingual settings, particularly for low-resource languages where other methods struggle.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999992847442627,
                    "sentence": "4. Resource Efficiency: The model requires only a multilingual Wikipedia dump, avoiding the need for parallel corpora or extensive language-specific preprocessing, which is a significant advantage for low-resource settings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999857544898987,
                    "sentence": "Weaknesses:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996769428253174,
                    "sentence": "1. Dependence on Wikipedia Size: The model's reliance on Wikipedia size limits its effectiveness for languages with sparse Wikipedia coverage, as shown in the experiments with Yoruba, Bengali, and Tamil.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998770952224731,
                    "sentence": "This dependency could hinder its applicability to truly low-resource languages with minimal Wikipedia presence.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999859631061554,
                    "sentence": "2. Limited Exploration of Additional Features: While the paper focuses on FreeBase types and Wikipedia categories, it does not explore other potentially valuable information from Wikipedia, such as document-level context or inter-title relations, which could further enhance performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998373985290527,
                    "sentence": "3. Evaluation Scope: The evaluation is limited to NER tasks and does not explore the potential of the proposed features in other NLP tasks, such as entity linking or relation extraction, which could broaden the impact of the work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9991196393966675,
                    "sentence": "Questions to Authors:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989376068115234,
                    "sentence": "1. How does the model handle ambiguous or noisy wikification results, particularly in low-resource languages with limited Wikipedia coverage?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9972878098487854,
                    "sentence": "2. Have you considered incorporating other Wikipedia-derived features, such as document-level context or inter-title relations, to improve performance?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9967138767242432,
                    "sentence": "3. Could the proposed approach be extended to other NLP tasks, such as entity linking or relation extraction?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9978896975517273,
                    "sentence": "If so, what modifications would be required?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990453124046326,
                    "sentence": "Conclusion:",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9957537651062012,
                    "sentence": "This paper presents a significant contribution to cross-lingual NER by introducing a scalable, language-independent model based on cross-lingual wikification.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.994499146938324,
                    "sentence": "While the reliance on Wikipedia size is a limitation, the approach is practical, innovative, and demonstrates strong results across a wide range of languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9873019456863403,
                    "sentence": "I recommend acceptance, with minor revisions to address the aforementioned weaknesses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 0.9984984300152882,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984984300152882,
                "mixed": 0.0015015699847118259
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984984300152882,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984984300152882,
                    "human": 0,
                    "mixed": 0.0015015699847118259
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Review of the Submission\nSummary and Contributions:\nThis paper addresses the challenging task of Named Entity Recognition (NER) in low-resource and cross-lingual settings by leveraging cross-lingual wikification to generate language-independent features. The authors propose a novel NER model that grounds words and phrases in non-English texts to English Wikipedia entries, utilizing FreeBase types and Wikipedia categories as features. The model demonstrates strong performance in both monolingual and cross-lingual scenarios, outperforming state-of-the-art methods on CoNLL datasets (Spanish, German, Dutch) and five low-resource languages (Turkish, Tagalog, Yoruba, Bengali, Tamil). Additionally, the paper highlights the utility of training on multiple source languages and shows that the proposed features enhance monolingual NER systems as well.\nThe main contributions of the paper are:\n1. Cross-lingual Wikification for NER: The introduction of a language-independent approach to NER using cross-lingual wikification, which provides robust features for both high-resource and low-resource languages.\n2. Performance on Low-Resource Languages: The model achieves competitive results on low-resource languages without requiring parallel corpora or native speaker interaction, demonstrating its practicality and scalability.\n3. Multi-Source Training: The paper shows that training on multiple source languages improves NER performance on target languages, illustrating the model's adaptability.\nStrengths:\n1. Novelty and Practicality: The use of cross-lingual wikification as a core feature for NER is innovative and eliminates the need for language-specific annotated data, making the approach highly scalable across languages.\n2. Comprehensive Evaluation: The paper evaluates the model on a diverse set of languages, including low-resource languages with non-Latin scripts, and provides detailed analyses of feature contributions and the impact of Wikipedia size.\n3. Strong Results: The proposed model consistently outperforms baselines and state-of-the-art methods in both monolingual and cross-lingual settings, particularly for low-resource languages where other methods struggle.\n4. Resource Efficiency: The model requires only a multilingual Wikipedia dump, avoiding the need for parallel corpora or extensive language-specific preprocessing, which is a significant advantage for low-resource settings.\nWeaknesses:\n1. Dependence on Wikipedia Size: The model's reliance on Wikipedia size limits its effectiveness for languages with sparse Wikipedia coverage, as shown in the experiments with Yoruba, Bengali, and Tamil. This dependency could hinder its applicability to truly low-resource languages with minimal Wikipedia presence.\n2. Limited Exploration of Additional Features: While the paper focuses on FreeBase types and Wikipedia categories, it does not explore other potentially valuable information from Wikipedia, such as document-level context or inter-title relations, which could further enhance performance.\n3. Evaluation Scope: The evaluation is limited to NER tasks and does not explore the potential of the proposed features in other NLP tasks, such as entity linking or relation extraction, which could broaden the impact of the work.\nQuestions to Authors:\n1. How does the model handle ambiguous or noisy wikification results, particularly in low-resource languages with limited Wikipedia coverage?\n2. Have you considered incorporating other Wikipedia-derived features, such as document-level context or inter-title relations, to improve performance?\n3. Could the proposed approach be extended to other NLP tasks, such as entity linking or relation extraction? If so, what modifications would be required?\nConclusion:\nThis paper presents a significant contribution to cross-lingual NER by introducing a scalable, language-independent model based on cross-lingual wikification. While the reliance on Wikipedia size is a limitation, the approach is practical, innovative, and demonstrates strong results across a wide range of languages. I recommend acceptance, with minor revisions to address the aforementioned weaknesses."
        }
    ]
}