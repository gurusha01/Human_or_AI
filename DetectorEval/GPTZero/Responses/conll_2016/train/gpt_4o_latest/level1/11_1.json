{
    "version": "2025-01-09-base",
    "scanId": "f2d5e79a-f463-4101-aa68-66dbeb2e287b",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999947547912598,
                    "sentence": "Review",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999992847442627,
                    "sentence": "Summary of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "This paper addresses the task of identifying all mentions of the main concept (MC) described in a Wikipedia article, a seldom-studied problem in the domain of coreference resolution (CR).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "The authors propose a binary classification approach that leverages Wikipedia's structured markup and external knowledge bases like Freebase to extract features for mention classification.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "Their classifier outperforms baselines built on state-of-the-art CR systems, achieving significant improvements in precision, recall, and F1 scores.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999992251396179,
                    "sentence": "Additionally, the authors demonstrate that integrating their classifier into a rule-based CR system (Dcoref) enhances overall coreference resolution performance on Wikipedia texts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999994039535522,
                    "sentence": "The paper also introduces a new dataset (WCR) for evaluating CR systems on Wikipedia articles.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999995827674866,
                    "sentence": "Main Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "1. Novel Task and Dataset: The paper revisits the underexplored task of identifying mentions of the MC in Wikipedia articles and introduces the WCR dataset, a dedicated resource for evaluating CR systems on this text genre.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980330467224,
                    "sentence": "This dataset is a valuable contribution, as it addresses the lack of resources for non-newswire texts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977946281433,
                    "sentence": "2. Feature-Rich Classifier: The authors design a classifier that incorporates features derived from Wikipedia markup and Freebase, including semantic attributes, entity types, and positional information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999984502792358,
                    "sentence": "The classifier achieves a significant improvement (13 F1 points) over baselines, demonstrating its effectiveness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "3. Improved CR Pipeline: By integrating their classifier into the Dcoref system, the authors enhance coreference resolution performance on Wikipedia texts, achieving a 4-point improvement in CoNLL F1 score.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "This demonstrates the practical utility of their approach in a full CR pipeline.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999985098838806,
                    "sentence": "Strengths",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986290931702,
                    "sentence": "1. Significant Performance Gains: The proposed classifier achieves substantial improvements over state-of-the-art baselines, particularly in identifying pronominal and non-pronominal mentions of the MC.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980926513672,
                    "sentence": "The results are well-supported by detailed experiments and ablation studies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983906745911,
                    "sentence": "2. Effective Use of External Knowledge: The paper demonstrates how Wikipedia markup and Freebase attributes can be effectively leveraged to improve CR performance, avoiding the cascading errors often associated with named-entity linking pipelines.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983906745911,
                    "sentence": "3. Practical Integration: The integration of the classifier into Dcoref shows that the proposed approach is not only effective in isolation but also enhances the performance of an established CR system, making it a practical contribution to the field.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998672604560852,
                    "sentence": "4. Dataset Contribution: The WCR dataset fills a critical gap in CR research by providing a resource tailored to Wikipedia texts, which differ significantly from traditional newswire datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999963641166687,
                    "sentence": "Weaknesses",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998552799224854,
                    "sentence": "1. Limited Generalization Beyond Wikipedia: While the approach is well-suited for Wikipedia articles, its reliance on Wikipedia-specific markup and Freebase attributes may limit its applicability to other text genres or domains without similar structured resources.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998341798782349,
                    "sentence": "2. Feature Engineering Complexity: The classifier relies on a large number of hand-crafted features, which may require significant effort to adapt to other datasets or tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993200302124023,
                    "sentence": "A discussion on the scalability of this approach to other domains would strengthen the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995927810668945,
                    "sentence": "3. Evaluation Scope: The evaluation focuses primarily on the MC identification task and its impact on Dcoref.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984797239303589,
                    "sentence": "However, the broader implications for general CR tasks beyond Wikipedia are not explored in depth.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9971743822097778,
                    "sentence": "Questions to Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984803199768066,
                    "sentence": "1. How well does the proposed approach generalize to other text genres or domains that lack structured markup like Wikipedia?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9946891665458679,
                    "sentence": "2. Could the reliance on Freebase, which is no longer actively maintained, pose challenges for future applications of this method?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9981286525726318,
                    "sentence": "Are there alternative knowledge bases that could be used?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9962266087532043,
                    "sentence": "3. Have you considered extending the classifier to identify mentions of secondary concepts in Wikipedia articles?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9929316639900208,
                    "sentence": "If so, what challenges do you anticipate?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9899758100509644,
                    "sentence": "Additional Comments",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.997774600982666,
                    "sentence": "Overall, this paper makes a strong contribution to the field of coreference resolution by addressing a novel task, introducing a valuable dataset, and demonstrating significant performance improvements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9982598423957825,
                    "sentence": "However, the reliance on Wikipedia-specific features and external knowledge bases raises questions about the generalizability of the approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987097978591919,
                    "sentence": "Future work could explore adapting the method to other domains or leveraging more generalizable features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 33,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 0.9984800378301695,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9984800378301695,
                "mixed": 0.0015199621698304396
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9984800378301695,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9984800378301695,
                    "human": 0,
                    "mixed": 0.0015199621698304396
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.65,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.92
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.65,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-01-09-base",
            "language": "en",
            "inputText": "Review\nSummary of the Paper\nThis paper addresses the task of identifying all mentions of the main concept (MC) described in a Wikipedia article, a seldom-studied problem in the domain of coreference resolution (CR). The authors propose a binary classification approach that leverages Wikipedia's structured markup and external knowledge bases like Freebase to extract features for mention classification. Their classifier outperforms baselines built on state-of-the-art CR systems, achieving significant improvements in precision, recall, and F1 scores. Additionally, the authors demonstrate that integrating their classifier into a rule-based CR system (Dcoref) enhances overall coreference resolution performance on Wikipedia texts. The paper also introduces a new dataset (WCR) for evaluating CR systems on Wikipedia articles.\nMain Contributions\n1. Novel Task and Dataset: The paper revisits the underexplored task of identifying mentions of the MC in Wikipedia articles and introduces the WCR dataset, a dedicated resource for evaluating CR systems on this text genre. This dataset is a valuable contribution, as it addresses the lack of resources for non-newswire texts.\n2. Feature-Rich Classifier: The authors design a classifier that incorporates features derived from Wikipedia markup and Freebase, including semantic attributes, entity types, and positional information. The classifier achieves a significant improvement (13 F1 points) over baselines, demonstrating its effectiveness.\n3. Improved CR Pipeline: By integrating their classifier into the Dcoref system, the authors enhance coreference resolution performance on Wikipedia texts, achieving a 4-point improvement in CoNLL F1 score. This demonstrates the practical utility of their approach in a full CR pipeline.\nStrengths\n1. Significant Performance Gains: The proposed classifier achieves substantial improvements over state-of-the-art baselines, particularly in identifying pronominal and non-pronominal mentions of the MC. The results are well-supported by detailed experiments and ablation studies.\n2. Effective Use of External Knowledge: The paper demonstrates how Wikipedia markup and Freebase attributes can be effectively leveraged to improve CR performance, avoiding the cascading errors often associated with named-entity linking pipelines.\n3. Practical Integration: The integration of the classifier into Dcoref shows that the proposed approach is not only effective in isolation but also enhances the performance of an established CR system, making it a practical contribution to the field.\n4. Dataset Contribution: The WCR dataset fills a critical gap in CR research by providing a resource tailored to Wikipedia texts, which differ significantly from traditional newswire datasets.\nWeaknesses\n1. Limited Generalization Beyond Wikipedia: While the approach is well-suited for Wikipedia articles, its reliance on Wikipedia-specific markup and Freebase attributes may limit its applicability to other text genres or domains without similar structured resources.\n2. Feature Engineering Complexity: The classifier relies on a large number of hand-crafted features, which may require significant effort to adapt to other datasets or tasks. A discussion on the scalability of this approach to other domains would strengthen the paper.\n3. Evaluation Scope: The evaluation focuses primarily on the MC identification task and its impact on Dcoref. However, the broader implications for general CR tasks beyond Wikipedia are not explored in depth.\nQuestions to Authors\n1. How well does the proposed approach generalize to other text genres or domains that lack structured markup like Wikipedia?\n2. Could the reliance on Freebase, which is no longer actively maintained, pose challenges for future applications of this method? Are there alternative knowledge bases that could be used?\n3. Have you considered extending the classifier to identify mentions of secondary concepts in Wikipedia articles? If so, what challenges do you anticipate?\nAdditional Comments\nOverall, this paper makes a strong contribution to the field of coreference resolution by addressing a novel task, introducing a valuable dataset, and demonstrating significant performance improvements. However, the reliance on Wikipedia-specific features and external knowledge bases raises questions about the generalizability of the approach. Future work could explore adapting the method to other domains or leveraging more generalizable features."
        }
    ]
}