{
    "version": "2025-03-13-base",
    "scanId": "6fb20271-69c5-4e4a-afd5-9903df4ae0ba",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999012351036072,
                    "sentence": "The paper presents an approach called Positive only Projection (PoF) which creates semantic spaces and word embeddings through random projections that differ from conventional methods by using a positive random projection matrix \\( R \\).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999012351036072,
                    "sentence": "This allows for the implementation of weighting strategies, like Positive Pointwise Mutual Information (PPMI).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999156594276428,
                    "sentence": "The authors show that combining PoS with PPM is effective in similarity tasks like the MEN relatedness test, in a way that is both efficient and scalable computationally.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999917209148407,
                    "sentence": "Introducing Poisson Point Process (PoPP) an approach to reducing dimensionality randomly that builds semantic spaces gradually and effectively overcomes the drawbacks of current random projection techniques (such as RI) allowing for additional post projection modifications, like PPM transformations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998948574066162,
                    "sentence": "The PoS + PPM + Pearson blend delivers a Spearman correlation of 0 75 on the MEN evaluation, as state of the art embeddings do but without requiring resource intensive training processes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999026656150818,
                    "sentence": "The paper thoroughly examines how dimensionality and sparsity factors and different weighting techniques influence the performance of PoPs (Probability of Performance) shedding light on how they function and can be improved.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999010562896729,
                    "sentence": "Areas of expertise",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999127388000488,
                    "sentence": "Computational efficiency is a feature of the Poisson Point Process (PoPP) method as it is scalable and economical, in terms of computational resources when compared to neural embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999300837516785,
                    "sentence": "The capacity to employ PPMIs in PoPop built areas is an advantage since it connects random projection methods, with count based models and takes advantage of the strengths of both techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999363422393799,
                    "sentence": "The paper presents experimental findings that include comparisons with RI and count based models and detailed examinations of parameters studies to validate the methods effectiveness, across various configurations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999460577964783,
                    "sentence": "The article provides an explanation of the PoI method including its mathematical basis and practical application for those who are knowledgeable, about random projection techniques and distributional semantics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999219179153442,
                    "sentence": "Areas of improvement",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999952912330627,
                    "sentence": "The paper shows results in practice but falls short in providing a solid theoretical explanation of PoPs characteristics like accurately defining the error \\( \\delta \\).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999945759773254,
                    "sentence": "This hinders its clarity and applicability, across scenarios.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999948143959045,
                    "sentence": "The assessment is mainly centered on the MEN relatedness test; however including benchmarks like SimLex_999 or practical tasks such as text classification could enhance the overall validity of the findings, for broader application purposes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961256980896,
                    "sentence": "The paper recognizes that the performance of PoPs can be affected by factors such as dimensionality and sparsity but notes the challenge of lacking recommendations, for choosing these parameters in real world applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999969005584717,
                    "sentence": "The paper asserts that it performs well compared to embeddings but lacks direct comparisons with popular models such, as Word It is challenging to interpret the results without such contextual information.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979734420776,
                    "sentence": "Queries, for Writers",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979138374329,
                    "sentence": "Could you offer an assessment or limits for the mistake \\( \\delta \\) which arises from the Poisson Point (PoC method)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979734420776,
                    "sentence": "How does this measure up against established projection methods such, as RI?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999978542327881,
                    "sentence": "Have you tested PoS on benchmarks or real world NLP applications yet?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979138374329,
                    "sentence": "If not done yet re planning to expand the evaluation, in research?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999976754188538,
                    "sentence": "How well does PoS function when combined with embedding methods as a starting point or, as a preprocessing step as mentioned in the conversation?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "Could you please explain why Kendalls \\( \\ ) was chosen as the similarity metric and if other measures have been explored for non Gaussian environments?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982714653015,
                    "sentence": "Suggestion",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999985098838806,
                    "sentence": "The research paper introduces an effective approach to creating semantic spaces that show potential in tasks related to semantic similarity tests; though it lacks solid theoretical support and thorough evaluation which are areas for improvement highlighted by the reviewers recommendation of acceptance pending minor revisions addressing these concerns before final approval, during the author response phase.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997932945046396,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997932945046396,
                "mixed": 0.00020670549536025372
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997932945046396,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997932945046396,
                    "human": 0,
                    "mixed": 0.00020670549536025372
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999643634105823,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 3.5636589417744805e-05,
                        "ai_paraphrased": 0.9999643634105823
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 3.563648941774483e-05,
                            "ai_paraphrased": 0.9999643634105823
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "\n\nThe paper presents an approach called Positive only Projection (PoF) which creates semantic spaces and word embeddings through random projections that differ from conventional methods by using a positive random projection matrix \\( R \\). This allows for the implementation of weighting strategies, like Positive Pointwise Mutual Information (PPMI). The authors show that combining PoS with PPM is effective in similarity tasks like the MEN relatedness test, in a way that is both efficient and scalable computationally. \nIntroducing Poisson Point Process (PoPP) an approach to reducing dimensionality randomly that builds semantic spaces gradually and effectively overcomes the drawbacks of current random projection techniques (such as RI) allowing for additional post projection modifications, like PPM transformations. \nThe PoS + PPM + Pearson blend delivers a Spearman correlation of 0 75 on the MEN evaluation, as state of the art embeddings do but without requiring resource intensive training processes. \nThe paper thoroughly examines how dimensionality and sparsity factors and different weighting techniques influence the performance of PoPs (Probability of Performance) shedding light on how they function and can be improved. \nAreas of expertise\nComputational efficiency is a feature of the Poisson Point Process (PoPP) method as it is scalable and economical, in terms of computational resources when compared to neural embeddings. \nThe capacity to employ PPMIs in PoPop built areas is an advantage since it connects random projection methods, with count based models and takes advantage of the strengths of both techniques. \nThe paper presents experimental findings that include comparisons with RI and count based models and detailed examinations of parameters studies to validate the methods effectiveness, across various configurations. \nThe article provides an explanation of the PoI method including its mathematical basis and practical application for those who are knowledgeable, about random projection techniques and distributional semantics. \nAreas of improvement\nThe paper shows results in practice but falls short in providing a solid theoretical explanation of PoPs characteristics like accurately defining the error \\( \\delta \\). This hinders its clarity and applicability, across scenarios. \nThe assessment is mainly centered on the MEN relatedness test; however including benchmarks like SimLex_999 or practical tasks such as text classification could enhance the overall validity of the findings, for broader application purposes. \nThe paper recognizes that the performance of PoPs can be affected by factors such as dimensionality and sparsity but notes the challenge of lacking recommendations, for choosing these parameters in real world applications. \nThe paper asserts that it performs well compared to embeddings but lacks direct comparisons with popular models such, as Word \tIt is challenging to interpret the results without such contextual information. \nQueries, for Writers \nCould you offer an assessment or limits for the mistake \\( \\delta \\) which arises from the Poisson Point (PoC method)? How does this measure up against established projection methods such, as RI? \nHave you tested PoS on benchmarks or real world NLP applications yet? If not done yet re planning to expand the evaluation, in research? \nHow well does PoS function when combined with embedding methods as a starting point or, as a preprocessing step as mentioned in the conversation? \nCould you please explain why Kendalls \\( \\ ) was chosen as the similarity metric and if other measures have been explored for non Gaussian environments? \nSuggestion\nThe research paper introduces an effective approach to creating semantic spaces that show potential in tasks related to semantic similarity tests; though it lacks solid theoretical support and thorough evaluation which are areas for improvement highlighted by the reviewers recommendation of acceptance pending minor revisions addressing these concerns before final approval, during the author response phase. "
        }
    ],
    "editorDocumentId": null
}