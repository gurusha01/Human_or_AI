{
    "version": "2025-03-13-base",
    "scanId": "0a136cba-f6d0-4780-9c06-709c9eda6053",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999964237213135,
                    "sentence": "Contributions;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999968409538269,
                    "sentence": "This study explores how compound nouns can be analyzed for compositionality using a combined approach that incorporates anchored packed trees (APTs) in contrast with the neural word embeddings techniques The authors utilize the dataset by Reddy et al., published in 2011 and consisting of 90 compound nouns along, with human judgments of their compositionality to test their methodologies This papers key findings are;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999996542930603,
                    "sentence": "A new innovative approach called the Integrated APT Approach has been introduced that utilizes APT (Abstract Part of Speech Tags) to syntactic structure in contextual features and align vector spaces before composing them together successfully outperform neural embeddings and previous methods, in detecting compositional relationships.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961256980896,
                    "sentence": "The best results are obtained when using a mix of both aligned and unaligned APT representations, in a composition model This indicates that various contextual factors offer additional valuable insights.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999955296516418,
                    "sentence": "The paper thoroughly compares APT based techniques with neural word embeddings like word vectors (such, as word tovec) and previous reference points to shed light on the advantages and constraints of each method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999947547912598,
                    "sentence": "Areas of expertise;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961853027344,
                    "sentence": "The methods based on APT show results with the hybrid APT model producing a Spearman correlation of 0.79 which surpasses benchmarks like the 0.71 correlation from Reddy et al., 2011.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958872795105,
                    "sentence": "This highlights how effective integrating structure, into compositionality detection can be.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999955296516418,
                    "sentence": "The authors thoroughly designed their experiments by investigating factors such as PPMi smoothing and the dimensionality of embeddings across different composition operations, like additive and intersective methods to ensure a comprehensive evaluation of their techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999949932098389,
                    "sentence": "The uniqueness of Advanced Persistent Threats (APTs); Utilizing dependency paths and alignment within APTs represents an language driven method for compositional analysis.It's the blend of aligned and unaligned APTs in the model that stands out, as inventive and showcases the value of incorporating various viewpoints on context.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958872795105,
                    "sentence": "**Result Clarity;** The research paper effectively communicates its findings through structured tables and rigorous statistical tests which enhance the credibility of the results presented.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999995231628418,
                    "sentence": "Areas, for improvement;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967813491821,
                    "sentence": "The analysis is focused on the dataset from Reddy et al.'",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963641166687,
                    "sentence": "s work in 2013 consisting of 90 compound nouns which may limit the scope of findings due to its size and lack of diversity, in representation; it would be beneficial to conduct tests on more varied datasets to increase the robustness of the conclusions reached.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967217445374,
                    "sentence": "The research specifically targets noun combinations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999997615814209,
                    "sentence": "May not apply to various other types of multiword expressions, like verb phrases or idioms as indicated by the authors who have acknowledged this restriction without offering initial findings on other forms of phrases.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999974966049194,
                    "sentence": "The authors point out that the sparse quality of APT representations may be a drawback but fail to discuss ways to overcome it such as smoothing or reducing dimensionalityá…³an oversight that could have enhanced performance further.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963045120239,
                    "sentence": "In the comparison with models that are discussed in the study report deals primarily with neural embeddings and not extensively with neural compositionality techniques like tensor based models or transformers which can weaken the argument supporting APTs superiority, over neural methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960064888,
                    "sentence": "Questions, for Writers;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963045120239,
                    "sentence": "Have you thought about testing your methods on more varied datasets to see how well they work in different situations?\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961853027344,
                    "sentence": "Could we reduce the sparsity of APT representations by using techniques, like dimensionality reduction or smoothing methods?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961256980896,
                    "sentence": "How does the APT strategy stack up against sophisticated neural composition techniques, like tensor based models or transformer based embeddings?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999969601631165,
                    "sentence": "In summary",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999964833259583,
                    "sentence": "This study adds a perspective to identifying compositionality through a fresh APT based method that integrates syntax into distributional representations.This research shows promise; however the small dataset and focus mainly on noun compounds may limit how broadly the results can be applied.Expanding the analysis to include extensive datasets and delving into advanced neural techniques would enhance the studys robustness.In summary this submission demonstrates a potential for making an impact, in the realm of compositional distributional semantics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997938739332978,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997938739332978,
                "mixed": 0.00020612606670239523
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997938739332978,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997938739332978,
                    "human": 0,
                    "mixed": 0.00020612606670239523
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999979360455759,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.063954424137e-06,
                        "ai_paraphrased": 0.9999979360455759
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.0638544241370297e-06,
                            "ai_paraphrased": 0.9999979360455759
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "\nContributions;   \nThis study explores how compound nouns can be analyzed for compositionality using a combined approach that incorporates anchored packed trees (APTs) in contrast with the neural word embeddings techniques The authors utilize the dataset by Reddy et al., published in 2011 and consisting of 90 compound nouns along, with human judgments of their compositionality to test their methodologies This papers key findings are;   \nA new innovative approach called the Integrated APT Approach has been introduced that utilizes APT (Abstract Part of Speech Tags) to syntactic structure in contextual features and align vector spaces before composing them together successfully outperform neural embeddings and previous methods, in detecting compositional relationships.   \nThe best results are obtained when using a mix of both aligned and unaligned APT representations, in a composition model This indicates that various contextual factors offer additional valuable insights.   \nThe paper thoroughly compares APT based techniques with neural word embeddings like word vectors (such, as word tovec) and previous reference points to shed light on the advantages and constraints of each method.   \nAreas of expertise;   \nThe methods based on APT show results with the hybrid APT model producing a Spearman correlation of 0.79 which surpasses benchmarks like the 0.71 correlation from Reddy et al., 2011. This highlights how effective integrating structure, into compositionality detection can be.   \nThe authors thoroughly designed their experiments by investigating factors such as PPMi smoothing and the dimensionality of embeddings across different composition operations, like additive and intersective methods to ensure a comprehensive evaluation of their techniques.   \nThe uniqueness of Advanced Persistent Threats (APTs); Utilizing dependency paths and alignment within APTs represents an language driven method for compositional analysis.It's the blend of aligned and unaligned APTs in the model that stands out, as inventive and showcases the value of incorporating various viewpoints on context.   \n**Result Clarity;** The research paper effectively communicates its findings through structured tables and rigorous statistical tests which enhance the credibility of the results presented.   \nAreas, for improvement;   \nThe analysis is focused on the dataset from Reddy et al.' s work in 2013 consisting of 90 compound nouns which may limit the scope of findings due to its size and lack of diversity, in representation; it would be beneficial to conduct tests on more varied datasets to increase the robustness of the conclusions reached.   \nThe research specifically targets noun combinations. May not apply to various other types of multiword expressions, like verb phrases or idioms as indicated by the authors who have acknowledged this restriction without offering initial findings on other forms of phrases.   \nThe authors point out that the sparse quality of APT representations may be a drawback but fail to discuss ways to overcome it such as smoothing or reducing dimensionalityâ€”an oversight that could have enhanced performance further.   \nIn the comparison with models that are discussed in the study report deals primarily with neural embeddings and not extensively with neural compositionality techniques like tensor based models or transformers which can weaken the argument supporting APTs superiority, over neural methods.   \nQuestions, for Writers;   \nHave you thought about testing your methods on more varied datasets to see how well they work in different situations?\"  \nCould we reduce the sparsity of APT representations by using techniques, like dimensionality reduction or smoothing methods?   \nHow does the APT strategy stack up against sophisticated neural composition techniques, like tensor based models or transformer based embeddings?   \nIn summary   \nThis study adds a perspective to identifying compositionality through a fresh APT based method that integrates syntax into distributional representations.This research shows promise; however the small dataset and focus mainly on noun compounds may limit how broadly the results can be applied.Expanding the analysis to include extensive datasets and delving into advanced neural techniques would enhance the studys robustness.In summary this submission demonstrates a potential for making an impact, in the realm of compositional distributional semantics. "
        }
    ],
    "editorDocumentId": null
}