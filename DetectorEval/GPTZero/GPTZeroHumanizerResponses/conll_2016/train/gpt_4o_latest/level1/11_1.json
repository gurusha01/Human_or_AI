{
    "version": "2025-03-13-base",
    "scanId": "ddf3dc3e-c9ad-464c-a596-8b571e39ff61",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999943971633911,
                    "sentence": "Check out this review.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999920129776001,
                    "sentence": "Summary of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933838844299,
                    "sentence": "This study focuses on the challenge of recognizing every reference to the idea (PI) outlined in a Wikipedia entryᅳa topic not often explored within coreference resolution (CR).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933242797852,
                    "sentence": "The researchers introduce a method of classification that utilizes the organized markup of Wikipedia and external databases such as Freebase to gather attributes for reference identification tasks effectively Their classifier surpasses standard CR system benchmarks and demonstrates notable enhancements in accuracy metrics like precision and recall along, with F1 scores.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999937415122986,
                    "sentence": "Furthermore \" the researchers show that incorporating their classifier into a rule based coreference resolution system (referred to as Dcorefl ) improves the performance of coreference resolution, on Wikipedia texts.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994695186615,
                    "sentence": "The study also presents a dataset (known as WCR ) for assessing coreference systems using Wikipedia articles.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999859929084778,
                    "sentence": "Key Findings",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999947547912598,
                    "sentence": "The paper explores a challenge of spotting references to the main character in Wikipedia articles and presents the WCR dataset specifically designed for assessing character recognition systems in this type of writing styleᅳa significant addition considering the scarcity of materials for texts, beyond news sources.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999904632568359,
                    "sentence": "The authors have created a classifier that includes features from Wikipedia markup and Freebase such as attributes and entity types along, with positional information to enhance its performance significantly by 13 F₁ points compared to baseline models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999886155128479,
                    "sentence": "The authors have enhanced the coreference resolution performance on Wikipedia texts by incorporating their classifier into the Dcorefsystem.This has led to a 4 point increase in the CoNNL Fscore s howcasing the effectiveness of their approach, in a comprehensive coreference resolution pipeline.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999884963035583,
                    "sentence": "Advantages",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999926090240479,
                    "sentence": "The new classifier shows enhancements compared to existing methods when detecting both pronominal and non pronominal mentions of the main character (MC).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999909400939941,
                    "sentence": "The findings are backed by experiments and, in depth analysis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999921321868896,
                    "sentence": "The research showcases the utilization of Wikipedia markup and Freebase attributes to enhance CR performance without encountering the common pitfalls linked to named entity linking processes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999992847442627,
                    "sentence": "The incorporation of the classifier into Dcorec reveals that the suggested method is not just successful on its own but also improves the capabilities of a established CR system - a valuable addition, to the field.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999991238117218,
                    "sentence": "The WCR dataset plays a role in computational research by offering a specialized database, for Wikipedia content that stands out from the usual newswire datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999802708625793,
                    "sentence": "Areas of opportunity",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999927282333374,
                    "sentence": "The method works great for Wikipedia articles.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999914765357971,
                    "sentence": "Might not be as effective for other types of text or subjects that don't have the same structured resources, like Wikipedia specific markup and Freebase attributes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999995231628418,
                    "sentence": "Feature Engineering Complexity is a factor in the classifiers operation as it heavily depends on numerous manually created features that could pose challenges when applied to different datasets or tasks with varying requirements and characteristics It would be beneficial to include a discussion, on how this approach can be scaled to suit other domains in order to enhance the papers credibility and relevance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958276748657,
                    "sentence": "Evaluation Focus; The assessment primarily centers around identifying multiple choice questions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961853027344,
                    "sentence": "Their influence of coreference resolution (Dcore).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958276748657,
                    "sentence": "However the broader significance, for cognitive reasoning tasks outside of Wikipedia is not extensively examined.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999943971633911,
                    "sentence": "Engaging with Writers; Queries, for Authors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999971389770508,
                    "sentence": "How effectively can the suggested method be applied to types of text or fields that do not have organized formatting similar, to Wikipedia?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999975562095642,
                    "sentence": "In the future could using Freebase be a problem since its no longer regularly updated for this methods applications and are there other knowledge bases that could be used instead?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999971985816956,
                    "sentence": "Have you thought about expanding the classifier to detect references to ideas, in Wikipedia articles and if you have considered it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999970197677612,
                    "sentence": "What difficulties do you foresee encountering?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999971985816956,
                    "sentence": "Additional.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960660934448,
                    "sentence": "Remarks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999943971633911,
                    "sentence": "This article significantly advances the study of coreference resolution by tackling a challenge and presenting a useful dataset while showcasing notable enhancements in performance metrics..",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999940395355225,
                    "sentence": "Using features specific to Wikipedia and external knowledge sources may raise doubts about how broadly applicable this method is.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933838844299,
                    "sentence": "Future research could investigate tailoring the technique, for fields or incorporating more versatile features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 30,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999449919646853,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 5.500803531468506e-05,
                        "ai_paraphrased": 0.9999449919646853
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 5.500793531468509e-05,
                            "ai_paraphrased": 0.9999449919646853
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "Check out this review.\nSummary of the Paper \nThis study focuses on the challenge of recognizing every reference to the idea (PI) outlined in a Wikipedia entry—a topic not often explored within coreference resolution (CR). The researchers introduce a method of classification that utilizes the organized markup of Wikipedia and external databases such as Freebase to gather attributes for reference identification tasks effectively Their classifier surpasses standard CR system benchmarks and demonstrates notable enhancements in accuracy metrics like precision and recall along, with F1 scores. Furthermore \" the researchers show that incorporating their classifier into a rule based coreference resolution system (referred to as Dcorefl ) improves the performance of coreference resolution, on Wikipedia texts.\" The study also presents a dataset (known as WCR ) for assessing coreference systems using Wikipedia articles.\" \nKey Findings\nThe paper explores a challenge of spotting references to the main character in Wikipedia articles and presents the WCR dataset specifically designed for assessing character recognition systems in this type of writing style—a significant addition considering the scarcity of materials for texts, beyond news sources. \nThe authors have created a classifier that includes features from Wikipedia markup and Freebase such as attributes and entity types along, with positional information to enhance its performance significantly by 13 F₁ points compared to baseline models. \nThe authors have enhanced the coreference resolution performance on Wikipedia texts by incorporating their classifier into the Dcorefsystem.This has led to a 4 point increase in the CoNNL Fscore s howcasing the effectiveness of their approach, in a comprehensive coreference resolution pipeline. \nAdvantages\nThe new classifier shows enhancements compared to existing methods when detecting both pronominal and non pronominal mentions of the main character (MC). The findings are backed by experiments and, in depth analysis. \nThe research showcases the utilization of Wikipedia markup and Freebase attributes to enhance CR performance without encountering the common pitfalls linked to named entity linking processes. \nThe incorporation of the classifier into Dcorec reveals that the suggested method is not just successful on its own but also improves the capabilities of a established CR system – a valuable addition, to the field. \nThe WCR dataset plays a role in computational research by offering a specialized database, for Wikipedia content that stands out from the usual newswire datasets. \nAreas of opportunity\nThe method works great for Wikipedia articles. Might not be as effective for other types of text or subjects that don't have the same structured resources, like Wikipedia specific markup and Freebase attributes. \nFeature Engineering Complexity is a factor in the classifiers operation as it heavily depends on numerous manually created features that could pose challenges when applied to different datasets or tasks with varying requirements and characteristics It would be beneficial to include a discussion, on how this approach can be scaled to suit other domains in order to enhance the papers credibility and relevance. \nEvaluation Focus; The assessment primarily centers around identifying multiple choice questions. Their influence of coreference resolution (Dcore). However the broader significance, for cognitive reasoning tasks outside of Wikipedia is not extensively examined. \nEngaging with Writers; Queries, for Authors\nHow effectively can the suggested method be applied to types of text or fields that do not have organized formatting similar, to Wikipedia? \nIn the future could using Freebase be a problem since its no longer regularly updated for this methods applications and are there other knowledge bases that could be used instead? \nHave you thought about expanding the classifier to detect references to ideas, in Wikipedia articles and if you have considered it. What difficulties do you foresee encountering? \nAdditional. Remarks. \nThis article significantly advances the study of coreference resolution by tackling a challenge and presenting a useful dataset while showcasing notable enhancements in performance metrics.. Using features specific to Wikipedia and external knowledge sources may raise doubts about how broadly applicable this method is. Future research could investigate tailoring the technique, for fields or incorporating more versatile features. "
        }
    ],
    "editorDocumentId": null
}