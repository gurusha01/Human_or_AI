{
    "version": "2025-03-13-base",
    "scanId": "6533038f-f0fc-494f-8f53-f15e8de23371",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9841066002845764,
                    "sentence": "The main goal of this study is to show that the word vector models contain information about the parts of speech they represent.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9934922456741333,
                    "sentence": "The researchers work with a modified version of the BNC dataset that includes UD POS annotations and lemmatized words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9939264059066772,
                    "sentence": "They create word embeddings based on this dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9934225082397461,
                    "sentence": "Then employ these embeddings to train a logistic classifier for predicting word POS tags.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99213045835495,
                    "sentence": "The evaluation is done using cross validation within the dataset and also, across other datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9909627437591553,
                    "sentence": "The findings are clearly laid out.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9959993362426758,
                    "sentence": "Thoroughly explored with, in depth analysis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9950087666511536,
                    "sentence": "The paper is nicely written and quite straightforward to grasp; however its main drawback lies in the absence of contributions in the fields of NLP or ML.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.997265636920929,
                    "sentence": "It details a set of experiments without presenting any fresh concepts or approaches within these areas.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9963736534118652,
                    "sentence": "Nevertheless the findings are intriguing as they offer evidence for the notion of POS.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9967585206031799,
                    "sentence": "In this regard it's clear that the paper would be a fit, for a publication center focused specifically on quantitative or empirical linguistics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9970740079879761,
                    "sentence": "Furthermore it would be beneficial if the writers could offer an examination of existing literature regarding POS tagging and POS induction with the utilization of word embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9970421195030212,
                    "sentence": "Some key studies worth exploring are those conducted by Lin et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99615478515625,
                    "sentence": "(2015), Ammar et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9960827827453613,
                    "sentence": "(2015), Duer and Levin (2015), Ling and colleagues from EMNLP (2015) well as Plank et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9966810345649719,
                    "sentence": "(2016) and Søgaard et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9966766238212585,
                    "sentence": "(2016), among others.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 7,
                    "completely_generated_prob": 0.9103421900070616
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                }
            ],
            "completely_generated_prob": 0.9997904215141322,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997904215141322,
                "mixed": 0.00020957848586795538
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997904215141322,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997904215141322,
                    "human": 0,
                    "mixed": 0.00020957848586795538
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9998686668385632,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.00013133316143674543,
                        "ai_paraphrased": 0.9998686668385632
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.00013133306143674545,
                            "ai_paraphrased": 0.9998686668385632
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "The main goal of this study is to show that the word vector models contain information about the parts of speech they represent. The researchers work with a modified version of the BNC dataset that includes UD POS annotations and lemmatized words. They create word embeddings based on this dataset. Then employ these embeddings to train a logistic classifier for predicting word POS tags. The evaluation is done using cross validation within the dataset and also, across other datasets. The findings are clearly laid out. Thoroughly explored with, in depth analysis. \nThe paper is nicely written and quite straightforward to grasp; however its main drawback lies in the absence of contributions in the fields of NLP or ML. It details a set of experiments without presenting any fresh concepts or approaches within these areas. Nevertheless the findings are intriguing as they offer evidence for the notion of POS. In this regard it's clear that the paper would be a fit, for a publication center focused specifically on quantitative or empirical linguistics. \nFurthermore​ it would be beneficial if the writers could offer an examination of existing literature regarding POS tagging and POS induction with the utilization of word embeddings​. Some key studies worth exploring are those conducted by Lin et al​. (2015)​, Ammar et al​. (2015)​, Duer and Levin (2015)​, Ling and colleagues from EMNLP (2015)​ well as Plank et al​.(2016)​​ and Søgaard et al.(2016), among others​​. "
        }
    ],
    "editorDocumentId": null
}