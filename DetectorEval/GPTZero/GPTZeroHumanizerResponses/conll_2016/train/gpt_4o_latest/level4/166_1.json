{
    "version": "2025-03-13-base",
    "scanId": "267fea83-a7fc-45d7-b6c9-467f1d27af42",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9967673420906067,
                    "sentence": "This study presents a method for identifying named entities in languages using information obtained from Wikipedia articles.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9952166676521301,
                    "sentence": "By employing a language Wikifier tool to link phrases in a specific language to relevant English Wikipedia pages and extracting data from those entries the research shows that this innovative technique offers advantages not just in single language contexts but also, in the difficult direct transfer scenario, in which an English based model is tested on a different language.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9966793656349182,
                    "sentence": "This paper impressed me with its ingenuity and thorough execution with its fresh approach to named entity recognition and the extensive experiments conducted to prove its efficacy in various scenarios, such, as low resource languages and non Latin scripts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.997866690158844,
                    "sentence": "What about entities that are not listed in Wikipedia Whats important is looking into how the suggested technique affects recognizing these entities beyond the findings showcased in the study.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9980218410491943,
                    "sentence": "One crucial factor of the process is its dependence on the language Wikifier tool.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9982073307037354,
                    "sentence": "How often do mistakes occur in predictions because of inaccuracies in the Wikifier during this stage, in the process?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9973168969154358,
                    "sentence": "Finally' when we look at how direct transfer performs with Tamil and Bengali languages and when we add features into the mix' I can't help but think about whether it would be a good idea to treat each type of feature differently.'",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9964165687561035,
                    "sentence": "This approach could help avoid the model relying much just' 0on lexical features alone.'",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9991667442893469,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9991667442893469,
                "mixed": 0.0008332557106530633
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9991667442893469,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9991667442893469,
                    "human": 0,
                    "mixed": 0.0008332557106530633
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9998677254890344,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.00013227451096555786,
                        "ai_paraphrased": 0.9998677254890344
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.00013227441096555788,
                            "ai_paraphrased": 0.9998677254890344
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This study presents a method for identifying named entities in languages using information obtained from Wikipedia articles. By employing a language Wikifier tool to link phrases in a specific language to relevant English Wikipedia pages and extracting data from those entries the research shows that this innovative technique offers advantages not just in single language contexts but also, in the difficult direct transfer scenario, in which an English based model is tested on a different language. \nThis paper impressed me with its ingenuity and thorough execution with its fresh approach to named entity recognition and the extensive experiments conducted to prove its efficacy in various scenarios, such, as low resource languages and non Latin scripts. \nWhat about entities that are not listed in Wikipedia Whats important is looking into how the suggested technique affects recognizing these entities beyond the findings showcased in the study. \nOne crucial factor of the process is its dependence on the language Wikifier tool. How often do mistakes occur in predictions because of inaccuracies in the Wikifier during this stage, in the process? \nFinally' when we look at how direct transfer performs with Tamil and Bengali languages and when we add features into the mix' I can't help but think about whether it would be a good idea to treat each type of feature differently.' This approach could help avoid the model relying much just' 0on lexical features alone.'"
        }
    ],
    "editorDocumentId": null
}