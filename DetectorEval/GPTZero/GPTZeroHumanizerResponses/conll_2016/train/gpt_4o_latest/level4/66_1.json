{
    "version": "2025-03-13-base",
    "scanId": "2978d64f-4f93-412e-bceb-af167e0ddeb0",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9964845776557922,
                    "sentence": "This study presents a Stack LSTM parser that extends the groundwork laid out by Henderson and colleagues in 2008 and 2013 regarding joint syntactic and semantic transition based parsing as well as the stack LSTM syntactic parsing by Dyer et al in 2015 The integration of the transition system from the former with the stack LSTM from the latter yields impressive outcomes when evaluated against combined systems, in the CoNLL 2008 and 2009 collaborative assignments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9964188933372498,
                    "sentence": "The paper impressed me a lot because it was very clear and had explanations along with strong references to previous work and interesting findings in the results section.The methodology seems reliable overall; however I do have an issue with the Chinese embeddings as they imply that having top notch embeddings could be more valuable, than having a groundbreaking model design.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9981536865234375,
                    "sentence": "Moreover the systems explanation is thorough the selection of hyperparameters is clearly.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9981606602668762,
                    "sentence": "The discussion is both interesting and thought provoking.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986370205879211,
                    "sentence": "The only thing I would like to mention is that the suggested system doesn't bring new ideas to the table in my opinion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992745518684387,
                    "sentence": "Henderson and colleagues established the foundation for synchronized joint syntax and semantic transition based parsing a few years back while last year saw the introduction of the stack LSTM approach, by Dyers and team.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987795352935791,
                    "sentence": "Therefore the approach itself isn't completely groundbreaking.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988978505134583,
                    "sentence": "Having said that I think this parser represents an essential step forward and I'm happy to see it explored in this research.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                }
            ],
            "completely_generated_prob": 0.9997932945046397,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997932945046397,
                "mixed": 0.00020670549536025372
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997932945046397,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997932945046397,
                    "human": 0,
                    "mixed": 0.00020670549536025372
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999892331226761,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 1.0766877324023857e-05,
                        "ai_paraphrased": 0.9999892331226761
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 1.0766777324023887e-05,
                            "ai_paraphrased": 0.9999892331226761
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This study presents a Stack LSTM parser that extends the groundwork laid out by Henderson and colleagues in 2008 and 2013 regarding joint syntactic and semantic transition based parsing as well as the stack LSTM syntactic parsing by Dyer et al in 2015 The integration of the transition system from the former with the stack LSTM from the latter yields impressive outcomes when evaluated against combined systems, in the CoNLL 2008 and 2009 collaborative assignments. \nThe paper impressed me a lot because it was very clear and had explanations along with strong references to previous work and interesting findings in the results section.The methodology seems reliable overall; however I do have an issue with the Chinese embeddings as they imply that having top notch embeddings could be more valuable, than having a groundbreaking model design. \nMoreover the systems explanation is thorough the selection of hyperparameters is clearly. The discussion is both interesting and thought provoking. \nThe only thing I would like to mention is that the suggested system doesn't bring new ideas to the table in my opinion. Henderson and colleagues established the foundation for synchronized joint syntax and semantic transition based parsing a few years back while last year saw the introduction of the stack LSTM approach, by Dyers and team. Therefore the approach itself isn't completely groundbreaking. Having said that I think this parser represents an essential step forward and I'm happy to see it explored in this research. "
        }
    ],
    "editorDocumentId": null
}