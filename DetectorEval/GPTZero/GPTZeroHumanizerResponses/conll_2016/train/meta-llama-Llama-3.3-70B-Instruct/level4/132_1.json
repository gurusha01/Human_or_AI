{
    "version": "2025-03-13-base",
    "scanId": "2c636c56-93c8-4043-8fff-6b33257c573c",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.999995768070221,
                    "sentence": "Combining word embeddings with topic modeling in a study is quite interesting!.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999962449073792,
                    "sentence": "The main problem here is the complex technical details in the paper that are hard to follow for readers not well versed in word embeddings and topic modeling methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958872795105,
                    "sentence": "It's crucial to simplify Section 1 to give an easy to understand summary of how these models work together effectively for those already familiar, with them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999955296516418,
                    "sentence": "Unfortunately the current explanation doesn't quite hit the mark in achieving this level of clarity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999996542930603,
                    "sentence": "I appreciate your feedback.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958872795105,
                    "sentence": "The third paragraph in the introduction is a bit confusing, to me because when you mention \"deriving an approximation \" I'm not sure what exactly is being approximated and why developing prototypes takes so much time with this approach.There's also no explanation given for why evaluating features is considered easy in this context.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958872795105,
                    "sentence": "What is the reason behind opting to use identical word vectors, for both the pivot and target languages straying from the word embedding method of word vectors like in word 2020vec?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999966621398926,
                    "sentence": "The explanation of how wordsre separated based on their distribution is not very clear in this context..",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960064888,
                    "sentence": "Moreover,\"co adaptation\"is a term that lacks clarity in its meaning..",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963641166687,
                    "sentence": "The phrase \"If we only included structure up, to this point.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999966621398926,
                    "sentence": "is also vague.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999974966049194,
                    "sentence": "Which specific kind of structure is being talked about here?.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999969005584717,
                    "sentence": "There is a mistake, in the text - \"its similarity\" should actually be \"its similarity.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961853027344,
                    "sentence": "Additionally Footnote 1 may impact the anonymity aspect.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963641166687,
                    "sentence": "One major issue is the absence of assessment, in the realm of NLP research nowadays goes beyond just depending on sample groupings for proof of concept validity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961853027344,
                    "sentence": "The depiction shown in Figure 2 seems to offer an evaluation; however its explanation gets lost within a lengthy caption.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999949336051941,
                    "sentence": "The final assessment exaggerates the models abilities when it comes to word analogies by showcasing a few specific instances (, like king + queen) instead of offering a thorough showcase of its capabilities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999944567680359,
                    "sentence": "Mentioned work by Chang lacks details with the name of the conference/journal shortened to \"Advances, in...‚Äù.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999957084655762,
                    "sentence": "Providing more specific information would assist in pinpoint accuracy of the venue.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9999999999999999,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9999999999999999,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9999999999999999,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9999999999999999,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999965825110384,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 3.4174889615556777e-06,
                        "ai_paraphrased": 0.9999965825110384
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 3.4173889615557076e-06,
                            "ai_paraphrased": 0.9999965825110384
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "Combining word embeddings with topic modeling in a study is quite interesting!. The main problem here is the complex technical details in the paper that are hard to follow for readers not well versed in word embeddings and topic modeling methods. It's crucial to simplify Section 1 to give an easy to understand summary of how these models work together effectively for those already familiar, with them. Unfortunately the current explanation doesn‚Äôt quite hit the mark in achieving this level of clarity. \nI appreciate your feedback.\nThe third paragraph in the introduction is a bit confusing, to me because when you mention \"deriving an approximation \" I'm not sure what exactly is being approximated and why developing prototypes takes so much time with this approach.There's also no explanation given for why evaluating features is considered easy in this context. \nWhat is the reason behind opting to use identical word vectors, for both the pivot and target languages straying from the word embedding method of word vectors like in word 2020vec? \nThe explanation of how wordsre separated based on their distribution is not very clear in this context.. Moreover,\"co adaptation\"is a term that lacks clarity in its meaning.. The phrase \"If we only included structure up, to this point.\" is also vague. Which specific kind of structure is being talked about here?.\nThere is a mistake, in the text ‚Äì \"its similarity\" should actually be \"its similarity.\" Additionally Footnote 1 may impact the anonymity aspect. \nOne major issue is the absence of assessment, in the realm of NLP research nowadays goes beyond just depending on sample groupings for proof of concept validity. The depiction shown in Figure 2 seems to offer an evaluation; however its explanation gets lost within a lengthy caption. \nThe final assessment exaggerates the models abilities when it comes to word analogies by showcasing a few specific instances (, like king + queen) instead of offering a thorough showcase of its capabilities. \nMentioned work by Chang lacks details with the name of the conference/journal shortened to \"Advances, in...‚Äù. Providing more specific information would assist in pinpoint accuracy of the venue. "
        }
    ],
    "editorDocumentId": null
}