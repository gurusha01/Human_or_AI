{
    "version": "2025-03-13-base",
    "scanId": "58f771e8-7613-4570-a073-8f5f33744c45",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999816417694092,
                    "sentence": "This document suggests a Stack LSTM parser that extends the groundwork laid by Henderson and colleagues (2008 and 2013) focusing on syntactic and semantic transition based parsing techniques like those introduced by Dyer et al.(2015).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999855160713196,
                    "sentence": "By merging the transition system from the work with the stack LSTM approach from the latter study the writers demonstrate significant advancements when compared to combined systems, in CoNLL 2008 and 2009 shared tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999914169311523,
                    "sentence": "This paper is really well written in my opinion!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999847412109375,
                    "sentence": "It has explanations and a comprehensive examination of previous research alongside interesting findings to boot!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999820590019226,
                    "sentence": "The methodology seems strong overall; however I do have a concern about the Chinese embeddings used.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999841451644897,
                    "sentence": "It makes me think that superior quality embeddings may offer more insight, than even the most advanced models out there.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99997878074646,
                    "sentence": "The system overview is brief yet informative; the hyperparameters are adequately.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999839067459106,
                    "sentence": "The discussions are captivating to read through it all!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999982476234436,
                    "sentence": "My only point of critique would be that the suggested system might not bring forward novel ideas since Henderson et al.s work had already paved the way, for semi synchronized joint syntax semantics transition based parsing a few years back and Dyer et al.s team has recently come up with the stack LSTM model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999876022338867,
                    "sentence": "I believe the field has been eagerly anticipating a parser that combines these ideas and I am happy to see it successfully implemented in this work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999931183682035,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 6.881631796590374e-06,
                        "ai_paraphrased": 0.9999931183682035
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 6.881531796590405e-06,
                            "ai_paraphrased": 0.9999931183682035
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This document suggests a Stack LSTM parser that extends the groundwork laid by Henderson and colleagues (2008 and 2013) focusing on syntactic and semantic transition based parsing techniques like those introduced by Dyer et al.(2015). By merging the transition system from the work with the stack LSTM approach from the latter study the writers demonstrate significant advancements when compared to combined systems, in CoNLL 2008 and 2009 shared tasks. \nThis paper is really well written in my opinion! It has explanations and a comprehensive examination of previous research alongside interesting findings to boot! The methodology seems strong overall; however I do have a concern about the Chinese embeddings used. It makes me think that superior quality embeddings may offer more insight, than even the most advanced models out there. \nThe system overview is brief yet informative; the hyperparameters are adequately. The discussions are captivating to read through it all! My only point of critique would be that the suggested system might not bring forward novel ideas since Henderson et al.s work had already paved the way, for semi synchronized joint syntax semantics transition based parsing a few years back and Dyer et al.s team has recently come up with the stack LSTM model. I believe the field has been eagerly anticipating a parser that combines these ideas and I am happy to see it successfully implemented in this work. "
        }
    ],
    "editorDocumentId": null
}