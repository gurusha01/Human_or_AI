{
    "version": "2025-03-13-base",
    "scanId": "e07d9a51-7c2d-48bc-8d9c-6c2f0672f386",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.999963641166687,
                    "sentence": "This study introduces a method for combined syntactic and semantic dependency parsing by utilizing the latest developments, in representation learning to avoid costly feature extraction processes.The key points highlighted in this research are;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999420642852783,
                    "sentence": "The researchers suggest a combined parsing approach that creates both semantic dependencies together by employing a stack LSTM to understand the algorithms overall state better.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999650120735168,
                    "sentence": "The parser utilizes a greedy inference algorithm that operates with linear time complexity to enhance efficiency and scalability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999328255653381,
                    "sentence": "The model demonstrates performance in the CoNNL 2008 and 2009 English tasks compared to earlier joint parsing models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999358057975769,
                    "sentence": "The papers notable aspects are;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999204874038696,
                    "sentence": "A fresh perspective is introduced by the writers as they suggest a method for combined parsing by utilizing representation learning to avoid the need, for costly feature extraction processes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999064207077026,
                    "sentence": "A quick and effective algorithm is the inference method, with linear time complexity that ensures efficiency and scalability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999901533126831,
                    "sentence": "The model excels, in performance demonstrating top notch results in the CoNNL 2008 and 2009 tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999368190765381,
                    "sentence": "The papers shortcomings are as follows;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999227523803711,
                    "sentence": "The authors only make a comparison by comparing their model to a small number of previous joint parsing models and fail to offer a thorough comparison, with other cutting edge models available.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999259114265442,
                    "sentence": "The authors did not thoroughly examine the models performance by lacking an analysis that includes error analysis and ablation studies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998878836631775,
                    "sentence": "Depending on existing word associations can be a limitation as not all languages and subject areas may have readily accessible pretrained embeddings available for use, within the model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998941421508789,
                    "sentence": "Authors are often asked questions;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998857378959656,
                    "sentence": "What is the models performance like, in languages and areas of study and what challenges does the method face?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999098777770996,
                    "sentence": "Could the writers offer a comprehensive examination of how well the model performs by delving into error analysis and conducting ablation studies?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999899685382843,
                    "sentence": "How does this model stack up against cutting edge models out there.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999046921730042,
                    "sentence": "Especially the ones that rely on expert designed features and intricate inference algorithms?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999834789358084,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 1.6521064191579725e-05,
                        "ai_paraphrased": 0.9999834789358084
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 1.6520964191579755e-05,
                            "ai_paraphrased": 0.9999834789358084
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This study introduces a method for combined syntactic and semantic dependency parsing by utilizing the latest developments, in representation learning to avoid costly feature extraction processes.The key points highlighted in this research are; \nThe researchers suggest a combined parsing approach that creates both semantic dependencies together by employing a stack LSTM to understand the algorithms overall state better. \nThe parser utilizes a greedy inference algorithm that operates with linear time complexity to enhance efficiency and scalability. \nThe model demonstrates performance in the CoNNL 2008 and 2009 English tasks compared to earlier joint parsing models. \nThe papers notable aspects are; \nA fresh perspective is introduced by the writers as they suggest a method for combined parsing by utilizing representation learning to avoid the need, for costly feature extraction processes. \nA quick and effective algorithm is the inference method, with linear time complexity that ensures efficiency and scalability. \nThe model excels, in performance demonstrating top notch results in the CoNNL 2008 and 2009 tasks. \nThe papers shortcomings are as follows; \nThe authors only make a comparison by comparing their model to a small number of previous joint parsing models and fail to offer a thorough comparison, with other cutting edge models available. \nThe authors did not thoroughly examine the models performance by lacking an analysis that includes error analysis and ablation studies. \nDepending on existing word associations can be a limitation as not all languages and subject areas may have readily accessible pretrained embeddings available for use, within the model. \nAuthors are often asked questions; \nWhat is the models performance like, in languages and areas of study and what challenges does the method face? \nCould the writers offer a comprehensive examination of how well the model performs by delving into error analysis and conducting ablation studies? \nHow does this model stack up against cutting edge models out there. Especially the ones that rely on expert designed features and intricate inference algorithms? "
        }
    ],
    "editorDocumentId": null
}